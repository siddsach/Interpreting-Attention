Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'type': 'continuous', 'domain': [0, 30], 'name': 'lr'}, {'type': 'continuous', 'domain': [0, 1], 'name': 'dropout'}, {'type': 'continuous', 'domain': [2, 8], 'name': 'anneal'}]
SETTINGS FOR THIS RUN
{'lr': 29.228843599931064, 'data': 'wikitext', 'dropout': 0.2464177359755153, 'anneal': 6.926870369946397, 'wordvec_source': '', 'num_layers': 1, 'wordvec_dim': 200, 'batch_size': 80, 'seq_len': 20, 'tune_wordvecs': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.865687608718872 and batch: 50, loss is 6.94115252494812 and perplexity is 1033.9611945838478
At time: 2.924936532974243 and batch: 100, loss is 6.221020021438599 and perplexity is 503.2162617003071
At time: 3.9852285385131836 and batch: 150, loss is 6.05591703414917 and perplexity is 426.62996036456246
At time: 5.048008680343628 and batch: 200, loss is 6.014064960479736 and perplexity is 409.1430950408871
At time: 6.110461473464966 and batch: 250, loss is 6.015647478103638 and perplexity is 409.79108379106253
At time: 7.172048091888428 and batch: 300, loss is 5.997776651382447 and perplexity is 402.53282703441937
At time: 8.234947919845581 and batch: 350, loss is 5.975940828323364 and perplexity is 393.8384612202735
At time: 9.299975872039795 and batch: 400, loss is 6.017307758331299 and perplexity is 410.4720169384553
At time: 10.363912343978882 and batch: 450, loss is 5.979627017974853 and perplexity is 395.2929035085255
At time: 11.428960084915161 and batch: 500, loss is 5.996509113311768 and perplexity is 402.02292458011146
At time: 12.494666576385498 and batch: 550, loss is 5.959803190231323 and perplexity is 387.53384628526464
At time: 13.559204339981079 and batch: 600, loss is 5.913240032196045 and perplexity is 369.9027126189361
At time: 14.62417459487915 and batch: 650, loss is 5.944117298126221 and perplexity is 381.5024596916814
At time: 15.688847541809082 and batch: 700, loss is 5.955891170501709 and perplexity is 386.02076775889344
At time: 16.756534337997437 and batch: 750, loss is 5.947749338150024 and perplexity is 382.8906112795161
At time: 17.821646451950073 and batch: 800, loss is 5.909716148376464 and perplexity is 368.6015124207802
At time: 18.887832403182983 and batch: 850, loss is 5.907621574401856 and perplexity is 367.8302572932945
At time: 19.953766345977783 and batch: 900, loss is 5.936322221755981 and perplexity is 378.5401794829696
At time: 21.020126819610596 and batch: 950, loss is 5.9000155544281006 and perplexity is 365.0431458585355
At time: 22.09655451774597 and batch: 1000, loss is 5.9185468864440915 and perplexity is 371.87095035692346
At time: 23.157835006713867 and batch: 1050, loss is 5.8945919799804685 and perplexity is 363.0686663885411
At time: 24.21873950958252 and batch: 1100, loss is 5.905879983901977 and perplexity is 367.19020512779065
At time: 25.2791645526886 and batch: 1150, loss is 5.9005700206756595 and perplexity is 365.24560608531107
At time: 26.339056253433228 and batch: 1200, loss is 5.891069192886352 and perplexity is 361.79190297952823
At time: 27.39988136291504 and batch: 1250, loss is 5.888114929199219 and perplexity is 360.72465154555357
At time: 28.459619998931885 and batch: 1300, loss is 5.877645130157471 and perplexity is 356.96763883770404
At time: 29.517468214035034 and batch: 1350, loss is 5.849021644592285 and perplexity is 346.8948279734479
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.421243082682292 and perplexity of 226.16008352021518
Finished 1 epochs...
Completing Train Step...
At time: 32.76070523262024 and batch: 50, loss is 5.790800819396972 and perplexity is 327.27500763559084
At time: 33.81173396110535 and batch: 100, loss is 5.885476541519165 and perplexity is 359.774174483872
At time: 34.86401581764221 and batch: 150, loss is 5.828367919921875 and perplexity is 339.80363950992864
At time: 35.91853380203247 and batch: 200, loss is 5.776211404800415 and perplexity is 322.53491850233365
At time: 36.971110582351685 and batch: 250, loss is 5.8509241771698 and perplexity is 347.55543489847395
At time: 38.02571630477905 and batch: 300, loss is 5.866675758361817 and perplexity is 353.07332621898416
At time: 39.077834606170654 and batch: 350, loss is 5.875914182662964 and perplexity is 356.350281058731
At time: 40.13303565979004 and batch: 400, loss is 5.887371063232422 and perplexity is 360.4564205302145
At time: 41.18644428253174 and batch: 450, loss is 5.868848075866699 and perplexity is 353.8411472596372
At time: 42.23963499069214 and batch: 500, loss is 5.902202072143555 and perplexity is 365.84219241023675
At time: 43.29350662231445 and batch: 550, loss is 5.8542016410827635 and perplexity is 348.6964040153258
At time: 44.346580505371094 and batch: 600, loss is 5.811538181304932 and perplexity is 334.1326872507985
At time: 45.40254473686218 and batch: 650, loss is 5.817338218688965 and perplexity is 336.07630039386294
At time: 46.457252502441406 and batch: 700, loss is 5.821627750396728 and perplexity is 337.5210066821205
At time: 47.51356053352356 and batch: 750, loss is 5.802822790145874 and perplexity is 331.23324342888986
At time: 48.568740367889404 and batch: 800, loss is 5.802405300140381 and perplexity is 331.09498572288476
At time: 49.622697830200195 and batch: 850, loss is 5.779781932830811 and perplexity is 323.6885968644373
At time: 50.72052574157715 and batch: 900, loss is 5.847383251190186 and perplexity is 346.3269431125112
At time: 51.7760272026062 and batch: 950, loss is 5.826630239486694 and perplexity is 339.21368210092237
At time: 52.83305811882019 and batch: 1000, loss is 5.824009189605713 and perplexity is 338.3257502849484
At time: 53.88966464996338 and batch: 1050, loss is 5.854759712219238 and perplexity is 348.89105572349723
At time: 54.94723701477051 and batch: 1100, loss is 5.804013700485229 and perplexity is 331.62794750516053
At time: 56.00454378128052 and batch: 1150, loss is 5.811089706420899 and perplexity is 333.9828707296166
At time: 57.082754611968994 and batch: 1200, loss is 5.811582336425781 and perplexity is 334.1474412457136
At time: 58.18691325187683 and batch: 1250, loss is 5.8125088500976565 and perplexity is 334.45717688344433
At time: 59.29887247085571 and batch: 1300, loss is 5.790527181625366 and perplexity is 327.18546508347
At time: 60.4133095741272 and batch: 1350, loss is 5.763570413589478 and perplexity is 318.48341886847965
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.606102701822917 and perplexity of 272.08178515646796
Annealing...
Finished 2 epochs...
Completing Train Step...
At time: 63.76942586898804 and batch: 50, loss is 5.756792783737183 and perplexity is 316.3321546127964
At time: 64.89966559410095 and batch: 100, loss is 5.731231737136841 and perplexity is 308.34883928007577
At time: 66.00317287445068 and batch: 150, loss is 5.6747320365905765 and perplexity is 291.4102408004524
At time: 67.10601449012756 and batch: 200, loss is 5.650378313064575 and perplexity is 284.39903734616234
At time: 68.20901465415955 and batch: 250, loss is 5.671516199111938 and perplexity is 290.4746180381202
At time: 69.3161187171936 and batch: 300, loss is 5.669701814651489 and perplexity is 289.9480632358735
At time: 70.42542338371277 and batch: 350, loss is 5.646126613616944 and perplexity is 283.1924250103269
At time: 71.53666043281555 and batch: 400, loss is 5.673692092895508 and perplexity is 291.10734808083845
At time: 72.65374946594238 and batch: 450, loss is 5.6451218318939205 and perplexity is 282.90802134330863
At time: 73.77035641670227 and batch: 500, loss is 5.663085336685181 and perplexity is 288.0359609311118
At time: 74.89230012893677 and batch: 550, loss is 5.6310967922210695 and perplexity is 278.9679197460005
At time: 76.02126383781433 and batch: 600, loss is 5.582448167800903 and perplexity is 265.721340561808
At time: 77.15390086174011 and batch: 650, loss is 5.612919540405273 and perplexity is 273.9428588797677
At time: 78.33307576179504 and batch: 700, loss is 5.640501689910889 and perplexity is 281.6039609084199
At time: 79.45724868774414 and batch: 750, loss is 5.603202037811279 and perplexity is 271.29371083601393
At time: 80.58162498474121 and batch: 800, loss is 5.572210016250611 and perplexity is 263.0147242233157
At time: 81.70658540725708 and batch: 850, loss is 5.555133419036865 and perplexity is 258.56145924025884
At time: 82.83091402053833 and batch: 900, loss is 5.572679529190063 and perplexity is 263.1382420339412
At time: 83.95520114898682 and batch: 950, loss is 5.537338733673096 and perplexity is 254.0011345327918
At time: 85.078768491745 and batch: 1000, loss is 5.547908039093017 and perplexity is 256.69998747712765
At time: 86.20319247245789 and batch: 1050, loss is 5.522712574005127 and perplexity is 250.31310994783738
At time: 87.32735776901245 and batch: 1100, loss is 5.487955341339111 and perplexity is 241.76237961058845
At time: 88.45188546180725 and batch: 1150, loss is 5.4832701492309575 and perplexity is 240.63232574446877
At time: 89.57646799087524 and batch: 1200, loss is 5.47293212890625 and perplexity is 238.1574784225984
At time: 90.70140981674194 and batch: 1250, loss is 5.497881078720093 and perplexity is 244.17399824641635
At time: 91.82455611228943 and batch: 1300, loss is 5.446181287765503 and perplexity is 231.87102439896407
At time: 92.94825148582458 and batch: 1350, loss is 5.443810348510742 and perplexity is 231.3219234848551
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.3323356119791665 and perplexity of 206.92069666850267
Finished 3 epochs...
Completing Train Step...
At time: 96.30892157554626 and batch: 50, loss is 5.559701194763184 and perplexity is 259.74521149674297
At time: 97.43440222740173 and batch: 100, loss is 5.57479923248291 and perplexity is 263.69660860871966
At time: 98.53135299682617 and batch: 150, loss is 5.5354400062561036 and perplexity is 253.5193131831644
At time: 99.62808442115784 and batch: 200, loss is 5.52020824432373 and perplexity is 249.6870276823674
At time: 100.73416876792908 and batch: 250, loss is 5.544901685714722 and perplexity is 255.92941548879688
At time: 101.84526753425598 and batch: 300, loss is 5.544508028030395 and perplexity is 255.82868673536925
At time: 102.96229195594788 and batch: 350, loss is 5.539154682159424 and perplexity is 254.46280656801895
At time: 104.07947826385498 and batch: 400, loss is 5.56676836013794 and perplexity is 261.5873756337857
At time: 105.19656157493591 and batch: 450, loss is 5.543587989807129 and perplexity is 255.59342280746318
At time: 106.3130087852478 and batch: 500, loss is 5.566936464309692 and perplexity is 261.63135325921513
At time: 107.45805239677429 and batch: 550, loss is 5.539870891571045 and perplexity is 254.64512050467587
At time: 108.57500338554382 and batch: 600, loss is 5.4906995677948 and perplexity is 242.42674149150082
At time: 109.69212484359741 and batch: 650, loss is 5.520484972000122 and perplexity is 249.7561325545374
At time: 110.80948138237 and batch: 700, loss is 5.551275444030762 and perplexity is 257.56585733148387
At time: 111.92963600158691 and batch: 750, loss is 5.521041927337646 and perplexity is 249.8952743099179
At time: 113.05164098739624 and batch: 800, loss is 5.49333004951477 and perplexity is 243.065280067258
At time: 114.17472410202026 and batch: 850, loss is 5.477906179428101 and perplexity is 239.34503679162637
At time: 115.29707646369934 and batch: 900, loss is 5.49905915260315 and perplexity is 244.46182276265637
At time: 116.4199788570404 and batch: 950, loss is 5.467157573699951 and perplexity is 236.78618802224125
At time: 117.54247546195984 and batch: 1000, loss is 5.485858192443848 and perplexity is 241.2558991713452
At time: 118.67617797851562 and batch: 1050, loss is 5.457754230499267 and perplexity is 234.57004215099775
At time: 119.80891728401184 and batch: 1100, loss is 5.433363637924194 and perplexity is 228.9179489737316
At time: 120.94190192222595 and batch: 1150, loss is 5.434531526565552 and perplexity is 229.18545582484154
At time: 122.07494449615479 and batch: 1200, loss is 5.420966215133667 and perplexity is 226.09747579971722
At time: 123.20793890953064 and batch: 1250, loss is 5.449648056030274 and perplexity is 232.67626248831894
At time: 124.34050250053406 and batch: 1300, loss is 5.406278400421143 and perplexity is 222.80086722128127
At time: 125.47368264198303 and batch: 1350, loss is 5.404062128067016 and perplexity is 222.30762659845564
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.3137300618489585 and perplexity of 203.1064166929996
Finished 4 epochs...
Completing Train Step...
At time: 128.8488597869873 and batch: 50, loss is 5.495312519073487 and perplexity is 243.54762754739397
At time: 129.95125889778137 and batch: 100, loss is 5.5125280952453615 and perplexity is 247.77673912708124
At time: 131.0533230304718 and batch: 150, loss is 5.4759019947052 and perplexity is 238.86582549976788
At time: 132.16300082206726 and batch: 200, loss is 5.46158618927002 and perplexity is 235.4706292857477
At time: 133.27274370193481 and batch: 250, loss is 5.486719121932984 and perplexity is 241.4636929244199
At time: 134.38271689414978 and batch: 300, loss is 5.482901668548584 and perplexity is 240.54367371516048
At time: 135.5382902622223 and batch: 350, loss is 5.48159857749939 and perplexity is 240.2304275454675
At time: 136.6589047908783 and batch: 400, loss is 5.510379657745362 and perplexity is 247.24497772172637
At time: 137.7808322906494 and batch: 450, loss is 5.484674482345581 and perplexity is 240.9704910807746
At time: 138.9109742641449 and batch: 500, loss is 5.513811044692993 and perplexity is 248.09482816012473
At time: 140.05179262161255 and batch: 550, loss is 5.491008167266846 and perplexity is 242.50156580071223
At time: 141.19297409057617 and batch: 600, loss is 5.440692539215088 and perplexity is 230.601828983511
At time: 142.3354516029358 and batch: 650, loss is 5.4683755683898925 and perplexity is 237.074768050699
At time: 143.47644090652466 and batch: 700, loss is 5.495960340499878 and perplexity is 243.70545403503658
At time: 144.61701488494873 and batch: 750, loss is 5.468708028793335 and perplexity is 237.15359912711085
At time: 145.75822377204895 and batch: 800, loss is 5.446552429199219 and perplexity is 231.95709731502137
At time: 146.89970135688782 and batch: 850, loss is 5.430950746536255 and perplexity is 228.36626067574252
At time: 148.0406301021576 and batch: 900, loss is 5.456041460037231 and perplexity is 234.1686213804757
At time: 149.1821722984314 and batch: 950, loss is 5.423605861663819 and perplexity is 226.6950816042356
At time: 150.32244634628296 and batch: 1000, loss is 5.442096490859985 and perplexity is 230.92581017437547
At time: 151.46373105049133 and batch: 1050, loss is 5.409960470199585 and perplexity is 223.62274774324013
At time: 152.60485982894897 and batch: 1100, loss is 5.3904198551177975 and perplexity is 219.29543854032437
At time: 153.74639654159546 and batch: 1150, loss is 5.400697345733643 and perplexity is 221.56086687042577
At time: 154.88652157783508 and batch: 1200, loss is 5.384529981613159 and perplexity is 218.00761243655523
At time: 156.02634811401367 and batch: 1250, loss is 5.413313751220703 and perplexity is 224.37387632791328
At time: 157.16601967811584 and batch: 1300, loss is 5.372626504898071 and perplexity is 215.42794784680376
At time: 158.30606365203857 and batch: 1350, loss is 5.371486673355102 and perplexity is 215.18253616716785
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.302839762369792 and perplexity of 200.90652745731438
Finished 5 epochs...
Completing Train Step...
At time: 161.71378135681152 and batch: 50, loss is 5.4492733192443845 and perplexity is 232.58908646861227
At time: 162.82772970199585 and batch: 100, loss is 5.466524095535278 and perplexity is 236.63623664290986
At time: 163.97018575668335 and batch: 150, loss is 5.432746438980103 and perplexity is 228.77670464974898
At time: 165.08417558670044 and batch: 200, loss is 5.419866151809693 and perplexity is 225.84889101351834
At time: 166.1987566947937 and batch: 250, loss is 5.444787139892578 and perplexity is 231.54798713668396
At time: 167.31377625465393 and batch: 300, loss is 5.435119400024414 and perplexity is 229.32022748193688
At time: 168.42741346359253 and batch: 350, loss is 5.439961042404175 and perplexity is 230.43320616206586
At time: 169.54107213020325 and batch: 400, loss is 5.471148986816406 and perplexity is 237.733188196115
At time: 170.65535354614258 and batch: 450, loss is 5.442861890792846 and perplexity is 231.10262843368858
At time: 171.76951503753662 and batch: 500, loss is 5.471268348693847 and perplexity is 237.76156616937865
At time: 172.88358855247498 and batch: 550, loss is 5.450271329879761 and perplexity is 232.82132872142293
At time: 173.9999225139618 and batch: 600, loss is 5.39753493309021 and perplexity is 220.86130671570032
At time: 175.1199927330017 and batch: 650, loss is 5.427071199417115 and perplexity is 227.48201934403556
At time: 176.23974227905273 and batch: 700, loss is 5.456103067398072 and perplexity is 234.18304833562937
At time: 177.35930013656616 and batch: 750, loss is 5.430158433914184 and perplexity is 228.18539486554783
At time: 178.47913432121277 and batch: 800, loss is 5.407590608596802 and perplexity is 223.09342024404847
At time: 179.60137701034546 and batch: 850, loss is 5.39496356010437 and perplexity is 220.29411945551183
At time: 180.73234248161316 and batch: 900, loss is 5.415582246780396 and perplexity is 224.8834452289457
At time: 181.8632516860962 and batch: 950, loss is 5.399774150848389 and perplexity is 221.35641739923244
At time: 182.9932587146759 and batch: 1000, loss is 5.413803873062133 and perplexity is 224.4838738192325
At time: 184.12905979156494 and batch: 1050, loss is 5.384709968566894 and perplexity is 218.04685449403195
At time: 185.26788020133972 and batch: 1100, loss is 5.363478374481201 and perplexity is 213.46617185721735
At time: 186.40686106681824 and batch: 1150, loss is 5.378909473419189 and perplexity is 216.78573586474948
At time: 187.54498720169067 and batch: 1200, loss is 5.368213672637939 and perplexity is 214.47939489062483
At time: 188.68421339988708 and batch: 1250, loss is 5.388721113204956 and perplexity is 218.9232284215535
At time: 189.82255053520203 and batch: 1300, loss is 5.3455798530578615 and perplexity is 209.67943261564324
At time: 190.96039605140686 and batch: 1350, loss is 5.342131223678589 and perplexity is 208.95757139542872
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.294014892578125 and perplexity of 199.1413536822866
Finished 6 epochs...
Completing Train Step...
At time: 194.34305143356323 and batch: 50, loss is 5.415267353057861 and perplexity is 224.81264199207362
At time: 195.4940423965454 and batch: 100, loss is 5.4318587017059325 and perplexity is 228.57370116178294
At time: 196.60122060775757 and batch: 150, loss is 5.398668823242187 and perplexity is 221.11188121146753
At time: 197.70918941497803 and batch: 200, loss is 5.385962266921997 and perplexity is 218.32008525876083
At time: 198.81665682792664 and batch: 250, loss is 5.414058113098145 and perplexity is 224.54095386310507
At time: 199.92983436584473 and batch: 300, loss is 5.404093513488769 and perplexity is 222.31460392656797
At time: 201.04398369789124 and batch: 350, loss is 5.408750467300415 and perplexity is 223.35232720795997
At time: 202.16227293014526 and batch: 400, loss is 5.438139896392823 and perplexity is 230.01393554016957
At time: 203.29376816749573 and batch: 450, loss is 5.412159423828125 and perplexity is 224.11502484471066
At time: 204.43138933181763 and batch: 500, loss is 5.439750900268555 and perplexity is 230.38478752358148
At time: 205.56989240646362 and batch: 550, loss is 5.418146724700928 and perplexity is 225.46089396973332
At time: 206.7096667289734 and batch: 600, loss is 5.360450992584228 and perplexity is 212.8209054596504
At time: 207.84843468666077 and batch: 650, loss is 5.395383996963501 and perplexity is 220.38675869629185
At time: 208.98852038383484 and batch: 700, loss is 5.424087104797363 and perplexity is 226.80420331059585
At time: 210.1270990371704 and batch: 750, loss is 5.398944911956787 and perplexity is 221.17293613443368
At time: 211.26659417152405 and batch: 800, loss is 5.383927259445191 and perplexity is 217.87625400604938
At time: 212.40546894073486 and batch: 850, loss is 5.377563209533691 and perplexity is 216.49408142363436
At time: 213.5445110797882 and batch: 900, loss is 5.415368099212646 and perplexity is 224.83529214223995
At time: 214.68482756614685 and batch: 950, loss is 5.3697559356689455 and perplexity is 214.81043374115106
At time: 215.82456803321838 and batch: 1000, loss is 5.383718214035034 and perplexity is 217.83071273542998
At time: 216.96410608291626 and batch: 1050, loss is 5.3514132404327395 and perplexity is 210.90614844635766
At time: 218.1035008430481 and batch: 1100, loss is 5.334553861618042 and perplexity is 207.38020789604704
At time: 219.24249935150146 and batch: 1150, loss is 5.348574571609497 and perplexity is 210.30830467981747
At time: 220.38064289093018 and batch: 1200, loss is 5.334753952026367 and perplexity is 207.42170683815513
At time: 221.5477578639984 and batch: 1250, loss is 5.361570520401001 and perplexity is 213.05929780183345
At time: 222.68486618995667 and batch: 1300, loss is 5.326534719467163 and perplexity is 205.72384670381905
At time: 223.82318902015686 and batch: 1350, loss is 5.321010303497315 and perplexity is 204.59047608753562
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2969962565104165 and perplexity of 199.7359524488153
Annealing...
Finished 7 epochs...
Completing Train Step...
At time: 227.1893434524536 and batch: 50, loss is 5.379919404983521 and perplexity is 217.00478521590452
At time: 228.32440757751465 and batch: 100, loss is 5.394576206207275 and perplexity is 220.20880419449986
At time: 229.43375182151794 and batch: 150, loss is 5.368896942138672 and perplexity is 214.62599219672006
At time: 230.54832315444946 and batch: 200, loss is 5.353435382843018 and perplexity is 211.33306220845847
At time: 231.66153931617737 and batch: 250, loss is 5.363268032073974 and perplexity is 213.42127559072728
At time: 232.77619194984436 and batch: 300, loss is 5.35666600227356 and perplexity is 212.0169029253339
At time: 233.90574097633362 and batch: 350, loss is 5.359029884338379 and perplexity is 212.51867871533526
At time: 235.03650784492493 and batch: 400, loss is 5.381686105728149 and perplexity is 217.38850659214702
At time: 236.16699624061584 and batch: 450, loss is 5.350873365402221 and perplexity is 210.79231621338369
At time: 237.29767608642578 and batch: 500, loss is 5.381116285324096 and perplexity is 217.26466947129418
At time: 238.4283561706543 and batch: 550, loss is 5.357121677398681 and perplexity is 212.11353576902184
At time: 239.5587694644928 and batch: 600, loss is 5.295495700836182 and perplexity is 199.4364622890449
At time: 240.68918657302856 and batch: 650, loss is 5.320528354644775 and perplexity is 204.49189769912343
At time: 241.82019639015198 and batch: 700, loss is 5.331630172729493 and perplexity is 206.77477816187505
At time: 242.95717906951904 and batch: 750, loss is 5.313994369506836 and perplexity is 203.16010636927936
At time: 244.09795689582825 and batch: 800, loss is 5.294375286102295 and perplexity is 199.2131358706892
At time: 245.23750638961792 and batch: 850, loss is 5.269777498245239 and perplexity is 194.37270936471683
At time: 246.3761966228485 and batch: 900, loss is 5.29573205947876 and perplexity is 199.4836063917907
At time: 247.515851020813 and batch: 950, loss is 5.255788421630859 and perplexity is 191.67254507795369
At time: 248.65509557724 and batch: 1000, loss is 5.262343139648437 and perplexity is 192.93303111492853
At time: 249.82851314544678 and batch: 1050, loss is 5.222367496490478 and perplexity is 185.37253379340802
At time: 250.96802926063538 and batch: 1100, loss is 5.200859956741333 and perplexity is 181.42819520851742
At time: 252.1070351600647 and batch: 1150, loss is 5.198974056243896 and perplexity is 181.0863621178368
At time: 253.24765372276306 and batch: 1200, loss is 5.175085544586182 and perplexity is 176.81173891654524
At time: 254.38606882095337 and batch: 1250, loss is 5.195361709594726 and perplexity is 180.43339548539265
At time: 255.52482676506042 and batch: 1300, loss is 5.164267950057983 and perplexity is 174.9093692999916
At time: 256.66374945640564 and batch: 1350, loss is 5.174635906219482 and perplexity is 176.7322554457936
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.198465983072917 and perplexity of 180.99438036432372
Finished 8 epochs...
Completing Train Step...
At time: 260.0797164440155 and batch: 50, loss is 5.326983823776245 and perplexity is 205.81625891966357
At time: 261.1885027885437 and batch: 100, loss is 5.343232097625733 and perplexity is 209.1877340086037
At time: 262.29735589027405 and batch: 150, loss is 5.318465642929077 and perplexity is 204.0705246009913
At time: 263.4067208766937 and batch: 200, loss is 5.307131690979004 and perplexity is 201.77065699494287
At time: 264.5246636867523 and batch: 250, loss is 5.318554983139038 and perplexity is 204.08875711894245
At time: 265.64829564094543 and batch: 300, loss is 5.314741649627686 and perplexity is 203.3119806173545
At time: 266.77970266342163 and batch: 350, loss is 5.318899888992309 and perplexity is 204.15916066645943
At time: 267.9108552932739 and batch: 400, loss is 5.342607669830322 and perplexity is 209.05715214674473
At time: 269.0420033931732 and batch: 450, loss is 5.313199634552002 and perplexity is 202.9987120726592
At time: 270.1787328720093 and batch: 500, loss is 5.346303415298462 and perplexity is 209.83120363698305
At time: 271.31849670410156 and batch: 550, loss is 5.32538779258728 and perplexity is 205.48803175130553
At time: 272.4585921764374 and batch: 600, loss is 5.266335992813111 and perplexity is 193.7049243815056
At time: 273.5981550216675 and batch: 650, loss is 5.292693862915039 and perplexity is 198.87845573315212
At time: 274.73813343048096 and batch: 700, loss is 5.307477798461914 and perplexity is 201.84050341564767
At time: 275.87837171554565 and batch: 750, loss is 5.290467147827148 and perplexity is 198.43610275491523
At time: 277.0180823802948 and batch: 800, loss is 5.271436977386474 and perplexity is 194.69553460832705
At time: 278.1860899925232 and batch: 850, loss is 5.248672113418579 and perplexity is 190.31338600463965
At time: 279.32623744010925 and batch: 900, loss is 5.279538717269897 and perplexity is 196.27931420833772
At time: 280.4662368297577 and batch: 950, loss is 5.242469596862793 and perplexity is 189.1366173134435
At time: 281.60560393333435 and batch: 1000, loss is 5.252947578430176 and perplexity is 191.12880613573182
At time: 282.7451195716858 and batch: 1050, loss is 5.216832218170166 and perplexity is 184.3492798362904
At time: 283.88453221321106 and batch: 1100, loss is 5.201088905334473 and perplexity is 181.46973769393168
At time: 285.02476716041565 and batch: 1150, loss is 5.202881717681885 and perplexity is 181.79537069256125
At time: 286.1651339530945 and batch: 1200, loss is 5.183775587081909 and perplexity is 178.3549359539561
At time: 287.3039813041687 and batch: 1250, loss is 5.207803726196289 and perplexity is 182.69237477494116
At time: 288.44330739974976 and batch: 1300, loss is 5.17765778541565 and perplexity is 177.26712672298365
At time: 289.58303809165955 and batch: 1350, loss is 5.182776527404785 and perplexity is 178.17683770942946
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.194701741536458 and perplexity of 180.31435449367433
Finished 9 epochs...
Completing Train Step...
At time: 292.98144268989563 and batch: 50, loss is 5.314629716873169 and perplexity is 203.28922462093217
At time: 294.0912401676178 and batch: 100, loss is 5.327406034469605 and perplexity is 205.9031750922244
At time: 295.20063638687134 and batch: 150, loss is 5.301759691238403 and perplexity is 200.68965125884387
At time: 296.31035685539246 and batch: 200, loss is 5.290532741546631 and perplexity is 198.44911934387315
At time: 297.4314286708832 and batch: 250, loss is 5.302962303161621 and perplexity is 200.93114821076517
At time: 298.55431485176086 and batch: 300, loss is 5.299704570770263 and perplexity is 200.27763336701315
At time: 299.6769003868103 and batch: 350, loss is 5.304581594467163 and perplexity is 201.2567778455408
At time: 300.80786967277527 and batch: 400, loss is 5.328475799560547 and perplexity is 206.12356098059968
At time: 301.94833850860596 and batch: 450, loss is 5.299705820083618 and perplexity is 200.27788357669152
At time: 303.09068846702576 and batch: 500, loss is 5.3336057949066165 and perplexity is 207.18369079471285
At time: 304.23322677612305 and batch: 550, loss is 5.313642559051513 and perplexity is 203.0886450909037
At time: 305.37570905685425 and batch: 600, loss is 5.255724887847901 and perplexity is 191.66036778291456
At time: 306.51807022094727 and batch: 650, loss is 5.2823778343200685 and perplexity is 196.8373659681837
At time: 307.695387840271 and batch: 700, loss is 5.298925809860229 and perplexity is 200.12172569027433
At time: 308.8375747203827 and batch: 750, loss is 5.281429491043091 and perplexity is 196.65078506086783
At time: 309.9796566963196 and batch: 800, loss is 5.262711038589478 and perplexity is 193.00402403107603
At time: 311.1220679283142 and batch: 850, loss is 5.240011825561523 and perplexity is 188.67233354876177
At time: 312.26466250419617 and batch: 900, loss is 5.273374557495117 and perplexity is 195.07313850419058
At time: 313.4070131778717 and batch: 950, loss is 5.23810604095459 and perplexity is 188.3131071325439
At time: 314.549711227417 and batch: 1000, loss is 5.250482263565064 and perplexity is 190.65819379097536
At time: 315.6919136047363 and batch: 1050, loss is 5.215724039077759 and perplexity is 184.14510097294462
At time: 316.8343331813812 and batch: 1100, loss is 5.202205743789673 and perplexity is 181.67252329374298
At time: 317.9767835140228 and batch: 1150, loss is 5.205719833374023 and perplexity is 182.3120598518641
At time: 319.11906695365906 and batch: 1200, loss is 5.188206167221069 and perplexity is 179.1469049364056
At time: 320.26811361312866 and batch: 1250, loss is 5.212335529327393 and perplexity is 183.52217948661263
At time: 321.41045594215393 and batch: 1300, loss is 5.182029457092285 and perplexity is 178.04377679272048
At time: 322.55297017097473 and batch: 1350, loss is 5.1839621925354 and perplexity is 178.38822106315703
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.193531494140625 and perplexity of 180.10346551010608
Finished 10 epochs...
Completing Train Step...
At time: 325.952171087265 and batch: 50, loss is 5.306030569076538 and perplexity is 201.54860518074472
At time: 327.097580909729 and batch: 100, loss is 5.317155485153198 and perplexity is 203.80333508478833
At time: 328.21552991867065 and batch: 150, loss is 5.291129903793335 and perplexity is 198.56766105663203
At time: 329.33593702316284 and batch: 200, loss is 5.280178766250611 and perplexity is 196.4049827960675
At time: 330.4584107398987 and batch: 250, loss is 5.29335015296936 and perplexity is 199.0090205251694
At time: 331.5817744731903 and batch: 300, loss is 5.2903930282592775 and perplexity is 198.42139530179082
At time: 332.70441198349 and batch: 350, loss is 5.296010503768921 and perplexity is 199.53915919679292
At time: 333.83399987220764 and batch: 400, loss is 5.3198966121673585 and perplexity is 204.3627522786784
At time: 334.9707877635956 and batch: 450, loss is 5.29150016784668 and perplexity is 198.64119713672147
At time: 336.14149260520935 and batch: 500, loss is 5.325679082870483 and perplexity is 205.54789713694836
At time: 337.28340911865234 and batch: 550, loss is 5.306255359649658 and perplexity is 201.59391649980273
At time: 338.42526149749756 and batch: 600, loss is 5.249329586029052 and perplexity is 190.43855298576614
At time: 339.56693482398987 and batch: 650, loss is 5.276066703796387 and perplexity is 195.5990114783709
At time: 340.70935130119324 and batch: 700, loss is 5.293302555084228 and perplexity is 198.99954834209996
At time: 341.8514144420624 and batch: 750, loss is 5.275817937850952 and perplexity is 195.5503591571257
At time: 342.9940459728241 and batch: 800, loss is 5.257305116653442 and perplexity is 191.96347444282878
At time: 344.1355617046356 and batch: 850, loss is 5.233595838546753 and perplexity is 187.46568935269167
At time: 345.27748441696167 and batch: 900, loss is 5.2689730739593506 and perplexity is 194.21641410906778
At time: 346.419305562973 and batch: 950, loss is 5.235074272155762 and perplexity is 187.74304990742922
At time: 347.5617859363556 and batch: 1000, loss is 5.248491439819336 and perplexity is 190.27900450621408
At time: 348.7041096687317 and batch: 1050, loss is 5.214463901519776 and perplexity is 183.9131989599955
At time: 349.847056388855 and batch: 1100, loss is 5.202182340621948 and perplexity is 181.66827163096076
At time: 350.9884271621704 and batch: 1150, loss is 5.206262178421021 and perplexity is 182.41096271184654
At time: 352.13021969795227 and batch: 1200, loss is 5.189823274612427 and perplexity is 179.4368390846618
At time: 353.2717649936676 and batch: 1250, loss is 5.213499383926392 and perplexity is 183.73589696313599
At time: 354.4132442474365 and batch: 1300, loss is 5.182840576171875 and perplexity is 178.18825008167903
At time: 355.5551550388336 and batch: 1350, loss is 5.182588529586792 and perplexity is 178.14334400119387
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.192853597005208 and perplexity of 179.98141526018944
Finished 11 epochs...
Completing Train Step...
At time: 358.93782353401184 and batch: 50, loss is 5.2986998462677 and perplexity is 200.07651057487163
At time: 360.0885136127472 and batch: 100, loss is 5.309170274734497 and perplexity is 202.18240292531524
At time: 361.2108292579651 and batch: 150, loss is 5.2834508419036865 and perplexity is 197.0486873090323
At time: 362.33389687538147 and batch: 200, loss is 5.2723150634765625 and perplexity is 194.86656912959643
At time: 363.456830739975 and batch: 250, loss is 5.286018304824829 and perplexity is 197.55525252279224
At time: 364.60828948020935 and batch: 300, loss is 5.283321971893311 and perplexity is 197.02329527882495
At time: 365.7306170463562 and batch: 350, loss is 5.289611139297485 and perplexity is 198.26631243971082
At time: 366.85369968414307 and batch: 400, loss is 5.313442506790161 and perplexity is 203.04802081182325
At time: 367.98445439338684 and batch: 450, loss is 5.285297260284424 and perplexity is 197.412857729196
At time: 369.11745405197144 and batch: 500, loss is 5.3198215293884275 and perplexity is 204.34740873135263
At time: 370.2588565349579 and batch: 550, loss is 5.300836362838745 and perplexity is 200.50443432550512
At time: 371.40019631385803 and batch: 600, loss is 5.244816513061523 and perplexity is 189.58102639584234
At time: 372.5417377948761 and batch: 650, loss is 5.271162700653076 and perplexity is 194.6421414756692
At time: 373.6832947731018 and batch: 700, loss is 5.288943557739258 and perplexity is 198.13399767627033
At time: 374.82484579086304 and batch: 750, loss is 5.271487274169922 and perplexity is 194.70532741374066
At time: 375.9661068916321 and batch: 800, loss is 5.253365173339843 and perplexity is 191.208637219632
At time: 377.10735392570496 and batch: 850, loss is 5.22959867477417 and perplexity is 186.7178538967052
At time: 378.2508282661438 and batch: 900, loss is 5.26521089553833 and perplexity is 193.48711005310267
At time: 379.39196252822876 and batch: 950, loss is 5.232242298126221 and perplexity is 187.2121186125263
At time: 380.5330011844635 and batch: 1000, loss is 5.246445150375366 and perplexity is 189.89003669397508
At time: 381.6742970943451 and batch: 1050, loss is 5.213187894821167 and perplexity is 183.67867414559805
At time: 382.8166358470917 and batch: 1100, loss is 5.2014278793334965 and perplexity is 181.5312616435401
At time: 383.9580798149109 and batch: 1150, loss is 5.2059260177612305 and perplexity is 182.34965362769677
At time: 385.09987783432007 and batch: 1200, loss is 5.189969511032104 and perplexity is 179.46308120429785
At time: 386.2401976585388 and batch: 1250, loss is 5.213532581329345 and perplexity is 183.74199661899033
At time: 387.38128566741943 and batch: 1300, loss is 5.182542572021484 and perplexity is 178.13515715495294
At time: 388.5224096775055 and batch: 1350, loss is 5.180549993515014 and perplexity is 177.78056226595922
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.192782389322916 and perplexity of 179.96859965704326
Finished 12 epochs...
Completing Train Step...
At time: 391.95130801200867 and batch: 50, loss is 5.292333374023437 and perplexity is 198.8067751798793
At time: 393.07134079933167 and batch: 100, loss is 5.3025450515747075 and perplexity is 200.84732685882602
At time: 394.220228433609 and batch: 150, loss is 5.27713698387146 and perplexity is 195.80846927231752
At time: 395.34155464172363 and batch: 200, loss is 5.2658420753479005 and perplexity is 193.60927375995718
At time: 396.4629588127136 and batch: 250, loss is 5.280120124816895 and perplexity is 196.39346566398123
At time: 397.58410596847534 and batch: 300, loss is 5.277623434066772 and perplexity is 195.90374351164616
At time: 398.7059931755066 and batch: 350, loss is 5.284315032958984 and perplexity is 197.2190486238226
At time: 399.8309214115143 and batch: 400, loss is 5.308006248474121 and perplexity is 201.94719422003715
At time: 400.9606599807739 and batch: 450, loss is 5.2801081085205075 and perplexity is 196.391105756068
At time: 402.0918929576874 and batch: 500, loss is 5.315103921890259 and perplexity is 203.3856482516456
At time: 403.23150062561035 and batch: 550, loss is 5.296310815811157 and perplexity is 199.5990922080496
At time: 404.37068367004395 and batch: 600, loss is 5.240563678741455 and perplexity is 188.77648171059982
At time: 405.51005268096924 and batch: 650, loss is 5.266964139938355 and perplexity is 193.82663779586514
At time: 406.6492929458618 and batch: 700, loss is 5.285281352996826 and perplexity is 197.40971745106924
At time: 407.78894567489624 and batch: 750, loss is 5.2677231121063235 and perplexity is 193.97380265931648
At time: 408.92787170410156 and batch: 800, loss is 5.249816875457764 and perplexity is 190.53137429303948
At time: 410.06708574295044 and batch: 850, loss is 5.22579571723938 and perplexity is 186.00912231956272
At time: 411.20630741119385 and batch: 900, loss is 5.261494064331055 and perplexity is 192.76928596612058
At time: 412.34667563438416 and batch: 950, loss is 5.229346990585327 and perplexity is 186.67086587842337
At time: 413.4858138561249 and batch: 1000, loss is 5.244092044830322 and perplexity is 189.44373070416847
At time: 414.6247889995575 and batch: 1050, loss is 5.211271076202393 and perplexity is 183.3269326631325
At time: 415.7643301486969 and batch: 1100, loss is 5.1999784851074216 and perplexity is 181.2683418642941
At time: 416.9034471511841 and batch: 1150, loss is 5.204997892379761 and perplexity is 182.18048880109077
At time: 418.04286098480225 and batch: 1200, loss is 5.189463596343995 and perplexity is 179.37231115842894
At time: 419.1817066669464 and batch: 1250, loss is 5.212624301910401 and perplexity is 183.57518331307978
At time: 420.3218402862549 and batch: 1300, loss is 5.181532764434815 and perplexity is 177.9553657144636
At time: 421.4612536430359 and batch: 1350, loss is 5.178083667755127 and perplexity is 177.34263773988772
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.192502848307291 and perplexity of 179.9182980829186
Finished 13 epochs...
Completing Train Step...
At time: 424.86207127571106 and batch: 50, loss is 5.28677451133728 and perplexity is 197.70470159137662
At time: 425.9768204689026 and batch: 100, loss is 5.296502313613892 and perplexity is 199.6373186556587
At time: 427.09222197532654 and batch: 150, loss is 5.2716773414611815 and perplexity is 194.74233804505982
At time: 428.21186804771423 and batch: 200, loss is 5.260231161117554 and perplexity is 192.5259906769474
At time: 429.3320927619934 and batch: 250, loss is 5.274779615402221 and perplexity is 195.34742020562257
At time: 430.46016788482666 and batch: 300, loss is 5.272558345794677 and perplexity is 194.91398248743934
At time: 431.6000270843506 and batch: 350, loss is 5.2795732307434085 and perplexity is 196.28608860615276
At time: 432.73957991600037 and batch: 400, loss is 5.303339109420777 and perplexity is 201.0068745912614
At time: 433.8787844181061 and batch: 450, loss is 5.275573196411133 and perplexity is 195.5025057367648
At time: 435.01856207847595 and batch: 500, loss is 5.310999765396118 and perplexity is 202.5526323057439
At time: 436.15763568878174 and batch: 550, loss is 5.292262058258057 and perplexity is 198.79259762809207
At time: 437.2970087528229 and batch: 600, loss is 5.236955585479737 and perplexity is 188.0965858603795
At time: 438.43629789352417 and batch: 650, loss is 5.263219709396362 and perplexity is 193.10222451745483
At time: 439.576012134552 and batch: 700, loss is 5.281790409088135 and perplexity is 196.7217726873555
At time: 440.71587777137756 and batch: 750, loss is 5.264178018569947 and perplexity is 193.28736484731894
At time: 441.8558964729309 and batch: 800, loss is 5.246437606811523 and perplexity is 189.88860425176298
At time: 442.9955813884735 and batch: 850, loss is 5.222490768432618 and perplexity is 185.39538643418382
At time: 444.13504219055176 and batch: 900, loss is 5.258031864166259 and perplexity is 192.10303412661588
At time: 445.27506017684937 and batch: 950, loss is 5.226422462463379 and perplexity is 186.12573918931255
At time: 446.4143671989441 and batch: 1000, loss is 5.241794719696045 and perplexity is 189.00901639134014
At time: 447.55380511283875 and batch: 1050, loss is 5.2093714427948 and perplexity is 182.97900926541544
At time: 448.69393157958984 and batch: 1100, loss is 5.198521242141724 and perplexity is 181.00438222158607
At time: 449.833820104599 and batch: 1150, loss is 5.2037256240844725 and perplexity is 181.9488537233967
At time: 451.0191972255707 and batch: 1200, loss is 5.188728313446045 and perplexity is 179.24047024179404
At time: 452.1580319404602 and batch: 1250, loss is 5.211017618179321 and perplexity is 183.28047286925639
At time: 453.29745078086853 and batch: 1300, loss is 5.179772987365722 and perplexity is 177.64247932844694
At time: 454.43723917007446 and batch: 1350, loss is 5.175511312484741 and perplexity is 176.88703570740518
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.192338053385416 and perplexity of 179.88865090396155
Finished 14 epochs...
Completing Train Step...
At time: 457.81898760795593 and batch: 50, loss is 5.281774950027466 and perplexity is 196.71873157704303
At time: 458.96117424964905 and batch: 100, loss is 5.29147364616394 and perplexity is 198.63592890777343
At time: 460.0747332572937 and batch: 150, loss is 5.2669037914276124 and perplexity is 193.81494099987762
At time: 461.1912863254547 and batch: 200, loss is 5.25528226852417 and perplexity is 191.575553972041
At time: 462.3111433982849 and batch: 250, loss is 5.269988231658935 and perplexity is 194.41367450550098
At time: 463.43119597435 and batch: 300, loss is 5.2681685829162594 and perplexity is 194.06023157564388
At time: 464.5623013973236 and batch: 350, loss is 5.275416126251221 and perplexity is 195.47180053842382
At time: 465.6953675746918 and batch: 400, loss is 5.299287252426147 and perplexity is 200.19407127390284
At time: 466.8344144821167 and batch: 450, loss is 5.2717287063598635 and perplexity is 194.75234122242648
At time: 467.97330927848816 and batch: 500, loss is 5.307168416976928 and perplexity is 201.77806735974858
At time: 469.1122283935547 and batch: 550, loss is 5.288438100814819 and perplexity is 198.033874781215
At time: 470.25200271606445 and batch: 600, loss is 5.233622264862061 and perplexity is 187.47064344556676
At time: 471.39160799980164 and batch: 650, loss is 5.259929418563843 and perplexity is 192.46790615659123
At time: 472.53089237213135 and batch: 700, loss is 5.2784890365600585 and perplexity is 196.07339169382607
At time: 473.6697790622711 and batch: 750, loss is 5.260823202133179 and perplexity is 192.64000770805106
At time: 474.80853390693665 and batch: 800, loss is 5.243287143707275 and perplexity is 189.2913085831678
At time: 475.94825053215027 and batch: 850, loss is 5.219284324645996 and perplexity is 184.80187858256693
At time: 477.0883803367615 and batch: 900, loss is 5.254560375213623 and perplexity is 191.43730676703427
At time: 478.2278709411621 and batch: 950, loss is 5.22344898223877 and perplexity is 185.57311999283763
At time: 479.3676552772522 and batch: 1000, loss is 5.239208354949951 and perplexity is 188.52080175736108
At time: 480.5351462364197 and batch: 1050, loss is 5.207379102706909 and perplexity is 182.61481576913434
At time: 481.67417907714844 and batch: 1100, loss is 5.196630392074585 and perplexity is 180.66245344321194
At time: 482.8138175010681 and batch: 1150, loss is 5.202136831283569 and perplexity is 181.66000421623818
At time: 483.95322942733765 and batch: 1200, loss is 5.187325763702392 and perplexity is 178.98925277987937
At time: 485.09260964393616 and batch: 1250, loss is 5.209382524490357 and perplexity is 182.9810369943247
At time: 486.2315640449524 and batch: 1300, loss is 5.177799596786499 and perplexity is 177.2922669997771
At time: 487.3785557746887 and batch: 1350, loss is 5.172791509628296 and perplexity is 176.40659149535708
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.192245279947917 and perplexity of 179.8719627895689
Finished 15 epochs...
Completing Train Step...
At time: 490.74055528640747 and batch: 50, loss is 5.277117710113526 and perplexity is 195.80469534364826
At time: 491.8757083415985 and batch: 100, loss is 5.286779317855835 and perplexity is 197.70565186497694
At time: 492.98974204063416 and batch: 150, loss is 5.2625579738616945 and perplexity is 192.9744841834887
At time: 494.12531900405884 and batch: 200, loss is 5.251143684387207 and perplexity is 190.78434080379256
At time: 495.26445984840393 and batch: 250, loss is 5.266167364120483 and perplexity is 193.67226292725826
At time: 496.40387511253357 and batch: 300, loss is 5.263965759277344 and perplexity is 193.2463421618645
At time: 497.54337191581726 and batch: 350, loss is 5.271602001190185 and perplexity is 194.72766665721718
At time: 498.683317899704 and batch: 400, loss is 5.295315628051758 and perplexity is 199.4005524432548
At time: 499.8227047920227 and batch: 450, loss is 5.267862491607666 and perplexity is 194.00084051542228
At time: 500.9617383480072 and batch: 500, loss is 5.303582420349121 and perplexity is 201.0557877108288
At time: 502.1011402606964 and batch: 550, loss is 5.284951515197754 and perplexity is 197.34461500156436
At time: 503.2411620616913 and batch: 600, loss is 5.230519237518311 and perplexity is 186.88981853664478
At time: 504.38078212738037 and batch: 650, loss is 5.256439075469971 and perplexity is 191.79729813638804
At time: 505.5206108093262 and batch: 700, loss is 5.275171327590942 and perplexity is 195.42395516001093
At time: 506.6609671115875 and batch: 750, loss is 5.257700395584107 and perplexity is 192.03936855841744
At time: 507.80060338974 and batch: 800, loss is 5.240197925567627 and perplexity is 188.70744873855404
At time: 508.9737775325775 and batch: 850, loss is 5.216092004776001 and perplexity is 184.2128725216399
At time: 510.1135513782501 and batch: 900, loss is 5.251465396881104 and perplexity is 190.8457283839152
At time: 511.25330233573914 and batch: 950, loss is 5.220570936203003 and perplexity is 185.03979983860594
At time: 512.3934056758881 and batch: 1000, loss is 5.236931390762329 and perplexity is 188.09203497169327
At time: 513.533668756485 and batch: 1050, loss is 5.205288877487183 and perplexity is 182.2335083237664
At time: 514.6739182472229 and batch: 1100, loss is 5.194836568832398 and perplexity is 180.33866742949664
At time: 515.813184261322 and batch: 1150, loss is 5.200693416595459 and perplexity is 181.39798264629385
At time: 516.9526998996735 and batch: 1200, loss is 5.18580078125 and perplexity is 178.7165053306181
At time: 518.0920734405518 and batch: 1250, loss is 5.207542896270752 and perplexity is 182.6447293503788
At time: 519.231555223465 and batch: 1300, loss is 5.175914249420166 and perplexity is 176.95832438894635
At time: 520.3716423511505 and batch: 1350, loss is 5.170200176239014 and perplexity is 175.95005497935492
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.192159423828125 and perplexity of 179.8565203437081
Finished 16 epochs...
Completing Train Step...
At time: 523.7818727493286 and batch: 50, loss is 5.272701511383056 and perplexity is 194.94188946003686
At time: 524.8968005180359 and batch: 100, loss is 5.282181301116943 and perplexity is 196.79868469135738
At time: 526.0188319683075 and batch: 150, loss is 5.258457279205322 and perplexity is 192.18477503205537
At time: 527.1409103870392 and batch: 200, loss is 5.246905965805054 and perplexity is 189.97756111758122
At time: 528.2629024982452 and batch: 250, loss is 5.261935415267945 and perplexity is 192.8543836486749
At time: 529.3930356502533 and batch: 300, loss is 5.259956169128418 and perplexity is 192.4730548506084
At time: 530.5263390541077 and batch: 350, loss is 5.268156366348267 and perplexity is 194.05786084011132
At time: 531.6633622646332 and batch: 400, loss is 5.2917262554168705 and perplexity is 198.68611251953544
At time: 532.8052940368652 and batch: 450, loss is 5.264357833862305 and perplexity is 193.32212399635773
At time: 533.9472362995148 and batch: 500, loss is 5.300141172409058 and perplexity is 200.36509400129387
At time: 535.0885167121887 and batch: 550, loss is 5.2816861057281494 and perplexity is 196.70125501553156
At time: 536.2300837039948 and batch: 600, loss is 5.227336483001709 and perplexity is 186.29593970917955
At time: 537.3995792865753 and batch: 650, loss is 5.25314341545105 and perplexity is 191.16623989706727
At time: 538.5410747528076 and batch: 700, loss is 5.272158918380737 and perplexity is 194.8361440459121
At time: 539.6828095912933 and batch: 750, loss is 5.2546281814575195 and perplexity is 191.45028785184206
At time: 540.8247680664062 and batch: 800, loss is 5.237269763946533 and perplexity is 188.15569104163615
At time: 541.967687368393 and batch: 850, loss is 5.2130264568328855 and perplexity is 183.64902382336237
At time: 543.109491109848 and batch: 900, loss is 5.2481401252746585 and perplexity is 190.2121684653083
At time: 544.2521986961365 and batch: 950, loss is 5.2177097034454345 and perplexity is 184.51111460828375
At time: 545.3942725658417 and batch: 1000, loss is 5.234659423828125 and perplexity is 187.66518117012419
At time: 546.5360376834869 and batch: 1050, loss is 5.203321809768677 and perplexity is 181.87539500436
At time: 547.677973985672 and batch: 1100, loss is 5.193070411682129 and perplexity is 180.02044210323407
At time: 548.8199682235718 and batch: 1150, loss is 5.1988631629943844 and perplexity is 181.06628197609592
At time: 549.9622600078583 and batch: 1200, loss is 5.184302339553833 and perplexity is 178.4489096056034
At time: 551.1029016971588 and batch: 1250, loss is 5.205595321655274 and perplexity is 182.28936127709176
At time: 552.2449531555176 and batch: 1300, loss is 5.173863401412964 and perplexity is 176.5957816491138
At time: 553.3868114948273 and batch: 1350, loss is 5.167520179748535 and perplexity is 175.4791407556012
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.192311197916666 and perplexity of 179.8838199747874
Annealing...
Finished 17 epochs...
Completing Train Step...
At time: 556.79523229599 and batch: 50, loss is 5.272311525344849 and perplexity is 194.86587966722794
At time: 557.9190888404846 and batch: 100, loss is 5.283943557739258 and perplexity is 197.1458002402229
At time: 559.0426890850067 and batch: 150, loss is 5.26071494102478 and perplexity is 192.61915341616935
At time: 560.1666910648346 and batch: 200, loss is 5.250135107040405 and perplexity is 190.5920170425308
At time: 561.2909498214722 and batch: 250, loss is 5.264405574798584 and perplexity is 193.33135359587385
At time: 562.4212801456451 and batch: 300, loss is 5.262261419296265 and perplexity is 192.9172652038868
At time: 563.5531735420227 and batch: 350, loss is 5.27009654045105 and perplexity is 194.43473235611182
At time: 564.6937477588654 and batch: 400, loss is 5.292362127304077 and perplexity is 198.81249160906185
At time: 565.8353447914124 and batch: 450, loss is 5.262872762680054 and perplexity is 193.03523995545547
At time: 567.0053226947784 and batch: 500, loss is 5.29443528175354 and perplexity is 199.225088151051
At time: 568.1475591659546 and batch: 550, loss is 5.272174472808838 and perplexity is 194.83917463427565
At time: 569.2904932498932 and batch: 600, loss is 5.219770736694336 and perplexity is 184.89179030816592
At time: 570.4319295883179 and batch: 650, loss is 5.244426708221436 and perplexity is 189.50714119550446
At time: 571.5738437175751 and batch: 700, loss is 5.260247964859008 and perplexity is 192.52922586109952
At time: 572.7157616615295 and batch: 750, loss is 5.241369695663452 and perplexity is 188.9287000863861
At time: 573.8580162525177 and batch: 800, loss is 5.223554048538208 and perplexity is 185.59261849813046
At time: 575.0007457733154 and batch: 850, loss is 5.190404424667358 and perplexity is 179.54114912050835
At time: 576.1433491706848 and batch: 900, loss is 5.219599075317383 and perplexity is 184.8600542528597
At time: 577.2855582237244 and batch: 950, loss is 5.189942617416381 and perplexity is 179.45825485805474
At time: 578.4277873039246 and batch: 1000, loss is 5.208342533111573 and perplexity is 182.79083721357884
At time: 579.5696866512299 and batch: 1050, loss is 5.172177619934082 and perplexity is 176.29833054038892
At time: 580.7116513252258 and batch: 1100, loss is 5.159673376083374 and perplexity is 174.10757861768184
At time: 581.8534724712372 and batch: 1150, loss is 5.16234112739563 and perplexity is 174.57267444317566
At time: 582.9957966804504 and batch: 1200, loss is 5.14379991531372 and perplexity is 171.36570785920324
At time: 584.1379292011261 and batch: 1250, loss is 5.163270254135131 and perplexity is 174.73494995857337
At time: 585.2803854942322 and batch: 1300, loss is 5.1377606773376465 and perplexity is 170.33390834592004
At time: 586.4219408035278 and batch: 1350, loss is 5.138703985214233 and perplexity is 170.49466147123698
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.174554443359375 and perplexity of 176.7178589171909
Finished 18 epochs...
Completing Train Step...
At time: 589.821634054184 and batch: 50, loss is 5.264889068603516 and perplexity is 193.42485070845257
At time: 590.9667854309082 and batch: 100, loss is 5.275236625671386 and perplexity is 195.43671638579292
At time: 592.0857241153717 and batch: 150, loss is 5.251491956710815 and perplexity is 190.85079728127647
At time: 593.2079491615295 and batch: 200, loss is 5.2416470432281494 and perplexity is 188.98110626828407
At time: 594.3345890045166 and batch: 250, loss is 5.2557386207580565 and perplexity is 191.6629998555987
At time: 595.4948921203613 and batch: 300, loss is 5.253721923828125 and perplexity is 191.2768631634195
At time: 596.6315770149231 and batch: 350, loss is 5.261693859100342 and perplexity is 192.80780410886942
At time: 597.7732510566711 and batch: 400, loss is 5.284336881637573 and perplexity is 197.22335764650066
At time: 598.9148125648499 and batch: 450, loss is 5.254775323867798 and perplexity is 191.47846038128117
At time: 600.056206703186 and batch: 500, loss is 5.287632160186767 and perplexity is 197.87433553401448
At time: 601.1975047588348 and batch: 550, loss is 5.266761360168457 and perplexity is 193.78733765962372
At time: 602.3393247127533 and batch: 600, loss is 5.214097127914429 and perplexity is 183.84575682169628
At time: 603.4812681674957 and batch: 650, loss is 5.239192848205566 and perplexity is 188.51787843614272
At time: 604.6235671043396 and batch: 700, loss is 5.2559334087371825 and perplexity is 191.70033714032286
At time: 605.7643892765045 and batch: 750, loss is 5.238130893707275 and perplexity is 188.31778728978
At time: 606.9055211544037 and batch: 800, loss is 5.220530576705933 and perplexity is 185.0323318760492
At time: 608.0467674732208 and batch: 850, loss is 5.188071041107178 and perplexity is 179.1226991467799
At time: 609.1880116462708 and batch: 900, loss is 5.218238229751587 and perplexity is 184.60865936134508
At time: 610.3295483589172 and batch: 950, loss is 5.18862250328064 and perplexity is 179.22150578132445
At time: 611.4709813594818 and batch: 1000, loss is 5.2082070541381835 and perplexity is 182.76607457605442
At time: 612.6128299236298 and batch: 1050, loss is 5.1728496265411374 and perplexity is 176.4168439997787
At time: 613.7535443305969 and batch: 1100, loss is 5.161417798995972 and perplexity is 174.4115609268469
At time: 614.894947052002 and batch: 1150, loss is 5.1649220848083495 and perplexity is 175.02382102595988
At time: 616.0364966392517 and batch: 1200, loss is 5.147816171646118 and perplexity is 172.05534041210348
At time: 617.1777009963989 and batch: 1250, loss is 5.168102540969849 and perplexity is 175.58136276450472
At time: 618.3194210529327 and batch: 1300, loss is 5.142315692901612 and perplexity is 171.11155169372728
At time: 619.4603092670441 and batch: 1350, loss is 5.141420774459839 and perplexity is 170.95848930990653
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.17278564453125 and perplexity of 176.4055568566125
Finished 19 epochs...
Completing Train Step...
At time: 622.8316729068756 and batch: 50, loss is 5.2623084354400635 and perplexity is 192.92633564299575
At time: 623.9733996391296 and batch: 100, loss is 5.271648616790771 and perplexity is 194.73674421592537
At time: 625.092362165451 and batch: 150, loss is 5.2474402236938475 and perplexity is 190.0790852459205
At time: 626.2180752754211 and batch: 200, loss is 5.237721462249755 and perplexity is 188.2406998457422
At time: 627.3483815193176 and batch: 250, loss is 5.251815557479858 and perplexity is 190.91256673983233
At time: 628.4838759899139 and batch: 300, loss is 5.249673070907593 and perplexity is 190.50397698444183
At time: 629.6233472824097 and batch: 350, loss is 5.257706527709961 and perplexity is 192.04054617160503
At time: 630.7626140117645 and batch: 400, loss is 5.280436601638794 and perplexity is 196.45562948002092
At time: 631.9027981758118 and batch: 450, loss is 5.25097993850708 and perplexity is 190.75310321157647
At time: 633.0425758361816 and batch: 500, loss is 5.284134836196899 and perplexity is 197.1835135915841
At time: 634.1817796230316 and batch: 550, loss is 5.263894033432007 and perplexity is 193.23248190169008
At time: 635.3208367824554 and batch: 600, loss is 5.211537160873413 and perplexity is 183.37571964014487
At time: 636.4597909450531 and batch: 650, loss is 5.236703033447266 and perplexity is 188.0490876834526
At time: 637.5995986461639 and batch: 700, loss is 5.253947277069091 and perplexity is 191.31997288173025
At time: 638.7390022277832 and batch: 750, loss is 5.236810007095337 and perplexity is 188.06920505637376
At time: 639.8780169487 and batch: 800, loss is 5.219404258728027 and perplexity is 184.8240439553976
At time: 641.0174684524536 and batch: 850, loss is 5.187341718673706 and perplexity is 178.99210857105493
At time: 642.1563129425049 and batch: 900, loss is 5.217957544326782 and perplexity is 184.55684967282193
At time: 643.2950937747955 and batch: 950, loss is 5.188515968322754 and perplexity is 179.2024134427726
At time: 644.43372631073 and batch: 1000, loss is 5.208653154373169 and perplexity is 182.84762475329444
At time: 645.5732769966125 and batch: 1050, loss is 5.173889427185059 and perplexity is 176.60037775048818
At time: 646.7153058052063 and batch: 1100, loss is 5.162963075637817 and perplexity is 174.68128338224795
At time: 647.8541827201843 and batch: 1150, loss is 5.166855497360229 and perplexity is 175.36254161621602
At time: 648.9928107261658 and batch: 1200, loss is 5.150508260726928 and perplexity is 172.51915274726622
At time: 650.1312460899353 and batch: 1250, loss is 5.171101636886597 and perplexity is 176.10873854260677
At time: 651.269674539566 and batch: 1300, loss is 5.144963512420654 and perplexity is 171.56522455711064
At time: 652.4091854095459 and batch: 1350, loss is 5.142805261611938 and perplexity is 171.1953430645551
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.172043050130208 and perplexity of 176.27460770484916
Finished 20 epochs...
Completing Train Step...
At time: 655.8235487937927 and batch: 50, loss is 5.260387420654297 and perplexity is 192.55607704964166
At time: 656.9371938705444 and batch: 100, loss is 5.269100580215454 and perplexity is 194.24117949574202
At time: 658.0532195568085 and batch: 150, loss is 5.244559278488159 and perplexity is 189.53226587311454
At time: 659.1805982589722 and batch: 200, loss is 5.234972238540649 and perplexity is 187.72389478258486
At time: 660.3112769126892 and batch: 250, loss is 5.24911376953125 and perplexity is 190.3974576389006
At time: 661.4417245388031 and batch: 300, loss is 5.246935796737671 and perplexity is 189.98322840993563
At time: 662.5731036663055 and batch: 350, loss is 5.255110759735107 and perplexity is 191.54269989822689
At time: 663.705078125 and batch: 400, loss is 5.277871150970459 and perplexity is 195.95227819159157
At time: 664.8436124324799 and batch: 450, loss is 5.248450679779053 and perplexity is 190.27124888438613
At time: 665.9822783470154 and batch: 500, loss is 5.2817701148986815 and perplexity is 196.71778041894103
At time: 667.1211557388306 and batch: 550, loss is 5.261975536346435 and perplexity is 192.86212132975953
At time: 668.259827375412 and batch: 600, loss is 5.209947671890259 and perplexity is 183.08447747842058
At time: 669.3984682559967 and batch: 650, loss is 5.235114192962646 and perplexity is 187.75054491107073
At time: 670.5369439125061 and batch: 700, loss is 5.252742137908935 and perplexity is 191.08954456727193
At time: 671.6772782802582 and batch: 750, loss is 5.236037864685058 and perplexity is 187.92404489645233
At time: 672.8164262771606 and batch: 800, loss is 5.218818426132202 and perplexity is 184.71579971555408
At time: 673.9555580615997 and batch: 850, loss is 5.186959581375122 and perplexity is 178.92372207756486
At time: 675.094324350357 and batch: 900, loss is 5.217842092514038 and perplexity is 184.5355434799159
At time: 676.2330071926117 and batch: 950, loss is 5.188566694259643 and perplexity is 179.21150388364592
At time: 677.3719232082367 and batch: 1000, loss is 5.209067010879517 and perplexity is 182.9233130934445
At time: 678.5115785598755 and batch: 1050, loss is 5.17468092918396 and perplexity is 176.7402126349795
At time: 679.6520254611969 and batch: 1100, loss is 5.164053030014038 and perplexity is 174.87178180995247
At time: 680.791042804718 and batch: 1150, loss is 5.168173666000366 and perplexity is 175.59385143841305
At time: 681.9588460922241 and batch: 1200, loss is 5.152364253997803 and perplexity is 172.8396444570904
At time: 683.0973360538483 and batch: 1250, loss is 5.173081617355347 and perplexity is 176.45777583477982
At time: 684.2366394996643 and batch: 1300, loss is 5.14665620803833 and perplexity is 171.8558781855267
At time: 685.3764088153839 and batch: 1350, loss is 5.143582334518433 and perplexity is 171.3284260282545
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.17166259765625 and perplexity of 176.20755634998764
Finished 21 epochs...
Completing Train Step...
At time: 688.781674861908 and batch: 50, loss is 5.258815832138062 and perplexity is 192.25369580190477
At time: 689.8894219398499 and batch: 100, loss is 5.267100563049317 and perplexity is 193.853082032542
At time: 691.0045540332794 and batch: 150, loss is 5.24224045753479 and perplexity is 189.09328364096552
At time: 692.1266660690308 and batch: 200, loss is 5.232834434509277 and perplexity is 187.32300654645584
At time: 693.2619926929474 and batch: 250, loss is 5.247071943283081 and perplexity is 190.0090957310027
At time: 694.4013426303864 and batch: 300, loss is 5.2448533916473385 and perplexity is 189.58801800491278
At time: 695.5413479804993 and batch: 350, loss is 5.253199806213379 and perplexity is 191.17702021101883
At time: 696.6795990467072 and batch: 400, loss is 5.275943250656128 and perplexity is 195.57486565664175
At time: 697.8176004886627 and batch: 450, loss is 5.246641044616699 and perplexity is 189.9272387023606
At time: 698.9555146694183 and batch: 500, loss is 5.279932432174682 and perplexity is 196.35660751460742
At time: 700.0932774543762 and batch: 550, loss is 5.2605312538146975 and perplexity is 192.5837749906515
At time: 701.2317271232605 and batch: 600, loss is 5.208853874206543 and perplexity is 182.88432958163799
At time: 702.3696756362915 and batch: 650, loss is 5.233981027603149 and perplexity is 187.53791299366512
At time: 703.5078701972961 and batch: 700, loss is 5.2518883895874025 and perplexity is 190.92647181078632
At time: 704.6470394134521 and batch: 750, loss is 5.2354676723480225 and perplexity is 187.81692258916925
At time: 705.785638332367 and batch: 800, loss is 5.218456268310547 and perplexity is 184.6489155559456
At time: 706.9237694740295 and batch: 850, loss is 5.186799173355102 and perplexity is 178.895023579368
At time: 708.0621955394745 and batch: 900, loss is 5.21776312828064 and perplexity is 184.520972347497
At time: 709.2005245685577 and batch: 950, loss is 5.188635778427124 and perplexity is 179.22388498885897
At time: 710.3767232894897 and batch: 1000, loss is 5.209420137405395 and perplexity is 182.98791957395898
At time: 711.5141251087189 and batch: 1050, loss is 5.175264768600464 and perplexity is 176.84343066604248
At time: 712.6519763469696 and batch: 1100, loss is 5.164815845489502 and perplexity is 175.0052276021259
At time: 713.7904362678528 and batch: 1150, loss is 5.1691498374938964 and perplexity is 175.76534484049347
At time: 714.9289360046387 and batch: 1200, loss is 5.153691520690918 and perplexity is 173.06920106815062
At time: 716.0675148963928 and batch: 1250, loss is 5.174511480331421 and perplexity is 176.7102667459708
At time: 717.2051079273224 and batch: 1300, loss is 5.147841377258301 and perplexity is 172.05967722694362
At time: 718.3427298069 and batch: 1350, loss is 5.144019660949707 and perplexity is 171.4033688634321
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.171442057291666 and perplexity of 176.16869975614895
Finished 22 epochs...
Completing Train Step...
At time: 721.7275671958923 and batch: 50, loss is 5.25748049736023 and perplexity is 191.99714408507046
At time: 722.8688271045685 and batch: 100, loss is 5.265376482009888 and perplexity is 193.51915155369454
At time: 723.9861931800842 and batch: 150, loss is 5.240347671508789 and perplexity is 188.7357090289487
At time: 725.1052958965302 and batch: 200, loss is 5.23105206489563 and perplexity is 186.9894250826941
At time: 726.2235748767853 and batch: 250, loss is 5.245428276062012 and perplexity is 189.69704053634712
At time: 727.3535542488098 and batch: 300, loss is 5.2431730461120605 and perplexity is 189.26971213213844
At time: 728.4920947551727 and batch: 350, loss is 5.251673841476441 and perplexity is 190.8855132908704
At time: 729.631315946579 and batch: 400, loss is 5.2743908977508545 and perplexity is 195.2714999719631
At time: 730.7705080509186 and batch: 450, loss is 5.245195274353027 and perplexity is 189.65284595061974
At time: 731.9090542793274 and batch: 500, loss is 5.278413362503052 and perplexity is 196.0585545862047
At time: 733.0474174022675 and batch: 550, loss is 5.259347801208496 and perplexity is 192.35599602961406
At time: 734.1862008571625 and batch: 600, loss is 5.2079204750061034 and perplexity is 182.71370513738128
At time: 735.3251504898071 and batch: 650, loss is 5.233009910583496 and perplexity is 187.3558801364354
At time: 736.4643685817719 and batch: 700, loss is 5.251163063049316 and perplexity is 190.78803798489173
At time: 737.6033458709717 and batch: 750, loss is 5.235024461746216 and perplexity is 187.73369858212246
At time: 738.7699172496796 and batch: 800, loss is 5.218154258728028 and perplexity is 184.59315823409244
At time: 739.9086565971375 and batch: 850, loss is 5.186591958999633 and perplexity is 178.8579578027735
At time: 741.0477566719055 and batch: 900, loss is 5.217574605941772 and perplexity is 184.48618930101355
At time: 742.1873412132263 and batch: 950, loss is 5.188570337295532 and perplexity is 179.2121567587755
At time: 743.3256962299347 and batch: 1000, loss is 5.209651975631714 and perplexity is 183.03034808675633
At time: 744.4647808074951 and batch: 1050, loss is 5.175645084381103 and perplexity is 176.91069980437385
At time: 745.6113359928131 and batch: 1100, loss is 5.1652992057800295 and perplexity is 175.08983862694086
At time: 746.7491552829742 and batch: 1150, loss is 5.169806833267212 and perplexity is 175.88085987143745
At time: 747.8873891830444 and batch: 1200, loss is 5.1546433067321775 and perplexity is 173.23400433418206
At time: 749.0255932807922 and batch: 1250, loss is 5.17551103591919 and perplexity is 176.8869867865513
At time: 750.1636447906494 and batch: 1300, loss is 5.148680992126465 and perplexity is 172.2042017541356
At time: 751.3019387722015 and batch: 1350, loss is 5.144302387237548 and perplexity is 171.45183595277172
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.171280517578125 and perplexity of 176.14024381329963
Finished 23 epochs...
Completing Train Step...
At time: 754.6815373897552 and batch: 50, loss is 5.2562405872344975 and perplexity is 191.75923240703705
At time: 755.8324429988861 and batch: 100, loss is 5.263842973709107 and perplexity is 193.22261575659226
At time: 756.9548058509827 and batch: 150, loss is 5.238693418502808 and perplexity is 188.42375051524704
At time: 758.0815720558167 and batch: 200, loss is 5.229496145248413 and perplexity is 186.69871078507873
At time: 759.2120559215546 and batch: 250, loss is 5.244055862426758 and perplexity is 189.43687629865667
At time: 760.3446683883667 and batch: 300, loss is 5.2418261241912845 and perplexity is 189.01495221730102
At time: 761.4848356246948 and batch: 350, loss is 5.250432348251342 and perplexity is 190.64867726493088
At time: 762.6251273155212 and batch: 400, loss is 5.273099002838134 and perplexity is 195.019392597731
At time: 763.7653307914734 and batch: 450, loss is 5.24394889831543 and perplexity is 189.416614435196
At time: 764.9061796665192 and batch: 500, loss is 5.27714316368103 and perplexity is 195.80967933510877
At time: 766.0466604232788 and batch: 550, loss is 5.258326988220215 and perplexity is 192.15973671956257
At time: 767.1865191459656 and batch: 600, loss is 5.20715223312378 and perplexity is 182.57339072122684
At time: 768.3549094200134 and batch: 650, loss is 5.232206907272339 and perplexity is 187.20549313303292
At time: 769.4953303337097 and batch: 700, loss is 5.250534839630127 and perplexity is 190.66821811209437
At time: 770.6359794139862 and batch: 750, loss is 5.234675731658935 and perplexity is 187.66824160710215
At time: 771.7777752876282 and batch: 800, loss is 5.217850513458252 and perplexity is 184.53709744997596
At time: 772.9182510375977 and batch: 850, loss is 5.186395864486695 and perplexity is 178.82288817724594
At time: 774.0581274032593 and batch: 900, loss is 5.217378282546997 and perplexity is 184.44997390112235
At time: 775.1987762451172 and batch: 950, loss is 5.188587121963501 and perplexity is 179.215164800567
At time: 776.3388435840607 and batch: 1000, loss is 5.209800090789795 and perplexity is 183.05745966346493
At time: 777.4794476032257 and batch: 1050, loss is 5.175933361053467 and perplexity is 176.96170638386923
At time: 778.620046377182 and batch: 1100, loss is 5.1655854225158695 and perplexity is 175.1399594413972
At time: 779.761883020401 and batch: 1150, loss is 5.17029203414917 and perplexity is 175.96621812604215
At time: 780.9025039672852 and batch: 1200, loss is 5.155332431793213 and perplexity is 173.35342537128102
At time: 782.0428531169891 and batch: 1250, loss is 5.176285028457642 and perplexity is 177.02394899149826
At time: 783.1831622123718 and batch: 1300, loss is 5.149260110855103 and perplexity is 172.3039573148903
At time: 784.3240251541138 and batch: 1350, loss is 5.144431495666504 and perplexity is 171.47397325897884
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.171184895833333 and perplexity of 176.12340178110327
Finished 24 epochs...
Completing Train Step...
At time: 787.7347800731659 and batch: 50, loss is 5.255095748901367 and perplexity is 191.53982470418427
At time: 788.8430736064911 and batch: 100, loss is 5.262488145828247 and perplexity is 192.96100962520896
At time: 789.9545006752014 and batch: 150, loss is 5.23729567527771 and perplexity is 188.16056646922365
At time: 791.0730929374695 and batch: 200, loss is 5.2281910419464115 and perplexity is 186.4552086134607
At time: 792.2048060894012 and batch: 250, loss is 5.242826375961304 and perplexity is 189.20410934442108
At time: 793.343419790268 and batch: 300, loss is 5.24057674407959 and perplexity is 188.77894815527773
At time: 794.4838910102844 and batch: 350, loss is 5.249341630935669 and perplexity is 190.44084681416757
At time: 795.6244704723358 and batch: 400, loss is 5.2720029926300045 and perplexity is 194.8057664422688
At time: 796.7941708564758 and batch: 450, loss is 5.242865266799927 and perplexity is 189.21146779399166
At time: 797.9349548816681 and batch: 500, loss is 5.2760449886322025 and perplexity is 195.59476405983924
At time: 799.0766475200653 and batch: 550, loss is 5.257398691177368 and perplexity is 191.98143817402163
At time: 800.2176992893219 and batch: 600, loss is 5.206487455368042 and perplexity is 182.45206032562814
At time: 801.3583958148956 and batch: 650, loss is 5.231549940109253 and perplexity is 187.08254566194293
At time: 802.4999282360077 and batch: 700, loss is 5.250040817260742 and perplexity is 190.5740470104468
At time: 803.6403028964996 and batch: 750, loss is 5.234347486495972 and perplexity is 187.60665052359343
At time: 804.7809128761292 and batch: 800, loss is 5.217633562088013 and perplexity is 184.4970662163967
At time: 805.9222505092621 and batch: 850, loss is 5.18618103981018 and perplexity is 178.78447673415053
At time: 807.0633282661438 and batch: 900, loss is 5.217175025939941 and perplexity is 184.4124870351112
At time: 808.2047190666199 and batch: 950, loss is 5.1884669494628906 and perplexity is 179.19362936007548
At time: 809.3454146385193 and batch: 1000, loss is 5.209862451553345 and perplexity is 183.06887562237338
At time: 810.485856294632 and batch: 1050, loss is 5.176139707565308 and perplexity is 176.998225582386
At time: 811.6265773773193 and batch: 1100, loss is 5.165823440551758 and perplexity is 175.18165087200845
At time: 812.7673370838165 and batch: 1150, loss is 5.170651979446411 and perplexity is 176.02956773924376
At time: 813.9130568504333 and batch: 1200, loss is 5.155882406234741 and perplexity is 173.44879154666225
At time: 815.054922580719 and batch: 1250, loss is 5.176853494644165 and perplexity is 177.12460972910688
At time: 816.1969501972198 and batch: 1300, loss is 5.149644184112549 and perplexity is 172.37014736714787
At time: 817.3380842208862 and batch: 1350, loss is 5.144482307434082 and perplexity is 171.48268637601623
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.171122233072917 and perplexity of 176.11236574835155
Finished 25 epochs...
Completing Train Step...
At time: 820.7249758243561 and batch: 50, loss is 5.254066162109375 and perplexity is 191.34271931649192
At time: 821.8335943222046 and batch: 100, loss is 5.261251230239868 and perplexity is 192.72248069494194
At time: 822.9487705230713 and batch: 150, loss is 5.235983543395996 and perplexity is 187.91383689734604
At time: 824.0805480480194 and batch: 200, loss is 5.2270081520080565 and perplexity is 186.2347830185493
At time: 825.246904373169 and batch: 250, loss is 5.241710176467896 and perplexity is 188.99303763440255
At time: 826.3872394561768 and batch: 300, loss is 5.239504480361939 and perplexity is 188.5766358239848
At time: 827.5277767181396 and batch: 350, loss is 5.248408727645874 and perplexity is 190.26326676704738
At time: 828.6691119670868 and batch: 400, loss is 5.271029682159424 and perplexity is 194.61625219312361
At time: 829.8093364238739 and batch: 450, loss is 5.241898641586304 and perplexity is 189.02865958626091
At time: 830.9502470493317 and batch: 500, loss is 5.275065031051636 and perplexity is 195.40318337388388
At time: 832.0907292366028 and batch: 550, loss is 5.256570301055908 and perplexity is 191.82246850067892
At time: 833.2316086292267 and batch: 600, loss is 5.205843229293823 and perplexity is 182.33455780422926
At time: 834.3720703125 and batch: 650, loss is 5.230929489135742 and perplexity is 186.96650611650713
At time: 835.5138878822327 and batch: 700, loss is 5.249576301574707 and perplexity is 190.48554293361664
At time: 836.654262304306 and batch: 750, loss is 5.233988666534424 and perplexity is 187.53934558836568
At time: 837.7942662239075 and batch: 800, loss is 5.2173873233795165 and perplexity is 184.4516414899827
At time: 838.9344985485077 and batch: 850, loss is 5.185991668701172 and perplexity is 178.7506233250479
At time: 840.0748226642609 and batch: 900, loss is 5.216958932876587 and perplexity is 184.37264108123915
At time: 841.2154738903046 and batch: 950, loss is 5.1883084583282475 and perplexity is 179.16523100894028
At time: 842.3567805290222 and batch: 1000, loss is 5.2099052429199215 and perplexity is 183.07670955735006
At time: 843.4970245361328 and batch: 1050, loss is 5.176289796829224 and perplexity is 177.0247931094785
At time: 844.6374406814575 and batch: 1100, loss is 5.1659920787811275 and perplexity is 175.2111956865521
At time: 845.7783467769623 and batch: 1150, loss is 5.170911159515381 and perplexity is 176.07519700759408
At time: 846.9197862148285 and batch: 1200, loss is 5.156275596618652 and perplexity is 173.51700335283374
At time: 848.060254573822 and batch: 1250, loss is 5.177276391983032 and perplexity is 177.1995310961159
At time: 849.2018475532532 and batch: 1300, loss is 5.150017967224121 and perplexity is 172.4345884599188
At time: 850.342812538147 and batch: 1350, loss is 5.1444676399230955 and perplexity is 171.4801711702758
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.17107421875 and perplexity of 176.1039100353522
Finished 26 epochs...
Completing Train Step...
At time: 853.7469148635864 and batch: 50, loss is 5.2531165599823 and perplexity is 191.1611061070211
At time: 854.8951442241669 and batch: 100, loss is 5.2601621627807615 and perplexity is 192.51270716207685
At time: 856.0156927108765 and batch: 150, loss is 5.2348293113708495 and perplexity is 187.6970658549368
At time: 857.137024641037 and batch: 200, loss is 5.225908718109131 and perplexity is 186.03014269980474
At time: 858.2569878101349 and batch: 250, loss is 5.2406786346435545 and perplexity is 188.7981839287252
At time: 859.3776881694794 and batch: 300, loss is 5.238514995574951 and perplexity is 188.3901343970346
At time: 860.5047175884247 and batch: 350, loss is 5.247559509277344 and perplexity is 190.1017602928907
At time: 861.6339223384857 and batch: 400, loss is 5.2701679229736325 and perplexity is 194.4486120931645
At time: 862.7655825614929 and batch: 450, loss is 5.241002378463745 and perplexity is 188.85931606907764
At time: 863.9047577381134 and batch: 500, loss is 5.274153852462769 and perplexity is 195.22521726876244
At time: 865.0428578853607 and batch: 550, loss is 5.2558397197723385 and perplexity is 191.68237777548623
At time: 866.1818306446075 and batch: 600, loss is 5.205297746658325 and perplexity is 182.23512459110705
At time: 867.3202118873596 and batch: 650, loss is 5.23037501335144 and perplexity is 186.86286645188744
At time: 868.4589903354645 and batch: 700, loss is 5.249111642837525 and perplexity is 190.39705272225274
At time: 869.59787774086 and batch: 750, loss is 5.23366415977478 and perplexity is 187.4784976763364
At time: 870.7364926338196 and batch: 800, loss is 5.217122526168823 and perplexity is 184.40280567588735
At time: 871.8752498626709 and batch: 850, loss is 5.1857540321350095 and perplexity is 178.70815068744727
At time: 873.0134737491608 and batch: 900, loss is 5.216699094772339 and perplexity is 184.32474026720328
At time: 874.1520545482635 and batch: 950, loss is 5.188153848648072 and perplexity is 179.13753247116153
At time: 875.2911221981049 and batch: 1000, loss is 5.209897317886353 and perplexity is 183.0752586740303
At time: 876.430008649826 and batch: 1050, loss is 5.176362619400025 and perplexity is 177.03768497941212
At time: 877.569034576416 and batch: 1100, loss is 5.166096925735474 and perplexity is 175.22956700985898
At time: 878.7076098918915 and batch: 1150, loss is 5.171080141067505 and perplexity is 176.10495298170957
At time: 879.8498435020447 and batch: 1200, loss is 5.156551866531372 and perplexity is 173.56494750266359
At time: 881.011164188385 and batch: 1250, loss is 5.177637948989868 and perplexity is 177.26361041165646
At time: 882.1517252922058 and batch: 1300, loss is 5.150260992050171 and perplexity is 172.4764994382821
At time: 883.2902481555939 and batch: 1350, loss is 5.144398241043091 and perplexity is 171.46827105138584
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.171036376953125 and perplexity of 176.09724607304858
Finished 27 epochs...
Completing Train Step...
At time: 886.6588268280029 and batch: 50, loss is 5.252190351486206 and perplexity is 190.98413303605457
At time: 887.7994019985199 and batch: 100, loss is 5.2591697692871096 and perplexity is 192.32175357026657
At time: 888.9122743606567 and batch: 150, loss is 5.233796348571778 and perplexity is 187.5032818714675
At time: 890.025506734848 and batch: 200, loss is 5.224904632568359 and perplexity is 185.8434462686511
At time: 891.1445343494415 and batch: 250, loss is 5.239769239425659 and perplexity is 188.62656980747067
At time: 892.2822659015656 and batch: 300, loss is 5.2376494789123536 and perplexity is 188.22715013961482
At time: 893.4202702045441 and batch: 350, loss is 5.246777601242066 and perplexity is 189.9531762960778
At time: 894.5580604076385 and batch: 400, loss is 5.269358835220337 and perplexity is 194.29134973057938
At time: 895.6971800327301 and batch: 450, loss is 5.240179529190064 and perplexity is 188.7039772370096
At time: 896.8349359035492 and batch: 500, loss is 5.273300619125366 and perplexity is 195.05871564755518
At time: 897.9734978675842 and batch: 550, loss is 5.255152091979981 and perplexity is 191.55061695161652
At time: 899.1116900444031 and batch: 600, loss is 5.204794511795044 and perplexity is 182.1434405943251
At time: 900.2499799728394 and batch: 650, loss is 5.229861965179444 and perplexity is 186.76702138850985
At time: 901.3879597187042 and batch: 700, loss is 5.248682804107666 and perplexity is 190.31542059675408
At time: 902.5260903835297 and batch: 750, loss is 5.233362588882446 and perplexity is 187.42196814275812
At time: 903.6640768051147 and batch: 800, loss is 5.216825923919678 and perplexity is 184.34811949939757
At time: 904.802485704422 and batch: 850, loss is 5.185530757904052 and perplexity is 178.6682542166294
At time: 905.9410262107849 and batch: 900, loss is 5.216409692764282 and perplexity is 184.27140403541398
At time: 907.0788509845734 and batch: 950, loss is 5.187950229644775 and perplexity is 179.10106037867834
At time: 908.2169108390808 and batch: 1000, loss is 5.209823799133301 and perplexity is 183.0617997040474
At time: 909.3549869060516 and batch: 1050, loss is 5.176396379470825 and perplexity is 177.04366188508115
At time: 910.4923377037048 and batch: 1100, loss is 5.166125679016114 and perplexity is 175.23460550721197
At time: 911.6633024215698 and batch: 1150, loss is 5.1711850929260255 and perplexity is 176.12343649374213
At time: 912.8018736839294 and batch: 1200, loss is 5.156701145172119 and perplexity is 173.59085897607466
At time: 913.9417591094971 and batch: 1250, loss is 5.177910232543946 and perplexity is 177.3118829491188
At time: 915.0795481204987 and batch: 1300, loss is 5.1504483318328855 and perplexity is 172.50881417503356
At time: 916.2179174423218 and batch: 1350, loss is 5.144315319061279 and perplexity is 171.4540531520288
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.170998942057292 and perplexity of 176.09065401437263
Finished 28 epochs...
Completing Train Step...
At time: 919.61776304245 and batch: 50, loss is 5.251325674057007 and perplexity is 190.81906474258167
At time: 920.7229738235474 and batch: 100, loss is 5.258216552734375 and perplexity is 192.13851663742557
At time: 921.8338661193848 and batch: 150, loss is 5.232777004241943 and perplexity is 187.31224884502393
At time: 922.9592170715332 and batch: 200, loss is 5.223945817947388 and perplexity is 185.66534225316866
At time: 924.0928564071655 and batch: 250, loss is 5.238841991424561 and perplexity is 188.4517472621165
At time: 925.231315612793 and batch: 300, loss is 5.2367972564697265 and perplexity is 188.06680707163918
At time: 926.3774738311768 and batch: 350, loss is 5.246070518493652 and perplexity is 189.81891115598862
At time: 927.5150382518768 and batch: 400, loss is 5.268600254058838 and perplexity is 194.14401986072852
At time: 928.6531915664673 and batch: 450, loss is 5.2394093322753905 and perplexity is 188.5586939714984
At time: 929.7908380031586 and batch: 500, loss is 5.272500371932983 and perplexity is 194.90268289871986
At time: 930.9284527301788 and batch: 550, loss is 5.254538192749023 and perplexity is 191.43306026285288
At time: 932.0663254261017 and batch: 600, loss is 5.204283666610718 and perplexity is 182.0504172571258
At time: 933.2044658660889 and batch: 650, loss is 5.229337749481201 and perplexity is 186.66914084148507
At time: 934.3432657718658 and batch: 700, loss is 5.248225345611572 and perplexity is 190.2283791011181
At time: 935.4834067821503 and batch: 750, loss is 5.233035860061645 and perplexity is 187.3607419868341
At time: 936.6209180355072 and batch: 800, loss is 5.216510467529297 and perplexity is 184.289974878575
At time: 937.7587714195251 and batch: 850, loss is 5.1852873420715335 and perplexity is 178.6247688275154
At time: 938.8963308334351 and batch: 900, loss is 5.216127014160156 and perplexity is 184.21932181375257
At time: 940.0623543262482 and batch: 950, loss is 5.1877430725097655 and perplexity is 179.06396215884627
At time: 941.2006411552429 and batch: 1000, loss is 5.209727716445923 and perplexity is 183.04421147935105
At time: 942.338390827179 and batch: 1050, loss is 5.176373910903931 and perplexity is 177.03968401240962
At time: 943.4767260551453 and batch: 1100, loss is 5.1660685634613035 and perplexity is 175.22459717131503
At time: 944.6146800518036 and batch: 1150, loss is 5.171201944351196 and perplexity is 176.12640444966013
At time: 945.7531018257141 and batch: 1200, loss is 5.1568909740448 and perplexity is 173.62381466101317
At time: 946.8905732631683 and batch: 1250, loss is 5.178142108917236 and perplexity is 177.35300215258005
At time: 948.0284848213196 and batch: 1300, loss is 5.1506264114379885 and perplexity is 172.5395372120306
At time: 949.1665472984314 and batch: 1350, loss is 5.144176015853882 and perplexity is 171.43017071599195
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.171002604166667 and perplexity of 176.0912988787883
Annealing...
Finished 29 epochs...
Completing Train Step...
At time: 952.5620858669281 and batch: 50, loss is 5.251281490325928 and perplexity is 190.81063383059626
At time: 953.6752786636353 and batch: 100, loss is 5.25828031539917 and perplexity is 192.15076829185108
At time: 954.7919726371765 and batch: 150, loss is 5.233165588378906 and perplexity is 187.38504955726884
At time: 955.9164385795593 and batch: 200, loss is 5.224896621704102 and perplexity is 185.84195750799304
At time: 957.05157995224 and batch: 250, loss is 5.238794393539429 and perplexity is 188.44277757096825
At time: 958.1893193721771 and batch: 300, loss is 5.237021722793579 and perplexity is 188.1090264747011
At time: 959.3274366855621 and batch: 350, loss is 5.246289205551148 and perplexity is 189.86042663440978
At time: 960.4662017822266 and batch: 400, loss is 5.269184274673462 and perplexity is 194.2574370863083
At time: 961.6044914722443 and batch: 450, loss is 5.238994665145874 and perplexity is 188.48052108810666
At time: 962.7431938648224 and batch: 500, loss is 5.271433734893799 and perplexity is 194.69490331050565
At time: 963.8815469741821 and batch: 550, loss is 5.252479333877563 and perplexity is 191.0393320629198
At time: 965.0204141139984 and batch: 600, loss is 5.201313343048096 and perplexity is 181.5104709178163
At time: 966.1586940288544 and batch: 650, loss is 5.226733169555664 and perplexity is 186.1835787616528
At time: 967.2971267700195 and batch: 700, loss is 5.244515647888184 and perplexity is 189.5239966470367
At time: 968.4359126091003 and batch: 750, loss is 5.2299063014984135 and perplexity is 186.77530213431072
At time: 969.6020905971527 and batch: 800, loss is 5.213745040893555 and perplexity is 183.78103851078373
At time: 970.7398779392242 and batch: 850, loss is 5.180578718185425 and perplexity is 177.78566902736034
At time: 971.8775579929352 and batch: 900, loss is 5.2104316997528075 and perplexity is 183.17311691696875
At time: 973.015487909317 and batch: 950, loss is 5.181624889373779 and perplexity is 177.97176059684563
At time: 974.1538550853729 and batch: 1000, loss is 5.203968391418457 and perplexity is 181.9930303236375
At time: 975.2925264835358 and batch: 1050, loss is 5.169830341339111 and perplexity is 175.8849945399358
At time: 976.4308657646179 and batch: 1100, loss is 5.15929347038269 and perplexity is 174.0414467187708
At time: 977.5684549808502 and batch: 1150, loss is 5.164179277420044 and perplexity is 174.89386031243708
At time: 978.7070214748383 and batch: 1200, loss is 5.149345140457154 and perplexity is 172.3186088747119
At time: 979.8452653884888 and batch: 1250, loss is 5.170415458679199 and perplexity is 175.9879380141713
At time: 980.9844317436218 and batch: 1300, loss is 5.1433545589447025 and perplexity is 171.28940604178823
At time: 982.1233661174774 and batch: 1350, loss is 5.138315544128418 and perplexity is 170.42844720081354
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.168655598958333 and perplexity of 175.6784962975729
Finished 30 epochs...
Completing Train Step...
At time: 985.503259897232 and batch: 50, loss is 5.250253705978394 and perplexity is 190.6146223938
At time: 986.6465797424316 and batch: 100, loss is 5.257347602844238 and perplexity is 191.97163041288658
At time: 987.7713491916656 and batch: 150, loss is 5.232332496643067 and perplexity is 187.2290056295412
At time: 988.9036846160889 and batch: 200, loss is 5.224012212753296 and perplexity is 185.67766987677203
At time: 990.0367338657379 and batch: 250, loss is 5.238037614822388 and perplexity is 188.30022203582357
At time: 991.1767094135284 and batch: 300, loss is 5.236453790664672 and perplexity is 188.0022236460784
At time: 992.3166899681091 and batch: 350, loss is 5.2454628658294675 and perplexity is 189.7036022263493
At time: 993.4570546150208 and batch: 400, loss is 5.268410081863403 and perplexity is 194.10710257667282
At time: 994.5977516174316 and batch: 450, loss is 5.238380556106567 and perplexity is 188.36480902992014
At time: 995.7455937862396 and batch: 500, loss is 5.270853004455566 and perplexity is 194.5818708778482
At time: 996.8864221572876 and batch: 550, loss is 5.252062911987305 and perplexity is 190.95979566464652
At time: 998.0565118789673 and batch: 600, loss is 5.201127452850342 and perplexity is 181.47673303635085
At time: 999.197099685669 and batch: 650, loss is 5.226324348449707 and perplexity is 186.10747854182043
At time: 1000.4808740615845 and batch: 700, loss is 5.244231224060059 and perplexity is 189.47009917161526
At time: 1001.6125466823578 and batch: 750, loss is 5.229652347564698 and perplexity is 186.72787583391542
At time: 1002.7446937561035 and batch: 800, loss is 5.213498077392578 and perplexity is 183.73565690613066
At time: 1003.87708568573 and batch: 850, loss is 5.180437908172608 and perplexity is 177.76063678746232
At time: 1005.0164473056793 and batch: 900, loss is 5.2104383563995365 and perplexity is 183.1743362397566
At time: 1006.1571264266968 and batch: 950, loss is 5.181583471298218 and perplexity is 177.9643895016668
At time: 1007.302990436554 and batch: 1000, loss is 5.20398247718811 and perplexity is 181.9955938535957
At time: 1008.4430510997772 and batch: 1050, loss is 5.169938278198242 and perplexity is 175.9039800384139
At time: 1009.5834000110626 and batch: 1100, loss is 5.1595650577545165 and perplexity is 174.08872059707764
At time: 1010.7230513095856 and batch: 1150, loss is 5.164496545791626 and perplexity is 174.94935740596878
At time: 1011.8627903461456 and batch: 1200, loss is 5.149737091064453 and perplexity is 172.38616249608592
At time: 1013.0025086402893 and batch: 1250, loss is 5.170810317993164 and perplexity is 176.05744221192853
At time: 1014.1426863670349 and batch: 1300, loss is 5.143627071380616 and perplexity is 171.3360908958875
At time: 1015.2831254005432 and batch: 1350, loss is 5.138548421859741 and perplexity is 170.46814081265026
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1684814453125 and perplexity of 175.64790391091333
Finished 31 epochs...
Completing Train Step...
At time: 1018.6870384216309 and batch: 50, loss is 5.249808654785157 and perplexity is 190.52980800342792
At time: 1019.8022880554199 and batch: 100, loss is 5.256840982437134 and perplexity is 191.87439829930054
At time: 1020.9204022884369 and batch: 150, loss is 5.231852140426636 and perplexity is 187.13909061013905
At time: 1022.0510172843933 and batch: 200, loss is 5.223526840209961 and perplexity is 185.58756890194195
At time: 1023.1879942417145 and batch: 250, loss is 5.237626323699951 and perplexity is 188.22279175043332
At time: 1024.328245639801 and batch: 300, loss is 5.236122283935547 and perplexity is 187.93990997312082
At time: 1025.4695796966553 and batch: 350, loss is 5.245049962997436 and perplexity is 189.62528924068292
At time: 1026.6382474899292 and batch: 400, loss is 5.268064060211182 and perplexity is 194.03994893530827
At time: 1027.7786524295807 and batch: 450, loss is 5.23808557510376 and perplexity is 188.30925318402132
At time: 1028.9192335605621 and batch: 500, loss is 5.2705549621582035 and perplexity is 194.5238858914451
At time: 1030.0597171783447 and batch: 550, loss is 5.251849555969239 and perplexity is 190.91905758904412
At time: 1031.2011535167694 and batch: 600, loss is 5.201012449264526 and perplexity is 181.45586376135336
At time: 1032.342044353485 and batch: 650, loss is 5.2260902309417725 and perplexity is 186.06391262270736
At time: 1033.4823169708252 and batch: 700, loss is 5.244081087112427 and perplexity is 189.44165484458384
At time: 1034.6227264404297 and batch: 750, loss is 5.229534835815429 and perplexity is 186.7059344038022
At time: 1035.763173341751 and batch: 800, loss is 5.213401117324829 and perplexity is 183.7178427480341
At time: 1036.90385055542 and batch: 850, loss is 5.180363807678223 and perplexity is 177.74746512441357
At time: 1038.0449690818787 and batch: 900, loss is 5.21047308921814 and perplexity is 183.1806985112392
At time: 1039.1862399578094 and batch: 950, loss is 5.181633644104004 and perplexity is 177.97331869841756
At time: 1040.3264083862305 and batch: 1000, loss is 5.204051923751831 and perplexity is 182.0082332610778
At time: 1041.4672374725342 and batch: 1050, loss is 5.170069131851196 and perplexity is 175.92699922281042
At time: 1042.60880112648 and batch: 1100, loss is 5.159796838760376 and perplexity is 174.12907573244266
At time: 1043.7491745948792 and batch: 1150, loss is 5.164742679595947 and perplexity is 174.9924236566833
At time: 1044.8901853561401 and batch: 1200, loss is 5.1500256156921385 and perplexity is 172.43590732539735
At time: 1046.0316700935364 and batch: 1250, loss is 5.171078491210937 and perplexity is 176.10466243403596
At time: 1047.1719794273376 and batch: 1300, loss is 5.143797283172607 and perplexity is 171.36525680107184
At time: 1048.3149979114532 and batch: 1350, loss is 5.1386585521698 and perplexity is 170.4869155556683
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.168402506510417 and perplexity of 175.6340390230363
Finished 32 epochs...
Completing Train Step...
At time: 1051.7388894557953 and batch: 50, loss is 5.249473400115967 and perplexity is 190.46594270184346
At time: 1052.849247455597 and batch: 100, loss is 5.256437816619873 and perplexity is 191.79705669249248
At time: 1053.9732129573822 and batch: 150, loss is 5.2314706134796145 and perplexity is 187.0677056227443
At time: 1055.1078226566315 and batch: 200, loss is 5.223163280487061 and perplexity is 185.52010900041284
At time: 1056.24795627594 and batch: 250, loss is 5.237298965454102 and perplexity is 188.16118555169575
At time: 1057.3869824409485 and batch: 300, loss is 5.235847082138061 and perplexity is 187.88819568833537
At time: 1058.5270977020264 and batch: 350, loss is 5.244747743606568 and perplexity is 189.56798946026382
At time: 1059.6674904823303 and batch: 400, loss is 5.267824401855469 and perplexity is 193.99345121221035
At time: 1060.8075087070465 and batch: 450, loss is 5.237876262664795 and perplexity is 188.2698418397438
At time: 1061.947066783905 and batch: 500, loss is 5.270342864990234 and perplexity is 194.48263230118468
At time: 1063.0866451263428 and batch: 550, loss is 5.251702165603637 and perplexity is 190.89092003299908
At time: 1064.2265701293945 and batch: 600, loss is 5.200908880233765 and perplexity is 181.4370715265812
At time: 1065.366956949234 and batch: 650, loss is 5.225911722183228 and perplexity is 186.0307015489771
At time: 1066.5065262317657 and batch: 700, loss is 5.243965044021606 and perplexity is 189.41967272488668
At time: 1067.6466343402863 and batch: 750, loss is 5.229452524185181 and perplexity is 186.6905669664324
At time: 1068.7858481407166 and batch: 800, loss is 5.213355798721313 and perplexity is 183.70951710061453
At time: 1069.92573595047 and batch: 850, loss is 5.180316600799561 and perplexity is 177.739074419446
At time: 1071.0654764175415 and batch: 900, loss is 5.210507154464722 and perplexity is 183.18693871318942
At time: 1072.2048869132996 and batch: 950, loss is 5.181692085266113 and perplexity is 177.98371996991503
At time: 1073.3450195789337 and batch: 1000, loss is 5.204126968383789 and perplexity is 182.02189251447652
At time: 1074.4850974082947 and batch: 1050, loss is 5.170185194015503 and perplexity is 175.94741887605187
At time: 1075.6253597736359 and batch: 1100, loss is 5.159983997344971 and perplexity is 174.16166853370967
At time: 1076.764969587326 and batch: 1150, loss is 5.164937953948975 and perplexity is 175.02659852562678
At time: 1077.9329035282135 and batch: 1200, loss is 5.150251884460449 and perplexity is 172.47492860024175
At time: 1079.0727603435516 and batch: 1250, loss is 5.171282339096069 and perplexity is 176.1405646562067
At time: 1080.2130184173584 and batch: 1300, loss is 5.143915205001831 and perplexity is 171.38546569713083
At time: 1081.353396654129 and batch: 1350, loss is 5.1387193775177 and perplexity is 170.49728579700292
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.168351236979166 and perplexity of 175.62503457901272
Finished 33 epochs...
Completing Train Step...
At time: 1084.7574241161346 and batch: 50, loss is 5.249185476303101 and perplexity is 190.41111091546685
At time: 1085.8764719963074 and batch: 100, loss is 5.256092529296875 and perplexity is 191.73084303225488
At time: 1086.9966797828674 and batch: 150, loss is 5.231145076751709 and perplexity is 187.00681812505513
At time: 1088.116126537323 and batch: 200, loss is 5.222860317230225 and perplexity is 185.46391173726434
At time: 1089.2438461780548 and batch: 250, loss is 5.237020349502563 and perplexity is 188.10876814644237
At time: 1090.3729059696198 and batch: 300, loss is 5.235611171722412 and perplexity is 187.8438761339227
At time: 1091.510585308075 and batch: 350, loss is 5.244501781463623 and perplexity is 189.52136864505533
At time: 1092.6487474441528 and batch: 400, loss is 5.2676363372802735 and perplexity is 193.95697134661015
At time: 1093.786756515503 and batch: 450, loss is 5.237704172134399 and perplexity is 188.23744517046404
At time: 1094.924711227417 and batch: 500, loss is 5.270173559188843 and perplexity is 194.44970805047808
At time: 1096.0626757144928 and batch: 550, loss is 5.2515871047973635 and perplexity is 190.86895723338267
At time: 1097.2005362510681 and batch: 600, loss is 5.20081600189209 and perplexity is 181.42022073480828
At time: 1098.3384914398193 and batch: 650, loss is 5.225761060714722 and perplexity is 186.00267600153256
At time: 1099.4765076637268 and batch: 700, loss is 5.24386438369751 and perplexity is 189.40060663885524
At time: 1100.6148324012756 and batch: 750, loss is 5.229384212493897 and perplexity is 186.6778142536408
At time: 1101.7525527477264 and batch: 800, loss is 5.213328094482422 and perplexity is 183.7044276387663
At time: 1102.891144990921 and batch: 850, loss is 5.180284395217895 and perplexity is 177.7333503213441
At time: 1104.028713464737 and batch: 900, loss is 5.210537090301513 and perplexity is 183.1924226495718
At time: 1105.1659145355225 and batch: 950, loss is 5.181747617721558 and perplexity is 177.9936041173571
At time: 1106.3362715244293 and batch: 1000, loss is 5.204193639755249 and perplexity is 182.03402856824542
At time: 1107.4739918708801 and batch: 1050, loss is 5.1702851295471195 and perplexity is 175.9650031535262
At time: 1108.6201384067535 and batch: 1100, loss is 5.16013822555542 and perplexity is 174.18853124761733
At time: 1109.75812458992 and batch: 1150, loss is 5.165098524093628 and perplexity is 175.05470482832624
At time: 1110.8959493637085 and batch: 1200, loss is 5.1504379081726075 and perplexity is 172.50701601113138
At time: 1112.0331692695618 and batch: 1250, loss is 5.171444339752197 and perplexity is 176.16910185471178
At time: 1113.1709167957306 and batch: 1300, loss is 5.144001684188843 and perplexity is 171.4002876137543
At time: 1114.3115940093994 and batch: 1350, loss is 5.138751678466797 and perplexity is 170.50279311009783
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.168316650390625 and perplexity of 175.61896041324707
Finished 34 epochs...
Completing Train Step...
At time: 1117.7032227516174 and batch: 50, loss is 5.2489305591583255 and perplexity is 190.36257804493204
At time: 1118.8433017730713 and batch: 100, loss is 5.255782794952393 and perplexity is 191.67146660120585
At time: 1119.9551067352295 and batch: 150, loss is 5.230853910446167 and perplexity is 186.95237596695623
At time: 1121.079831123352 and batch: 200, loss is 5.222595100402832 and perplexity is 185.41473010918344
At time: 1122.211368560791 and batch: 250, loss is 5.236777296066284 and perplexity is 188.0630532197603
At time: 1123.3491823673248 and batch: 300, loss is 5.235403995513916 and perplexity is 187.80496338291348
At time: 1124.4863517284393 and batch: 350, loss is 5.244291572570801 and perplexity is 189.48153375495707
At time: 1125.6248869895935 and batch: 400, loss is 5.267478790283203 and perplexity is 193.92641641519563
At time: 1126.76256108284 and batch: 450, loss is 5.237553396224976 and perplexity is 188.2090656380096
At time: 1127.9004938602448 and batch: 500, loss is 5.270029678344726 and perplexity is 194.4217324749686
At time: 1129.0382916927338 and batch: 550, loss is 5.251490345001221 and perplexity is 190.85048968546332
At time: 1130.1763994693756 and batch: 600, loss is 5.200733003616333 and perplexity is 181.40516379415854
At time: 1131.313725233078 and batch: 650, loss is 5.225625944137573 and perplexity is 185.9775456544123
At time: 1132.4515073299408 and batch: 700, loss is 5.243771190643311 and perplexity is 189.38295664029684
At time: 1133.588617324829 and batch: 750, loss is 5.229322652816773 and perplexity is 186.66632278137845
At time: 1134.7547483444214 and batch: 800, loss is 5.213306674957275 and perplexity is 183.7004928193001
At time: 1135.8929605484009 and batch: 850, loss is 5.180258569717407 and perplexity is 177.72876032788827
At time: 1137.030920267105 and batch: 900, loss is 5.210560274124146 and perplexity is 183.1966697994385
At time: 1138.1687223911285 and batch: 950, loss is 5.181796026229859 and perplexity is 178.0022207307765
At time: 1139.3062686920166 and batch: 1000, loss is 5.20425048828125 and perplexity is 182.04437722860186
At time: 1140.4439404010773 and batch: 1050, loss is 5.170371036529541 and perplexity is 175.98012042528927
At time: 1141.5812847614288 and batch: 1100, loss is 5.16026798248291 and perplexity is 174.21113488269356
At time: 1142.7189173698425 and batch: 1150, loss is 5.165233058929443 and perplexity is 175.07825736858211
At time: 1143.8563995361328 and batch: 1200, loss is 5.1505955219268795 and perplexity is 172.53420763239365
At time: 1144.9940476417542 and batch: 1250, loss is 5.171577224731445 and perplexity is 176.19251363765858
At time: 1146.1317760944366 and batch: 1300, loss is 5.144066848754883 and perplexity is 171.41145720304257
At time: 1147.2697069644928 and batch: 1350, loss is 5.138765869140625 and perplexity is 170.50521267678923
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.168289388020833 and perplexity of 175.61417268946846
Finished 35 epochs...
Completing Train Step...
At time: 1150.626992225647 and batch: 50, loss is 5.248699502944946 and perplexity is 190.3185986695295
At time: 1151.7644288539886 and batch: 100, loss is 5.255498208999634 and perplexity is 191.61692735518616
At time: 1152.8763325214386 and batch: 150, loss is 5.230587825775147 and perplexity is 186.9026374231261
At time: 1153.9941947460175 and batch: 200, loss is 5.222357683181762 and perplexity is 185.37071468443224
At time: 1155.112365245819 and batch: 250, loss is 5.236561479568482 and perplexity is 188.0224704896172
At time: 1156.245110988617 and batch: 300, loss is 5.235217342376709 and perplexity is 187.76991226861688
At time: 1157.382644891739 and batch: 350, loss is 5.244105987548828 and perplexity is 189.44637208319236
At time: 1158.5201742649078 and batch: 400, loss is 5.2673410797119145 and perplexity is 193.89971253634857
At time: 1159.657681465149 and batch: 450, loss is 5.237417764663697 and perplexity is 188.18354027965148
At time: 1160.7948496341705 and batch: 500, loss is 5.269901609420776 and perplexity is 194.39683468724846
At time: 1161.931969165802 and batch: 550, loss is 5.251403150558471 and perplexity is 190.83384930885143
At time: 1163.0699970722198 and batch: 600, loss is 5.200656681060791 and perplexity is 181.39131901681048
At time: 1164.236135005951 and batch: 650, loss is 5.225500459671021 and perplexity is 185.9542098254777
At time: 1165.3741478919983 and batch: 700, loss is 5.24368052482605 and perplexity is 189.36578685812566
At time: 1166.51202750206 and batch: 750, loss is 5.229264497756958 and perplexity is 186.65546750585935
At time: 1167.6492280960083 and batch: 800, loss is 5.213286380767823 and perplexity is 183.69676480452497
At time: 1168.7868671417236 and batch: 850, loss is 5.180232391357422 and perplexity is 177.72410774131959
At time: 1169.9245643615723 and batch: 900, loss is 5.21057538986206 and perplexity is 183.19943897321502
At time: 1171.0626027584076 and batch: 950, loss is 5.181836233139038 and perplexity is 178.00937779377995
At time: 1172.2004747390747 and batch: 1000, loss is 5.20429856300354 and perplexity is 182.05312917185353
At time: 1173.3388435840607 and batch: 1050, loss is 5.170444393157959 and perplexity is 175.9930302070955
At time: 1174.4767353534698 and batch: 1100, loss is 5.160377063751221 and perplexity is 174.23013909072307
At time: 1175.6151051521301 and batch: 1150, loss is 5.165345649719239 and perplexity is 175.09797067760294
At time: 1176.7528860569 and batch: 1200, loss is 5.150730199813843 and perplexity is 172.55744573970097
At time: 1177.8905317783356 and batch: 1250, loss is 5.171687154769898 and perplexity is 176.21188355210603
At time: 1179.0281882286072 and batch: 1300, loss is 5.144116058349609 and perplexity is 171.41989249893
At time: 1180.166318655014 and batch: 1350, loss is 5.138768453598022 and perplexity is 170.50565334081685
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.168267415364583 and perplexity of 175.61031402201206
Finished 36 epochs...
Completing Train Step...
At time: 1183.5777184963226 and batch: 50, loss is 5.248491334915161 and perplexity is 190.27898454515312
At time: 1184.6903824806213 and batch: 100, loss is 5.255233316421509 and perplexity is 191.5661761753889
At time: 1185.8066835403442 and batch: 150, loss is 5.230341653823853 and perplexity is 186.85663289891374
At time: 1186.9335417747498 and batch: 200, loss is 5.222144536972046 and perplexity is 185.3312078297225
At time: 1188.06991147995 and batch: 250, loss is 5.236352996826172 and perplexity is 187.9832751352731
At time: 1189.2080557346344 and batch: 300, loss is 5.2350420570373535 and perplexity is 187.7370018402662
At time: 1190.345939874649 and batch: 350, loss is 5.243938341140747 and perplexity is 189.41461474146513
At time: 1191.4840989112854 and batch: 400, loss is 5.267214422225952 and perplexity is 193.87515524144533
At time: 1192.6507110595703 and batch: 450, loss is 5.237295217514038 and perplexity is 188.16048033617164
At time: 1193.7893438339233 and batch: 500, loss is 5.269784832000733 and perplexity is 194.374134851869
At time: 1194.9277923107147 and batch: 550, loss is 5.251324100494385 and perplexity is 190.81876447706998
At time: 1196.0662906169891 and batch: 600, loss is 5.200588150024414 and perplexity is 181.37888850767112
At time: 1197.2041597366333 and batch: 650, loss is 5.2253830623626705 and perplexity is 185.93238058314003
At time: 1198.3423345088959 and batch: 700, loss is 5.243593492507935 and perplexity is 189.34930663189027
At time: 1199.4814631938934 and batch: 750, loss is 5.229211540222168 and perplexity is 186.64558295417817
At time: 1200.619817495346 and batch: 800, loss is 5.213269348144531 and perplexity is 183.69363599337623
At time: 1201.7580885887146 and batch: 850, loss is 5.180204811096192 and perplexity is 177.71920613159529
At time: 1202.8959963321686 and batch: 900, loss is 5.210586709976196 and perplexity is 183.2015128235119
At time: 1204.034321308136 and batch: 950, loss is 5.181872348785401 and perplexity is 178.0158068336113
At time: 1205.1721575260162 and batch: 1000, loss is 5.204338836669922 and perplexity is 182.06046126648567
At time: 1206.3104972839355 and batch: 1050, loss is 5.170508594512939 and perplexity is 176.00432956081482
At time: 1207.44912648201 and batch: 1100, loss is 5.160470886230469 and perplexity is 174.24648656120038
At time: 1208.587738275528 and batch: 1150, loss is 5.1654421329498295 and perplexity is 175.11486551050473
At time: 1209.7255082130432 and batch: 1200, loss is 5.1508503246307376 and perplexity is 172.5781754163236
At time: 1210.8628051280975 and batch: 1250, loss is 5.171778078079224 and perplexity is 176.2279060480993
At time: 1212.000405550003 and batch: 1300, loss is 5.1441527843475345 and perplexity is 171.4261881811532
At time: 1213.1384949684143 and batch: 1350, loss is 5.138754405975342 and perplexity is 170.50325815855723
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.16824951171875 and perplexity of 175.6071699852902
Finished 37 epochs...
Completing Train Step...
At time: 1216.543241739273 and batch: 50, loss is 5.248289556503296 and perplexity is 190.2405942271392
At time: 1217.6573343276978 and batch: 100, loss is 5.254982929229737 and perplexity is 191.5182164629972
At time: 1218.7741417884827 and batch: 150, loss is 5.230099363327026 and perplexity is 186.81136479673026
At time: 1219.9043188095093 and batch: 200, loss is 5.2219408512115475 and perplexity is 185.29346234595096
At time: 1221.0639896392822 and batch: 250, loss is 5.236160945892334 and perplexity is 187.94717623826187
At time: 1222.196515083313 and batch: 300, loss is 5.234878463745117 and perplexity is 187.70629183810425
At time: 1223.329743862152 and batch: 350, loss is 5.243783159255981 and perplexity is 189.3852233051157
At time: 1224.4681560993195 and batch: 400, loss is 5.267091121673584 and perplexity is 193.85125180139755
At time: 1225.6086921691895 and batch: 450, loss is 5.237180213928223 and perplexity is 188.13884245046532
At time: 1226.7484691143036 and batch: 500, loss is 5.269672660827637 and perplexity is 194.3523328999413
At time: 1227.8886740207672 and batch: 550, loss is 5.251246929168701 and perplexity is 190.8040393082377
At time: 1229.0294997692108 and batch: 600, loss is 5.200521860122681 and perplexity is 181.3668653174879
At time: 1230.1692669391632 and batch: 650, loss is 5.225270481109619 and perplexity is 185.91144926101046
At time: 1231.309897184372 and batch: 700, loss is 5.243506250381469 and perplexity is 189.33278811630066
At time: 1232.4497327804565 and batch: 750, loss is 5.2291593170166015 and perplexity is 186.6358359780429
At time: 1233.590040922165 and batch: 800, loss is 5.213252925872803 and perplexity is 183.69061935134133
At time: 1234.731125831604 and batch: 850, loss is 5.180162763595581 and perplexity is 177.71173364026777
At time: 1235.8725113868713 and batch: 900, loss is 5.210591220855713 and perplexity is 183.2023392253275
At time: 1237.0124773979187 and batch: 950, loss is 5.181906061172485 and perplexity is 178.0218082725593
At time: 1238.1521608829498 and batch: 1000, loss is 5.204373474121094 and perplexity is 182.06676748603823
At time: 1239.292273759842 and batch: 1050, loss is 5.170562839508056 and perplexity is 176.0138771737652
At time: 1240.4330263137817 and batch: 1100, loss is 5.160549955368042 and perplexity is 174.26026462532062
At time: 1241.5732777118683 and batch: 1150, loss is 5.165523452758789 and perplexity is 175.12910639693925
At time: 1242.7143139839172 and batch: 1200, loss is 5.150953502655029 and perplexity is 172.59598261013863
At time: 1243.8541152477264 and batch: 1250, loss is 5.171852416992188 and perplexity is 176.24100712602277
At time: 1244.9945604801178 and batch: 1300, loss is 5.144180116653442 and perplexity is 171.4308737182021
At time: 1246.135403394699 and batch: 1350, loss is 5.138731641769409 and perplexity is 170.49937683145413
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.168233642578125 and perplexity of 175.6043832725263
Finished 38 epochs...
Completing Train Step...
At time: 1249.524004459381 and batch: 50, loss is 5.248104944229126 and perplexity is 190.20547672006063
At time: 1250.663914680481 and batch: 100, loss is 5.254745655059814 and perplexity is 191.4727795278796
At time: 1251.7812235355377 and batch: 150, loss is 5.229867820739746 and perplexity is 186.768115017268
At time: 1252.90682721138 and batch: 200, loss is 5.221754112243652 and perplexity is 185.25886406655877
At time: 1254.0387609004974 and batch: 250, loss is 5.23597113609314 and perplexity is 187.91150540792458
At time: 1255.1772933006287 and batch: 300, loss is 5.234722766876221 and perplexity is 187.6770688312173
At time: 1256.3185300827026 and batch: 350, loss is 5.243641080856324 and perplexity is 189.3583176670699
At time: 1257.4594061374664 and batch: 400, loss is 5.266964082717895 and perplexity is 193.8266267050162
At time: 1258.5998647212982 and batch: 450, loss is 5.2370744323730465 and perplexity is 188.1189418836968
At time: 1259.740645647049 and batch: 500, loss is 5.269567384719848 and perplexity is 194.33187331976535
At time: 1260.8812065124512 and batch: 550, loss is 5.251175079345703 and perplexity is 190.79033056427744
At time: 1262.0225415229797 and batch: 600, loss is 5.200460519790649 and perplexity is 181.35574055495164
At time: 1263.1639165878296 and batch: 650, loss is 5.225164079666138 and perplexity is 185.89166906678875
At time: 1264.3054916858673 and batch: 700, loss is 5.243425941467285 and perplexity is 189.31758361620413
At time: 1265.446593761444 and batch: 750, loss is 5.229110431671143 and perplexity is 186.62671244373152
At time: 1266.5875165462494 and batch: 800, loss is 5.213238105773926 and perplexity is 183.68789705837213
At time: 1267.7282395362854 and batch: 850, loss is 5.180128593444824 and perplexity is 177.70566130728486
At time: 1268.869089603424 and batch: 900, loss is 5.210593338012695 and perplexity is 183.20272709384972
At time: 1270.0103869438171 and batch: 950, loss is 5.18193567276001 and perplexity is 178.02707985896583
At time: 1271.1513261795044 and batch: 1000, loss is 5.2044041633605955 and perplexity is 182.07235506240968
At time: 1272.291841506958 and batch: 1050, loss is 5.1706116676330565 and perplexity is 176.02247181118992
At time: 1273.4327182769775 and batch: 1100, loss is 5.160621223449707 and perplexity is 174.27268426264743
At time: 1274.576734304428 and batch: 1150, loss is 5.165597152709961 and perplexity is 175.1420138791641
At time: 1275.7176883220673 and batch: 1200, loss is 5.151048717498779 and perplexity is 172.6124170920456
At time: 1276.8586885929108 and batch: 1250, loss is 5.171921939849853 and perplexity is 176.25326033040997
At time: 1277.9990031719208 and batch: 1300, loss is 5.14419828414917 and perplexity is 171.4339882161593
At time: 1279.1392920017242 and batch: 1350, loss is 5.1387074851989745 and perplexity is 170.49525820099484
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1682206217447915 and perplexity of 175.60209677200518
Finished 39 epochs...
Completing Train Step...
At time: 1282.5143122673035 and batch: 50, loss is 5.2479219722747805 and perplexity is 190.1706776359833
At time: 1283.6570801734924 and batch: 100, loss is 5.254517230987549 and perplexity is 191.4290475307625
At time: 1284.7739362716675 and batch: 150, loss is 5.229654092788696 and perplexity is 186.72820171616982
At time: 1285.9022462368011 and batch: 200, loss is 5.22157190322876 and perplexity is 185.2251113065591
At time: 1287.0396189689636 and batch: 250, loss is 5.235800266265869 and perplexity is 187.87939974447607
At time: 1288.178825378418 and batch: 300, loss is 5.234579420089721 and perplexity is 187.65016785463104
At time: 1289.3183405399323 and batch: 350, loss is 5.243508701324463 and perplexity is 189.3332521607398
At time: 1290.4579493999481 and batch: 400, loss is 5.266857233047485 and perplexity is 193.8059175002416
At time: 1291.5972981452942 and batch: 450, loss is 5.236974506378174 and perplexity is 188.1001448504465
At time: 1292.73632645607 and batch: 500, loss is 5.269467601776123 and perplexity is 194.31248328079948
At time: 1293.8752834796906 and batch: 550, loss is 5.25110725402832 and perplexity is 190.77739058838728
At time: 1295.0150074958801 and batch: 600, loss is 5.200398349761963 and perplexity is 181.34446601383186
At time: 1296.1546864509583 and batch: 650, loss is 5.2250597953796385 and perplexity is 185.87228449748446
At time: 1297.2942953109741 and batch: 700, loss is 5.243348731994629 and perplexity is 189.30296706968377
At time: 1298.4344804286957 and batch: 750, loss is 5.229058704376221 and perplexity is 186.61705899841206
At time: 1299.573820590973 and batch: 800, loss is 5.213214836120605 and perplexity is 183.68362275441936
At time: 1300.7131118774414 and batch: 850, loss is 5.180092725753784 and perplexity is 177.69928752983614
At time: 1301.8523423671722 and batch: 900, loss is 5.210591583251953 and perplexity is 183.20240561717844
At time: 1302.9921708106995 and batch: 950, loss is 5.181957960128784 and perplexity is 178.03104765836224
At time: 1304.1317369937897 and batch: 1000, loss is 5.204427604675293 and perplexity is 182.07662312780673
At time: 1305.2720756530762 and batch: 1050, loss is 5.170652933120728 and perplexity is 176.02973561420148
At time: 1306.4118099212646 and batch: 1100, loss is 5.160681924819946 and perplexity is 174.2832631744515
At time: 1307.59334731102 and batch: 1150, loss is 5.165662126541138 and perplexity is 175.15339389650347
At time: 1308.7322862148285 and batch: 1200, loss is 5.151133298873901 and perplexity is 172.62701750509927
At time: 1309.8714072704315 and batch: 1250, loss is 5.171982250213623 and perplexity is 176.26389054920907
At time: 1311.0107374191284 and batch: 1300, loss is 5.144208068847656 and perplexity is 171.43566565425087
At time: 1312.1507499217987 and batch: 1350, loss is 5.138689985275269 and perplexity is 170.49227457309084
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.168207600911458 and perplexity of 175.59981030125604
Finished 40 epochs...
Completing Train Step...
At time: 1315.5514178276062 and batch: 50, loss is 5.247750358581543 and perplexity is 190.13804454387156
At time: 1316.663348197937 and batch: 100, loss is 5.2542971324920655 and perplexity is 191.38691892180094
At time: 1317.775280714035 and batch: 150, loss is 5.229455394744873 and perplexity is 186.69110287361804
At time: 1318.8927116394043 and batch: 200, loss is 5.22140323638916 and perplexity is 185.19387260696092
At time: 1320.0182430744171 and batch: 250, loss is 5.235631790161133 and perplexity is 187.8477492213002
At time: 1321.146517276764 and batch: 300, loss is 5.234440927505493 and perplexity is 187.6241814974544
At time: 1322.278030872345 and batch: 350, loss is 5.2433843994140625 and perplexity is 189.30971913842404
At time: 1323.4156382083893 and batch: 400, loss is 5.2667584896087645 and perplexity is 193.7867813823018
At time: 1324.5528590679169 and batch: 450, loss is 5.236881160736084 and perplexity is 188.0825873411195
At time: 1325.6901242733002 and batch: 500, loss is 5.269370269775391 and perplexity is 194.29357137841612
At time: 1326.8277440071106 and batch: 550, loss is 5.25104546546936 and perplexity is 190.76560309251062
At time: 1327.9650819301605 and batch: 600, loss is 5.200331840515137 and perplexity is 181.33240533105905
At time: 1329.102544784546 and batch: 650, loss is 5.224960374832153 and perplexity is 185.85380589178914
At time: 1330.2397713661194 and batch: 700, loss is 5.243276662826538 and perplexity is 189.28932465393473
At time: 1331.3782889842987 and batch: 750, loss is 5.229014682769775 and perplexity is 186.60884399650493
At time: 1332.5160613059998 and batch: 800, loss is 5.2131933498382566 and perplexity is 183.67967611863742
At time: 1333.6543645858765 and batch: 850, loss is 5.180058612823486 and perplexity is 177.69322578981902
At time: 1334.7915933132172 and batch: 900, loss is 5.2105883121490475 and perplexity is 183.2018063442372
At time: 1335.9582867622375 and batch: 950, loss is 5.181971216201783 and perplexity is 178.03340766656817
At time: 1337.0957300662994 and batch: 1000, loss is 5.204445648193359 and perplexity is 182.079908460285
At time: 1338.2332611083984 and batch: 1050, loss is 5.170695791244507 and perplexity is 176.03728008006885
At time: 1339.3720214366913 and batch: 1100, loss is 5.160737810134887 and perplexity is 174.29300332166602
At time: 1340.5098388195038 and batch: 1150, loss is 5.165721340179443 and perplexity is 175.16376567328993
At time: 1341.648591518402 and batch: 1200, loss is 5.151211862564087 and perplexity is 172.64058025338298
At time: 1342.7856795787811 and batch: 1250, loss is 5.17203649520874 and perplexity is 176.27345224242586
At time: 1343.9227585792542 and batch: 1300, loss is 5.144210109710693 and perplexity is 171.43601553132112
At time: 1345.0599131584167 and batch: 1350, loss is 5.138665885925293 and perplexity is 170.48816586960643
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.168199462890625 and perplexity of 175.59838127215625
Finished 41 epochs...
Completing Train Step...
At time: 1348.4671335220337 and batch: 50, loss is 5.247570562362671 and perplexity is 190.1038615154805
At time: 1349.5715129375458 and batch: 100, loss is 5.254081220626831 and perplexity is 191.34560067586528
At time: 1350.6806752681732 and batch: 150, loss is 5.229255905151367 and perplexity is 186.65386365593636
At time: 1351.80020570755 and batch: 200, loss is 5.2212450981140135 and perplexity is 185.16458868289476
At time: 1352.9309060573578 and batch: 250, loss is 5.235476531982422 and perplexity is 187.81858658580862
At time: 1354.0684604644775 and batch: 300, loss is 5.2343106174469 and perplexity is 187.59973377229676
At time: 1355.205971479416 and batch: 350, loss is 5.243271932601929 and perplexity is 189.28842927503064
At time: 1356.34334731102 and batch: 400, loss is 5.266668157577515 and perplexity is 193.76927701932442
At time: 1357.4803385734558 and batch: 450, loss is 5.236788854598999 and perplexity is 188.06522696527603
At time: 1358.617238998413 and batch: 500, loss is 5.269268217086792 and perplexity is 194.27374420880477
At time: 1359.754070520401 and batch: 550, loss is 5.2509861755371094 and perplexity is 190.7542929481196
At time: 1360.891524553299 and batch: 600, loss is 5.200256004333496 and perplexity is 181.31865429525055
At time: 1362.0291180610657 and batch: 650, loss is 5.224862308502197 and perplexity is 185.83558078478623
At time: 1363.1659877300262 and batch: 700, loss is 5.2431972694396975 and perplexity is 189.2742969299165
At time: 1364.3030302524567 and batch: 750, loss is 5.228980073928833 and perplexity is 186.60238579246072
At time: 1365.4685781002045 and batch: 800, loss is 5.213172245025635 and perplexity is 183.67579963439684
At time: 1366.6057198047638 and batch: 850, loss is 5.180021028518677 and perplexity is 177.68654743895985
At time: 1367.7437648773193 and batch: 900, loss is 5.21058012008667 and perplexity is 183.2003055497592
At time: 1368.8815681934357 and batch: 950, loss is 5.181982393264771 and perplexity is 178.03539756830023
At time: 1370.0185010433197 and batch: 1000, loss is 5.204460582733154 and perplexity is 182.08262776022946
At time: 1371.1553449630737 and batch: 1050, loss is 5.170725860595703 and perplexity is 176.04257348645152
At time: 1372.2927474975586 and batch: 1100, loss is 5.160780143737793 and perplexity is 174.3003819286383
At time: 1373.4296638965607 and batch: 1150, loss is 5.165769891738892 and perplexity is 175.1722703537283
At time: 1374.5671906471252 and batch: 1200, loss is 5.151279373168945 and perplexity is 172.65223571680826
At time: 1375.7045867443085 and batch: 1250, loss is 5.172083559036255 and perplexity is 176.28174854100396
At time: 1376.8416893482208 and batch: 1300, loss is 5.144211730957031 and perplexity is 171.4362934715588
At time: 1377.9784140586853 and batch: 1350, loss is 5.138641700744629 and perplexity is 170.48404263237472
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1681917317708335 and perplexity of 175.59702370528322
Finished 42 epochs...
Completing Train Step...
At time: 1381.3576464653015 and batch: 50, loss is 5.247406883239746 and perplexity is 190.07274802854664
At time: 1382.5058252811432 and batch: 100, loss is 5.253881673812867 and perplexity is 191.3074220802196
At time: 1383.6243221759796 and batch: 150, loss is 5.229074487686157 and perplexity is 186.6200044565381
At time: 1384.7470815181732 and batch: 200, loss is 5.221090450286865 and perplexity is 185.13595559566951
At time: 1385.8818621635437 and batch: 250, loss is 5.235322217941285 and perplexity is 187.78960577684225
At time: 1387.0187485218048 and batch: 300, loss is 5.234184656143189 and perplexity is 187.57610495344463
At time: 1388.1556324958801 and batch: 350, loss is 5.243159914016724 and perplexity is 189.2672266405543
At time: 1389.2935590744019 and batch: 400, loss is 5.266579532623291 and perplexity is 193.7521049869652
At time: 1390.4335627555847 and batch: 450, loss is 5.236702327728271 and perplexity is 188.0489549736864
At time: 1391.57049036026 and batch: 500, loss is 5.26918291091919 and perplexity is 194.2571721670792
At time: 1392.7074835300446 and batch: 550, loss is 5.250927534103393 and perplexity is 190.74310717087187
At time: 1393.8728454113007 and batch: 600, loss is 5.200207214355469 and perplexity is 181.30980797789925
At time: 1395.0093727111816 and batch: 650, loss is 5.224767990112305 and perplexity is 185.8180538985888
At time: 1396.1476500034332 and batch: 700, loss is 5.243127479553222 and perplexity is 189.26108795915272
At time: 1397.2847390174866 and batch: 750, loss is 5.228939046859741 and perplexity is 186.59473020053053
At time: 1398.421549797058 and batch: 800, loss is 5.213152399063111 and perplexity is 183.67215444753197
At time: 1399.5585525035858 and batch: 850, loss is 5.17998498916626 and perplexity is 177.68014384624828
At time: 1400.69602060318 and batch: 900, loss is 5.210571355819702 and perplexity is 183.1986999404089
At time: 1401.83469247818 and batch: 950, loss is 5.181992778778076 and perplexity is 178.0372465668919
At time: 1402.9724411964417 and batch: 1000, loss is 5.204474678039551 and perplexity is 182.0851942887452
At time: 1404.1110537052155 and batch: 1050, loss is 5.17075135231018 and perplexity is 176.0470611706698
At time: 1405.2480792999268 and batch: 1100, loss is 5.160817308425903 and perplexity is 174.3068598683447
At time: 1406.3862447738647 and batch: 1150, loss is 5.165814466476441 and perplexity is 175.1800787857333
At time: 1407.5233738422394 and batch: 1200, loss is 5.151342525482177 and perplexity is 172.6631394491728
At time: 1408.6609001159668 and batch: 1250, loss is 5.1721275806427 and perplexity is 176.28950891757248
At time: 1409.7981116771698 and batch: 1300, loss is 5.1442108058929445 and perplexity is 171.4361348820739
At time: 1410.9354031085968 and batch: 1350, loss is 5.138613185882568 and perplexity is 170.47918137272487
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.168186442057292 and perplexity of 175.59609484978571
Finished 43 epochs...
Completing Train Step...
At time: 1414.3399295806885 and batch: 50, loss is 5.24724081993103 and perplexity is 190.04118653978747
At time: 1415.4880323410034 and batch: 100, loss is 5.253689613342285 and perplexity is 191.27068301488313
At time: 1416.607530593872 and batch: 150, loss is 5.228895416259766 and perplexity is 186.5865891381006
At time: 1417.7273235321045 and batch: 200, loss is 5.220934019088745 and perplexity is 185.10699682140762
At time: 1418.8482658863068 and batch: 250, loss is 5.235180330276489 and perplexity is 187.7629626384168
At time: 1419.9763753414154 and batch: 300, loss is 5.2340656089782716 and perplexity is 187.5537758790766
At time: 1421.110045671463 and batch: 350, loss is 5.243050622940063 and perplexity is 189.2465425518919
At time: 1422.247987985611 and batch: 400, loss is 5.266495771408081 and perplexity is 193.7358767548597
At time: 1423.413873910904 and batch: 450, loss is 5.236616134643555 and perplexity is 188.03274715269055
At time: 1424.5519931316376 and batch: 500, loss is 5.269098587036133 and perplexity is 194.24079233862557
At time: 1425.6900680065155 and batch: 550, loss is 5.250868415832519 and perplexity is 190.73183110150887
At time: 1426.8279011249542 and batch: 600, loss is 5.200158300399781 and perplexity is 181.30093961488106
At time: 1427.9655504226685 and batch: 650, loss is 5.224674005508422 and perplexity is 185.80059068304845
At time: 1429.1030185222626 and batch: 700, loss is 5.243054370880127 and perplexity is 189.24725183791992
At time: 1430.2406206130981 and batch: 750, loss is 5.228895120620727 and perplexity is 186.58653397582893
At time: 1431.3780839443207 and batch: 800, loss is 5.213128023147583 and perplexity is 183.66767732517752
At time: 1432.516014099121 and batch: 850, loss is 5.179945812225342 and perplexity is 177.67318301810337
At time: 1433.6534395217896 and batch: 900, loss is 5.210558099746704 and perplexity is 183.19627146116537
At time: 1434.7914276123047 and batch: 950, loss is 5.1819977378845214 and perplexity is 178.0381294747381
At time: 1435.9291582107544 and batch: 1000, loss is 5.204486589431763 and perplexity is 182.0873631898277
At time: 1437.0674657821655 and batch: 1050, loss is 5.170772390365601 and perplexity is 176.05076489745878
At time: 1438.2054512500763 and batch: 1100, loss is 5.160847644805909 and perplexity is 174.31214778769098
At time: 1439.3438303470612 and batch: 1150, loss is 5.165853643417359 and perplexity is 175.1869419397677
At time: 1440.4813158512115 and batch: 1200, loss is 5.151398344039917 and perplexity is 172.6727775255809
At time: 1441.618609905243 and batch: 1250, loss is 5.172167100906372 and perplexity is 176.29647606311835
At time: 1442.7566142082214 and batch: 1300, loss is 5.144207162857056 and perplexity is 171.4355103352195
At time: 1443.8943254947662 and batch: 1350, loss is 5.138586692810058 and perplexity is 170.474664915239
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.168179524739584 and perplexity of 175.5948802000104
Finished 44 epochs...
Completing Train Step...
At time: 1447.299643278122 and batch: 50, loss is 5.2470845603942875 and perplexity is 190.01149311201777
At time: 1448.4222328662872 and batch: 100, loss is 5.253504762649536 and perplexity is 191.23532976426236
At time: 1449.544018983841 and batch: 150, loss is 5.2287242984771725 and perplexity is 186.55466358629835
At time: 1450.6663179397583 and batch: 200, loss is 5.220786724090576 and perplexity is 185.07973349457484
At time: 1451.8250319957733 and batch: 250, loss is 5.235034685134888 and perplexity is 187.73561786650077
At time: 1452.9554617404938 and batch: 300, loss is 5.233948020935059 and perplexity is 187.53172309417113
At time: 1454.0859112739563 and batch: 350, loss is 5.242944793701172 and perplexity is 189.22651579405778
At time: 1455.2164289951324 and batch: 400, loss is 5.266413850784302 and perplexity is 193.72000644104932
At time: 1456.3547220230103 and batch: 450, loss is 5.236531782150268 and perplexity is 188.01688679058867
At time: 1457.4949173927307 and batch: 500, loss is 5.269017210006714 and perplexity is 194.22498624308832
At time: 1458.635403394699 and batch: 550, loss is 5.250811929702759 and perplexity is 190.72105770282454
At time: 1459.7759578227997 and batch: 600, loss is 5.2001117324829105 and perplexity is 181.29249700437552
At time: 1460.9161667823792 and batch: 650, loss is 5.224582347869873 and perplexity is 185.78356142010836
At time: 1462.0575151443481 and batch: 700, loss is 5.24298285484314 and perplexity is 189.2337181084028
At time: 1463.197734117508 and batch: 750, loss is 5.228851852416992 and perplexity is 186.57846088631788
At time: 1464.3376953601837 and batch: 800, loss is 5.213099365234375 and perplexity is 183.66241386824188
At time: 1465.4789612293243 and batch: 850, loss is 5.179905729293823 and perplexity is 177.66606149880238
At time: 1466.6192426681519 and batch: 900, loss is 5.21054328918457 and perplexity is 183.19355824149636
At time: 1467.7594366073608 and batch: 950, loss is 5.1819979763031006 and perplexity is 178.038171922341
At time: 1468.8990986347198 and batch: 1000, loss is 5.20449610710144 and perplexity is 182.08909624545026
At time: 1470.039231300354 and batch: 1050, loss is 5.17079005241394 and perplexity is 176.05387434203809
At time: 1471.1796748638153 and batch: 1100, loss is 5.1608743000030515 and perplexity is 174.31679417427955
At time: 1472.3200116157532 and batch: 1150, loss is 5.165889959335328 and perplexity is 175.1933041299041
At time: 1473.4605886936188 and batch: 1200, loss is 5.151451864242554 and perplexity is 172.68201925493133
At time: 1474.6006891727448 and batch: 1250, loss is 5.17220368385315 and perplexity is 176.30292562569053
At time: 1475.741108417511 and batch: 1300, loss is 5.144199657440185 and perplexity is 171.43422364507666
At time: 1476.8811905384064 and batch: 1350, loss is 5.138554611206055 and perplexity is 170.46919590227438
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.168175862630208 and perplexity of 175.59423715353077
Finished 45 epochs...
Completing Train Step...
At time: 1480.3072838783264 and batch: 50, loss is 5.246921119689941 and perplexity is 189.98044003748694
At time: 1481.4228591918945 and batch: 100, loss is 5.253324861526489 and perplexity is 191.2009294080957
At time: 1482.5396511554718 and batch: 150, loss is 5.228550758361816 and perplexity is 186.52229167745298
At time: 1483.6605398654938 and batch: 200, loss is 5.220635251998901 and perplexity is 185.05170120332428
At time: 1484.7814857959747 and batch: 250, loss is 5.234895219802857 and perplexity is 187.70943708191925
At time: 1485.9132068157196 and batch: 300, loss is 5.2338315296173095 and perplexity is 187.5098785490027
At time: 1487.0452296733856 and batch: 350, loss is 5.242838697433472 and perplexity is 189.20644063195084
At time: 1488.1832437515259 and batch: 400, loss is 5.2663328742980955 and perplexity is 193.70432031073233
At time: 1489.3232445716858 and batch: 450, loss is 5.236444387435913 and perplexity is 188.00045582647383
At time: 1490.4631142616272 and batch: 500, loss is 5.268932065963745 and perplexity is 194.20844984651183
At time: 1491.6028685569763 and batch: 550, loss is 5.250750389099121 and perplexity is 190.70932097495339
At time: 1492.7438731193542 and batch: 600, loss is 5.2000510692596436 and perplexity is 181.28149955072698
At time: 1493.884111881256 and batch: 650, loss is 5.224487438201904 and perplexity is 185.76592960070812
At time: 1495.0252678394318 and batch: 700, loss is 5.2429025363922115 and perplexity is 189.218519759663
At time: 1496.1654920578003 and batch: 750, loss is 5.228781604766846 and perplexity is 186.56535464821943
At time: 1497.3059101104736 and batch: 800, loss is 5.213049707412719 and perplexity is 183.65329381929192
At time: 1498.445814371109 and batch: 850, loss is 5.179853820800782 and perplexity is 177.65683936064104
At time: 1499.5864236354828 and batch: 900, loss is 5.210463342666626 and perplexity is 183.17891313982534
At time: 1500.7268657684326 and batch: 950, loss is 5.1819595527648925 and perplexity is 178.03133119726292
At time: 1501.8680484294891 and batch: 1000, loss is 5.204500904083252 and perplexity is 182.08996972562812
At time: 1503.0086178779602 and batch: 1050, loss is 5.170770635604859 and perplexity is 176.05045597075897
At time: 1504.1495759487152 and batch: 1100, loss is 5.16091534614563 and perplexity is 174.32394935311225
At time: 1505.2899379730225 and batch: 1150, loss is 5.165904407501221 and perplexity is 175.19583537011135
At time: 1506.4304118156433 and batch: 1200, loss is 5.15152645111084 and perplexity is 172.6948995463012
At time: 1507.5709533691406 and batch: 1250, loss is 5.172218103408813 and perplexity is 176.30546785386906
At time: 1508.7119731903076 and batch: 1300, loss is 5.144146356582642 and perplexity is 171.42508629746044
At time: 1509.8528008460999 and batch: 1350, loss is 5.138497514724731 and perplexity is 170.45946298887452
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.168168131510416 and perplexity of 175.59287961869626
Finished 46 epochs...
Completing Train Step...
At time: 1513.2305328845978 and batch: 50, loss is 5.24660291671753 and perplexity is 189.91999731380415
At time: 1514.3752541542053 and batch: 100, loss is 5.253202791213989 and perplexity is 191.17759087539255
At time: 1515.4916622638702 and batch: 150, loss is 5.2283406162261965 and perplexity is 186.48309960283655
At time: 1516.6109521389008 and batch: 200, loss is 5.220438394546509 and perplexity is 185.01527598227025
At time: 1517.732706785202 and batch: 250, loss is 5.234672040939331 and perplexity is 187.66754897752185
At time: 1518.8652765750885 and batch: 300, loss is 5.233691263198852 and perplexity is 187.4835790544244
At time: 1520.0050168037415 and batch: 350, loss is 5.2427133941650395 and perplexity is 189.18273393182574
At time: 1521.1449155807495 and batch: 400, loss is 5.266215419769287 and perplexity is 193.6815701971401
At time: 1522.285176038742 and batch: 450, loss is 5.236329784393311 and perplexity is 187.97891163676388
At time: 1523.4252161979675 and batch: 500, loss is 5.268817644119263 and perplexity is 194.18622942874123
At time: 1524.5641825199127 and batch: 550, loss is 5.250677528381348 and perplexity is 190.69542626313665
At time: 1525.7039184570312 and batch: 600, loss is 5.199914112091064 and perplexity is 181.25667344992772
At time: 1526.843026638031 and batch: 650, loss is 5.224387893676758 and perplexity is 185.74743853981485
At time: 1527.9823565483093 and batch: 700, loss is 5.242818117141724 and perplexity is 189.20254674827078
At time: 1529.1220190525055 and batch: 750, loss is 5.228667974472046 and perplexity is 186.54415637637698
At time: 1530.2620396614075 and batch: 800, loss is 5.213000946044922 and perplexity is 183.64433885181475
At time: 1531.400948524475 and batch: 850, loss is 5.179814195632934 and perplexity is 177.64979981803458
At time: 1532.5403671264648 and batch: 900, loss is 5.210417261123657 and perplexity is 183.17047216735665
At time: 1533.6800792217255 and batch: 950, loss is 5.181951417922973 and perplexity is 178.02988294641762
At time: 1534.8198728561401 and batch: 1000, loss is 5.2045081520080565 and perplexity is 182.09128950481914
At time: 1535.9605634212494 and batch: 1050, loss is 5.170775690078735 and perplexity is 176.0513458154385
At time: 1537.1007611751556 and batch: 1100, loss is 5.1609336853027346 and perplexity is 174.32714633672148
At time: 1538.2854225635529 and batch: 1150, loss is 5.165933446884155 and perplexity is 175.20092302293403
At time: 1539.42498421669 and batch: 1200, loss is 5.151571388244629 and perplexity is 172.70266013447483
At time: 1540.564264535904 and batch: 1250, loss is 5.172252931594849 and perplexity is 176.3116083604333
At time: 1541.7036304473877 and batch: 1300, loss is 5.144145603179932 and perplexity is 171.42495714538452
At time: 1542.8426990509033 and batch: 1350, loss is 5.138480243682861 and perplexity is 170.45651900177498
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.168165690104167 and perplexity of 175.5924509256659
Finished 47 epochs...
Completing Train Step...
At time: 1546.2284350395203 and batch: 50, loss is 5.246462736129761 and perplexity is 189.89337608288517
At time: 1547.3757309913635 and batch: 100, loss is 5.2530439090728756 and perplexity is 191.14721858329258
At time: 1548.4947471618652 and batch: 150, loss is 5.228176774978638 and perplexity is 186.45254848198428
At time: 1549.6149315834045 and batch: 200, loss is 5.22029218673706 and perplexity is 184.98822728146817
At time: 1550.7343480587006 and batch: 250, loss is 5.234537038803101 and perplexity is 187.64221516760654
At time: 1551.8655259609222 and batch: 300, loss is 5.233577003479004 and perplexity is 187.46215845698453
At time: 1553.0028157234192 and batch: 350, loss is 5.2426075267791745 and perplexity is 189.1627067104671
At time: 1554.1405255794525 and batch: 400, loss is 5.266135835647583 and perplexity is 193.6661568328235
At time: 1555.278285741806 and batch: 450, loss is 5.236243848800659 and perplexity is 187.9627582516717
At time: 1556.4163267612457 and batch: 500, loss is 5.268733253479004 and perplexity is 194.16984261996663
At time: 1557.554036140442 and batch: 550, loss is 5.250618286132813 and perplexity is 190.68412937192934
At time: 1558.6918139457703 and batch: 600, loss is 5.19986590385437 and perplexity is 181.2479355959316
At time: 1559.829337835312 and batch: 650, loss is 5.2242904472351075 and perplexity is 185.72933899476598
At time: 1560.966655254364 and batch: 700, loss is 5.242741842269897 and perplexity is 189.18811589863088
At time: 1562.1043210029602 and batch: 750, loss is 5.228621120452881 and perplexity is 186.53541623765594
At time: 1563.2416067123413 and batch: 800, loss is 5.212970628738403 and perplexity is 183.63877133449986
At time: 1564.379384279251 and batch: 850, loss is 5.1797703266143795 and perplexity is 177.64200666661034
At time: 1565.5173184871674 and batch: 900, loss is 5.21039454460144 and perplexity is 183.16631121851748
At time: 1566.682846069336 and batch: 950, loss is 5.181940765380859 and perplexity is 178.02798648569305
At time: 1567.8199846744537 and batch: 1000, loss is 5.204510116577149 and perplexity is 182.09164723608987
At time: 1568.9580237865448 and batch: 1050, loss is 5.170779590606689 and perplexity is 176.05203250997343
At time: 1570.095522403717 and batch: 1100, loss is 5.160949153900146 and perplexity is 174.32984295402252
At time: 1571.2333731651306 and batch: 1150, loss is 5.165958070755005 and perplexity is 175.205237200951
At time: 1572.3713250160217 and batch: 1200, loss is 5.151611976623535 and perplexity is 172.70966999774095
At time: 1573.5106887817383 and batch: 1250, loss is 5.172283143997192 and perplexity is 176.3169352381514
At time: 1574.64790225029 and batch: 1300, loss is 5.144141054153442 and perplexity is 171.42417733048717
At time: 1575.7850799560547 and batch: 1350, loss is 5.1384617042541505 and perplexity is 170.45335886458636
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.168160400390625 and perplexity of 175.591522094357
Finished 48 epochs...
Completing Train Step...
At time: 1579.1912467479706 and batch: 50, loss is 5.246330394744873 and perplexity is 189.86824699335918
At time: 1580.3098900318146 and batch: 100, loss is 5.252889671325684 and perplexity is 191.117738740427
At time: 1581.4296522140503 and batch: 150, loss is 5.228020143508911 and perplexity is 186.42334643232093
At time: 1582.5489864349365 and batch: 200, loss is 5.220154514312744 and perplexity is 184.96276125677332
At time: 1583.668179988861 and batch: 250, loss is 5.234399347305298 and perplexity is 187.61638020861702
At time: 1584.8084180355072 and batch: 300, loss is 5.233462247848511 and perplexity is 187.44064735308092
At time: 1585.9463233947754 and batch: 350, loss is 5.242504720687866 and perplexity is 189.14326063157367
At time: 1587.08336520195 and batch: 400, loss is 5.266057605743408 and perplexity is 193.65100694052754
At time: 1588.2206807136536 and batch: 450, loss is 5.236161508560181 and perplexity is 187.94728199012454
At time: 1589.3577861785889 and batch: 500, loss is 5.268650236129761 and perplexity is 194.15372382340854
At time: 1590.4957571029663 and batch: 550, loss is 5.250561895370484 and perplexity is 190.67337685168428
At time: 1591.6330959796906 and batch: 600, loss is 5.199819078445435 and perplexity is 181.2394487859294
At time: 1592.7708258628845 and batch: 650, loss is 5.224195022583007 and perplexity is 185.7116166827938
At time: 1593.9081366062164 and batch: 700, loss is 5.242668371200562 and perplexity is 189.17421655605636
At time: 1595.0889868736267 and batch: 750, loss is 5.228575248718261 and perplexity is 186.52685973079753
At time: 1596.226080417633 and batch: 800, loss is 5.21294303894043 and perplexity is 183.63370484779065
At time: 1597.3635370731354 and batch: 850, loss is 5.17972885131836 and perplexity is 177.63463906458608
At time: 1598.5010800361633 and batch: 900, loss is 5.210369863510132 and perplexity is 183.16179052985365
At time: 1599.6385562419891 and batch: 950, loss is 5.18192946434021 and perplexity is 178.02597459554934
At time: 1600.776108264923 and batch: 1000, loss is 5.204508962631226 and perplexity is 182.0914371122972
At time: 1601.9131910800934 and batch: 1050, loss is 5.170782413482666 and perplexity is 176.05252948372805
At time: 1603.0504095554352 and batch: 1100, loss is 5.160964059829712 and perplexity is 174.3324415217497
At time: 1604.1874251365662 and batch: 1150, loss is 5.165981092453003 and perplexity is 175.2092707694391
At time: 1605.3255710601807 and batch: 1200, loss is 5.151652030944824 and perplexity is 172.71658790489786
At time: 1606.4635224342346 and batch: 1250, loss is 5.172311086654663 and perplexity is 176.32186207071308
At time: 1607.6011898517609 and batch: 1300, loss is 5.144134254455566 and perplexity is 171.42301170183566
At time: 1608.7377111911774 and batch: 1350, loss is 5.138437700271607 and perplexity is 170.4492673542421
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.168158365885417 and perplexity of 175.59116485285426
Finished 49 epochs...
Completing Train Step...
At time: 1612.1430792808533 and batch: 50, loss is 5.246194343566895 and perplexity is 189.8424169518388
At time: 1613.2618539333344 and batch: 100, loss is 5.252738637924194 and perplexity is 191.08887575795217
At time: 1614.3815953731537 and batch: 150, loss is 5.227862339019776 and perplexity is 186.39393031243318
At time: 1615.5030682086945 and batch: 200, loss is 5.22001467704773 and perplexity is 184.9368983784489
At time: 1616.631189584732 and batch: 250, loss is 5.2342715835571285 and perplexity is 187.5924111678834
At time: 1617.7590773105621 and batch: 300, loss is 5.233351306915283 and perplexity is 187.41985366619562
At time: 1618.89346575737 and batch: 350, loss is 5.242403469085693 and perplexity is 189.12411054289947
At time: 1620.0310289859772 and batch: 400, loss is 5.265982303619385 and perplexity is 193.63642515741216
At time: 1621.1689524650574 and batch: 450, loss is 5.23607892036438 and perplexity is 187.9317604041581
At time: 1622.3065285682678 and batch: 500, loss is 5.268567237854004 and perplexity is 194.1376100678156
At time: 1623.443449497223 and batch: 550, loss is 5.25050539970398 and perplexity is 190.66260493646058
At time: 1624.6091408729553 and batch: 600, loss is 5.199770698547363 and perplexity is 181.230680651973
At time: 1625.7470490932465 and batch: 650, loss is 5.224098949432373 and perplexity is 185.69377563970605
At time: 1626.88529586792 and batch: 700, loss is 5.242593879699707 and perplexity is 189.16012520959134
At time: 1628.0227372646332 and batch: 750, loss is 5.228527202606201 and perplexity is 186.51789805568117
At time: 1629.1604535579681 and batch: 800, loss is 5.212913608551025 and perplexity is 183.62830051587537
At time: 1630.2973544597626 and batch: 850, loss is 5.179686641693115 and perplexity is 177.62714133128003
At time: 1631.4343798160553 and batch: 900, loss is 5.210341091156006 and perplexity is 183.15652060976856
At time: 1632.571655511856 and batch: 950, loss is 5.181917514801025 and perplexity is 178.02384727990025
At time: 1633.7090208530426 and batch: 1000, loss is 5.204505519866943 and perplexity is 182.09081021548047
At time: 1634.8463871479034 and batch: 1050, loss is 5.170782318115235 and perplexity is 176.05251269405136
At time: 1635.9847087860107 and batch: 1100, loss is 5.1609753894805905 and perplexity is 174.3344166586378
At time: 1637.121384859085 and batch: 1150, loss is 5.166000318527222 and perplexity is 175.21263938826527
At time: 1638.2583374977112 and batch: 1200, loss is 5.151687135696411 and perplexity is 172.72265118423564
At time: 1639.3952958583832 and batch: 1250, loss is 5.172336282730103 and perplexity is 176.32630474562035
At time: 1640.5331242084503 and batch: 1300, loss is 5.144126319885254 and perplexity is 171.42165153929238
At time: 1641.6702995300293 and batch: 1350, loss is 5.138415222167969 and perplexity is 170.4454360210062
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.168153483072917 and perplexity of 175.5903074762128
Finished Training.
Improved accuracyfrom -10000000 to -175.5903074762128
<pretraining.langmodel.trainer.TrainLangModel object at 0x7feac6e81860>
SETTINGS FOR THIS RUN
{'lr': 11.536897931568085, 'data': 'wikitext', 'dropout': 0.4563768022406083, 'anneal': 7.971243729914938, 'wordvec_source': '', 'num_layers': 1, 'wordvec_dim': 200, 'batch_size': 80, 'seq_len': 20, 'tune_wordvecs': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.5656185150146484 and batch: 50, loss is 7.034980335235596 and perplexity is 1135.672579238395
At time: 2.616243362426758 and batch: 100, loss is 6.335994615554809 and perplexity is 564.5306147744369
At time: 3.669668197631836 and batch: 150, loss is 6.101332817077637 and perplexity is 446.4524131198506
At time: 4.724376440048218 and batch: 200, loss is 6.0164992713928225 and perplexity is 410.140289790753
At time: 5.78145694732666 and batch: 250, loss is 6.01163311958313 and perplexity is 408.14933295519
At time: 6.8628740310668945 and batch: 300, loss is 5.988352727890015 and perplexity is 398.7572069892741
At time: 7.920201063156128 and batch: 350, loss is 5.9747519779205325 and perplexity is 393.3705244155443
At time: 8.979376077651978 and batch: 400, loss is 5.996546392440796 and perplexity is 402.037911923945
At time: 10.037949562072754 and batch: 450, loss is 5.951425771713257 and perplexity is 384.30087395394077
At time: 11.09541940689087 and batch: 500, loss is 5.953472776412964 and perplexity is 385.08834535287934
At time: 12.154918670654297 and batch: 550, loss is 5.911085081100464 and perplexity is 369.1064486262431
At time: 13.214473962783813 and batch: 600, loss is 5.849614725112915 and perplexity is 347.1006255598639
At time: 14.276532173156738 and batch: 650, loss is 5.874307231903076 and perplexity is 355.7781035574602
At time: 15.339066743850708 and batch: 700, loss is 5.87231297492981 and perplexity is 355.06929759903153
At time: 16.398436307907104 and batch: 750, loss is 5.847302379608155 and perplexity is 346.2989362372171
At time: 17.460788011550903 and batch: 800, loss is 5.805045957565308 and perplexity is 331.9704495465904
At time: 18.535665273666382 and batch: 850, loss is 5.806091442108154 and perplexity is 332.31770101166273
At time: 19.61709761619568 and batch: 900, loss is 5.830256175994873 and perplexity is 340.4458819641406
At time: 20.680343866348267 and batch: 950, loss is 5.798824634552002 and perplexity is 329.911565281849
At time: 21.74433660507202 and batch: 1000, loss is 5.816347427368164 and perplexity is 335.7434838154208
At time: 22.807703256607056 and batch: 1050, loss is 5.780727167129516 and perplexity is 323.99470307654747
At time: 23.869477033615112 and batch: 1100, loss is 5.772040224075317 and perplexity is 321.1923690219193
At time: 24.93285036087036 and batch: 1150, loss is 5.77308876991272 and perplexity is 321.5293305724057
At time: 25.996120929718018 and batch: 1200, loss is 5.762966346740723 and perplexity is 318.29109168834816
At time: 27.060099601745605 and batch: 1250, loss is 5.770544013977051 and perplexity is 320.71215709445556
At time: 28.12399387359619 and batch: 1300, loss is 5.740059318542481 and perplexity is 311.0828634161503
At time: 29.189706325531006 and batch: 1350, loss is 5.713577251434327 and perplexity is 302.9528707809282
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.21944580078125 and perplexity of 184.8317220851499
Finished 1 epochs...
Completing Train Step...
At time: 32.437613010406494 and batch: 50, loss is 5.515760726928711 and perplexity is 248.57900608253536
At time: 33.49993419647217 and batch: 100, loss is 5.496426677703857 and perplexity is 243.81912945854515
At time: 34.560413122177124 and batch: 150, loss is 5.408954963684082 and perplexity is 223.398006621636
At time: 35.62308716773987 and batch: 200, loss is 5.386455821990967 and perplexity is 218.4278648388894
At time: 36.68312931060791 and batch: 250, loss is 5.413541059494019 and perplexity is 224.42488416335044
At time: 37.745757818222046 and batch: 300, loss is 5.394518756866455 and perplexity is 220.19615370724077
At time: 38.83735418319702 and batch: 350, loss is 5.3909156799316404 and perplexity is 219.4041976208125
At time: 39.89772987365723 and batch: 400, loss is 5.404619407653809 and perplexity is 222.43154862714863
At time: 40.96460843086243 and batch: 450, loss is 5.368927392959595 and perplexity is 214.63252783388103
At time: 42.06169295310974 and batch: 500, loss is 5.411477851867676 and perplexity is 223.96232637127116
At time: 43.19530200958252 and batch: 550, loss is 5.385258264541626 and perplexity is 218.16644148819182
At time: 44.33713126182556 and batch: 600, loss is 5.3330887508392335 and perplexity is 207.0765953854378
At time: 45.47766399383545 and batch: 650, loss is 5.358370838165283 and perplexity is 212.37866523615807
At time: 46.618499517440796 and batch: 700, loss is 5.367558555603027 and perplexity is 214.33893180029972
At time: 47.75881862640381 and batch: 750, loss is 5.3352323913574216 and perplexity is 207.52096928445667
At time: 48.89944529533386 and batch: 800, loss is 5.284959936141968 and perplexity is 197.34627683655532
At time: 50.040160179138184 and batch: 850, loss is 5.286710739135742 and perplexity is 197.69209392931515
At time: 51.18074107170105 and batch: 900, loss is 5.332607669830322 and perplexity is 206.9769987269592
At time: 52.321412086486816 and batch: 950, loss is 5.292068166732788 and perplexity is 198.75405716458113
At time: 53.46160864830017 and batch: 1000, loss is 5.316337432861328 and perplexity is 203.63668147440924
At time: 54.602404832839966 and batch: 1050, loss is 5.269563608169555 and perplexity is 194.33113941705804
At time: 55.74264717102051 and batch: 1100, loss is 5.263019685745239 and perplexity is 193.06360336816724
At time: 56.88363337516785 and batch: 1150, loss is 5.26703106880188 and perplexity is 193.83961082658396
At time: 58.024545192718506 and batch: 1200, loss is 5.255562829971313 and perplexity is 191.6293102273144
At time: 59.16554307937622 and batch: 1250, loss is 5.287243967056274 and perplexity is 197.7975369835586
At time: 60.30599927902222 and batch: 1300, loss is 5.2660329723358155 and perplexity is 193.6462367150965
At time: 61.446802377700806 and batch: 1350, loss is 5.236114139556885 and perplexity is 187.93837932556136
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0654219563802085 and perplexity of 158.44728581329426
Finished 2 epochs...
Completing Train Step...
At time: 64.81816935539246 and batch: 50, loss is 5.248665885925293 and perplexity is 190.31220083299633
At time: 65.95448088645935 and batch: 100, loss is 5.272818279266358 and perplexity is 194.96465374087842
At time: 67.06867218017578 and batch: 150, loss is 5.209961671829223 and perplexity is 183.08704066787283
At time: 68.19574451446533 and batch: 200, loss is 5.203090915679931 and perplexity is 181.83340589846998
At time: 69.33688282966614 and batch: 250, loss is 5.237103462219238 and perplexity is 188.12440302691314
At time: 70.47779607772827 and batch: 300, loss is 5.230842380523682 and perplexity is 186.95022043297948
At time: 71.61888027191162 and batch: 350, loss is 5.2172706413269045 and perplexity is 184.4301205494242
At time: 72.75959539413452 and batch: 400, loss is 5.24404055595398 and perplexity is 189.4339767104577
At time: 73.9015166759491 and batch: 450, loss is 5.207015752792358 and perplexity is 182.54847474466158
At time: 75.04245853424072 and batch: 500, loss is 5.264644536972046 and perplexity is 193.37755799665968
At time: 76.18382477760315 and batch: 550, loss is 5.237284011840821 and perplexity is 188.15837188312983
At time: 77.32525372505188 and batch: 600, loss is 5.196942138671875 and perplexity is 180.7187831281685
At time: 78.46776127815247 and batch: 650, loss is 5.219061117172242 and perplexity is 184.76063402532134
At time: 79.60952091217041 and batch: 700, loss is 5.227459354400635 and perplexity is 186.31883155825375
At time: 80.75073838233948 and batch: 750, loss is 5.187804460525513 and perplexity is 179.07495487758217
At time: 81.89218401908875 and batch: 800, loss is 5.153026304244995 and perplexity is 172.95411087350652
At time: 83.03358626365662 and batch: 850, loss is 5.148687791824341 and perplexity is 172.20537269466152
At time: 84.17501163482666 and batch: 900, loss is 5.197644186019898 and perplexity is 180.84570081650196
At time: 85.31660079956055 and batch: 950, loss is 5.148839406967163 and perplexity is 172.23148361619283
At time: 86.45902514457703 and batch: 1000, loss is 5.160370225906372 and perplexity is 174.22894773613717
At time: 87.60019564628601 and batch: 1050, loss is 5.124737777709961 and perplexity is 168.1300484246623
At time: 88.74115777015686 and batch: 1100, loss is 5.132404289245605 and perplexity is 169.42397298661717
At time: 89.88254070281982 and batch: 1150, loss is 5.124640369415284 and perplexity is 168.1136719609759
At time: 91.02388978004456 and batch: 1200, loss is 5.118242893218994 and perplexity is 167.04160167484812
At time: 92.16558623313904 and batch: 1250, loss is 5.144436731338501 and perplexity is 171.47487104280899
At time: 93.30721378326416 and batch: 1300, loss is 5.128567276000976 and perplexity is 168.7751365513579
At time: 94.44820928573608 and batch: 1350, loss is 5.108202114105224 and perplexity is 165.37276607503188
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0310982259114585 and perplexity of 153.10105995291048
Finished 3 epochs...
Completing Train Step...
At time: 97.85735249519348 and batch: 50, loss is 5.13338755607605 and perplexity is 169.59064388709277
At time: 98.97449922561646 and batch: 100, loss is 5.173240995407104 and perplexity is 176.48590157256285
At time: 100.09840416908264 and batch: 150, loss is 5.125699129104614 and perplexity is 168.29175819870255
At time: 101.22999334335327 and batch: 200, loss is 5.116786460876465 and perplexity is 166.79849396156246
At time: 102.3617160320282 and batch: 250, loss is 5.141841030120849 and perplexity is 171.03035068185338
At time: 103.49337410926819 and batch: 300, loss is 5.137880744934082 and perplexity is 170.35436115672204
At time: 104.62677717208862 and batch: 350, loss is 5.142164144515991 and perplexity is 171.08562197915992
At time: 105.76848793029785 and batch: 400, loss is 5.139926967620849 and perplexity is 170.7033009978685
At time: 106.91004872322083 and batch: 450, loss is 5.10614595413208 and perplexity is 165.0330825542856
At time: 108.05079531669617 and batch: 500, loss is 5.168305187225342 and perplexity is 175.61694727561556
At time: 109.19167423248291 and batch: 550, loss is 5.1387883567810055 and perplexity is 170.509046979807
At time: 110.33264589309692 and batch: 600, loss is 5.0899704074859615 and perplexity is 162.38505660031973
At time: 111.47345685958862 and batch: 650, loss is 5.123547639846802 and perplexity is 167.9300695129393
At time: 112.61500430107117 and batch: 700, loss is 5.134558963775635 and perplexity is 169.78942007436777
At time: 113.75648260116577 and batch: 750, loss is 5.100341930389404 and perplexity is 164.07800096405327
At time: 114.8966121673584 and batch: 800, loss is 5.061973466873169 and perplexity is 157.90182306259143
At time: 116.03743433952332 and batch: 850, loss is 5.068940019607544 and perplexity is 159.00569506657322
At time: 117.17799019813538 and batch: 900, loss is 5.112824878692627 and perplexity is 166.13901517180076
At time: 118.31929922103882 and batch: 950, loss is 5.082411823272705 and perplexity is 161.16228251711433
At time: 119.46014451980591 and batch: 1000, loss is 5.099665088653564 and perplexity is 163.96698369986478
At time: 120.60225796699524 and batch: 1050, loss is 5.049187726974488 and perplexity is 155.89578310401885
At time: 121.74327993392944 and batch: 1100, loss is 5.060454988479615 and perplexity is 157.66223450702705
At time: 122.88455128669739 and batch: 1150, loss is 5.046975364685059 and perplexity is 155.5512663908118
At time: 124.06960821151733 and batch: 1200, loss is 5.046443834304809 and perplexity is 155.46860813667152
At time: 125.21059083938599 and batch: 1250, loss is 5.081168003082276 and perplexity is 160.9619502306829
At time: 126.35261058807373 and batch: 1300, loss is 5.061072235107422 and perplexity is 157.75958102992485
At time: 127.49447345733643 and batch: 1350, loss is 5.030847864151001 and perplexity is 153.06273409987696
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0391259765625 and perplexity of 154.33506359631434
Annealing...
Finished 4 epochs...
Completing Train Step...
At time: 130.90658593177795 and batch: 50, loss is 5.062466440200805 and perplexity is 157.97968363976355
At time: 132.0270276069641 and batch: 100, loss is 5.071917533874512 and perplexity is 159.47984233198721
At time: 133.1544463634491 and batch: 150, loss is 5.029418153762817 and perplexity is 152.8440550799734
At time: 134.29198813438416 and batch: 200, loss is 5.005491647720337 and perplexity is 149.2304339281867
At time: 135.43076848983765 and batch: 250, loss is 5.012868280410767 and perplexity is 150.33532219277762
At time: 136.56927108764648 and batch: 300, loss is 5.001899318695068 and perplexity is 148.69531085348217
At time: 137.70832872390747 and batch: 350, loss is 4.982846384048462 and perplexity is 145.8890474821434
At time: 138.84748721122742 and batch: 400, loss is 4.990646915435791 and perplexity is 147.03150968918112
At time: 139.9861354827881 and batch: 450, loss is 4.940464696884155 and perplexity is 139.83521545302602
At time: 141.12563753128052 and batch: 500, loss is 4.9890758228302 and perplexity is 146.80069093781444
At time: 142.26433968544006 and batch: 550, loss is 4.957180719375611 and perplexity is 142.1923501310957
At time: 143.40330934524536 and batch: 600, loss is 4.902578115463257 and perplexity is 134.63644091682764
At time: 144.54154920578003 and batch: 650, loss is 4.917990131378174 and perplexity is 136.7275324637745
At time: 145.68101716041565 and batch: 700, loss is 4.899830751419067 and perplexity is 134.2670532535524
At time: 146.8200182914734 and batch: 750, loss is 4.854636392593384 and perplexity is 128.33401953012722
At time: 147.9594931602478 and batch: 800, loss is 4.820226678848266 and perplexity is 123.99319422893552
At time: 149.09885168075562 and batch: 850, loss is 4.7915913772583005 and perplexity is 120.49296593678578
At time: 150.2377507686615 and batch: 900, loss is 4.815910911560058 and perplexity is 123.45922153706758
At time: 151.37609815597534 and batch: 950, loss is 4.778193941116333 and perplexity is 118.88943470862657
At time: 152.5431249141693 and batch: 1000, loss is 4.780864276885986 and perplexity is 119.20733367835454
At time: 153.68252682685852 and batch: 1050, loss is 4.7189433383941655 and perplexity is 112.04979137959127
At time: 154.8220989704132 and batch: 1100, loss is 4.686471605300904 and perplexity is 108.46977961616878
At time: 155.96118211746216 and batch: 1150, loss is 4.678854598999023 and perplexity is 107.64670328953912
At time: 157.10015225410461 and batch: 1200, loss is 4.654606475830078 and perplexity is 105.06786511795468
At time: 158.23886227607727 and batch: 1250, loss is 4.669293737411499 and perplexity is 106.62241241321169
At time: 159.37781405448914 and batch: 1300, loss is 4.622997665405274 and perplexity is 101.79873374708036
At time: 160.51669692993164 and batch: 1350, loss is 4.604618806838989 and perplexity is 99.94487728324461
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.859499918619791 and perplexity of 128.95969563689476
Finished 5 epochs...
Completing Train Step...
At time: 163.91420578956604 and batch: 50, loss is 4.896958475112915 and perplexity is 133.88195449756594
At time: 165.0634925365448 and batch: 100, loss is 4.917421178817749 and perplexity is 136.64976310973313
At time: 166.2020616531372 and batch: 150, loss is 4.883757238388061 and perplexity is 132.12616193847495
At time: 167.34112572669983 and batch: 200, loss is 4.866999216079712 and perplexity is 129.93043814874454
At time: 168.47990560531616 and batch: 250, loss is 4.881504001617432 and perplexity is 131.82878556753676
At time: 169.61948943138123 and batch: 300, loss is 4.878268985748291 and perplexity is 131.40300642668137
At time: 170.75815153121948 and batch: 350, loss is 4.863015651702881 and perplexity is 129.4138814354238
At time: 171.8974232673645 and batch: 400, loss is 4.872697916030884 and perplexity is 130.6729865008759
At time: 173.03631567955017 and batch: 450, loss is 4.8260994815826415 and perplexity is 124.7235242420185
At time: 174.17522716522217 and batch: 500, loss is 4.883701944351197 and perplexity is 132.11885635158546
At time: 175.313862323761 and batch: 550, loss is 4.8546654415130615 and perplexity is 128.33774754889967
At time: 176.4532597064972 and batch: 600, loss is 4.803033542633057 and perplexity is 121.87958420898428
At time: 177.59209966659546 and batch: 650, loss is 4.819533662796021 and perplexity is 123.9072947232717
At time: 178.73106288909912 and batch: 700, loss is 4.810644111633301 and perplexity is 122.81069584478323
At time: 179.86946606636047 and batch: 750, loss is 4.769418315887451 and perplexity is 117.85067015655633
At time: 181.03620028495789 and batch: 800, loss is 4.7420268249511714 and perplexity is 114.66637498323222
At time: 182.17521023750305 and batch: 850, loss is 4.713825511932373 and perplexity is 111.4778049044519
At time: 183.31452107429504 and batch: 900, loss is 4.7441670608520505 and perplexity is 114.91205088400763
At time: 184.45396399497986 and batch: 950, loss is 4.714425373077392 and perplexity is 111.54469616887557
At time: 185.5924527645111 and batch: 1000, loss is 4.7222349643707275 and perplexity is 112.41922506876698
At time: 186.73160481452942 and batch: 1050, loss is 4.666345281600952 and perplexity is 106.3085039418364
At time: 187.87038707733154 and batch: 1100, loss is 4.641782569885254 and perplexity is 103.72908722581458
At time: 189.00925469398499 and batch: 1150, loss is 4.639892406463623 and perplexity is 103.53320748006504
At time: 190.14778780937195 and batch: 1200, loss is 4.623572425842285 and perplexity is 101.85726044958142
At time: 191.28664588928223 and batch: 1250, loss is 4.648930625915527 and perplexity is 104.47320488225454
At time: 192.42553091049194 and batch: 1300, loss is 4.612102041244507 and perplexity is 100.695593617472
At time: 193.5646984577179 and batch: 1350, loss is 4.600747737884522 and perplexity is 99.55873165202273
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.840098470052084 and perplexity of 126.48180578693238
Finished 6 epochs...
Completing Train Step...
At time: 196.9575047492981 and batch: 50, loss is 4.8357373046875 and perplexity is 125.93139879661966
At time: 198.12034797668457 and batch: 100, loss is 4.854109315872193 and perplexity is 128.26639547899313
At time: 199.25833249092102 and batch: 150, loss is 4.81994366645813 and perplexity is 123.95810758388797
At time: 200.39709639549255 and batch: 200, loss is 4.802800302505493 and perplexity is 121.85116031414125
At time: 201.53583312034607 and batch: 250, loss is 4.817394495010376 and perplexity is 123.64251953024345
At time: 202.6748161315918 and batch: 300, loss is 4.8144167137146 and perplexity is 123.27488678483564
At time: 203.8139259815216 and batch: 350, loss is 4.802791233062744 and perplexity is 121.85005519703031
At time: 204.95316314697266 and batch: 400, loss is 4.814065170288086 and perplexity is 123.23155792516633
At time: 206.09334349632263 and batch: 450, loss is 4.766612968444824 and perplexity is 117.52052138794444
At time: 207.23208260536194 and batch: 500, loss is 4.828951272964478 and perplexity is 125.07971736640395
At time: 208.37065887451172 and batch: 550, loss is 4.803574848175049 and perplexity is 121.94557616266603
At time: 209.50993180274963 and batch: 600, loss is 4.751784629821778 and perplexity is 115.79074386022899
At time: 210.67707657814026 and batch: 650, loss is 4.765948162078858 and perplexity is 117.44241896156574
At time: 211.81624388694763 and batch: 700, loss is 4.764100713729858 and perplexity is 117.22565045451668
At time: 212.95504999160767 and batch: 750, loss is 4.72522442817688 and perplexity is 112.75580111351563
At time: 214.09367442131042 and batch: 800, loss is 4.698837490081787 and perplexity is 109.81943203780372
At time: 215.23255276679993 and batch: 850, loss is 4.672715721130371 and perplexity is 106.98789755801238
At time: 216.37129545211792 and batch: 900, loss is 4.705413427352905 and perplexity is 110.54397740552349
At time: 217.5105230808258 and batch: 950, loss is 4.681743726730347 and perplexity is 107.95815806486848
At time: 218.65033268928528 and batch: 1000, loss is 4.6888346672058105 and perplexity is 108.72640350986998
At time: 219.7892074584961 and batch: 1050, loss is 4.634613695144654 and perplexity is 102.98812549678405
At time: 220.92788815498352 and batch: 1100, loss is 4.6128715133666995 and perplexity is 100.77310588752927
At time: 222.06785035133362 and batch: 1150, loss is 4.613241167068481 and perplexity is 100.81036392502212
At time: 223.20649361610413 and batch: 1200, loss is 4.598655471801758 and perplexity is 99.3506460556712
At time: 224.3455114364624 and batch: 1250, loss is 4.629508790969848 and perplexity is 102.46372064208025
At time: 225.48483991622925 and batch: 1300, loss is 4.597705554962158 and perplexity is 99.2563160138986
At time: 226.62424731254578 and batch: 1350, loss is 4.5871223449707035 and perplexity is 98.2114045899223
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.832410888671875 and perplexity of 125.51319452111309
Finished 7 epochs...
Completing Train Step...
At time: 230.05705857276917 and batch: 50, loss is 4.7923221683502195 and perplexity is 120.58105330574325
At time: 231.19347524642944 and batch: 100, loss is 4.810014743804931 and perplexity is 122.73342706163251
At time: 232.3332986831665 and batch: 150, loss is 4.776055908203125 and perplexity is 118.63551672341708
At time: 233.47256112098694 and batch: 200, loss is 4.758986186981201 and perplexity is 116.62762733586595
At time: 234.6118505001068 and batch: 250, loss is 4.77364824295044 and perplexity is 118.3502256925346
At time: 235.75147032737732 and batch: 300, loss is 4.771868743896484 and perplexity is 118.13980885168971
At time: 236.89098715782166 and batch: 350, loss is 4.762140893936158 and perplexity is 116.99613428305663
At time: 238.0309522151947 and batch: 400, loss is 4.772905817031861 and perplexity is 118.26239202654028
At time: 239.20409560203552 and batch: 450, loss is 4.725805788040161 and perplexity is 112.8213718688911
At time: 240.34465861320496 and batch: 500, loss is 4.793221006393432 and perplexity is 120.68948486765136
At time: 241.48311114311218 and batch: 550, loss is 4.767165193557739 and perplexity is 117.58543709352945
At time: 242.62259650230408 and batch: 600, loss is 4.716017341613769 and perplexity is 111.72241323803405
At time: 243.76186180114746 and batch: 650, loss is 4.72895245552063 and perplexity is 113.17694234849483
At time: 244.90154838562012 and batch: 700, loss is 4.728636074066162 and perplexity is 113.141140926614
At time: 246.04138112068176 and batch: 750, loss is 4.691445455551148 and perplexity is 109.01063601098546
At time: 247.1808648109436 and batch: 800, loss is 4.666309766769409 and perplexity is 106.30472848027014
At time: 248.32013082504272 and batch: 850, loss is 4.643157472610474 and perplexity is 103.87180271800358
At time: 249.4591805934906 and batch: 900, loss is 4.6784456348419186 and perplexity is 107.60268864708226
At time: 250.59856510162354 and batch: 950, loss is 4.6567661094665525 and perplexity is 105.29501840923301
At time: 251.73797917366028 and batch: 1000, loss is 4.664763031005859 and perplexity is 106.14043025062456
At time: 252.877592086792 and batch: 1050, loss is 4.610159025192261 and perplexity is 100.50013041824425
At time: 254.01705479621887 and batch: 1100, loss is 4.589938831329346 and perplexity is 98.48840557284642
At time: 255.15615582466125 and batch: 1150, loss is 4.591643571853638 and perplexity is 98.65644594091619
At time: 256.29483556747437 and batch: 1200, loss is 4.579508638381958 and perplexity is 97.46649114636051
At time: 257.43385553359985 and batch: 1250, loss is 4.613834228515625 and perplexity is 100.87016839744918
At time: 258.5730936527252 and batch: 1300, loss is 4.581968107223511 and perplexity is 97.70650197302021
At time: 259.7124834060669 and batch: 1350, loss is 4.570019006729126 and perplexity is 96.54594477802648
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.827288411458333 and perplexity of 124.87189995287106
Finished 8 epochs...
Completing Train Step...
At time: 263.13092494010925 and batch: 50, loss is 4.755826139450074 and perplexity is 116.2596601930794
At time: 264.2723603248596 and batch: 100, loss is 4.774015693664551 and perplexity is 118.3937215582846
At time: 265.4135036468506 and batch: 150, loss is 4.740115308761597 and perplexity is 114.4473977070329
At time: 266.5561053752899 and batch: 200, loss is 4.72149775505066 and perplexity is 112.33637910945022
At time: 267.72607040405273 and batch: 250, loss is 4.73813081741333 and perplexity is 114.22050304616049
At time: 268.8666124343872 and batch: 300, loss is 4.736646127700806 and perplexity is 114.05104686637969
At time: 270.00775480270386 and batch: 350, loss is 4.726630363464356 and perplexity is 112.91443996501721
At time: 271.15003061294556 and batch: 400, loss is 4.738393220901489 and perplexity is 114.25047883728321
At time: 272.29094219207764 and batch: 450, loss is 4.690525188446045 and perplexity is 108.91036325449453
At time: 273.4368691444397 and batch: 500, loss is 4.759670667648315 and perplexity is 116.70748401908878
At time: 274.5781784057617 and batch: 550, loss is 4.735202398300171 and perplexity is 113.88650682107597
At time: 275.71967673301697 and batch: 600, loss is 4.68386604309082 and perplexity is 108.18752273608067
At time: 276.8604974746704 and batch: 650, loss is 4.697180299758911 and perplexity is 109.63759105194355
At time: 278.00208592414856 and batch: 700, loss is 4.698429212570191 and perplexity is 109.7746043850504
At time: 279.1432466506958 and batch: 750, loss is 4.66190920829773 and perplexity is 105.83795608962613
At time: 280.28414487838745 and batch: 800, loss is 4.637784023284912 and perplexity is 103.3151497623653
At time: 281.42567348480225 and batch: 850, loss is 4.616572465896606 and perplexity is 101.14675336801548
At time: 282.56640696525574 and batch: 900, loss is 4.653656377792358 and perplexity is 104.9680877521241
At time: 283.707323551178 and batch: 950, loss is 4.631833810806274 and perplexity is 102.70222798479662
At time: 284.8480439186096 and batch: 1000, loss is 4.641512756347656 and perplexity is 103.70110348920366
At time: 285.98875308036804 and batch: 1050, loss is 4.587540616989136 and perplexity is 98.2524922646665
At time: 287.1299259662628 and batch: 1100, loss is 4.568366146087646 and perplexity is 96.38649959244393
At time: 288.271377325058 and batch: 1150, loss is 4.570561447143555 and perplexity is 96.59832940680869
At time: 289.41305470466614 and batch: 1200, loss is 4.55846773147583 and perplexity is 95.43713242288831
At time: 290.55394411087036 and batch: 1250, loss is 4.595238695144653 and perplexity is 99.0117663551687
At time: 291.69495725631714 and batch: 1300, loss is 4.565239191055298 and perplexity is 96.0855740779691
At time: 292.8366734981537 and batch: 1350, loss is 4.552712230682373 and perplexity is 94.88942161843315
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.822971598307292 and perplexity of 124.3340131067521
Finished 9 epochs...
Completing Train Step...
At time: 296.2510414123535 and batch: 50, loss is 4.724407768249511 and perplexity is 112.66375555924144
At time: 297.41990995407104 and batch: 100, loss is 4.74328272819519 and perplexity is 114.81047532465594
At time: 298.5610935688019 and batch: 150, loss is 4.709629020690918 and perplexity is 111.01096949301312
At time: 299.70266795158386 and batch: 200, loss is 4.691475782394409 and perplexity is 109.01394200958761
At time: 300.8443036079407 and batch: 250, loss is 4.707617874145508 and perplexity is 110.78793451839996
At time: 301.98610520362854 and batch: 300, loss is 4.7064620399475094 and perplexity is 110.65995601017396
At time: 303.1280109882355 and batch: 350, loss is 4.6999440765380855 and perplexity is 109.94102399753531
At time: 304.2690224647522 and batch: 400, loss is 4.70913914680481 and perplexity is 110.9566014358199
At time: 305.41009283065796 and batch: 450, loss is 4.662730007171631 and perplexity is 105.92486342664348
At time: 306.55159854888916 and batch: 500, loss is 4.732328929901123 and perplexity is 113.55972726286133
At time: 307.69258308410645 and batch: 550, loss is 4.708594408035278 and perplexity is 110.89617553294259
At time: 308.83501839637756 and batch: 600, loss is 4.657406549453736 and perplexity is 105.36247514816431
At time: 309.9770531654358 and batch: 650, loss is 4.670242033004761 and perplexity is 106.72356993308065
At time: 311.11853075027466 and batch: 700, loss is 4.672235383987426 and perplexity is 106.9365196373194
At time: 312.25999116897583 and batch: 750, loss is 4.638183116912842 and perplexity is 103.3563904091964
At time: 313.401251077652 and batch: 800, loss is 4.614030523300171 and perplexity is 100.88997062889567
At time: 314.54304814338684 and batch: 850, loss is 4.5942763996124265 and perplexity is 98.91653360314206
At time: 315.6850504875183 and batch: 900, loss is 4.630147066116333 and perplexity is 102.52914156443582
At time: 316.82644486427307 and batch: 950, loss is 4.609321212768554 and perplexity is 100.41596542255837
At time: 317.96792101860046 and batch: 1000, loss is 4.618731822967529 and perplexity is 101.36540130963127
At time: 319.1092953681946 and batch: 1050, loss is 4.566240282058716 and perplexity is 96.18181264548146
At time: 320.25068044662476 and batch: 1100, loss is 4.549660472869873 and perplexity is 94.60028349884385
At time: 321.39231729507446 and batch: 1150, loss is 4.552758445739746 and perplexity is 94.89380703983281
At time: 322.5341799259186 and batch: 1200, loss is 4.541784915924072 and perplexity is 93.85817965530752
At time: 323.6754229068756 and batch: 1250, loss is 4.579572505950928 and perplexity is 97.47271629299647
At time: 324.81657433509827 and batch: 1300, loss is 4.547585439682007 and perplexity is 94.40418829339345
At time: 325.9585757255554 and batch: 1350, loss is 4.535319271087647 and perplexity is 93.25328362937924
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.818529459635417 and perplexity of 123.78292908092538
Finished 10 epochs...
Completing Train Step...
At time: 329.3536636829376 and batch: 50, loss is 4.697955045700073 and perplexity is 109.72256524306431
At time: 330.52268290519714 and batch: 100, loss is 4.715575094223023 and perplexity is 111.67301521616987
At time: 331.6633815765381 and batch: 150, loss is 4.6840143966674805 and perplexity is 108.20357393262539
At time: 332.80402159690857 and batch: 200, loss is 4.665614070892334 and perplexity is 106.23079843834736
At time: 333.9445297718048 and batch: 250, loss is 4.680371980667115 and perplexity is 107.810168411867
At time: 335.0856635570526 and batch: 300, loss is 4.6805734443664555 and perplexity is 107.83189043524794
At time: 336.22647500038147 and batch: 350, loss is 4.6763794803619385 and perplexity is 107.38059438940886
At time: 337.36765146255493 and batch: 400, loss is 4.685743904113769 and perplexity is 108.39087474184123
At time: 338.50947976112366 and batch: 450, loss is 4.637498569488526 and perplexity is 103.28566226950005
At time: 339.65021204948425 and batch: 500, loss is 4.707975540161133 and perplexity is 110.82756668463549
At time: 340.7911868095398 and batch: 550, loss is 4.685689096450806 and perplexity is 108.38493425410367
At time: 341.9325430393219 and batch: 600, loss is 4.635676412582398 and perplexity is 103.09763095000139
At time: 343.07325744628906 and batch: 650, loss is 4.647458133697509 and perplexity is 104.319482106645
At time: 344.21421694755554 and batch: 700, loss is 4.650487327575684 and perplexity is 104.63596514545424
At time: 345.35610485076904 and batch: 750, loss is 4.616278257369995 and perplexity is 101.11699950786985
At time: 346.4968111515045 and batch: 800, loss is 4.591888341903687 and perplexity is 98.68059703973904
At time: 347.63903737068176 and batch: 850, loss is 4.573607397079468 and perplexity is 96.89301164791758
At time: 348.7797646522522 and batch: 900, loss is 4.610867395401001 and perplexity is 100.5713469374593
At time: 349.9204456806183 and batch: 950, loss is 4.589919996261597 and perplexity is 98.48655055452471
At time: 351.06158113479614 and batch: 1000, loss is 4.5991175079345705 and perplexity is 99.39656025015886
At time: 352.20344257354736 and batch: 1050, loss is 4.546941337585449 and perplexity is 94.34340193620137
At time: 353.34406042099 and batch: 1100, loss is 4.531858072280884 and perplexity is 92.93107341383168
At time: 354.53014159202576 and batch: 1150, loss is 4.536023979187012 and perplexity is 93.31902313450549
At time: 355.67108941078186 and batch: 1200, loss is 4.52228554725647 and perplexity is 92.04573262201757
At time: 356.81199884414673 and batch: 1250, loss is 4.562622289657593 and perplexity is 95.83445632337484
At time: 357.9534511566162 and batch: 1300, loss is 4.532910404205322 and perplexity is 93.02891922326224
At time: 359.09488010406494 and batch: 1350, loss is 4.519903039932251 and perplexity is 91.82669402402598
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.817180582682291 and perplexity of 123.61607369968593
Finished 11 epochs...
Completing Train Step...
At time: 362.510605096817 and batch: 50, loss is 4.673854703903198 and perplexity is 107.10982435331057
At time: 363.64917635917664 and batch: 100, loss is 4.689470338821411 and perplexity is 108.7955397700986
At time: 364.7884638309479 and batch: 150, loss is 4.660699081420899 and perplexity is 105.70995619804803
At time: 365.9277241230011 and batch: 200, loss is 4.641332292556763 and perplexity is 103.68239088347288
At time: 367.06648206710815 and batch: 250, loss is 4.656431684494018 and perplexity is 105.2598110130379
At time: 368.20497369766235 and batch: 300, loss is 4.656810731887817 and perplexity is 105.29971703273274
At time: 369.343807220459 and batch: 350, loss is 4.653941431045532 and perplexity is 104.99801351203229
At time: 370.48271131515503 and batch: 400, loss is 4.662693185806274 and perplexity is 105.92096320035316
At time: 371.62156558036804 and batch: 450, loss is 4.615189905166626 and perplexity is 101.007008464012
At time: 372.76109552383423 and batch: 500, loss is 4.686257028579712 and perplexity is 108.446507023478
At time: 373.89986276626587 and batch: 550, loss is 4.6614679431915285 and perplexity is 105.79126379528985
At time: 375.03890895843506 and batch: 600, loss is 4.611756362915039 and perplexity is 100.66079134842724
At time: 376.17760396003723 and batch: 650, loss is 4.623166627883911 and perplexity is 101.81593536662966
At time: 377.3163831233978 and batch: 700, loss is 4.628887338638306 and perplexity is 102.40006410578884
At time: 378.45551586151123 and batch: 750, loss is 4.594968585968018 and perplexity is 98.98502598005423
At time: 379.59414505958557 and batch: 800, loss is 4.5707266139984135 and perplexity is 96.61428556673953
At time: 380.73314571380615 and batch: 850, loss is 4.556671743392944 and perplexity is 95.26588229801536
At time: 381.87147092819214 and batch: 900, loss is 4.590345335006714 and perplexity is 98.52844961036274
At time: 383.03845405578613 and batch: 950, loss is 4.571578502655029 and perplexity is 96.69662524782143
At time: 384.17686653137207 and batch: 1000, loss is 4.579161758422852 and perplexity is 97.43268783708167
At time: 385.3159613609314 and batch: 1050, loss is 4.52885853767395 and perplexity is 92.6527410854774
At time: 386.4560172557831 and batch: 1100, loss is 4.51377854347229 and perplexity is 91.2660204357948
At time: 387.5947308540344 and batch: 1150, loss is 4.518520374298095 and perplexity is 91.6998161449558
At time: 388.7336688041687 and batch: 1200, loss is 4.504655723571777 and perplexity is 90.43720329133473
At time: 389.87233424186707 and batch: 1250, loss is 4.547099885940551 and perplexity is 94.35836111323826
At time: 391.0114288330078 and batch: 1300, loss is 4.516497573852539 and perplexity is 91.51451319462961
At time: 392.15047550201416 and batch: 1350, loss is 4.504149084091186 and perplexity is 90.391395838545
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.815417073567708 and perplexity of 123.39826773485706
Finished 12 epochs...
Completing Train Step...
At time: 395.5639569759369 and batch: 50, loss is 4.651312828063965 and perplexity is 104.72237784773034
At time: 396.7019464969635 and batch: 100, loss is 4.666787872314453 and perplexity is 106.355565512186
At time: 397.8405375480652 and batch: 150, loss is 4.639194440841675 and perplexity is 103.46097007305984
At time: 398.9792537689209 and batch: 200, loss is 4.618390159606934 and perplexity is 101.33077438168483
At time: 400.1183214187622 and batch: 250, loss is 4.636953592300415 and perplexity is 103.22938927484623
At time: 401.2571771144867 and batch: 300, loss is 4.637203035354614 and perplexity is 103.25514234081821
At time: 402.39509201049805 and batch: 350, loss is 4.633743934631347 and perplexity is 102.89858943499742
At time: 403.5337188243866 and batch: 400, loss is 4.643914852142334 and perplexity is 103.95050289450901
At time: 404.6720943450928 and batch: 450, loss is 4.594387845993042 and perplexity is 98.92755810710429
At time: 405.81073784828186 and batch: 500, loss is 4.6668960475921635 and perplexity is 106.36707117732439
At time: 406.95043778419495 and batch: 550, loss is 4.642464237213135 and perplexity is 103.79982006091974
At time: 408.08992409706116 and batch: 600, loss is 4.592147769927979 and perplexity is 98.7062008730974
At time: 409.22841238975525 and batch: 650, loss is 4.603758544921875 and perplexity is 99.8589354830362
At time: 410.3676052093506 and batch: 700, loss is 4.6105452728271485 and perplexity is 100.53895585355777
At time: 411.5061402320862 and batch: 750, loss is 4.575976858139038 and perplexity is 97.1228680763489
At time: 412.68899488449097 and batch: 800, loss is 4.554518480300903 and perplexity is 95.06097048342954
At time: 413.82793855667114 and batch: 850, loss is 4.540697860717773 and perplexity is 93.75620606796073
At time: 414.96713066101074 and batch: 900, loss is 4.572640295028687 and perplexity is 96.79935151440002
At time: 416.1060492992401 and batch: 950, loss is 4.555413513183594 and perplexity is 95.14609126513965
At time: 417.24458956718445 and batch: 1000, loss is 4.563136615753174 and perplexity is 95.88375916289937
At time: 418.38319182395935 and batch: 1050, loss is 4.512264003753662 and perplexity is 91.12789904445258
At time: 419.5222885608673 and batch: 1100, loss is 4.497912635803223 and perplexity is 89.8294287335106
At time: 420.66090536117554 and batch: 1150, loss is 4.503616724014282 and perplexity is 90.34328787462078
At time: 421.80019879341125 and batch: 1200, loss is 4.490494832992554 and perplexity is 89.16555702334831
At time: 422.9389510154724 and batch: 1250, loss is 4.5308495712280275 and perplexity is 92.83739957147449
At time: 424.0772759914398 and batch: 1300, loss is 4.502253284454346 and perplexity is 90.22019419642194
At time: 425.215749502182 and batch: 1350, loss is 4.489893236160278 and perplexity is 89.11193143880321
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.81469482421875 and perplexity of 123.30917559356641
Finished 13 epochs...
Completing Train Step...
At time: 428.61083793640137 and batch: 50, loss is 4.629966468811035 and perplexity is 102.51062674966792
At time: 429.7772288322449 and batch: 100, loss is 4.646296396255493 and perplexity is 104.19836062765098
At time: 430.9227111339569 and batch: 150, loss is 4.619152641296386 and perplexity is 101.40806670497489
At time: 432.0608344078064 and batch: 200, loss is 4.599040870666504 and perplexity is 99.38894306121006
At time: 433.19871282577515 and batch: 250, loss is 4.6162677574157716 and perplexity is 101.11593778957781
At time: 434.3368630409241 and batch: 300, loss is 4.616234378814697 and perplexity is 101.11256273735567
At time: 435.4754385948181 and batch: 350, loss is 4.614212732315064 and perplexity is 100.90835536593809
At time: 436.6172559261322 and batch: 400, loss is 4.62273154258728 and perplexity is 101.77164638562974
At time: 437.7553377151489 and batch: 450, loss is 4.575790958404541 and perplexity is 97.10481463907652
At time: 438.89351439476013 and batch: 500, loss is 4.649133625030518 and perplexity is 104.49441500313091
At time: 440.0320391654968 and batch: 550, loss is 4.623839626312256 and perplexity is 101.88448039387245
At time: 441.19876170158386 and batch: 600, loss is 4.573733520507813 and perplexity is 96.905232897406
At time: 442.33747720718384 and batch: 650, loss is 4.5837703132629395 and perplexity is 97.8827479890816
At time: 443.47670245170593 and batch: 700, loss is 4.592632579803467 and perplexity is 98.75406621591047
At time: 444.6147196292877 and batch: 750, loss is 4.558308238983154 and perplexity is 95.42191213053779
At time: 445.7530937194824 and batch: 800, loss is 4.538089437484741 and perplexity is 93.51196887727326
At time: 446.8924334049225 and batch: 850, loss is 4.523560266494751 and perplexity is 92.16313990295444
At time: 448.03096055984497 and batch: 900, loss is 4.557492084503174 and perplexity is 95.34406488147593
At time: 449.16984248161316 and batch: 950, loss is 4.539537258148194 and perplexity is 93.64745549458891
At time: 450.30887389183044 and batch: 1000, loss is 4.547553653717041 and perplexity is 94.40118761286173
At time: 451.44839239120483 and batch: 1050, loss is 4.496790809631348 and perplexity is 89.72871223311837
At time: 452.58667373657227 and batch: 1100, loss is 4.483542737960815 and perplexity is 88.54781937081665
At time: 453.7251207828522 and batch: 1150, loss is 4.490978889465332 and perplexity is 89.20872863628067
At time: 454.86363410949707 and batch: 1200, loss is 4.4755706882476805 and perplexity is 87.84471805583405
At time: 456.0021240711212 and batch: 1250, loss is 4.517541303634643 and perplexity is 91.61007948155994
At time: 457.14038276672363 and batch: 1300, loss is 4.487891960144043 and perplexity is 88.93377220002233
At time: 458.2798535823822 and batch: 1350, loss is 4.475973596572876 and perplexity is 87.88011855516227
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.815421142578125 and perplexity of 123.39876984471542
Annealing...
Finished 14 epochs...
Completing Train Step...
At time: 461.6957883834839 and batch: 50, loss is 4.616410531997681 and perplexity is 101.13037560597215
At time: 462.8631844520569 and batch: 100, loss is 4.63919960975647 and perplexity is 103.46150485538087
At time: 464.02193880081177 and batch: 150, loss is 4.616421823501587 and perplexity is 101.13151752645032
At time: 465.1617558002472 and batch: 200, loss is 4.595603151321411 and perplexity is 99.04785838157004
At time: 466.30139803886414 and batch: 250, loss is 4.610871114730835 and perplexity is 100.57172099616606
At time: 467.4405162334442 and batch: 300, loss is 4.611494560241699 and perplexity is 100.63444153352816
At time: 468.57975816726685 and batch: 350, loss is 4.606295528411866 and perplexity is 100.11259758591478
At time: 469.7192077636719 and batch: 400, loss is 4.612655563354492 and perplexity is 100.75134628366061
At time: 470.88655185699463 and batch: 450, loss is 4.560153541564941 and perplexity is 95.59815699389041
At time: 472.0256543159485 and batch: 500, loss is 4.627121782302856 and perplexity is 102.21943053015578
At time: 473.1649167537689 and batch: 550, loss is 4.597928142547607 and perplexity is 99.27841169664177
At time: 474.30372428894043 and batch: 600, loss is 4.549024457931519 and perplexity is 94.54013543492715
At time: 475.4432752132416 and batch: 650, loss is 4.556321325302124 and perplexity is 95.23250525772113
At time: 476.58205461502075 and batch: 700, loss is 4.557255725860596 and perplexity is 95.3215321507304
At time: 477.7216067314148 and batch: 750, loss is 4.520192642211914 and perplexity is 91.85329109504957
At time: 478.86108350753784 and batch: 800, loss is 4.494748802185058 and perplexity is 89.54567248246248
At time: 480.00063371658325 and batch: 850, loss is 4.472330141067505 and perplexity is 87.5605138397362
At time: 481.1395606994629 and batch: 900, loss is 4.493524045944214 and perplexity is 89.43606799434018
At time: 482.2790458202362 and batch: 950, loss is 4.477324352264405 and perplexity is 87.99890333201891
At time: 483.41825246810913 and batch: 1000, loss is 4.481023368835449 and perplexity is 88.3250155090093
At time: 484.55786871910095 and batch: 1050, loss is 4.423244781494141 and perplexity is 83.36635256489079
At time: 485.69758653640747 and batch: 1100, loss is 4.404359636306762 and perplexity is 81.80674000036097
At time: 486.83754658699036 and batch: 1150, loss is 4.405497579574585 and perplexity is 81.89988441588605
At time: 487.9772410392761 and batch: 1200, loss is 4.383395147323609 and perplexity is 80.10955595923791
At time: 489.1164450645447 and batch: 1250, loss is 4.421880168914795 and perplexity is 83.25266737724685
At time: 490.25580072402954 and batch: 1300, loss is 4.38721960067749 and perplexity is 80.41651782572747
At time: 491.39538049697876 and batch: 1350, loss is 4.381001081466675 and perplexity is 79.91799779942056
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.786468098958333 and perplexity of 119.87722559050819
Finished 15 epochs...
Completing Train Step...
At time: 494.82249784469604 and batch: 50, loss is 4.596547918319702 and perplexity is 99.1414797476451
At time: 495.9640483856201 and batch: 100, loss is 4.61553092956543 and perplexity is 101.0414601924545
At time: 497.10546016693115 and batch: 150, loss is 4.591520872116089 and perplexity is 98.64434156350887
At time: 498.24646186828613 and batch: 200, loss is 4.572311706542969 and perplexity is 96.76754958722714
At time: 499.41620922088623 and batch: 250, loss is 4.588043279647827 and perplexity is 98.30189253844765
At time: 500.5581383705139 and batch: 300, loss is 4.588107223510742 and perplexity is 98.30817854216193
At time: 501.69934368133545 and batch: 350, loss is 4.583352870941162 and perplexity is 97.84189611474298
At time: 502.84089851379395 and batch: 400, loss is 4.589433164596557 and perplexity is 98.43861585214647
At time: 503.98276591300964 and batch: 450, loss is 4.538579502105713 and perplexity is 93.55780701576502
At time: 505.1250777244568 and batch: 500, loss is 4.608355350494385 and perplexity is 100.31902425327783
At time: 506.2685811519623 and batch: 550, loss is 4.581279287338257 and perplexity is 97.63922296576177
At time: 507.41055130958557 and batch: 600, loss is 4.531965675354004 and perplexity is 92.94107362093622
At time: 508.55253195762634 and batch: 650, loss is 4.540169200897217 and perplexity is 93.7066540281251
At time: 509.6936490535736 and batch: 700, loss is 4.543234786987305 and perplexity is 93.99436061259628
At time: 510.8356018066406 and batch: 750, loss is 4.506988410949707 and perplexity is 90.64841125925534
At time: 511.9765088558197 and batch: 800, loss is 4.483234519958496 and perplexity is 88.5205315443362
At time: 513.1186671257019 and batch: 850, loss is 4.46288420677185 and perplexity is 86.73731703144252
At time: 514.2608532905579 and batch: 900, loss is 4.485589761734008 and perplexity is 88.72926451003067
At time: 515.4027888774872 and batch: 950, loss is 4.4701675701141355 and perplexity is 87.37136261603256
At time: 516.5440983772278 and batch: 1000, loss is 4.475970363616943 and perplexity is 87.87983444307083
At time: 517.6863174438477 and batch: 1050, loss is 4.420384540557861 and perplexity is 83.12824539484295
At time: 518.8287470340729 and batch: 1100, loss is 4.403139867782593 and perplexity is 81.707015546583
At time: 519.9708714485168 and batch: 1150, loss is 4.406094951629639 and perplexity is 81.94882373418342
At time: 521.1127619743347 and batch: 1200, loss is 4.386417503356934 and perplexity is 80.35204181372599
At time: 522.2538874149323 and batch: 1250, loss is 4.426341361999512 and perplexity is 83.62490329201829
At time: 523.3949687480927 and batch: 1300, loss is 4.393115568161011 and perplexity is 80.89205148791258
At time: 524.5365788936615 and batch: 1350, loss is 4.387800779342651 and perplexity is 80.4632677739347
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.78294677734375 and perplexity of 119.45584167450545
Finished 16 epochs...
Completing Train Step...
At time: 527.9767320156097 and batch: 50, loss is 4.588687047958374 and perplexity is 98.36519655610464
At time: 529.1185486316681 and batch: 100, loss is 4.605844163894654 and perplexity is 100.06742050807055
At time: 530.2606372833252 and batch: 150, loss is 4.580519495010376 and perplexity is 97.565065608915
At time: 531.4023005962372 and batch: 200, loss is 4.562130069732666 and perplexity is 95.78729630198113
At time: 532.5440945625305 and batch: 250, loss is 4.57760871887207 and perplexity is 97.28148845902902
At time: 533.6860449314117 and batch: 300, loss is 4.576948366165161 and perplexity is 97.21726957068499
At time: 534.8277094364166 and batch: 350, loss is 4.572813644409179 and perplexity is 96.81613307651182
At time: 535.9699673652649 and batch: 400, loss is 4.57869122505188 and perplexity is 97.38685329021847
At time: 537.1116895675659 and batch: 450, loss is 4.52829665184021 and perplexity is 92.60069544602736
At time: 538.253671169281 and batch: 500, loss is 4.599037857055664 and perplexity is 99.3886435420652
At time: 539.3950853347778 and batch: 550, loss is 4.572520036697387 and perplexity is 96.7877112858473
At time: 540.5371425151825 and batch: 600, loss is 4.52383056640625 and perplexity is 92.18805495863064
At time: 541.6794142723083 and batch: 650, loss is 4.532339057922363 and perplexity is 92.97578267718589
At time: 542.8219528198242 and batch: 700, loss is 4.536534814834595 and perplexity is 93.36670599613608
At time: 543.9631793498993 and batch: 750, loss is 4.500456409454346 and perplexity is 90.05822534744287
At time: 545.104918718338 and batch: 800, loss is 4.47763388633728 and perplexity is 88.02614620705735
At time: 546.247086763382 and batch: 850, loss is 4.457889614105224 and perplexity is 86.3051795375932
At time: 547.3895795345306 and batch: 900, loss is 4.481436805725098 and perplexity is 88.36153987844013
At time: 548.5318274497986 and batch: 950, loss is 4.4668483543396 and perplexity is 87.08183897252852
At time: 549.6744341850281 and batch: 1000, loss is 4.473638601303101 and perplexity is 87.67515827779148
At time: 550.8167884349823 and batch: 1050, loss is 4.419116535186768 and perplexity is 83.02290513331559
At time: 551.9590487480164 and batch: 1100, loss is 4.4030001258850096 and perplexity is 81.69559845092652
At time: 553.1075158119202 and batch: 1150, loss is 4.4068425846099855 and perplexity is 82.01011428607183
At time: 554.249392747879 and batch: 1200, loss is 4.388583335876465 and perplexity is 80.52625947393176
At time: 555.3909463882446 and batch: 1250, loss is 4.42886513710022 and perplexity is 83.83622028686653
At time: 556.5331664085388 and batch: 1300, loss is 4.396044015884399 and perplexity is 81.12928682803813
At time: 557.6746039390564 and batch: 1350, loss is 4.390689458847046 and perplexity is 80.6960364015309
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7815283203125 and perplexity of 119.28651881295016
Finished 17 epochs...
Completing Train Step...
At time: 561.0757644176483 and batch: 50, loss is 4.5827248096466064 and perplexity is 97.78046470017358
At time: 562.2444975376129 and batch: 100, loss is 4.598746709823608 and perplexity is 99.35971102561557
At time: 563.3854434490204 and batch: 150, loss is 4.572896709442139 and perplexity is 96.82417544581205
At time: 564.531644821167 and batch: 200, loss is 4.555078802108764 and perplexity is 95.11425014375169
At time: 565.6724264621735 and batch: 250, loss is 4.570182180404663 and perplexity is 96.56169982006318
At time: 566.8141620159149 and batch: 300, loss is 4.569390363693238 and perplexity is 96.48527091529729
At time: 567.9548363685608 and batch: 350, loss is 4.56570276260376 and perplexity is 96.13012694225155
At time: 569.095743894577 and batch: 400, loss is 4.571429195404053 and perplexity is 96.68218881828562
At time: 570.2367033958435 and batch: 450, loss is 4.521552734375 and perplexity is 91.9783050323884
At time: 571.3781764507294 and batch: 500, loss is 4.592482929229736 and perplexity is 98.73928871900107
At time: 572.5186312198639 and batch: 550, loss is 4.566748428344726 and perplexity is 96.2306994961429
At time: 573.6591789722443 and batch: 600, loss is 4.5185512447357175 and perplexity is 91.70264700210475
At time: 574.7998864650726 and batch: 650, loss is 4.52709511756897 and perplexity is 92.48949935324407
At time: 575.940744638443 and batch: 700, loss is 4.531939973831177 and perplexity is 92.93868492450767
At time: 577.082088470459 and batch: 750, loss is 4.495759267807006 and perplexity is 89.63620103639322
At time: 578.2234120368958 and batch: 800, loss is 4.473755798339844 and perplexity is 87.68543414867665
At time: 579.364102602005 and batch: 850, loss is 4.454386262893677 and perplexity is 86.00335119634657
At time: 580.5051157474518 and batch: 900, loss is 4.478569984436035 and perplexity is 88.10858589496006
At time: 581.6457669734955 and batch: 950, loss is 4.464393177032471 and perplexity is 86.86829986307389
At time: 582.7862448692322 and batch: 1000, loss is 4.472156982421875 and perplexity is 87.54535329237692
At time: 583.9278049468994 and batch: 1050, loss is 4.418075866699219 and perplexity is 82.93655075313313
At time: 585.0684096813202 and batch: 1100, loss is 4.40281572341919 and perplexity is 81.68053497003976
At time: 586.2547218799591 and batch: 1150, loss is 4.407077875137329 and perplexity is 82.02941275939465
At time: 587.395444393158 and batch: 1200, loss is 4.389677124023438 and perplexity is 80.61438632933327
At time: 588.5358164310455 and batch: 1250, loss is 4.430149374008178 and perplexity is 83.94395501883525
At time: 589.6764769554138 and batch: 1300, loss is 4.397569599151612 and perplexity is 81.25315076885816
At time: 590.8175067901611 and batch: 1350, loss is 4.391949939727783 and perplexity is 80.7978163449269
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.780960286458333 and perplexity of 119.21877927291611
Finished 18 epochs...
Completing Train Step...
At time: 594.2155385017395 and batch: 50, loss is 4.577701654434204 and perplexity is 97.29052978896823
At time: 595.381596326828 and batch: 100, loss is 4.592912788391113 and perplexity is 98.78174183062058
At time: 596.5196144580841 and batch: 150, loss is 4.566894741058349 and perplexity is 96.24478030099529
At time: 597.6584212779999 and batch: 200, loss is 4.549460716247559 and perplexity is 94.58138835302022
At time: 598.7967185974121 and batch: 250, loss is 4.564432020187378 and perplexity is 96.00804789439364
At time: 599.935054063797 and batch: 300, loss is 4.5637025547027585 and perplexity is 95.93803887489508
At time: 601.0731871128082 and batch: 350, loss is 4.560091514587402 and perplexity is 95.59222751304956
At time: 602.211671590805 and batch: 400, loss is 4.565732564926147 and perplexity is 96.13299188597662
At time: 603.3506009578705 and batch: 450, loss is 4.516330575942993 and perplexity is 91.49923173825412
At time: 604.4894614219666 and batch: 500, loss is 4.587347059249878 and perplexity is 98.23347657476366
At time: 605.6285059452057 and batch: 550, loss is 4.5621450328826905 and perplexity is 95.78872959238942
At time: 606.7727496623993 and batch: 600, loss is 4.514379053115845 and perplexity is 91.32084302029327
At time: 607.9125216007233 and batch: 650, loss is 4.5229784107208255 and perplexity is 92.10952984603186
At time: 609.0509617328644 and batch: 700, loss is 4.528075284957886 and perplexity is 92.58019898747767
At time: 610.1897900104523 and batch: 750, loss is 4.4920130443573 and perplexity is 89.30103199916694
At time: 611.3287749290466 and batch: 800, loss is 4.470653085708618 and perplexity is 87.41379307458502
At time: 612.4680442810059 and batch: 850, loss is 4.451616868972779 and perplexity is 85.76550353731224
At time: 613.6066102981567 and batch: 900, loss is 4.47619366645813 and perplexity is 87.89946045097511
At time: 614.7732758522034 and batch: 950, loss is 4.462382898330689 and perplexity is 86.69384577941416
At time: 615.9115767478943 and batch: 1000, loss is 4.470651178359986 and perplexity is 87.41362634616532
At time: 617.0505981445312 and batch: 1050, loss is 4.416805686950684 and perplexity is 82.83127330075132
At time: 618.1891510486603 and batch: 1100, loss is 4.40232798576355 and perplexity is 81.64070601123309
At time: 619.3281996250153 and batch: 1150, loss is 4.406893291473389 and perplexity is 82.01427286716803
At time: 620.4667155742645 and batch: 1200, loss is 4.3896839427948 and perplexity is 80.6149360222763
At time: 621.6052174568176 and batch: 1250, loss is 4.430986547470093 and perplexity is 84.014260094931
At time: 622.743280172348 and batch: 1300, loss is 4.398238277435302 and perplexity is 81.30750115569529
At time: 623.8847470283508 and batch: 1350, loss is 4.392337322235107 and perplexity is 80.82912206886236
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.780513916015625 and perplexity of 119.16557540883255
Finished 19 epochs...
Completing Train Step...
At time: 627.3070397377014 and batch: 50, loss is 4.573289585113526 and perplexity is 96.8622227821938
At time: 628.4451196193695 and batch: 100, loss is 4.58811203956604 and perplexity is 98.3086520009261
At time: 629.5833094120026 and batch: 150, loss is 4.561823539733886 and perplexity is 95.75793912182068
At time: 630.7215702533722 and batch: 200, loss is 4.544668712615967 and perplexity is 94.1292382143427
At time: 631.8605406284332 and batch: 250, loss is 4.5595620918273925 and perplexity is 95.54163220645935
At time: 632.998636007309 and batch: 300, loss is 4.558898859024048 and perplexity is 95.47828687056928
At time: 634.1368026733398 and batch: 350, loss is 4.555498332977295 and perplexity is 95.15416187924126
At time: 635.2748146057129 and batch: 400, loss is 4.560957126617431 and perplexity is 95.67500911836997
At time: 636.4131453037262 and batch: 450, loss is 4.51192684173584 and perplexity is 91.09717935717772
At time: 637.5512804985046 and batch: 500, loss is 4.583031835556031 and perplexity is 97.81049044537707
At time: 638.6897249221802 and batch: 550, loss is 4.55825291633606 and perplexity is 95.41663328378914
At time: 639.8285796642303 and batch: 600, loss is 4.510943307876587 and perplexity is 91.00762624327633
At time: 640.9665830135345 and batch: 650, loss is 4.519516696929932 and perplexity is 91.79122427554948
At time: 642.104510307312 and batch: 700, loss is 4.5248509216308594 and perplexity is 92.282167528115
At time: 643.2883198261261 and batch: 750, loss is 4.488878002166748 and perplexity is 89.02150788507682
At time: 644.4263024330139 and batch: 800, loss is 4.467671642303467 and perplexity is 87.1535619226956
At time: 645.5650873184204 and batch: 850, loss is 4.449183712005615 and perplexity is 85.55707627578839
At time: 646.7038209438324 and batch: 900, loss is 4.474003200531006 and perplexity is 87.70713040095754
At time: 647.8428614139557 and batch: 950, loss is 4.460455112457275 and perplexity is 86.52687959744102
At time: 648.9811208248138 and batch: 1000, loss is 4.469158945083618 and perplexity is 87.28328210032122
At time: 650.1191236972809 and batch: 1050, loss is 4.4156442070007325 and perplexity is 82.73512228713005
At time: 651.2574760913849 and batch: 1100, loss is 4.401716451644898 and perplexity is 81.59079519667485
At time: 652.3959333896637 and batch: 1150, loss is 4.406540899276734 and perplexity is 81.98537676907407
At time: 653.5344111919403 and batch: 1200, loss is 4.389807271957397 and perplexity is 80.62487880793385
At time: 654.6730358600616 and batch: 1250, loss is 4.430978479385376 and perplexity is 84.01358226349754
At time: 655.8114302158356 and batch: 1300, loss is 4.398306922912598 and perplexity is 81.31308273949287
At time: 656.9495947360992 and batch: 1350, loss is 4.392278356552124 and perplexity is 80.82435606499133
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.780194905598958 and perplexity of 119.12756641192435
Finished 20 epochs...
Completing Train Step...
At time: 660.3664371967316 and batch: 50, loss is 4.569180355072022 and perplexity is 96.46501030411072
At time: 661.5050206184387 and batch: 100, loss is 4.583791007995606 and perplexity is 97.88477366734422
At time: 662.6438655853271 and batch: 150, loss is 4.557372493743896 and perplexity is 95.33266329413996
At time: 663.7822861671448 and batch: 200, loss is 4.540381126403808 and perplexity is 93.72651496269599
At time: 664.920464515686 and batch: 250, loss is 4.555250463485717 and perplexity is 95.1305789883751
At time: 666.0586595535278 and batch: 300, loss is 4.554597616195679 and perplexity is 95.06849351605403
At time: 667.1969521045685 and batch: 350, loss is 4.551577119827271 and perplexity is 94.78177271419813
At time: 668.3356726169586 and batch: 400, loss is 4.556862487792968 and perplexity is 95.28405546473687
At time: 669.4745697975159 and batch: 450, loss is 4.508063449859619 and perplexity is 90.74591422883339
At time: 670.6128263473511 and batch: 500, loss is 4.579148292541504 and perplexity is 97.43137582890157
At time: 671.7510499954224 and batch: 550, loss is 4.554807024002075 and perplexity is 95.08840368533833
At time: 672.9177992343903 and batch: 600, loss is 4.507929801940918 and perplexity is 90.73378703667115
At time: 674.0561246871948 and batch: 650, loss is 4.516396579742431 and perplexity is 91.5052712345072
At time: 675.1950061321259 and batch: 700, loss is 4.521936874389649 and perplexity is 92.01364436702265
At time: 676.3336293697357 and batch: 750, loss is 4.486092290878296 and perplexity is 88.77386475692151
At time: 677.4718835353851 and batch: 800, loss is 4.465198488235473 and perplexity is 86.93828405388363
At time: 678.6099784374237 and batch: 850, loss is 4.446680345535278 and perplexity is 85.34316342258488
At time: 679.7484357357025 and batch: 900, loss is 4.471849384307862 and perplexity is 87.51842864801073
At time: 680.886904001236 and batch: 950, loss is 4.458604679107666 and perplexity is 86.36691542096428
At time: 682.0253374576569 and batch: 1000, loss is 4.467622632980347 and perplexity is 87.14929069028425
At time: 683.1636579036713 and batch: 1050, loss is 4.414433317184448 and perplexity is 82.63499980098672
At time: 684.3024561405182 and batch: 1100, loss is 4.400818538665772 and perplexity is 81.51756664404448
At time: 685.4407844543457 and batch: 1150, loss is 4.405854253768921 and perplexity is 81.92910120130325
At time: 686.5803034305573 and batch: 1200, loss is 4.389519329071045 and perplexity is 80.60166678964625
At time: 687.7183439731598 and batch: 1250, loss is 4.430606985092163 and perplexity is 83.98237749369011
At time: 688.8568758964539 and batch: 1300, loss is 4.398126668930054 and perplexity is 81.29842705340874
At time: 689.9953713417053 and batch: 1350, loss is 4.391824445724487 and perplexity is 80.7876773397017
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.78002197265625 and perplexity of 119.10696711250715
Finished 21 epochs...
Completing Train Step...
At time: 693.3890902996063 and batch: 50, loss is 4.565404405593872 and perplexity is 96.10145012319468
At time: 694.5563960075378 and batch: 100, loss is 4.57988320350647 and perplexity is 97.50300553283347
At time: 695.695220708847 and batch: 150, loss is 4.553450574874878 and perplexity is 94.95950854276803
At time: 696.8343379497528 and batch: 200, loss is 4.536532936096191 and perplexity is 93.36653058468464
At time: 697.9734880924225 and batch: 250, loss is 4.551439437866211 and perplexity is 94.76872387217382
At time: 699.1127288341522 and batch: 300, loss is 4.550766639709472 and perplexity is 94.70498509350686
At time: 700.251389503479 and batch: 350, loss is 4.548129529953003 and perplexity is 94.455566669755
At time: 701.4347882270813 and batch: 400, loss is 4.553186359405518 and perplexity is 94.93442208590913
At time: 702.5748462677002 and batch: 450, loss is 4.504579887390137 and perplexity is 90.43034513921022
At time: 703.7143356800079 and batch: 500, loss is 4.5757272434234615 and perplexity is 97.09862780474816
At time: 704.8541762828827 and batch: 550, loss is 4.551583013534546 and perplexity is 94.78233133186768
At time: 705.9936661720276 and batch: 600, loss is 4.505910816192627 and perplexity is 90.55078161858661
At time: 707.1332266330719 and batch: 650, loss is 4.513571329116822 and perplexity is 91.2471107654393
At time: 708.2729477882385 and batch: 700, loss is 4.519226884841919 and perplexity is 91.76462592362901
At time: 709.4125037193298 and batch: 750, loss is 4.483575105667114 and perplexity is 88.55068550701236
At time: 710.5521636009216 and batch: 800, loss is 4.46269458770752 and perplexity is 86.72087154178296
At time: 711.6914892196655 and batch: 850, loss is 4.444496040344238 and perplexity is 85.15695135373319
At time: 712.8304398059845 and batch: 900, loss is 4.469761791229248 and perplexity is 87.33591635409785
At time: 713.9696569442749 and batch: 950, loss is 4.456730499267578 and perplexity is 86.20519987857251
At time: 715.1089866161346 and batch: 1000, loss is 4.466057653427124 and perplexity is 87.0130104979477
At time: 716.2481973171234 and batch: 1050, loss is 4.413225212097168 and perplexity is 82.53522831669346
At time: 717.3877952098846 and batch: 1100, loss is 4.399790487289429 and perplexity is 81.43380546023728
At time: 718.5273497104645 and batch: 1150, loss is 4.40486930847168 and perplexity is 81.84844524574036
At time: 719.6668491363525 and batch: 1200, loss is 4.388879289627075 and perplexity is 80.55009504938569
At time: 720.8060534000397 and batch: 1250, loss is 4.429964466094971 and perplexity is 83.92843455225909
At time: 721.9450521469116 and batch: 1300, loss is 4.397613277435303 and perplexity is 81.25669984453646
At time: 723.0847978591919 and batch: 1350, loss is 4.391166391372681 and perplexity is 80.73453214518707
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.779919026692708 and perplexity of 119.09470616213167
Finished 22 epochs...
Completing Train Step...
At time: 726.4752042293549 and batch: 50, loss is 4.561856145858765 and perplexity is 95.76106146804531
At time: 727.6445472240448 and batch: 100, loss is 4.5762384986877445 and perplexity is 97.14828268144498
At time: 728.7854425907135 and batch: 150, loss is 4.549824075698853 and perplexity is 94.61576163894573
At time: 729.9547665119171 and batch: 200, loss is 4.532943878173828 and perplexity is 93.03203332249484
At time: 731.0959541797638 and batch: 250, loss is 4.547963037490844 and perplexity is 94.43984183896482
At time: 732.2374749183655 and batch: 300, loss is 4.5472979164123535 and perplexity is 94.37704879431206
At time: 733.378830909729 and batch: 350, loss is 4.5449457931518555 and perplexity is 94.15532320776502
At time: 734.519891500473 and batch: 400, loss is 4.549849758148193 and perplexity is 94.61819163465483
At time: 735.6617341041565 and batch: 450, loss is 4.501354179382324 and perplexity is 90.13911321784279
At time: 736.8032331466675 and batch: 500, loss is 4.572510137557983 and perplexity is 96.78675317554291
At time: 737.944819688797 and batch: 550, loss is 4.548962993621826 and perplexity is 94.5343247693405
At time: 739.0865395069122 and batch: 600, loss is 4.5026248264312745 and perplexity is 90.25372101365686
At time: 740.2277202606201 and batch: 650, loss is 4.5109858798980715 and perplexity is 91.0115007043673
At time: 741.3686587810516 and batch: 700, loss is 4.51656478881836 and perplexity is 91.52066454623522
At time: 742.5104541778564 and batch: 750, loss is 4.481166038513184 and perplexity is 88.33761770946246
At time: 743.651650428772 and batch: 800, loss is 4.4603923797607425 and perplexity is 86.52145170321633
At time: 744.7928071022034 and batch: 850, loss is 4.44229022026062 and perplexity is 84.96931745956347
At time: 745.9353404045105 and batch: 900, loss is 4.467599601745605 and perplexity is 87.14728355762627
At time: 747.0777359008789 and batch: 950, loss is 4.454548692703247 and perplexity is 86.01732183889743
At time: 748.218957901001 and batch: 1000, loss is 4.4652446842193605 and perplexity is 86.94230034622053
At time: 749.3610427379608 and batch: 1050, loss is 4.412644548416138 and perplexity is 82.48731701872592
At time: 750.5022382736206 and batch: 1100, loss is 4.398444805145264 and perplexity is 81.32429514186373
At time: 751.6446316242218 and batch: 1150, loss is 4.403358726501465 and perplexity is 81.724899796319
At time: 752.7868657112122 and batch: 1200, loss is 4.388418083190918 and perplexity is 80.51295339275973
At time: 753.9291687011719 and batch: 1250, loss is 4.42914137840271 and perplexity is 83.85938251258878
At time: 755.0703356266022 and batch: 1300, loss is 4.396440076828003 and perplexity is 81.16142533391648
At time: 756.2122111320496 and batch: 1350, loss is 4.390339040756226 and perplexity is 80.66776400438738
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7796826171875 and perplexity of 119.06655436938185
Finished 23 epochs...
Completing Train Step...
At time: 759.6604566574097 and batch: 50, loss is 4.558595132827759 and perplexity is 95.4492920171411
At time: 760.8022029399872 and batch: 100, loss is 4.5727362537384035 and perplexity is 96.80864070095483
At time: 761.9439780712128 and batch: 150, loss is 4.546499719619751 and perplexity is 94.30174739333553
At time: 763.0852265357971 and batch: 200, loss is 4.530585784912109 and perplexity is 92.81291356554071
At time: 764.2267127037048 and batch: 250, loss is 4.54461893081665 and perplexity is 94.124552408131
At time: 765.3685503005981 and batch: 300, loss is 4.5439019298553465 and perplexity is 94.05708920205407
At time: 766.5105085372925 and batch: 350, loss is 4.541699419021606 and perplexity is 93.85015541470463
At time: 767.6520700454712 and batch: 400, loss is 4.546188306808472 and perplexity is 94.27238519319116
At time: 768.7942717075348 and batch: 450, loss is 4.497603416442871 and perplexity is 89.80165602916708
At time: 769.9357161521912 and batch: 500, loss is 4.56962474822998 and perplexity is 96.50788822129313
At time: 771.0771484375 and batch: 550, loss is 4.5457564735412594 and perplexity is 94.23168402977596
At time: 772.2184863090515 and batch: 600, loss is 4.500695133209229 and perplexity is 90.07972695152563
At time: 773.3597311973572 and batch: 650, loss is 4.508495988845826 and perplexity is 90.78517386462578
At time: 774.5017125606537 and batch: 700, loss is 4.5142083168029785 and perplexity is 91.30525256723423
At time: 775.6435344219208 and batch: 750, loss is 4.478935260772705 and perplexity is 88.1407757551841
At time: 776.7852144241333 and batch: 800, loss is 4.457740173339844 and perplexity is 86.29228298916588
At time: 777.9264667034149 and batch: 850, loss is 4.4399647045135495 and perplexity is 84.77194955382728
At time: 779.0683841705322 and batch: 900, loss is 4.465655422210693 and perplexity is 86.97801818686149
At time: 780.2100405693054 and batch: 950, loss is 4.4527386283874515 and perplexity is 85.86176577980352
At time: 781.3517308235168 and batch: 1000, loss is 4.463545398712158 and perplexity is 86.79468601025084
At time: 782.493688583374 and batch: 1050, loss is 4.411205997467041 and perplexity is 82.36874012044387
At time: 783.6354787349701 and batch: 1100, loss is 4.39710563659668 and perplexity is 81.21546109340635
At time: 784.776398897171 and batch: 1150, loss is 4.401998062133789 and perplexity is 81.61377525596016
At time: 785.9180219173431 and batch: 1200, loss is 4.3875348758697506 and perplexity is 80.44187515590444
At time: 787.0592918395996 and batch: 1250, loss is 4.428190240859985 and perplexity is 83.77965862577254
At time: 788.2008135318756 and batch: 1300, loss is 4.395456800460815 and perplexity is 81.0816604443504
At time: 789.3432240486145 and batch: 1350, loss is 4.389229230880737 and perplexity is 80.57828778324244
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7794722493489585 and perplexity of 119.04150923013479
Finished 24 epochs...
Completing Train Step...
At time: 792.769876241684 and batch: 50, loss is 4.555417184829712 and perplexity is 95.1464406085576
At time: 793.9108273983002 and batch: 100, loss is 4.569518184661865 and perplexity is 96.49760454431537
At time: 795.0530042648315 and batch: 150, loss is 4.543437843322754 and perplexity is 94.01344870092821
At time: 796.1941828727722 and batch: 200, loss is 4.527602663040161 and perplexity is 92.53645389454802
At time: 797.3347456455231 and batch: 250, loss is 4.541461238861084 and perplexity is 93.82780483146131
At time: 798.4756689071655 and batch: 300, loss is 4.540674552917481 and perplexity is 93.75402084250003
At time: 799.6160523891449 and batch: 350, loss is 4.538697366714477 and perplexity is 93.56883481996695
At time: 800.7572746276855 and batch: 400, loss is 4.543025817871094 and perplexity is 93.97472074626447
At time: 801.8982894420624 and batch: 450, loss is 4.4947694969177245 and perplexity is 89.54752562539099
At time: 803.0403184890747 and batch: 500, loss is 4.566740093231201 and perplexity is 96.22989740568072
At time: 804.1809115409851 and batch: 550, loss is 4.543140020370483 and perplexity is 93.98545350709553
At time: 805.32200050354 and batch: 600, loss is 4.498277940750122 and perplexity is 89.86224986269951
At time: 806.4638288021088 and batch: 650, loss is 4.5059419536590575 and perplexity is 90.55360118440633
At time: 807.6048586368561 and batch: 700, loss is 4.511937818527222 and perplexity is 91.09817931739916
At time: 808.7461152076721 and batch: 750, loss is 4.476571016311645 and perplexity is 87.93263555841767
At time: 809.8875768184662 and batch: 800, loss is 4.455632905960083 and perplexity is 86.11063353530109
At time: 811.0286662578583 and batch: 850, loss is 4.437845878601074 and perplexity is 84.59252270471713
At time: 812.1702742576599 and batch: 900, loss is 4.463465452194214 and perplexity is 86.78774735469261
At time: 813.3112573623657 and batch: 950, loss is 4.4504892539978025 and perplexity is 85.66884757678308
At time: 814.4530951976776 and batch: 1000, loss is 4.462081375122071 and perplexity is 86.66770951341073
At time: 815.5943984985352 and batch: 1050, loss is 4.409669628143311 and perplexity is 82.24228847797407
At time: 816.7812285423279 and batch: 1100, loss is 4.395780487060547 and perplexity is 81.10790973936358
At time: 817.9221420288086 and batch: 1150, loss is 4.4001545715332036 and perplexity is 81.46345962369526
At time: 819.0636060237885 and batch: 1200, loss is 4.386461915969849 and perplexity is 80.3556105371036
At time: 820.204071521759 and batch: 1250, loss is 4.427090864181519 and perplexity is 83.68760383366698
At time: 821.3462500572205 and batch: 1300, loss is 4.394435338973999 and perplexity is 80.9988809361567
At time: 822.4871301651001 and batch: 1350, loss is 4.387985324859619 and perplexity is 80.47811827953791
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7790433756510415 and perplexity of 118.99046640411079
Finished 25 epochs...
Completing Train Step...
At time: 825.8842327594757 and batch: 50, loss is 4.552430305480957 and perplexity is 94.86267366976868
At time: 827.0508539676666 and batch: 100, loss is 4.566585683822632 and perplexity is 96.21503975124602
At time: 828.189202785492 and batch: 150, loss is 4.540539283752441 and perplexity is 93.74133967208654
At time: 829.3282659053802 and batch: 200, loss is 4.524913921356201 and perplexity is 92.28798146245938
At time: 830.467123746872 and batch: 250, loss is 4.538496475219727 and perplexity is 93.55003952484859
At time: 831.6063940525055 and batch: 300, loss is 4.537750396728516 and perplexity is 93.4802698825582
At time: 832.7451176643372 and batch: 350, loss is 4.5360761165618895 and perplexity is 93.32388867023491
At time: 833.8840622901917 and batch: 400, loss is 4.54013014793396 and perplexity is 93.70299457706507
At time: 835.0227048397064 and batch: 450, loss is 4.492126522064209 and perplexity is 89.31116625049769
At time: 836.1617441177368 and batch: 500, loss is 4.564076900482178 and perplexity is 95.97395959779969
At time: 837.300891160965 and batch: 550, loss is 4.540720663070679 and perplexity is 93.7583439544329
At time: 838.440954208374 and batch: 600, loss is 4.496104297637939 and perplexity is 89.66713353569288
At time: 839.5797505378723 and batch: 650, loss is 4.503608283996582 and perplexity is 90.34252537888973
At time: 840.7184932231903 and batch: 700, loss is 4.509721937179566 and perplexity is 90.8965400478987
At time: 841.8573560714722 and batch: 750, loss is 4.47443510055542 and perplexity is 87.74501929423698
At time: 842.9961407184601 and batch: 800, loss is 4.453729858398438 and perplexity is 85.94691673395936
At time: 844.1353833675385 and batch: 850, loss is 4.435932674407959 and perplexity is 84.43083465601823
At time: 845.3027694225311 and batch: 900, loss is 4.461598453521728 and perplexity is 86.62586590883792
At time: 846.4413685798645 and batch: 950, loss is 4.448596134185791 and perplexity is 85.50681960173912
At time: 847.5799081325531 and batch: 1000, loss is 4.460558242797852 and perplexity is 86.53580360416296
At time: 848.7186281681061 and batch: 1050, loss is 4.408232297897339 and perplexity is 82.12416406148131
At time: 849.8574767112732 and batch: 1100, loss is 4.394468441009521 and perplexity is 81.00156220836827
At time: 850.996595621109 and batch: 1150, loss is 4.398708009719849 and perplexity is 81.34570288555443
At time: 852.1356871128082 and batch: 1200, loss is 4.3854937076568605 and perplexity is 80.27784721860681
At time: 853.2742884159088 and batch: 1250, loss is 4.425989894866944 and perplexity is 83.59551705149828
At time: 854.4131052494049 and batch: 1300, loss is 4.3933767986297605 and perplexity is 80.91318571677299
At time: 855.5519754886627 and batch: 1350, loss is 4.386770210266113 and perplexity is 80.38038753261198
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.779059244791667 and perplexity of 118.992354695538
Annealing...
Finished 26 epochs...
Completing Train Step...
At time: 858.9432873725891 and batch: 50, loss is 4.550992774963379 and perplexity is 94.72640365101137
At time: 860.1094362735748 and batch: 100, loss is 4.5665468502044675 and perplexity is 96.21130344567823
At time: 861.2478423118591 and batch: 150, loss is 4.541403951644898 and perplexity is 93.82242985168196
At time: 862.3865010738373 and batch: 200, loss is 4.524699287414551 and perplexity is 92.26817545482795
At time: 863.5254883766174 and batch: 250, loss is 4.538149843215942 and perplexity is 93.51761770673846
At time: 864.6646294593811 and batch: 300, loss is 4.537793951034546 and perplexity is 93.48434143950672
At time: 865.8044602870941 and batch: 350, loss is 4.53589412689209 and perplexity is 93.30690623191241
At time: 866.9433887004852 and batch: 400, loss is 4.539942932128906 and perplexity is 93.68545353753058
At time: 868.0817692279816 and batch: 450, loss is 4.49064302444458 and perplexity is 89.17877157583199
At time: 869.2203736305237 and batch: 500, loss is 4.561924419403076 and perplexity is 95.76759963830824
At time: 870.3595383167267 and batch: 550, loss is 4.535939464569092 and perplexity is 93.31113664618707
At time: 871.4984395503998 and batch: 600, loss is 4.491180639266968 and perplexity is 89.22672829524004
At time: 872.6376559734344 and batch: 650, loss is 4.498582487106323 and perplexity is 89.88962125117199
At time: 873.7765438556671 and batch: 700, loss is 4.502816505432129 and perplexity is 90.27102241482885
At time: 874.960649728775 and batch: 750, loss is 4.467402229309082 and perplexity is 87.13008478327193
At time: 876.0989460945129 and batch: 800, loss is 4.446426372528077 and perplexity is 85.321491314908
At time: 877.238068819046 and batch: 850, loss is 4.426744375228882 and perplexity is 83.65861202642647
At time: 878.3774888515472 and batch: 900, loss is 4.4501808166503904 and perplexity is 85.64242817925455
At time: 879.5173072814941 and batch: 950, loss is 4.436854333877563 and perplexity is 84.50868700547208
At time: 880.6560316085815 and batch: 1000, loss is 4.4474379920959475 and perplexity is 85.40784787771187
At time: 881.7951321601868 and batch: 1050, loss is 4.395228624343872 and perplexity is 81.06316165648597
At time: 882.9339687824249 and batch: 1100, loss is 4.37974555015564 and perplexity is 79.81772121423707
At time: 884.0729920864105 and batch: 1150, loss is 4.383488750457763 and perplexity is 80.11705481570421
At time: 885.2120935916901 and batch: 1200, loss is 4.369535703659057 and perplexity is 79.00694054903411
At time: 886.3512148857117 and batch: 1250, loss is 4.408570861816406 and perplexity is 82.15197304761011
At time: 887.4904899597168 and batch: 1300, loss is 4.375594635009765 and perplexity is 79.48709130941145
At time: 888.6292579174042 and batch: 1350, loss is 4.370579986572266 and perplexity is 79.08948924166718
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.775623779296875 and perplexity of 118.58426196246256
Finished 27 epochs...
Completing Train Step...
At time: 892.0563764572144 and batch: 50, loss is 4.549060611724854 and perplexity is 94.54355348123283
At time: 893.1953203678131 and batch: 100, loss is 4.564017543792724 and perplexity is 95.96826307034941
At time: 894.3344008922577 and batch: 150, loss is 4.538623685836792 and perplexity is 93.56194084007379
At time: 895.4727864265442 and batch: 200, loss is 4.522766246795654 and perplexity is 92.089989599575
At time: 896.6110215187073 and batch: 250, loss is 4.53591106414795 and perplexity is 93.30848660824036
At time: 897.7491459846497 and batch: 300, loss is 4.535695638656616 and perplexity is 93.28838774664848
At time: 898.8876197338104 and batch: 350, loss is 4.533718996047973 and perplexity is 93.10417206879521
At time: 900.0265216827393 and batch: 400, loss is 4.5377544403076175 and perplexity is 93.48064787818815
At time: 901.1656632423401 and batch: 450, loss is 4.488786516189575 and perplexity is 89.01336403796809
At time: 902.3042387962341 and batch: 500, loss is 4.560177774429321 and perplexity is 95.60047363913318
At time: 903.4704043865204 and batch: 550, loss is 4.534458322525024 and perplexity is 93.17303190014125
At time: 904.6087100505829 and batch: 600, loss is 4.490036315917969 and perplexity is 89.1246824645459
At time: 905.7474384307861 and batch: 650, loss is 4.497383651733398 and perplexity is 89.78192296271486
At time: 906.8858230113983 and batch: 700, loss is 4.501756019592285 and perplexity is 90.17534201663052
At time: 908.0249276161194 and batch: 750, loss is 4.466355600357056 and perplexity is 87.03893961984899
At time: 909.1635589599609 and batch: 800, loss is 4.445465717315674 and perplexity is 85.23956613677151
At time: 910.3024432659149 and batch: 850, loss is 4.426072072982788 and perplexity is 83.60238705586077
At time: 911.4406008720398 and batch: 900, loss is 4.449693431854248 and perplexity is 85.60069753212282
At time: 912.5791738033295 and batch: 950, loss is 4.436151075363159 and perplexity is 84.44927644473428
At time: 913.7174024581909 and batch: 1000, loss is 4.447334308624267 and perplexity is 85.39899295459769
At time: 914.8562378883362 and batch: 1050, loss is 4.395162343978882 and perplexity is 81.05778893859893
At time: 915.9952263832092 and batch: 1100, loss is 4.3799940204620365 and perplexity is 79.83755601196013
At time: 917.1334557533264 and batch: 1150, loss is 4.3839437198638915 and perplexity is 80.15351391781356
At time: 918.271648645401 and batch: 1200, loss is 4.370195636749267 and perplexity is 79.0590970514667
At time: 919.4097592830658 and batch: 1250, loss is 4.4095455837249755 and perplexity is 82.23208741384288
At time: 920.5485153198242 and batch: 1300, loss is 4.376487874984742 and perplexity is 79.55812407679434
At time: 921.6871399879456 and batch: 1350, loss is 4.3715160369873045 and perplexity is 79.16355565043534
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.775137532552083 and perplexity of 118.52661476761598
Finished 28 epochs...
Completing Train Step...
At time: 925.112544298172 and batch: 50, loss is 4.548070516586304 and perplexity is 94.44999269323353
At time: 926.2517311573029 and batch: 100, loss is 4.562792768478394 and perplexity is 95.85079546117981
At time: 927.3910999298096 and batch: 150, loss is 4.5372464561462404 and perplexity is 93.43317324887154
At time: 928.530163526535 and batch: 200, loss is 4.521502466201782 and perplexity is 91.97368156722632
At time: 929.6693239212036 and batch: 250, loss is 4.5346918869018555 and perplexity is 93.1947963428748
At time: 930.8082218170166 and batch: 300, loss is 4.534404163360596 and perplexity is 93.16798586323206
At time: 931.9920933246613 and batch: 350, loss is 4.532414979934693 and perplexity is 92.9828418536747
At time: 933.131635427475 and batch: 400, loss is 4.536495294570923 and perplexity is 93.36301619220839
At time: 934.2710356712341 and batch: 450, loss is 4.487694025039673 and perplexity is 88.91617082656222
At time: 935.4105701446533 and batch: 500, loss is 4.559043140411377 and perplexity is 95.49206360409799
At time: 936.549946308136 and batch: 550, loss is 4.53356104850769 and perplexity is 93.08946765512039
At time: 937.6890916824341 and batch: 600, loss is 4.489337825775147 and perplexity is 89.062451488754
At time: 938.8280513286591 and batch: 650, loss is 4.496573219299316 and perplexity is 89.70919025680449
At time: 939.9672584533691 and batch: 700, loss is 4.501097221374511 and perplexity is 90.11595422645588
At time: 941.1068699359894 and batch: 750, loss is 4.465752964019775 and perplexity is 86.9865025938913
At time: 942.2461886405945 and batch: 800, loss is 4.444963340759277 and perplexity is 85.19675453174074
At time: 943.3861148357391 and batch: 850, loss is 4.425734033584595 and perplexity is 83.57413093136361
At time: 944.5253403186798 and batch: 900, loss is 4.449479017257691 and perplexity is 85.58234546064273
At time: 945.6647243499756 and batch: 950, loss is 4.435812740325928 and perplexity is 84.42070912857871
At time: 946.8040997982025 and batch: 1000, loss is 4.447307195663452 and perplexity is 85.39667756643671
At time: 947.9432418346405 and batch: 1050, loss is 4.395205917358399 and perplexity is 81.06132097735004
At time: 949.0826478004456 and batch: 1100, loss is 4.38023832321167 and perplexity is 79.85706292911762
At time: 950.2220640182495 and batch: 1150, loss is 4.384265518188476 and perplexity is 80.17931133486205
At time: 951.3608863353729 and batch: 1200, loss is 4.370818567276001 and perplexity is 79.10836071876415
At time: 952.4996089935303 and batch: 1250, loss is 4.410245485305786 and perplexity is 82.28966192771354
At time: 953.6389586925507 and batch: 1300, loss is 4.377077560424805 and perplexity is 79.60505217925072
At time: 954.7778759002686 and batch: 1350, loss is 4.372091312408447 and perplexity is 79.20910960002873
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.774677734375 and perplexity of 118.47212897340438
Finished 29 epochs...
Completing Train Step...
At time: 958.1754896640778 and batch: 50, loss is 4.54726508140564 and perplexity is 94.37394997415646
At time: 959.3441936969757 and batch: 100, loss is 4.561823806762695 and perplexity is 95.75796469195252
At time: 960.4847013950348 and batch: 150, loss is 4.53623067855835 and perplexity is 93.338314111569
At time: 961.6536753177643 and batch: 200, loss is 4.520491905212403 and perplexity is 91.8807835000721
At time: 962.7957215309143 and batch: 250, loss is 4.533718891143799 and perplexity is 93.10416230177944
At time: 963.9374387264252 and batch: 300, loss is 4.533376035690307 and perplexity is 93.07224650355685
At time: 965.0787887573242 and batch: 350, loss is 4.531420822143555 and perplexity is 92.89044817156297
At time: 966.2197904586792 and batch: 400, loss is 4.53552206993103 and perplexity is 93.27219720520179
At time: 967.3615074157715 and batch: 450, loss is 4.486865158081055 and perplexity is 88.84250168565332
At time: 968.5030655860901 and batch: 500, loss is 4.558165864944458 and perplexity is 95.40832749460033
At time: 969.6443185806274 and batch: 550, loss is 4.532848815917969 and perplexity is 93.02318990788417
At time: 970.7855443954468 and batch: 600, loss is 4.488812437057495 and perplexity is 89.01567137152439
At time: 971.9271376132965 and batch: 650, loss is 4.495935707092285 and perplexity is 89.65201777894555
At time: 973.0683147907257 and batch: 700, loss is 4.500524864196778 and perplexity is 90.06439047107646
At time: 974.2095539569855 and batch: 750, loss is 4.465274486541748 and perplexity is 86.94489146729511
At time: 975.351142168045 and batch: 800, loss is 4.44466537475586 and perplexity is 85.17137257695639
At time: 976.4921181201935 and batch: 850, loss is 4.425477571487427 and perplexity is 83.55270008269363
At time: 977.6338376998901 and batch: 900, loss is 4.449344387054444 and perplexity is 85.57082426764669
At time: 978.7751228809357 and batch: 950, loss is 4.435532760620117 and perplexity is 84.3970763517759
At time: 979.9157021045685 and batch: 1000, loss is 4.447259798049926 and perplexity is 85.39263006363879
At time: 981.0568103790283 and batch: 1050, loss is 4.395219144821167 and perplexity is 81.06239322004669
At time: 982.1981959342957 and batch: 1100, loss is 4.380416984558106 and perplexity is 79.87133157409262
At time: 983.3405442237854 and batch: 1150, loss is 4.384466209411621 and perplexity is 80.19540423372253
At time: 984.4822354316711 and batch: 1200, loss is 4.371304025650025 and perplexity is 79.14677385816603
At time: 985.6237318515778 and batch: 1250, loss is 4.410777254104614 and perplexity is 82.3334326393107
At time: 986.7659089565277 and batch: 1300, loss is 4.377491807937622 and perplexity is 79.63803520522019
At time: 987.907009601593 and batch: 1350, loss is 4.372477760314942 and perplexity is 79.23972570999375
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.774313557942708 and perplexity of 118.42899207134708
Finished 30 epochs...
Completing Train Step...
At time: 991.3057398796082 and batch: 50, loss is 4.546566467285157 and perplexity is 94.30804202489134
At time: 992.6483464241028 and batch: 100, loss is 4.560988597869873 and perplexity is 95.67802017811493
At time: 993.7893500328064 and batch: 150, loss is 4.535379457473755 and perplexity is 93.25889637641737
At time: 994.9304962158203 and batch: 200, loss is 4.519671144485474 and perplexity is 91.80540230061153
At time: 996.0712609291077 and batch: 250, loss is 4.532894344329834 and perplexity is 93.02742520239964
At time: 997.2121756076813 and batch: 300, loss is 4.532518510818481 and perplexity is 92.99246894781118
At time: 998.3544454574585 and batch: 350, loss is 4.530606622695923 and perplexity is 92.81484760111918
At time: 999.496414899826 and batch: 400, loss is 4.534740009307861 and perplexity is 93.19928120861243
At time: 1000.6376674175262 and batch: 450, loss is 4.486140041351319 and perplexity is 88.7781038521643
At time: 1001.7789978981018 and batch: 500, loss is 4.557432041168213 and perplexity is 95.33834027771559
At time: 1002.9199204444885 and batch: 550, loss is 4.532247457504273 and perplexity is 92.96726644667145
At time: 1004.0614249706268 and batch: 600, loss is 4.488323621749878 and perplexity is 88.97216978172781
At time: 1005.202944278717 and batch: 650, loss is 4.4954088687896725 and perplexity is 89.60479810173254
At time: 1006.3452501296997 and batch: 700, loss is 4.5000909900665285 and perplexity is 90.02532233793342
At time: 1007.4864416122437 and batch: 750, loss is 4.46487096786499 and perplexity is 86.9098146572893
At time: 1008.6273362636566 and batch: 800, loss is 4.444406042098999 and perplexity is 85.14928772240329
At time: 1009.7685866355896 and batch: 850, loss is 4.4252823638916015 and perplexity is 83.536391552812
At time: 1010.9095439910889 and batch: 900, loss is 4.449230499267578 and perplexity is 85.56107935077466
At time: 1012.0510296821594 and batch: 950, loss is 4.435367517471313 and perplexity is 84.38313146530987
At time: 1013.1924450397491 and batch: 1000, loss is 4.447229957580566 and perplexity is 85.39008194549649
At time: 1014.3334474563599 and batch: 1050, loss is 4.3952387428283695 and perplexity is 81.0639818969803
At time: 1015.474368095398 and batch: 1100, loss is 4.380552043914795 and perplexity is 79.88211967325343
At time: 1016.6156580448151 and batch: 1150, loss is 4.384666767120361 and perplexity is 80.21148965322064
At time: 1017.7564311027527 and batch: 1200, loss is 4.371691179275513 and perplexity is 79.1774217509495
At time: 1018.8985221385956 and batch: 1250, loss is 4.411161499023438 and perplexity is 82.36507492125536
At time: 1020.0399122238159 and batch: 1300, loss is 4.377801580429077 and perplexity is 79.66270869918786
At time: 1021.1812472343445 and batch: 1350, loss is 4.372731275558472 and perplexity is 79.25981673493735
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.774212239583333 and perplexity of 118.4169936480085
Finished 31 epochs...
Completing Train Step...
At time: 1024.6063973903656 and batch: 50, loss is 4.54592490196228 and perplexity is 94.24755666019075
At time: 1025.746898651123 and batch: 100, loss is 4.5602696514129635 and perplexity is 95.60925752579827
At time: 1026.8874595165253 and batch: 150, loss is 4.534620313644409 and perplexity is 93.18812632642376
At time: 1028.0285048484802 and batch: 200, loss is 4.518954782485962 and perplexity is 91.73965994952596
At time: 1029.1686661243439 and batch: 250, loss is 4.532173938751221 and perplexity is 92.96043186040588
At time: 1030.309195280075 and batch: 300, loss is 4.53176456451416 and perplexity is 92.92238404296562
At time: 1031.449562072754 and batch: 350, loss is 4.529899578094483 and perplexity is 92.74924655835379
At time: 1032.5905916690826 and batch: 400, loss is 4.53406286239624 and perplexity is 93.13619296559182
At time: 1033.7319915294647 and batch: 450, loss is 4.485499658584595 and perplexity is 88.72127008402006
At time: 1034.8726832866669 and batch: 500, loss is 4.556795883178711 and perplexity is 95.27770931832139
At time: 1036.0129487514496 and batch: 550, loss is 4.5317056846618655 and perplexity is 92.91691294778856
At time: 1037.153865814209 and batch: 600, loss is 4.4878848361968995 and perplexity is 88.93313864278664
At time: 1038.2946174144745 and batch: 650, loss is 4.4949462890625 and perplexity is 89.56335832401277
At time: 1039.434916973114 and batch: 700, loss is 4.499705743789673 and perplexity is 89.99064709736254
At time: 1040.6041650772095 and batch: 750, loss is 4.464507522583008 and perplexity is 86.878233434565
At time: 1041.7450678348541 and batch: 800, loss is 4.444175701141358 and perplexity is 85.12967661263447
At time: 1042.8855769634247 and batch: 850, loss is 4.425110015869141 and perplexity is 83.52199546152893
At time: 1044.0257017612457 and batch: 900, loss is 4.4491118144989015 and perplexity is 85.55092515645019
At time: 1045.1660664081573 and batch: 950, loss is 4.435217208862305 and perplexity is 84.37044890736826
At time: 1046.3079731464386 and batch: 1000, loss is 4.447185020446778 and perplexity is 85.38624484617468
At time: 1047.448755979538 and batch: 1050, loss is 4.3952327060699465 and perplexity is 81.06349253478186
At time: 1048.5903460979462 and batch: 1100, loss is 4.380640964508057 and perplexity is 79.889223154544
At time: 1049.7316272258759 and batch: 1150, loss is 4.384809465408325 and perplexity is 80.22293651217335
At time: 1050.8721873760223 and batch: 1200, loss is 4.37200457572937 and perplexity is 79.20223956285584
At time: 1052.012927532196 and batch: 1250, loss is 4.41146406173706 and perplexity is 82.3899992922338
At time: 1053.1534442901611 and batch: 1300, loss is 4.378031139373779 and perplexity is 79.68099808569478
At time: 1054.2942657470703 and batch: 1350, loss is 4.37290545463562 and perplexity is 79.27362333904703
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.774138997395833 and perplexity of 118.40832084596795
Finished 32 epochs...
Completing Train Step...
At time: 1057.7329297065735 and batch: 50, loss is 4.545326261520386 and perplexity is 94.19115314562113
At time: 1058.8711776733398 and batch: 100, loss is 4.5596129512786865 and perplexity is 95.5464915250192
At time: 1060.0101327896118 and batch: 150, loss is 4.5339327239990235 and perplexity is 93.1240731593596
At time: 1061.1482000350952 and batch: 200, loss is 4.518302402496338 and perplexity is 91.67983034905897
At time: 1062.287034034729 and batch: 250, loss is 4.53151759147644 and perplexity is 92.89943755320517
At time: 1063.4253914356232 and batch: 300, loss is 4.531082363128662 and perplexity is 92.85901388189129
At time: 1064.563730955124 and batch: 350, loss is 4.529266691207885 and perplexity is 92.69056534770827
At time: 1065.7024703025818 and batch: 400, loss is 4.533454275131225 and perplexity is 93.0795287089624
At time: 1066.8414483070374 and batch: 450, loss is 4.484919776916504 and perplexity is 88.66983715987479
At time: 1067.9805765151978 and batch: 500, loss is 4.556221332550049 and perplexity is 95.22298317351098
At time: 1069.1194269657135 and batch: 550, loss is 4.531202802658081 and perplexity is 92.87019845134415
At time: 1070.286145210266 and batch: 600, loss is 4.487481298446656 and perplexity is 88.8972580041796
At time: 1071.4245448112488 and batch: 650, loss is 4.4945234775543215 and perplexity is 89.5254979098757
At time: 1072.5627257823944 and batch: 700, loss is 4.49934684753418 and perplexity is 89.95835558608773
At time: 1073.7011060714722 and batch: 750, loss is 4.4641674041748045 and perplexity is 86.84868957259215
At time: 1074.8397164344788 and batch: 800, loss is 4.4439628791809085 and perplexity is 85.11156107572576
At time: 1075.978490114212 and batch: 850, loss is 4.424944982528687 and perplexity is 83.50821268495666
At time: 1077.1173841953278 and batch: 900, loss is 4.4489868640899655 and perplexity is 85.5402362011756
At time: 1078.255758523941 and batch: 950, loss is 4.435070724487304 and perplexity is 84.35809086004406
At time: 1079.394392490387 and batch: 1000, loss is 4.447123174667358 and perplexity is 85.38096423060404
At time: 1080.5330557823181 and batch: 1050, loss is 4.395202894210815 and perplexity is 81.0610759173838
At time: 1081.6719708442688 and batch: 1100, loss is 4.380691938400268 and perplexity is 79.89329552298526
At time: 1082.810307264328 and batch: 1150, loss is 4.384906234741211 and perplexity is 80.2307000078499
At time: 1083.9493291378021 and batch: 1200, loss is 4.372256450653076 and perplexity is 79.22219113344771
At time: 1085.0872068405151 and batch: 1250, loss is 4.411705017089844 and perplexity is 82.40985399553153
At time: 1086.2260394096375 and batch: 1300, loss is 4.378203001022339 and perplexity is 79.69469337019804
At time: 1087.364452123642 and batch: 1350, loss is 4.373022413253784 and perplexity is 79.2828956147153
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.774082438151042 and perplexity of 118.40162395015132
Finished 33 epochs...
Completing Train Step...
At time: 1090.7609467506409 and batch: 50, loss is 4.544761209487915 and perplexity is 94.13794527711825
At time: 1091.9268207550049 and batch: 100, loss is 4.559002132415771 and perplexity is 95.48814774626464
At time: 1093.065321445465 and batch: 150, loss is 4.53329626083374 and perplexity is 93.06482197459098
At time: 1094.2031407356262 and batch: 200, loss is 4.517696180343628 and perplexity is 91.62426884795269
At time: 1095.3415923118591 and batch: 250, loss is 4.530907278060913 and perplexity is 92.84275707835798
At time: 1096.4800086021423 and batch: 300, loss is 4.5304529666900635 and perplexity is 92.8005871379833
At time: 1097.6186826229095 and batch: 350, loss is 4.528688316345215 and perplexity is 92.6369709550232
At time: 1098.7853031158447 and batch: 400, loss is 4.532893009185791 and perplexity is 93.02730099747002
At time: 1099.9234533309937 and batch: 450, loss is 4.484383449554444 and perplexity is 88.62229385054498
At time: 1101.0621213912964 and batch: 500, loss is 4.555687656402588 and perplexity is 95.17217849652918
At time: 1102.2003457546234 and batch: 550, loss is 4.530728826522827 and perplexity is 92.82619062375582
At time: 1103.3389496803284 and batch: 600, loss is 4.487103366851807 and perplexity is 88.86366726958418
At time: 1104.4778261184692 and batch: 650, loss is 4.494126081466675 and perplexity is 89.4899278954221
At time: 1105.6161377429962 and batch: 700, loss is 4.499006576538086 and perplexity is 89.92775057411977
At time: 1106.7557561397552 and batch: 750, loss is 4.463845691680908 and perplexity is 86.82075375796936
At time: 1107.893696308136 and batch: 800, loss is 4.4437598133087155 and perplexity is 85.0942795770429
At time: 1109.0321958065033 and batch: 850, loss is 4.424779415130615 and perplexity is 83.49438759198871
At time: 1110.1706120967865 and batch: 900, loss is 4.4488570022583005 and perplexity is 85.5291285106696
At time: 1111.3091473579407 and batch: 950, loss is 4.434925689697265 and perplexity is 84.34585688924521
At time: 1112.447271823883 and batch: 1000, loss is 4.4470458984375 and perplexity is 85.37436656651118
At time: 1113.5856206417084 and batch: 1050, loss is 4.39515344619751 and perplexity is 81.05706770732313
At time: 1114.7240188121796 and batch: 1100, loss is 4.380711221694947 and perplexity is 79.89483614379974
At time: 1115.8631913661957 and batch: 1150, loss is 4.384965944290161 and perplexity is 80.2354906897826
At time: 1117.0032150745392 and batch: 1200, loss is 4.372456283569336 and perplexity is 79.23802391683735
At time: 1118.1424510478973 and batch: 1250, loss is 4.411897678375244 and perplexity is 82.42573271348992
At time: 1119.2812209129333 and batch: 1300, loss is 4.378331861495972 and perplexity is 79.70496352782622
At time: 1120.419959306717 and batch: 1350, loss is 4.373095407485962 and perplexity is 79.28868302002657
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.774039306640625 and perplexity of 118.39651721940587
Finished 34 epochs...
Completing Train Step...
At time: 1123.8400819301605 and batch: 50, loss is 4.544223356246948 and perplexity is 94.08732649211201
At time: 1125.0066504478455 and batch: 100, loss is 4.558426008224488 and perplexity is 95.43315055849354
At time: 1126.145616531372 and batch: 150, loss is 4.532697401046753 and perplexity is 93.0091058798567
At time: 1127.3118722438812 and batch: 200, loss is 4.517124910354614 and perplexity is 91.57194160081052
At time: 1128.4499583244324 and batch: 250, loss is 4.530331325531006 and perplexity is 92.78929945354005
At time: 1129.5882499217987 and batch: 300, loss is 4.529863176345825 and perplexity is 92.74587038504202
At time: 1130.7265920639038 and batch: 350, loss is 4.528150463104248 and perplexity is 92.5871592568542
At time: 1131.865385055542 and batch: 400, loss is 4.532363367080689 and perplexity is 92.97804286767897
At time: 1133.0050420761108 and batch: 450, loss is 4.483880453109741 and perplexity is 88.5777283608978
At time: 1134.1430642604828 and batch: 500, loss is 4.555183744430542 and perplexity is 95.12423217775564
At time: 1135.281506061554 and batch: 550, loss is 4.530277624130249 and perplexity is 92.78431667197647
At time: 1136.4197499752045 and batch: 600, loss is 4.4867442607879635 and perplexity is 88.8317615169298
At time: 1137.5583922863007 and batch: 650, loss is 4.493746013641357 and perplexity is 89.45592211579975
At time: 1138.6972551345825 and batch: 700, loss is 4.498679857254029 and perplexity is 89.89837424300354
At time: 1139.8369834423065 and batch: 750, loss is 4.463542070388794 and perplexity is 86.79439712995023
At time: 1140.9752736091614 and batch: 800, loss is 4.443562774658203 and perplexity is 85.07751436678018
At time: 1142.1138324737549 and batch: 850, loss is 4.424608888626099 and perplexity is 83.48015079983563
At time: 1143.2523415088654 and batch: 900, loss is 4.44872465133667 and perplexity is 85.51780940074882
At time: 1144.3913021087646 and batch: 950, loss is 4.4347834873199465 and perplexity is 84.3338635606387
At time: 1145.5302588939667 and batch: 1000, loss is 4.446953210830689 and perplexity is 85.36645378750508
At time: 1146.6698668003082 and batch: 1050, loss is 4.395089178085327 and perplexity is 81.05185848999763
At time: 1147.8086776733398 and batch: 1100, loss is 4.3807047080993655 and perplexity is 79.89431574284292
At time: 1148.9476664066315 and batch: 1150, loss is 4.384994354248047 and perplexity is 80.2377702090744
At time: 1150.0866730213165 and batch: 1200, loss is 4.372609958648682 and perplexity is 79.25020176214171
At time: 1151.225450515747 and batch: 1250, loss is 4.412053661346436 and perplexity is 82.43859072697074
At time: 1152.3644659519196 and batch: 1300, loss is 4.3784270858764645 and perplexity is 79.71255374498149
At time: 1153.503643989563 and batch: 1350, loss is 4.373134860992431 and perplexity is 79.29181129830545
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.774005126953125 and perplexity of 118.39247053260388
Finished 35 epochs...
Completing Train Step...
At time: 1156.9304728507996 and batch: 50, loss is 4.543707571029663 and perplexity is 94.03881015305434
At time: 1158.0700883865356 and batch: 100, loss is 4.557879962921143 and perplexity is 95.38105395969366
At time: 1159.2101862430573 and batch: 150, loss is 4.5321279144287105 and perplexity is 92.95615351796388
At time: 1160.3497548103333 and batch: 200, loss is 4.516580381393433 and perplexity is 91.52209160019358
At time: 1161.489287853241 and batch: 250, loss is 4.529782829284668 and perplexity is 92.73841882628155
At time: 1162.6285169124603 and batch: 300, loss is 4.529304237365722 and perplexity is 92.69404558763922
At time: 1163.7678499221802 and batch: 350, loss is 4.527643899917603 and perplexity is 92.54026988763543
At time: 1164.906977891922 and batch: 400, loss is 4.53185866355896 and perplexity is 92.93112836195424
At time: 1166.0476024150848 and batch: 450, loss is 4.4834032726287845 and perplexity is 88.53547088090066
At time: 1167.1875076293945 and batch: 500, loss is 4.554704208374023 and perplexity is 95.07862761396801
At time: 1168.327365398407 and batch: 550, loss is 4.529844512939453 and perplexity is 92.7441394473264
At time: 1169.4664623737335 and batch: 600, loss is 4.4863988876342775 and perplexity is 88.80108670873976
At time: 1170.6059279441833 and batch: 650, loss is 4.493385457992554 and perplexity is 89.42367409171499
At time: 1171.7454252243042 and batch: 700, loss is 4.498363676071167 and perplexity is 89.86995456181906
At time: 1172.8850798606873 and batch: 750, loss is 4.463249464035034 and perplexity is 86.76900425311895
At time: 1174.0245895385742 and batch: 800, loss is 4.443370409011841 and perplexity is 85.06114994976441
At time: 1175.1647264957428 and batch: 850, loss is 4.4244413089752195 and perplexity is 83.46616239742775
At time: 1176.3043134212494 and batch: 900, loss is 4.448586158752441 and perplexity is 85.5059666384136
At time: 1177.443351984024 and batch: 950, loss is 4.434635753631592 and perplexity is 84.3214055281799
At time: 1178.5826251506805 and batch: 1000, loss is 4.446842441558838 and perplexity is 85.35699833127521
At time: 1179.7222394943237 and batch: 1050, loss is 4.39501392364502 and perplexity is 81.04575920725298
At time: 1180.8625757694244 and batch: 1100, loss is 4.3806797122955325 and perplexity is 79.89231874515762
At time: 1182.0023350715637 and batch: 1150, loss is 4.384998626708985 and perplexity is 80.2381130225457
At time: 1183.1417059898376 and batch: 1200, loss is 4.372729940414429 and perplexity is 79.2597109117358
At time: 1184.2806510925293 and batch: 1250, loss is 4.412180528640747 and perplexity is 82.44905015138856
At time: 1185.4200413227081 and batch: 1300, loss is 4.37849139213562 and perplexity is 79.71767992594158
At time: 1186.5592420101166 and batch: 1350, loss is 4.373150110244751 and perplexity is 79.2930204483621
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.773978271484375 and perplexity of 118.38929109000414
Finished 36 epochs...
Completing Train Step...
At time: 1190.007125377655 and batch: 50, loss is 4.543207502365112 and perplexity is 93.99179604696549
At time: 1191.14790225029 and batch: 100, loss is 4.557357959747314 and perplexity is 95.3312777396063
At time: 1192.2890644073486 and batch: 150, loss is 4.531580867767334 and perplexity is 92.90531607102312
At time: 1193.4301245212555 and batch: 200, loss is 4.516060924530029 and perplexity is 91.4745621673726
At time: 1194.5720376968384 and batch: 250, loss is 4.529260730743408 and perplexity is 92.69001287053263
At time: 1195.713348865509 and batch: 300, loss is 4.528773593902588 and perplexity is 92.64487114647841
At time: 1196.8544030189514 and batch: 350, loss is 4.527163562774658 and perplexity is 92.49583003270115
At time: 1197.9957945346832 and batch: 400, loss is 4.53137848854065 and perplexity is 92.8865158674513
At time: 1199.137889623642 and batch: 450, loss is 4.482944412231445 and perplexity is 88.49485477882665
At time: 1200.27920794487 and batch: 500, loss is 4.554249696731567 and perplexity is 95.03542308999208
At time: 1201.419977426529 and batch: 550, loss is 4.529426851272583 and perplexity is 92.70541186352895
At time: 1202.561965227127 and batch: 600, loss is 4.486062812805176 and perplexity is 88.77124791301499
At time: 1203.7040572166443 and batch: 650, loss is 4.493044958114624 and perplexity is 89.39323052491225
At time: 1204.8455085754395 and batch: 700, loss is 4.4980548477172855 and perplexity is 89.84220445691845
At time: 1205.9869410991669 and batch: 750, loss is 4.462958898544311 and perplexity is 86.74379583734387
At time: 1207.1287868022919 and batch: 800, loss is 4.443175296783448 and perplexity is 85.04455509822989
At time: 1208.2705099582672 and batch: 850, loss is 4.424280643463135 and perplexity is 83.45275334091974
At time: 1209.4124488830566 and batch: 900, loss is 4.448438205718994 and perplexity is 85.49331670709256
At time: 1210.554485797882 and batch: 950, loss is 4.434474601745605 and perplexity is 84.30781806950168
At time: 1211.696251630783 and batch: 1000, loss is 4.4467118453979495 and perplexity is 85.34585176285357
At time: 1212.8377270698547 and batch: 1050, loss is 4.3949289226531985 and perplexity is 81.03887053011381
At time: 1214.0077533721924 and batch: 1100, loss is 4.380641069412231 and perplexity is 79.88923153525742
At time: 1215.1492969989777 and batch: 1150, loss is 4.3849876022338865 and perplexity is 80.23722844434278
At time: 1216.2907390594482 and batch: 1200, loss is 4.372828121185303 and perplexity is 79.26749307327543
At time: 1217.4320030212402 and batch: 1250, loss is 4.412277755737304 and perplexity is 82.4570668228612
At time: 1218.5736057758331 and batch: 1300, loss is 4.378527011871338 and perplexity is 79.72051949920468
At time: 1219.7152166366577 and batch: 1350, loss is 4.3731397533416745 and perplexity is 79.29219922248737
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.773950602213541 and perplexity of 118.38601538996349
Finished 37 epochs...
Completing Train Step...
At time: 1223.1183502674103 and batch: 50, loss is 4.542708406448364 and perplexity is 93.94489682992804
At time: 1224.2884781360626 and batch: 100, loss is 4.556848316192627 and perplexity is 95.28270514675204
At time: 1225.4297506809235 and batch: 150, loss is 4.531049585342407 and perplexity is 92.85597021886495
At time: 1226.572241783142 and batch: 200, loss is 4.51556092262268 and perplexity is 91.42883614431703
At time: 1227.713862657547 and batch: 250, loss is 4.528754863739014 and perplexity is 92.64313590913824
At time: 1228.8560881614685 and batch: 300, loss is 4.528262023925781 and perplexity is 92.59748893258713
At time: 1229.9977939128876 and batch: 350, loss is 4.526694583892822 and perplexity is 92.45246161198955
At time: 1231.1400995254517 and batch: 400, loss is 4.53090090751648 and perplexity is 92.84216562133265
At time: 1232.2816278934479 and batch: 450, loss is 4.482493734359741 and perplexity is 88.45498109178725
At time: 1233.4230806827545 and batch: 500, loss is 4.553819160461426 and perplexity is 94.99451570009307
At time: 1234.5661046504974 and batch: 550, loss is 4.52903341293335 and perplexity is 92.66894517441463
At time: 1235.7080645561218 and batch: 600, loss is 4.485739631652832 and perplexity is 88.74256335422352
At time: 1236.849934577942 and batch: 650, loss is 4.49272084236145 and perplexity is 89.36426146558985
At time: 1237.9922120571136 and batch: 700, loss is 4.497743577957153 and perplexity is 89.81424364739037
At time: 1239.1343269348145 and batch: 750, loss is 4.46267409324646 and perplexity is 86.71909426247034
At time: 1240.2756600379944 and batch: 800, loss is 4.442961273193359 and perplexity is 85.02635550487089
At time: 1241.4177205562592 and batch: 850, loss is 4.424133920669556 and perplexity is 83.44050981804162
At time: 1242.6041209697723 and batch: 900, loss is 4.4482624721527095 and perplexity is 85.47829398169134
At time: 1243.746230840683 and batch: 950, loss is 4.434297342300415 and perplexity is 84.29287503688141
At time: 1244.888738155365 and batch: 1000, loss is 4.446543598175049 and perplexity is 85.33149376818864
At time: 1246.030471086502 and batch: 1050, loss is 4.394825582504272 and perplexity is 81.03049639386413
At time: 1247.1719250679016 and batch: 1100, loss is 4.3806110191345216 and perplexity is 79.88683087773416
At time: 1248.3135187625885 and batch: 1150, loss is 4.3849557018280025 and perplexity is 80.2346688850141
At time: 1249.4553422927856 and batch: 1200, loss is 4.372902231216431 and perplexity is 79.2733678073402
At time: 1250.597068309784 and batch: 1250, loss is 4.41234564781189 and perplexity is 82.46266519423239
At time: 1251.7383739948273 and batch: 1300, loss is 4.378552169799804 and perplexity is 79.72252512756019
At time: 1252.8798158168793 and batch: 1350, loss is 4.373083658218384 and perplexity is 79.28775144154659
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.773907063802083 and perplexity of 118.38086116311878
Finished 38 epochs...
Completing Train Step...
At time: 1256.2811784744263 and batch: 50, loss is 4.542196140289307 and perplexity is 93.89678436271248
At time: 1257.4503026008606 and batch: 100, loss is 4.556350049972534 and perplexity is 95.23524081933579
At time: 1258.5915052890778 and batch: 150, loss is 4.530512065887451 and perplexity is 92.80607174026643
At time: 1259.7325685024261 and batch: 200, loss is 4.515066928863526 and perplexity is 91.3836820237001
At time: 1260.8732280731201 and batch: 250, loss is 4.5282465267181395 and perplexity is 92.59605394119326
At time: 1262.0138285160065 and batch: 300, loss is 4.52774715423584 and perplexity is 92.54982556343603
At time: 1263.1545934677124 and batch: 350, loss is 4.526208801269531 and perplexity is 92.40756071957762
At time: 1264.295832157135 and batch: 400, loss is 4.530420694351196 and perplexity is 92.79759229431369
At time: 1265.4371163845062 and batch: 450, loss is 4.482059602737427 and perplexity is 88.41658832170486
At time: 1266.578579902649 and batch: 500, loss is 4.553405418395996 and perplexity is 94.95522060254072
At time: 1267.7194538116455 and batch: 550, loss is 4.528621444702148 and perplexity is 92.63077637568989
At time: 1268.8604483604431 and batch: 600, loss is 4.4854440498352055 and perplexity is 88.71633654232177
At time: 1270.001298904419 and batch: 650, loss is 4.492453460693359 and perplexity is 89.34037029446439
At time: 1271.142620563507 and batch: 700, loss is 4.497424058914184 and perplexity is 89.78555087040363
At time: 1272.312177181244 and batch: 750, loss is 4.462403049468994 and perplexity is 86.69559277669264
At time: 1273.4530808925629 and batch: 800, loss is 4.442722301483155 and perplexity is 85.00603903891044
At time: 1274.593951702118 and batch: 850, loss is 4.423975963592529 and perplexity is 83.42733083988894
At time: 1275.7350342273712 and batch: 900, loss is 4.448076238632202 and perplexity is 85.46237654030276
At time: 1276.8760464191437 and batch: 950, loss is 4.43410551071167 and perplexity is 84.27670655160594
At time: 1278.0169157981873 and batch: 1000, loss is 4.446368837356568 and perplexity is 85.3165824694888
At time: 1279.1582989692688 and batch: 1050, loss is 4.394678707122803 and perplexity is 81.01859588276307
At time: 1280.2998428344727 and batch: 1100, loss is 4.380576543807983 and perplexity is 79.88407680062765
At time: 1281.4407958984375 and batch: 1150, loss is 4.38490460395813 and perplexity is 80.23056916908844
At time: 1282.5820348262787 and batch: 1200, loss is 4.372943143844605 and perplexity is 79.27661115550791
At time: 1283.722592830658 and batch: 1250, loss is 4.412387180328369 and perplexity is 82.46609014735647
At time: 1284.8639993667603 and batch: 1300, loss is 4.378553190231323 and perplexity is 79.7226064789791
At time: 1286.0051386356354 and batch: 1350, loss is 4.373026065826416 and perplexity is 79.28318520177888
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.773871663411458 and perplexity of 118.3766705085669
Finished 39 epochs...
Completing Train Step...
At time: 1289.4440732002258 and batch: 50, loss is 4.541723709106446 and perplexity is 93.85243507062826
At time: 1290.582688331604 and batch: 100, loss is 4.555846128463745 and perplexity is 95.1872618229317
At time: 1291.7212355136871 and batch: 150, loss is 4.5299725914001465 and perplexity is 92.75601873466931
At time: 1292.860517024994 and batch: 200, loss is 4.514610986709595 and perplexity is 91.34202584800899
At time: 1294.000004529953 and batch: 250, loss is 4.527769737243652 and perplexity is 92.55191564046979
At time: 1295.1383275985718 and batch: 300, loss is 4.527267436981202 and perplexity is 92.50543846267979
At time: 1296.277006149292 and batch: 350, loss is 4.525743436813355 and perplexity is 92.36456752986383
At time: 1297.4164943695068 and batch: 400, loss is 4.529983615875244 and perplexity is 92.75704132672473
At time: 1298.5556147098541 and batch: 450, loss is 4.481674766540527 and perplexity is 88.38256896447218
At time: 1299.6944324970245 and batch: 500, loss is 4.552959766387939 and perplexity is 94.91291304572779
At time: 1300.861340522766 and batch: 550, loss is 4.528232488632202 and perplexity is 92.5947540789544
At time: 1302.0006227493286 and batch: 600, loss is 4.4851741600036625 and perplexity is 88.6923961359787
At time: 1303.1393685340881 and batch: 650, loss is 4.492196292877197 and perplexity is 89.31739778056287
At time: 1304.277803182602 and batch: 700, loss is 4.497114171981812 and perplexity is 89.75773181207695
At time: 1305.416499376297 and batch: 750, loss is 4.462121181488037 and perplexity is 86.67115950863848
At time: 1306.5551030635834 and batch: 800, loss is 4.44249189376831 and perplexity is 84.98645524792244
At time: 1307.6941266059875 and batch: 850, loss is 4.423793659210205 and perplexity is 83.41212305813603
At time: 1308.8333020210266 and batch: 900, loss is 4.447930202484131 and perplexity is 85.44989685529255
At time: 1309.972312450409 and batch: 950, loss is 4.433901510238647 and perplexity is 84.25951581712322
At time: 1311.1108157634735 and batch: 1000, loss is 4.4462151622772215 and perplexity is 85.30347244427612
At time: 1312.249784708023 and batch: 1050, loss is 4.394547176361084 and perplexity is 81.00794014592718
At time: 1313.3893864154816 and batch: 1100, loss is 4.380524034500122 and perplexity is 79.8798822531731
At time: 1314.5281562805176 and batch: 1150, loss is 4.3848643970489505 and perplexity is 80.22734341072973
At time: 1315.6677763462067 and batch: 1200, loss is 4.372974710464478 and perplexity is 79.27911368965512
At time: 1316.805995464325 and batch: 1250, loss is 4.4124136161804195 and perplexity is 82.46827023753093
At time: 1317.9508097171783 and batch: 1300, loss is 4.378538827896119 and perplexity is 79.72146148440387
At time: 1319.089512348175 and batch: 1350, loss is 4.37299560546875 and perplexity is 79.28077024438119
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.773855794270833 and perplexity of 118.37479198744121
Finished 40 epochs...
Completing Train Step...
At time: 1322.5111610889435 and batch: 50, loss is 4.541266565322876 and perplexity is 93.80954081853018
At time: 1323.649015903473 and batch: 100, loss is 4.555360517501831 and perplexity is 95.14104906677451
At time: 1324.787005662918 and batch: 150, loss is 4.529486522674561 and perplexity is 92.71094389047605
At time: 1325.925445318222 and batch: 200, loss is 4.514171695709228 and perplexity is 91.30190893024427
At time: 1327.0641028881073 and batch: 250, loss is 4.5273202419281 and perplexity is 92.51032333641726
At time: 1328.2027006149292 and batch: 300, loss is 4.526810331344604 and perplexity is 92.4631633681707
At time: 1329.3692181110382 and batch: 350, loss is 4.525327157974243 and perplexity is 92.32612611664602
At time: 1330.507609128952 and batch: 400, loss is 4.529573459625244 and perplexity is 92.71900424759917
At time: 1331.6463677883148 and batch: 450, loss is 4.481300497055054 and perplexity is 88.34949625530005
At time: 1332.7850377559662 and batch: 500, loss is 4.552544164657593 and perplexity is 94.87347527060518
At time: 1333.9236702919006 and batch: 550, loss is 4.527862281799316 and perplexity is 92.56048121272102
At time: 1335.0624024868011 and batch: 600, loss is 4.484893455505371 and perplexity is 88.66750327535148
At time: 1336.2017397880554 and batch: 650, loss is 4.491901712417603 and perplexity is 89.2910904954712
At time: 1337.340885400772 and batch: 700, loss is 4.496823043823242 and perplexity is 89.73160461226342
At time: 1338.4796767234802 and batch: 750, loss is 4.461844358444214 and perplexity is 86.64717025499395
At time: 1339.6250281333923 and batch: 800, loss is 4.442297000885009 and perplexity is 84.96989360654307
At time: 1340.7639582157135 and batch: 850, loss is 4.423625926971436 and perplexity is 83.39813332929205
At time: 1341.9031600952148 and batch: 900, loss is 4.44777027130127 and perplexity is 85.43623184497285
At time: 1343.041949748993 and batch: 950, loss is 4.433728713989257 and perplexity is 84.24495734667536
At time: 1344.1810631752014 and batch: 1000, loss is 4.446075201034546 and perplexity is 85.29153409974055
At time: 1345.3205506801605 and batch: 1050, loss is 4.394432830810547 and perplexity is 80.99867777797866
At time: 1346.4592583179474 and batch: 1100, loss is 4.380453481674194 and perplexity is 79.87424670054975
At time: 1347.597410440445 and batch: 1150, loss is 4.384807195663452 and perplexity is 80.22275442678115
At time: 1348.7360484600067 and batch: 1200, loss is 4.373003005981445 and perplexity is 79.28135696489888
At time: 1349.8744721412659 and batch: 1250, loss is 4.412437171936035 and perplexity is 82.47021286283058
At time: 1351.0128619670868 and batch: 1300, loss is 4.378520183563232 and perplexity is 79.71997514479371
At time: 1352.1583123207092 and batch: 1350, loss is 4.372945289611817 and perplexity is 79.27678126484331
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.773846028645833 and perplexity of 118.37363598925772
Finished 41 epochs...
Completing Train Step...
At time: 1355.575612783432 and batch: 50, loss is 4.540828676223755 and perplexity is 93.76847163574215
At time: 1356.742097377777 and batch: 100, loss is 4.5549062156677245 and perplexity is 95.09783613028604
At time: 1357.8804471492767 and batch: 150, loss is 4.52902847290039 and perplexity is 92.66848738790189
At time: 1359.046808719635 and batch: 200, loss is 4.513734512329101 and perplexity is 91.26200197705008
At time: 1360.1849858760834 and batch: 250, loss is 4.526874570846558 and perplexity is 92.46910334652308
At time: 1361.3232181072235 and batch: 300, loss is 4.526363716125489 and perplexity is 92.42187713241975
At time: 1362.4614753723145 and batch: 350, loss is 4.524932708740234 and perplexity is 92.28971532849613
At time: 1363.6004829406738 and batch: 400, loss is 4.529176445007324 and perplexity is 92.68220075379983
At time: 1364.7390525341034 and batch: 450, loss is 4.480916299819946 and perplexity is 88.31555914280545
At time: 1365.8777222633362 and batch: 500, loss is 4.552148523330689 and perplexity is 94.83594682735223
At time: 1367.0157661437988 and batch: 550, loss is 4.527498025894165 and perplexity is 92.52677165068185
At time: 1368.1546003818512 and batch: 600, loss is 4.484606781005859 and perplexity is 88.64208820632724
At time: 1369.292652130127 and batch: 650, loss is 4.491602087020874 and perplexity is 89.26434062472764
At time: 1370.4313509464264 and batch: 700, loss is 4.496537570953369 and perplexity is 89.70599232955632
At time: 1371.5699591636658 and batch: 750, loss is 4.461571960449219 and perplexity is 86.62357095389157
At time: 1372.7082681655884 and batch: 800, loss is 4.442109642028808 and perplexity is 84.95397523573585
At time: 1373.8465673923492 and batch: 850, loss is 4.423462371826172 and perplexity is 83.38449425088179
At time: 1374.9850685596466 and batch: 900, loss is 4.4476070308685305 and perplexity is 85.42228633578131
At time: 1376.1235477924347 and batch: 950, loss is 4.433556098937988 and perplexity is 84.23041665405108
At time: 1377.261875629425 and batch: 1000, loss is 4.445933246612549 and perplexity is 85.27942744863286
At time: 1378.400229215622 and batch: 1050, loss is 4.394313564300537 and perplexity is 80.98901792442466
At time: 1379.5386743545532 and batch: 1100, loss is 4.380373945236206 and perplexity is 79.86789404011758
At time: 1380.676649093628 and batch: 1150, loss is 4.3847403049469 and perplexity is 80.21738844872279
At time: 1381.8141191005707 and batch: 1200, loss is 4.373018074035644 and perplexity is 79.28255158968291
At time: 1382.9520738124847 and batch: 1250, loss is 4.412450742721558 and perplexity is 82.47133205599552
At time: 1384.0904712677002 and batch: 1300, loss is 4.378492269515991 and perplexity is 79.71774986869985
At time: 1385.2297644615173 and batch: 1350, loss is 4.372883243560791 and perplexity is 79.27186260622103
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.773839925130209 and perplexity of 118.37291349612582
Finished 42 epochs...
Completing Train Step...
At time: 1388.626100063324 and batch: 50, loss is 4.540401229858398 and perplexity is 93.72839920837328
At time: 1389.792946100235 and batch: 100, loss is 4.554464130401612 and perplexity is 95.05580406965554
At time: 1390.9322636127472 and batch: 150, loss is 4.528581991195678 and perplexity is 92.62712183884747
At time: 1392.071682691574 and batch: 200, loss is 4.51330493927002 and perplexity is 91.22280669890338
At time: 1393.2106909751892 and batch: 250, loss is 4.5264372062683105 and perplexity is 92.42866947895229
At time: 1394.3493509292603 and batch: 300, loss is 4.52592770576477 and perplexity is 92.38158902008844
At time: 1395.487919330597 and batch: 350, loss is 4.524547834396362 and perplexity is 92.25420221934358
At time: 1396.6265873908997 and batch: 400, loss is 4.52878846168518 and perplexity is 92.6462485805206
At time: 1397.765706539154 and batch: 450, loss is 4.480536556243896 and perplexity is 88.28202824353043
At time: 1398.9050161838531 and batch: 500, loss is 4.551761369705201 and perplexity is 94.79923785317615
At time: 1400.0439603328705 and batch: 550, loss is 4.527139205932617 and perplexity is 92.4935771538162
At time: 1401.1828575134277 and batch: 600, loss is 4.48432204246521 and perplexity is 88.61685198052479
At time: 1402.3221447467804 and batch: 650, loss is 4.491304874420166 and perplexity is 89.23781408010697
At time: 1403.46080160141 and batch: 700, loss is 4.496255283355713 and perplexity is 89.68067301431871
At time: 1404.6000537872314 and batch: 750, loss is 4.461300811767578 and perplexity is 86.6000862708927
At time: 1405.7405650615692 and batch: 800, loss is 4.441923522949219 and perplexity is 84.93816515138236
At time: 1406.8807384967804 and batch: 850, loss is 4.423298311233521 and perplexity is 83.37081526345911
At time: 1408.0194642543793 and batch: 900, loss is 4.447440519332885 and perplexity is 85.40806372385256
At time: 1409.1586756706238 and batch: 950, loss is 4.433381967544555 and perplexity is 84.21575077116208
At time: 1410.2975192070007 and batch: 1000, loss is 4.445787391662598 and perplexity is 85.26698992906938
At time: 1411.4365921020508 and batch: 1050, loss is 4.394189109802246 and perplexity is 80.97893910402207
At time: 1412.5764365196228 and batch: 1100, loss is 4.38028917312622 and perplexity is 79.8611237571893
At time: 1413.7162518501282 and batch: 1150, loss is 4.3846659660339355 and perplexity is 80.21142539691084
At time: 1414.8551099300385 and batch: 1200, loss is 4.373022441864014 and perplexity is 79.2828978830172
At time: 1416.0387902259827 and batch: 1250, loss is 4.412454023361206 and perplexity is 82.47160261516109
At time: 1417.1775994300842 and batch: 1300, loss is 4.378455352783203 and perplexity is 79.7148070041503
At time: 1418.3174631595612 and batch: 1350, loss is 4.372813577651978 and perplexity is 79.26634025223139
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7738350423177085 and perplexity of 118.37233550479523
Finished 43 epochs...
Completing Train Step...
At time: 1421.7406678199768 and batch: 50, loss is 4.539981384277343 and perplexity is 93.68905601375741
At time: 1422.8815746307373 and batch: 100, loss is 4.554031019210815 and perplexity is 95.01464325141175
At time: 1424.0230770111084 and batch: 150, loss is 4.528144512176514 and perplexity is 92.58660827899973
At time: 1425.1641826629639 and batch: 200, loss is 4.512882890701294 and perplexity is 91.1843143672891
At time: 1426.3057115077972 and batch: 250, loss is 4.526008358001709 and perplexity is 92.38904010236405
At time: 1427.4472541809082 and batch: 300, loss is 4.525501098632812 and perplexity is 92.34218678058662
At time: 1428.5887377262115 and batch: 350, loss is 4.5241713714599605 and perplexity is 92.21947846799351
At time: 1429.7301516532898 and batch: 400, loss is 4.5284084033966066 and perplexity is 92.6110442961061
At time: 1430.8712050914764 and batch: 450, loss is 4.480163087844849 and perplexity is 88.24906385174015
At time: 1432.012351989746 and batch: 500, loss is 4.551380815505982 and perplexity is 94.76316846874154
At time: 1433.155636548996 and batch: 550, loss is 4.52678599357605 and perplexity is 92.46091304848484
At time: 1434.2978603839874 and batch: 600, loss is 4.484040803909302 and perplexity is 88.5919330092967
At time: 1435.4393241405487 and batch: 650, loss is 4.491010589599609 and perplexity is 89.2115566097805
At time: 1436.5805547237396 and batch: 700, loss is 4.49597583770752 and perplexity is 89.65561564176777
At time: 1437.7216742038727 and batch: 750, loss is 4.461030759811401 and perplexity is 86.57670290569405
At time: 1438.8623723983765 and batch: 800, loss is 4.441737756729126 and perplexity is 84.92238797497915
At time: 1440.0043795108795 and batch: 850, loss is 4.423133859634399 and perplexity is 83.35710592686102
At time: 1441.1464612483978 and batch: 900, loss is 4.447271003723144 and perplexity is 85.39358695090776
At time: 1442.288100719452 and batch: 950, loss is 4.433205509185791 and perplexity is 84.20089150905798
At time: 1443.4293949604034 and batch: 1000, loss is 4.445638227462768 and perplexity is 85.2542720952911
At time: 1444.570252418518 and batch: 1050, loss is 4.394060010910034 and perplexity is 80.96848548748092
At time: 1445.7392208576202 and batch: 1100, loss is 4.380199108123779 and perplexity is 79.85393138877838
At time: 1446.880680322647 and batch: 1150, loss is 4.3845849609375 and perplexity is 80.20492812582089
At time: 1448.0222046375275 and batch: 1200, loss is 4.373017835617065 and perplexity is 79.28253268725186
At time: 1449.1636898517609 and batch: 1250, loss is 4.412448444366455 and perplexity is 82.47114250780649
At time: 1450.3049137592316 and batch: 1300, loss is 4.378410148620605 and perplexity is 79.71120364449706
At time: 1451.4459290504456 and batch: 1350, loss is 4.372737712860108 and perplexity is 79.26032695592748
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.773831380208334 and perplexity of 118.37190201314941
Finished 44 epochs...
Completing Train Step...
At time: 1454.8767533302307 and batch: 50, loss is 4.53956820487976 and perplexity is 93.65035362209956
At time: 1456.0191040039062 and batch: 100, loss is 4.553605461120606 and perplexity is 94.97421760362857
At time: 1457.1603565216064 and batch: 150, loss is 4.527715225219726 and perplexity is 92.54687058573931
At time: 1458.301837682724 and batch: 200, loss is 4.512467412948609 and perplexity is 91.14643718238429
At time: 1459.4430570602417 and batch: 250, loss is 4.525587396621704 and perplexity is 92.35015606945751
At time: 1460.584923028946 and batch: 300, loss is 4.525082635879516 and perplexity is 92.30355309880323
At time: 1461.726350069046 and batch: 350, loss is 4.523802995681763 and perplexity is 92.18551330220416
At time: 1462.8679594993591 and batch: 400, loss is 4.528035774230957 and perplexity is 92.57654114877883
At time: 1464.009759902954 and batch: 450, loss is 4.479796028137207 and perplexity is 88.21667712045871
At time: 1465.1509788036346 and batch: 500, loss is 4.551005802154541 and perplexity is 94.72763767801779
At time: 1466.2937109470367 and batch: 550, loss is 4.526437873840332 and perplexity is 92.42873118176662
At time: 1467.4359934329987 and batch: 600, loss is 4.483763256072998 and perplexity is 88.56734792190271
At time: 1468.5783305168152 and batch: 650, loss is 4.490718774795532 and perplexity is 89.18552715494182
At time: 1469.7208380699158 and batch: 700, loss is 4.495698852539062 and perplexity is 89.6307858048731
At time: 1470.8627758026123 and batch: 750, loss is 4.460761213302613 and perplexity is 86.55336960252986
At time: 1472.0050172805786 and batch: 800, loss is 4.441551914215088 and perplexity is 84.90660725130985
At time: 1473.1463680267334 and batch: 850, loss is 4.42296877861023 and perplexity is 83.34334638619359
At time: 1474.3329780101776 and batch: 900, loss is 4.447099208831787 and perplexity is 85.37891802897394
At time: 1475.4749941825867 and batch: 950, loss is 4.433027133941651 and perplexity is 84.18587349393907
At time: 1476.6172630786896 and batch: 1000, loss is 4.4454862499237064 and perplexity is 85.24131634533998
At time: 1477.7590806484222 and batch: 1050, loss is 4.393926229476929 and perplexity is 80.95765413198929
At time: 1478.9010083675385 and batch: 1100, loss is 4.38010404586792 and perplexity is 79.8463406547232
At time: 1480.042465686798 and batch: 1150, loss is 4.384498014450073 and perplexity is 80.19795489219952
At time: 1481.1848683357239 and batch: 1200, loss is 4.373005285263061 and perplexity is 79.28153766964422
At time: 1482.3266308307648 and batch: 1250, loss is 4.41243543624878 and perplexity is 82.4700697204574
At time: 1483.4690985679626 and batch: 1300, loss is 4.378357028961181 and perplexity is 79.70696952496567
At time: 1484.6108679771423 and batch: 1350, loss is 4.372656087875367 and perplexity is 79.25385759698338
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.773829345703125 and perplexity of 118.37166118514317
Finished 45 epochs...
Completing Train Step...
At time: 1488.0145299434662 and batch: 50, loss is 4.53916090965271 and perplexity is 93.61221804680382
At time: 1489.1835796833038 and batch: 100, loss is 4.553186807632446 and perplexity is 94.93446463808309
At time: 1490.3249113559723 and batch: 150, loss is 4.527293386459351 and perplexity is 92.50783896167958
At time: 1491.4661478996277 and batch: 200, loss is 4.512057962417603 and perplexity is 91.10912486457615
At time: 1492.6068816184998 and batch: 250, loss is 4.525173807144165 and perplexity is 92.31196891410528
At time: 1493.7478594779968 and batch: 300, loss is 4.524671678543091 and perplexity is 92.26562806979733
At time: 1494.8884148597717 and batch: 350, loss is 4.523441772460938 and perplexity is 92.15221976773664
At time: 1496.0299694538116 and batch: 400, loss is 4.5276698398590085 and perplexity is 92.5426704079485
At time: 1497.1713128089905 and batch: 450, loss is 4.479434709548951 and perplexity is 88.18480855292053
At time: 1498.3124012947083 and batch: 500, loss is 4.550635795593262 and perplexity is 94.69259431407957
At time: 1499.4533586502075 and batch: 550, loss is 4.526094541549683 and perplexity is 92.39700286075842
At time: 1500.594527721405 and batch: 600, loss is 4.48348970413208 and perplexity is 88.54312346545133
At time: 1501.7351322174072 and batch: 650, loss is 4.490428676605225 and perplexity is 89.15965834734115
At time: 1502.9046874046326 and batch: 700, loss is 4.4954243183135985 and perplexity is 89.60618246389855
At time: 1504.0469281673431 and batch: 750, loss is 4.460492258071899 and perplexity is 86.53009375126067
At time: 1505.1882815361023 and batch: 800, loss is 4.441366138458252 and perplexity is 84.8908351271719
At time: 1506.3297822475433 and batch: 850, loss is 4.422803430557251 and perplexity is 83.32956686537979
At time: 1507.4752442836761 and batch: 900, loss is 4.446925277709961 and perplexity is 85.36406926934902
At time: 1508.6184422969818 and batch: 950, loss is 4.432846393585205 and perplexity is 84.17065908412641
At time: 1509.7593417167664 and batch: 1000, loss is 4.445331830978393 and perplexity is 85.22815448741908
At time: 1510.9011261463165 and batch: 1050, loss is 4.393788156509399 and perplexity is 80.94647684009774
At time: 1512.0418887138367 and batch: 1100, loss is 4.38000415802002 and perplexity is 79.83836537391592
At time: 1513.1834795475006 and batch: 1150, loss is 4.3844058799743655 and perplexity is 80.19056623605292
At time: 1514.3237857818604 and batch: 1200, loss is 4.372986192703247 and perplexity is 79.28002399659411
At time: 1515.4638240337372 and batch: 1250, loss is 4.412416019439697 and perplexity is 82.46846843040466
At time: 1516.6043632030487 and batch: 1300, loss is 4.3782972145080565 and perplexity is 79.70220203875702
At time: 1517.74582862854 and batch: 1350, loss is 4.372569465637207 and perplexity is 79.24699274778418
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.773829345703125 and perplexity of 118.37166118514317
Finished 46 epochs...
Completing Train Step...
At time: 1521.1476135253906 and batch: 50, loss is 4.538758745193482 and perplexity is 93.57457810898576
At time: 1522.3144178390503 and batch: 100, loss is 4.552774238586426 and perplexity is 94.89530569501218
At time: 1523.453059911728 and batch: 150, loss is 4.526878213882446 and perplexity is 92.46944021539873
At time: 1524.5923748016357 and batch: 200, loss is 4.511653747558594 and perplexity is 91.07230464465589
At time: 1525.7326164245605 and batch: 250, loss is 4.524767055511474 and perplexity is 92.2744285053614
At time: 1526.8712055683136 and batch: 300, loss is 4.524267292022705 and perplexity is 92.22832463652209
At time: 1528.0093393325806 and batch: 350, loss is 4.523087081909179 and perplexity is 92.11954004199903
At time: 1529.1483299732208 and batch: 400, loss is 4.527310266494751 and perplexity is 92.50940051045546
At time: 1530.2874381542206 and batch: 450, loss is 4.47907901763916 and perplexity is 88.15344750771749
At time: 1531.4267749786377 and batch: 500, loss is 4.550270404815674 and perplexity is 94.65800083386547
At time: 1532.6099281311035 and batch: 550, loss is 4.525755834579468 and perplexity is 92.36571265126767
At time: 1533.7489793300629 and batch: 600, loss is 4.483219804763794 and perplexity is 88.51922895706335
At time: 1534.8878574371338 and batch: 650, loss is 4.490140027999878 and perplexity is 89.13392625025163
At time: 1536.0267295837402 and batch: 700, loss is 4.495151739120484 and perplexity is 89.58176101152554
At time: 1537.1654527187347 and batch: 750, loss is 4.460223379135132 and perplexity is 86.5068307592589
At time: 1538.3049974441528 and batch: 800, loss is 4.441180067062378 and perplexity is 84.8750408404609
At time: 1539.4445946216583 and batch: 850, loss is 4.422637777328491 and perplexity is 83.31576419683724
At time: 1540.5835320949554 and batch: 900, loss is 4.446749505996704 and perplexity is 85.3490659992568
At time: 1541.7224698066711 and batch: 950, loss is 4.432663164138794 and perplexity is 84.15523795370413
At time: 1542.8611974716187 and batch: 1000, loss is 4.445175065994262 and perplexity is 85.21479474433067
At time: 1544.0007791519165 and batch: 1050, loss is 4.393645544052124 and perplexity is 80.93493368724604
At time: 1545.1395163536072 and batch: 1100, loss is 4.379899692535401 and perplexity is 79.83002545601029
At time: 1546.278818845749 and batch: 1150, loss is 4.384309396743775 and perplexity is 80.1828295643951
At time: 1547.4171435832977 and batch: 1200, loss is 4.372961349487305 and perplexity is 79.27805445030309
At time: 1548.5553328990936 and batch: 1250, loss is 4.4123910045623775 and perplexity is 82.46640551758598
At time: 1549.6943836212158 and batch: 1300, loss is 4.3782307815551755 and perplexity is 79.69690736199692
At time: 1550.8335828781128 and batch: 1350, loss is 4.372478075027466 and perplexity is 79.2397506477318
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.773826904296875 and perplexity of 118.37137219218255
Finished 47 epochs...
Completing Train Step...
At time: 1554.2550194263458 and batch: 50, loss is 4.538361225128174 and perplexity is 93.53738772903561
At time: 1555.3929314613342 and batch: 100, loss is 4.552366867065429 and perplexity is 94.85665592293853
At time: 1556.5315108299255 and batch: 150, loss is 4.526469421386719 and perplexity is 92.43164712744627
At time: 1557.670333623886 and batch: 200, loss is 4.511253995895386 and perplexity is 91.03590561517301
At time: 1558.8091616630554 and batch: 250, loss is 4.524366865158081 and perplexity is 92.23750855720495
At time: 1559.9483087062836 and batch: 300, loss is 4.523869495391846 and perplexity is 92.19164381594908
At time: 1561.1203560829163 and batch: 350, loss is 4.52273811340332 and perplexity is 92.08739883221128
At time: 1562.2586364746094 and batch: 400, loss is 4.526956911087036 and perplexity is 92.47671758820441
At time: 1563.3968873023987 and batch: 450, loss is 4.478728265762329 and perplexity is 88.12253294254285
At time: 1564.535401582718 and batch: 500, loss is 4.549909219741822 and perplexity is 94.62381795038885
At time: 1565.6738555431366 and batch: 550, loss is 4.525421257019043 and perplexity is 92.33481432569334
At time: 1566.8128674030304 and batch: 600, loss is 4.482953567504882 and perplexity is 88.49566497712873
At time: 1567.95170545578 and batch: 650, loss is 4.489852418899536 and perplexity is 89.10829420809385
At time: 1569.0895025730133 and batch: 700, loss is 4.494880752563477 and perplexity is 89.55748884740203
At time: 1570.2283594608307 and batch: 750, loss is 4.4599544715881345 and perplexity is 86.4835715470299
At time: 1571.3667504787445 and batch: 800, loss is 4.440993680953979 and perplexity is 84.85922278607704
At time: 1572.506219625473 and batch: 850, loss is 4.422471694946289 and perplexity is 83.30192806524506
At time: 1573.644769191742 and batch: 900, loss is 4.446572341918945 and perplexity is 85.33394655004268
At time: 1574.7838025093079 and batch: 950, loss is 4.432477197647095 and perplexity is 84.13958935444641
At time: 1575.9219663143158 and batch: 1000, loss is 4.445015964508056 and perplexity is 85.201238022316
At time: 1577.0607273578644 and batch: 1050, loss is 4.393498754501342 and perplexity is 80.92305415660441
At time: 1578.1993496418 and batch: 1100, loss is 4.379790773391724 and perplexity is 79.8213309115077
At time: 1579.3382403850555 and batch: 1150, loss is 4.384208698272705 and perplexity is 80.1747556825725
At time: 1580.477399110794 and batch: 1200, loss is 4.372930965423584 and perplexity is 79.27564569743903
At time: 1581.6162536144257 and batch: 1250, loss is 4.4123606300354 and perplexity is 82.46390067756873
At time: 1582.7548899650574 and batch: 1300, loss is 4.378158836364746 and perplexity is 79.69117375907518
At time: 1583.8930990695953 and batch: 1350, loss is 4.37238187789917 and perplexity is 79.2321283778987
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.773827311197917 and perplexity of 118.37142035762702
Annealing...
Finished 48 epochs...
Completing Train Step...
At time: 1587.3297312259674 and batch: 50, loss is 4.538171224594116 and perplexity is 93.51961726366513
At time: 1588.468460559845 and batch: 100, loss is 4.552439870834351 and perplexity is 94.863581069106
At time: 1589.6349663734436 and batch: 150, loss is 4.526629047393799 and perplexity is 92.44640279986825
At time: 1590.7734110355377 and batch: 200, loss is 4.511188650131226 and perplexity is 91.02995699871518
At time: 1591.9116234779358 and batch: 250, loss is 4.524262685775756 and perplexity is 92.22789981106162
At time: 1593.050125360489 and batch: 300, loss is 4.523913421630859 and perplexity is 92.19569353707422
At time: 1594.1890366077423 and batch: 350, loss is 4.522871370315552 and perplexity is 92.09967093228805
At time: 1595.3284451961517 and batch: 400, loss is 4.52739688873291 and perplexity is 92.51741422885655
At time: 1596.467316865921 and batch: 450, loss is 4.479077472686767 and perplexity is 88.15331131494305
At time: 1597.6061463356018 and batch: 500, loss is 4.549778718948364 and perplexity is 94.61147027277472
At time: 1598.7450671195984 and batch: 550, loss is 4.525177011489868 and perplexity is 92.3122647140401
At time: 1599.8840186595917 and batch: 600, loss is 4.481674365997314 and perplexity is 88.38253356344114
At time: 1601.0228168964386 and batch: 650, loss is 4.489007291793823 and perplexity is 89.03301818669817
At time: 1602.161676645279 and batch: 700, loss is 4.493410110473633 and perplexity is 89.42587863432213
At time: 1603.299899339676 and batch: 750, loss is 4.458841218948364 and perplexity is 86.3873470537318
At time: 1604.4380671977997 and batch: 800, loss is 4.439736652374267 and perplexity is 84.75261933361324
At time: 1605.575937986374 and batch: 850, loss is 4.420500192642212 and perplexity is 83.13785990564969
At time: 1606.7144832611084 and batch: 900, loss is 4.444616622924805 and perplexity is 85.1672204178033
At time: 1607.8529727458954 and batch: 950, loss is 4.430734176635742 and perplexity is 83.99306002126609
At time: 1608.9920647144318 and batch: 1000, loss is 4.442762060165405 and perplexity is 85.00941883419362
At time: 1610.1308782100677 and batch: 1050, loss is 4.390859241485596 and perplexity is 80.70973835065531
At time: 1611.2696566581726 and batch: 1100, loss is 4.377381067276001 and perplexity is 79.62921652481369
At time: 1612.4077849388123 and batch: 1150, loss is 4.3816454792022705 and perplexity is 79.96951337271261
At time: 1613.5459077358246 and batch: 1200, loss is 4.370295190811158 and perplexity is 79.06696809749835
At time: 1614.6843140125275 and batch: 1250, loss is 4.409586696624756 and perplexity is 82.23546828290965
At time: 1615.8230195045471 and batch: 1300, loss is 4.375631666183471 and perplexity is 79.49003486419844
At time: 1616.962492465973 and batch: 1350, loss is 4.369986934661865 and perplexity is 79.04259897453535
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.774620361328125 and perplexity of 118.46533206137703
Annealing...
Finished 49 epochs...
Completing Train Step...
At time: 1620.3555257320404 and batch: 50, loss is 4.538020782470703 and perplexity is 93.50554903211705
At time: 1621.522733926773 and batch: 100, loss is 4.552270736694336 and perplexity is 94.84753775567738
At time: 1622.6614663600922 and batch: 150, loss is 4.526432781219483 and perplexity is 92.42826047848168
At time: 1623.8006494045258 and batch: 200, loss is 4.511198997497559 and perplexity is 91.0308989239007
At time: 1624.9394249916077 and batch: 250, loss is 4.524182415008545 and perplexity is 92.22049690390794
At time: 1626.079017162323 and batch: 300, loss is 4.523800897598266 and perplexity is 92.18531988950299
At time: 1627.2178604602814 and batch: 350, loss is 4.522697067260742 and perplexity is 92.08361907728187
At time: 1628.357117176056 and batch: 400, loss is 4.527223901748657 and perplexity is 92.50141130456697
At time: 1629.4962425231934 and batch: 450, loss is 4.478888168334961 and perplexity is 88.1366250889224
At time: 1630.6357963085175 and batch: 500, loss is 4.54968448638916 and perplexity is 94.60255521185199
At time: 1631.7747905254364 and batch: 550, loss is 4.5250145626068115 and perplexity is 92.29726990772262
At time: 1632.9142909049988 and batch: 600, loss is 4.4815307712554935 and perplexity is 88.36984320750864
At time: 1634.0528373718262 and batch: 650, loss is 4.4888688087463375 and perplexity is 89.02068947669123
At time: 1635.1919906139374 and batch: 700, loss is 4.4932668590545655 and perplexity is 89.41306916781545
At time: 1636.3308579921722 and batch: 750, loss is 4.458739719390869 and perplexity is 86.37857922120578
At time: 1637.4702625274658 and batch: 800, loss is 4.439518632888794 and perplexity is 84.73414362525902
At time: 1638.6088454723358 and batch: 850, loss is 4.420256462097168 and perplexity is 83.11759913892524
At time: 1639.7479212284088 and batch: 900, loss is 4.444322748184204 and perplexity is 85.1421956002563
At time: 1640.8866076469421 and batch: 950, loss is 4.430461883544922 and perplexity is 83.97019240483375
At time: 1642.026448249817 and batch: 1000, loss is 4.44247709274292 and perplexity is 84.98519737054944
At time: 1643.1658098697662 and batch: 1050, loss is 4.3905651569366455 and perplexity is 80.68600635343445
At time: 1644.3050496578217 and batch: 1100, loss is 4.377098827362061 and perplexity is 79.60674515290277
At time: 1645.443960905075 and batch: 1150, loss is 4.381327095031739 and perplexity is 79.94405639829348
At time: 1646.5829772949219 and batch: 1200, loss is 4.369960193634033 and perplexity is 79.040485322457
At time: 1647.76695895195 and batch: 1250, loss is 4.409190101623535 and perplexity is 82.20286057372022
At time: 1648.9054481983185 and batch: 1300, loss is 4.375285482406616 and perplexity is 79.46252146632754
At time: 1650.0449147224426 and batch: 1350, loss is 4.369666671752929 and perplexity is 79.01728861505893
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.774691569010416 and perplexity of 118.47376800345334
Annealing...
Finished Training.
Improved accuracyfrom -175.5903074762128 to -118.37137219218255
<pretraining.langmodel.trainer.TrainLangModel object at 0x7feac4b70a20>
SETTINGS FOR THIS RUN
{'lr': 24.25140582114941, 'data': 'wikitext', 'dropout': 0.21040662221197415, 'anneal': 2.5866975937895478, 'wordvec_source': '', 'num_layers': 1, 'wordvec_dim': 200, 'batch_size': 80, 'seq_len': 20, 'tune_wordvecs': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.5711300373077393 and batch: 50, loss is 6.979352617263794 and perplexity is 1074.2227086050607
At time: 2.6310126781463623 and batch: 100, loss is 6.123696384429931 and perplexity is 456.5491605731413
At time: 3.6896750926971436 and batch: 150, loss is 5.9735075378417966 and perplexity is 392.8813028357742
At time: 4.750738143920898 and batch: 200, loss is 5.917269525527954 and perplexity is 371.396240191743
At time: 5.812068462371826 and batch: 250, loss is 5.921421270370484 and perplexity is 372.94138792659027
At time: 6.872382640838623 and batch: 300, loss is 5.902975254058838 and perplexity is 366.1251643575548
At time: 7.934997320175171 and batch: 350, loss is 5.877238779067993 and perplexity is 356.8226141162265
At time: 8.997284889221191 and batch: 400, loss is 5.912752733230591 and perplexity is 369.72250332122655
At time: 10.060032844543457 and batch: 450, loss is 5.883281135559082 and perplexity is 358.98519050388813
At time: 11.123803853988647 and batch: 500, loss is 5.896130800247192 and perplexity is 363.62779389863135
At time: 12.18726134300232 and batch: 550, loss is 5.865103282928467 and perplexity is 352.51856337711627
At time: 13.286463260650635 and batch: 600, loss is 5.8034467697143555 and perplexity is 331.43999070152023
At time: 14.35035490989685 and batch: 650, loss is 5.832690124511719 and perplexity is 341.27551895089874
At time: 15.413313150405884 and batch: 700, loss is 5.848631792068481 and perplexity is 346.7596165072461
At time: 16.481303215026855 and batch: 750, loss is 5.823976879119873 and perplexity is 338.31481899218323
At time: 17.547985076904297 and batch: 800, loss is 5.775296487808228 and perplexity is 322.23996077631483
At time: 18.616774320602417 and batch: 850, loss is 5.78589789390564 and perplexity is 325.67432986641063
At time: 19.68364667892456 and batch: 900, loss is 5.835150928497314 and perplexity is 342.1163652627811
At time: 20.752045154571533 and batch: 950, loss is 5.778565921783447 and perplexity is 323.29522717416154
At time: 21.820897340774536 and batch: 1000, loss is 5.802849884033203 and perplexity is 331.2422179466438
At time: 22.88910937309265 and batch: 1050, loss is 5.7803548812866214 and perplexity is 323.87410688493947
At time: 23.958094596862793 and batch: 1100, loss is 5.7704372978210445 and perplexity is 320.6779337519902
At time: 25.0255126953125 and batch: 1150, loss is 5.778479595184326 and perplexity is 323.2673194012963
At time: 26.094070196151733 and batch: 1200, loss is 5.7831034660339355 and perplexity is 324.7655268255974
At time: 27.161930561065674 and batch: 1250, loss is 5.778339805603028 and perplexity is 323.22213315642654
At time: 28.231464862823486 and batch: 1300, loss is 5.756402139663696 and perplexity is 316.20860546478605
At time: 29.30093026161194 and batch: 1350, loss is 5.722190570831299 and perplexity is 305.5735708803951
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.37658447265625 and perplexity of 216.2822943412176
Finished 1 epochs...
Completing Train Step...
At time: 32.54827928543091 and batch: 50, loss is 5.67984281539917 and perplexity is 292.9033864021058
At time: 33.60794377326965 and batch: 100, loss is 5.717715969085694 and perplexity is 304.2093053953663
At time: 34.66921424865723 and batch: 150, loss is 5.684901580810547 and perplexity is 294.38887011098507
At time: 35.73039793968201 and batch: 200, loss is 5.650054016113281 and perplexity is 284.3068225586955
At time: 36.791252851486206 and batch: 250, loss is 5.700378313064575 and perplexity is 298.9804877991859
At time: 37.85240364074707 and batch: 300, loss is 5.713683452606201 and perplexity is 302.98504643934393
At time: 38.91318345069885 and batch: 350, loss is 5.701700649261475 and perplexity is 299.3761020302316
At time: 39.977320432662964 and batch: 400, loss is 5.749755535125733 and perplexity is 314.1138610931664
At time: 41.07292580604553 and batch: 450, loss is 5.696317920684814 and perplexity is 297.76897098614785
At time: 42.20570707321167 and batch: 500, loss is 5.729528455734253 and perplexity is 307.8240814685987
At time: 43.34719944000244 and batch: 550, loss is 5.727458858489991 and perplexity is 307.187668384415
At time: 44.489105224609375 and batch: 600, loss is 5.691397333145142 and perplexity is 296.30737161069106
At time: 45.6306893825531 and batch: 650, loss is 5.679417495727539 and perplexity is 292.7788353188721
At time: 46.77202272415161 and batch: 700, loss is 5.664636859893799 and perplexity is 288.48320227235587
At time: 47.913429498672485 and batch: 750, loss is 5.656862955093384 and perplexity is 286.24925581535496
At time: 49.05465817451477 and batch: 800, loss is 5.6358479976654055 and perplexity is 280.2965073421142
At time: 50.19684052467346 and batch: 850, loss is 5.6651935863494876 and perplexity is 288.6438532182492
At time: 51.36696219444275 and batch: 900, loss is 5.673664360046387 and perplexity is 291.09927495662197
At time: 52.50809645652771 and batch: 950, loss is 5.66197018623352 and perplexity is 287.71493652770704
At time: 53.649250745773315 and batch: 1000, loss is 5.701569938659668 and perplexity is 299.3369729571169
At time: 54.79081058502197 and batch: 1050, loss is 5.66687195777893 and perplexity is 289.12871158717417
At time: 55.93208694458008 and batch: 1100, loss is 5.683496770858764 and perplexity is 293.9756000474734
At time: 57.07393717765808 and batch: 1150, loss is 5.654824066162109 and perplexity is 285.6662199507494
At time: 58.21536183357239 and batch: 1200, loss is 5.657468824386597 and perplexity is 286.4227379981154
At time: 59.356740951538086 and batch: 1250, loss is 5.6496504783630375 and perplexity is 284.1921171686753
At time: 60.49768686294556 and batch: 1300, loss is 5.658760118484497 and perplexity is 286.79283288844454
At time: 61.639392614364624 and batch: 1350, loss is 5.683130655288696 and perplexity is 293.8679907030062
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.501671142578125 and perplexity of 245.10118923888382
Annealing...
Finished 2 epochs...
Completing Train Step...
At time: 65.0201165676117 and batch: 50, loss is 5.6396983623504635 and perplexity is 281.3778315256407
At time: 66.16336059570312 and batch: 100, loss is 5.639326219558716 and perplexity is 281.27313827550824
At time: 67.27871918678284 and batch: 150, loss is 5.576026411056518 and perplexity is 264.0204100772134
At time: 68.39398789405823 and batch: 200, loss is 5.569029216766357 and perplexity is 262.17945623837716
At time: 69.50948071479797 and batch: 250, loss is 5.568088464736938 and perplexity is 261.9329263627712
At time: 70.62581181526184 and batch: 300, loss is 5.573722276687622 and perplexity is 263.4127718851166
At time: 71.74639081954956 and batch: 350, loss is 5.5720813274383545 and perplexity is 262.98087934862457
At time: 72.86720657348633 and batch: 400, loss is 5.606589841842651 and perplexity is 272.21435937113944
At time: 73.99696469306946 and batch: 450, loss is 5.567703037261963 and perplexity is 261.8319896694873
At time: 75.12818598747253 and batch: 500, loss is 5.588231868743897 and perplexity is 267.2626462588546
At time: 76.26231598854065 and batch: 550, loss is 5.557451267242431 and perplexity is 259.16146054193604
At time: 77.40304493904114 and batch: 600, loss is 5.514740381240845 and perplexity is 248.32549892004897
At time: 78.54383087158203 and batch: 650, loss is 5.56770471572876 and perplexity is 261.8324291461571
At time: 79.68465518951416 and batch: 700, loss is 5.563614225387573 and perplexity is 260.7635936446952
At time: 80.86041927337646 and batch: 750, loss is 5.523183813095093 and perplexity is 250.4310950673925
At time: 82.00128769874573 and batch: 800, loss is 5.4684264183044435 and perplexity is 237.08682358890553
At time: 83.14092326164246 and batch: 850, loss is 5.485218572616577 and perplexity is 241.10163645479443
At time: 84.28079771995544 and batch: 900, loss is 5.52999981880188 and perplexity is 252.14386533551416
At time: 85.4215157032013 and batch: 950, loss is 5.472612972259522 and perplexity is 238.08148100857667
At time: 86.56215071678162 and batch: 1000, loss is 5.495810165405273 and perplexity is 243.66885829337434
At time: 87.7025682926178 and batch: 1050, loss is 5.443574800491333 and perplexity is 231.26744248063048
At time: 88.84180212020874 and batch: 1100, loss is 5.440544595718384 and perplexity is 230.5677154660836
At time: 89.98178243637085 and batch: 1150, loss is 5.485899477005005 and perplexity is 241.265859520872
At time: 91.1218991279602 and batch: 1200, loss is 5.4747076416015625 and perplexity is 238.58070566050483
At time: 92.26192545890808 and batch: 1250, loss is 5.475931463241577 and perplexity is 238.87286462975163
At time: 93.40253639221191 and batch: 1300, loss is 5.419641809463501 and perplexity is 225.79822922642816
At time: 94.54352021217346 and batch: 1350, loss is 5.397043266296387 and perplexity is 220.75274323586385
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.312030029296875 and perplexity of 202.76142250684717
Finished 3 epochs...
Completing Train Step...
At time: 97.967280626297 and batch: 50, loss is 5.4889813327789305 and perplexity is 242.01055303267245
At time: 99.08761072158813 and batch: 100, loss is 5.510759286880493 and perplexity is 247.33885693729965
At time: 100.20864486694336 and batch: 150, loss is 5.455235185623169 and perplexity is 233.9798933060133
At time: 101.32891511917114 and batch: 200, loss is 5.4440451335906985 and perplexity is 231.37624079735394
At time: 102.44940757751465 and batch: 250, loss is 5.466702060699463 and perplexity is 236.6783533971625
At time: 103.56981468200684 and batch: 300, loss is 5.481766862869263 and perplexity is 240.2708582136713
At time: 104.68999671936035 and batch: 350, loss is 5.493226566314697 and perplexity is 243.0401281956705
At time: 105.81051683425903 and batch: 400, loss is 5.510797176361084 and perplexity is 247.3482286556627
At time: 106.93960189819336 and batch: 450, loss is 5.472106552124023 and perplexity is 237.96094227690116
At time: 108.06827712059021 and batch: 500, loss is 5.500253572463989 and perplexity is 244.75398726779042
At time: 109.22516560554504 and batch: 550, loss is 5.497602710723877 and perplexity is 244.10603747928647
At time: 110.3537266254425 and batch: 600, loss is 5.4423503398895265 and perplexity is 230.9844379081662
At time: 111.48662042617798 and batch: 650, loss is 5.476802272796631 and perplexity is 239.08096799876486
At time: 112.6256492137909 and batch: 700, loss is 5.463531455993652 and perplexity is 235.92912827211816
At time: 113.76463842391968 and batch: 750, loss is 5.443171148300171 and perplexity is 231.17410970898493
At time: 114.9037914276123 and batch: 800, loss is 5.406165313720703 and perplexity is 222.77567283095422
At time: 116.04195356369019 and batch: 850, loss is 5.426251831054688 and perplexity is 227.2957041151899
At time: 117.17962622642517 and batch: 900, loss is 5.479571733474732 and perplexity is 239.74401105055952
At time: 118.3185384273529 and batch: 950, loss is 5.411454582214356 and perplexity is 223.95711490621454
At time: 119.45730757713318 and batch: 1000, loss is 5.4322801780700685 and perplexity is 228.6700598793202
At time: 120.59645438194275 and batch: 1050, loss is 5.408324785232544 and perplexity is 223.2572703608834
At time: 121.73535442352295 and batch: 1100, loss is 5.414202289581299 and perplexity is 224.57332972201974
At time: 122.87361121177673 and batch: 1150, loss is 5.414663105010987 and perplexity is 224.67684042528487
At time: 124.0118350982666 and batch: 1200, loss is 5.401747207641602 and perplexity is 221.79359733089362
At time: 125.14994049072266 and batch: 1250, loss is 5.412042570114136 and perplexity is 224.08883770175896
At time: 126.28848838806152 and batch: 1300, loss is 5.374375791549682 and perplexity is 215.8051228777999
At time: 127.42764186859131 and batch: 1350, loss is 5.347295665740967 and perplexity is 210.0395120716204
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.307245279947916 and perplexity of 201.7935772175453
Finished 4 epochs...
Completing Train Step...
At time: 130.83027458190918 and batch: 50, loss is 5.431712923049926 and perplexity is 228.54038242346869
At time: 131.9429669380188 and batch: 100, loss is 5.462548046112061 and perplexity is 235.6972272815721
At time: 133.05572295188904 and batch: 150, loss is 5.422193870544434 and perplexity is 226.37521603901448
At time: 134.1685070991516 and batch: 200, loss is 5.405072002410889 and perplexity is 222.53224276496704
At time: 135.2832155227661 and batch: 250, loss is 5.435707521438599 and perplexity is 229.45513528562034
At time: 136.41028881072998 and batch: 300, loss is 5.438362140655517 and perplexity is 230.06506049858706
At time: 137.57060647010803 and batch: 350, loss is 5.459410629272461 and perplexity is 234.95890564864587
At time: 138.7089364528656 and batch: 400, loss is 5.482419681549072 and perplexity is 240.4277627276536
At time: 139.8469672203064 and batch: 450, loss is 5.448241815567017 and perplexity is 232.3492936654451
At time: 140.98543787002563 and batch: 500, loss is 5.4622304821014405 and perplexity is 235.622390208194
At time: 142.12436819076538 and batch: 550, loss is 5.4613321590423585 and perplexity is 235.41082022515894
At time: 143.2626233100891 and batch: 600, loss is 5.418733186721802 and perplexity is 225.59315700107038
At time: 144.4003345966339 and batch: 650, loss is 5.459833335876465 and perplexity is 235.05824532402238
At time: 145.5380344390869 and batch: 700, loss is 5.453526773452759 and perplexity is 233.58050046959062
At time: 146.67728543281555 and batch: 750, loss is 5.429976644515992 and perplexity is 228.14391695017574
At time: 147.8151478767395 and batch: 800, loss is 5.399447813034057 and perplexity is 221.28419221533545
At time: 148.9532072544098 and batch: 850, loss is 5.401947193145752 and perplexity is 221.83795727079763
At time: 150.0914900302887 and batch: 900, loss is 5.455071811676025 and perplexity is 233.94167020970562
At time: 151.22894740104675 and batch: 950, loss is 5.3992659378051755 and perplexity is 221.243949761892
At time: 152.36679983139038 and batch: 1000, loss is 5.417652807235718 and perplexity is 225.34956239304816
At time: 153.50442147254944 and batch: 1050, loss is 5.403591041564941 and perplexity is 222.20292513991504
At time: 154.64333534240723 and batch: 1100, loss is 5.415583248138428 and perplexity is 224.8836704179026
At time: 155.78148555755615 and batch: 1150, loss is 5.407397270202637 and perplexity is 223.05029188974734
At time: 156.91942858695984 and batch: 1200, loss is 5.382934846878052 and perplexity is 217.66013812928608
At time: 158.05721807479858 and batch: 1250, loss is 5.396368246078492 and perplexity is 220.6037809529564
At time: 159.19570183753967 and batch: 1300, loss is 5.367484540939331 and perplexity is 214.32306816342356
At time: 160.33361864089966 and batch: 1350, loss is 5.331194725036621 and perplexity is 206.68475816270333
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.323779296875 and perplexity of 205.15777081616358
Annealing...
Finished 5 epochs...
Completing Train Step...
At time: 163.73592615127563 and batch: 50, loss is 5.392149238586426 and perplexity is 219.6750125664031
At time: 164.88346910476685 and batch: 100, loss is 5.397833595275879 and perplexity is 220.92727948758946
At time: 166.00292372703552 and batch: 150, loss is 5.358633775711059 and perplexity is 212.43451490333598
At time: 167.15010380744934 and batch: 200, loss is 5.352505369186401 and perplexity is 211.13661093985098
At time: 168.27435183525085 and batch: 250, loss is 5.344811086654663 and perplexity is 209.51830005699117
At time: 169.40258693695068 and batch: 300, loss is 5.34457103729248 and perplexity is 209.46801135882336
At time: 170.53085708618164 and batch: 350, loss is 5.347522211074829 and perplexity is 210.08710093332064
At time: 171.65915203094482 and batch: 400, loss is 5.36774453163147 and perplexity is 214.3787974104855
At time: 172.7870273590088 and batch: 450, loss is 5.334105281829834 and perplexity is 207.28720218811043
At time: 173.9148690700531 and batch: 500, loss is 5.351187400817871 and perplexity is 210.85852286109343
At time: 175.04666137695312 and batch: 550, loss is 5.3384737873077395 and perplexity is 208.19471826761063
At time: 176.18536925315857 and batch: 600, loss is 5.2854628753662105 and perplexity is 197.44555498327898
At time: 177.3235900402069 and batch: 650, loss is 5.316249094009399 and perplexity is 203.618693238299
At time: 178.46190476417542 and batch: 700, loss is 5.318388671875 and perplexity is 204.05481768210348
At time: 179.59934759140015 and batch: 750, loss is 5.298523960113525 and perplexity is 200.04132298148173
At time: 180.73727917671204 and batch: 800, loss is 5.2698110008239745 and perplexity is 194.3792214608017
At time: 181.8753743171692 and batch: 850, loss is 5.29479866027832 and perplexity is 199.29749542450998
At time: 183.01355123519897 and batch: 900, loss is 5.326502456665039 and perplexity is 205.71720958312724
At time: 184.15114307403564 and batch: 950, loss is 5.274515514373779 and perplexity is 195.29583556312116
At time: 185.28863787651062 and batch: 1000, loss is 5.277871389389038 and perplexity is 195.9523249102609
At time: 186.42654967308044 and batch: 1050, loss is 5.2458062171936035 and perplexity is 189.76874840032906
At time: 187.56429505348206 and batch: 1100, loss is 5.2613896465301515 and perplexity is 192.74915847205088
At time: 188.70269584655762 and batch: 1150, loss is 5.270776023864746 and perplexity is 194.56689242699753
At time: 189.84075713157654 and batch: 1200, loss is 5.223489894866943 and perplexity is 185.58071243220712
At time: 190.97880816459656 and batch: 1250, loss is 5.240857954025269 and perplexity is 188.83204213796188
At time: 192.11696481704712 and batch: 1300, loss is 5.213505754470825 and perplexity is 183.73706746455994
At time: 193.25348138809204 and batch: 1350, loss is 5.201976976394653 and perplexity is 181.63096729735224
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.201976725260416 and perplexity of 181.6309216836036
Finished 6 epochs...
Completing Train Step...
At time: 196.62662863731384 and batch: 50, loss is 5.315650634765625 and perplexity is 203.49687220522276
At time: 197.76654601097107 and batch: 100, loss is 5.337453584671021 and perplexity is 207.98242577617597
At time: 198.88352870941162 and batch: 150, loss is 5.300916976928711 and perplexity is 200.52059845953215
At time: 200.00131130218506 and batch: 200, loss is 5.296732110977173 and perplexity is 199.68320005660888
At time: 201.1339635848999 and batch: 250, loss is 5.295076732635498 and perplexity is 199.35292225481982
At time: 202.27331829071045 and batch: 300, loss is 5.289706964492797 and perplexity is 198.28531225814027
At time: 203.41095900535583 and batch: 350, loss is 5.29998143196106 and perplexity is 200.33309014763793
At time: 204.54937314987183 and batch: 400, loss is 5.321039619445801 and perplexity is 204.59647393930936
At time: 205.68793845176697 and batch: 450, loss is 5.290907726287842 and perplexity is 198.5235486895962
At time: 206.82558679580688 and batch: 500, loss is 5.306764307022095 and perplexity is 201.69654330751146
At time: 207.96290802955627 and batch: 550, loss is 5.301828517913818 and perplexity is 200.7034645356857
At time: 209.10066747665405 and batch: 600, loss is 5.251358547210693 and perplexity is 190.8253376701281
At time: 210.23891186714172 and batch: 650, loss is 5.280535068511963 and perplexity is 196.4749748039934
At time: 211.3770444393158 and batch: 700, loss is 5.287202425003052 and perplexity is 197.7893202384214
At time: 212.51545906066895 and batch: 750, loss is 5.268010482788086 and perplexity is 194.02955305336152
At time: 213.65322518348694 and batch: 800, loss is 5.2390694904327395 and perplexity is 188.49462472481332
At time: 214.7919671535492 and batch: 850, loss is 5.261162643432617 and perplexity is 192.70540878187603
At time: 215.92985272407532 and batch: 900, loss is 5.295159645080567 and perplexity is 199.36945177827772
At time: 217.06770968437195 and batch: 950, loss is 5.248845558166504 and perplexity is 190.34639772467395
At time: 218.20489978790283 and batch: 1000, loss is 5.256242752075195 and perplexity is 191.7596475356769
At time: 219.3431990146637 and batch: 1050, loss is 5.223855743408203 and perplexity is 185.64861928619072
At time: 220.48134851455688 and batch: 1100, loss is 5.232892942428589 and perplexity is 187.33396674643427
At time: 221.61882257461548 and batch: 1150, loss is 5.246213331222534 and perplexity is 189.8460216484998
At time: 222.75700545310974 and batch: 1200, loss is 5.208042373657227 and perplexity is 182.7359790491316
At time: 223.93807935714722 and batch: 1250, loss is 5.228864431381226 and perplexity is 186.58080786486542
At time: 225.07394218444824 and batch: 1300, loss is 5.1980581474304195 and perplexity is 180.92057945526292
At time: 226.21133041381836 and batch: 1350, loss is 5.187785453796387 and perplexity is 179.07155128076732
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.200752766927083 and perplexity of 181.40874899620997
Finished 7 epochs...
Completing Train Step...
At time: 229.60834193229675 and batch: 50, loss is 5.277014217376709 and perplexity is 195.7844320284166
At time: 230.72295093536377 and batch: 100, loss is 5.300527305603027 and perplexity is 200.4424765540252
At time: 231.85016679763794 and batch: 150, loss is 5.26467921257019 and perplexity is 193.38426359541046
At time: 232.98087620735168 and batch: 200, loss is 5.2594483280181885 and perplexity is 192.3753339361929
At time: 234.11818885803223 and batch: 250, loss is 5.263309488296509 and perplexity is 193.11956180103726
At time: 235.25745224952698 and batch: 300, loss is 5.257981567382813 and perplexity is 192.09337220489283
At time: 236.39699745178223 and batch: 350, loss is 5.271225891113281 and perplexity is 194.65444139077886
At time: 237.53685426712036 and batch: 400, loss is 5.294558658599853 and perplexity is 199.24966943048284
At time: 238.67666697502136 and batch: 450, loss is 5.2631079196929935 and perplexity is 193.08063888360442
At time: 239.81642699241638 and batch: 500, loss is 5.279084634780884 and perplexity is 196.19020744124253
At time: 240.95726370811462 and batch: 550, loss is 5.275849781036377 and perplexity is 195.55658620261613
At time: 242.0972192287445 and batch: 600, loss is 5.2230129814147945 and perplexity is 185.4922275954705
At time: 243.23736810684204 and batch: 650, loss is 5.25105206489563 and perplexity is 190.7668620401971
At time: 244.37743473052979 and batch: 700, loss is 5.2624968242645265 and perplexity is 192.96268423230197
At time: 245.51712083816528 and batch: 750, loss is 5.2423836135864255 and perplexity is 189.12035542654104
At time: 246.65710759162903 and batch: 800, loss is 5.215243330001831 and perplexity is 184.05660202444744
At time: 247.79755234718323 and batch: 850, loss is 5.235554676055909 and perplexity is 187.83326406871262
At time: 248.93687558174133 and batch: 900, loss is 5.270890274047852 and perplexity is 194.5891229999829
At time: 250.07643365859985 and batch: 950, loss is 5.226658620834351 and perplexity is 186.16969953127244
At time: 251.21504020690918 and batch: 1000, loss is 5.23688380241394 and perplexity is 188.08308419538184
At time: 252.35461378097534 and batch: 1050, loss is 5.2033492279052735 and perplexity is 181.88038175714723
At time: 253.52298426628113 and batch: 1100, loss is 5.209350833892822 and perplexity is 182.97523830780727
At time: 254.66296458244324 and batch: 1150, loss is 5.221987171173096 and perplexity is 185.30204533078216
At time: 255.80293679237366 and batch: 1200, loss is 5.184275226593018 and perplexity is 178.4440713928992
At time: 256.9464933872223 and batch: 1250, loss is 5.206669797897339 and perplexity is 182.48533212912358
At time: 258.0861828327179 and batch: 1300, loss is 5.180696878433228 and perplexity is 177.80667746722523
At time: 259.22460317611694 and batch: 1350, loss is 5.17265097618103 and perplexity is 176.3818022108364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.201239013671875 and perplexity of 181.49697985913272
Annealing...
Finished 8 epochs...
Completing Train Step...
At time: 262.62927746772766 and batch: 50, loss is 5.242845067977905 and perplexity is 189.20764598382732
At time: 263.7479958534241 and batch: 100, loss is 5.2627708435058596 and perplexity is 193.01556696575324
At time: 264.8744604587555 and batch: 150, loss is 5.229185657501221 and perplexity is 186.6407521211564
At time: 266.0060567855835 and batch: 200, loss is 5.217239799499512 and perplexity is 184.424432475196
At time: 267.14165806770325 and batch: 250, loss is 5.212184610366822 and perplexity is 183.49448459993707
At time: 268.282835483551 and batch: 300, loss is 5.206638269424438 and perplexity is 182.47957873597306
At time: 269.42366075515747 and batch: 350, loss is 5.219266271591186 and perplexity is 184.79854237423834
At time: 270.56562066078186 and batch: 400, loss is 5.239163589477539 and perplexity is 188.5123627235011
At time: 271.7064061164856 and batch: 450, loss is 5.202475061416626 and perplexity is 181.7214574957249
At time: 272.847252368927 and batch: 500, loss is 5.222619934082031 and perplexity is 185.41933469628398
At time: 273.9881057739258 and batch: 550, loss is 5.2228053760528566 and perplexity is 185.4537224115035
At time: 275.1297998428345 and batch: 600, loss is 5.162392778396606 and perplexity is 174.58169152942259
At time: 276.27057814598083 and batch: 650, loss is 5.18036735534668 and perplexity is 177.74809571460744
At time: 277.4117314815521 and batch: 700, loss is 5.188476524353027 and perplexity is 179.19534512760393
At time: 278.5525817871094 and batch: 750, loss is 5.170364551544189 and perplexity is 175.97897920048644
At time: 279.69518423080444 and batch: 800, loss is 5.145590047836304 and perplexity is 171.67274992709844
At time: 280.8361644744873 and batch: 850, loss is 5.151529397964477 and perplexity is 172.69540845364398
At time: 282.01249623298645 and batch: 900, loss is 5.185537919998169 and perplexity is 178.66953386006426
At time: 283.1536180973053 and batch: 950, loss is 5.13820707321167 and perplexity is 170.40996167349485
At time: 284.29465889930725 and batch: 1000, loss is 5.152398986816406 and perplexity is 172.84564776936418
At time: 285.4354684352875 and batch: 1050, loss is 5.112995080947876 and perplexity is 166.16729481342895
At time: 286.577112197876 and batch: 1100, loss is 5.118283882141113 and perplexity is 167.04844867037428
At time: 287.7187879085541 and batch: 1150, loss is 5.135795392990112 and perplexity is 169.99948251056225
At time: 288.8599109649658 and batch: 1200, loss is 5.093066968917847 and perplexity is 162.88867123811764
At time: 290.0013723373413 and batch: 1250, loss is 5.1127336311340335 and perplexity is 166.12385608390463
At time: 291.1415536403656 and batch: 1300, loss is 5.089415464401245 and perplexity is 162.29496713567283
At time: 292.2817499637604 and batch: 1350, loss is 5.082872171401977 and perplexity is 161.2364903517888
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1554878743489585 and perplexity of 173.38037396519283
Finished 9 epochs...
Completing Train Step...
At time: 295.68079352378845 and batch: 50, loss is 5.202088813781739 and perplexity is 181.65128156607477
At time: 296.8258810043335 and batch: 100, loss is 5.223704261779785 and perplexity is 185.62049906093026
At time: 297.9470329284668 and batch: 150, loss is 5.190897388458252 and perplexity is 179.6296782250289
At time: 299.07567286491394 and batch: 200, loss is 5.182309103012085 and perplexity is 178.09357297077088
At time: 300.21521162986755 and batch: 250, loss is 5.181190786361694 and perplexity is 177.89451928606022
At time: 301.35556530952454 and batch: 300, loss is 5.178177661895752 and perplexity is 177.359307692145
At time: 302.49617290496826 and batch: 350, loss is 5.1927583789825436 and perplexity is 179.96427860158428
At time: 303.6369824409485 and batch: 400, loss is 5.2145372581481935 and perplexity is 183.92669070704125
At time: 304.777711391449 and batch: 450, loss is 5.1782714462280275 and perplexity is 177.37594199639605
At time: 305.9181282520294 and batch: 500, loss is 5.200615606307983 and perplexity is 181.38386856623413
At time: 307.05862975120544 and batch: 550, loss is 5.202449884414673 and perplexity is 181.716882351829
At time: 308.19954442977905 and batch: 600, loss is 5.143253831863404 and perplexity is 171.27215342877747
At time: 309.33998918533325 and batch: 650, loss is 5.163155422210694 and perplexity is 174.7148859600189
At time: 310.5091893672943 and batch: 700, loss is 5.173796033859253 and perplexity is 176.58388522402936
At time: 311.6497414112091 and batch: 750, loss is 5.157834749221802 and perplexity is 173.78775385612954
At time: 312.79021668434143 and batch: 800, loss is 5.132097635269165 and perplexity is 169.3720264168147
At time: 313.93062353134155 and batch: 850, loss is 5.1393296337127685 and perplexity is 170.60136457603275
At time: 315.0711238384247 and batch: 900, loss is 5.175824928283691 and perplexity is 176.9425189761925
At time: 316.21160435676575 and batch: 950, loss is 5.131551866531372 and perplexity is 169.27961368002494
At time: 317.3516550064087 and batch: 1000, loss is 5.14764949798584 and perplexity is 172.02666570847177
At time: 318.4921946525574 and batch: 1050, loss is 5.108150882720947 and perplexity is 165.3642940163236
At time: 319.63211965560913 and batch: 1100, loss is 5.113678674697876 and perplexity is 166.2809245714892
At time: 320.77246713638306 and batch: 1150, loss is 5.131866846084595 and perplexity is 169.33294169528793
At time: 321.9135973453522 and batch: 1200, loss is 5.092591314315796 and perplexity is 162.81121091566118
At time: 323.05405712127686 and batch: 1250, loss is 5.115028953552246 and perplexity is 166.50560184216994
At time: 324.19496512413025 and batch: 1300, loss is 5.090126552581787 and perplexity is 162.41041421022493
At time: 325.3354139328003 and batch: 1350, loss is 5.08149416923523 and perplexity is 161.01445913360953
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.154439697265625 and perplexity of 173.19873584159208
Finished 10 epochs...
Completing Train Step...
At time: 328.7143008708954 and batch: 50, loss is 5.187020225524902 and perplexity is 178.93457308358742
At time: 329.8601784706116 and batch: 100, loss is 5.207630834579468 and perplexity is 182.66079152520362
At time: 330.9851620197296 and batch: 150, loss is 5.175894432067871 and perplexity is 176.95481757823836
At time: 332.12429451942444 and batch: 200, loss is 5.1665371322631835 and perplexity is 175.30672118974536
At time: 333.2629859447479 and batch: 250, loss is 5.166839475631714 and perplexity is 175.35973202768977
At time: 334.4023549556732 and batch: 300, loss is 5.164763736724853 and perplexity is 174.9961085335022
At time: 335.5408384799957 and batch: 350, loss is 5.1802685356140135 and perplexity is 177.73053156316368
At time: 336.6796860694885 and batch: 400, loss is 5.201899166107178 and perplexity is 181.6168350893951
At time: 337.8188388347626 and batch: 450, loss is 5.166525669097901 and perplexity is 175.30471163134317
At time: 338.95789337158203 and batch: 500, loss is 5.189573230743409 and perplexity is 179.39197761207453
At time: 340.12454414367676 and batch: 550, loss is 5.192197904586792 and perplexity is 179.86344149222688
At time: 341.2634129524231 and batch: 600, loss is 5.133226909637451 and perplexity is 169.56340194235193
At time: 342.40190839767456 and batch: 650, loss is 5.153255367279053 and perplexity is 172.99373280468265
At time: 343.54088401794434 and batch: 700, loss is 5.164953804016113 and perplexity is 175.02937273094994
At time: 344.68028497695923 and batch: 750, loss is 5.150115871429444 and perplexity is 172.45147135771194
At time: 345.81904911994934 and batch: 800, loss is 5.124336013793945 and perplexity is 168.0625134054826
At time: 346.9581460952759 and batch: 850, loss is 5.131466693878174 and perplexity is 169.26519630018745
At time: 348.09700107574463 and batch: 900, loss is 5.169702653884888 and perplexity is 175.86253766650793
At time: 349.23596000671387 and batch: 950, loss is 5.126149959564209 and perplexity is 168.3676463544581
At time: 350.3749351501465 and batch: 1000, loss is 5.142487535476684 and perplexity is 171.14095846999072
At time: 351.5145196914673 and batch: 1050, loss is 5.1026037979125975 and perplexity is 164.44954369752313
At time: 352.6538875102997 and batch: 1100, loss is 5.1081148147583 and perplexity is 165.35832977070368
At time: 353.79357957839966 and batch: 1150, loss is 5.1267686939239505 and perplexity is 168.4718534372532
At time: 354.9323716163635 and batch: 1200, loss is 5.089203872680664 and perplexity is 162.26063049713724
At time: 356.0716404914856 and batch: 1250, loss is 5.112021493911743 and perplexity is 166.00559521645758
At time: 357.2101140022278 and batch: 1300, loss is 5.085560445785522 and perplexity is 161.67052141439925
At time: 358.34966492652893 and batch: 1350, loss is 5.07476734161377 and perplexity is 159.93497743666447
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.154780680338542 and perplexity of 173.2578037487706
Annealing...
Finished 11 epochs...
Completing Train Step...
At time: 361.779541015625 and batch: 50, loss is 5.176966638565063 and perplexity is 177.1446514357164
At time: 362.9045798778534 and batch: 100, loss is 5.197987127304077 and perplexity is 180.90773090911014
At time: 364.04363656044006 and batch: 150, loss is 5.164922752380371 and perplexity is 175.02393786700492
At time: 365.1828691959381 and batch: 200, loss is 5.1552835464477536 and perplexity is 173.34495113632977
At time: 366.3223159313202 and batch: 250, loss is 5.155243091583252 and perplexity is 173.33793863166537
At time: 367.4611780643463 and batch: 300, loss is 5.152518424987793 and perplexity is 172.86629337037783
At time: 368.6286563873291 and batch: 350, loss is 5.166217212677002 and perplexity is 175.2506461062845
At time: 369.76766657829285 and batch: 400, loss is 5.1870856285095215 and perplexity is 178.94627632142783
At time: 370.9057967662811 and batch: 450, loss is 5.147762870788574 and perplexity is 172.0461699593131
At time: 372.0442268848419 and batch: 500, loss is 5.169808130264283 and perplexity is 175.8810879885454
At time: 373.18328523635864 and batch: 550, loss is 5.168412218093872 and perplexity is 175.63574471594626
At time: 374.3221082687378 and batch: 600, loss is 5.111554946899414 and perplexity is 165.92816386606654
At time: 375.4609787464142 and batch: 650, loss is 5.128462181091309 and perplexity is 168.75740007565093
At time: 376.599369764328 and batch: 700, loss is 5.137582120895385 and perplexity is 170.30349684441492
At time: 377.738322019577 and batch: 750, loss is 5.119333791732788 and perplexity is 167.2239265407381
At time: 378.8765640258789 and batch: 800, loss is 5.094874601364136 and perplexity is 163.18338036802567
At time: 380.01560378074646 and batch: 850, loss is 5.092555465698243 and perplexity is 162.80537446344263
At time: 381.1550476551056 and batch: 900, loss is 5.1296901512146 and perplexity is 168.9647564086628
At time: 382.2933704853058 and batch: 950, loss is 5.087543506622314 and perplexity is 161.9914419912245
At time: 383.43124985694885 and batch: 1000, loss is 5.102424573898316 and perplexity is 164.42007303115926
At time: 384.56925415992737 and batch: 1050, loss is 5.060062589645386 and perplexity is 157.60038016658385
At time: 385.7080478668213 and batch: 1100, loss is 5.066452293395996 and perplexity is 158.61062404918417
At time: 386.84678769111633 and batch: 1150, loss is 5.081398391723633 and perplexity is 160.9990383078786
At time: 387.98562598228455 and batch: 1200, loss is 5.043516159057617 and perplexity is 155.01411217383892
At time: 389.12349796295166 and batch: 1250, loss is 5.066572360992431 and perplexity is 158.629669188912
At time: 390.2619307041168 and batch: 1300, loss is 5.040286331176758 and perplexity is 154.51425093982547
At time: 391.4002876281738 and batch: 1350, loss is 5.037385511398315 and perplexity is 154.06668241630882
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.136769612630208 and perplexity of 170.16518004502097
Finished 12 epochs...
Completing Train Step...
At time: 394.8051989078522 and batch: 50, loss is 5.159271144866944 and perplexity is 174.03756119708487
At time: 395.9301462173462 and batch: 100, loss is 5.1793268775939945 and perplexity is 177.56324895658008
At time: 397.09666109085083 and batch: 150, loss is 5.146347370147705 and perplexity is 171.802810773652
At time: 398.2350060939789 and batch: 200, loss is 5.139006719589234 and perplexity is 170.54628387956288
At time: 399.37325406074524 and batch: 250, loss is 5.140598526000977 and perplexity is 170.81797673158422
At time: 400.5116662979126 and batch: 300, loss is 5.138539714813232 and perplexity is 170.46665654508178
At time: 401.6505193710327 and batch: 350, loss is 5.1526361751556395 and perplexity is 172.8866496038886
At time: 402.7891731262207 and batch: 400, loss is 5.1742713928222654 and perplexity is 176.6678459107457
At time: 403.9273543357849 and batch: 450, loss is 5.135498561859131 and perplexity is 169.94902886037983
At time: 405.06592559814453 and batch: 500, loss is 5.158612899780273 and perplexity is 173.92303952333035
At time: 406.20428705215454 and batch: 550, loss is 5.159284095764161 and perplexity is 174.03981515424715
At time: 407.34318804740906 and batch: 600, loss is 5.103309707641602 and perplexity is 164.5656712132988
At time: 408.48206186294556 and batch: 650, loss is 5.120420122146607 and perplexity is 167.40568568542625
At time: 409.62086939811707 and batch: 700, loss is 5.130833892822266 and perplexity is 169.1581189881314
At time: 410.75881481170654 and batch: 750, loss is 5.11331449508667 and perplexity is 166.22037947434188
At time: 411.8966872692108 and batch: 800, loss is 5.089334411621094 and perplexity is 162.28181321047018
At time: 413.03485131263733 and batch: 850, loss is 5.0879899024963375 and perplexity is 162.06377044491708
At time: 414.1736295223236 and batch: 900, loss is 5.12637544631958 and perplexity is 168.4056153093313
At time: 415.31255435943604 and batch: 950, loss is 5.0857351112365725 and perplexity is 161.69876213521093
At time: 416.4515640735626 and batch: 1000, loss is 5.102023458480835 and perplexity is 164.3541348302217
At time: 417.5899569988251 and batch: 1050, loss is 5.061525650024414 and perplexity is 157.83112779622212
At time: 418.7285363674164 and batch: 1100, loss is 5.068274745941162 and perplexity is 158.89994794412885
At time: 419.86655926704407 and batch: 1150, loss is 5.083077745437622 and perplexity is 161.26963979501932
At time: 421.0051336288452 and batch: 1200, loss is 5.046811571121216 and perplexity is 155.52579018100596
At time: 422.14615201950073 and batch: 1250, loss is 5.070162963867188 and perplexity is 159.20026912096674
At time: 423.28458762168884 and batch: 1300, loss is 5.042325296401978 and perplexity is 154.8296215298661
At time: 424.4221305847168 and batch: 1350, loss is 5.03657525062561 and perplexity is 153.94189878763268
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.135676676432292 and perplexity of 169.97930195507402
Finished 13 epochs...
Completing Train Step...
At time: 427.8080024719238 and batch: 50, loss is 5.151941041946412 and perplexity is 172.76651211293424
At time: 428.95112895965576 and batch: 100, loss is 5.171228866577149 and perplexity is 176.13114622834627
At time: 430.0839726924896 and batch: 150, loss is 5.138588972091675 and perplexity is 170.4750534754517
At time: 431.22268176078796 and batch: 200, loss is 5.131664962768554 and perplexity is 169.29875965001202
At time: 432.3606541156769 and batch: 250, loss is 5.133970832824707 and perplexity is 169.6895910204377
At time: 433.49898290634155 and batch: 300, loss is 5.132182750701904 and perplexity is 169.3864432036739
At time: 434.6372079849243 and batch: 350, loss is 5.146789255142212 and perplexity is 171.8787446335281
At time: 435.77645325660706 and batch: 400, loss is 5.168703556060791 and perplexity is 175.6869215312428
At time: 436.91492080688477 and batch: 450, loss is 5.129702501296997 and perplexity is 168.96684315021227
At time: 438.05329513549805 and batch: 500, loss is 5.153679656982422 and perplexity is 173.06714783777892
At time: 439.1909625530243 and batch: 550, loss is 5.155006618499756 and perplexity is 173.2969537209354
At time: 440.32922625541687 and batch: 600, loss is 5.099186916351318 and perplexity is 163.88859797221212
At time: 441.4676043987274 and batch: 650, loss is 5.116389379501343 and perplexity is 166.7322745343326
At time: 442.6060585975647 and batch: 700, loss is 5.127270631790161 and perplexity is 168.5564370659712
At time: 443.74435925483704 and batch: 750, loss is 5.1098153686523435 and perplexity is 165.6397697564152
At time: 444.8825206756592 and batch: 800, loss is 5.0859643173217775 and perplexity is 161.7358287232439
At time: 446.0205979347229 and batch: 850, loss is 5.084735345840454 and perplexity is 161.53718209275925
At time: 447.1586308479309 and batch: 900, loss is 5.124198007583618 and perplexity is 168.03932133527113
At time: 448.29626202583313 and batch: 950, loss is 5.083885831832886 and perplexity is 161.40001226592227
At time: 449.4345419406891 and batch: 1000, loss is 5.100942945480346 and perplexity is 164.1766439587192
At time: 450.57301664352417 and batch: 1050, loss is 5.06137791633606 and perplexity is 157.80781254384212
At time: 451.7111303806305 and batch: 1100, loss is 5.068181571960449 and perplexity is 158.88514329315862
At time: 452.84859681129456 and batch: 1150, loss is 5.0828042984008786 and perplexity is 161.22554711868125
At time: 453.9870853424072 and batch: 1200, loss is 5.04739016532898 and perplexity is 155.61580254016627
At time: 455.153361082077 and batch: 1250, loss is 5.0705545616149905 and perplexity is 159.26262379598245
At time: 456.2912242412567 and batch: 1300, loss is 5.041582260131836 and perplexity is 154.7146202357345
At time: 457.4299750328064 and batch: 1350, loss is 5.034078235626221 and perplexity is 153.55798307844654
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.135210774739583 and perplexity of 169.90012675592962
Finished 14 epochs...
Completing Train Step...
At time: 460.809166431427 and batch: 50, loss is 5.146102266311646 and perplexity is 171.7607064058674
At time: 461.95726108551025 and batch: 100, loss is 5.16495759010315 and perplexity is 175.03003540864356
At time: 463.0852584838867 and batch: 150, loss is 5.132784385681152 and perplexity is 169.48838267501657
At time: 464.22578024864197 and batch: 200, loss is 5.1266382122039795 and perplexity is 168.44987237414466
At time: 465.36582493782043 and batch: 250, loss is 5.129598121643067 and perplexity is 168.94920737002295
At time: 466.50568199157715 and batch: 300, loss is 5.127462558746338 and perplexity is 168.5887906945487
At time: 467.64528346061707 and batch: 350, loss is 5.14267936706543 and perplexity is 171.17379186109355
At time: 468.78502440452576 and batch: 400, loss is 5.164703369140625 and perplexity is 174.9855447600386
At time: 469.9250223636627 and batch: 450, loss is 5.1256278610229495 and perplexity is 168.2797647953143
At time: 471.0652256011963 and batch: 500, loss is 5.150076751708984 and perplexity is 172.44472523631364
At time: 472.20568799972534 and batch: 550, loss is 5.151777696609497 and perplexity is 172.7382938135322
At time: 473.3460314273834 and batch: 600, loss is 5.095934724807739 and perplexity is 163.3564666253493
At time: 474.4863579273224 and batch: 650, loss is 5.113026990890503 and perplexity is 166.17259728687327
At time: 475.6268594264984 and batch: 700, loss is 5.124384136199951 and perplexity is 168.0706011725869
At time: 476.7669060230255 and batch: 750, loss is 5.106875715255737 and perplexity is 165.15356123703373
At time: 477.9072289466858 and batch: 800, loss is 5.083006706237793 and perplexity is 161.25818373577098
At time: 479.0476973056793 and batch: 850, loss is 5.0817580413818355 and perplexity is 161.05695197066723
At time: 480.1878056526184 and batch: 900, loss is 5.121676836013794 and perplexity is 167.6161989818567
At time: 481.3278548717499 and batch: 950, loss is 5.081856203079224 and perplexity is 161.072762370424
At time: 482.46753311157227 and batch: 1000, loss is 5.099505376815796 and perplexity is 163.94079832267778
At time: 483.6424045562744 and batch: 1050, loss is 5.060184268951416 and perplexity is 157.619558038224
At time: 484.78252935409546 and batch: 1100, loss is 5.067124147415161 and perplexity is 158.71722303990416
At time: 485.92284297943115 and batch: 1150, loss is 5.0816288089752195 and perplexity is 161.03613953801116
At time: 487.06408619880676 and batch: 1200, loss is 5.046579637527466 and perplexity is 155.4897227083594
At time: 488.2038323879242 and batch: 1250, loss is 5.069560203552246 and perplexity is 159.1043384311235
At time: 489.3437554836273 and batch: 1300, loss is 5.0402884101867675 and perplexity is 154.5145721768337
At time: 490.4838697910309 and batch: 1350, loss is 5.031579170227051 and perplexity is 153.1747107469517
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.135284423828125 and perplexity of 169.91264020620474
Annealing...
Finished 15 epochs...
Completing Train Step...
At time: 493.90805983543396 and batch: 50, loss is 5.143031892776489 and perplexity is 171.2341456612922
At time: 495.0328257083893 and batch: 100, loss is 5.162248268127441 and perplexity is 174.5564645050143
At time: 496.17272686958313 and batch: 150, loss is 5.131467065811157 and perplexity is 169.26525925550857
At time: 497.312753200531 and batch: 200, loss is 5.123951416015625 and perplexity is 167.99788936413597
At time: 498.45303416252136 and batch: 250, loss is 5.12632266998291 and perplexity is 168.3967277124101
At time: 499.59337997436523 and batch: 300, loss is 5.123616743087768 and perplexity is 167.94167442596233
At time: 500.7343280315399 and batch: 350, loss is 5.138530340194702 and perplexity is 170.4650584926951
At time: 501.87553310394287 and batch: 400, loss is 5.1601122379302975 and perplexity is 174.18400456018588
At time: 503.0157992839813 and batch: 450, loss is 5.11876654624939 and perplexity is 167.1290964222127
At time: 504.15569829940796 and batch: 500, loss is 5.142620716094971 and perplexity is 171.16375264649147
At time: 505.2962923049927 and batch: 550, loss is 5.142583799362183 and perplexity is 171.15743395660542
At time: 506.4373576641083 and batch: 600, loss is 5.087674493789673 and perplexity is 162.01266218110325
At time: 507.5786597728729 and batch: 650, loss is 5.104221754074096 and perplexity is 164.71583121267693
At time: 508.7193171977997 and batch: 700, loss is 5.113990402221679 and perplexity is 166.33276699229646
At time: 509.859988451004 and batch: 750, loss is 5.094533424377442 and perplexity is 163.12771545036748
At time: 511.00072288513184 and batch: 800, loss is 5.0708969211578365 and perplexity is 159.3171582097135
At time: 512.1692841053009 and batch: 850, loss is 5.064626398086548 and perplexity is 158.3212818893367
At time: 513.3102126121521 and batch: 900, loss is 5.101724328994751 and perplexity is 164.30497901467774
At time: 514.4522356987 and batch: 950, loss is 5.062220821380615 and perplexity is 157.94088562121075
At time: 515.5925273895264 and batch: 1000, loss is 5.082230081558228 and perplexity is 161.1329952690186
At time: 516.7335002422333 and batch: 1050, loss is 5.041095542907715 and perplexity is 154.63933628772565
At time: 517.8748738765717 and batch: 1100, loss is 5.045182399749756 and perplexity is 155.2726183023051
At time: 519.0156292915344 and batch: 1150, loss is 5.059402914047241 and perplexity is 157.49644932561836
At time: 520.1566095352173 and batch: 1200, loss is 5.023560419082641 and perplexity is 151.9513523184472
At time: 521.2981870174408 and batch: 1250, loss is 5.045972719192505 and perplexity is 155.39538177626622
At time: 522.4391434192657 and batch: 1300, loss is 5.020096359252929 and perplexity is 151.42589437712897
At time: 523.580591917038 and batch: 1350, loss is 5.014238796234131 and perplexity is 150.54150038361757
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.121687825520834 and perplexity of 167.61804101137682
Finished 16 epochs...
Completing Train Step...
At time: 527.0106012821198 and batch: 50, loss is 5.135883569717407 and perplexity is 170.01447316947574
At time: 528.1395032405853 and batch: 100, loss is 5.154196920394898 and perplexity is 173.15669229829706
At time: 529.2721123695374 and batch: 150, loss is 5.12318862915039 and perplexity is 167.86979164258258
At time: 530.4095995426178 and batch: 200, loss is 5.11605224609375 and perplexity is 166.67607298870462
At time: 531.5638191699982 and batch: 250, loss is 5.118972311019897 and perplexity is 167.16348924067702
At time: 532.7045741081238 and batch: 300, loss is 5.1166087341308595 and perplexity is 166.76885204221767
At time: 533.8450496196747 and batch: 350, loss is 5.131865816116333 and perplexity is 169.33276728782212
At time: 534.9866592884064 and batch: 400, loss is 5.1538575077056885 and perplexity is 173.09793069249093
At time: 536.1271524429321 and batch: 450, loss is 5.112908563613892 and perplexity is 166.1529190839702
At time: 537.2680661678314 and batch: 500, loss is 5.137349834442139 and perplexity is 170.2639422433343
At time: 538.4085702896118 and batch: 550, loss is 5.138677883148193 and perplexity is 170.49021126640378
At time: 539.5495073795319 and batch: 600, loss is 5.084009170532227 and perplexity is 161.4199203612028
At time: 540.6901412010193 and batch: 650, loss is 5.100637664794922 and perplexity is 164.12653164987003
At time: 541.8668551445007 and batch: 700, loss is 5.111432008743286 and perplexity is 165.90776621740147
At time: 543.0077269077301 and batch: 750, loss is 5.092954273223877 and perplexity is 162.87031542060288
At time: 544.1484184265137 and batch: 800, loss is 5.069345140457154 and perplexity is 159.07012463885175
At time: 545.2883524894714 and batch: 850, loss is 5.063546752929687 and perplexity is 158.15044332322668
At time: 546.4287643432617 and batch: 900, loss is 5.1011260223388675 and perplexity is 164.20670365447108
At time: 547.5693001747131 and batch: 950, loss is 5.062505884170532 and perplexity is 157.98591510851864
At time: 548.7109689712524 and batch: 1000, loss is 5.083396263122559 and perplexity is 161.321015208892
At time: 549.8516445159912 and batch: 1050, loss is 5.04273229598999 and perplexity is 154.8926499474408
At time: 550.9922432899475 and batch: 1100, loss is 5.047077369689942 and perplexity is 155.56713420778414
At time: 552.13214635849 and batch: 1150, loss is 5.061805086135864 and perplexity is 157.8752376754988
At time: 553.2728049755096 and batch: 1200, loss is 5.026385316848755 and perplexity is 152.381206214971
At time: 554.4139761924744 and batch: 1250, loss is 5.048881196975708 and perplexity is 155.84800369309977
At time: 555.5550363063812 and batch: 1300, loss is 5.022163829803467 and perplexity is 151.7392868075215
At time: 556.6956562995911 and batch: 1350, loss is 5.014940147399902 and perplexity is 150.6471198742556
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.120910237630208 and perplexity of 167.4877539138355
Finished 17 epochs...
Completing Train Step...
At time: 560.1140542030334 and batch: 50, loss is 5.1328327846527095 and perplexity is 169.4965859369421
At time: 561.2554752826691 and batch: 100, loss is 5.150425682067871 and perplexity is 172.50490693517875
At time: 562.3717551231384 and batch: 150, loss is 5.118990964889527 and perplexity is 167.16660751569597
At time: 563.4926128387451 and batch: 200, loss is 5.111928272247314 and perplexity is 165.99012061986204
At time: 564.6297960281372 and batch: 250, loss is 5.11503041267395 and perplexity is 166.50584479428474
At time: 565.7679991722107 and batch: 300, loss is 5.112990083694458 and perplexity is 166.16646443542191
At time: 566.9056808948517 and batch: 350, loss is 5.128506650924683 and perplexity is 168.76490485597984
At time: 568.0445041656494 and batch: 400, loss is 5.150632305145264 and perplexity is 172.54055411255297
At time: 569.1827147006989 and batch: 450, loss is 5.109751653671265 and perplexity is 165.62921635782766
At time: 570.3499376773834 and batch: 500, loss is 5.134465179443359 and perplexity is 169.77349723364685
At time: 571.4879860877991 and batch: 550, loss is 5.136460666656494 and perplexity is 170.11261631787377
At time: 572.626317024231 and batch: 600, loss is 5.082125291824341 and perplexity is 161.11611106998484
At time: 573.7642550468445 and batch: 650, loss is 5.0987402439117435 and perplexity is 163.8154097991242
At time: 574.9027252197266 and batch: 700, loss is 5.110095615386963 and perplexity is 165.6861962661476
At time: 576.0411365032196 and batch: 750, loss is 5.092086057662964 and perplexity is 162.72897024626266
At time: 577.1800403594971 and batch: 800, loss is 5.068495540618897 and perplexity is 158.93503608042158
At time: 578.3188161849976 and batch: 850, loss is 5.062666425704956 and perplexity is 158.0112804457881
At time: 579.457172870636 and batch: 900, loss is 5.100491704940796 and perplexity is 164.1025775134659
At time: 580.5951874256134 and batch: 950, loss is 5.062494354248047 and perplexity is 157.9840935536649
At time: 581.733345746994 and batch: 1000, loss is 5.083908567428589 and perplexity is 161.40368183306236
At time: 582.8718545436859 and batch: 1050, loss is 5.043483905792236 and perplexity is 155.0091125431688
At time: 584.0105113983154 and batch: 1100, loss is 5.047821159362793 and perplexity is 155.68288647797817
At time: 585.149019241333 and batch: 1150, loss is 5.0628017330169675 and perplexity is 158.03266197391866
At time: 586.2872264385223 and batch: 1200, loss is 5.027588758468628 and perplexity is 152.56469848959114
At time: 587.4255292415619 and batch: 1250, loss is 5.049994840621948 and perplexity is 156.0216595095927
At time: 588.5630583763123 and batch: 1300, loss is 5.022882022857666 and perplexity is 151.8483040523839
At time: 589.7008428573608 and batch: 1350, loss is 5.014723901748657 and perplexity is 150.6145466117503
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.12066162109375 and perplexity of 167.4461188643536
Finished 18 epochs...
Completing Train Step...
At time: 593.0621361732483 and batch: 50, loss is 5.1303974151611325 and perplexity is 169.08430135903873
At time: 594.1975367069244 and batch: 100, loss is 5.147538270950317 and perplexity is 172.00753275648472
At time: 595.3133890628815 and batch: 150, loss is 5.115817556381225 and perplexity is 166.63696041888863
At time: 596.4321775436401 and batch: 200, loss is 5.108878831863404 and perplexity is 165.48471463707185
At time: 597.5564970970154 and batch: 250, loss is 5.1120426464080815 and perplexity is 166.0091066863406
At time: 598.7170531749725 and batch: 300, loss is 5.110202846527099 and perplexity is 165.7039639384849
At time: 599.8550007343292 and batch: 350, loss is 5.125928707122803 and perplexity is 168.33039872236506
At time: 600.9932723045349 and batch: 400, loss is 5.148179893493652 and perplexity is 172.11793208068488
At time: 602.3348269462585 and batch: 450, loss is 5.107391529083252 and perplexity is 165.23877170206188
At time: 603.4661681652069 and batch: 500, loss is 5.1323166179656985 and perplexity is 169.4091200211573
At time: 604.6042339801788 and batch: 550, loss is 5.134807920455932 and perplexity is 169.83169554690144
At time: 605.7427790164948 and batch: 600, loss is 5.080686120986939 and perplexity is 160.8844042343504
At time: 606.88045835495 and batch: 650, loss is 5.097308120727539 and perplexity is 163.5809738634588
At time: 608.0188522338867 and batch: 700, loss is 5.1089466953277585 and perplexity is 165.49594538417927
At time: 609.1567437648773 and batch: 750, loss is 5.091231002807617 and perplexity is 162.5898875203018
At time: 610.2943871021271 and batch: 800, loss is 5.067705841064453 and perplexity is 158.80957469816227
At time: 611.4326317310333 and batch: 850, loss is 5.061974725723267 and perplexity is 157.90202183744196
At time: 612.5708129405975 and batch: 900, loss is 5.099683666229248 and perplexity is 163.97002983720898
At time: 613.7091906070709 and batch: 950, loss is 5.062222547531128 and perplexity is 157.94115825118683
At time: 614.8467597961426 and batch: 1000, loss is 5.08409387588501 and perplexity is 161.43359407161336
At time: 615.9847848415375 and batch: 1050, loss is 5.043851661682129 and perplexity is 155.06612854063545
At time: 617.1229610443115 and batch: 1100, loss is 5.047974014282227 and perplexity is 155.70668519187691
At time: 618.2610368728638 and batch: 1150, loss is 5.063240613937378 and perplexity is 158.1020347161336
At time: 619.399115562439 and batch: 1200, loss is 5.028258800506592 and perplexity is 152.66695750618257
At time: 620.5366945266724 and batch: 1250, loss is 5.0504842948913575 and perplexity is 156.0980436687115
At time: 621.6762979030609 and batch: 1300, loss is 5.0230924510955814 and perplexity is 151.88026058559666
At time: 622.8142912387848 and batch: 1350, loss is 5.014205513000488 and perplexity is 150.5364899590694
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.120508219401041 and perplexity of 167.42043431635926
Finished 19 epochs...
Completing Train Step...
At time: 626.2362613677979 and batch: 50, loss is 5.1282644367218015 and perplexity is 168.72403254920224
At time: 627.3487994670868 and batch: 100, loss is 5.145143022537232 and perplexity is 171.59602501498574
At time: 628.4891402721405 and batch: 150, loss is 5.1131836032867435 and perplexity is 166.19862401352475
At time: 629.604822397232 and batch: 200, loss is 5.10634765625 and perplexity is 165.06637343387126
At time: 630.7404592037201 and batch: 250, loss is 5.109557285308838 and perplexity is 165.59702640672947
At time: 631.8787984848022 and batch: 300, loss is 5.1080820178985595 and perplexity is 165.35290662568673
At time: 633.0175130367279 and batch: 350, loss is 5.123936748504638 and perplexity is 167.995425271319
At time: 634.1564688682556 and batch: 400, loss is 5.1460477733612064 and perplexity is 171.75134691322134
At time: 635.2944388389587 and batch: 450, loss is 5.105344314575195 and perplexity is 164.90083852022184
At time: 636.432689666748 and batch: 500, loss is 5.130402641296387 and perplexity is 169.08518501877606
At time: 637.5706005096436 and batch: 550, loss is 5.133291816711425 and perplexity is 169.57440816381208
At time: 638.7091429233551 and batch: 600, loss is 5.079373331069946 and perplexity is 160.67333538551176
At time: 639.8476884365082 and batch: 650, loss is 5.095983896255493 and perplexity is 163.36449929680074
At time: 640.986296415329 and batch: 700, loss is 5.108030204772949 and perplexity is 165.34433939671507
At time: 642.1245455741882 and batch: 750, loss is 5.090563840866089 and perplexity is 162.48144991201582
At time: 643.2619848251343 and batch: 800, loss is 5.0669670581817625 and perplexity is 158.69229223124182
At time: 644.4002432823181 and batch: 850, loss is 5.060917949676513 and perplexity is 157.7352429025432
At time: 645.5387725830078 and batch: 900, loss is 5.098895587921143 and perplexity is 163.8408595183633
At time: 646.6772928237915 and batch: 950, loss is 5.061750259399414 and perplexity is 157.86658212873058
At time: 647.8158404827118 and batch: 1000, loss is 5.083985481262207 and perplexity is 161.41609648641546
At time: 648.9535369873047 and batch: 1050, loss is 5.043762884140015 and perplexity is 155.0523627619335
At time: 650.0913133621216 and batch: 1100, loss is 5.047677459716797 and perplexity is 155.66051650962046
At time: 651.2292728424072 and batch: 1150, loss is 5.0633104705810545 and perplexity is 158.1130795794114
At time: 652.367525100708 and batch: 1200, loss is 5.02843596458435 and perplexity is 152.69400700294213
At time: 653.5057241916656 and batch: 1250, loss is 5.050689458847046 and perplexity is 156.13007264630932
At time: 654.6447620391846 and batch: 1300, loss is 5.022974767684937 and perplexity is 151.86238785020416
At time: 655.783595085144 and batch: 1350, loss is 5.013567180633545 and perplexity is 150.44042830801487
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.120458984375 and perplexity of 167.41219156983348
Finished 20 epochs...
Completing Train Step...
At time: 659.1931002140045 and batch: 50, loss is 5.126219348907471 and perplexity is 168.37932968020957
At time: 660.312792301178 and batch: 100, loss is 5.143104343414307 and perplexity is 171.24655213378455
At time: 661.4327487945557 and batch: 150, loss is 5.110869741439819 and perplexity is 165.81450792556726
At time: 662.5612576007843 and batch: 200, loss is 5.104071493148804 and perplexity is 164.69108271888092
At time: 663.6995446681976 and batch: 250, loss is 5.107513456344605 and perplexity is 165.2589200412558
At time: 664.8373506069183 and batch: 300, loss is 5.1061790084838865 and perplexity is 165.03853770601387
At time: 665.9755754470825 and batch: 350, loss is 5.122236642837525 and perplexity is 167.71005794280677
At time: 667.1144664287567 and batch: 400, loss is 5.144222049713135 and perplexity is 171.4380624899855
At time: 668.2526066303253 and batch: 450, loss is 5.10363130569458 and perplexity is 164.618603723788
At time: 669.3910191059113 and batch: 500, loss is 5.12880618095398 and perplexity is 168.8154625842766
At time: 670.5284993648529 and batch: 550, loss is 5.131918458938599 and perplexity is 169.3416816772315
At time: 671.6666674613953 and batch: 600, loss is 5.078141050338745 and perplexity is 160.47546267270343
At time: 672.8046927452087 and batch: 650, loss is 5.094857292175293 and perplexity is 163.18055582052418
At time: 673.9431772232056 and batch: 700, loss is 5.107049503326416 and perplexity is 165.18226544995954
At time: 675.0813903808594 and batch: 750, loss is 5.089795007705688 and perplexity is 162.35657679482117
At time: 676.2197787761688 and batch: 800, loss is 5.066135501861572 and perplexity is 158.56038550420863
At time: 677.3576006889343 and batch: 850, loss is 5.060193510055542 and perplexity is 157.62101462370225
At time: 678.5411944389343 and batch: 900, loss is 5.098032751083374 and perplexity is 163.69955256043033
At time: 679.6790242195129 and batch: 950, loss is 5.0613005828857425 and perplexity is 157.7956091930808
At time: 680.8169181346893 and batch: 1000, loss is 5.083641424179077 and perplexity is 161.36056968782998
At time: 681.9567632675171 and batch: 1050, loss is 5.0434913825988765 and perplexity is 155.01027152066354
At time: 683.0968716144562 and batch: 1100, loss is 5.047267570495605 and perplexity is 155.59672601614892
At time: 684.2362592220306 and batch: 1150, loss is 5.063153476715088 and perplexity is 158.0882587441987
At time: 685.3747200965881 and batch: 1200, loss is 5.028496599197387 and perplexity is 152.70326582566958
At time: 686.5124952793121 and batch: 1250, loss is 5.050743188858032 and perplexity is 156.13846174219898
At time: 687.651275396347 and batch: 1300, loss is 5.022737979888916 and perplexity is 151.8264329470958
At time: 688.7897706031799 and batch: 1350, loss is 5.012843885421753 and perplexity is 150.33165480897745
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.120368245442708 and perplexity of 167.3970014554955
Finished 21 epochs...
Completing Train Step...
At time: 692.1755702495575 and batch: 50, loss is 5.124286384582519 and perplexity is 168.05417280244254
At time: 693.3188664913177 and batch: 100, loss is 5.141024169921875 and perplexity is 170.89069984093683
At time: 694.4427947998047 and batch: 150, loss is 5.108791618347168 and perplexity is 165.47028276256154
At time: 695.5745418071747 and batch: 200, loss is 5.101945648193359 and perplexity is 164.34134688526606
At time: 696.7058670520782 and batch: 250, loss is 5.105643157958984 and perplexity is 164.95012540895843
At time: 697.8429906368256 and batch: 300, loss is 5.104340620040894 and perplexity is 164.7354114828917
At time: 698.9829649925232 and batch: 350, loss is 5.120650186538696 and perplexity is 167.44420420343553
At time: 700.1230096817017 and batch: 400, loss is 5.142606534957886 and perplexity is 171.16132536706203
At time: 701.2632963657379 and batch: 450, loss is 5.101913652420044 and perplexity is 164.33608874090447
At time: 702.4038112163544 and batch: 500, loss is 5.127381916046143 and perplexity is 168.57519578741687
At time: 703.5440118312836 and batch: 550, loss is 5.130754499435425 and perplexity is 169.14468948526724
At time: 704.6846508979797 and batch: 600, loss is 5.077038888931274 and perplexity is 160.29869024466825
At time: 705.8247594833374 and batch: 650, loss is 5.09356840133667 and perplexity is 162.97036937987207
At time: 706.993141412735 and batch: 700, loss is 5.106016883850097 and perplexity is 165.0117830623792
At time: 708.13329911232 and batch: 750, loss is 5.08896050453186 and perplexity is 162.22114623267043
At time: 709.273854970932 and batch: 800, loss is 5.065313682556153 and perplexity is 158.43013104847074
At time: 710.4144909381866 and batch: 850, loss is 5.059195432662964 and perplexity is 157.46377513405406
At time: 711.5552072525024 and batch: 900, loss is 5.096904954910278 and perplexity is 163.51503689910103
At time: 712.6949670314789 and batch: 950, loss is 5.0607154750823975 and perplexity is 157.70330875629452
At time: 713.8348944187164 and batch: 1000, loss is 5.083453073501587 and perplexity is 161.33018017724135
At time: 714.9752883911133 and batch: 1050, loss is 5.043254508972168 and perplexity is 154.97355802387253
At time: 716.1158232688904 and batch: 1100, loss is 5.046843338012695 and perplexity is 155.53073083037896
At time: 717.256105184555 and batch: 1150, loss is 5.062950878143311 and perplexity is 158.05623353300302
At time: 718.3963484764099 and batch: 1200, loss is 5.028368654251099 and perplexity is 152.68372946434147
At time: 719.5362310409546 and batch: 1250, loss is 5.050552539825439 and perplexity is 156.10869693292346
At time: 720.6759805679321 and batch: 1300, loss is 5.022543992996216 and perplexity is 151.79698346563768
At time: 721.8161211013794 and batch: 1350, loss is 5.0121926593780515 and perplexity is 150.23378679073303
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.120341796875 and perplexity of 167.39257410311717
Finished 22 epochs...
Completing Train Step...
At time: 725.1850249767303 and batch: 50, loss is 5.122519025802612 and perplexity is 167.75742309348476
At time: 726.3281915187836 and batch: 100, loss is 5.1391325855255126 and perplexity is 170.567751198236
At time: 727.4582052230835 and batch: 150, loss is 5.106729612350464 and perplexity is 165.12943358452387
At time: 728.5982518196106 and batch: 200, loss is 5.100072803497315 and perplexity is 164.03384910308668
At time: 729.738938331604 and batch: 250, loss is 5.1038500022888185 and perplexity is 164.6546091887635
At time: 730.8798229694366 and batch: 300, loss is 5.102678165435791 and perplexity is 164.46177385753597
At time: 732.0208852291107 and batch: 350, loss is 5.119327793121338 and perplexity is 167.2229234323862
At time: 733.1620247364044 and batch: 400, loss is 5.141202831268311 and perplexity is 170.92123413103133
At time: 734.3031332492828 and batch: 450, loss is 5.100424165725708 and perplexity is 164.09149452845895
At time: 735.4440486431122 and batch: 500, loss is 5.126059093475342 and perplexity is 168.35234813999702
At time: 736.6197152137756 and batch: 550, loss is 5.129678325653076 and perplexity is 168.96275831735483
At time: 737.7609765529633 and batch: 600, loss is 5.0759408664703365 and perplexity is 160.12277527928669
At time: 738.902327299118 and batch: 650, loss is 5.092600250244141 and perplexity is 162.81266579147598
At time: 740.0431196689606 and batch: 700, loss is 5.105117216110229 and perplexity is 164.86339404487472
At time: 741.1860020160675 and batch: 750, loss is 5.088196325302124 and perplexity is 162.09722755616522
At time: 742.3277904987335 and batch: 800, loss is 5.064561710357666 and perplexity is 158.31104077641834
At time: 743.4686155319214 and batch: 850, loss is 5.058459520339966 and perplexity is 157.34793822963758
At time: 744.609964132309 and batch: 900, loss is 5.095924615859985 and perplexity is 163.35481527170973
At time: 745.7521049976349 and batch: 950, loss is 5.0602511787414555 and perplexity is 157.63010468259134
At time: 746.8927826881409 and batch: 1000, loss is 5.08309458732605 and perplexity is 161.27235590317167
At time: 748.0341515541077 and batch: 1050, loss is 5.042995929718018 and perplexity is 154.93349025739556
At time: 749.1747789382935 and batch: 1100, loss is 5.046400537490845 and perplexity is 155.46187698698745
At time: 750.3157858848572 and batch: 1150, loss is 5.062673654556274 and perplexity is 158.0124226899696
At time: 751.4571032524109 and batch: 1200, loss is 5.0282157611846925 and perplexity is 152.6603869652519
At time: 752.5984861850739 and batch: 1250, loss is 5.050364971160889 and perplexity is 156.07941857905175
At time: 753.7397353649139 and batch: 1300, loss is 5.022131767272949 and perplexity is 151.7344217400011
At time: 754.8805651664734 and batch: 1350, loss is 5.011301012039184 and perplexity is 150.0998909373448
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.120403238932291 and perplexity of 167.40285936321595
Annealing...
Finished 23 epochs...
Completing Train Step...
At time: 758.3010125160217 and batch: 50, loss is 5.1217847919464115 and perplexity is 167.6342951217148
At time: 759.416232585907 and batch: 100, loss is 5.138662099838257 and perplexity is 170.4875203877938
At time: 760.537700176239 and batch: 150, loss is 5.106339664459228 and perplexity is 165.06505426322266
At time: 761.6686098575592 and batch: 200, loss is 5.100234661102295 and perplexity is 164.060401377824
At time: 762.7993469238281 and batch: 250, loss is 5.10282711982727 and perplexity is 164.48627298556355
At time: 763.9311747550964 and batch: 300, loss is 5.102044143676758 and perplexity is 164.3575345628634
At time: 765.0990369319916 and batch: 350, loss is 5.118283700942993 and perplexity is 167.04841840151224
At time: 766.2396392822266 and batch: 400, loss is 5.13915982246399 and perplexity is 170.57239700485005
At time: 767.3800933361053 and batch: 450, loss is 5.09781268119812 and perplexity is 163.6635311824379
At time: 768.5202851295471 and batch: 500, loss is 5.122795715332031 and perplexity is 167.80384623803985
At time: 769.6601893901825 and batch: 550, loss is 5.125091009140014 and perplexity is 168.18944773233588
At time: 770.7998323440552 and batch: 600, loss is 5.071337747573852 and perplexity is 159.3874049037385
At time: 771.9402375221252 and batch: 650, loss is 5.088116273880005 and perplexity is 162.08425196194216
At time: 773.0806033611298 and batch: 700, loss is 5.099518404006958 and perplexity is 163.94293402470788
At time: 774.2209684848785 and batch: 750, loss is 5.082836580276489 and perplexity is 161.2307518657477
At time: 775.3609685897827 and batch: 800, loss is 5.059067344665527 and perplexity is 157.44360720609058
At time: 776.5008244514465 and batch: 850, loss is 5.050871706008911 and perplexity is 156.1585295019427
At time: 777.6408467292786 and batch: 900, loss is 5.085910758972168 and perplexity is 161.72716665115
At time: 778.7806832790375 and batch: 950, loss is 5.050754556655884 and perplexity is 156.14023670275756
At time: 779.9211623668671 and batch: 1000, loss is 5.0743662548065185 and perplexity is 159.8708424898969
At time: 781.0616991519928 and batch: 1050, loss is 5.033514289855957 and perplexity is 153.47140911720334
At time: 782.2021098136902 and batch: 1100, loss is 5.0359547901153565 and perplexity is 153.84641354403624
At time: 783.3415343761444 and batch: 1150, loss is 5.052471914291382 and perplexity is 156.40861571588002
At time: 784.48144364357 and batch: 1200, loss is 5.016547327041626 and perplexity is 150.88943152542004
At time: 785.6211473941803 and batch: 1250, loss is 5.039258155822754 and perplexity is 154.3554648391327
At time: 786.76118516922 and batch: 1300, loss is 5.012523488998413 and perplexity is 150.28349679970083
At time: 787.9018630981445 and batch: 1350, loss is 5.003979263305664 and perplexity is 149.00491072759235
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.116578776041667 and perplexity of 166.76385604090936
Finished 24 epochs...
Completing Train Step...
At time: 791.3150360584259 and batch: 50, loss is 5.119212942123413 and perplexity is 167.20371881560996
At time: 792.4350082874298 and batch: 100, loss is 5.1359789943695064 and perplexity is 170.03069751551877
At time: 793.5871870517731 and batch: 150, loss is 5.103402624130249 and perplexity is 164.58096278802853
At time: 794.7196731567383 and batch: 200, loss is 5.097426204681397 and perplexity is 163.60029129214524
At time: 795.8586347103119 and batch: 250, loss is 5.100351705551147 and perplexity is 164.07960486089036
At time: 796.9965867996216 and batch: 300, loss is 5.0992977333068845 and perplexity is 163.9067606140372
At time: 798.1345493793488 and batch: 350, loss is 5.115953722000122 and perplexity is 166.65965218861953
At time: 799.2735314369202 and batch: 400, loss is 5.137133932113647 and perplexity is 170.2271858297862
At time: 800.411979675293 and batch: 450, loss is 5.095920562744141 and perplexity is 163.3541531770614
At time: 801.5507781505585 and batch: 500, loss is 5.12101333618164 and perplexity is 167.50502254881695
At time: 802.690810918808 and batch: 550, loss is 5.123756580352783 and perplexity is 167.965160572477
At time: 803.8291878700256 and batch: 600, loss is 5.070100736618042 and perplexity is 159.1903628343798
At time: 804.9672245979309 and batch: 650, loss is 5.087012691497803 and perplexity is 161.9054773014714
At time: 806.1062791347504 and batch: 700, loss is 5.09867033958435 and perplexity is 163.80395879332764
At time: 807.2450289726257 and batch: 750, loss is 5.082296543121338 and perplexity is 161.1437047756341
At time: 808.3837473392487 and batch: 800, loss is 5.058727331161499 and perplexity is 157.39008335344968
At time: 809.5223813056946 and batch: 850, loss is 5.0508179855346675 and perplexity is 156.1501408170048
At time: 810.6608695983887 and batch: 900, loss is 5.086016101837158 and perplexity is 161.7442043516161
At time: 811.7995798587799 and batch: 950, loss is 5.050795183181763 and perplexity is 156.14658026698243
At time: 812.93821144104 and batch: 1000, loss is 5.074573221206665 and perplexity is 159.90393380693274
At time: 814.0776047706604 and batch: 1050, loss is 5.033948841094971 and perplexity is 153.5381148006574
At time: 815.2172029018402 and batch: 1100, loss is 5.036634492874145 and perplexity is 153.95101892200663
At time: 816.3562633991241 and batch: 1150, loss is 5.053402290344239 and perplexity is 156.55420226101853
At time: 817.4949600696564 and batch: 1200, loss is 5.0177518749237064 and perplexity is 151.07129457998164
At time: 818.6332521438599 and batch: 1250, loss is 5.040411252975463 and perplexity is 154.53355434366134
At time: 819.7717077732086 and batch: 1300, loss is 5.013599700927735 and perplexity is 150.445320754553
At time: 820.9102051258087 and batch: 1350, loss is 5.0041851234436034 and perplexity is 149.03558805657968
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.116263020833333 and perplexity of 166.71120779721863
Finished 25 epochs...
Completing Train Step...
At time: 824.2929534912109 and batch: 50, loss is 5.117899179458618 and perplexity is 166.98419704374317
At time: 825.4362561702728 and batch: 100, loss is 5.134488744735718 and perplexity is 169.7774980428838
At time: 826.5659680366516 and batch: 150, loss is 5.101820087432861 and perplexity is 164.32071335617778
At time: 827.7046318054199 and batch: 200, loss is 5.095902576446533 and perplexity is 163.35121506706983
At time: 828.8429141044617 and batch: 250, loss is 5.0989399337768555 and perplexity is 163.84812534258276
At time: 829.9814646244049 and batch: 300, loss is 5.097802057266235 and perplexity is 163.66179244146664
At time: 831.1190621852875 and batch: 350, loss is 5.114631509780883 and perplexity is 166.4394383768204
At time: 832.2573821544647 and batch: 400, loss is 5.135891342163086 and perplexity is 170.01579460286848
At time: 833.3954973220825 and batch: 450, loss is 5.0948085021972656 and perplexity is 163.1725944390106
At time: 834.5334551334381 and batch: 500, loss is 5.119880361557007 and perplexity is 167.3153510755426
At time: 835.6721413135529 and batch: 550, loss is 5.122908477783203 and perplexity is 167.8227692779419
At time: 836.8107523918152 and batch: 600, loss is 5.069317140579224 and perplexity is 159.06567075713392
At time: 837.953045129776 and batch: 650, loss is 5.086333456039429 and perplexity is 161.79554270034956
At time: 839.091283082962 and batch: 700, loss is 5.098187503814697 and perplexity is 163.72488747357832
At time: 840.2287263870239 and batch: 750, loss is 5.081955108642578 and perplexity is 161.08869415058516
At time: 841.3663744926453 and batch: 800, loss is 5.058568458557129 and perplexity is 157.36508036720267
At time: 842.5047769546509 and batch: 850, loss is 5.050752754211426 and perplexity is 156.13995526890693
At time: 843.643061876297 and batch: 900, loss is 5.085992851257324 and perplexity is 161.74044374879844
At time: 844.7809672355652 and batch: 950, loss is 5.050745964050293 and perplexity is 156.1388950570509
At time: 845.9194366931915 and batch: 1000, loss is 5.074659166336059 and perplexity is 159.91767736180168
At time: 847.0574007034302 and batch: 1050, loss is 5.0341739845275875 and perplexity is 153.5726867905433
At time: 848.1957416534424 and batch: 1100, loss is 5.036994571685791 and perplexity is 154.00646340354416
At time: 849.3335709571838 and batch: 1150, loss is 5.053924942016602 and perplexity is 156.63604696291782
At time: 850.4715511798859 and batch: 1200, loss is 5.018444166183472 and perplexity is 151.1759161269336
At time: 851.6377620697021 and batch: 1250, loss is 5.0410490894317626 and perplexity is 154.63215291988365
At time: 852.7753489017487 and batch: 1300, loss is 5.014143381118775 and perplexity is 150.527137134239
At time: 853.9132745265961 and batch: 1350, loss is 5.00414966583252 and perplexity is 149.03030370434655
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.116121826171875 and perplexity of 166.6876707263658
Finished 26 epochs...
Completing Train Step...
At time: 857.2766454219818 and batch: 50, loss is 5.116782217025757 and perplexity is 166.79778609515776
At time: 858.4265012741089 and batch: 100, loss is 5.1334186553955075 and perplexity is 169.59591812271617
At time: 859.5626449584961 and batch: 150, loss is 5.100644617080689 and perplexity is 164.12767270838643
At time: 860.7001111507416 and batch: 200, loss is 5.09474513053894 and perplexity is 163.1622542487487
At time: 861.8384432792664 and batch: 250, loss is 5.097859983444214 and perplexity is 163.67127301816808
At time: 862.9774806499481 and batch: 300, loss is 5.096677856445313 and perplexity is 163.47790710144204
At time: 864.1155986785889 and batch: 350, loss is 5.1137236309051515 and perplexity is 166.28840009923456
At time: 865.2546017169952 and batch: 400, loss is 5.134983997344971 and perplexity is 169.86160161632012
At time: 866.392516374588 and batch: 450, loss is 5.093955602645874 and perplexity is 163.03348393848873
At time: 867.5302233695984 and batch: 500, loss is 5.1189992809295655 and perplexity is 167.16799768567756
At time: 868.6686339378357 and batch: 550, loss is 5.122210102081299 and perplexity is 167.70560685011026
At time: 869.806697845459 and batch: 600, loss is 5.068737163543701 and perplexity is 158.9734430685107
At time: 870.9456167221069 and batch: 650, loss is 5.085785369873047 and perplexity is 161.70688909873886
At time: 872.0839750766754 and batch: 700, loss is 5.097791223526001 and perplexity is 163.6600193817256
At time: 873.2225272655487 and batch: 750, loss is 5.081678085327148 and perplexity is 161.04407500701015
At time: 874.3613328933716 and batch: 800, loss is 5.058429527282715 and perplexity is 157.343218954691
At time: 875.4996376037598 and batch: 850, loss is 5.050667562484741 and perplexity is 156.12665400310007
At time: 876.637136220932 and batch: 900, loss is 5.085970230102539 and perplexity is 161.73678503456773
At time: 877.7757377624512 and batch: 950, loss is 5.050661916732788 and perplexity is 156.12577255322654
At time: 878.9138853549957 and batch: 1000, loss is 5.074688215255737 and perplexity is 159.92232286503952
At time: 880.0887274742126 and batch: 1050, loss is 5.034330139160156 and perplexity is 153.59666974949798
At time: 881.2267072200775 and batch: 1100, loss is 5.037197151184082 and perplexity is 154.03766511594094
At time: 882.3649604320526 and batch: 1150, loss is 5.054256343841553 and perplexity is 156.68796503713156
At time: 883.5035996437073 and batch: 1200, loss is 5.01890998840332 and perplexity is 151.24635363217524
At time: 884.6418604850769 and batch: 1250, loss is 5.041431941986084 and perplexity is 154.69136556874292
At time: 885.7804498672485 and batch: 1300, loss is 5.014470376968384 and perplexity is 150.57636693186657
At time: 886.9189124107361 and batch: 1350, loss is 5.004003496170044 and perplexity is 149.00852158713653
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.116075439453125 and perplexity of 166.67993881159526
Finished 27 epochs...
Completing Train Step...
At time: 890.3219027519226 and batch: 50, loss is 5.115844821929931 and perplexity is 166.64150392898952
At time: 891.4401905536652 and batch: 100, loss is 5.132472801208496 and perplexity is 169.43558095320495
At time: 892.5744001865387 and batch: 150, loss is 5.099563074111939 and perplexity is 163.95025753635136
At time: 893.7130048274994 and batch: 200, loss is 5.093784265518188 and perplexity is 163.00555264253646
At time: 894.8506724834442 and batch: 250, loss is 5.096970930099487 and perplexity is 163.5258251904748
At time: 895.9885692596436 and batch: 300, loss is 5.095712070465088 and perplexity is 163.32009864754937
At time: 897.1266543865204 and batch: 350, loss is 5.112920331954956 and perplexity is 166.15487443969644
At time: 898.265053987503 and batch: 400, loss is 5.134228076934814 and perplexity is 169.7332482833204
At time: 899.4035682678223 and batch: 450, loss is 5.093230495452881 and perplexity is 162.9153100361373
At time: 900.5420351028442 and batch: 500, loss is 5.1182206439971925 and perplexity is 167.03788517054716
At time: 901.6796200275421 and batch: 550, loss is 5.121598405838013 and perplexity is 167.60305332942139
At time: 902.817389011383 and batch: 600, loss is 5.068239355087281 and perplexity is 158.8943244388003
At time: 903.9556205272675 and batch: 650, loss is 5.08534013748169 and perplexity is 161.63490797915847
At time: 905.093959569931 and batch: 700, loss is 5.097439403533936 and perplexity is 163.60245064251578
At time: 906.2326579093933 and batch: 750, loss is 5.081407947540283 and perplexity is 161.00057679252023
At time: 907.3715467453003 and batch: 800, loss is 5.058259363174439 and perplexity is 157.31644706401633
At time: 908.5365297794342 and batch: 850, loss is 5.0505242443084715 and perplexity is 156.10427981913315
At time: 909.6744334697723 and batch: 900, loss is 5.08585638999939 and perplexity is 161.71837395025608
At time: 910.8126885890961 and batch: 950, loss is 5.050517435073853 and perplexity is 156.1032168720858
At time: 911.9505844116211 and batch: 1000, loss is 5.074601936340332 and perplexity is 159.90852553569152
At time: 913.088880777359 and batch: 1050, loss is 5.034393348693848 and perplexity is 153.60637883021943
At time: 914.2274580001831 and batch: 1100, loss is 5.037294607162476 and perplexity is 154.05267773882736
At time: 915.365297794342 and batch: 1150, loss is 5.0544552230834965 and perplexity is 156.71913011978108
At time: 916.5033345222473 and batch: 1200, loss is 5.019251308441162 and perplexity is 151.2979858543752
At time: 917.6410298347473 and batch: 1250, loss is 5.041686353683471 and perplexity is 154.73072586827644
At time: 918.7791039943695 and batch: 1300, loss is 5.014671506881714 and perplexity is 150.6066553893525
At time: 919.917299747467 and batch: 1350, loss is 5.003777284622192 and perplexity is 148.97481795104477
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.116045328776042 and perplexity of 166.6749200413411
Finished 28 epochs...
Completing Train Step...
At time: 923.3222224712372 and batch: 50, loss is 5.114909992218018 and perplexity is 166.4857952917486
At time: 924.4521343708038 and batch: 100, loss is 5.131598310470581 and perplexity is 169.28747587468627
At time: 925.5924894809723 and batch: 150, loss is 5.0986404132843015 and perplexity is 163.79905682025694
At time: 926.7324302196503 and batch: 200, loss is 5.092914628982544 and perplexity is 162.8638586784995
At time: 927.8723661899567 and batch: 250, loss is 5.096128711700439 and perplexity is 163.38815871253783
At time: 929.0127987861633 and batch: 300, loss is 5.094826612472534 and perplexity is 163.1755495663712
At time: 930.1527285575867 and batch: 350, loss is 5.112213525772095 and perplexity is 166.03747664076243
At time: 931.292647600174 and batch: 400, loss is 5.1335227489471436 and perplexity is 169.61357288303395
At time: 932.4324743747711 and batch: 450, loss is 5.092549772262573 and perplexity is 162.80444754415512
At time: 933.5727832317352 and batch: 500, loss is 5.117502126693726 and perplexity is 166.917908667476
At time: 934.7135033607483 and batch: 550, loss is 5.121034450531006 and perplexity is 167.508559345722
At time: 935.8545100688934 and batch: 600, loss is 5.067750797271729 and perplexity is 158.8167143348041
At time: 936.9945101737976 and batch: 650, loss is 5.084856615066529 and perplexity is 161.55677276966298
At time: 938.16224360466 and batch: 700, loss is 5.0971221923828125 and perplexity is 163.5505623510283
At time: 939.3020401000977 and batch: 750, loss is 5.081136465072632 and perplexity is 160.95687389119348
At time: 940.4425144195557 and batch: 800, loss is 5.058107938766479 and perplexity is 157.29262731764842
At time: 941.5830233097076 and batch: 850, loss is 5.050384693145752 and perplexity is 156.08249680533666
At time: 942.7236170768738 and batch: 900, loss is 5.085727548599243 and perplexity is 161.6975392707403
At time: 943.8633348941803 and batch: 950, loss is 5.050325231552124 and perplexity is 156.07321616726276
At time: 945.0034806728363 and batch: 1000, loss is 5.074474840164185 and perplexity is 159.88820306504414
At time: 946.1439821720123 and batch: 1050, loss is 5.034405097961426 and perplexity is 153.60818360326843
At time: 947.2843046188354 and batch: 1100, loss is 5.037316856384277 and perplexity is 154.05610532915387
At time: 948.4245665073395 and batch: 1150, loss is 5.054586410522461 and perplexity is 156.73969104973662
At time: 949.5649909973145 and batch: 1200, loss is 5.0194987964630124 and perplexity is 151.33543492751164
At time: 950.7044622898102 and batch: 1250, loss is 5.041866960525513 and perplexity is 154.758673819762
At time: 951.8444550037384 and batch: 1300, loss is 5.014804983139038 and perplexity is 150.62675914369908
At time: 952.984587430954 and batch: 1350, loss is 5.00352855682373 and perplexity is 148.93776838036968
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.11605224609375 and perplexity of 166.67607298870462
Annealing...
Finished 29 epochs...
Completing Train Step...
At time: 956.3628931045532 and batch: 50, loss is 5.114436130523682 and perplexity is 166.40692273952527
At time: 957.50510430336 and batch: 100, loss is 5.131324081420899 and perplexity is 169.24105869581433
At time: 958.633866071701 and batch: 150, loss is 5.098502235412598 and perplexity is 163.7764249788443
At time: 959.7741825580597 and batch: 200, loss is 5.092984275817871 and perplexity is 162.87520202585517
At time: 960.914496421814 and batch: 250, loss is 5.095569448471069 and perplexity is 163.29680727038777
At time: 962.0556406974792 and batch: 300, loss is 5.094565715789795 and perplexity is 163.13298315974373
At time: 963.1963000297546 and batch: 350, loss is 5.111642646789551 and perplexity is 165.94271638592605
At time: 964.3375158309937 and batch: 400, loss is 5.133088064193726 and perplexity is 169.53986047092047
At time: 965.4777357578278 and batch: 450, loss is 5.0917924118041995 and perplexity is 162.68119257325003
At time: 966.646249294281 and batch: 500, loss is 5.116167964935303 and perplexity is 166.69536166679578
At time: 967.7870028018951 and batch: 550, loss is 5.1189870262146 and perplexity is 167.16594910206703
At time: 968.9277997016907 and batch: 600, loss is 5.065379810333252 and perplexity is 158.4406080272684
At time: 970.0689580440521 and batch: 650, loss is 5.082940101623535 and perplexity is 161.24744355432415
At time: 971.2103798389435 and batch: 700, loss is 5.094523067474365 and perplexity is 163.12602596117844
At time: 972.3509466648102 and batch: 750, loss is 5.0786957359313964 and perplexity is 160.56450079162
At time: 973.4912109375 and batch: 800, loss is 5.055916862487793 and perplexity is 156.9483644639352
At time: 974.6319515705109 and batch: 850, loss is 5.047383623123169 and perplexity is 155.61478447288883
At time: 975.7730321884155 and batch: 900, loss is 5.082089738845825 and perplexity is 161.11038301417474
At time: 976.914119720459 and batch: 950, loss is 5.046028165817261 and perplexity is 155.40399816456107
At time: 978.0545876026154 and batch: 1000, loss is 5.07049518585205 and perplexity is 159.25316773691986
At time: 979.1956853866577 and batch: 1050, loss is 5.030041589736938 and perplexity is 152.93937327164832
At time: 980.3357181549072 and batch: 1100, loss is 5.032855033874512 and perplexity is 153.37026551618717
At time: 981.4770579338074 and batch: 1150, loss is 5.050219230651855 and perplexity is 156.0566731426444
At time: 982.6177911758423 and batch: 1200, loss is 5.014806041717529 and perplexity is 150.62691859403083
At time: 983.7590937614441 and batch: 1250, loss is 5.036856489181519 and perplexity is 153.9851992735392
At time: 984.8996117115021 and batch: 1300, loss is 5.010209369659424 and perplexity is 149.93612493841565
At time: 986.0409693717957 and batch: 1350, loss is 4.999977483749389 and perplexity is 148.40981743231342
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.114170328776042 and perplexity of 166.36269736649274
Finished 30 epochs...
Completing Train Step...
At time: 989.422055721283 and batch: 50, loss is 5.1134006690979 and perplexity is 166.23470396838005
At time: 990.5703501701355 and batch: 100, loss is 5.130248908996582 and perplexity is 169.05919316236532
At time: 991.7001357078552 and batch: 150, loss is 5.0974940490722656 and perplexity is 163.61139103077716
At time: 992.8378341197968 and batch: 200, loss is 5.09203706741333 and perplexity is 162.72099830866284
At time: 993.9784958362579 and batch: 250, loss is 5.094812335968018 and perplexity is 163.17322000652987
At time: 995.1467840671539 and batch: 300, loss is 5.093857660293579 and perplexity is 163.01751683750942
At time: 996.2867913246155 and batch: 350, loss is 5.1109279441833495 and perplexity is 165.82415906570438
At time: 997.4269773960114 and batch: 400, loss is 5.132516746520996 and perplexity is 169.44302701636715
At time: 998.5672709941864 and batch: 450, loss is 5.091266050338745 and perplexity is 162.59558599430392
At time: 999.7068524360657 and batch: 500, loss is 5.115650939941406 and perplexity is 166.60919827468038
At time: 1000.8469090461731 and batch: 550, loss is 5.118600931167602 and perplexity is 167.10141961515131
At time: 1001.9869437217712 and batch: 600, loss is 5.065138635635376 and perplexity is 158.40240076899323
At time: 1003.1274511814117 and batch: 650, loss is 5.08265531539917 and perplexity is 161.20152904190638
At time: 1004.267612695694 and batch: 700, loss is 5.094323635101318 and perplexity is 163.09349659452747
At time: 1005.4091317653656 and batch: 750, loss is 5.0785531902313235 and perplexity is 160.54161464364753
At time: 1006.5535032749176 and batch: 800, loss is 5.055918607711792 and perplexity is 156.9486383742265
At time: 1007.6935498714447 and batch: 850, loss is 5.047463617324829 and perplexity is 155.62723325124765
At time: 1008.8328478336334 and batch: 900, loss is 5.082166042327881 and perplexity is 161.12267676641608
At time: 1009.9728381633759 and batch: 950, loss is 5.046044893264771 and perplexity is 155.4065976985249
At time: 1011.1126263141632 and batch: 1000, loss is 5.07056155204773 and perplexity is 159.26373711453326
At time: 1012.2532227039337 and batch: 1050, loss is 5.030117444992065 and perplexity is 152.95097496684602
At time: 1013.3923952579498 and batch: 1100, loss is 5.033073778152466 and perplexity is 153.40381805375617
At time: 1014.5318732261658 and batch: 1150, loss is 5.050493745803833 and perplexity is 156.0995189446312
At time: 1015.6721737384796 and batch: 1200, loss is 5.01518027305603 and perplexity is 150.6832984562882
At time: 1016.8116195201874 and batch: 1250, loss is 5.037170419692993 and perplexity is 154.03354751450357
At time: 1017.9518871307373 and batch: 1300, loss is 5.010424690246582 and perplexity is 149.96841274886404
At time: 1019.0918469429016 and batch: 1350, loss is 5.000045547485351 and perplexity is 148.4199191027161
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.114110514322917 and perplexity of 166.3527467703271
Finished 31 epochs...
Completing Train Step...
At time: 1022.4989936351776 and batch: 50, loss is 5.112814149856567 and perplexity is 166.1372327031058
At time: 1023.6379725933075 and batch: 100, loss is 5.129571981430054 and perplexity is 168.94479105947585
At time: 1024.8039512634277 and batch: 150, loss is 5.096885261535644 and perplexity is 163.5118167679288
At time: 1025.9426126480103 and batch: 200, loss is 5.091446323394775 and perplexity is 162.6249002396931
At time: 1027.081527709961 and batch: 250, loss is 5.09432825088501 and perplexity is 163.0942494005666
At time: 1028.2198295593262 and batch: 300, loss is 5.093382244110107 and perplexity is 162.9400340915506
At time: 1029.3581910133362 and batch: 350, loss is 5.110497703552246 and perplexity is 165.75283012026134
At time: 1030.4961063861847 and batch: 400, loss is 5.132167119979858 and perplexity is 169.38379559195386
At time: 1031.6349213123322 and batch: 450, loss is 5.090932464599609 and perplexity is 162.54135547133723
At time: 1032.7738752365112 and batch: 500, loss is 5.115269203186035 and perplexity is 166.5456095577634
At time: 1033.9129164218903 and batch: 550, loss is 5.118329982757569 and perplexity is 167.05614988434996
At time: 1035.0512065887451 and batch: 600, loss is 5.064945964813233 and perplexity is 158.37188418812943
At time: 1036.1902418136597 and batch: 650, loss is 5.082478771209717 and perplexity is 161.17307236062786
At time: 1037.328929901123 and batch: 700, loss is 5.094202480316162 and perplexity is 163.07373823392132
At time: 1038.4681272506714 and batch: 750, loss is 5.078471879959107 and perplexity is 160.52856149194363
At time: 1039.6066370010376 and batch: 800, loss is 5.055983419418335 and perplexity is 156.95881081296213
At time: 1040.745584487915 and batch: 850, loss is 5.047557773590088 and perplexity is 155.64188722017388
At time: 1041.884800195694 and batch: 900, loss is 5.082208986282349 and perplexity is 161.1295961598829
At time: 1043.023110628128 and batch: 950, loss is 5.046042432785034 and perplexity is 155.4062153242108
At time: 1044.1611988544464 and batch: 1000, loss is 5.070606651306153 and perplexity is 159.27091995293992
At time: 1045.2993624210358 and batch: 1050, loss is 5.030149774551392 and perplexity is 152.95591988439833
At time: 1046.4384689331055 and batch: 1100, loss is 5.033189744949341 and perplexity is 153.4216088347142
At time: 1047.5771226882935 and batch: 1150, loss is 5.0506508159637455 and perplexity is 156.12403944670325
At time: 1048.7157385349274 and batch: 1200, loss is 5.0153961181640625 and perplexity is 150.7158262194752
At time: 1049.8531951904297 and batch: 1250, loss is 5.037335634231567 and perplexity is 154.05899819833476
At time: 1050.9911210536957 and batch: 1300, loss is 5.010546064376831 and perplexity is 149.9866161392142
At time: 1052.1290483474731 and batch: 1350, loss is 5.0000368309021 and perplexity is 148.41862539377343
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.114066162109375 and perplexity of 166.34536882139446
Finished 32 epochs...
Completing Train Step...
At time: 1055.5280454158783 and batch: 50, loss is 5.112312068939209 and perplexity is 166.05383930577148
At time: 1056.645682811737 and batch: 100, loss is 5.12899224281311 and perplexity is 168.84687562538878
At time: 1057.770402431488 and batch: 150, loss is 5.0963598823547365 and perplexity is 163.42593362614934
At time: 1058.9010078907013 and batch: 200, loss is 5.090919981002807 and perplexity is 162.5393263832571
At time: 1060.039299249649 and batch: 250, loss is 5.093888368606567 and perplexity is 163.02252290730263
At time: 1061.1771397590637 and batch: 300, loss is 5.092982778549194 and perplexity is 162.8749581580995
At time: 1062.3152961730957 and batch: 350, loss is 5.110199995040894 and perplexity is 165.70349143659124
At time: 1063.4531774520874 and batch: 400, loss is 5.131877031326294 and perplexity is 169.33466640100994
At time: 1064.590983390808 and batch: 450, loss is 5.090611066818237 and perplexity is 162.48912343438758
At time: 1065.7300107479095 and batch: 500, loss is 5.114900932312012 and perplexity is 166.48428695292463
At time: 1066.868197441101 and batch: 550, loss is 5.118078079223633 and perplexity is 167.01407314968992
At time: 1068.006718635559 and batch: 600, loss is 5.06476450920105 and perplexity is 158.34314932806112
At time: 1069.1448545455933 and batch: 650, loss is 5.082327795028687 and perplexity is 161.1487409024595
At time: 1070.28293967247 and batch: 700, loss is 5.094098424911499 and perplexity is 163.05677041291148
At time: 1071.4209420681 and batch: 750, loss is 5.078413124084473 and perplexity is 160.51912977299656
At time: 1072.559159040451 and batch: 800, loss is 5.056055326461792 and perplexity is 156.97009766278927
At time: 1073.6974604129791 and batch: 850, loss is 5.047631177902222 and perplexity is 155.65331242516896
At time: 1074.8363738059998 and batch: 900, loss is 5.082242679595947 and perplexity is 161.1350252413577
At time: 1075.975025653839 and batch: 950, loss is 5.046019382476807 and perplexity is 155.40263320433175
At time: 1077.1131129264832 and batch: 1000, loss is 5.070608787536621 and perplexity is 159.2712601926952
At time: 1078.2513144016266 and batch: 1050, loss is 5.030159683227539 and perplexity is 152.957435482582
At time: 1079.389405965805 and batch: 1100, loss is 5.0332308101654055 and perplexity is 153.42790925559322
At time: 1080.527726650238 and batch: 1150, loss is 5.050748434066772 and perplexity is 156.13928072317105
At time: 1081.694818019867 and batch: 1200, loss is 5.015547189712525 and perplexity is 150.73859681267098
At time: 1082.8324348926544 and batch: 1250, loss is 5.037432765960693 and perplexity is 154.07396294198105
At time: 1083.9703135490417 and batch: 1300, loss is 5.010623731613159 and perplexity is 149.9982656375623
At time: 1085.1118178367615 and batch: 1350, loss is 4.99998872756958 and perplexity is 148.4114861349964
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1140625 and perplexity of 166.34475964757527
Finished 33 epochs...
Completing Train Step...
At time: 1088.4961795806885 and batch: 50, loss is 5.111828889846802 and perplexity is 165.973624942917
At time: 1089.6735167503357 and batch: 100, loss is 5.12847318649292 and perplexity is 168.75925732883354
At time: 1090.8075470924377 and batch: 150, loss is 5.095947246551514 and perplexity is 163.3585121459751
At time: 1091.952852010727 and batch: 200, loss is 5.090505142211914 and perplexity is 162.47191274948952
At time: 1093.1035325527191 and batch: 250, loss is 5.093510723114013 and perplexity is 162.9609698096984
At time: 1094.255693435669 and batch: 300, loss is 5.0926389980316165 and perplexity is 162.8189745442727
At time: 1095.4067902565002 and batch: 350, loss is 5.1099032783508305 and perplexity is 165.65433173869232
At time: 1096.5592167377472 and batch: 400, loss is 5.1316296672821045 and perplexity is 169.29278427338733
At time: 1097.710424900055 and batch: 450, loss is 5.09035367012024 and perplexity is 162.4473046527941
At time: 1098.8627042770386 and batch: 500, loss is 5.114620409011841 and perplexity is 166.43759078131026
At time: 1100.0137031078339 and batch: 550, loss is 5.117870187759399 and perplexity is 166.97935595830413
At time: 1101.1657192707062 and batch: 600, loss is 5.064593801498413 and perplexity is 158.31612123982814
At time: 1102.3205456733704 and batch: 650, loss is 5.08217230796814 and perplexity is 161.123686306309
At time: 1103.4733276367188 and batch: 700, loss is 5.093979873657227 and perplexity is 163.0374409740487
At time: 1104.6245336532593 and batch: 750, loss is 5.0783429527282715 and perplexity is 160.50786632315456
At time: 1105.7751922607422 and batch: 800, loss is 5.056099920272827 and perplexity is 156.97709771374105
At time: 1106.9275770187378 and batch: 850, loss is 5.047650995254517 and perplexity is 155.65639709226207
At time: 1108.079924583435 and batch: 900, loss is 5.08224271774292 and perplexity is 161.13503138817123
At time: 1109.2306010723114 and batch: 950, loss is 5.045982971191406 and perplexity is 155.3969748977158
At time: 1110.3826262950897 and batch: 1000, loss is 5.070592231750489 and perplexity is 159.26862335360198
At time: 1111.5821542739868 and batch: 1050, loss is 5.030142374038697 and perplexity is 152.95478793635993
At time: 1112.7333931922913 and batch: 1100, loss is 5.033274459838867 and perplexity is 153.43460647989687
At time: 1113.8852274417877 and batch: 1150, loss is 5.050832099914551 and perplexity is 156.15234479496502
At time: 1115.03684091568 and batch: 1200, loss is 5.015674266815186 and perplexity is 150.75775345397258
At time: 1116.188146829605 and batch: 1250, loss is 5.0375044059753415 and perplexity is 154.08500119832888
At time: 1117.3406419754028 and batch: 1300, loss is 5.010676736831665 and perplexity is 150.00621653912572
At time: 1118.491857290268 and batch: 1350, loss is 4.999921426773072 and perplexity is 148.4014982598683
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.114058430989584 and perplexity of 166.34408279039258
Finished 34 epochs...
Completing Train Step...
At time: 1122.0273842811584 and batch: 50, loss is 5.111394844055176 and perplexity is 165.90160042159062
At time: 1123.2030022144318 and batch: 100, loss is 5.128015546798706 and perplexity is 168.68204406318904
At time: 1124.3343431949615 and batch: 150, loss is 5.0955696868896485 and perplexity is 163.29684620338517
At time: 1125.4767215251923 and batch: 200, loss is 5.090125532150268 and perplexity is 162.41024848160384
At time: 1126.6274735927582 and batch: 250, loss is 5.093160047531128 and perplexity is 162.90383339538099
At time: 1127.7783975601196 and batch: 300, loss is 5.092322816848755 and perplexity is 162.76750238600178
At time: 1128.9286711215973 and batch: 350, loss is 5.109634094238281 and perplexity is 165.60974622553837
At time: 1130.0802071094513 and batch: 400, loss is 5.131407070159912 and perplexity is 169.25510438067354
At time: 1131.2312161922455 and batch: 450, loss is 5.090112991333008 and perplexity is 162.4082117371277
At time: 1132.382604598999 and batch: 500, loss is 5.114355087280273 and perplexity is 166.393437129247
At time: 1133.5331337451935 and batch: 550, loss is 5.117677145004272 and perplexity is 166.94712491446546
At time: 1134.6831467151642 and batch: 600, loss is 5.064428730010986 and perplexity is 158.2899899190388
At time: 1135.8338823318481 and batch: 650, loss is 5.082034273147583 and perplexity is 161.1014471621057
At time: 1136.9844579696655 and batch: 700, loss is 5.093866348266602 and perplexity is 163.0189331354503
At time: 1138.1365942955017 and batch: 750, loss is 5.0782742595672605 and perplexity is 160.49684090913928
At time: 1139.2866804599762 and batch: 800, loss is 5.056116085052491 and perplexity is 156.97963523444693
At time: 1140.4855027198792 and batch: 850, loss is 5.047667045593261 and perplexity is 155.6588954502128
At time: 1141.636151790619 and batch: 900, loss is 5.082229461669922 and perplexity is 161.13289538459009
At time: 1142.7866899967194 and batch: 950, loss is 5.045934829711914 and perplexity is 155.38949403750698
At time: 1143.9375088214874 and batch: 1000, loss is 5.070545120239258 and perplexity is 159.26112014480927
At time: 1145.0884008407593 and batch: 1050, loss is 5.030099840164184 and perplexity is 152.9482823149594
At time: 1146.2401597499847 and batch: 1100, loss is 5.033286228179931 and perplexity is 153.43641216130192
At time: 1147.3904790878296 and batch: 1150, loss is 5.050890674591065 and perplexity is 156.16149163593224
At time: 1148.5395023822784 and batch: 1200, loss is 5.015788230895996 and perplexity is 150.77493540181388
At time: 1149.6906609535217 and batch: 1250, loss is 5.037530794143676 and perplexity is 154.0890672729263
At time: 1150.8405227661133 and batch: 1300, loss is 5.01070008277893 and perplexity is 150.00971861722599
At time: 1151.9919238090515 and batch: 1350, loss is 4.999828109741211 and perplexity is 148.3876505186521
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.114046223958334 and perplexity of 166.3420522353693
Finished 35 epochs...
Completing Train Step...
At time: 1155.5812647342682 and batch: 50, loss is 5.110992498397827 and perplexity is 165.83486405955685
At time: 1156.7119209766388 and batch: 100, loss is 5.127590656280518 and perplexity is 168.610387886171
At time: 1157.8299350738525 and batch: 150, loss is 5.095219078063965 and perplexity is 163.239602923486
At time: 1158.9686887264252 and batch: 200, loss is 5.089762725830078 and perplexity is 162.35133570460118
At time: 1160.1088643074036 and batch: 250, loss is 5.09282958984375 and perplexity is 162.85000946508777
At time: 1161.2486696243286 and batch: 300, loss is 5.092023038864136 and perplexity is 162.7187155851448
At time: 1162.3899192810059 and batch: 350, loss is 5.10936858177185 and perplexity is 165.5657806103208
At time: 1163.5306208133698 and batch: 400, loss is 5.131187009811401 and perplexity is 169.2178621413367
At time: 1164.671374797821 and batch: 450, loss is 5.08991660118103 and perplexity is 162.37631949550573
At time: 1165.8124537467957 and batch: 500, loss is 5.114094715118409 and perplexity is 166.35011855002233
At time: 1166.9528748989105 and batch: 550, loss is 5.117481098175049 and perplexity is 166.91439866802133
At time: 1168.092975616455 and batch: 600, loss is 5.064262638092041 and perplexity is 158.26370141407784
At time: 1169.2603447437286 and batch: 650, loss is 5.081900463104248 and perplexity is 161.07989161268634
At time: 1170.4003789424896 and batch: 700, loss is 5.093742160797119 and perplexity is 162.9986894836965
At time: 1171.5409615039825 and batch: 750, loss is 5.078200521469117 and perplexity is 160.48500661365713
At time: 1172.680659532547 and batch: 800, loss is 5.056116056442261 and perplexity is 156.97963074322357
At time: 1173.8215594291687 and batch: 850, loss is 5.047673530578614 and perplexity is 155.6599048991429
At time: 1174.960830450058 and batch: 900, loss is 5.08219430923462 and perplexity is 161.12723127046434
At time: 1176.1014292240143 and batch: 950, loss is 5.045887985229492 and perplexity is 155.38221506757608
At time: 1177.241527080536 and batch: 1000, loss is 5.070499649047852 and perplexity is 159.2538785165756
At time: 1178.3819091320038 and batch: 1050, loss is 5.030046157836914 and perplexity is 152.94007191559137
At time: 1179.522843837738 and batch: 1100, loss is 5.033268337249756 and perplexity is 153.43366706572178
At time: 1180.6629664897919 and batch: 1150, loss is 5.050929012298584 and perplexity is 156.16747862428738
At time: 1181.8030886650085 and batch: 1200, loss is 5.015872249603271 and perplexity is 150.78760384916166
At time: 1182.9431068897247 and batch: 1250, loss is 5.037556743621826 and perplexity is 154.0930658556909
At time: 1184.0831909179688 and batch: 1300, loss is 5.010711059570313 and perplexity is 150.01136525164998
At time: 1185.2234926223755 and batch: 1350, loss is 4.99972897529602 and perplexity is 148.37294092037075
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.114037272135417 and perplexity of 166.34056317743898
Finished 36 epochs...
Completing Train Step...
At time: 1188.630137681961 and batch: 50, loss is 5.110605716705322 and perplexity is 165.7707345730147
At time: 1189.7538189888 and batch: 100, loss is 5.127192277908325 and perplexity is 168.54323053221697
At time: 1190.8846554756165 and batch: 150, loss is 5.094882507324218 and perplexity is 163.18467049441676
At time: 1192.0233976840973 and batch: 200, loss is 5.089427680969238 and perplexity is 162.2969498352846
At time: 1193.1641597747803 and batch: 250, loss is 5.092512884140015 and perplexity is 162.79844210450648
At time: 1194.3049583435059 and batch: 300, loss is 5.091736354827881 and perplexity is 162.67207341308912
At time: 1195.4461810588837 and batch: 350, loss is 5.109120903015136 and perplexity is 165.52477856150273
At time: 1196.5871403217316 and batch: 400, loss is 5.130968542098999 and perplexity is 169.18089754003
At time: 1197.7278265953064 and batch: 450, loss is 5.089707193374633 and perplexity is 162.34232018661402
At time: 1198.8957324028015 and batch: 500, loss is 5.113864316940307 and perplexity is 166.31179620065072
At time: 1200.0365285873413 and batch: 550, loss is 5.117288589477539 and perplexity is 166.88226928722992
At time: 1201.1775290966034 and batch: 600, loss is 5.064099798202514 and perplexity is 158.23793186863546
At time: 1202.3183951377869 and batch: 650, loss is 5.081778554916382 and perplexity is 161.06025585190247
At time: 1203.4597368240356 and batch: 700, loss is 5.093609733581543 and perplexity is 162.9771054502938
At time: 1204.6000752449036 and batch: 750, loss is 5.078120212554932 and perplexity is 160.472118754545
At time: 1205.7417063713074 and batch: 800, loss is 5.05609787940979 and perplexity is 156.97677734531146
At time: 1206.88250207901 and batch: 850, loss is 5.047673053741455 and perplexity is 155.65983067473388
At time: 1208.023645401001 and batch: 900, loss is 5.082138652801514 and perplexity is 161.11826375304793
At time: 1209.1644978523254 and batch: 950, loss is 5.045825824737549 and perplexity is 155.37255673283482
At time: 1210.304477930069 and batch: 1000, loss is 5.070426731109619 and perplexity is 159.24226647546686
At time: 1211.4448506832123 and batch: 1050, loss is 5.0299832725524904 and perplexity is 152.93045453806815
At time: 1212.585615158081 and batch: 1100, loss is 5.033246088027954 and perplexity is 153.43025332400805
At time: 1213.7266595363617 and batch: 1150, loss is 5.050962429046631 and perplexity is 156.17269732076915
At time: 1214.8678231239319 and batch: 1200, loss is 5.0159159183502195 and perplexity is 150.7941886986521
At time: 1216.0089180469513 and batch: 1250, loss is 5.037571821212769 and perplexity is 154.09538922542035
At time: 1217.1497659683228 and batch: 1300, loss is 5.010702600479126 and perplexity is 150.01009629719937
At time: 1218.290107011795 and batch: 1350, loss is 4.9996333503723145 and perplexity is 148.35875344756408
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.114024251302084 and perplexity of 166.33839729879008
Finished 37 epochs...
Completing Train Step...
At time: 1221.6763424873352 and batch: 50, loss is 5.110241270065307 and perplexity is 165.71033099339613
At time: 1222.8335905075073 and batch: 100, loss is 5.126799669265747 and perplexity is 168.47707199131932
At time: 1223.9670329093933 and batch: 150, loss is 5.094557399749756 and perplexity is 163.13162654496494
At time: 1225.1068348884583 and batch: 200, loss is 5.0891072463989255 and perplexity is 162.24495261319979
At time: 1226.2468087673187 and batch: 250, loss is 5.092203369140625 and perplexity is 162.74806134200094
At time: 1227.413638830185 and batch: 300, loss is 5.091455125808716 and perplexity is 162.6263317376824
At time: 1228.5536754131317 and batch: 350, loss is 5.108892726898193 and perplexity is 165.48701406891416
At time: 1229.6940460205078 and batch: 400, loss is 5.130747117996216 and perplexity is 169.1434409586322
At time: 1230.833610534668 and batch: 450, loss is 5.089486360549927 and perplexity is 162.30647363167145
At time: 1231.973356962204 and batch: 500, loss is 5.113632316589356 and perplexity is 166.27321628101524
At time: 1233.1127095222473 and batch: 550, loss is 5.117098331451416 and perplexity is 166.85052161630077
At time: 1234.2535524368286 and batch: 600, loss is 5.0639465713500975 and perplexity is 158.2136874258995
At time: 1235.3931674957275 and batch: 650, loss is 5.08165717124939 and perplexity is 161.04070695392286
At time: 1236.5335659980774 and batch: 700, loss is 5.093468513488769 and perplexity is 162.9540914334012
At time: 1237.6729061603546 and batch: 750, loss is 5.07803713798523 and perplexity is 160.45878815605477
At time: 1238.8124740123749 and batch: 800, loss is 5.056076421737671 and perplexity is 156.97340902523115
At time: 1239.9518492221832 and batch: 850, loss is 5.047665319442749 and perplexity is 155.6586267597626
At time: 1241.091510295868 and batch: 900, loss is 5.08209755897522 and perplexity is 161.11164292314305
At time: 1242.2315006256104 and batch: 950, loss is 5.04575855255127 and perplexity is 155.36210483282062
At time: 1243.3716502189636 and batch: 1000, loss is 5.070356674194336 and perplexity is 159.231110844264
At time: 1244.5116090774536 and batch: 1050, loss is 5.029911947250366 and perplexity is 152.91954711618646
At time: 1245.6513710021973 and batch: 1100, loss is 5.03320647239685 and perplexity is 153.42417520808723
At time: 1246.7907192707062 and batch: 1150, loss is 5.050983772277832 and perplexity is 156.17603058632656
At time: 1247.9304151535034 and batch: 1200, loss is 5.015945863723755 and perplexity is 150.79870435457082
At time: 1249.0704588890076 and batch: 1250, loss is 5.037581043243408 and perplexity is 154.09681030437383
At time: 1250.2108447551727 and batch: 1300, loss is 5.010693788528442 and perplexity is 150.0087744214529
At time: 1251.3506455421448 and batch: 1350, loss is 4.9995381546020505 and perplexity is 148.34463099396382
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.114020589192708 and perplexity of 166.33778815050115
Finished 38 epochs...
Completing Train Step...
At time: 1254.7279925346375 and batch: 50, loss is 5.10988567352295 and perplexity is 165.65141544836482
At time: 1255.8837294578552 and batch: 100, loss is 5.126410417556762 and perplexity is 168.4115047650273
At time: 1257.0222601890564 and batch: 150, loss is 5.0942642116546635 and perplexity is 163.0838053047806
At time: 1258.1612510681152 and batch: 200, loss is 5.0888114929199215 and perplexity is 162.19697519910684
At time: 1259.2989766597748 and batch: 250, loss is 5.091888914108276 and perplexity is 162.69689244068778
At time: 1260.4372427463531 and batch: 300, loss is 5.091183309555054 and perplexity is 162.5821332646464
At time: 1261.575689792633 and batch: 350, loss is 5.108670930862427 and perplexity is 165.45031377536318
At time: 1262.7133812904358 and batch: 400, loss is 5.130557861328125 and perplexity is 169.11143246357304
At time: 1263.852025270462 and batch: 450, loss is 5.089282007217407 and perplexity is 162.2733091516467
At time: 1264.9908332824707 and batch: 500, loss is 5.113401184082031 and perplexity is 166.23478957663664
At time: 1266.1292209625244 and batch: 550, loss is 5.116925306320191 and perplexity is 166.82165478031914
At time: 1267.2676329612732 and batch: 600, loss is 5.063800582885742 and perplexity is 158.19059173852517
At time: 1268.405480146408 and batch: 650, loss is 5.081490631103516 and perplexity is 161.0138894442531
At time: 1269.5438814163208 and batch: 700, loss is 5.093314714431763 and perplexity is 162.92903117497488
At time: 1270.682006597519 and batch: 750, loss is 5.077958354949951 and perplexity is 160.44614722363875
At time: 1271.8203625679016 and batch: 800, loss is 5.056049900054932 and perplexity is 156.9692458814856
At time: 1272.9577944278717 and batch: 850, loss is 5.047665843963623 and perplexity is 155.65870840598294
At time: 1274.0952322483063 and batch: 900, loss is 5.0820579338073735 and perplexity is 161.10525897373356
At time: 1275.233068704605 and batch: 950, loss is 5.045669937133789 and perplexity is 155.3483379650276
At time: 1276.370432138443 and batch: 1000, loss is 5.0702856922149655 and perplexity is 159.21980870596772
At time: 1277.5089330673218 and batch: 1050, loss is 5.029815902709961 and perplexity is 152.90486073384943
At time: 1278.64710521698 and batch: 1100, loss is 5.03315728187561 and perplexity is 153.41662837855563
At time: 1279.7852964401245 and batch: 1150, loss is 5.050982646942138 and perplexity is 156.1758548359637
At time: 1280.9230563640594 and batch: 1200, loss is 5.015969648361206 and perplexity is 150.80229108973637
At time: 1282.061471939087 and batch: 1250, loss is 5.037582635879517 and perplexity is 154.09705572471353
At time: 1283.198962688446 and batch: 1300, loss is 5.010685396194458 and perplexity is 150.00751550300004
At time: 1284.3369550704956 and batch: 1350, loss is 4.999437618255615 and perplexity is 148.32971771642616
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.114031168619792 and perplexity of 166.3395479183108
Annealing...
Finished 39 epochs...
Completing Train Step...
At time: 1287.7408332824707 and batch: 50, loss is 5.109752645492554 and perplexity is 165.62938063249203
At time: 1288.8683602809906 and batch: 100, loss is 5.1262709903717045 and perplexity is 168.38802525986526
At time: 1290.0061433315277 and batch: 150, loss is 5.094235649108887 and perplexity is 163.079147282649
At time: 1291.1438710689545 and batch: 200, loss is 5.08900110244751 and perplexity is 162.2277322067693
At time: 1292.282338142395 and batch: 250, loss is 5.0916689682006835 and perplexity is 162.6611118600578
At time: 1293.4207634925842 and batch: 300, loss is 5.091203098297119 and perplexity is 162.58535059237934
At time: 1294.5585677623749 and batch: 350, loss is 5.108622360229492 and perplexity is 165.44227794405808
At time: 1295.6964535713196 and batch: 400, loss is 5.1307431411743165 and perplexity is 169.14276830662956
At time: 1296.834553718567 and batch: 450, loss is 5.0891977882385255 and perplexity is 162.2596432347231
At time: 1297.972280740738 and batch: 500, loss is 5.1133053016662595 and perplexity is 166.2188513475369
At time: 1299.1102862358093 and batch: 550, loss is 5.116237421035766 and perplexity is 166.70694007867345
At time: 1300.248339176178 and batch: 600, loss is 5.06280369758606 and perplexity is 158.0329724403069
At time: 1301.3856506347656 and batch: 650, loss is 5.080515613555908 and perplexity is 160.85697458643742
At time: 1302.5233392715454 and batch: 700, loss is 5.092157039642334 and perplexity is 162.74052148063146
At time: 1303.661129951477 and batch: 750, loss is 5.07697606086731 and perplexity is 160.28861930467625
At time: 1304.7984988689423 and batch: 800, loss is 5.05498929977417 and perplexity is 156.80285250925897
At time: 1305.937166929245 and batch: 850, loss is 5.0463286304473876 and perplexity is 155.45069858495071
At time: 1307.0753064155579 and batch: 900, loss is 5.080398473739624 and perplexity is 160.83813293356175
At time: 1308.2127995491028 and batch: 950, loss is 5.043975334167481 and perplexity is 155.08530714005408
At time: 1309.349740743637 and batch: 1000, loss is 5.068624963760376 and perplexity is 158.95560728324838
At time: 1310.4869358539581 and batch: 1050, loss is 5.027939577102661 and perplexity is 152.61823041816686
At time: 1311.6247401237488 and batch: 1100, loss is 5.031224222183227 and perplexity is 153.1203513309637
At time: 1312.7623903751373 and batch: 1150, loss is 5.049192152023315 and perplexity is 155.89647295199742
At time: 1313.9281437397003 and batch: 1200, loss is 5.013954086303711 and perplexity is 150.49864582436683
At time: 1315.0655643939972 and batch: 1250, loss is 5.035664615631103 and perplexity is 153.80177771673416
At time: 1316.203127861023 and batch: 1300, loss is 5.00848572731018 and perplexity is 149.67791128171544
At time: 1317.3404796123505 and batch: 1350, loss is 4.9979120540618895 and perplexity is 148.10360372976723
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.114127197265625 and perplexity of 166.35552204682065
Annealing...
Finished 40 epochs...
Completing Train Step...
At time: 1320.7359368801117 and batch: 50, loss is 5.109594030380249 and perplexity is 165.60311139308624
At time: 1321.866928577423 and batch: 100, loss is 5.126233263015747 and perplexity is 168.38167254473362
At time: 1323.0046343803406 and batch: 150, loss is 5.094042682647705 and perplexity is 163.04768151272214
At time: 1324.1419615745544 and batch: 200, loss is 5.088843240737915 and perplexity is 162.2021246808965
At time: 1325.2797784805298 and batch: 250, loss is 5.091369276046753 and perplexity is 162.6123709050894
At time: 1326.4178228378296 and batch: 300, loss is 5.090972051620484 and perplexity is 162.54779012673285
At time: 1327.5559568405151 and batch: 350, loss is 5.108447437286377 and perplexity is 165.41334082484124
At time: 1328.694191455841 and batch: 400, loss is 5.1307768058776855 and perplexity is 169.1484625435985
At time: 1329.8318500518799 and batch: 450, loss is 5.089121990203857 and perplexity is 162.2473447387667
At time: 1330.969988822937 and batch: 500, loss is 5.1131893825531005 and perplexity is 166.19958452241661
At time: 1332.1077811717987 and batch: 550, loss is 5.115966892242431 and perplexity is 166.66184715107607
At time: 1333.2462420463562 and batch: 600, loss is 5.062393131256104 and perplexity is 157.9681027403686
At time: 1334.3840465545654 and batch: 650, loss is 5.080153198242187 and perplexity is 160.79868811812077
At time: 1335.5224261283875 and batch: 700, loss is 5.09166181564331 and perplexity is 162.65994842128364
At time: 1336.6603095531464 and batch: 750, loss is 5.076683282852173 and perplexity is 160.24169719008418
At time: 1337.797837972641 and batch: 800, loss is 5.05463282585144 and perplexity is 156.74696634290208
At time: 1338.9357414245605 and batch: 850, loss is 5.0456842517852785 and perplexity is 155.3505617382612
At time: 1340.0733680725098 and batch: 900, loss is 5.079628000259399 and perplexity is 160.71425914439018
At time: 1341.2110118865967 and batch: 950, loss is 5.043358945846558 and perplexity is 154.98974382306812
At time: 1342.3778240680695 and batch: 1000, loss is 5.067950963973999 and perplexity is 158.84850733462167
At time: 1343.515715122223 and batch: 1050, loss is 5.027221689224243 and perplexity is 152.50870695801
At time: 1344.6538355350494 and batch: 1100, loss is 5.030500364303589 and perplexity is 153.00955406369516
At time: 1345.7920353412628 and batch: 1150, loss is 5.048462371826172 and perplexity is 155.78274429674028
At time: 1346.9309611320496 and batch: 1200, loss is 5.013165111541748 and perplexity is 150.37995302007235
At time: 1348.0691411495209 and batch: 1250, loss is 5.035017566680908 and perplexity is 153.70229262725678
At time: 1349.2079601287842 and batch: 1300, loss is 5.007648754119873 and perplexity is 149.5526872946616
At time: 1350.3459491729736 and batch: 1350, loss is 4.997340536117553 and perplexity is 148.01898404575203
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.114780680338542 and perplexity of 166.4642680925446
Annealing...
Finished 41 epochs...
Completing Train Step...
At time: 1353.7193367481232 and batch: 50, loss is 5.1094484043121335 and perplexity is 165.57899701898975
At time: 1354.8804709911346 and batch: 100, loss is 5.126169109344483 and perplexity is 168.37087058876253
At time: 1356.0191714763641 and batch: 150, loss is 5.09392819404602 and perplexity is 163.02901548020208
At time: 1357.157602071762 and batch: 200, loss is 5.088714179992675 and perplexity is 162.18119210462177
At time: 1358.2949736118317 and batch: 250, loss is 5.0912815284729005 and perplexity is 162.5981026900739
At time: 1359.4329750537872 and batch: 300, loss is 5.090869016647339 and perplexity is 162.53104288233317
At time: 1360.57102060318 and batch: 350, loss is 5.1083529090881346 and perplexity is 165.39770533877663
At time: 1361.7101171016693 and batch: 400, loss is 5.130792770385742 and perplexity is 169.15116293714675
At time: 1362.8490755558014 and batch: 450, loss is 5.089056234359742 and perplexity is 162.23667637841527
At time: 1363.9876792430878 and batch: 500, loss is 5.113130197525025 and perplexity is 166.1897482864223
At time: 1365.1260039806366 and batch: 550, loss is 5.115846281051636 and perplexity is 166.64174707940214
At time: 1366.264579296112 and batch: 600, loss is 5.062174987792969 and perplexity is 157.93364678967882
At time: 1367.40282869339 and batch: 650, loss is 5.080010471343994 and perplexity is 160.7757394578666
At time: 1368.5415296554565 and batch: 700, loss is 5.091467866897583 and perplexity is 162.62840378742717
At time: 1369.6797769069672 and batch: 750, loss is 5.07660026550293 and perplexity is 160.2283949013133
At time: 1370.8448939323425 and batch: 800, loss is 5.054493989944458 and perplexity is 156.72520574627416
At time: 1371.98312997818 and batch: 850, loss is 5.045411367416381 and perplexity is 155.30817478189542
At time: 1373.1213791370392 and batch: 900, loss is 5.079290523529052 and perplexity is 160.66003097258178
At time: 1374.2597420215607 and batch: 950, loss is 5.043106889724731 and perplexity is 154.95068263233006
At time: 1375.39772605896 and batch: 1000, loss is 5.0676679515838625 and perplexity is 158.80355759985724
At time: 1376.536166191101 and batch: 1050, loss is 5.026932849884033 and perplexity is 152.46466280486425
At time: 1377.6745338439941 and batch: 1100, loss is 5.030199365615845 and perplexity is 152.96350531936315
At time: 1378.8129246234894 and batch: 1150, loss is 5.048170022964477 and perplexity is 155.73720804533335
At time: 1379.9509851932526 and batch: 1200, loss is 5.012855405807495 and perplexity is 150.3333866976061
At time: 1381.089299440384 and batch: 1250, loss is 5.034729270935059 and perplexity is 153.657987296991
At time: 1382.2272326946259 and batch: 1300, loss is 5.007339715957642 and perplexity is 149.50647694777143
At time: 1383.3660826683044 and batch: 1350, loss is 4.997116355895996 and perplexity is 147.98580483631423
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.115156656901042 and perplexity of 166.52686652287505
Annealing...
Finished 42 epochs...
Completing Train Step...
At time: 1386.7484731674194 and batch: 50, loss is 5.109382104873657 and perplexity is 165.56801958836672
At time: 1387.9108974933624 and batch: 100, loss is 5.126135053634644 and perplexity is 168.3651366968849
At time: 1389.0499558448792 and batch: 150, loss is 5.093877534866333 and perplexity is 163.02075677320414
At time: 1390.190459728241 and batch: 200, loss is 5.088666381835938 and perplexity is 162.17344032784348
At time: 1391.3311705589294 and batch: 250, loss is 5.09124641418457 and perplexity is 162.5923932736557
At time: 1392.4711782932281 and batch: 300, loss is 5.090823230743408 and perplexity is 162.5236014219762
At time: 1393.6109173297882 and batch: 350, loss is 5.10830062866211 and perplexity is 165.38905850231012
At time: 1394.7510015964508 and batch: 400, loss is 5.130751781463623 and perplexity is 169.14422975539546
At time: 1395.8911669254303 and batch: 450, loss is 5.088992624282837 and perplexity is 162.22635681917157
At time: 1397.0310499668121 and batch: 500, loss is 5.113091602325439 and perplexity is 166.18333428369377
At time: 1398.1716401576996 and batch: 550, loss is 5.115782270431518 and perplexity is 166.63108057922244
At time: 1399.3115119934082 and batch: 600, loss is 5.062072515487671 and perplexity is 157.91746379397676
At time: 1400.478312253952 and batch: 650, loss is 5.079942064285278 and perplexity is 160.764741638586
At time: 1401.618644952774 and batch: 700, loss is 5.091396427154541 and perplexity is 162.61678607103752
At time: 1402.759688615799 and batch: 750, loss is 5.076564540863037 and perplexity is 160.2226709018494
At time: 1403.8997440338135 and batch: 800, loss is 5.054418592453003 and perplexity is 156.71338950437627
At time: 1405.0405058860779 and batch: 850, loss is 5.045299415588379 and perplexity is 155.29078872104364
At time: 1406.1805963516235 and batch: 900, loss is 5.079160242080689 and perplexity is 160.6391013144552
At time: 1407.320853471756 and batch: 950, loss is 5.043003568649292 and perplexity is 154.93467378820017
At time: 1408.4604716300964 and batch: 1000, loss is 5.067558345794677 and perplexity is 158.7861527644539
At time: 1409.6007030010223 and batch: 1050, loss is 5.026819438934326 and perplexity is 152.4473726231253
At time: 1410.7412259578705 and batch: 1100, loss is 5.030086450576782 and perplexity is 152.94623441427564
At time: 1411.8820428848267 and batch: 1150, loss is 5.0480539894104 and perplexity is 155.71913835194746
At time: 1413.0227680206299 and batch: 1200, loss is 5.012727108001709 and perplexity is 150.31410049117179
At time: 1414.1644034385681 and batch: 1250, loss is 5.034594964981079 and perplexity is 153.6373515002067
At time: 1415.3045809268951 and batch: 1300, loss is 5.007211332321167 and perplexity is 149.48728399464127
At time: 1416.4446535110474 and batch: 1350, loss is 4.997027788162232 and perplexity is 147.97269864935174
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.115262858072916 and perplexity of 166.54455281038398
Annealing...
Model not improving. Stopping early with 166.33778815050115loss at 42 epochs.
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7feac4b70a20>
SETTINGS FOR THIS RUN
{'lr': 21.779401101626867, 'data': 'wikitext', 'dropout': 0.5430837354688028, 'anneal': 7.65681972637775, 'wordvec_source': '', 'num_layers': 1, 'wordvec_dim': 200, 'batch_size': 80, 'seq_len': 20, 'tune_wordvecs': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.5832233428955078 and batch: 50, loss is 7.103274736404419 and perplexity is 1215.9424527977746
At time: 2.6383216381073 and batch: 100, loss is 6.462410383224487 and perplexity is 640.6032965677465
At time: 3.693545341491699 and batch: 150, loss is 6.303870944976807 and perplexity is 546.6840032868095
At time: 4.748618841171265 and batch: 200, loss is 6.249736623764038 and perplexity is 517.8764103653323
At time: 5.8038763999938965 and batch: 250, loss is 6.2556171703338626 and perplexity is 520.9307785893136
At time: 6.886764764785767 and batch: 300, loss is 6.247358140945434 and perplexity is 516.6461139205966
At time: 7.9426844120025635 and batch: 350, loss is 6.225526475906372 and perplexity is 505.489100246389
At time: 9.003213167190552 and batch: 400, loss is 6.255882835388183 and perplexity is 521.0691900776386
At time: 10.06071949005127 and batch: 450, loss is 6.215681257247925 and perplexity is 500.5368674333544
At time: 11.12129282951355 and batch: 500, loss is 6.200176200866699 and perplexity is 492.83587155093835
At time: 12.182095289230347 and batch: 550, loss is 6.160228414535522 and perplexity is 473.5362250397206
At time: 13.242282152175903 and batch: 600, loss is 6.11455883026123 and perplexity is 452.3964197292825
At time: 14.302813291549683 and batch: 650, loss is 6.139727821350098 and perplexity is 463.9272825721449
At time: 15.364163637161255 and batch: 700, loss is 6.143709812164307 and perplexity is 465.7783197103736
At time: 16.425352573394775 and batch: 750, loss is 6.119050483703614 and perplexity is 454.43299804329115
At time: 17.488563299179077 and batch: 800, loss is 6.081134595870972 and perplexity is 437.5253276401723
At time: 18.552067279815674 and batch: 850, loss is 6.078825006484985 and perplexity is 436.51598981398706
At time: 19.615357637405396 and batch: 900, loss is 6.115370836257934 and perplexity is 452.76391752000256
At time: 20.6793475151062 and batch: 950, loss is 6.080266695022583 and perplexity is 437.14576377284885
At time: 21.743592739105225 and batch: 1000, loss is 6.092084894180298 and perplexity is 442.3426881259187
At time: 22.8089017868042 and batch: 1050, loss is 6.087906436920166 and perplexity is 440.4982342786409
At time: 23.873409509658813 and batch: 1100, loss is 6.082631931304932 and perplexity is 438.1809405302175
At time: 24.93844723701477 and batch: 1150, loss is 6.07414909362793 and perplexity is 434.47964368368025
At time: 26.006784200668335 and batch: 1200, loss is 6.0632838535308835 and perplexity is 429.7844713153317
At time: 27.072808504104614 and batch: 1250, loss is 6.0508137130737305 and perplexity is 424.45827680890415
At time: 28.138707399368286 and batch: 1300, loss is 6.036352605819702 and perplexity is 418.364309102427
At time: 29.205039024353027 and batch: 1350, loss is 6.027375917434693 and perplexity is 414.625588837358
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.472410074869791 and perplexity of 238.0331797977974
Finished 1 epochs...
Completing Train Step...
At time: 32.46622705459595 and batch: 50, loss is 5.852727432250976 and perplexity is 348.1827314202821
At time: 33.52771830558777 and batch: 100, loss is 5.907196245193481 and perplexity is 367.6738416075818
At time: 34.58847665786743 and batch: 150, loss is 5.8402515888214115 and perplexity is 343.86584258511186
At time: 35.64946699142456 and batch: 200, loss is 5.815240468978882 and perplexity is 335.37203537627704
At time: 36.70977973937988 and batch: 250, loss is 5.863168983459473 and perplexity is 351.8373459588094
At time: 37.7720832824707 and batch: 300, loss is 5.844077129364013 and perplexity is 345.1838347159282
At time: 38.861143827438354 and batch: 350, loss is 5.803180418014526 and perplexity is 331.3517228522732
At time: 39.93118929862976 and batch: 400, loss is 5.835468788146972 and perplexity is 342.225127535439
At time: 41.036322593688965 and batch: 450, loss is 5.826563730239868 and perplexity is 339.19112200464843
At time: 42.17261075973511 and batch: 500, loss is 5.844460830688477 and perplexity is 345.316307623882
At time: 43.31421685218811 and batch: 550, loss is 5.8275625610351565 and perplexity is 339.53008579835205
At time: 44.45537209510803 and batch: 600, loss is 5.774008131027221 and perplexity is 321.8250680600484
At time: 45.5964515209198 and batch: 650, loss is 5.806796741485596 and perplexity is 332.5521671539918
At time: 46.73690366744995 and batch: 700, loss is 5.821130199432373 and perplexity is 337.3531145506652
At time: 47.87767219543457 and batch: 750, loss is 5.764348564147949 and perplexity is 318.73134336751934
At time: 49.01852893829346 and batch: 800, loss is 5.759692430496216 and perplexity is 317.25073725867696
At time: 50.15972661972046 and batch: 850, loss is 5.747092590332032 and perplexity is 313.278505968074
At time: 51.301063776016235 and batch: 900, loss is 5.755199756622314 and perplexity is 315.82863008379167
At time: 52.44316339492798 and batch: 950, loss is 5.717564668655395 and perplexity is 304.163281878336
At time: 53.58453702926636 and batch: 1000, loss is 5.795107297897339 and perplexity is 328.68744956217586
At time: 54.72541427612305 and batch: 1050, loss is 5.756412086486816 and perplexity is 316.21175075149637
At time: 55.86639213562012 and batch: 1100, loss is 5.7572869873046875 and perplexity is 316.4885257285215
At time: 57.007317304611206 and batch: 1150, loss is 5.779133377075195 and perplexity is 323.47873482288725
At time: 58.14902591705322 and batch: 1200, loss is 5.7769410514831545 and perplexity is 322.77034091283224
At time: 59.29028630256653 and batch: 1250, loss is 5.800671854019165 and perplexity is 330.52154755979967
At time: 60.431116342544556 and batch: 1300, loss is 5.77275131225586 and perplexity is 321.4208463433453
At time: 61.571656465530396 and batch: 1350, loss is 5.754123220443725 and perplexity is 315.4888120832769
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.509283447265625 and perplexity of 246.97409368617122
Annealing...
Finished 2 epochs...
Completing Train Step...
At time: 64.9558379650116 and batch: 50, loss is 5.719578905105591 and perplexity is 304.7765560797863
At time: 66.09774255752563 and batch: 100, loss is 5.699745931625366 and perplexity is 298.79147785750445
At time: 67.21115350723267 and batch: 150, loss is 5.649185028076172 and perplexity is 284.05987064569274
At time: 68.32449507713318 and batch: 200, loss is 5.6317848777771 and perplexity is 279.1599395976405
At time: 69.4413993358612 and batch: 250, loss is 5.64975902557373 and perplexity is 284.22296710460176
At time: 70.57176804542542 and batch: 300, loss is 5.648989820480347 and perplexity is 284.00442541311503
At time: 71.70165491104126 and batch: 350, loss is 5.630425500869751 and perplexity is 278.78071383606385
At time: 72.83621549606323 and batch: 400, loss is 5.669700136184693 and perplexity is 289.9475765680851
At time: 73.97555947303772 and batch: 450, loss is 5.635077629089356 and perplexity is 280.0806588729951
At time: 75.1144528388977 and batch: 500, loss is 5.645393581390381 and perplexity is 282.98491190266543
At time: 76.25350975990295 and batch: 550, loss is 5.6095682144165036 and perplexity is 273.02632371924744
At time: 77.39257788658142 and batch: 600, loss is 5.5545947456359865 and perplexity is 258.4222165662031
At time: 78.53227138519287 and batch: 650, loss is 5.583657264709473 and perplexity is 266.0428177225785
At time: 79.67139744758606 and batch: 700, loss is 5.593799819946289 and perplexity is 268.75490218027096
At time: 80.81118702888489 and batch: 750, loss is 5.558416976928711 and perplexity is 259.41185615996875
At time: 81.94988059997559 and batch: 800, loss is 5.5246028709411625 and perplexity is 250.78672354676146
At time: 83.08918046951294 and batch: 850, loss is 5.521109609603882 and perplexity is 249.91218836078906
At time: 84.22809267044067 and batch: 900, loss is 5.566670951843261 and perplexity is 261.5618960945952
At time: 85.36592364311218 and batch: 950, loss is 5.499601497650146 and perplexity is 244.59444138068608
At time: 86.504230260849 and batch: 1000, loss is 5.509977445602417 and perplexity is 247.14555278570336
At time: 87.64302253723145 and batch: 1050, loss is 5.4817665004730225 and perplexity is 240.27077114043146
At time: 88.78009104728699 and batch: 1100, loss is 5.454182682037353 and perplexity is 233.73375818107226
At time: 89.91796040534973 and batch: 1150, loss is 5.477887802124023 and perplexity is 239.34063831552197
At time: 91.05672693252563 and batch: 1200, loss is 5.402171659469604 and perplexity is 221.88775801064259
At time: 92.19592475891113 and batch: 1250, loss is 5.410778980255127 and perplexity is 223.80586014036203
At time: 93.33489608764648 and batch: 1300, loss is 5.3781234169006344 and perplexity is 216.61539698070916
At time: 94.47437143325806 and batch: 1350, loss is 5.371698722839356 and perplexity is 215.22817035116404
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.269595133463541 and perplexity of 194.33726585992724
Finished 3 epochs...
Completing Train Step...
At time: 97.90977382659912 and batch: 50, loss is 5.533826684951782 and perplexity is 253.1106348275404
At time: 99.02442908287048 and batch: 100, loss is 5.538457469940186 and perplexity is 254.2854538233727
At time: 100.13851070404053 and batch: 150, loss is 5.502504949569702 and perplexity is 245.30564154915268
At time: 101.25210952758789 and batch: 200, loss is 5.492739486694336 and perplexity is 242.9217771278328
At time: 102.36443734169006 and batch: 250, loss is 5.520295095443726 and perplexity is 249.70871422210644
At time: 103.47971224784851 and batch: 300, loss is 5.520750350952149 and perplexity is 249.82242137069625
At time: 104.5990538597107 and batch: 350, loss is 5.509735622406006 and perplexity is 247.08579448391285
At time: 105.72958016395569 and batch: 400, loss is 5.547501029968262 and perplexity is 256.595529499017
At time: 106.86826753616333 and batch: 450, loss is 5.51233983039856 and perplexity is 247.73009586802917
At time: 108.00679922103882 and batch: 500, loss is 5.527684497833252 and perplexity is 251.56074667092182
At time: 109.14467215538025 and batch: 550, loss is 5.500493478775025 and perplexity is 244.81271233796292
At time: 110.2816834449768 and batch: 600, loss is 5.452522382736206 and perplexity is 233.34601216200357
At time: 111.41997075080872 and batch: 650, loss is 5.484628286361694 and perplexity is 240.9593594689712
At time: 112.55873608589172 and batch: 700, loss is 5.498948392868042 and perplexity is 244.43474773536227
At time: 113.69745421409607 and batch: 750, loss is 5.470982942581177 and perplexity is 237.69371724774484
At time: 114.83371376991272 and batch: 800, loss is 5.446538925170898 and perplexity is 231.9539649809597
At time: 115.97187900543213 and batch: 850, loss is 5.441611671447754 and perplexity is 230.81387999397242
At time: 117.11054420471191 and batch: 900, loss is 5.486369094848633 and perplexity is 241.3791888822235
At time: 118.24866843223572 and batch: 950, loss is 5.429237737655639 and perplexity is 227.97540211084623
At time: 119.38700723648071 and batch: 1000, loss is 5.442498798370361 and perplexity is 231.01873205247983
At time: 120.52508187294006 and batch: 1050, loss is 5.411377973556519 and perplexity is 223.93995850940118
At time: 121.65972709655762 and batch: 1100, loss is 5.396100788116455 and perplexity is 220.54478660489096
At time: 122.7982828617096 and batch: 1150, loss is 5.41482572555542 and perplexity is 224.71338046639653
At time: 123.96499490737915 and batch: 1200, loss is 5.356589412689209 and perplexity is 212.0006652606894
At time: 125.10344696044922 and batch: 1250, loss is 5.369533166885376 and perplexity is 214.76258601181667
At time: 126.24213480949402 and batch: 1300, loss is 5.3433154010772705 and perplexity is 209.20516079471165
At time: 127.38073778152466 and batch: 1350, loss is 5.334999265670777 and perplexity is 207.47259645469268
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.239045817057292 and perplexity of 188.49016247361087
Finished 4 epochs...
Completing Train Step...
At time: 130.77827310562134 and batch: 50, loss is 5.4603449153900145 and perplexity is 235.17852707103657
At time: 131.88718056678772 and batch: 100, loss is 5.4680516719818115 and perplexity is 236.99799281916282
At time: 133.00034189224243 and batch: 150, loss is 5.439203252792359 and perplexity is 230.25865241807875
At time: 134.1183214187622 and batch: 200, loss is 5.428599109649658 and perplexity is 227.82985711388574
At time: 135.2484085559845 and batch: 250, loss is 5.452477807998657 and perplexity is 233.33561105656833
At time: 136.38710498809814 and batch: 300, loss is 5.452995185852051 and perplexity is 233.45636496914344
At time: 137.52503395080566 and batch: 350, loss is 5.445082025527954 and perplexity is 231.61627738040187
At time: 138.66394686698914 and batch: 400, loss is 5.484439258575439 and perplexity is 240.91381575932232
At time: 139.8017864227295 and batch: 450, loss is 5.452280931472778 and perplexity is 233.28967727388974
At time: 140.9409055709839 and batch: 500, loss is 5.471910791397095 and perplexity is 237.91436342916379
At time: 142.0793116092682 and batch: 550, loss is 5.442678985595703 and perplexity is 231.06036242732847
At time: 143.21924352645874 and batch: 600, loss is 5.394229326248169 and perplexity is 220.1324314203643
At time: 144.35770225524902 and batch: 650, loss is 5.426254196166992 and perplexity is 227.29624169569212
At time: 145.49641871452332 and batch: 700, loss is 5.447465448379517 and perplexity is 232.16897530349138
At time: 146.63476657867432 and batch: 750, loss is 5.420125703811646 and perplexity is 225.90751815338643
At time: 147.77408361434937 and batch: 800, loss is 5.39260048866272 and perplexity is 219.77416330178954
At time: 148.91314911842346 and batch: 850, loss is 5.38924165725708 and perplexity is 219.03721727151515
At time: 150.05270385742188 and batch: 900, loss is 5.437748203277588 and perplexity is 229.92385830767796
At time: 151.19002771377563 and batch: 950, loss is 5.388323583602905 and perplexity is 218.8362172535828
At time: 152.37532901763916 and batch: 1000, loss is 5.40094256401062 and perplexity is 221.6152043064393
At time: 153.51122760772705 and batch: 1050, loss is 5.371982173919678 and perplexity is 215.28918565558428
At time: 154.64438128471375 and batch: 1100, loss is 5.359103183746338 and perplexity is 212.53425677958984
At time: 155.78147053718567 and batch: 1150, loss is 5.374723482131958 and perplexity is 215.88016933234803
At time: 156.92085313796997 and batch: 1200, loss is 5.323112306594848 and perplexity is 205.02097820187493
At time: 158.05934190750122 and batch: 1250, loss is 5.3374158382415775 and perplexity is 207.97457533038002
At time: 159.1976408958435 and batch: 1300, loss is 5.314003820419312 and perplexity is 203.16202642673633
At time: 160.33569812774658 and batch: 1350, loss is 5.309048767089844 and perplexity is 202.15783771020634
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.227771809895834 and perplexity of 186.3770569969886
Finished 5 epochs...
Completing Train Step...
At time: 163.70659017562866 and batch: 50, loss is 5.415551471710205 and perplexity is 224.87652453162704
At time: 164.8455195426941 and batch: 100, loss is 5.425207166671753 and perplexity is 227.05838037212058
At time: 165.96373534202576 and batch: 150, loss is 5.3983495235443115 and perplexity is 221.04129152483256
At time: 167.09035992622375 and batch: 200, loss is 5.382371129989624 and perplexity is 217.53747401065112
At time: 168.22682642936707 and batch: 250, loss is 5.4067426204681395 and perplexity is 222.90431986087037
At time: 169.3637113571167 and batch: 300, loss is 5.403584785461426 and perplexity is 222.20153501976233
At time: 170.50179743766785 and batch: 350, loss is 5.401476106643677 and perplexity is 221.73347701503081
At time: 171.64077520370483 and batch: 400, loss is 5.441637783050537 and perplexity is 230.81990699301062
At time: 172.77874779701233 and batch: 450, loss is 5.404506015777588 and perplexity is 222.406328126446
At time: 173.91756582260132 and batch: 500, loss is 5.426434907913208 and perplexity is 227.33732050803744
At time: 175.0554485321045 and batch: 550, loss is 5.399303417205811 and perplexity is 221.25224200791655
At time: 176.19391751289368 and batch: 600, loss is 5.352237644195557 and perplexity is 211.08009195872964
At time: 177.33259654045105 and batch: 650, loss is 5.385027809143066 and perplexity is 218.1161696468974
At time: 178.47176432609558 and batch: 700, loss is 5.408545875549317 and perplexity is 223.30663583842272
At time: 179.61036896705627 and batch: 750, loss is 5.3826695251464844 and perplexity is 217.60239582502723
At time: 180.77363109588623 and batch: 800, loss is 5.363562297821045 and perplexity is 213.48408740305896
At time: 181.91081476211548 and batch: 850, loss is 5.354328470230103 and perplexity is 211.52188540604837
At time: 183.049889087677 and batch: 900, loss is 5.398285388946533 and perplexity is 221.02711558509716
At time: 184.18689966201782 and batch: 950, loss is 5.354901475906372 and perplexity is 211.6431233787473
At time: 185.32505559921265 and batch: 1000, loss is 5.364377613067627 and perplexity is 213.65821520930317
At time: 186.4640917778015 and batch: 1050, loss is 5.334654197692871 and perplexity is 207.40101665602174
At time: 187.59850192070007 and batch: 1100, loss is 5.325622024536133 and perplexity is 205.53616925089864
At time: 188.73580312728882 and batch: 1150, loss is 5.336762084960937 and perplexity is 207.83865570325997
At time: 189.8725562095642 and batch: 1200, loss is 5.290512371063232 and perplexity is 198.44507688055566
At time: 191.01223993301392 and batch: 1250, loss is 5.307589282989502 and perplexity is 201.86300676318336
At time: 192.15090250968933 and batch: 1300, loss is 5.285072088241577 and perplexity is 197.3684108770189
At time: 193.28777050971985 and batch: 1350, loss is 5.281368761062622 and perplexity is 196.63884282516153
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.226146647135416 and perplexity of 186.07440993653847
Finished 6 epochs...
Completing Train Step...
At time: 196.66099190711975 and batch: 50, loss is 5.3799283313751225 and perplexity is 217.0067222942424
At time: 197.808988571167 and batch: 100, loss is 5.388443260192871 and perplexity is 218.86240839302664
At time: 198.9408414363861 and batch: 150, loss is 5.363480129241943 and perplexity is 213.46654643960412
At time: 200.07933259010315 and batch: 200, loss is 5.342587080001831 and perplexity is 209.05284774015084
At time: 201.22009134292603 and batch: 250, loss is 5.368742713928222 and perplexity is 214.5928933664798
At time: 202.36062741279602 and batch: 300, loss is 5.3656352996826175 and perplexity is 213.92709933729617
At time: 203.50277709960938 and batch: 350, loss is 5.364257755279541 and perplexity is 213.63260814285567
At time: 204.64501214027405 and batch: 400, loss is 5.404847173690796 and perplexity is 222.48221674950005
At time: 205.7864646911621 and batch: 450, loss is 5.367590026855469 and perplexity is 214.34567742107643
At time: 206.92846012115479 and batch: 500, loss is 5.393296012878418 and perplexity is 219.9270747249852
At time: 208.06902360916138 and batch: 550, loss is 5.363428163528442 and perplexity is 213.45545378643106
At time: 209.21006798744202 and batch: 600, loss is 5.317796869277954 and perplexity is 203.934093237103
At time: 210.39593935012817 and batch: 650, loss is 5.3514931201934814 and perplexity is 210.92299625192496
At time: 211.53751373291016 and batch: 700, loss is 5.376105928421021 and perplexity is 216.17881845694706
At time: 212.67889022827148 and batch: 750, loss is 5.354448308944702 and perplexity is 211.5472354358323
At time: 213.82034301757812 and batch: 800, loss is 5.326495494842529 and perplexity is 205.7157774214122
At time: 214.96147871017456 and batch: 850, loss is 5.321390104293823 and perplexity is 204.66819447112954
At time: 216.10242366790771 and batch: 900, loss is 5.365324811935425 and perplexity is 213.86068790466106
At time: 217.2425456047058 and batch: 950, loss is 5.323689060211182 and perplexity is 205.1392588986081
At time: 218.38386368751526 and batch: 1000, loss is 5.3379803562164305 and perplexity is 208.0920138614285
At time: 219.52494430541992 and batch: 1050, loss is 5.307615213394165 and perplexity is 201.86824122050066
At time: 220.66483449935913 and batch: 1100, loss is 5.29182505607605 and perplexity is 198.70574380819832
At time: 221.80436897277832 and batch: 1150, loss is 5.309234504699707 and perplexity is 202.19538951108063
At time: 222.9450376033783 and batch: 1200, loss is 5.26815357208252 and perplexity is 194.05731859163546
At time: 224.08642101287842 and batch: 1250, loss is 5.283237409591675 and perplexity is 197.00663523991588
At time: 225.22646474838257 and batch: 1300, loss is 5.263271636962891 and perplexity is 193.11225210641715
At time: 226.36718225479126 and batch: 1350, loss is 5.254762153625489 and perplexity is 191.47593858016737
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.21604248046875 and perplexity of 184.2037497326434
Finished 7 epochs...
Completing Train Step...
At time: 229.78881740570068 and batch: 50, loss is 5.346192560195923 and perplexity is 209.80794406663276
At time: 230.92035222053528 and batch: 100, loss is 5.35934063911438 and perplexity is 212.58473017210667
At time: 232.05414056777954 and batch: 150, loss is 5.332464637756348 and perplexity is 206.94739649465114
At time: 233.1944544315338 and batch: 200, loss is 5.313032331466675 and perplexity is 202.96475260265333
At time: 234.3413257598877 and batch: 250, loss is 5.338542709350586 and perplexity is 208.20906796740306
At time: 235.48293137550354 and batch: 300, loss is 5.33467960357666 and perplexity is 207.40628592908357
At time: 236.62394332885742 and batch: 350, loss is 5.3363111782073975 and perplexity is 207.7449609751371
At time: 237.7659993171692 and batch: 400, loss is 5.376327428817749 and perplexity is 216.22670745451973
At time: 238.93536925315857 and batch: 450, loss is 5.341774740219116 and perplexity is 208.88309475312897
At time: 240.0774121284485 and batch: 500, loss is 5.367907247543335 and perplexity is 214.41368309014135
At time: 241.21850204467773 and batch: 550, loss is 5.3371164512634275 and perplexity is 207.9123197704568
At time: 242.35993146896362 and batch: 600, loss is 5.287401943206787 and perplexity is 197.82878674532577
At time: 243.50135850906372 and batch: 650, loss is 5.321647472381592 and perplexity is 204.72087631198914
At time: 244.64243006706238 and batch: 700, loss is 5.348914241790771 and perplexity is 210.37975227341317
At time: 245.7832133769989 and batch: 750, loss is 5.328809661865234 and perplexity is 206.19238935667988
At time: 246.92301440238953 and batch: 800, loss is 5.302714109420776 and perplexity is 200.88128454561928
At time: 248.064227104187 and batch: 850, loss is 5.2982420730590825 and perplexity is 199.98494186910588
At time: 249.205961227417 and batch: 900, loss is 5.340970249176025 and perplexity is 208.71511775140323
At time: 250.34525322914124 and batch: 950, loss is 5.3015735912323 and perplexity is 200.6523063885678
At time: 251.48570346832275 and batch: 1000, loss is 5.3147798442840575 and perplexity is 203.31974619689134
At time: 252.6258726119995 and batch: 1050, loss is 5.285643730163574 and perplexity is 197.48126718838034
At time: 253.76457118988037 and batch: 1100, loss is 5.273484306335449 and perplexity is 195.0945487297736
At time: 254.9047145843506 and batch: 1150, loss is 5.2832347011566165 and perplexity is 197.00610166096084
At time: 256.04590916633606 and batch: 1200, loss is 5.245104999542236 and perplexity is 189.63572584860415
At time: 257.18694949150085 and batch: 1250, loss is 5.2601988315582275 and perplexity is 192.51976649712296
At time: 258.32783794403076 and batch: 1300, loss is 5.241653804779053 and perplexity is 188.98238407797382
At time: 259.46608662605286 and batch: 1350, loss is 5.240481653213501 and perplexity is 188.76099785506662
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.214305826822916 and perplexity of 183.88412923447603
Finished 8 epochs...
Completing Train Step...
At time: 262.8665544986725 and batch: 50, loss is 5.322299671173096 and perplexity is 204.8544385699527
At time: 263.9839255809784 and batch: 100, loss is 5.334747314453125 and perplexity is 207.42033006595318
At time: 265.1223886013031 and batch: 150, loss is 5.308081178665161 and perplexity is 201.9623267288139
At time: 266.2617943286896 and batch: 200, loss is 5.285443201065063 and perplexity is 197.4416704181832
At time: 267.44319105148315 and batch: 250, loss is 5.310189170837402 and perplexity is 202.38851077114137
At time: 268.58394289016724 and batch: 300, loss is 5.306223306655884 and perplexity is 201.58745491480946
At time: 269.7248547077179 and batch: 350, loss is 5.310783739089966 and perplexity is 202.50888033474405
At time: 270.86523032188416 and batch: 400, loss is 5.350387792587281 and perplexity is 210.68998604141754
At time: 272.00565695762634 and batch: 450, loss is 5.318296337127686 and perplexity is 204.0359772019035
At time: 273.14624285697937 and batch: 500, loss is 5.342772226333619 and perplexity is 209.0915566913593
At time: 274.28692173957825 and batch: 550, loss is 5.3134918212890625 and perplexity is 203.0580342701248
At time: 275.42807173728943 and batch: 600, loss is 5.262744884490967 and perplexity is 193.0105565368091
At time: 276.56852102279663 and batch: 650, loss is 5.296968545913696 and perplexity is 199.7304177230721
At time: 277.70939207077026 and batch: 700, loss is 5.325174083709717 and perplexity is 205.4441218268247
At time: 278.8495624065399 and batch: 750, loss is 5.303765020370483 and perplexity is 201.09250385404204
At time: 279.98682141304016 and batch: 800, loss is 5.285019235610962 and perplexity is 197.35797971296338
At time: 281.1270680427551 and batch: 850, loss is 5.275936727523804 and perplexity is 195.57358990007478
At time: 282.26735258102417 and batch: 900, loss is 5.318788661956787 and perplexity is 204.1364539110697
At time: 283.4069719314575 and batch: 950, loss is 5.279257440567017 and perplexity is 196.22411317374002
At time: 284.5477433204651 and batch: 1000, loss is 5.291633892059326 and perplexity is 198.6677620505542
At time: 285.6872761249542 and batch: 1050, loss is 5.258614759445191 and perplexity is 192.21504271974538
At time: 286.8267254829407 and batch: 1100, loss is 5.24729627609253 and perplexity is 190.05172578675015
At time: 287.96612644195557 and batch: 1150, loss is 5.260932121276856 and perplexity is 192.66099103545076
At time: 289.1068139076233 and batch: 1200, loss is 5.2236385154724125 and perplexity is 185.608295599715
At time: 290.2469313144684 and batch: 1250, loss is 5.240674095153809 and perplexity is 188.7973268832505
At time: 291.38800740242004 and batch: 1300, loss is 5.224343643188477 and perplexity is 185.73921930681644
At time: 292.52536845207214 and batch: 1350, loss is 5.222983312606812 and perplexity is 185.48672434382553
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2119523111979165 and perplexity of 183.45186393423006
Finished 9 epochs...
Completing Train Step...
At time: 295.90760350227356 and batch: 50, loss is 5.297291221618653 and perplexity is 199.79487627545728
At time: 297.0630979537964 and batch: 100, loss is 5.31021863937378 and perplexity is 202.39447495221077
At time: 298.2018187046051 and batch: 150, loss is 5.284498891830444 and perplexity is 197.255312429142
At time: 299.33933687210083 and batch: 200, loss is 5.260060396194458 and perplexity is 192.49311679788804
At time: 300.4773712158203 and batch: 250, loss is 5.288493671417236 and perplexity is 198.0448799487147
At time: 301.6138572692871 and batch: 300, loss is 5.287644701004028 and perplexity is 197.8768170554572
At time: 302.7503125667572 and batch: 350, loss is 5.292880344390869 and perplexity is 198.91554633933606
At time: 303.88977789878845 and batch: 400, loss is 5.3262568378448485 and perplexity is 205.66668776962473
At time: 305.0279221534729 and batch: 450, loss is 5.296724243164062 and perplexity is 199.68162899269
At time: 306.1658751964569 and batch: 500, loss is 5.318194913864136 and perplexity is 204.01528425660476
At time: 307.30419421195984 and batch: 550, loss is 5.288432703018189 and perplexity is 198.03280583751803
At time: 308.44381952285767 and batch: 600, loss is 5.239077939987182 and perplexity is 188.49621742713592
At time: 309.58218264579773 and batch: 650, loss is 5.274532384872437 and perplexity is 195.29913032904497
At time: 310.72287225723267 and batch: 700, loss is 5.30429931640625 and perplexity is 201.19997548995147
At time: 311.8620765209198 and batch: 750, loss is 5.287029857635498 and perplexity is 197.75519120096135
At time: 312.99815702438354 and batch: 800, loss is 5.270100736618042 and perplexity is 194.43554823842973
At time: 314.1363661289215 and batch: 850, loss is 5.258812303543091 and perplexity is 192.2530174176775
At time: 315.27575278282166 and batch: 900, loss is 5.298394584655762 and perplexity is 200.01544421782404
At time: 316.41399240493774 and batch: 950, loss is 5.25746114730835 and perplexity is 191.9934289663156
At time: 317.55374813079834 and batch: 1000, loss is 5.271708164215088 and perplexity is 194.74834063272823
At time: 318.69334530830383 and batch: 1050, loss is 5.240416488647461 and perplexity is 188.7486977273267
At time: 319.8263108730316 and batch: 1100, loss is 5.2346031188964846 and perplexity is 187.65461499239382
At time: 320.9645802974701 and batch: 1150, loss is 5.240537805557251 and perplexity is 188.77159752510013
At time: 322.1022551059723 and batch: 1200, loss is 5.206750326156616 and perplexity is 182.50002794696988
At time: 323.2417662143707 and batch: 1250, loss is 5.2236083984375 and perplexity is 185.60270571237228
At time: 324.3812458515167 and batch: 1300, loss is 5.205849742889404 and perplexity is 182.33574546166724
At time: 325.5207769870758 and batch: 1350, loss is 5.198818044662476 and perplexity is 181.0581127517805
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.213253987630209 and perplexity of 183.69081438632028
Annealing...
Finished 10 epochs...
Completing Train Step...
At time: 328.92977833747864 and batch: 50, loss is 5.272766103744507 and perplexity is 194.95448162369715
At time: 330.0815393924713 and batch: 100, loss is 5.295011072158814 and perplexity is 199.33983307664172
At time: 331.2195086479187 and batch: 150, loss is 5.270003137588501 and perplexity is 194.41657244363788
At time: 332.3598954677582 and batch: 200, loss is 5.247521266937256 and perplexity is 190.09449049573024
At time: 333.4991943836212 and batch: 250, loss is 5.265992546081543 and perplexity is 193.63840848132637
At time: 334.63785767555237 and batch: 300, loss is 5.2650712299346925 and perplexity is 193.4600884461194
At time: 335.7760965824127 and batch: 350, loss is 5.2681958293914795 and perplexity is 194.06551910496765
At time: 336.9147970676422 and batch: 400, loss is 5.301087169647217 and perplexity is 200.55472850956102
At time: 338.05404567718506 and batch: 450, loss is 5.260140914916992 and perplexity is 192.50861672175785
At time: 339.19300723075867 and batch: 500, loss is 5.281734743118286 and perplexity is 196.71082228387374
At time: 340.3323907852173 and batch: 550, loss is 5.247278356552124 and perplexity is 190.0483201776844
At time: 341.4716019630432 and batch: 600, loss is 5.199139728546142 and perplexity is 181.11636559765836
At time: 342.6105978488922 and batch: 650, loss is 5.2242325592041015 and perplexity is 185.71858780021725
At time: 343.7491834163666 and batch: 700, loss is 5.2475278854370115 and perplexity is 190.09574864023259
At time: 344.8880228996277 and batch: 750, loss is 5.230745239257812 and perplexity is 186.93206073395442
At time: 346.02711033821106 and batch: 800, loss is 5.206442232131958 and perplexity is 182.44380943959732
At time: 347.1668698787689 and batch: 850, loss is 5.177043294906616 and perplexity is 177.15823121710264
At time: 348.3057584762573 and batch: 900, loss is 5.209320755004883 and perplexity is 182.96973469889014
At time: 349.4448857307434 and batch: 950, loss is 5.1700770378112795 and perplexity is 175.9283901001419
At time: 350.5838282108307 and batch: 1000, loss is 5.186451692581176 and perplexity is 178.8328717970232
At time: 351.72302055358887 and batch: 1050, loss is 5.1468909740447994 and perplexity is 171.89622884003234
At time: 352.862309217453 and batch: 1100, loss is 5.126728086471558 and perplexity is 168.46501236338548
At time: 354.03003692626953 and batch: 1150, loss is 5.122433843612671 and perplexity is 167.74313375741394
At time: 355.16925597190857 and batch: 1200, loss is 5.08100567817688 and perplexity is 160.93582421784808
At time: 356.3080847263336 and batch: 1250, loss is 5.092934637069702 and perplexity is 162.86711730537826
At time: 357.4472954273224 and batch: 1300, loss is 5.080609998703003 and perplexity is 160.87215781216915
At time: 358.58671474456787 and batch: 1350, loss is 5.0930241680145265 and perplexity is 162.88169960504518
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.136256510416667 and perplexity of 170.07789031066525
Finished 11 epochs...
Completing Train Step...
At time: 362.0042679309845 and batch: 50, loss is 5.235848121643066 and perplexity is 187.88839099915663
At time: 363.1379454135895 and batch: 100, loss is 5.255734186172486 and perplexity is 191.66214991150966
At time: 364.2773861885071 and batch: 150, loss is 5.2302912330627445 and perplexity is 186.84721168277926
At time: 365.4165904521942 and batch: 200, loss is 5.210967874526977 and perplexity is 183.27135605588623
At time: 366.55597853660583 and batch: 250, loss is 5.2305332469940184 and perplexity is 186.89243678335762
At time: 367.6955945491791 and batch: 300, loss is 5.232030172348022 and perplexity is 187.1724103079038
At time: 368.8354001045227 and batch: 350, loss is 5.235863428115845 and perplexity is 187.89126692970908
At time: 369.9751136302948 and batch: 400, loss is 5.269108123779297 and perplexity is 194.24264477200717
At time: 371.1153154373169 and batch: 450, loss is 5.22820294380188 and perplexity is 186.45742778961107
At time: 372.2538893222809 and batch: 500, loss is 5.253976125717163 and perplexity is 191.3254922839102
At time: 373.39301347732544 and batch: 550, loss is 5.223351278305054 and perplexity is 185.55498965473947
At time: 374.53227138519287 and batch: 600, loss is 5.175404825210571 and perplexity is 176.86820049200983
At time: 375.67125511169434 and batch: 650, loss is 5.20190055847168 and perplexity is 181.61708796640528
At time: 376.8098132610321 and batch: 700, loss is 5.226598281860351 and perplexity is 186.15846658150866
At time: 377.9488432407379 and batch: 750, loss is 5.211583738327026 and perplexity is 183.38426101313632
At time: 379.09396862983704 and batch: 800, loss is 5.187774314880371 and perplexity is 179.06955662890587
At time: 380.2325026988983 and batch: 850, loss is 5.161995763778687 and perplexity is 174.5123938028797
At time: 381.3713209629059 and batch: 900, loss is 5.19725790977478 and perplexity is 180.77585790844154
At time: 382.54270195961 and batch: 950, loss is 5.160343255996704 and perplexity is 174.22424886051957
At time: 383.68157410621643 and batch: 1000, loss is 5.178569240570068 and perplexity is 177.42877141409716
At time: 384.82040524482727 and batch: 1050, loss is 5.141709814071655 and perplexity is 171.0079102272507
At time: 385.96086621284485 and batch: 1100, loss is 5.125524740219117 and perplexity is 168.26241254540415
At time: 387.0994095802307 and batch: 1150, loss is 5.124681777954102 and perplexity is 168.12063344661865
At time: 388.23848032951355 and batch: 1200, loss is 5.087037963867187 and perplexity is 161.9095690882035
At time: 389.37775683403015 and batch: 1250, loss is 5.10522084236145 and perplexity is 164.88047910557825
At time: 390.5162835121155 and batch: 1300, loss is 5.093404026031494 and perplexity is 162.9435832772178
At time: 391.6545100212097 and batch: 1350, loss is 5.100584535598755 and perplexity is 164.11781197081064
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.132015787760417 and perplexity of 169.3581643056982
Finished 12 epochs...
Completing Train Step...
At time: 395.0798707008362 and batch: 50, loss is 5.226554498672486 and perplexity is 186.15031614882085
At time: 396.20889616012573 and batch: 100, loss is 5.243074226379394 and perplexity is 189.25100947389478
At time: 397.3475329875946 and batch: 150, loss is 5.216332349777222 and perplexity is 184.25715248573192
At time: 398.48577404022217 and batch: 200, loss is 5.197249031066894 and perplexity is 180.77425285953169
At time: 399.62429904937744 and batch: 250, loss is 5.217142057418823 and perplexity is 184.40640732835806
At time: 400.76251006126404 and batch: 300, loss is 5.219045085906982 and perplexity is 184.75767210232956
At time: 401.9013388156891 and batch: 350, loss is 5.223404722213745 and perplexity is 185.56490670366438
At time: 403.0407226085663 and batch: 400, loss is 5.256932373046875 and perplexity is 191.89193461887012
At time: 404.17921018600464 and batch: 450, loss is 5.21664665222168 and perplexity is 184.31507406113667
At time: 405.31760692596436 and batch: 500, loss is 5.243076477050781 and perplexity is 189.2514354162061
At time: 406.45608854293823 and batch: 550, loss is 5.213875169754028 and perplexity is 183.8049552839993
At time: 407.5949652194977 and batch: 600, loss is 5.166341619491577 and perplexity is 175.2724498371571
At time: 408.73349165916443 and batch: 650, loss is 5.193325004577637 and perplexity is 180.0662798635762
At time: 409.87290143966675 and batch: 700, loss is 5.218819551467895 and perplexity is 184.71600758295352
At time: 411.01158022880554 and batch: 750, loss is 5.20379711151123 and perplexity is 181.96186124368245
At time: 412.1779553890228 and batch: 800, loss is 5.180362501144409 and perplexity is 177.74723289149182
At time: 413.32302498817444 and batch: 850, loss is 5.155997467041016 and perplexity is 173.46874985265237
At time: 414.6468515396118 and batch: 900, loss is 5.192653579711914 and perplexity is 179.9454194646766
At time: 415.786502122879 and batch: 950, loss is 5.157279186248779 and perplexity is 173.6912306297702
At time: 416.92554545402527 and batch: 1000, loss is 5.176407518386841 and perplexity is 177.04563397054554
At time: 418.06427335739136 and batch: 1050, loss is 5.140885257720948 and perplexity is 170.86696268643234
At time: 419.2027077674866 and batch: 1100, loss is 5.126384639739991 and perplexity is 168.40716354006912
At time: 420.34095001220703 and batch: 1150, loss is 5.1273212814331055 and perplexity is 168.56497460553445
At time: 421.47989559173584 and batch: 1200, loss is 5.090841264724731 and perplexity is 162.52653239599735
At time: 422.6185460090637 and batch: 1250, loss is 5.110729379653931 and perplexity is 165.79123553842373
At time: 423.75716042518616 and batch: 1300, loss is 5.098915252685547 and perplexity is 163.8440814419446
At time: 424.8956220149994 and batch: 1350, loss is 5.1026107025146485 and perplexity is 164.45067916009978
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.130732014973958 and perplexity of 169.1408864007695
Finished 13 epochs...
Completing Train Step...
At time: 428.31045150756836 and batch: 50, loss is 5.219816398620606 and perplexity is 184.90023301621648
At time: 429.43171191215515 and batch: 100, loss is 5.234572896957397 and perplexity is 187.64894379174785
At time: 430.57044506073 and batch: 150, loss is 5.207311067581177 and perplexity is 182.60239196981507
At time: 431.7117404937744 and batch: 200, loss is 5.188435277938843 and perplexity is 179.18795411460627
At time: 432.8519582748413 and batch: 250, loss is 5.208707160949707 and perplexity is 182.85749999419704
At time: 433.99202609062195 and batch: 300, loss is 5.211228971481323 and perplexity is 183.31921389626757
At time: 435.1327314376831 and batch: 350, loss is 5.2160553550720214 and perplexity is 184.20612129810874
At time: 436.2738060951233 and batch: 400, loss is 5.249618053436279 and perplexity is 190.493496225668
At time: 437.4145760536194 and batch: 450, loss is 5.2093849372863765 and perplexity is 182.9814784907751
At time: 438.55532002449036 and batch: 500, loss is 5.236607847213745 and perplexity is 188.0311888509537
At time: 439.69589138031006 and batch: 550, loss is 5.208136768341064 and perplexity is 182.75322916824663
At time: 440.8683431148529 and batch: 600, loss is 5.160970191955567 and perplexity is 174.33351055349945
At time: 442.0090982913971 and batch: 650, loss is 5.188187341690064 and perplexity is 179.14353243253692
At time: 443.149968624115 and batch: 700, loss is 5.214217853546143 and perplexity is 183.86795305662673
At time: 444.291029214859 and batch: 750, loss is 5.199122591018677 and perplexity is 181.11326173756478
At time: 445.43367862701416 and batch: 800, loss is 5.175542726516723 and perplexity is 176.8925925296827
At time: 446.5750906467438 and batch: 850, loss is 5.152206449508667 and perplexity is 172.8123717372299
At time: 447.71602630615234 and batch: 900, loss is 5.189425268173218 and perplexity is 179.36543627760588
At time: 448.8566334247589 and batch: 950, loss is 5.155219287872314 and perplexity is 173.33381259458739
At time: 449.9970643520355 and batch: 1000, loss is 5.17513518333435 and perplexity is 176.82051584776275
At time: 451.13769578933716 and batch: 1050, loss is 5.140013637542725 and perplexity is 170.71809648078232
At time: 452.2790787220001 and batch: 1100, loss is 5.1263453483581545 and perplexity is 168.40054671989537
At time: 453.4200940132141 and batch: 1150, loss is 5.127878093719483 and perplexity is 168.6588597902342
At time: 454.5612795352936 and batch: 1200, loss is 5.092781562805175 and perplexity is 162.84218844921293
At time: 455.7014482021332 and batch: 1250, loss is 5.113368282318115 and perplexity is 166.22932024881112
At time: 456.8424003124237 and batch: 1300, loss is 5.101288633346558 and perplexity is 164.23340764314426
At time: 457.9830765724182 and batch: 1350, loss is 5.1028934097290035 and perplexity is 164.49717712584942
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.12982666015625 and perplexity of 168.98782318311098
Finished 14 epochs...
Completing Train Step...
At time: 461.41056418418884 and batch: 50, loss is 5.214005794525146 and perplexity is 183.82896633239832
At time: 462.5444951057434 and batch: 100, loss is 5.228107891082764 and perplexity is 186.4397053463968
At time: 463.7136175632477 and batch: 150, loss is 5.200666494369507 and perplexity is 181.3930990745565
At time: 464.85514974594116 and batch: 200, loss is 5.1818248462677 and perplexity is 178.0073508354384
At time: 465.9968259334564 and batch: 250, loss is 5.202452735900879 and perplexity is 181.71740051575125
At time: 467.13840532302856 and batch: 300, loss is 5.205433988571167 and perplexity is 182.2599543444565
At time: 468.27985167503357 and batch: 350, loss is 5.210520133972168 and perplexity is 183.18931640485516
At time: 469.42122864723206 and batch: 400, loss is 5.2441816234588625 and perplexity is 189.46070157385284
At time: 470.56295895576477 and batch: 450, loss is 5.2038648891448975 and perplexity is 181.97419460601358
At time: 471.7044024467468 and batch: 500, loss is 5.231808452606201 and perplexity is 187.1309150897389
At time: 472.84609842300415 and batch: 550, loss is 5.20411376953125 and perplexity is 182.0194900502133
At time: 473.98847460746765 and batch: 600, loss is 5.156967477798462 and perplexity is 173.63709804266765
At time: 475.13068652153015 and batch: 650, loss is 5.184302453994751 and perplexity is 178.4489300274616
At time: 476.2722203731537 and batch: 700, loss is 5.21035322189331 and perplexity is 183.1587424468819
At time: 477.41345024108887 and batch: 750, loss is 5.195302686691284 and perplexity is 180.4227460967952
At time: 478.554270029068 and batch: 800, loss is 5.171817522048951 and perplexity is 176.23485731338235
At time: 479.69600224494934 and batch: 850, loss is 5.1487464427948 and perplexity is 172.21547300308185
At time: 480.8376839160919 and batch: 900, loss is 5.186852893829346 and perplexity is 178.9046341630147
At time: 481.9792561531067 and batch: 950, loss is 5.1531330108642575 and perplexity is 172.9725672066543
At time: 483.1201391220093 and batch: 1000, loss is 5.173635349273682 and perplexity is 176.5555131951486
At time: 484.2609233856201 and batch: 1050, loss is 5.138843469619751 and perplexity is 170.51844447637677
At time: 485.40268087387085 and batch: 1100, loss is 5.125525970458984 and perplexity is 168.26261954865956
At time: 486.5438435077667 and batch: 1150, loss is 5.12749662399292 and perplexity is 168.59453381109455
At time: 487.6854569911957 and batch: 1200, loss is 5.093364286422729 and perplexity is 162.9371080916292
At time: 488.82686042785645 and batch: 1250, loss is 5.11430362701416 and perplexity is 166.38487469900718
At time: 489.9679026603699 and batch: 1300, loss is 5.1020904064178465 and perplexity is 164.36513836881596
At time: 491.10958671569824 and batch: 1350, loss is 5.102085304260254 and perplexity is 164.36429975411667
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.129429931640625 and perplexity of 168.92079419189608
Finished 15 epochs...
Completing Train Step...
At time: 494.5285611152649 and batch: 50, loss is 5.2088942527771 and perplexity is 182.89171433853565
At time: 495.666380405426 and batch: 100, loss is 5.222589845657349 and perplexity is 185.41375580452774
At time: 496.80677461624146 and batch: 150, loss is 5.194821329116821 and perplexity is 180.33591914043916
At time: 497.94724440574646 and batch: 200, loss is 5.176304588317871 and perplexity is 177.02741158906161
At time: 499.0875961780548 and batch: 250, loss is 5.1976432037353515 and perplexity is 180.84552317465204
At time: 500.22855496406555 and batch: 300, loss is 5.2003183174133305 and perplexity is 181.32995317106142
At time: 501.3697609901428 and batch: 350, loss is 5.206087265014649 and perplexity is 182.3790593792406
At time: 502.5106563568115 and batch: 400, loss is 5.239517946243286 and perplexity is 188.57917519168495
At time: 503.6520173549652 and batch: 450, loss is 5.199300413131714 and perplexity is 181.14547054410014
At time: 504.7927565574646 and batch: 500, loss is 5.227837572097778 and perplexity is 186.38931396566687
At time: 505.9335994720459 and batch: 550, loss is 5.200522441864013 and perplexity is 181.3669708261205
At time: 507.0743420124054 and batch: 600, loss is 5.153438539505005 and perplexity is 173.02542335412178
At time: 508.2154116630554 and batch: 650, loss is 5.180799379348755 and perplexity is 177.82490374854171
At time: 509.35665678977966 and batch: 700, loss is 5.207128992080689 and perplexity is 182.56914757449363
At time: 510.4973249435425 and batch: 750, loss is 5.191905755996704 and perplexity is 179.8109023163832
At time: 511.6391987800598 and batch: 800, loss is 5.168793468475342 and perplexity is 175.70271867673182
At time: 512.779974937439 and batch: 850, loss is 5.145906143188476 and perplexity is 171.72702346279928
At time: 513.9212741851807 and batch: 900, loss is 5.184391584396362 and perplexity is 178.46483596110266
At time: 515.0623877048492 and batch: 950, loss is 5.151223802566529 and perplexity is 172.64264159463895
At time: 516.2040493488312 and batch: 1000, loss is 5.172038545608521 and perplexity is 176.27381367384422
At time: 517.3451128005981 and batch: 1050, loss is 5.137511386871338 and perplexity is 170.2914510188036
At time: 518.4860575199127 and batch: 1100, loss is 5.124459609985352 and perplexity is 168.08328657577368
At time: 519.6266543865204 and batch: 1150, loss is 5.126711845397949 and perplexity is 168.4622763329373
At time: 520.8130593299866 and batch: 1200, loss is 5.0931946849823 and perplexity is 162.90947606667928
At time: 521.9537584781647 and batch: 1250, loss is 5.114293851852417 and perplexity is 166.38324826789471
At time: 523.0953145027161 and batch: 1300, loss is 5.101737766265869 and perplexity is 164.30718684006035
At time: 524.2360877990723 and batch: 1350, loss is 5.101010789871216 and perplexity is 164.18778280097334
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.128900553385416 and perplexity of 168.8313948617168
Finished 16 epochs...
Completing Train Step...
At time: 527.6606607437134 and batch: 50, loss is 5.204367685317993 and perplexity is 182.06571354042057
At time: 528.7841339111328 and batch: 100, loss is 5.217808313369751 and perplexity is 184.52931013244577
At time: 529.9192686080933 and batch: 150, loss is 5.1901797103881835 and perplexity is 179.5008081933625
At time: 531.059050321579 and batch: 200, loss is 5.171649351119995 and perplexity is 176.20522222566353
At time: 532.1979713439941 and batch: 250, loss is 5.193255681991577 and perplexity is 180.053797636049
At time: 533.336719751358 and batch: 300, loss is 5.196360177993775 and perplexity is 180.613642499417
At time: 534.4755625724792 and batch: 350, loss is 5.202076263427735 and perplexity is 181.64900179249182
At time: 535.615528345108 and batch: 400, loss is 5.235562543869019 and perplexity is 187.83474191154392
At time: 536.7546138763428 and batch: 450, loss is 5.195603151321411 and perplexity is 180.47696489547533
At time: 537.8946802616119 and batch: 500, loss is 5.224376754760742 and perplexity is 185.7453695262202
At time: 539.0338521003723 and batch: 550, loss is 5.197479467391968 and perplexity is 180.81591461403508
At time: 540.1736421585083 and batch: 600, loss is 5.150627946853637 and perplexity is 172.53980213213947
At time: 541.3124384880066 and batch: 650, loss is 5.177920866012573 and perplexity is 177.31376839948783
At time: 542.4522869586945 and batch: 700, loss is 5.2041045093536376 and perplexity is 182.0178045252107
At time: 543.5915472507477 and batch: 750, loss is 5.1888703346252445 and perplexity is 179.2659279924651
At time: 544.7317314147949 and batch: 800, loss is 5.165722246170044 and perplexity is 175.16392437008713
At time: 545.8708765506744 and batch: 850, loss is 5.14307020187378 and perplexity is 171.24070561248993
At time: 547.0105109214783 and batch: 900, loss is 5.182215347290039 and perplexity is 178.07687646195401
At time: 548.1496753692627 and batch: 950, loss is 5.149513854980468 and perplexity is 172.3476839792937
At time: 549.3171782493591 and batch: 1000, loss is 5.170472421646118 and perplexity is 175.99796309478907
At time: 550.4565153121948 and batch: 1050, loss is 5.136152439117431 and perplexity is 170.06019100466028
At time: 551.5973780155182 and batch: 1100, loss is 5.123266763687134 and perplexity is 167.88290858342222
At time: 552.7362201213837 and batch: 1150, loss is 5.125692663192749 and perplexity is 168.29067004254432
At time: 553.8754351139069 and batch: 1200, loss is 5.092368125915527 and perplexity is 162.7748773967119
At time: 555.0150196552277 and batch: 1250, loss is 5.113973875045776 and perplexity is 166.33001800411444
At time: 556.1542704105377 and batch: 1300, loss is 5.101111602783203 and perplexity is 164.20433588383847
At time: 557.2933249473572 and batch: 1350, loss is 5.099332065582275 and perplexity is 163.91238800268098
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.128539632161458 and perplexity of 168.7704710230553
Finished 17 epochs...
Completing Train Step...
At time: 560.6860709190369 and batch: 50, loss is 5.200414190292358 and perplexity is 181.34733862910952
At time: 561.8357186317444 and batch: 100, loss is 5.213714532852173 and perplexity is 183.77543179678096
At time: 562.9740521907806 and batch: 150, loss is 5.185880708694458 and perplexity is 178.7307902550427
At time: 564.1132709980011 and batch: 200, loss is 5.167512578964233 and perplexity is 175.47780698157177
At time: 565.2530262470245 and batch: 250, loss is 5.1892267513275145 and perplexity is 179.3298327510347
At time: 566.3916358947754 and batch: 300, loss is 5.19274130821228 and perplexity is 179.96120649895036
At time: 567.5299677848816 and batch: 350, loss is 5.198797492980957 and perplexity is 181.05439174134756
At time: 568.6684584617615 and batch: 400, loss is 5.232033176422119 and perplexity is 187.17297258853782
At time: 569.8069746494293 and batch: 450, loss is 5.192099733352661 and perplexity is 179.8457849428973
At time: 570.9458413124084 and batch: 500, loss is 5.221275024414062 and perplexity is 185.17013005685007
At time: 572.0844798088074 and batch: 550, loss is 5.194520168304443 and perplexity is 180.2816172057477
At time: 573.2233238220215 and batch: 600, loss is 5.147936697006226 and perplexity is 172.07607869368437
At time: 574.3618814945221 and batch: 650, loss is 5.17512243270874 and perplexity is 176.81826128993848
At time: 575.5009996891022 and batch: 700, loss is 5.201416501998901 and perplexity is 181.52919631338588
At time: 576.6395757198334 and batch: 750, loss is 5.18594952583313 and perplexity is 178.74309041984688
At time: 577.8247199058533 and batch: 800, loss is 5.163099250793457 and perplexity is 174.7050722528897
At time: 578.9640462398529 and batch: 850, loss is 5.140744562149048 and perplexity is 170.84292415249573
At time: 580.1031341552734 and batch: 900, loss is 5.179530563354493 and perplexity is 177.5994197455926
At time: 581.2415075302124 and batch: 950, loss is 5.147313604354858 and perplexity is 171.96889275042884
At time: 582.3801407814026 and batch: 1000, loss is 5.168509159088135 and perplexity is 175.65277184496722
At time: 583.5192904472351 and batch: 1050, loss is 5.13433141708374 and perplexity is 169.75078944881344
At time: 584.6588788032532 and batch: 1100, loss is 5.121565980911255 and perplexity is 167.59761890079875
At time: 585.7989604473114 and batch: 1150, loss is 5.124318180084228 and perplexity is 168.05951625412948
At time: 586.9381198883057 and batch: 1200, loss is 5.091375494003296 and perplexity is 162.61338202488864
At time: 588.0771496295929 and batch: 1250, loss is 5.113142595291138 and perplexity is 166.1918086808241
At time: 589.2157726287842 and batch: 1300, loss is 5.100114431381225 and perplexity is 164.04067762724208
At time: 590.3542885780334 and batch: 1350, loss is 5.097466974258423 and perplexity is 163.60696134278925
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.128446044921875 and perplexity of 168.75467699962022
Finished 18 epochs...
Completing Train Step...
At time: 593.7893822193146 and batch: 50, loss is 5.196731491088867 and perplexity is 180.6807191624804
At time: 594.9563364982605 and batch: 100, loss is 5.209815921783448 and perplexity is 183.06035766788605
At time: 596.0944540500641 and batch: 150, loss is 5.1818677425384525 and perplexity is 178.01498685073284
At time: 597.233291387558 and batch: 200, loss is 5.163517084121704 and perplexity is 174.77808510723048
At time: 598.3717701435089 and batch: 250, loss is 5.1857802772521975 and perplexity is 178.71284096535268
At time: 599.5107750892639 and batch: 300, loss is 5.189498167037964 and perplexity is 179.37851229089276
At time: 600.6494312286377 and batch: 350, loss is 5.195469694137573 and perplexity is 180.45288055514274
At time: 601.7877044677734 and batch: 400, loss is 5.229039993286133 and perplexity is 186.61356722247675
At time: 602.9259548187256 and batch: 450, loss is 5.189078779220581 and perplexity is 179.3032989010297
At time: 604.0644161701202 and batch: 500, loss is 5.2186445713043215 and perplexity is 184.68368877338972
At time: 605.2032403945923 and batch: 550, loss is 5.192166767120361 and perplexity is 179.85784108754692
At time: 606.3423774242401 and batch: 600, loss is 5.145379514694214 and perplexity is 171.63661092800695
At time: 607.5094497203827 and batch: 650, loss is 5.172514019012451 and perplexity is 176.35764711276136
At time: 608.6480448246002 and batch: 700, loss is 5.1989877319335935 and perplexity is 181.08883861566738
At time: 609.7870185375214 and batch: 750, loss is 5.183461751937866 and perplexity is 178.298970689333
At time: 610.9262223243713 and batch: 800, loss is 5.160431642532348 and perplexity is 174.2396486188572
At time: 612.065160036087 and batch: 850, loss is 5.138309135437011 and perplexity is 170.42735498098833
At time: 613.2043828964233 and batch: 900, loss is 5.177425565719605 and perplexity is 177.22596658397973
At time: 614.3436114788055 and batch: 950, loss is 5.145450801849365 and perplexity is 171.64884684984668
At time: 615.4824850559235 and batch: 1000, loss is 5.166785459518433 and perplexity is 175.35026003236214
At time: 616.6211044788361 and batch: 1050, loss is 5.132498950958252 and perplexity is 169.44001170917792
At time: 617.759443283081 and batch: 1100, loss is 5.120239276885986 and perplexity is 167.37541389790618
At time: 618.8979756832123 and batch: 1150, loss is 5.122836771011353 and perplexity is 167.8107356803644
At time: 620.0368428230286 and batch: 1200, loss is 5.0906893825531006 and perplexity is 162.50184938781132
At time: 621.1753916740417 and batch: 1250, loss is 5.112049074172973 and perplexity is 166.01017375727773
At time: 622.3138380050659 and batch: 1300, loss is 5.09845703125 and perplexity is 163.769021770029
At time: 623.4523797035217 and batch: 1350, loss is 5.095668640136719 and perplexity is 163.31300575606022
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.128089599609375 and perplexity of 168.6945359051835
Finished 19 epochs...
Completing Train Step...
At time: 626.8712232112885 and batch: 50, loss is 5.193090877532959 and perplexity is 180.02412641244965
At time: 628.0085799694061 and batch: 100, loss is 5.206202163696289 and perplexity is 182.40001569662562
At time: 629.1475131511688 and batch: 150, loss is 5.178161354064941 and perplexity is 177.35641537014618
At time: 630.285252571106 and batch: 200, loss is 5.159847087860108 and perplexity is 174.13782578157458
At time: 631.4233660697937 and batch: 250, loss is 5.182470197677612 and perplexity is 178.12226520636216
At time: 632.5611455440521 and batch: 300, loss is 5.186366920471191 and perplexity is 178.8177123997024
At time: 633.6998779773712 and batch: 350, loss is 5.192532281875611 and perplexity is 179.92359379837268
At time: 634.8394265174866 and batch: 400, loss is 5.22555305480957 and perplexity is 185.9639903701096
At time: 636.006495475769 and batch: 450, loss is 5.185650053024292 and perplexity is 178.68956973889289
At time: 637.1447978019714 and batch: 500, loss is 5.2159278678894045 and perplexity is 184.1826388755694
At time: 638.2829697132111 and batch: 550, loss is 5.189448051452636 and perplexity is 179.3695228570113
At time: 639.4216632843018 and batch: 600, loss is 5.142632389068604 and perplexity is 171.16575064812432
At time: 640.5601005554199 and batch: 650, loss is 5.170059289932251 and perplexity is 175.92526777206413
At time: 641.6992931365967 and batch: 700, loss is 5.1963496589660645 and perplexity is 180.6117426294991
At time: 642.8387048244476 and batch: 750, loss is 5.180667686462402 and perplexity is 177.80148701564414
At time: 643.9767680168152 and batch: 800, loss is 5.1581239414215085 and perplexity is 173.83801918676969
At time: 645.1155598163605 and batch: 850, loss is 5.136023731231689 and perplexity is 170.03830432555148
At time: 646.253945350647 and batch: 900, loss is 5.174964103698731 and perplexity is 176.79026804580664
At time: 647.3927721977234 and batch: 950, loss is 5.1435788631439205 and perplexity is 171.32783128415545
At time: 648.5316271781921 and batch: 1000, loss is 5.164884786605835 and perplexity is 175.01729307377965
At time: 649.6710388660431 and batch: 1050, loss is 5.1305970859527585 and perplexity is 169.11806592612936
At time: 650.8099279403687 and batch: 1100, loss is 5.118388185501098 and perplexity is 167.06587329355852
At time: 651.9495303630829 and batch: 1150, loss is 5.121341953277588 and perplexity is 167.56007660824065
At time: 653.0878353118896 and batch: 1200, loss is 5.0892656135559085 and perplexity is 162.27064891975175
At time: 654.2262098789215 and batch: 1250, loss is 5.110875101089477 and perplexity is 165.81539663561958
At time: 655.3655462265015 and batch: 1300, loss is 5.097103509902954 and perplexity is 163.54750684948365
At time: 656.5045783519745 and batch: 1350, loss is 5.093747777938843 and perplexity is 162.99960507300753
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.12796142578125 and perplexity of 168.6729150663753
Finished 20 epochs...
Completing Train Step...
At time: 659.9519851207733 and batch: 50, loss is 5.189620141983032 and perplexity is 179.4003933095167
At time: 661.0778708457947 and batch: 100, loss is 5.202632083892822 and perplexity is 181.74999408934346
At time: 662.2165403366089 and batch: 150, loss is 5.174694919586182 and perplexity is 176.7426853189399
At time: 663.3576366901398 and batch: 200, loss is 5.156437025070191 and perplexity is 173.54501619497464
At time: 664.5265295505524 and batch: 250, loss is 5.179348278045654 and perplexity is 177.56704893096637
At time: 665.6673691272736 and batch: 300, loss is 5.183070554733276 and perplexity is 178.22923427165324
At time: 666.8079319000244 and batch: 350, loss is 5.1895729923248295 and perplexity is 179.39193484169922
At time: 667.9490296840668 and batch: 400, loss is 5.222776670455932 and perplexity is 185.44839892810705
At time: 669.0898447036743 and batch: 450, loss is 5.182646045684814 and perplexity is 178.1535904058932
At time: 670.23215675354 and batch: 500, loss is 5.213244895935059 and perplexity is 183.68914433302592
At time: 671.3731479644775 and batch: 550, loss is 5.186950435638428 and perplexity is 178.92208569579736
At time: 672.5134706497192 and batch: 600, loss is 5.140207548141479 and perplexity is 170.75120373890945
At time: 673.6541068553925 and batch: 650, loss is 5.167637681961059 and perplexity is 175.49976115433938
At time: 674.7953469753265 and batch: 700, loss is 5.193799104690552 and perplexity is 180.15166954722162
At time: 675.9360086917877 and batch: 750, loss is 5.178026256561279 and perplexity is 177.33245657959404
At time: 677.0776727199554 and batch: 800, loss is 5.155696792602539 and perplexity is 173.4166000741427
At time: 678.2186498641968 and batch: 850, loss is 5.133638324737549 and perplexity is 169.63317723865606
At time: 679.3593237400055 and batch: 900, loss is 5.1723936080932615 and perplexity is 176.33641300480133
At time: 680.50000166893 and batch: 950, loss is 5.141449003219605 and perplexity is 170.96331532414712
At time: 681.6414031982422 and batch: 1000, loss is 5.162986869812012 and perplexity is 174.68543982858267
At time: 682.7825524806976 and batch: 1050, loss is 5.1285702419281005 and perplexity is 168.77563712685566
At time: 683.9247953891754 and batch: 1100, loss is 5.1164945793151855 and perplexity is 166.74981566122057
At time: 685.0662024021149 and batch: 1150, loss is 5.119481649398804 and perplexity is 167.24865370822397
At time: 686.2073216438293 and batch: 1200, loss is 5.087892045974732 and perplexity is 162.04791222399083
At time: 687.3476748466492 and batch: 1250, loss is 5.109404039382935 and perplexity is 165.57165128145797
At time: 688.4885444641113 and batch: 1300, loss is 5.095498762130737 and perplexity is 163.28526482464534
At time: 689.629115819931 and batch: 1350, loss is 5.091805210113526 and perplexity is 162.68327463079748
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.127828369140625 and perplexity of 168.65047350796436
Finished 21 epochs...
Completing Train Step...
At time: 693.02627825737 and batch: 50, loss is 5.186371755599976 and perplexity is 178.81857700846106
At time: 694.1950852870941 and batch: 100, loss is 5.1993681335449216 and perplexity is 181.15773820559698
At time: 695.3360166549683 and batch: 150, loss is 5.1715194034576415 and perplexity is 176.1823262566119
At time: 696.478188753128 and batch: 200, loss is 5.153130130767822 and perplexity is 172.9720690296975
At time: 697.6197113990784 and batch: 250, loss is 5.176179513931275 and perplexity is 177.00527137876188
At time: 698.7615747451782 and batch: 300, loss is 5.180212373733521 and perplexity is 177.72055016257983
At time: 699.9029307365417 and batch: 350, loss is 5.186797304153442 and perplexity is 178.89468918880547
At time: 701.0443680286407 and batch: 400, loss is 5.219900207519531 and perplexity is 184.9157299505381
At time: 702.1860108375549 and batch: 450, loss is 5.179589614868164 and perplexity is 177.6099075698137
At time: 703.3275673389435 and batch: 500, loss is 5.2106591320037845 and perplexity is 183.21478112898083
At time: 704.4697122573853 and batch: 550, loss is 5.184193563461304 and perplexity is 178.4294996861872
At time: 705.6123323440552 and batch: 600, loss is 5.137718152999878 and perplexity is 170.326665163275
At time: 706.7537248134613 and batch: 650, loss is 5.165136756896973 and perplexity is 175.06139778837513
At time: 707.8952226638794 and batch: 700, loss is 5.1912518405914305 and perplexity is 179.69335963299667
At time: 709.0366086959839 and batch: 750, loss is 5.175493783950806 and perplexity is 176.8839351641711
At time: 710.1781327724457 and batch: 800, loss is 5.153309993743896 and perplexity is 173.0031830988615
At time: 711.3205893039703 and batch: 850, loss is 5.1313604068756105 and perplexity is 169.24720656588877
At time: 712.4631662368774 and batch: 900, loss is 5.170193109512329 and perplexity is 175.94881159279956
At time: 713.6050951480865 and batch: 950, loss is 5.139654016494751 and perplexity is 170.6567136979496
At time: 714.7459492683411 and batch: 1000, loss is 5.161026935577393 and perplexity is 174.34340314896212
At time: 715.8878195285797 and batch: 1050, loss is 5.126445875167847 and perplexity is 168.4174763405337
At time: 717.029627084732 and batch: 1100, loss is 5.114739828109741 and perplexity is 166.45746779508193
At time: 718.1716854572296 and batch: 1150, loss is 5.117859411239624 and perplexity is 166.9775565116685
At time: 719.3137249946594 and batch: 1200, loss is 5.086685543060303 and perplexity is 161.85251884066068
At time: 720.4558041095734 and batch: 1250, loss is 5.108100347518921 and perplexity is 165.35593750946816
At time: 721.5967786312103 and batch: 1300, loss is 5.093992719650268 and perplexity is 163.03953536533325
At time: 722.7385411262512 and batch: 1350, loss is 5.089664659500122 and perplexity is 162.33541528558646
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.127459309895833 and perplexity of 168.58824297566076
Finished 22 epochs...
Completing Train Step...
At time: 726.1652212142944 and batch: 50, loss is 5.183100681304932 and perplexity is 178.23460378833286
At time: 727.3340373039246 and batch: 100, loss is 5.196382894515991 and perplexity is 180.6177454598417
At time: 728.4744503498077 and batch: 150, loss is 5.168251218795777 and perplexity is 175.60746976051163
At time: 729.6148941516876 and batch: 200, loss is 5.150207347869873 and perplexity is 172.4672473260123
At time: 730.7563741207123 and batch: 250, loss is 5.173315391540528 and perplexity is 176.49903192966144
At time: 731.8976790904999 and batch: 300, loss is 5.177458038330078 and perplexity is 177.23172166719917
At time: 733.038400888443 and batch: 350, loss is 5.183820037841797 and perplexity is 178.36286414259473
At time: 734.1794912815094 and batch: 400, loss is 5.217020044326782 and perplexity is 184.3839087049989
At time: 735.3197135925293 and batch: 450, loss is 5.176867208480835 and perplexity is 177.1270388037308
At time: 736.4597511291504 and batch: 500, loss is 5.208235969543457 and perplexity is 182.77135940757722
At time: 737.6006348133087 and batch: 550, loss is 5.181949224472046 and perplexity is 178.02949244703402
At time: 738.7413222789764 and batch: 600, loss is 5.135135612487793 and perplexity is 169.88735715972496
At time: 739.8819036483765 and batch: 650, loss is 5.162559394836426 and perplexity is 174.61078213274195
At time: 741.0231807231903 and batch: 700, loss is 5.189004030227661 and perplexity is 179.28989666091786
At time: 742.1633648872375 and batch: 750, loss is 5.172794427871704 and perplexity is 176.40710629348095
At time: 743.3045439720154 and batch: 800, loss is 5.151196098327636 and perplexity is 172.63785872790635
At time: 744.4460072517395 and batch: 850, loss is 5.129036617279053 and perplexity is 168.85436828156082
At time: 745.5868802070618 and batch: 900, loss is 5.167778444290161 and perplexity is 175.52446664823697
At time: 746.7282676696777 and batch: 950, loss is 5.137517986297607 and perplexity is 170.2925748483872
At time: 747.8700664043427 and batch: 1000, loss is 5.159086332321167 and perplexity is 174.0053998443416
At time: 749.0110337734222 and batch: 1050, loss is 5.124819746017456 and perplexity is 168.1438303250026
At time: 750.1512625217438 and batch: 1100, loss is 5.11292763710022 and perplexity is 166.15608822962395
At time: 751.3194839954376 and batch: 1150, loss is 5.11596209526062 and perplexity is 166.66104767914425
At time: 752.4596467018127 and batch: 1200, loss is 5.085177345275879 and perplexity is 161.6085972176041
At time: 753.6004962921143 and batch: 1250, loss is 5.106489963531494 and perplexity is 165.0898652522296
At time: 754.7420029640198 and batch: 1300, loss is 5.092353315353393 and perplexity is 162.7724666271288
At time: 755.8826174736023 and batch: 1350, loss is 5.087630767822265 and perplexity is 162.0055781755957
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.127019856770834 and perplexity of 168.51417262186314
Finished 23 epochs...
Completing Train Step...
At time: 759.3767454624176 and batch: 50, loss is 5.179881401062012 and perplexity is 177.66173925024978
At time: 760.5012171268463 and batch: 100, loss is 5.1932001876831055 and perplexity is 180.04380595230495
At time: 761.6407418251038 and batch: 150, loss is 5.165269393920898 and perplexity is 175.08461895114084
At time: 762.7801592350006 and batch: 200, loss is 5.1474419116973875 and perplexity is 171.99095903765843
At time: 763.9192471504211 and batch: 250, loss is 5.170438985824585 and perplexity is 175.99207855668263
At time: 765.0582702159882 and batch: 300, loss is 5.174748592376709 and perplexity is 176.75217184664805
At time: 766.1971454620361 and batch: 350, loss is 5.181364240646363 and perplexity is 177.92537852890604
At time: 767.3366770744324 and batch: 400, loss is 5.214325790405273 and perplexity is 183.88780025707743
At time: 768.4760746955872 and batch: 450, loss is 5.174284019470215 and perplexity is 176.67007664752333
At time: 769.6153216362 and batch: 500, loss is 5.205890941619873 and perplexity is 182.34325761764393
At time: 770.7539794445038 and batch: 550, loss is 5.179397497177124 and perplexity is 177.57578884197608
At time: 771.8929071426392 and batch: 600, loss is 5.132861194610595 and perplexity is 169.50140139621354
At time: 773.0317718982697 and batch: 650, loss is 5.1605082035064695 and perplexity is 174.2529890867591
At time: 774.1711177825928 and batch: 700, loss is 5.186660327911377 and perplexity is 178.87018654473331
At time: 775.3106985092163 and batch: 750, loss is 5.170358276367187 and perplexity is 175.97787490470816
At time: 776.4500751495361 and batch: 800, loss is 5.149322547912598 and perplexity is 172.31471580284042
At time: 777.5890579223633 and batch: 850, loss is 5.126697931289673 and perplexity is 168.4599323468912
At time: 778.7297422885895 and batch: 900, loss is 5.165695695877075 and perplexity is 175.1592737783151
At time: 779.9139051437378 and batch: 950, loss is 5.135383081436157 and perplexity is 169.9294042077965
At time: 781.053323507309 and batch: 1000, loss is 5.157015428543091 and perplexity is 173.64542427043685
At time: 782.1925587654114 and batch: 1050, loss is 5.122563905715943 and perplexity is 167.76495220104533
At time: 783.3324110507965 and batch: 1100, loss is 5.110993566513062 and perplexity is 165.83504119039617
At time: 784.4714608192444 and batch: 1150, loss is 5.114528522491455 and perplexity is 166.42229811283784
At time: 785.611242055893 and batch: 1200, loss is 5.083703298568725 and perplexity is 161.37055408347874
At time: 786.7497763633728 and batch: 1250, loss is 5.105395193099976 and perplexity is 164.90922864505765
At time: 787.8890309333801 and batch: 1300, loss is 5.091123914718628 and perplexity is 162.57247701220393
At time: 789.0285193920135 and batch: 1350, loss is 5.085791120529175 and perplexity is 161.7078190221253
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.126885172526042 and perplexity of 168.49147794612884
Finished 24 epochs...
Completing Train Step...
At time: 792.4504342079163 and batch: 50, loss is 5.177066297531128 and perplexity is 177.1623063682439
At time: 793.5841267108917 and batch: 100, loss is 5.190298662185669 and perplexity is 179.52216140712363
At time: 794.7235743999481 and batch: 150, loss is 5.162737388610839 and perplexity is 174.6418645310617
At time: 795.8629858493805 and batch: 200, loss is 5.144547834396362 and perplexity is 171.49392348370085
At time: 797.002632856369 and batch: 250, loss is 5.167846431732178 and perplexity is 175.53640051340759
At time: 798.1406755447388 and batch: 300, loss is 5.1724001121521 and perplexity is 176.3375599109366
At time: 799.2792596817017 and batch: 350, loss is 5.178816709518433 and perplexity is 177.4726849589639
At time: 800.4181125164032 and batch: 400, loss is 5.211910305023193 and perplexity is 183.44415798503016
At time: 801.5569934844971 and batch: 450, loss is 5.171514139175415 and perplexity is 176.18139878556445
At time: 802.6963505744934 and batch: 500, loss is 5.203627014160157 and perplexity is 181.9309126453004
At time: 803.8359527587891 and batch: 550, loss is 5.177242116928101 and perplexity is 177.19345767653778
At time: 804.9745109081268 and batch: 600, loss is 5.130932054519653 and perplexity is 169.17472465122484
At time: 806.112978219986 and batch: 650, loss is 5.15831748008728 and perplexity is 173.8716668210176
At time: 807.2519888877869 and batch: 700, loss is 5.184380664825439 and perplexity is 178.46288721230889
At time: 808.3907630443573 and batch: 750, loss is 5.1679586410522464 and perplexity is 175.5560984386812
At time: 809.5580818653107 and batch: 800, loss is 5.147199630737305 and perplexity is 171.94929395050968
At time: 810.6974530220032 and batch: 850, loss is 5.124383583068847 and perplexity is 168.0705082075355
At time: 811.8359620571136 and batch: 900, loss is 5.163347034454346 and perplexity is 174.74836667887257
At time: 812.9744102954865 and batch: 950, loss is 5.133550462722778 and perplexity is 169.6182735806741
At time: 814.1132266521454 and batch: 1000, loss is 5.155169782638549 and perplexity is 173.32523187607254
At time: 815.2521116733551 and batch: 1050, loss is 5.120704669952392 and perplexity is 167.45332738381293
At time: 816.3913054466248 and batch: 1100, loss is 5.109199514389038 and perplexity is 165.53779120322437
At time: 817.5307803153992 and batch: 1150, loss is 5.112795963287353 and perplexity is 166.1342112642991
At time: 818.6700837612152 and batch: 1200, loss is 5.082146787643433 and perplexity is 161.11957442998494
At time: 819.8079900741577 and batch: 1250, loss is 5.103779401779175 and perplexity is 164.64298489978475
At time: 820.9466876983643 and batch: 1300, loss is 5.089474983215332 and perplexity is 162.30462702711884
At time: 822.0855538845062 and batch: 1350, loss is 5.0837338924407955 and perplexity is 161.37549110908725
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.126782633463542 and perplexity of 168.47420187369218
Finished 25 epochs...
Completing Train Step...
At time: 825.4782869815826 and batch: 50, loss is 5.174446458816528 and perplexity is 176.69877715026948
At time: 826.6436474323273 and batch: 100, loss is 5.187522602081299 and perplexity is 179.02448820196616
At time: 827.7817234992981 and batch: 150, loss is 5.15996904373169 and perplexity is 174.15906420694216
At time: 828.9205281734467 and batch: 200, loss is 5.141844997406006 and perplexity is 171.0310292093709
At time: 830.058974981308 and batch: 250, loss is 5.165594530105591 and perplexity is 175.14155455155543
At time: 831.1980166435242 and batch: 300, loss is 5.169915313720703 and perplexity is 175.8999405417979
At time: 832.3368556499481 and batch: 350, loss is 5.176521854400635 and perplexity is 177.06587781987176
At time: 833.4757037162781 and batch: 400, loss is 5.2094583988189695 and perplexity is 182.9949210843719
At time: 834.6142320632935 and batch: 450, loss is 5.168974752426148 and perplexity is 175.734573647051
At time: 835.7531750202179 and batch: 500, loss is 5.201359090805053 and perplexity is 181.51877480466578
At time: 836.892326593399 and batch: 550, loss is 5.175062980651855 and perplexity is 176.80774939309006
At time: 838.0635421276093 and batch: 600, loss is 5.128780088424683 and perplexity is 168.81105781933925
At time: 839.2023651599884 and batch: 650, loss is 5.1561548709869385 and perplexity is 173.49605666741726
At time: 840.3410243988037 and batch: 700, loss is 5.182118940353393 and perplexity is 178.0597094433301
At time: 841.4796719551086 and batch: 750, loss is 5.165618524551392 and perplexity is 175.14575702651143
At time: 842.6184084415436 and batch: 800, loss is 5.144764671325683 and perplexity is 171.53111373143017
At time: 843.7574231624603 and batch: 850, loss is 5.122370882034302 and perplexity is 167.73257271742528
At time: 844.8978357315063 and batch: 900, loss is 5.160895214080811 and perplexity is 174.3204398873909
At time: 846.0373165607452 and batch: 950, loss is 5.131784238815308 and perplexity is 169.3189541411189
At time: 847.1763560771942 and batch: 1000, loss is 5.153256778717041 and perplexity is 172.99397697478108
At time: 848.3155827522278 and batch: 1050, loss is 5.118814554214477 and perplexity is 167.1371201426386
At time: 849.4548101425171 and batch: 1100, loss is 5.107276363372803 and perplexity is 165.21974295727557
At time: 850.5951609611511 and batch: 1150, loss is 5.111092500686645 and perplexity is 165.8514487547685
At time: 851.7338457107544 and batch: 1200, loss is 5.080682315826416 and perplexity is 160.88379204453145
At time: 852.8732635974884 and batch: 1250, loss is 5.102143182754516 and perplexity is 164.37381318760586
At time: 854.0118117332458 and batch: 1300, loss is 5.087772521972656 and perplexity is 162.02854476645496
At time: 855.1503026485443 and batch: 1350, loss is 5.081671743392945 and perplexity is 161.04305367932116
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.126702880859375 and perplexity of 168.4607661531318
Finished 26 epochs...
Completing Train Step...
At time: 858.5730423927307 and batch: 50, loss is 5.171645641326904 and perplexity is 176.20456854196013
At time: 859.7393922805786 and batch: 100, loss is 5.184624938964844 and perplexity is 178.50648640535928
At time: 860.8780686855316 and batch: 150, loss is 5.157377042770386 and perplexity is 173.70822828108516
At time: 862.0163781642914 and batch: 200, loss is 5.139322156906128 and perplexity is 170.60008902738574
At time: 863.154928445816 and batch: 250, loss is 5.162986059188842 and perplexity is 174.68529822457518
At time: 864.2931387424469 and batch: 300, loss is 5.167395534515381 and perplexity is 175.45726948029156
At time: 865.4312534332275 and batch: 350, loss is 5.174119310379028 and perplexity is 176.64097987607605
At time: 866.5699059963226 and batch: 400, loss is 5.207056970596313 and perplexity is 182.55599914697444
At time: 867.7362313270569 and batch: 450, loss is 5.166628351211548 and perplexity is 175.32271321387026
At time: 868.8738186359406 and batch: 500, loss is 5.199152841567993 and perplexity is 181.11874059608962
At time: 870.0122566223145 and batch: 550, loss is 5.172781238555908 and perplexity is 176.40477961979104
At time: 871.1504278182983 and batch: 600, loss is 5.12667423248291 and perplexity is 168.45594009481317
At time: 872.2887334823608 and batch: 650, loss is 5.153728008270264 and perplexity is 173.07551605956553
At time: 873.4272978305817 and batch: 700, loss is 5.180005121231079 and perplexity is 177.68372095042832
At time: 874.565770149231 and batch: 750, loss is 5.16339563369751 and perplexity is 174.75685952360854
At time: 875.7035686969757 and batch: 800, loss is 5.14271879196167 and perplexity is 171.18054050310806
At time: 876.8417336940765 and batch: 850, loss is 5.120236978530884 and perplexity is 167.3750292102118
At time: 877.9795804023743 and batch: 900, loss is 5.15870701789856 and perplexity is 173.93940960288543
At time: 879.1180965900421 and batch: 950, loss is 5.130018253326416 and perplexity is 169.02020319766976
At time: 880.2564315795898 and batch: 1000, loss is 5.1515208339691165 and perplexity is 172.69392949730002
At time: 881.3948504924774 and batch: 1050, loss is 5.116925601959228 and perplexity is 166.82170409931993
At time: 882.5326709747314 and batch: 1100, loss is 5.10512409210205 and perplexity is 164.8645276481211
At time: 883.6705420017242 and batch: 1150, loss is 5.109440879821777 and perplexity is 165.57775112611085
At time: 884.8085927963257 and batch: 1200, loss is 5.078987302780152 and perplexity is 160.6113229026938
At time: 885.9466099739075 and batch: 1250, loss is 5.100447969436646 and perplexity is 164.09540056145087
At time: 887.0849711894989 and batch: 1300, loss is 5.085726337432861 and perplexity is 161.69734342823537
At time: 888.2239038944244 and batch: 1350, loss is 5.0796220588684085 and perplexity is 160.71330428097545
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.126393229166666 and perplexity of 168.40861006726442
Finished 27 epochs...
Completing Train Step...
At time: 891.6484653949738 and batch: 50, loss is 5.168864297866821 and perplexity is 175.71516403412025
At time: 892.7879700660706 and batch: 100, loss is 5.181779928207398 and perplexity is 177.99935527009328
At time: 893.9288914203644 and batch: 150, loss is 5.154623174667359 and perplexity is 173.23051681108362
At time: 895.06960105896 and batch: 200, loss is 5.136556406021118 and perplexity is 170.12890357132773
At time: 896.2405731678009 and batch: 250, loss is 5.160708789825439 and perplexity is 174.28794535816718
At time: 897.3808915615082 and batch: 300, loss is 5.165059652328491 and perplexity is 175.04790027520747
At time: 898.5213801860809 and batch: 350, loss is 5.171715002059937 and perplexity is 176.21679064385995
At time: 899.6619415283203 and batch: 400, loss is 5.204631290435791 and perplexity is 182.11371332050126
At time: 900.8026719093323 and batch: 450, loss is 5.164081687927246 and perplexity is 174.87679334210776
At time: 901.9430661201477 and batch: 500, loss is 5.19688723564148 and perplexity is 180.70886139169465
At time: 903.0834257602692 and batch: 550, loss is 5.1707140159606935 and perplexity is 176.04048833877133
At time: 904.2235155105591 and batch: 600, loss is 5.1243854331970216 and perplexity is 168.07081915980564
At time: 905.3649940490723 and batch: 650, loss is 5.151668348312378 and perplexity is 172.71940620793896
At time: 906.5051622390747 and batch: 700, loss is 5.177656421661377 and perplexity is 177.26688497434694
At time: 907.6457059383392 and batch: 750, loss is 5.161052150726318 and perplexity is 174.34779929926123
At time: 908.7863454818726 and batch: 800, loss is 5.14084080696106 and perplexity is 170.85936768890414
At time: 909.9268088340759 and batch: 850, loss is 5.118010492324829 and perplexity is 167.00278556787976
At time: 911.0683133602142 and batch: 900, loss is 5.156390352249145 and perplexity is 173.5369165485086
At time: 912.2087519168854 and batch: 950, loss is 5.127982130050659 and perplexity is 168.67640735200334
At time: 913.3484973907471 and batch: 1000, loss is 5.149746417999268 and perplexity is 172.38777033808458
At time: 914.4887497425079 and batch: 1050, loss is 5.115118293762207 and perplexity is 166.52047815211472
At time: 915.6295964717865 and batch: 1100, loss is 5.1035398006439205 and perplexity is 164.6035409792839
At time: 916.7704284191132 and batch: 1150, loss is 5.107602052688598 and perplexity is 165.27356202598736
At time: 917.9106643199921 and batch: 1200, loss is 5.077706623077392 and perplexity is 160.40576289777758
At time: 919.0506749153137 and batch: 1250, loss is 5.098951711654663 and perplexity is 163.85005513714643
At time: 920.1912336349487 and batch: 1300, loss is 5.084256181716919 and perplexity is 161.45979781184954
At time: 921.3319399356842 and batch: 1350, loss is 5.077953872680664 and perplexity is 160.4454280624125
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.126194254557292 and perplexity of 168.37510436336365
Finished 28 epochs...
Completing Train Step...
At time: 924.7742483615875 and batch: 50, loss is 5.1661755466461186 and perplexity is 175.24334425957207
At time: 925.9137599468231 and batch: 100, loss is 5.1793648147583005 and perplexity is 177.56998533050913
At time: 927.0550351142883 and batch: 150, loss is 5.152120885848999 and perplexity is 172.79758591084178
At time: 928.1957659721375 and batch: 200, loss is 5.134355564117431 and perplexity is 169.75488847633477
At time: 929.3374996185303 and batch: 250, loss is 5.1581559753417965 and perplexity is 173.84358798921414
At time: 930.4787464141846 and batch: 300, loss is 5.16291748046875 and perplexity is 174.6733189411707
At time: 931.6192774772644 and batch: 350, loss is 5.169538993835449 and perplexity is 175.8337583499754
At time: 932.7606823444366 and batch: 400, loss is 5.202480535507203 and perplexity is 181.72245225816562
At time: 933.9011759757996 and batch: 450, loss is 5.161709508895874 and perplexity is 174.46244592729502
At time: 935.042496919632 and batch: 500, loss is 5.194596853256225 and perplexity is 180.29544262296432
At time: 936.1834988594055 and batch: 550, loss is 5.168688249588013 and perplexity is 175.6842324047415
At time: 937.3253393173218 and batch: 600, loss is 5.1223469257354735 and perplexity is 167.72855451392087
At time: 938.4663634300232 and batch: 650, loss is 5.149486150741577 and perplexity is 172.3429092840243
At time: 939.608136177063 and batch: 700, loss is 5.1756931591033934 and perplexity is 176.91920494157654
At time: 940.7488408088684 and batch: 750, loss is 5.158724308013916 and perplexity is 173.94241706134204
At time: 941.8903458118439 and batch: 800, loss is 5.1387270736694335 and perplexity is 170.49859797503393
At time: 943.0315353870392 and batch: 850, loss is 5.11555549621582 and perplexity is 166.59329723091963
At time: 944.173262834549 and batch: 900, loss is 5.154355411529541 and perplexity is 173.1841382738449
At time: 945.3148458003998 and batch: 950, loss is 5.126198844909668 and perplexity is 168.37587726619805
At time: 946.4553759098053 and batch: 1000, loss is 5.14770339012146 and perplexity is 172.0359368426889
At time: 947.5965759754181 and batch: 1050, loss is 5.113234443664551 and perplexity is 166.20707382915472
At time: 948.7379786968231 and batch: 1100, loss is 5.101274738311767 and perplexity is 164.23112563008567
At time: 949.8792893886566 and batch: 1150, loss is 5.105814065933227 and perplexity is 164.97831910993875
At time: 951.0211462974548 and batch: 1200, loss is 5.0762381172180175 and perplexity is 160.17037896872483
At time: 952.1621696949005 and batch: 1250, loss is 5.0971095085144045 and perplexity is 163.54848791037338
At time: 953.3027985095978 and batch: 1300, loss is 5.0828691101074215 and perplexity is 161.23599676015422
At time: 954.4435942173004 and batch: 1350, loss is 5.0760440921783445 and perplexity is 160.1393049192603
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.12609619140625 and perplexity of 168.35859377962606
Finished 29 epochs...
Completing Train Step...
At time: 957.8425989151001 and batch: 50, loss is 5.163766345977783 and perplexity is 174.82165604718736
At time: 959.0252408981323 and batch: 100, loss is 5.176765584945679 and perplexity is 177.10903944247076
At time: 960.1651277542114 and batch: 150, loss is 5.149838495254516 and perplexity is 172.40364406160901
At time: 961.3056640625 and batch: 200, loss is 5.131735000610352 and perplexity is 169.3106173849971
At time: 962.4458138942719 and batch: 250, loss is 5.156037130355835 and perplexity is 173.47563033473952
At time: 963.5864102840424 and batch: 300, loss is 5.16064787864685 and perplexity is 174.27732959731412
At time: 964.7273352146149 and batch: 350, loss is 5.167066059112549 and perplexity is 175.39947014800165
At time: 965.8678374290466 and batch: 400, loss is 5.199950485229492 and perplexity is 181.2632664439054
At time: 967.0080273151398 and batch: 450, loss is 5.159173622131347 and perplexity is 174.02058940560164
At time: 968.1488535404205 and batch: 500, loss is 5.192068243026734 and perplexity is 179.84012162968307
At time: 969.2889604568481 and batch: 550, loss is 5.166281528472901 and perplexity is 175.26191785354243
At time: 970.429890871048 and batch: 600, loss is 5.120010089874268 and perplexity is 167.33705802246197
At time: 971.5716321468353 and batch: 650, loss is 5.147045516967774 and perplexity is 171.92279623853437
At time: 972.7125771045685 and batch: 700, loss is 5.173633127212525 and perplexity is 176.5551208784365
At time: 973.8530025482178 and batch: 750, loss is 5.156493816375733 and perplexity is 173.55487232288317
At time: 974.9933512210846 and batch: 800, loss is 5.136380214691162 and perplexity is 170.09893097407695
At time: 976.1341519355774 and batch: 850, loss is 5.113662195205689 and perplexity is 166.2781843688704
At time: 977.2753190994263 and batch: 900, loss is 5.15243070602417 and perplexity is 172.8511303833284
At time: 978.4163162708282 and batch: 950, loss is 5.124170560836792 and perplexity is 168.03470926585499
At time: 979.5568675994873 and batch: 1000, loss is 5.146009178161621 and perplexity is 171.74471826362597
At time: 980.6974828243256 and batch: 1050, loss is 5.1113245487213135 and perplexity is 165.88993872308697
At time: 981.8376016616821 and batch: 1100, loss is 5.099487524032593 and perplexity is 163.9378715492728
At time: 983.0066397190094 and batch: 1150, loss is 5.104323129653931 and perplexity is 164.73253022199563
At time: 984.1470036506653 and batch: 1200, loss is 5.074308137893677 and perplexity is 159.86155156006075
At time: 985.2880325317383 and batch: 1250, loss is 5.095440855026245 and perplexity is 163.2758097215146
At time: 986.4289243221283 and batch: 1300, loss is 5.081158094406128 and perplexity is 160.96035531874767
At time: 987.5693597793579 and batch: 1350, loss is 5.073848552703858 and perplexity is 159.7880984388184
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.125983479817708 and perplexity of 168.33961888444176
Finished 30 epochs...
Completing Train Step...
At time: 990.9657080173492 and batch: 50, loss is 5.160921840667725 and perplexity is 174.32508150752943
At time: 992.133220911026 and batch: 100, loss is 5.174034957885742 and perplexity is 176.62608039741988
At time: 993.272696018219 and batch: 150, loss is 5.147462549209595 and perplexity is 171.99450853980147
At time: 994.4116926193237 and batch: 200, loss is 5.129427165985107 and perplexity is 168.92032701581556
At time: 995.5504333972931 and batch: 250, loss is 5.153380575180054 and perplexity is 173.015394342923
At time: 996.6892940998077 and batch: 300, loss is 5.157972450256348 and perplexity is 173.81168625734728
At time: 997.8276183605194 and batch: 350, loss is 5.164524574279785 and perplexity is 174.95426104068164
At time: 998.9670119285583 and batch: 400, loss is 5.197297811508179 and perplexity is 180.78307132244154
At time: 1000.107134103775 and batch: 450, loss is 5.156625871658325 and perplexity is 173.57779267393647
At time: 1001.2464129924774 and batch: 500, loss is 5.190092973709106 and perplexity is 179.48523956456344
At time: 1002.3855619430542 and batch: 550, loss is 5.164380912780762 and perplexity is 174.9291286546014
At time: 1003.5247185230255 and batch: 600, loss is 5.118072118759155 and perplexity is 167.01307767120642
At time: 1004.6632416248322 and batch: 650, loss is 5.145094118118286 and perplexity is 171.5876334162838
At time: 1005.8022954463959 and batch: 700, loss is 5.1716510200500485 and perplexity is 176.2055163000999
At time: 1006.9416389465332 and batch: 750, loss is 5.154285364151001 and perplexity is 173.17200760381985
At time: 1008.0807549953461 and batch: 800, loss is 5.13427918434143 and perplexity is 169.74192313112928
At time: 1009.2193465232849 and batch: 850, loss is 5.111475982666016 and perplexity is 165.91506199310416
At time: 1010.3578925132751 and batch: 900, loss is 5.150060653686523 and perplexity is 172.44194923959765
At time: 1011.5257637500763 and batch: 950, loss is 5.122179183959961 and perplexity is 167.70042178796524
At time: 1012.6646628379822 and batch: 1000, loss is 5.143941297531128 and perplexity is 171.38993763575732
At time: 1013.8040630817413 and batch: 1050, loss is 5.109336481094361 and perplexity is 165.56046592189713
At time: 1014.9432344436646 and batch: 1100, loss is 5.097330102920532 and perplexity is 163.58456977151909
At time: 1016.0818765163422 and batch: 1150, loss is 5.102325830459595 and perplexity is 164.40383842929685
At time: 1017.220813035965 and batch: 1200, loss is 5.072761039733887 and perplexity is 159.61442126452616
At time: 1018.3597331047058 and batch: 1250, loss is 5.093586902618409 and perplexity is 162.97338456848337
At time: 1019.4982450008392 and batch: 1300, loss is 5.0793751621246335 and perplexity is 160.67362958744502
At time: 1020.6371781826019 and batch: 1350, loss is 5.0718168354034425 and perplexity is 159.4637837642482
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.125957845052083 and perplexity of 168.33530359307724
Finished 31 epochs...
Completing Train Step...
At time: 1024.07834482193 and batch: 50, loss is 5.158258638381958 and perplexity is 173.86143621663066
At time: 1025.21297955513 and batch: 100, loss is 5.1715833187103275 and perplexity is 176.19358735438752
At time: 1026.351467370987 and batch: 150, loss is 5.145042810440064 and perplexity is 171.578829879048
At time: 1027.490345954895 and batch: 200, loss is 5.1270325660705565 and perplexity is 168.51631433260033
At time: 1028.6295189857483 and batch: 250, loss is 5.1512010955810545 and perplexity is 172.6387214451916
At time: 1029.7682497501373 and batch: 300, loss is 5.155815134048462 and perplexity is 173.43712365971393
At time: 1030.9077153205872 and batch: 350, loss is 5.162458400726319 and perplexity is 174.59314836265384
At time: 1032.0464932918549 and batch: 400, loss is 5.195128660202027 and perplexity is 180.39135049162252
At time: 1033.1850099563599 and batch: 450, loss is 5.154310712814331 and perplexity is 173.17639733837552
At time: 1034.3236076831818 and batch: 500, loss is 5.188041439056397 and perplexity is 179.11739682602385
At time: 1035.4625096321106 and batch: 550, loss is 5.162169170379639 and perplexity is 174.54265802784545
At time: 1036.60084939003 and batch: 600, loss is 5.11593258857727 and perplexity is 166.65613013693414
At time: 1037.7392046451569 and batch: 650, loss is 5.1429025840759275 and perplexity is 171.2120050279441
At time: 1038.8772659301758 and batch: 700, loss is 5.1696109962463375 and perplexity is 175.8464192602948
At time: 1040.0437564849854 and batch: 750, loss is 5.151777696609497 and perplexity is 172.7382938135322
At time: 1041.1820075511932 and batch: 800, loss is 5.132259330749512 and perplexity is 169.39941532225487
At time: 1042.3209669589996 and batch: 850, loss is 5.109459915161133 and perplexity is 165.58090298479152
At time: 1043.4599657058716 and batch: 900, loss is 5.148167810440063 and perplexity is 172.11585238305253
At time: 1044.5983846187592 and batch: 950, loss is 5.120408802032471 and perplexity is 167.40379064468334
At time: 1045.736739397049 and batch: 1000, loss is 5.142170238494873 and perplexity is 171.08666457450397
At time: 1046.8752286434174 and batch: 1050, loss is 5.107604818344116 and perplexity is 165.27401911635823
At time: 1048.0143418312073 and batch: 1100, loss is 5.095526685714722 and perplexity is 163.28982439811065
At time: 1049.1528873443604 and batch: 1150, loss is 5.100347700119019 and perplexity is 164.07894765248565
At time: 1050.291741847992 and batch: 1200, loss is 5.070978240966797 and perplexity is 159.33011437737264
At time: 1051.42982006073 and batch: 1250, loss is 5.092015819549561 and perplexity is 162.71754087179
At time: 1052.5685176849365 and batch: 1300, loss is 5.077523040771484 and perplexity is 160.37631794081307
At time: 1053.7068781852722 and batch: 1350, loss is 5.070281372070313 and perplexity is 159.21912085484834
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.125871988932292 and perplexity of 168.32085159749187
Finished 32 epochs...
Completing Train Step...
At time: 1057.119933128357 and batch: 50, loss is 5.155841836929321 and perplexity is 173.4417549923983
At time: 1058.252768278122 and batch: 100, loss is 5.169000577926636 and perplexity is 175.7391121389727
At time: 1059.3915798664093 and batch: 150, loss is 5.142608289718628 and perplexity is 171.16162571449985
At time: 1060.5305857658386 and batch: 200, loss is 5.124646320343017 and perplexity is 168.11467239626552
At time: 1061.6693952083588 and batch: 250, loss is 5.1490403175354 and perplexity is 172.26609021773407
At time: 1062.808431148529 and batch: 300, loss is 5.153596935272216 and perplexity is 173.05283201945207
At time: 1063.9472889900208 and batch: 350, loss is 5.16026104927063 and perplexity is 174.20992704410085
At time: 1065.0857746601105 and batch: 400, loss is 5.193033199310303 and perplexity is 180.01374324024738
At time: 1066.2242674827576 and batch: 450, loss is 5.151770210266113 and perplexity is 172.73700064018968
At time: 1067.362883090973 and batch: 500, loss is 5.185549840927124 and perplexity is 178.67166377957915
At time: 1068.5015783309937 and batch: 550, loss is 5.160085182189942 and perplexity is 174.17929194673633
At time: 1069.669236421585 and batch: 600, loss is 5.114011678695679 and perplexity is 166.33630600473737
At time: 1070.80819606781 and batch: 650, loss is 5.140951604843139 and perplexity is 170.87829959376566
At time: 1071.946341753006 and batch: 700, loss is 5.167356491088867 and perplexity is 175.45041916101508
At time: 1073.0852270126343 and batch: 750, loss is 5.14976580619812 and perplexity is 172.39111265885634
At time: 1074.2243876457214 and batch: 800, loss is 5.130110073089599 and perplexity is 169.03572330521604
At time: 1075.3633635044098 and batch: 850, loss is 5.107168989181519 and perplexity is 165.20200357338442
At time: 1076.5032846927643 and batch: 900, loss is 5.146014633178711 and perplexity is 171.74565513655463
At time: 1077.643103837967 and batch: 950, loss is 5.118390855789184 and perplexity is 167.06631940816516
At time: 1078.7813255786896 and batch: 1000, loss is 5.140159072875977 and perplexity is 170.74292672959015
At time: 1079.9200265407562 and batch: 1050, loss is 5.105619916915893 and perplexity is 164.9462918405342
At time: 1081.0587494373322 and batch: 1100, loss is 5.093733129501342 and perplexity is 162.9972174009679
At time: 1082.197069644928 and batch: 1150, loss is 5.098415851593018 and perplexity is 163.76227795674313
At time: 1083.3363120555878 and batch: 1200, loss is 5.069564094543457 and perplexity is 159.1049575059104
At time: 1084.4757022857666 and batch: 1250, loss is 5.090167112350464 and perplexity is 162.4170016726481
At time: 1085.6139905452728 and batch: 1300, loss is 5.075522356033325 and perplexity is 160.05577624750399
At time: 1086.7526314258575 and batch: 1350, loss is 5.068124437332154 and perplexity is 158.87606570887962
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.125633544921875 and perplexity of 168.28072128320693
Finished 33 epochs...
Completing Train Step...
At time: 1090.1605303287506 and batch: 50, loss is 5.153556451797486 and perplexity is 173.04582638130717
At time: 1091.3281691074371 and batch: 100, loss is 5.166319894790649 and perplexity is 175.2686421369642
At time: 1092.4664688110352 and batch: 150, loss is 5.139909572601319 and perplexity is 170.70033163643984
At time: 1093.6052911281586 and batch: 200, loss is 5.122176542282104 and perplexity is 167.69997877805955
At time: 1094.7440440654755 and batch: 250, loss is 5.146619958877563 and perplexity is 171.84964866707782
At time: 1095.8829426765442 and batch: 300, loss is 5.151266717910767 and perplexity is 172.65005077201576
At time: 1097.0216782093048 and batch: 350, loss is 5.158054132461547 and perplexity is 173.82588415902032
At time: 1098.189661026001 and batch: 400, loss is 5.190493135452271 and perplexity is 179.55707706325066
At time: 1099.3291699886322 and batch: 450, loss is 5.149471549987793 and perplexity is 172.34039296600957
At time: 1100.467789888382 and batch: 500, loss is 5.183584251403809 and perplexity is 178.32081355586297
At time: 1101.6062695980072 and batch: 550, loss is 5.158106870651245 and perplexity is 173.83505166321018
At time: 1102.7453536987305 and batch: 600, loss is 5.111822967529297 and perplexity is 165.97264199732334
At time: 1103.8844408988953 and batch: 650, loss is 5.139104881286621 and perplexity is 170.5630258139665
At time: 1105.023378610611 and batch: 700, loss is 5.165436916351318 and perplexity is 175.1139520089407
At time: 1106.1629922389984 and batch: 750, loss is 5.147724905014038 and perplexity is 172.03963821720677
At time: 1107.301604270935 and batch: 800, loss is 5.128047389984131 and perplexity is 168.68741552231765
At time: 1108.4400873184204 and batch: 850, loss is 5.104972333908081 and perplexity is 164.83951000351988
At time: 1109.5787363052368 and batch: 900, loss is 5.143873891830444 and perplexity is 171.3783853662697
At time: 1110.7175498008728 and batch: 950, loss is 5.116943454742431 and perplexity is 166.82468235762175
At time: 1111.8566081523895 and batch: 1000, loss is 5.1384718704223635 and perplexity is 170.45509173091335
At time: 1112.99551486969 and batch: 1050, loss is 5.104064044952392 and perplexity is 164.68985607191775
At time: 1114.1340544223785 and batch: 1100, loss is 5.09202579498291 and perplexity is 162.71916405786976
At time: 1115.2729229927063 and batch: 1150, loss is 5.096521949768066 and perplexity is 163.45242179085932
At time: 1116.4118263721466 and batch: 1200, loss is 5.06778772354126 and perplexity is 158.82257895188218
At time: 1117.550411939621 and batch: 1250, loss is 5.088232364654541 and perplexity is 162.10306954054496
At time: 1118.6890425682068 and batch: 1300, loss is 5.0738567543029784 and perplexity is 159.78940896212023
At time: 1119.8288223743439 and batch: 1350, loss is 5.066012058258057 and perplexity is 158.54081344689473
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.125550537109375 and perplexity of 168.2667532483833
Finished 34 epochs...
Completing Train Step...
At time: 1123.2209470272064 and batch: 50, loss is 5.151002321243286 and perplexity is 172.60440870802196
At time: 1124.382774591446 and batch: 100, loss is 5.1640855884552 and perplexity is 174.877475455259
At time: 1125.5238127708435 and batch: 150, loss is 5.1377996063232425 and perplexity is 170.34053940125384
At time: 1126.6934113502502 and batch: 200, loss is 5.119882946014404 and perplexity is 167.31578349549818
At time: 1127.8339354991913 and batch: 250, loss is 5.144545440673828 and perplexity is 171.49351297532309
At time: 1128.9743893146515 and batch: 300, loss is 5.149404602050781 and perplexity is 172.32885551844515
At time: 1130.114854812622 and batch: 350, loss is 5.15614686012268 and perplexity is 173.4946668196249
At time: 1131.2561902999878 and batch: 400, loss is 5.188592720031738 and perplexity is 179.21616806209693
At time: 1132.3972322940826 and batch: 450, loss is 5.147191133499145 and perplexity is 171.9478328626153
At time: 1133.5389564037323 and batch: 500, loss is 5.181750497817993 and perplexity is 177.99411675684001
At time: 1134.6799154281616 and batch: 550, loss is 5.156075382232666 and perplexity is 173.48226623010123
At time: 1135.8205261230469 and batch: 600, loss is 5.110036735534668 and perplexity is 165.676440974582
At time: 1136.9619557857513 and batch: 650, loss is 5.137288045883179 and perplexity is 170.2534222047126
At time: 1138.1028645038605 and batch: 700, loss is 5.163373403549194 and perplexity is 174.75297469588241
At time: 1139.2443187236786 and batch: 750, loss is 5.14559796333313 and perplexity is 171.67410880758368
At time: 1140.3859486579895 and batch: 800, loss is 5.1260318946838375 and perplexity is 168.3477692218515
At time: 1141.5271320343018 and batch: 850, loss is 5.103023462295532 and perplexity is 164.5185717971071
At time: 1142.6679260730743 and batch: 900, loss is 5.141929388046265 and perplexity is 171.04546323646986
At time: 1143.8087701797485 and batch: 950, loss is 5.114967622756958 and perplexity is 166.49539023433533
At time: 1144.950114250183 and batch: 1000, loss is 5.136465425491333 and perplexity is 170.1134258576451
At time: 1146.091359615326 and batch: 1050, loss is 5.102306890487671 and perplexity is 164.40072465470027
At time: 1147.2329452037811 and batch: 1100, loss is 5.090315542221069 and perplexity is 162.44111099641808
At time: 1148.3741161823273 and batch: 1150, loss is 5.094842748641968 and perplexity is 163.17818261593
At time: 1149.5150904655457 and batch: 1200, loss is 5.066106357574463 and perplexity is 158.5557644421485
At time: 1150.6555688381195 and batch: 1250, loss is 5.086608934402466 and perplexity is 161.84012001135966
At time: 1151.7976484298706 and batch: 1300, loss is 5.072496309280395 and perplexity is 159.57217205897336
At time: 1152.9389243125916 and batch: 1350, loss is 5.064149188995361 and perplexity is 158.24574755855883
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1253959147135415 and perplexity of 168.24073745122115
Finished 35 epochs...
Completing Train Step...
At time: 1156.3859844207764 and batch: 50, loss is 5.148806571960449 and perplexity is 172.2258284871156
At time: 1157.5198061466217 and batch: 100, loss is 5.161796169281006 and perplexity is 174.47756556517749
At time: 1158.6615648269653 and batch: 150, loss is 5.135669269561768 and perplexity is 169.97804294505534
At time: 1159.8032944202423 and batch: 200, loss is 5.1175263977050784 and perplexity is 166.92195998309683
At time: 1160.9445481300354 and batch: 250, loss is 5.142202291488648 and perplexity is 171.0921485021862
At time: 1162.086306810379 and batch: 300, loss is 5.147248315811157 and perplexity is 171.9576655183681
At time: 1163.227868795395 and batch: 350, loss is 5.154073247909546 and perplexity is 173.1352789039563
At time: 1164.369990825653 and batch: 400, loss is 5.18692626953125 and perplexity is 178.91776189774288
At time: 1165.5121064186096 and batch: 450, loss is 5.145170135498047 and perplexity is 171.60067755435978
At time: 1166.6538927555084 and batch: 500, loss is 5.180031309127807 and perplexity is 177.68837417429174
At time: 1167.7958583831787 and batch: 550, loss is 5.154179124832154 and perplexity is 173.15361090493232
At time: 1168.9379951953888 and batch: 600, loss is 5.10818886756897 and perplexity is 165.37057547319952
At time: 1170.0796473026276 and batch: 650, loss is 5.135257730484009 and perplexity is 169.90810473016376
At time: 1171.2210516929626 and batch: 700, loss is 5.161853628158569 and perplexity is 174.4875911382812
At time: 1172.3630077838898 and batch: 750, loss is 5.143506889343262 and perplexity is 171.31550061272725
At time: 1173.5045466423035 and batch: 800, loss is 5.123945856094361 and perplexity is 167.9969553116951
At time: 1174.646470785141 and batch: 850, loss is 5.101080989837646 and perplexity is 164.19930918238526
At time: 1175.7888157367706 and batch: 900, loss is 5.140044069290161 and perplexity is 170.72329180982823
At time: 1176.9302380084991 and batch: 950, loss is 5.1129762554168705 and perplexity is 166.1641666553131
At time: 1178.0717051029205 and batch: 1000, loss is 5.134769134521484 and perplexity is 169.82510859363214
At time: 1179.213543176651 and batch: 1050, loss is 5.100445775985718 and perplexity is 164.09504062663706
At time: 1180.3548917770386 and batch: 1100, loss is 5.088423976898193 and perplexity is 162.13413344942015
At time: 1181.4970197677612 and batch: 1150, loss is 5.093148918151855 and perplexity is 162.90202038692306
At time: 1182.6395180225372 and batch: 1200, loss is 5.0642963218688966 and perplexity is 158.26903242306437
At time: 1183.7808637619019 and batch: 1250, loss is 5.084891242980957 and perplexity is 161.56236724062765
At time: 1184.9223217964172 and batch: 1300, loss is 5.070628433227539 and perplexity is 159.27438921738099
At time: 1186.0628292560577 and batch: 1350, loss is 5.062268629074096 and perplexity is 157.9484365911545
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.125475260416667 and perplexity of 168.25408716044254
Annealing...
Finished 36 epochs...
Completing Train Step...
At time: 1189.4847807884216 and batch: 50, loss is 5.148522424697876 and perplexity is 172.17689794147606
At time: 1190.6175100803375 and batch: 100, loss is 5.16293514251709 and perplexity is 174.6764040570181
At time: 1191.7582349777222 and batch: 150, loss is 5.137291965484619 and perplexity is 170.25408953157924
At time: 1192.8988852500916 and batch: 200, loss is 5.119917974472046 and perplexity is 167.32164441198202
At time: 1194.0393385887146 and batch: 250, loss is 5.143723573684692 and perplexity is 171.35262602125647
At time: 1195.1795995235443 and batch: 300, loss is 5.1493392658233645 and perplexity is 172.31759656896318
At time: 1196.320763349533 and batch: 350, loss is 5.155124454498291 and perplexity is 173.3173755437096
At time: 1197.4623115062714 and batch: 400, loss is 5.186314067840576 and perplexity is 178.80826166295185
At time: 1198.6028118133545 and batch: 450, loss is 5.142689142227173 and perplexity is 171.17546512077337
At time: 1199.7436392307281 and batch: 500, loss is 5.175650310516358 and perplexity is 176.9116243660349
At time: 1200.8839721679688 and batch: 550, loss is 5.146209688186645 and perplexity is 171.77915825404912
At time: 1202.0249545574188 and batch: 600, loss is 5.101828212738037 and perplexity is 164.32204851754486
At time: 1203.1658380031586 and batch: 650, loss is 5.129303531646729 and perplexity is 168.89944395390464
At time: 1204.3074352741241 and batch: 700, loss is 5.1526658153533935 and perplexity is 172.8917740743167
At time: 1205.4475071430206 and batch: 750, loss is 5.1334004402160645 and perplexity is 169.59282893076994
At time: 1206.588203907013 and batch: 800, loss is 5.114139614105224 and perplexity is 166.35758766947856
At time: 1207.7289853096008 and batch: 850, loss is 5.086553640365601 and perplexity is 161.83117146520047
At time: 1208.869907617569 and batch: 900, loss is 5.1192262172698975 and perplexity is 167.20593848420313
At time: 1210.0110998153687 and batch: 950, loss is 5.092296371459961 and perplexity is 162.763197993034
At time: 1211.1536922454834 and batch: 1000, loss is 5.114300708770752 and perplexity is 166.3843891481519
At time: 1212.2945003509521 and batch: 1050, loss is 5.078143806457519 and perplexity is 160.4759049627484
At time: 1213.4804332256317 and batch: 1100, loss is 5.063570604324341 and perplexity is 158.15421547685048
At time: 1214.620934009552 and batch: 1150, loss is 5.066488761901855 and perplexity is 158.61640844713008
At time: 1215.761992931366 and batch: 1200, loss is 5.034857711791992 and perplexity is 153.6777245280604
At time: 1216.9022796154022 and batch: 1250, loss is 5.055419368743896 and perplexity is 156.87030305364124
At time: 1218.0431797504425 and batch: 1300, loss is 5.044769020080566 and perplexity is 155.20844502359532
At time: 1219.184213399887 and batch: 1350, loss is 5.041507501602172 and perplexity is 154.70305443053488
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.11713623046875 and perplexity of 166.85684520693988
Finished 37 epochs...
Completing Train Step...
At time: 1222.5875618457794 and batch: 50, loss is 5.144135599136352 and perplexity is 171.4232422112208
At time: 1223.7561264038086 and batch: 100, loss is 5.158433084487915 and perplexity is 173.89176831273582
At time: 1224.8954491615295 and batch: 150, loss is 5.132368745803833 and perplexity is 169.41795118251702
At time: 1226.0351309776306 and batch: 200, loss is 5.1151767921447755 and perplexity is 166.53021961567828
At time: 1227.1735906600952 and batch: 250, loss is 5.138934812545776 and perplexity is 170.53402084142115
At time: 1228.3121964931488 and batch: 300, loss is 5.144307384490967 and perplexity is 171.45269274318576
At time: 1229.4508068561554 and batch: 350, loss is 5.150508871078491 and perplexity is 172.5192580446329
At time: 1230.5898361206055 and batch: 400, loss is 5.182162017822265 and perplexity is 178.06737997013323
At time: 1231.729380607605 and batch: 450, loss is 5.138680715560913 and perplexity is 170.49069416573062
At time: 1232.868928194046 and batch: 500, loss is 5.171850757598877 and perplexity is 176.2407146731171
At time: 1234.0074121952057 and batch: 550, loss is 5.143228454589844 and perplexity is 171.26780706363638
At time: 1235.1463494300842 and batch: 600, loss is 5.09885645866394 and perplexity is 163.83444867265757
At time: 1236.285138130188 and batch: 650, loss is 5.126475191116333 and perplexity is 168.42241373096599
At time: 1237.4244668483734 and batch: 700, loss is 5.150172967910766 and perplexity is 172.4613180110273
At time: 1238.5636594295502 and batch: 750, loss is 5.131346502304077 and perplexity is 169.24485327235908
At time: 1239.703689813614 and batch: 800, loss is 5.11227499961853 and perplexity is 166.04768391684104
At time: 1240.8427319526672 and batch: 850, loss is 5.085156669616699 and perplexity is 161.6052558878698
At time: 1242.0101058483124 and batch: 900, loss is 5.118343553543091 and perplexity is 167.05841698291331
At time: 1243.148737668991 and batch: 950, loss is 5.0913019943237305 and perplexity is 162.6014304326412
At time: 1244.2871675491333 and batch: 1000, loss is 5.113945646286011 and perplexity is 166.32532278026494
At time: 1245.4266786575317 and batch: 1050, loss is 5.078096399307251 and perplexity is 160.46829743773432
At time: 1246.5658569335938 and batch: 1100, loss is 5.064281015396118 and perplexity is 158.26660990096815
At time: 1247.704859495163 and batch: 1150, loss is 5.067663536071778 and perplexity is 158.8028564023776
At time: 1248.8433809280396 and batch: 1200, loss is 5.036861228942871 and perplexity is 153.9859291283652
At time: 1249.9823582172394 and batch: 1250, loss is 5.0574735832214355 and perplexity is 157.19287950844785
At time: 1251.121431350708 and batch: 1300, loss is 5.046741905212403 and perplexity is 155.51495571289
At time: 1252.2606313228607 and batch: 1350, loss is 5.042601528167725 and perplexity is 154.87239629721407
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.11598388671875 and perplexity of 166.66467950595782
Finished 38 epochs...
Completing Train Step...
At time: 1255.6517996788025 and batch: 50, loss is 5.142328186035156 and perplexity is 171.11368942654707
At time: 1256.81774020195 and batch: 100, loss is 5.156236448287964 and perplexity is 173.51021058477008
At time: 1257.957827091217 and batch: 150, loss is 5.129778356552124 and perplexity is 168.979660659339
At time: 1259.0966575145721 and batch: 200, loss is 5.112687139511109 and perplexity is 166.11613289576192
At time: 1260.2357246875763 and batch: 250, loss is 5.136492404937744 and perplexity is 170.11801548561436
At time: 1261.3749165534973 and batch: 300, loss is 5.141711959838867 and perplexity is 171.00827717081114
At time: 1262.5131134986877 and batch: 350, loss is 5.148023862838745 and perplexity is 172.0910785020662
At time: 1263.6519870758057 and batch: 400, loss is 5.179735202789306 and perplexity is 177.63576730941818
At time: 1264.790833234787 and batch: 450, loss is 5.13641248703003 and perplexity is 170.1044205529987
At time: 1265.9297108650208 and batch: 500, loss is 5.169615125656128 and perplexity is 175.8471454037193
At time: 1267.0682787895203 and batch: 550, loss is 5.141473417282104 and perplexity is 170.96748928416406
At time: 1268.2077703475952 and batch: 600, loss is 5.097096176147461 and perplexity is 163.54630743645495
At time: 1269.3461935520172 and batch: 650, loss is 5.124828901290893 and perplexity is 168.14536973479284
At time: 1270.4847645759583 and batch: 700, loss is 5.14875114440918 and perplexity is 172.21628269572955
At time: 1271.6680567264557 and batch: 750, loss is 5.130281639099121 and perplexity is 169.06472657764687
At time: 1272.8065690994263 and batch: 800, loss is 5.111527147293091 and perplexity is 165.92355119254876
At time: 1273.9457585811615 and batch: 850, loss is 5.08453818321228 and perplexity is 161.50533613690936
At time: 1275.084688425064 and batch: 900, loss is 5.118043222427368 and perplexity is 167.0082516756284
At time: 1276.2226359844208 and batch: 950, loss is 5.090951271057129 and perplexity is 162.54441232717838
At time: 1277.3612294197083 and batch: 1000, loss is 5.113936109542847 and perplexity is 166.3237365859435
At time: 1278.5001635551453 and batch: 1050, loss is 5.078373050689697 and perplexity is 160.51269735542536
At time: 1279.6391594409943 and batch: 1100, loss is 5.0649354362487795 and perplexity is 158.37021676831696
At time: 1280.7778296470642 and batch: 1150, loss is 5.068525905609131 and perplexity is 158.93986221451243
At time: 1281.916578054428 and batch: 1200, loss is 5.038318853378296 and perplexity is 154.2105464454496
At time: 1283.055325269699 and batch: 1250, loss is 5.058746709823608 and perplexity is 157.393133392247
At time: 1284.1936655044556 and batch: 1300, loss is 5.047820634841919 and perplexity is 155.68280481907593
At time: 1285.3342127799988 and batch: 1350, loss is 5.043035173416138 and perplexity is 154.9395705398216
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.115380452473958 and perplexity of 166.56413866888954
Finished 39 epochs...
Completing Train Step...
At time: 1288.7543573379517 and batch: 50, loss is 5.1408772373199465 and perplexity is 170.8655922703694
At time: 1289.8872299194336 and batch: 100, loss is 5.15470106124878 and perplexity is 173.24400966928528
At time: 1291.0254843235016 and batch: 150, loss is 5.1279531955719 and perplexity is 168.67152685868518
At time: 1292.1636459827423 and batch: 200, loss is 5.111035842895507 and perplexity is 165.84205224422033
At time: 1293.3013715744019 and batch: 250, loss is 5.134843349456787 and perplexity is 169.83771262077698
At time: 1294.4400560855865 and batch: 300, loss is 5.139898471832275 and perplexity is 170.6984367420001
At time: 1295.578712940216 and batch: 350, loss is 5.146365976333618 and perplexity is 171.806007398428
At time: 1296.7168490886688 and batch: 400, loss is 5.178112802505493 and perplexity is 177.34780464863545
At time: 1297.8547613620758 and batch: 450, loss is 5.134875822067261 and perplexity is 169.843227784208
At time: 1298.9924879074097 and batch: 500, loss is 5.16813027381897 and perplexity is 175.58623220346814
At time: 1300.1583609580994 and batch: 550, loss is 5.140302982330322 and perplexity is 170.76750001913103
At time: 1301.2968645095825 and batch: 600, loss is 5.0960329723358155 and perplexity is 163.3725167828218
At time: 1302.4353294372559 and batch: 650, loss is 5.123765497207642 and perplexity is 167.9666583001127
At time: 1303.5736346244812 and batch: 700, loss is 5.1478938865661625 and perplexity is 172.0687121987137
At time: 1304.7117671966553 and batch: 750, loss is 5.129673728942871 and perplexity is 168.96198164630442
At time: 1305.8497173786163 and batch: 800, loss is 5.111180839538574 and perplexity is 165.86610052849312
At time: 1306.9882986545563 and batch: 850, loss is 5.084253559112549 and perplexity is 161.45937436723347
At time: 1308.1265888214111 and batch: 900, loss is 5.117964401245117 and perplexity is 166.99508840656463
At time: 1309.2653534412384 and batch: 950, loss is 5.090785493850708 and perplexity is 162.51746840198948
At time: 1310.4038212299347 and batch: 1000, loss is 5.114025497436524 and perplexity is 166.33860457892482
At time: 1311.5423452854156 and batch: 1050, loss is 5.078686628341675 and perplexity is 160.5630384426822
At time: 1312.6811184883118 and batch: 1100, loss is 5.065551967620849 and perplexity is 158.46788708066816
At time: 1313.8191437721252 and batch: 1150, loss is 5.069255800247192 and perplexity is 159.05591391532187
At time: 1314.9579231739044 and batch: 1200, loss is 5.039336185455323 and perplexity is 154.36750960925744
At time: 1316.0965428352356 and batch: 1250, loss is 5.059614763259888 and perplexity is 157.52981835887962
At time: 1317.235371351242 and batch: 1300, loss is 5.048522863388062 and perplexity is 155.79216812328633
At time: 1318.3731911182404 and batch: 1350, loss is 5.043144588470459 and perplexity is 154.95652418882395
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.114969482421875 and perplexity of 166.49569986025932
Finished 40 epochs...
Completing Train Step...
At time: 1321.8085842132568 and batch: 50, loss is 5.139686393737793 and perplexity is 170.66223918129526
At time: 1322.9441721439362 and batch: 100, loss is 5.153428030014038 and perplexity is 173.02360495455332
At time: 1324.0831718444824 and batch: 150, loss is 5.126596193313599 and perplexity is 168.44279444612715
At time: 1325.2207782268524 and batch: 200, loss is 5.1096689414978025 and perplexity is 165.6155173718981
At time: 1326.3585901260376 and batch: 250, loss is 5.133548336029053 and perplexity is 169.6179128549396
At time: 1327.4964652061462 and batch: 300, loss is 5.138493661880493 and perplexity is 170.45880623637987
At time: 1328.6621582508087 and batch: 350, loss is 5.145098237991333 and perplexity is 171.58834033700614
At time: 1329.8002309799194 and batch: 400, loss is 5.176883888244629 and perplexity is 177.1299932655394
At time: 1330.9399201869965 and batch: 450, loss is 5.133722591400146 and perplexity is 169.64747226265624
At time: 1332.0780067443848 and batch: 500, loss is 5.167049789428711 and perplexity is 175.3966164772913
At time: 1333.2161977291107 and batch: 550, loss is 5.139435329437256 and perplexity is 170.61939736383766
At time: 1334.3547382354736 and batch: 600, loss is 5.095244207382202 and perplexity is 163.24370507495865
At time: 1335.4926936626434 and batch: 650, loss is 5.122945737838745 and perplexity is 167.82902248014304
At time: 1336.6311581134796 and batch: 700, loss is 5.147178325653076 and perplexity is 171.94563059534326
At time: 1337.7698781490326 and batch: 750, loss is 5.129203643798828 and perplexity is 168.88257379451247
At time: 1338.908302783966 and batch: 800, loss is 5.110849275588989 and perplexity is 165.81111442530815
At time: 1340.0465259552002 and batch: 850, loss is 5.084050073623657 and perplexity is 161.4265230699987
At time: 1341.1848366260529 and batch: 900, loss is 5.117900781631469 and perplexity is 166.9844645815046
At time: 1342.322630405426 and batch: 950, loss is 5.090639266967774 and perplexity is 162.49370571657667
At time: 1343.4618875980377 and batch: 1000, loss is 5.114102249145508 and perplexity is 166.35137184104457
At time: 1344.6005728244781 and batch: 1050, loss is 5.078917064666748 and perplexity is 160.6000422625519
At time: 1345.739153623581 and batch: 1100, loss is 5.066023616790772 and perplexity is 158.54264595666416
At time: 1346.8771078586578 and batch: 1150, loss is 5.069788770675659 and perplexity is 159.1407086084363
At time: 1348.0155124664307 and batch: 1200, loss is 5.040062913894653 and perplexity is 154.47973364185802
At time: 1349.1529068946838 and batch: 1250, loss is 5.060258111953735 and perplexity is 157.63119756935743
At time: 1350.2912318706512 and batch: 1300, loss is 5.048863430023193 and perplexity is 155.84523477361623
At time: 1351.429808139801 and batch: 1350, loss is 5.043204956054687 and perplexity is 154.96587882220513
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.11477294921875 and perplexity of 166.46298114232175
Finished 41 epochs...
Completing Train Step...
At time: 1354.8199837207794 and batch: 50, loss is 5.13879135131836 and perplexity is 170.5095575762819
At time: 1355.9864127635956 and batch: 100, loss is 5.152366609573364 and perplexity is 172.84005159441242
At time: 1357.1270253658295 and batch: 150, loss is 5.125443563461304 and perplexity is 168.24875410267353
At time: 1358.295386314392 and batch: 200, loss is 5.1085365295410154 and perplexity is 165.42807852882052
At time: 1359.4359233379364 and batch: 250, loss is 5.132454700469971 and perplexity is 169.43251407181378
At time: 1360.5763487815857 and batch: 300, loss is 5.137321434020996 and perplexity is 170.2591067443346
At time: 1361.7163715362549 and batch: 350, loss is 5.144017267227173 and perplexity is 171.40295857181673
At time: 1362.856934785843 and batch: 400, loss is 5.175794363021851 and perplexity is 176.93711076442136
At time: 1363.9972534179688 and batch: 450, loss is 5.132633619308471 and perplexity is 169.4628314525301
At time: 1365.1380999088287 and batch: 500, loss is 5.16590500831604 and perplexity is 175.19594063039713
At time: 1366.2787177562714 and batch: 550, loss is 5.138564224243164 and perplexity is 170.47083463685718
At time: 1367.4192554950714 and batch: 600, loss is 5.0945290851593015 and perplexity is 163.12700760516117
At time: 1368.5595800876617 and batch: 650, loss is 5.122211885452271 and perplexity is 167.705905931688
At time: 1369.6996085643768 and batch: 700, loss is 5.146625108718872 and perplexity is 171.85053366777623
At time: 1370.8404314517975 and batch: 750, loss is 5.128829860687256 and perplexity is 168.81946013673382
At time: 1371.980800151825 and batch: 800, loss is 5.110644960403443 and perplexity is 165.77724015733023
At time: 1373.1213476657867 and batch: 850, loss is 5.083915929794312 and perplexity is 161.4048701503715
At time: 1374.261257648468 and batch: 900, loss is 5.117766447067261 and perplexity is 166.96203430284004
At time: 1375.4012548923492 and batch: 950, loss is 5.090458517074585 and perplexity is 162.46433765084188
At time: 1376.5417621135712 and batch: 1000, loss is 5.114105825424194 and perplexity is 166.35196676097397
At time: 1377.682673215866 and batch: 1050, loss is 5.079019508361816 and perplexity is 160.61649556706365
At time: 1378.8234586715698 and batch: 1100, loss is 5.066319589614868 and perplexity is 158.58957721617378
At time: 1379.9641733169556 and batch: 1150, loss is 5.070139789581299 and perplexity is 159.19657981116535
At time: 1381.1047489643097 and batch: 1200, loss is 5.040640163421631 and perplexity is 154.56893273762145
At time: 1382.2447638511658 and batch: 1250, loss is 5.060750827789307 and perplexity is 157.70888409369869
At time: 1383.3843793869019 and batch: 1300, loss is 5.04923457145691 and perplexity is 155.90308613234205
At time: 1384.5254304409027 and batch: 1350, loss is 5.0432296562194825 and perplexity is 154.96970655222225
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.114591064453125 and perplexity of 166.4327068153144
Finished 42 epochs...
Completing Train Step...
At time: 1387.9327597618103 and batch: 50, loss is 5.13796326637268 and perplexity is 170.3684196237306
At time: 1389.0977494716644 and batch: 100, loss is 5.151543083190918 and perplexity is 172.69777184558572
At time: 1390.2390282154083 and batch: 150, loss is 5.124368515014648 and perplexity is 168.06797573108838
At time: 1391.3802411556244 and batch: 200, loss is 5.107602767944336 and perplexity is 165.27368023889312
At time: 1392.520754814148 and batch: 250, loss is 5.131481895446777 and perplexity is 169.2677694162388
At time: 1393.6615550518036 and batch: 300, loss is 5.136315288543702 and perplexity is 170.08788746431188
At time: 1394.8026690483093 and batch: 350, loss is 5.143112421035767 and perplexity is 171.24793540419574
At time: 1395.9434983730316 and batch: 400, loss is 5.174942235946656 and perplexity is 176.78640208232588
At time: 1397.0845289230347 and batch: 450, loss is 5.131672382354736 and perplexity is 169.3000157814097
At time: 1398.2245695590973 and batch: 500, loss is 5.16517557144165 and perplexity is 175.06819284869354
At time: 1399.3652753829956 and batch: 550, loss is 5.1378336524963375 and perplexity is 170.34633894346894
At time: 1400.5064554214478 and batch: 600, loss is 5.093998670578003 and perplexity is 163.040505604713
At time: 1401.647409915924 and batch: 650, loss is 5.1216306972503665 and perplexity is 167.60846555611198
At time: 1402.7883772850037 and batch: 700, loss is 5.146153383255005 and perplexity is 171.76948651257226
At time: 1403.9298784732819 and batch: 750, loss is 5.128484506607055 and perplexity is 168.7611677137007
At time: 1405.070526599884 and batch: 800, loss is 5.110493049621582 and perplexity is 165.75205871987762
At time: 1406.2117204666138 and batch: 850, loss is 5.083791332244873 and perplexity is 161.38476075190016
At time: 1407.3531913757324 and batch: 900, loss is 5.117645473480224 and perplexity is 166.94183752831424
At time: 1408.4950160980225 and batch: 950, loss is 5.090254306793213 and perplexity is 162.43116415003755
At time: 1409.6357624530792 and batch: 1000, loss is 5.114087190628052 and perplexity is 166.3488668548686
At time: 1410.7765452861786 and batch: 1050, loss is 5.0790811252594 and perplexity is 160.62639256212915
At time: 1411.9175720214844 and batch: 1100, loss is 5.0665386772155765 and perplexity is 158.62432603252185
At time: 1413.0590851306915 and batch: 1150, loss is 5.070411252975464 and perplexity is 159.23980172137806
At time: 1414.2003734111786 and batch: 1200, loss is 5.0411140251159665 and perplexity is 154.6421943905548
At time: 1415.3712358474731 and batch: 1250, loss is 5.061137161254883 and perplexity is 157.7698240842636
At time: 1416.5120248794556 and batch: 1300, loss is 5.049473466873169 and perplexity is 155.94033511412817
At time: 1417.6525330543518 and batch: 1350, loss is 5.0432126998901365 and perplexity is 154.9670788571174
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1144417317708335 and perplexity of 166.40785482843768
Finished 43 epochs...
Completing Train Step...
At time: 1421.0776898860931 and batch: 50, loss is 5.137270565032959 and perplexity is 170.25044605615253
At time: 1422.217322587967 and batch: 100, loss is 5.150720453262329 and perplexity is 172.5557639078629
At time: 1423.357854604721 and batch: 150, loss is 5.123417139053345 and perplexity is 167.9081559355233
At time: 1424.4983925819397 and batch: 200, loss is 5.106777620315552 and perplexity is 165.13736130290164
At time: 1425.638772726059 and batch: 250, loss is 5.130610313415527 and perplexity is 169.1203029438449
At time: 1426.7789690494537 and batch: 300, loss is 5.135433750152588 and perplexity is 169.9380145307267
At time: 1427.9197158813477 and batch: 350, loss is 5.142399139404297 and perplexity is 171.1258309500539
At time: 1429.0608186721802 and batch: 400, loss is 5.174176836013794 and perplexity is 176.65114155284473
At time: 1430.2019891738892 and batch: 450, loss is 5.130967979431152 and perplexity is 169.1808023474055
At time: 1431.3426377773285 and batch: 500, loss is 5.164479160308838 and perplexity is 174.9463158533664
At time: 1432.4826309680939 and batch: 550, loss is 5.137267255783081 and perplexity is 170.24988265581695
At time: 1433.6231365203857 and batch: 600, loss is 5.0935522651672365 and perplexity is 162.9677396835958
At time: 1434.7637691497803 and batch: 650, loss is 5.121049585342408 and perplexity is 167.51109457536091
At time: 1435.9043757915497 and batch: 700, loss is 5.14581823348999 and perplexity is 171.7119276554884
At time: 1437.0457215309143 and batch: 750, loss is 5.128234539031983 and perplexity is 168.71898816582015
At time: 1438.1858777999878 and batch: 800, loss is 5.1103732299804685 and perplexity is 165.73219955747055
At time: 1439.3261880874634 and batch: 850, loss is 5.083663520812988 and perplexity is 161.3641352526594
At time: 1440.4662079811096 and batch: 900, loss is 5.117608823776245 and perplexity is 166.93571927150393
At time: 1441.6063673496246 and batch: 950, loss is 5.090021657943725 and perplexity is 162.3933791220692
At time: 1442.7468886375427 and batch: 1000, loss is 5.114083518981934 and perplexity is 166.34825608181868
At time: 1443.8877909183502 and batch: 1050, loss is 5.079010171890259 and perplexity is 160.61499598272152
At time: 1445.0731182098389 and batch: 1100, loss is 5.0667621040344235 and perplexity is 158.6597709206009
At time: 1446.2132387161255 and batch: 1150, loss is 5.0706191253662105 and perplexity is 159.27290672035235
At time: 1447.3538014888763 and batch: 1200, loss is 5.041561765670776 and perplexity is 154.7114494754663
At time: 1448.4944350719452 and batch: 1250, loss is 5.061469984054566 and perplexity is 157.82234221795215
At time: 1449.6351737976074 and batch: 1300, loss is 5.049621782302856 and perplexity is 155.96346518716715
At time: 1450.7771654129028 and batch: 1350, loss is 5.043130683898926 and perplexity is 154.95436959972818
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1142586263020835 and perplexity of 166.3773874296344
Finished 44 epochs...
Completing Train Step...
At time: 1454.2027258872986 and batch: 50, loss is 5.136604042053222 and perplexity is 170.13700803027078
At time: 1455.3380346298218 and batch: 100, loss is 5.149982347488403 and perplexity is 172.4284464948374
At time: 1456.4770545959473 and batch: 150, loss is 5.122569055557251 and perplexity is 167.76581616615087
At time: 1457.616200685501 and batch: 200, loss is 5.106036281585693 and perplexity is 165.01498394836207
At time: 1458.7549402713776 and batch: 250, loss is 5.129800510406494 and perplexity is 168.98340425160018
At time: 1459.893426656723 and batch: 300, loss is 5.134426803588867 and perplexity is 169.76698215563198
At time: 1461.0319752693176 and batch: 350, loss is 5.1419151020050045 and perplexity is 171.04301969137902
At time: 1462.1707973480225 and batch: 400, loss is 5.17352915763855 and perplexity is 176.53676547195406
At time: 1463.3103115558624 and batch: 450, loss is 5.130257654190063 and perplexity is 169.06067162418404
At time: 1464.4496788978577 and batch: 500, loss is 5.163738842010498 and perplexity is 174.81684782420163
At time: 1465.5883243083954 and batch: 550, loss is 5.136689071655273 and perplexity is 170.15147532742327
At time: 1466.7272295951843 and batch: 600, loss is 5.0931317996978756 and perplexity is 162.89923178005225
At time: 1467.8659970760345 and batch: 650, loss is 5.120606288909912 and perplexity is 167.43685396124775
At time: 1469.0047607421875 and batch: 700, loss is 5.145448007583618 and perplexity is 171.64836721802357
At time: 1470.143401145935 and batch: 750, loss is 5.127933053970337 and perplexity is 168.6681295782097
At time: 1471.2827603816986 and batch: 800, loss is 5.110213823318482 and perplexity is 165.70578284631117
At time: 1472.4213905334473 and batch: 850, loss is 5.083525009155274 and perplexity is 161.3417859866426
At time: 1473.5882031917572 and batch: 900, loss is 5.117460517883301 and perplexity is 166.9109635563477
At time: 1474.7263524532318 and batch: 950, loss is 5.0897969627380375 and perplexity is 162.35689420749122
At time: 1475.8650317192078 and batch: 1000, loss is 5.114062480926513 and perplexity is 166.34475647480073
At time: 1477.0039811134338 and batch: 1050, loss is 5.079066009521484 and perplexity is 160.62396459402717
At time: 1478.1433219909668 and batch: 1100, loss is 5.066963872909546 and perplexity is 158.69178675389742
At time: 1479.282019853592 and batch: 1150, loss is 5.07084529876709 and perplexity is 159.3089340893959
At time: 1480.4214115142822 and batch: 1200, loss is 5.041821393966675 and perplexity is 154.75162216020684
At time: 1481.560306072235 and batch: 1250, loss is 5.061684513092041 and perplexity is 157.85620332508583
At time: 1482.6991965770721 and batch: 1300, loss is 5.04968490600586 and perplexity is 155.9733104893557
At time: 1483.8384578227997 and batch: 1350, loss is 5.042992630004883 and perplexity is 154.93297902216622
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.114193929036459 and perplexity of 166.36662361580434
Finished 45 epochs...
Completing Train Step...
At time: 1487.2308344841003 and batch: 50, loss is 5.135966033935547 and perplexity is 170.02849385817268
At time: 1488.397212266922 and batch: 100, loss is 5.1492818832397464 and perplexity is 172.30770882376407
At time: 1489.535323381424 and batch: 150, loss is 5.121787605285644 and perplexity is 167.63476673451743
At time: 1490.6742403507233 and batch: 200, loss is 5.10528606414795 and perplexity is 164.89123325568303
At time: 1491.8124930858612 and batch: 250, loss is 5.12924259185791 and perplexity is 168.8891515710695
At time: 1492.9513266086578 and batch: 300, loss is 5.134128713607788 and perplexity is 169.71638386093048
At time: 1494.0893015861511 and batch: 350, loss is 5.141292991638184 and perplexity is 170.9366451474408
At time: 1495.2272808551788 and batch: 400, loss is 5.172942199707031 and perplexity is 176.43317622149584
At time: 1496.365681886673 and batch: 450, loss is 5.1296462059021 and perplexity is 168.9573313627901
At time: 1497.5044956207275 and batch: 500, loss is 5.163034791946411 and perplexity is 174.69381132829625
At time: 1498.6429932117462 and batch: 550, loss is 5.136105632781982 and perplexity is 170.0522312965974
At time: 1499.7819459438324 and batch: 600, loss is 5.092709999084473 and perplexity is 162.8305352732975
At time: 1500.920030593872 and batch: 650, loss is 5.120214338302612 and perplexity is 167.37123984423974
At time: 1502.1039624214172 and batch: 700, loss is 5.145073394775391 and perplexity is 171.58407758376447
At time: 1503.2423417568207 and batch: 750, loss is 5.127609901428222 and perplexity is 168.61363284921524
At time: 1504.3810896873474 and batch: 800, loss is 5.110067224502563 and perplexity is 165.68149235527716
At time: 1505.5192303657532 and batch: 850, loss is 5.083396644592285 and perplexity is 161.3210767479872
At time: 1506.6584033966064 and batch: 900, loss is 5.117301321029663 and perplexity is 166.8843939710651
At time: 1507.796541929245 and batch: 950, loss is 5.089581718444824 and perplexity is 162.32195157328547
At time: 1508.935034275055 and batch: 1000, loss is 5.114081039428711 and perplexity is 166.3478436129755
At time: 1510.0735211372375 and batch: 1050, loss is 5.079113645553589 and perplexity is 160.63161626460752
At time: 1511.2126986980438 and batch: 1100, loss is 5.067137441635132 and perplexity is 158.71933307560607
At time: 1512.3512439727783 and batch: 1150, loss is 5.071055002212525 and perplexity is 159.34234522485573
At time: 1513.4903905391693 and batch: 1200, loss is 5.042085275650025 and perplexity is 154.7924636671894
At time: 1514.6282942295074 and batch: 1250, loss is 5.061888236999511 and perplexity is 157.88836568365502
At time: 1515.7666623592377 and batch: 1300, loss is 5.0496861934661865 and perplexity is 155.97351129893426
At time: 1516.905502319336 and batch: 1350, loss is 5.042805833816528 and perplexity is 154.90404083509014
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.114002278645834 and perplexity of 166.33474244251863
Finished 46 epochs...
Completing Train Step...
At time: 1520.2977533340454 and batch: 50, loss is 5.135407333374023 and perplexity is 169.9335253751219
At time: 1521.462599992752 and batch: 100, loss is 5.148584594726563 and perplexity is 172.18760251690875
At time: 1522.6009366512299 and batch: 150, loss is 5.121148481369018 and perplexity is 167.5276615762194
At time: 1523.7393600940704 and batch: 200, loss is 5.1046489715576175 and perplexity is 164.78621572926122
At time: 1524.877442598343 and batch: 250, loss is 5.128518610000611 and perplexity is 168.76692314035935
At time: 1526.0161409378052 and batch: 300, loss is 5.13337438583374 and perplexity is 169.5884103519274
At time: 1527.1550624370575 and batch: 350, loss is 5.140655317306519 and perplexity is 170.8276779829636
At time: 1528.2937586307526 and batch: 400, loss is 5.172241764068604 and perplexity is 176.30963940691382
At time: 1529.4324684143066 and batch: 450, loss is 5.129095220565796 and perplexity is 168.86426399248086
At time: 1530.5710475444794 and batch: 500, loss is 5.162411966323853 and perplexity is 174.58504142235682
At time: 1531.7377111911774 and batch: 550, loss is 5.135573129653931 and perplexity is 169.96170205719068
At time: 1532.8762662410736 and batch: 600, loss is 5.09229377746582 and perplexity is 162.76277578679975
At time: 1534.0152487754822 and batch: 650, loss is 5.119793634414673 and perplexity is 167.30084092249643
At time: 1535.1544830799103 and batch: 700, loss is 5.144716663360596 and perplexity is 171.52287906937696
At time: 1536.2932114601135 and batch: 750, loss is 5.127341222763062 and perplexity is 168.56833604882783
At time: 1537.4313979148865 and batch: 800, loss is 5.109862813949585 and perplexity is 165.64762877096143
At time: 1538.5703284740448 and batch: 850, loss is 5.083255796432495 and perplexity is 161.29835657127708
At time: 1539.709203004837 and batch: 900, loss is 5.117115688323975 and perplexity is 166.85341764467375
At time: 1540.8484303951263 and batch: 950, loss is 5.089366674423218 and perplexity is 162.28704896095766
At time: 1541.987535238266 and batch: 1000, loss is 5.114085760116577 and perplexity is 166.34862889107598
At time: 1543.1263220310211 and batch: 1050, loss is 5.0790912055969235 and perplexity is 160.6280117385423
At time: 1544.2650213241577 and batch: 1100, loss is 5.067266521453857 and perplexity is 158.73982186066354
At time: 1545.4035091400146 and batch: 1150, loss is 5.0711881542205814 and perplexity is 159.36356339068024
At time: 1546.5420770645142 and batch: 1200, loss is 5.042151079177857 and perplexity is 154.8026498925216
At time: 1547.681411266327 and batch: 1250, loss is 5.0620436668396 and perplexity is 157.91290815435178
At time: 1548.8203225135803 and batch: 1300, loss is 5.049668560028076 and perplexity is 155.97076097392477
At time: 1549.9591026306152 and batch: 1350, loss is 5.042696857452393 and perplexity is 154.88716087570506
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.11397705078125 and perplexity of 166.33054622509172
Finished 47 epochs...
Completing Train Step...
At time: 1553.382902622223 and batch: 50, loss is 5.134904623031616 and perplexity is 169.84811950340026
At time: 1554.5210826396942 and batch: 100, loss is 5.147954788208008 and perplexity is 172.07919178490556
At time: 1555.6603529453278 and batch: 150, loss is 5.120482578277588 and perplexity is 167.41614152337053
At time: 1556.798791885376 and batch: 200, loss is 5.104063720703125 and perplexity is 164.6898026713612
At time: 1557.9373495578766 and batch: 250, loss is 5.1278854084014895 and perplexity is 168.6600934806732
At time: 1559.0763008594513 and batch: 300, loss is 5.132444047927857 and perplexity is 169.43070919443542
At time: 1560.259199142456 and batch: 350, loss is 5.14025333404541 and perplexity is 170.7590219160998
At time: 1561.3980662822723 and batch: 400, loss is 5.171865043640136 and perplexity is 176.24323247322315
At time: 1562.5379800796509 and batch: 450, loss is 5.128600978851319 and perplexity is 168.78082485038203
At time: 1563.6764545440674 and batch: 500, loss is 5.161752996444702 and perplexity is 174.47003303640207
At time: 1564.8151273727417 and batch: 550, loss is 5.135169906616211 and perplexity is 169.8931833984703
At time: 1565.9535179138184 and batch: 600, loss is 5.091879930496216 and perplexity is 162.69543084148788
At time: 1567.0922629833221 and batch: 650, loss is 5.119360942840576 and perplexity is 167.22846691723015
At time: 1568.2310378551483 and batch: 700, loss is 5.144420318603515 and perplexity is 171.47205669428956
At time: 1569.3701539039612 and batch: 750, loss is 5.127129602432251 and perplexity is 168.53266733603445
At time: 1570.509577512741 and batch: 800, loss is 5.109691848754883 and perplexity is 165.61931121258417
At time: 1571.6488795280457 and batch: 850, loss is 5.08311972618103 and perplexity is 161.27641015649843
At time: 1572.7871520519257 and batch: 900, loss is 5.11691219329834 and perplexity is 166.8194672586574
At time: 1573.926277399063 and batch: 950, loss is 5.089070158004761 and perplexity is 162.23893532003257
At time: 1575.0652797222137 and batch: 1000, loss is 5.113991851806641 and perplexity is 166.33300810594884
At time: 1576.2041025161743 and batch: 1050, loss is 5.078993186950684 and perplexity is 160.6122679698876
At time: 1577.3431415557861 and batch: 1100, loss is 5.067349538803101 and perplexity is 158.7530005669169
At time: 1578.481700181961 and batch: 1150, loss is 5.07117546081543 and perplexity is 159.36154053724215
At time: 1579.619999885559 and batch: 1200, loss is 5.04223222732544 and perplexity is 154.8152123505045
At time: 1580.758663892746 and batch: 1250, loss is 5.0620791721344 and perplexity is 157.9185149982443
At time: 1581.8975336551666 and batch: 1300, loss is 5.049598903656006 and perplexity is 155.95989699494336
At time: 1583.0370690822601 and batch: 1350, loss is 5.042566947937011 and perplexity is 154.8670408666155
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.113897298177084 and perplexity of 166.3172814598347
Finished 48 epochs...
Completing Train Step...
At time: 1586.4695193767548 and batch: 50, loss is 5.134364404678345 and perplexity is 169.75638921140037
At time: 1587.610252380371 and batch: 100, loss is 5.147384490966797 and perplexity is 171.98108347466922
At time: 1588.779498577118 and batch: 150, loss is 5.119851112365723 and perplexity is 167.31045730840395
At time: 1589.9206337928772 and batch: 200, loss is 5.1035237216949465 and perplexity is 164.60089434862513
At time: 1591.061672925949 and batch: 250, loss is 5.127358589172363 and perplexity is 168.57126350096658
At time: 1592.202026605606 and batch: 300, loss is 5.131965322494507 and perplexity is 169.3496178165547
At time: 1593.3425884246826 and batch: 350, loss is 5.139754476547242 and perplexity is 170.6738587415472
At time: 1594.4841356277466 and batch: 400, loss is 5.171409721374512 and perplexity is 176.16300327176944
At time: 1595.6248171329498 and batch: 450, loss is 5.12812502861023 and perplexity is 168.70051268991543
At time: 1596.7659912109375 and batch: 500, loss is 5.161267175674438 and perplexity is 174.38529245659802
At time: 1597.906991481781 and batch: 550, loss is 5.1347941970825195 and perplexity is 169.82936489911833
At time: 1599.0481922626495 and batch: 600, loss is 5.091516218185425 and perplexity is 162.63626727029322
At time: 1600.1892116069794 and batch: 650, loss is 5.1190713596343995 and perplexity is 167.18004737269817
At time: 1601.3305404186249 and batch: 700, loss is 5.144110794067383 and perplexity is 171.41899009861197
At time: 1602.471761226654 and batch: 750, loss is 5.1268610095977785 and perplexity is 168.48740674782042
At time: 1603.6130282878876 and batch: 800, loss is 5.1095270252227785 and perplexity is 165.59201550227485
At time: 1604.7542841434479 and batch: 850, loss is 5.082941102981567 and perplexity is 161.24760502082776
At time: 1605.8956506252289 and batch: 900, loss is 5.116734914779663 and perplexity is 166.7898963718342
At time: 1607.0360782146454 and batch: 950, loss is 5.088856859207153 and perplexity is 162.20433364058317
At time: 1608.1775743961334 and batch: 1000, loss is 5.113942127227784 and perplexity is 166.3247374727993
At time: 1609.318644285202 and batch: 1050, loss is 5.079024953842163 and perplexity is 160.61737020341502
At time: 1610.460580587387 and batch: 1100, loss is 5.06740553855896 and perplexity is 158.76189094511776
At time: 1611.6017291545868 and batch: 1150, loss is 5.071163301467895 and perplexity is 159.35960281666792
At time: 1612.7430038452148 and batch: 1200, loss is 5.042263126373291 and perplexity is 154.81999606706475
At time: 1613.8837575912476 and batch: 1250, loss is 5.062126502990723 and perplexity is 157.92598959367655
At time: 1615.0246863365173 and batch: 1300, loss is 5.049536046981811 and perplexity is 155.95009418259986
At time: 1616.1661188602448 and batch: 1350, loss is 5.042364578247071 and perplexity is 154.8357036425324
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.113960774739583 and perplexity of 166.32783904422212
Annealing...
Finished 49 epochs...
Completing Train Step...
At time: 1619.5898616313934 and batch: 50, loss is 5.134258852005005 and perplexity is 169.73847191632848
At time: 1620.7588136196136 and batch: 100, loss is 5.14739239692688 and perplexity is 171.982443155625
At time: 1621.8998866081238 and batch: 150, loss is 5.119963779449463 and perplexity is 167.3293087516567
At time: 1623.0422382354736 and batch: 200, loss is 5.103886499404907 and perplexity is 164.6606187168141
At time: 1624.1847157478333 and batch: 250, loss is 5.126994438171387 and perplexity is 168.5098892820467
At time: 1625.3270602226257 and batch: 300, loss is 5.132224893569946 and perplexity is 169.39358178461694
At time: 1626.4683530330658 and batch: 350, loss is 5.140061645507813 and perplexity is 170.72629250593369
At time: 1627.6099112033844 and batch: 400, loss is 5.172171897888184 and perplexity is 176.2973217561359
At time: 1628.7508645057678 and batch: 450, loss is 5.128322906494141 and perplexity is 168.73389809338883
At time: 1629.8926684856415 and batch: 500, loss is 5.161151456832886 and perplexity is 174.36511396010977
At time: 1631.0349519252777 and batch: 550, loss is 5.133414459228516 and perplexity is 169.5952064714157
At time: 1632.1765840053558 and batch: 600, loss is 5.089732980728149 and perplexity is 162.3465066193935
At time: 1633.3179140090942 and batch: 650, loss is 5.117586708068847 and perplexity is 166.93202741080648
At time: 1634.4591097831726 and batch: 700, loss is 5.141928958892822 and perplexity is 171.04538983173623
At time: 1635.5999388694763 and batch: 750, loss is 5.124960441589355 and perplexity is 168.16748908167355
At time: 1636.7410275936127 and batch: 800, loss is 5.107504081726074 and perplexity is 165.2573708091834
At time: 1637.8822658061981 and batch: 850, loss is 5.080021705627441 and perplexity is 160.77754566824086
At time: 1639.0236048698425 and batch: 900, loss is 5.11330132484436 and perplexity is 166.21819032608317
At time: 1640.165281534195 and batch: 950, loss is 5.08542405128479 and perplexity is 161.64847194809502
At time: 1641.3062541484833 and batch: 1000, loss is 5.110584287643433 and perplexity is 165.76718229974514
At time: 1642.4471282958984 and batch: 1050, loss is 5.075217666625977 and perplexity is 160.00701637658182
At time: 1643.5887517929077 and batch: 1100, loss is 5.063282384872436 and perplexity is 158.10863892388934
At time: 1644.7295689582825 and batch: 1150, loss is 5.066924648284912 and perplexity is 158.68556225020725
At time: 1645.8706188201904 and batch: 1200, loss is 5.037860841751098 and perplexity is 154.13993239440367
At time: 1647.0409185886383 and batch: 1250, loss is 5.057895946502685 and perplexity is 157.25928603167748
At time: 1648.1819441318512 and batch: 1300, loss is 5.044709300994873 and perplexity is 155.19917639392642
At time: 1649.3234164714813 and batch: 1350, loss is 5.038673448562622 and perplexity is 154.2652384587806
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1138688151041665 and perplexity of 166.31254430004427
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7feac4b70a20>
SETTINGS FOR THIS RUN
{'lr': 1.9255212810427624, 'data': 'wikitext', 'dropout': 0.002372384860573895, 'anneal': 6.455311187146002, 'wordvec_source': '', 'num_layers': 1, 'wordvec_dim': 200, 'batch_size': 80, 'seq_len': 20, 'tune_wordvecs': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.5786314010620117 and batch: 50, loss is 7.56205714225769 and perplexity is 1923.7989737283388
At time: 2.6347544193267822 and batch: 100, loss is 6.470355997085571 and perplexity is 645.7135581978421
At time: 3.693382978439331 and batch: 150, loss is 6.267113199234009 and perplexity is 526.9539689254453
At time: 4.751676797866821 and batch: 200, loss is 6.169479131698608 and perplexity is 477.937098960023
At time: 5.812320709228516 and batch: 250, loss is 6.120291767120361 and perplexity is 454.99742842434887
At time: 6.874298095703125 and batch: 300, loss is 6.042153730392456 and perplexity is 420.79834582538786
At time: 7.934968709945679 and batch: 350, loss is 6.005907192230224 and perplexity is 405.81897761520645
At time: 8.997517824172974 and batch: 400, loss is 5.996055784225464 and perplexity is 401.840717198112
At time: 10.060331583023071 and batch: 450, loss is 5.91087140083313 and perplexity is 369.02758628758863
At time: 11.123502492904663 and batch: 500, loss is 5.8799888610839846 and perplexity is 357.80525612395724
At time: 12.188146591186523 and batch: 550, loss is 5.802071599960327 and perplexity is 330.9845176991589
At time: 13.279263257980347 and batch: 600, loss is 5.71911208152771 and perplexity is 304.6343124013576
At time: 14.343982219696045 and batch: 650, loss is 5.727918033599853 and perplexity is 307.32875370474875
At time: 15.410186290740967 and batch: 700, loss is 5.710104722976684 and perplexity is 301.9026827749886
At time: 16.475348234176636 and batch: 750, loss is 5.661849956512452 and perplexity is 287.6803467205441
At time: 17.543407440185547 and batch: 800, loss is 5.5943935680389405 and perplexity is 268.91452227320474
At time: 18.610281467437744 and batch: 850, loss is 5.577223167419434 and perplexity is 264.3365673267789
At time: 19.67811679840088 and batch: 900, loss is 5.59998309135437 and perplexity is 270.42183492051805
At time: 20.745389699935913 and batch: 950, loss is 5.54595290184021 and perplexity is 256.1985940749927
At time: 21.813483953475952 and batch: 1000, loss is 5.551869478225708 and perplexity is 257.7189057116744
At time: 22.881688833236694 and batch: 1050, loss is 5.504862585067749 and perplexity is 245.88466513261156
At time: 23.950782775878906 and batch: 1100, loss is 5.471441745758057 and perplexity is 237.80279690147486
At time: 25.019083738327026 and batch: 1150, loss is 5.468619918823242 and perplexity is 237.1327044511124
At time: 26.087855577468872 and batch: 1200, loss is 5.443425445556641 and perplexity is 231.2329041261635
At time: 27.15587615966797 and batch: 1250, loss is 5.454573593139648 and perplexity is 233.82514516305562
At time: 28.224080324172974 and batch: 1300, loss is 5.405565090179444 and perplexity is 222.64199774917986
At time: 29.292354106903076 and batch: 1350, loss is 5.382275505065918 and perplexity is 217.51667300085887
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.10690185546875 and perplexity of 165.1578784427304
Finished 1 epochs...
Completing Train Step...
At time: 32.521785736083984 and batch: 50, loss is 5.431999568939209 and perplexity is 228.6059019746318
At time: 33.578186988830566 and batch: 100, loss is 5.427067003250122 and perplexity is 227.48106479349732
At time: 34.63495445251465 and batch: 150, loss is 5.363147392272949 and perplexity is 213.3955300435055
At time: 35.69169998168945 and batch: 200, loss is 5.353642959594726 and perplexity is 211.3769345923262
At time: 36.74853467941284 and batch: 250, loss is 5.373803834915162 and perplexity is 215.68172699791637
At time: 37.80835247039795 and batch: 300, loss is 5.345229768753052 and perplexity is 209.6060399847968
At time: 38.86939764022827 and batch: 350, loss is 5.345123958587647 and perplexity is 209.58386270834737
At time: 39.930307388305664 and batch: 400, loss is 5.377010335922241 and perplexity is 216.37442064067284
At time: 41.01608848571777 and batch: 450, loss is 5.328652925491333 and perplexity is 206.16007404180493
At time: 42.14002227783203 and batch: 500, loss is 5.352126741409302 and perplexity is 211.0566838864427
At time: 43.27758026123047 and batch: 550, loss is 5.312953958511352 and perplexity is 202.94884627848646
At time: 44.415406465530396 and batch: 600, loss is 5.2530421543121335 and perplexity is 191.14688316595175
At time: 45.552412271499634 and batch: 650, loss is 5.280336151123047 and perplexity is 196.43589640183376
At time: 46.6899151802063 and batch: 700, loss is 5.279805145263672 and perplexity is 196.33161547919363
At time: 47.8275408744812 and batch: 750, loss is 5.236998510360718 and perplexity is 188.10466005723123
At time: 48.96538281440735 and batch: 800, loss is 5.18585807800293 and perplexity is 178.7267454994299
At time: 50.103137254714966 and batch: 850, loss is 5.172103223800659 and perplexity is 176.28521511414223
At time: 51.286365032196045 and batch: 900, loss is 5.213772649765015 and perplexity is 183.78611256789696
At time: 52.423879861831665 and batch: 950, loss is 5.168134508132934 and perplexity is 175.58697569227718
At time: 53.56164503097534 and batch: 1000, loss is 5.18920714378357 and perplexity is 179.32631656793035
At time: 54.699442625045776 and batch: 1050, loss is 5.139192361831665 and perplexity is 170.57794741309428
At time: 55.83641743659973 and batch: 1100, loss is 5.112662839889526 and perplexity is 166.11209638563685
At time: 56.974849462509155 and batch: 1150, loss is 5.121201391220093 and perplexity is 167.53652567434125
At time: 58.11211681365967 and batch: 1200, loss is 5.103844995498657 and perplexity is 164.65378479974999
At time: 59.24932646751404 and batch: 1250, loss is 5.142644510269165 and perplexity is 171.16782539509137
At time: 60.3867506980896 and batch: 1300, loss is 5.103690614700318 and perplexity is 164.62836737903427
At time: 61.52479076385498 and batch: 1350, loss is 5.0821240234375 and perplexity is 161.1159067125593
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.90578125 and perplexity of 135.06839097839296
Finished 2 epochs...
Completing Train Step...
At time: 64.91431546211243 and batch: 50, loss is 5.154000005722046 and perplexity is 173.12259856176965
At time: 66.06148505210876 and batch: 100, loss is 5.152111797332764 and perplexity is 172.79601544431353
At time: 67.18108797073364 and batch: 150, loss is 5.092909278869629 and perplexity is 162.86298734079674
At time: 68.30122303962708 and batch: 200, loss is 5.09603325843811 and perplexity is 163.37256352408045
At time: 69.42378163337708 and batch: 250, loss is 5.117011232376099 and perplexity is 166.83598972301817
At time: 70.56041049957275 and batch: 300, loss is 5.093317947387695 and perplexity is 162.9295579182042
At time: 71.69716882705688 and batch: 350, loss is 5.093978290557861 and perplexity is 163.03718286978366
At time: 72.83442068099976 and batch: 400, loss is 5.128568325042725 and perplexity is 168.77531360361513
At time: 73.97179460525513 and batch: 450, loss is 5.084889783859253 and perplexity is 161.56213150164297
At time: 75.1088376045227 and batch: 500, loss is 5.127349624633789 and perplexity is 168.56975234414577
At time: 76.24581122398376 and batch: 550, loss is 5.09238260269165 and perplexity is 162.7772338692274
At time: 77.38278889656067 and batch: 600, loss is 5.038397951126099 and perplexity is 154.2227446347791
At time: 78.51997113227844 and batch: 650, loss is 5.067796831130981 and perplexity is 158.82402544935684
At time: 79.65751099586487 and batch: 700, loss is 5.073020162582398 and perplexity is 159.65578636711777
At time: 80.82292032241821 and batch: 750, loss is 5.029771776199341 and perplexity is 152.8981137247504
At time: 81.95997476577759 and batch: 800, loss is 4.982850646972656 and perplexity is 145.88966939741917
At time: 83.09682321548462 and batch: 850, loss is 4.970779399871827 and perplexity is 144.13918566542947
At time: 84.2335753440857 and batch: 900, loss is 5.018062810897828 and perplexity is 151.11827538375607
At time: 85.37076187133789 and batch: 950, loss is 4.973788042068481 and perplexity is 144.5735019251101
At time: 86.50749087333679 and batch: 1000, loss is 4.995324773788452 and perplexity is 147.7209134743645
At time: 87.64423537254333 and batch: 1050, loss is 4.940895986557007 and perplexity is 139.89553794465073
At time: 88.78086805343628 and batch: 1100, loss is 4.919427099227906 and perplexity is 136.92414676247913
At time: 89.91812038421631 and batch: 1150, loss is 4.934020442962646 and perplexity is 138.93697915738798
At time: 91.05545020103455 and batch: 1200, loss is 4.917934637069703 and perplexity is 136.71994507444185
At time: 92.19211959838867 and batch: 1250, loss is 4.96628023147583 and perplexity is 143.49213588112158
At time: 93.32789278030396 and batch: 1300, loss is 4.934935169219971 and perplexity is 139.06412660402495
At time: 94.46494817733765 and batch: 1350, loss is 4.912351341247558 and perplexity is 135.9587242144004
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.808464762369792 and perplexity of 122.54333988207178
Finished 3 epochs...
Completing Train Step...
At time: 97.87143325805664 and batch: 50, loss is 4.991447410583496 and perplexity is 147.14925482016253
At time: 98.98939681053162 and batch: 100, loss is 4.989195041656494 and perplexity is 146.81819338717713
At time: 100.1080174446106 and batch: 150, loss is 4.934585599899292 and perplexity is 139.0155225474957
At time: 101.22677707672119 and batch: 200, loss is 4.942838678359985 and perplexity is 140.16757601699848
At time: 102.35005211830139 and batch: 250, loss is 4.960041093826294 and perplexity is 142.59965574206916
At time: 103.4814453125 and batch: 300, loss is 4.937576761245728 and perplexity is 139.4319629147666
At time: 104.6178879737854 and batch: 350, loss is 4.940142974853516 and perplexity is 139.7902346196061
At time: 105.75471806526184 and batch: 400, loss is 4.975567884445191 and perplexity is 144.83104909908386
At time: 106.89225435256958 and batch: 450, loss is 4.929144735336304 and perplexity is 138.26121182921122
At time: 108.0286340713501 and batch: 500, loss is 4.981731815338135 and perplexity is 145.72653469729656
At time: 109.19442772865295 and batch: 550, loss is 4.952262105941773 and perplexity is 141.49467812355655
At time: 110.33210444450378 and batch: 600, loss is 4.900304841995239 and perplexity is 134.3307230896324
At time: 111.46905708312988 and batch: 650, loss is 4.925577907562256 and perplexity is 137.76893635161292
At time: 112.60597729682922 and batch: 700, loss is 4.936112737655639 and perplexity is 139.2279805857519
At time: 113.7429621219635 and batch: 750, loss is 4.8922186279296875 and perplexity is 133.24887602549794
At time: 114.87952184677124 and batch: 800, loss is 4.850603799819947 and perplexity is 127.81754276053175
At time: 116.01680898666382 and batch: 850, loss is 4.835307531356811 and perplexity is 125.8772884683414
At time: 117.1557674407959 and batch: 900, loss is 4.8859625339508055 and perplexity is 132.41786069989348
At time: 118.29310655593872 and batch: 950, loss is 4.84196759223938 and perplexity is 126.71843681367763
At time: 119.42989444732666 and batch: 1000, loss is 4.86442153930664 and perplexity is 129.59595076160397
At time: 120.56656122207642 and batch: 1050, loss is 4.805948781967163 and perplexity is 122.23541077469217
At time: 121.70384478569031 and batch: 1100, loss is 4.7884056282043455 and perplexity is 120.10971637713862
At time: 122.84089255332947 and batch: 1150, loss is 4.808265018463135 and perplexity is 122.51886504106044
At time: 123.97865676879883 and batch: 1200, loss is 4.790236558914184 and perplexity is 120.32983039066627
At time: 125.11528873443604 and batch: 1250, loss is 4.845559072494507 and perplexity is 127.17436181019492
At time: 126.25256609916687 and batch: 1300, loss is 4.81558895111084 and perplexity is 123.41947894875545
At time: 127.3902759552002 and batch: 1350, loss is 4.794132814407349 and perplexity is 120.79958069264916
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.753526204427083 and perplexity of 115.9925777826674
Finished 4 epochs...
Completing Train Step...
At time: 130.81361031532288 and batch: 50, loss is 4.875974760055542 and perplexity is 131.10188382691453
At time: 131.93649578094482 and batch: 100, loss is 4.874809617996216 and perplexity is 130.949220462535
At time: 133.06476640701294 and batch: 150, loss is 4.822787857055664 and perplexity is 124.31116991824624
At time: 134.20052552223206 and batch: 200, loss is 4.832368507385254 and perplexity is 125.50787522316145
At time: 135.33807015419006 and batch: 250, loss is 4.847427835464478 and perplexity is 127.41224275059301
At time: 136.4753909111023 and batch: 300, loss is 4.826159362792969 and perplexity is 124.73099306122512
At time: 137.64120650291443 and batch: 350, loss is 4.8272789478302 and perplexity is 124.87071821723734
At time: 138.77907514572144 and batch: 400, loss is 4.864937524795533 and perplexity is 129.66283764646315
At time: 139.917400598526 and batch: 450, loss is 4.815979499816894 and perplexity is 123.4676896802674
At time: 141.05525946617126 and batch: 500, loss is 4.874639949798584 and perplexity is 130.92700442904828
At time: 142.19280099868774 and batch: 550, loss is 4.850425958633423 and perplexity is 127.79481355822271
At time: 143.33078980445862 and batch: 600, loss is 4.797460241317749 and perplexity is 121.20220194312527
At time: 144.46819400787354 and batch: 650, loss is 4.821039762496948 and perplexity is 124.09405206508312
At time: 145.60689640045166 and batch: 700, loss is 4.836212587356568 and perplexity is 125.99126603376229
At time: 146.74437260627747 and batch: 750, loss is 4.789735193252564 and perplexity is 120.26951626661851
At time: 147.88210892677307 and batch: 800, loss is 4.752492742538452 and perplexity is 115.87276579538998
At time: 149.01973271369934 and batch: 850, loss is 4.732437314987183 and perplexity is 113.57203611070936
At time: 150.15763187408447 and batch: 900, loss is 4.785537023544311 and perplexity is 119.76566279780589
At time: 151.2955822944641 and batch: 950, loss is 4.743301963806152 and perplexity is 114.81268379553421
At time: 152.43415451049805 and batch: 1000, loss is 4.766016035079956 and perplexity is 117.45039040151664
At time: 153.5719952583313 and batch: 1050, loss is 4.705524473190308 and perplexity is 110.55625353565829
At time: 154.70996379852295 and batch: 1100, loss is 4.69147310256958 and perplexity is 109.01364987171048
At time: 155.84761834144592 and batch: 1150, loss is 4.7137584400177 and perplexity is 111.47032812537716
At time: 156.9856472015381 and batch: 1200, loss is 4.692583093643188 and perplexity is 109.13472123160314
At time: 158.12351536750793 and batch: 1250, loss is 4.7502972030639645 and perplexity is 115.61864163596138
At time: 159.26147079467773 and batch: 1300, loss is 4.723135185241699 and perplexity is 112.52047276728047
At time: 160.39943170547485 and batch: 1350, loss is 4.701374120712281 and perplexity is 110.09835698815883
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.713490804036458 and perplexity of 111.44049864662894
Finished 5 epochs...
Completing Train Step...
At time: 163.78530550003052 and batch: 50, loss is 4.783015079498291 and perplexity is 119.46400104451244
At time: 164.94435334205627 and batch: 100, loss is 4.784666252136231 and perplexity is 119.66141967552373
At time: 166.08411741256714 and batch: 150, loss is 4.734940967559814 and perplexity is 113.85673727878743
At time: 167.25304651260376 and batch: 200, loss is 4.742812585830689 and perplexity is 114.75651074282932
At time: 168.39292979240417 and batch: 250, loss is 4.756888475418091 and perplexity is 116.38323263783676
At time: 169.53373908996582 and batch: 300, loss is 4.739016637802124 and perplexity is 114.32172672295651
At time: 170.67378997802734 and batch: 350, loss is 4.739570169448853 and perplexity is 114.38502493377155
At time: 171.81413435935974 and batch: 400, loss is 4.77659462928772 and perplexity is 118.69944539597363
At time: 172.95455169677734 and batch: 450, loss is 4.726422424316406 and perplexity is 112.89096307354671
At time: 174.09544277191162 and batch: 500, loss is 4.789753189086914 and perplexity is 120.27168063638544
At time: 175.23519253730774 and batch: 550, loss is 4.770541982650757 and perplexity is 117.98316946623835
At time: 176.37736582756042 and batch: 600, loss is 4.714866333007812 and perplexity is 111.59389375662214
At time: 177.5172939300537 and batch: 650, loss is 4.73943531036377 and perplexity is 114.36960011407368
At time: 178.65776133537292 and batch: 700, loss is 4.754794874191284 and perplexity is 116.13982744481895
At time: 179.7976849079132 and batch: 750, loss is 4.707730379104614 and perplexity is 110.80039941161041
At time: 180.93834137916565 and batch: 800, loss is 4.672475862503052 and perplexity is 106.96223866514077
At time: 182.07796359062195 and batch: 850, loss is 4.6504281139373775 and perplexity is 104.62976945269683
At time: 183.21846985816956 and batch: 900, loss is 4.704695339202881 and perplexity is 110.46462557950484
At time: 184.35876870155334 and batch: 950, loss is 4.6635716533660885 and perplexity is 106.01405221228107
At time: 185.4987988471985 and batch: 1000, loss is 4.686788148880005 and perplexity is 108.50412046333342
At time: 186.64065146446228 and batch: 1050, loss is 4.624379577636719 and perplexity is 101.93950790875624
At time: 187.78202867507935 and batch: 1100, loss is 4.613807735443115 and perplexity is 100.86749607216294
At time: 188.9223244190216 and batch: 1150, loss is 4.637106418609619 and perplexity is 103.24516664697857
At time: 190.06270718574524 and batch: 1200, loss is 4.613554058074951 and perplexity is 100.84191151647462
At time: 191.20232939720154 and batch: 1250, loss is 4.672751226425171 and perplexity is 106.99169626229188
At time: 192.34222674369812 and batch: 1300, loss is 4.647384090423584 and perplexity is 104.31175823660945
At time: 193.48325991630554 and batch: 1350, loss is 4.625035228729248 and perplexity is 102.0063665740719
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.687014973958333 and perplexity of 108.52873471041515
Finished 6 epochs...
Completing Train Step...
At time: 196.90374302864075 and batch: 50, loss is 4.709009504318237 and perplexity is 110.9422176785013
At time: 198.07013058662415 and batch: 100, loss is 4.710194234848022 and perplexity is 111.07373220007885
At time: 199.21049857139587 and batch: 150, loss is 4.66445026397705 and perplexity is 106.10723821457643
At time: 200.35183143615723 and batch: 200, loss is 4.66851773262024 and perplexity is 106.53970500514632
At time: 201.49335026741028 and batch: 250, loss is 4.681246242523193 and perplexity is 107.90446394329396
At time: 202.6348774433136 and batch: 300, loss is 4.667116165161133 and perplexity is 106.39048701547446
At time: 203.77583575248718 and batch: 350, loss is 4.66878119468689 and perplexity is 106.5677778739129
At time: 204.91665506362915 and batch: 400, loss is 4.704719552993774 and perplexity is 110.46730037923311
At time: 206.05784273147583 and batch: 450, loss is 4.65362138748169 and perplexity is 104.96441495037999
At time: 207.1988708972931 and batch: 500, loss is 4.717728614807129 and perplexity is 111.91376448934223
At time: 208.33988785743713 and batch: 550, loss is 4.7014781665802 and perplexity is 110.10981286322608
At time: 209.4810335636139 and batch: 600, loss is 4.645522022247315 and perplexity is 104.11770335896294
At time: 210.62243175506592 and batch: 650, loss is 4.670767021179199 and perplexity is 106.77961325498283
At time: 211.7636866569519 and batch: 700, loss is 4.686195106506347 and perplexity is 108.4397919988202
At time: 212.90461564064026 and batch: 750, loss is 4.638311176300049 and perplexity is 103.36962701273373
At time: 214.04584860801697 and batch: 800, loss is 4.604448080062866 and perplexity is 99.92781547305144
At time: 215.18763637542725 and batch: 850, loss is 4.580815830230713 and perplexity is 97.59398185836942
At time: 216.32878422737122 and batch: 900, loss is 4.635882873535156 and perplexity is 103.1189187825919
At time: 217.46994829177856 and batch: 950, loss is 4.597032060623169 and perplexity is 99.18948995296718
At time: 218.610675573349 and batch: 1000, loss is 4.619765748977661 and perplexity is 101.47025983320906
At time: 219.75253534317017 and batch: 1050, loss is 4.5564275741577145 and perplexity is 95.24262413997005
At time: 220.893728017807 and batch: 1100, loss is 4.546795978546142 and perplexity is 94.3296892665854
At time: 222.03479051589966 and batch: 1150, loss is 4.571120166778565 and perplexity is 96.65231587040165
At time: 223.17632389068604 and batch: 1200, loss is 4.546874952316284 and perplexity is 94.33713913195122
At time: 224.34573888778687 and batch: 1250, loss is 4.608211736679078 and perplexity is 100.3046180899437
At time: 225.4862220287323 and batch: 1300, loss is 4.583072214126587 and perplexity is 97.81443997290428
At time: 226.81190252304077 and batch: 1350, loss is 4.559875659942627 and perplexity is 95.57159571355145
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.667284749348958 and perplexity of 106.40842428124755
Finished 7 epochs...
Completing Train Step...
At time: 230.2316539287567 and batch: 50, loss is 4.64729118347168 and perplexity is 104.30206739928397
At time: 231.36669921875 and batch: 100, loss is 4.647318134307861 and perplexity is 104.30487846509594
At time: 232.50721645355225 and batch: 150, loss is 4.603270072937011 and perplexity is 99.81016910208956
At time: 233.64756560325623 and batch: 200, loss is 4.605230264663696 and perplexity is 100.00600804803643
At time: 234.78861570358276 and batch: 250, loss is 4.616987581253052 and perplexity is 101.18874965464182
At time: 235.92913150787354 and batch: 300, loss is 4.605571985244751 and perplexity is 100.04018799887933
At time: 237.11583709716797 and batch: 350, loss is 4.608761653900147 and perplexity is 100.35979249607173
At time: 238.2560098171234 and batch: 400, loss is 4.64284969329834 and perplexity is 103.8398380452977
At time: 239.39645957946777 and batch: 450, loss is 4.59067512512207 and perplexity is 98.56094867776663
At time: 240.5363028049469 and batch: 500, loss is 4.656444358825683 and perplexity is 105.26114511924813
At time: 241.67713928222656 and batch: 550, loss is 4.642650032043457 and perplexity is 103.81910732255673
At time: 242.81783080101013 and batch: 600, loss is 4.585498380661011 and perplexity is 98.05204220849666
At time: 243.9583797454834 and batch: 650, loss is 4.611075038909912 and perplexity is 100.59223209309181
At time: 245.09841012954712 and batch: 700, loss is 4.62760437965393 and perplexity is 102.2687732619361
At time: 246.23894953727722 and batch: 750, loss is 4.579087638854981 and perplexity is 97.42546643598956
At time: 247.3800823688507 and batch: 800, loss is 4.545494594573975 and perplexity is 94.2070099646271
At time: 248.52031135559082 and batch: 850, loss is 4.52057520866394 and perplexity is 91.88843780527823
At time: 249.66063356399536 and batch: 900, loss is 4.576788158416748 and perplexity is 97.20169585836818
At time: 250.8017611503601 and batch: 950, loss is 4.539216041564941 and perplexity is 93.61737920966402
At time: 251.94175839424133 and batch: 1000, loss is 4.56216025352478 and perplexity is 95.79018756945442
At time: 253.08239674568176 and batch: 1050, loss is 4.497216711044311 and perplexity is 89.76693595763322
At time: 254.22239232063293 and batch: 1100, loss is 4.488253707885742 and perplexity is 88.96594961097848
At time: 255.36243796348572 and batch: 1150, loss is 4.5138075637817385 and perplexity is 91.26866904238152
At time: 256.5030529499054 and batch: 1200, loss is 4.4892336368560795 and perplexity is 89.05317265158828
At time: 257.6434848308563 and batch: 1250, loss is 4.552038354873657 and perplexity is 94.82549947291415
At time: 258.7838170528412 and batch: 1300, loss is 4.526485996246338 and perplexity is 92.43317918171853
At time: 259.9243369102478 and batch: 1350, loss is 4.5029345703125 and perplexity is 90.28168088147413
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.658268229166667 and perplexity of 105.4533029821347
Finished 8 epochs...
Completing Train Step...
At time: 263.3470153808594 and batch: 50, loss is 4.593816232681275 and perplexity is 98.87102595679373
At time: 264.4842617511749 and batch: 100, loss is 4.592780342102051 and perplexity is 98.76865942186537
At time: 265.62137508392334 and batch: 150, loss is 4.548953104019165 and perplexity is 94.5333898670536
At time: 266.7584192752838 and batch: 200, loss is 4.54970425605774 and perplexity is 94.60442549150265
At time: 267.8953504562378 and batch: 250, loss is 4.5611684608459475 and perplexity is 95.69523065928689
At time: 269.032386302948 and batch: 300, loss is 4.553253631591797 and perplexity is 94.94080874685592
At time: 270.1693172454834 and batch: 350, loss is 4.5557530498504635 and perplexity is 95.17840233691986
At time: 271.3066840171814 and batch: 400, loss is 4.588311853408814 and perplexity is 98.32829739310561
At time: 272.4438760280609 and batch: 450, loss is 4.536438417434693 and perplexity is 93.35770612222979
At time: 273.58108615875244 and batch: 500, loss is 4.602407579421997 and perplexity is 99.72412059198174
At time: 274.7462339401245 and batch: 550, loss is 4.591462087631226 and perplexity is 98.63854297714053
At time: 275.8832402229309 and batch: 600, loss is 4.533367252349853 and perplexity is 93.0714290219191
At time: 277.020626783371 and batch: 650, loss is 4.557476768493652 and perplexity is 95.34260460205319
At time: 278.15822315216064 and batch: 700, loss is 4.575925235748291 and perplexity is 97.11785449111034
At time: 279.2960271835327 and batch: 750, loss is 4.527427129745483 and perplexity is 92.52021209144837
At time: 280.4329204559326 and batch: 800, loss is 4.4932758998870845 and perplexity is 89.413877540053
At time: 281.56973218917847 and batch: 850, loss is 4.467912111282349 and perplexity is 87.17452217078082
At time: 282.7068817615509 and batch: 900, loss is 4.522729139328003 and perplexity is 92.08657243666651
At time: 283.8444631099701 and batch: 950, loss is 4.488908386230468 and perplexity is 89.02421276133722
At time: 284.9815924167633 and batch: 1000, loss is 4.509824504852295 and perplexity is 90.9058635726085
At time: 286.1187880039215 and batch: 1050, loss is 4.446168212890625 and perplexity is 85.29946759258374
At time: 287.25620126724243 and batch: 1100, loss is 4.437015142440796 and perplexity is 84.52227781874039
At time: 288.3935046195984 and batch: 1150, loss is 4.463346481323242 and perplexity is 86.77742275497565
At time: 289.5308666229248 and batch: 1200, loss is 4.438182401657104 and perplexity is 84.62099482946955
At time: 290.6679410934448 and batch: 1250, loss is 4.502189702987671 and perplexity is 90.2144580465096
At time: 291.8051018714905 and batch: 1300, loss is 4.476464948654175 and perplexity is 87.92330924436767
At time: 292.94277787208557 and batch: 1350, loss is 4.45234432220459 and perplexity is 85.82791662858853
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.647824300130209 and perplexity of 104.35768739358896
Finished 9 epochs...
Completing Train Step...
At time: 296.3791415691376 and batch: 50, loss is 4.545383911132813 and perplexity is 94.19658338561813
At time: 297.51610255241394 and batch: 100, loss is 4.544214925765991 and perplexity is 94.08653329404127
At time: 298.6539566516876 and batch: 150, loss is 4.50126371383667 and perplexity is 90.13095910261951
At time: 299.79142475128174 and batch: 200, loss is 4.5006263637542725 and perplexity is 90.0735324307999
At time: 300.92871356010437 and batch: 250, loss is 4.51257435798645 and perplexity is 91.15618536280836
At time: 302.065491437912 and batch: 300, loss is 4.506256370544434 and perplexity is 90.58207724209244
At time: 303.23078536987305 and batch: 350, loss is 4.508202333450317 and perplexity is 90.75851822246635
At time: 304.3688008785248 and batch: 400, loss is 4.539614181518555 and perplexity is 93.65465944956402
At time: 305.5061447620392 and batch: 450, loss is 4.4866849803924564 and perplexity is 88.82649569105516
At time: 306.6438949108124 and batch: 500, loss is 4.552995843887329 and perplexity is 94.91633732805967
At time: 307.7816262245178 and batch: 550, loss is 4.545596361160278 and perplexity is 94.21659757827815
At time: 308.9193034172058 and batch: 600, loss is 4.4881228160858155 and perplexity is 88.95430545978029
At time: 310.05682253837585 and batch: 650, loss is 4.5094818496704105 and perplexity is 90.87471954352785
At time: 311.19442486763 and batch: 700, loss is 4.529630460739136 and perplexity is 92.72428948475101
At time: 312.3319470882416 and batch: 750, loss is 4.482244815826416 and perplexity is 88.43296574775583
At time: 313.4697780609131 and batch: 800, loss is 4.447501182556152 and perplexity is 85.4132450094462
At time: 314.6071343421936 and batch: 850, loss is 4.42151985168457 and perplexity is 83.22267541036435
At time: 315.74445724487305 and batch: 900, loss is 4.475307359695434 and perplexity is 87.82158907879959
At time: 316.8818473815918 and batch: 950, loss is 4.442650213241577 and perplexity is 84.99991132390339
At time: 318.01939392089844 and batch: 1000, loss is 4.4636616706848145 and perplexity is 86.8047783863282
At time: 319.1565971374512 and batch: 1050, loss is 4.400453262329101 and perplexity is 81.48779564357848
At time: 320.2951920032501 and batch: 1100, loss is 4.392065353393555 and perplexity is 80.80714205524448
At time: 321.4323675632477 and batch: 1150, loss is 4.418930416107178 and perplexity is 83.00745442450774
At time: 322.5699987411499 and batch: 1200, loss is 4.392998790740966 and perplexity is 80.88260567437736
At time: 323.70681977272034 and batch: 1250, loss is 4.457438411712647 and perplexity is 86.26624721793242
At time: 324.84363079071045 and batch: 1300, loss is 4.431727867126465 and perplexity is 84.07656460828184
At time: 325.9803841114044 and batch: 1350, loss is 4.408141851425171 and perplexity is 82.1167365564631
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.638514404296875 and perplexity of 103.39063674977524
Finished 10 epochs...
Completing Train Step...
At time: 329.37841176986694 and batch: 50, loss is 4.501684465408325 and perplexity is 90.16888982446261
At time: 330.5434904098511 and batch: 100, loss is 4.500417337417603 and perplexity is 90.05470665789473
At time: 331.68079662323 and batch: 150, loss is 4.459399223327637 and perplexity is 86.43556502336952
At time: 332.84621691703796 and batch: 200, loss is 4.4581632328033445 and perplexity is 86.32879747946723
At time: 333.983402967453 and batch: 250, loss is 4.468350286483765 and perplexity is 87.21272825445926
At time: 335.121239900589 and batch: 300, loss is 4.463603229522705 and perplexity is 86.79970556243494
At time: 336.25801825523376 and batch: 350, loss is 4.466026935577393 and perplexity is 87.01033768641827
At time: 337.39554810523987 and batch: 400, loss is 4.496171178817749 and perplexity is 89.67313077992311
At time: 338.53287267684937 and batch: 450, loss is 4.442208375930786 and perplexity is 84.962363487295
At time: 339.67043471336365 and batch: 500, loss is 4.510126266479492 and perplexity is 90.93329961328588
At time: 340.8079595565796 and batch: 550, loss is 4.503294458389282 and perplexity is 90.3141780292925
At time: 341.94595742225647 and batch: 600, loss is 4.446276798248291 and perplexity is 85.30873036867278
At time: 343.08294582366943 and batch: 650, loss is 4.465185556411743 and perplexity is 86.93715979058827
At time: 344.2203450202942 and batch: 700, loss is 4.4872223663330075 and perplexity is 88.87424262910551
At time: 345.35781931877136 and batch: 750, loss is 4.439988784790039 and perplexity is 84.77399091038919
At time: 346.4951856136322 and batch: 800, loss is 4.405743799209595 and perplexity is 81.92005225829175
At time: 347.63272404670715 and batch: 850, loss is 4.379533557891846 and perplexity is 79.80080226823219
At time: 348.77043414115906 and batch: 900, loss is 4.433050832748413 and perplexity is 84.18786862232811
At time: 349.9072480201721 and batch: 950, loss is 4.400137462615967 and perplexity is 81.46206588402946
At time: 351.04406452178955 and batch: 1000, loss is 4.42190354347229 and perplexity is 83.25461339425061
At time: 352.1812162399292 and batch: 1050, loss is 4.359567880630493 and perplexity is 78.22332530481147
At time: 353.3184037208557 and batch: 1100, loss is 4.352386960983276 and perplexity is 77.66362188900555
At time: 354.45518612861633 and batch: 1150, loss is 4.37779803276062 and perplexity is 79.66242608281034
At time: 355.5923843383789 and batch: 1200, loss is 4.3515108203887936 and perplexity is 77.5956074366162
At time: 356.72948145866394 and batch: 1250, loss is 4.4166976165771485 and perplexity is 82.82232217778962
At time: 357.8665907382965 and batch: 1300, loss is 4.391148557662964 and perplexity is 80.73309236181504
At time: 359.0042176246643 and batch: 1350, loss is 4.36700740814209 and perplexity is 78.80743995992916
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.631710205078125 and perplexity of 102.68953418565336
Finished 11 epochs...
Completing Train Step...
At time: 362.4195947647095 and batch: 50, loss is 4.461160821914673 and perplexity is 86.58796398607228
At time: 363.58628845214844 and batch: 100, loss is 4.460344820022583 and perplexity is 86.51733686347929
At time: 364.72464084625244 and batch: 150, loss is 4.421025638580322 and perplexity is 83.18155583535933
At time: 365.86272978782654 and batch: 200, loss is 4.418920726776123 and perplexity is 83.00665014169829
At time: 367.0020134449005 and batch: 250, loss is 4.427685604095459 and perplexity is 83.73739099570757
At time: 368.1398766040802 and batch: 300, loss is 4.424708127975464 and perplexity is 83.48843572677447
At time: 369.2781431674957 and batch: 350, loss is 4.427442598342895 and perplexity is 83.71704480021232
At time: 370.4161891937256 and batch: 400, loss is 4.455489625930786 and perplexity is 86.09829648505293
At time: 371.554119348526 and batch: 450, loss is 4.400661897659302 and perplexity is 81.5047986503822
At time: 372.6919958591461 and batch: 500, loss is 4.469513492584229 and perplexity is 87.31423365640919
At time: 373.8300154209137 and batch: 550, loss is 4.464665546417236 and perplexity is 86.89196335092171
At time: 374.96782636642456 and batch: 600, loss is 4.407666721343994 and perplexity is 82.07772969215817
At time: 376.1056296825409 and batch: 650, loss is 4.427021512985229 and perplexity is 83.6818001994733
At time: 377.2438027858734 and batch: 700, loss is 4.447877264022827 and perplexity is 85.44537338896814
At time: 378.3817641735077 and batch: 750, loss is 4.402950677871704 and perplexity is 81.6915588657629
At time: 379.5198211669922 and batch: 800, loss is 4.367908515930176 and perplexity is 78.87848596308211
At time: 380.65809321403503 and batch: 850, loss is 4.341609373092651 and perplexity is 76.83108978082187
At time: 381.7968981266022 and batch: 900, loss is 4.39387466430664 and perplexity is 80.95347964439783
At time: 382.9355049133301 and batch: 950, loss is 4.361512784957886 and perplexity is 78.37561023050189
At time: 384.0738751888275 and batch: 1000, loss is 4.3835274028778075 and perplexity is 80.12015159360824
At time: 385.21214532852173 and batch: 1050, loss is 4.322141094207764 and perplexity is 75.3497866946437
At time: 386.3500053882599 and batch: 1100, loss is 4.313140926361084 and perplexity is 74.67466861241942
At time: 387.48771572113037 and batch: 1150, loss is 4.339369039535523 and perplexity is 76.65915517949665
At time: 388.62577390670776 and batch: 1200, loss is 4.31253173828125 and perplexity is 74.62919154788446
At time: 389.79230284690857 and batch: 1250, loss is 4.380254163742065 and perplexity is 79.85832791736921
At time: 390.93070578575134 and batch: 1300, loss is 4.354618873596191 and perplexity is 77.83715388835682
At time: 392.069055557251 and batch: 1350, loss is 4.331440315246582 and perplexity is 76.05374909437232
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.626286214192708 and perplexity of 102.13405490730848
Finished 12 epochs...
Completing Train Step...
At time: 395.4879584312439 and batch: 50, loss is 4.422840852737426 and perplexity is 83.33268529779384
At time: 396.62820982933044 and batch: 100, loss is 4.422621746063232 and perplexity is 83.3144285504272
At time: 397.76920676231384 and batch: 150, loss is 4.385121259689331 and perplexity is 80.24795346485209
At time: 398.9093301296234 and batch: 200, loss is 4.381036796569824 and perplexity is 79.92085212992653
At time: 400.0499978065491 and batch: 250, loss is 4.389185619354248 and perplexity is 80.5747737177378
At time: 401.1906371116638 and batch: 300, loss is 4.389714250564575 and perplexity is 80.61737931822292
At time: 402.3313789367676 and batch: 350, loss is 4.391625852584839 and perplexity is 80.77163505421053
At time: 403.47262692451477 and batch: 400, loss is 4.419482679367065 and perplexity is 83.05330905263094
At time: 404.61402010917664 and batch: 450, loss is 4.363214960098267 and perplexity is 78.50913285305381
At time: 405.7548360824585 and batch: 500, loss is 4.433639945983887 and perplexity is 84.23747942175436
At time: 406.89528226852417 and batch: 550, loss is 4.428645296096802 and perplexity is 83.81779167383247
At time: 408.03614377975464 and batch: 600, loss is 4.372957181930542 and perplexity is 79.2777240551996
At time: 409.1774003505707 and batch: 650, loss is 4.390865955352783 and perplexity is 80.71028022693838
At time: 410.31781244277954 and batch: 700, loss is 4.411576833724975 and perplexity is 82.39929110015628
At time: 411.4592146873474 and batch: 750, loss is 4.3672945594787596 and perplexity is 78.83007287103297
At time: 412.6004581451416 and batch: 800, loss is 4.334118452072143 and perplexity is 76.25770442878549
At time: 413.74130034446716 and batch: 850, loss is 4.304942607879639 and perplexity is 74.06496458550455
At time: 414.8817603588104 and batch: 900, loss is 4.357331705093384 and perplexity is 78.04859964976063
At time: 416.02283477783203 and batch: 950, loss is 4.325649929046631 and perplexity is 75.61464104464557
At time: 417.1633987426758 and batch: 1000, loss is 4.348753728866577 and perplexity is 77.38196389792135
At time: 418.3042063713074 and batch: 1050, loss is 4.286923341751098 and perplexity is 72.74232060248062
At time: 419.4762828350067 and batch: 1100, loss is 4.278059253692627 and perplexity is 72.10037559884258
At time: 420.6161298751831 and batch: 1150, loss is 4.303414192199707 and perplexity is 73.9518489981375
At time: 421.75682163238525 and batch: 1200, loss is 4.276380977630615 and perplexity is 71.97947274697208
At time: 422.89717078208923 and batch: 1250, loss is 4.346098203659057 and perplexity is 77.1767467424438
At time: 424.03726387023926 and batch: 1300, loss is 4.3198619556427005 and perplexity is 75.17824964252776
At time: 425.17768001556396 and batch: 1350, loss is 4.296693687438965 and perplexity is 73.45652153446366
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.624921468098958 and perplexity of 101.99476292554853
Finished 13 epochs...
Completing Train Step...
At time: 428.60132813453674 and batch: 50, loss is 4.388314838409424 and perplexity is 80.5046412795778
At time: 429.7417573928833 and batch: 100, loss is 4.388157558441162 and perplexity is 80.49198050782142
At time: 430.88302516937256 and batch: 150, loss is 4.352047510147095 and perplexity is 77.63726338157626
At time: 432.0242898464203 and batch: 200, loss is 4.345712804794312 and perplexity is 77.14700864274755
At time: 433.1655521392822 and batch: 250, loss is 4.354109268188477 and perplexity is 77.79749775916139
At time: 434.30581045150757 and batch: 300, loss is 4.356802206039429 and perplexity is 78.00728392936632
At time: 435.44661569595337 and batch: 350, loss is 4.358408632278443 and perplexity is 78.13269758402717
At time: 436.5877709388733 and batch: 400, loss is 4.385306663513184 and perplexity is 80.26283312161083
At time: 437.72874784469604 and batch: 450, loss is 4.330449275970459 and perplexity is 75.97841417801973
At time: 438.8701093196869 and batch: 500, loss is 4.401003322601318 and perplexity is 81.53263117262374
At time: 440.01189708709717 and batch: 550, loss is 4.397100191116333 and perplexity is 81.21501883741327
At time: 441.1532852649689 and batch: 600, loss is 4.340988712310791 and perplexity is 76.78341853193498
At time: 442.29371213912964 and batch: 650, loss is 4.35805115699768 and perplexity is 78.10477206765987
At time: 443.4344744682312 and batch: 700, loss is 4.377924327850342 and perplexity is 79.6724876914124
At time: 444.5756974220276 and batch: 750, loss is 4.333005199432373 and perplexity is 76.17285757478218
At time: 445.716876745224 and batch: 800, loss is 4.300794801712036 and perplexity is 73.75839370641296
At time: 446.8578636646271 and batch: 850, loss is 4.27260383605957 and perplexity is 71.70810890065435
At time: 448.02597093582153 and batch: 900, loss is 4.325410013198852 and perplexity is 75.59650206993561
At time: 449.166699886322 and batch: 950, loss is 4.292912149429322 and perplexity is 73.17926746003036
At time: 450.30780696868896 and batch: 1000, loss is 4.317130374908447 and perplexity is 74.97317440147275
At time: 451.4488968849182 and batch: 1050, loss is 4.253879261016846 and perplexity is 70.37789771910401
At time: 452.59027123451233 and batch: 1100, loss is 4.245417442321777 and perplexity is 69.7848852289736
At time: 453.7311749458313 and batch: 1150, loss is 4.270183048248291 and perplexity is 71.53472872763295
At time: 454.8728218078613 and batch: 1200, loss is 4.242712283134461 and perplexity is 69.5963611143974
At time: 456.0135221481323 and batch: 1250, loss is 4.314426984786987 and perplexity is 74.77076637961655
At time: 457.1547236442566 and batch: 1300, loss is 4.287236289978027 and perplexity is 72.76508874517499
At time: 458.295615196228 and batch: 1350, loss is 4.264540987014771 and perplexity is 71.13226184685985
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.622967936197917 and perplexity of 101.79570739640182
Finished 14 epochs...
Completing Train Step...
At time: 461.6872148513794 and batch: 50, loss is 4.354968910217285 and perplexity is 77.8644045117793
At time: 462.85484766960144 and batch: 100, loss is 4.355958404541016 and perplexity is 77.94148902912113
At time: 463.9954330921173 and batch: 150, loss is 4.321437635421753 and perplexity is 75.29679986438003
At time: 465.1361298561096 and batch: 200, loss is 4.312581281661988 and perplexity is 74.63288902192737
At time: 466.2769446372986 and batch: 250, loss is 4.3216712474823 and perplexity is 75.31439215975512
At time: 467.4186432361603 and batch: 300, loss is 4.326430206298828 and perplexity is 75.67366445330269
At time: 468.55976033210754 and batch: 350, loss is 4.326564607620239 and perplexity is 75.68383577730559
At time: 469.70081877708435 and batch: 400, loss is 4.353134307861328 and perplexity is 77.7216852483952
At time: 470.84186840057373 and batch: 450, loss is 4.300163459777832 and perplexity is 73.7118416361499
At time: 471.9829452037811 and batch: 500, loss is 4.3693710136413575 and perplexity is 78.99392996598267
At time: 473.12487626075745 and batch: 550, loss is 4.366856927871704 and perplexity is 78.79558188728093
At time: 474.2668206691742 and batch: 600, loss is 4.309915790557861 and perplexity is 74.43422061222915
At time: 475.40813398361206 and batch: 650, loss is 4.32776074886322 and perplexity is 75.77441849877023
At time: 476.57786655426025 and batch: 700, loss is 4.346663217544556 and perplexity is 77.22036499729035
At time: 477.7189781665802 and batch: 750, loss is 4.301729011535644 and perplexity is 73.8273317186574
At time: 478.8602080345154 and batch: 800, loss is 4.269785213470459 and perplexity is 71.50627538496222
At time: 480.0013539791107 and batch: 850, loss is 4.241416878700257 and perplexity is 69.50626404827393
At time: 481.1429970264435 and batch: 900, loss is 4.295307970046997 and perplexity is 73.35480204852718
At time: 482.28444647789 and batch: 950, loss is 4.262367811203003 and perplexity is 70.97784678229081
At time: 483.42577838897705 and batch: 1000, loss is 4.28684736251831 and perplexity is 72.73679390672973
At time: 484.5667917728424 and batch: 1050, loss is 4.222681245803833 and perplexity is 68.21614355145144
At time: 485.70771193504333 and batch: 1100, loss is 4.213962726593017 and perplexity is 67.62398491757689
At time: 486.84921860694885 and batch: 1150, loss is 4.238251504898071 and perplexity is 69.28659858603058
At time: 487.9914891719818 and batch: 1200, loss is 4.211206359863281 and perplexity is 67.43784506811265
At time: 489.1376004219055 and batch: 1250, loss is 4.283795480728149 and perplexity is 72.51514820021254
At time: 490.2780840396881 and batch: 1300, loss is 4.257099838256836 and perplexity is 70.60492055075318
At time: 491.4182302951813 and batch: 1350, loss is 4.233945960998535 and perplexity is 68.98892338085197
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.62198974609375 and perplexity of 101.69618052881455
Finished 15 epochs...
Completing Train Step...
At time: 494.8068940639496 and batch: 50, loss is 4.324059886932373 and perplexity is 75.49450611603878
At time: 495.9723331928253 and batch: 100, loss is 4.324395303726196 and perplexity is 75.51983248843935
At time: 497.1094102859497 and batch: 150, loss is 4.292499504089355 and perplexity is 73.14907660581689
At time: 498.24676609039307 and batch: 200, loss is 4.2823491954803465 and perplexity is 72.41034641603372
At time: 499.38420820236206 and batch: 250, loss is 4.291468014717102 and perplexity is 73.07366301155484
At time: 500.5217475891113 and batch: 300, loss is 4.2975282382965085 and perplexity is 73.51785032494027
At time: 501.6596851348877 and batch: 350, loss is 4.297636470794678 and perplexity is 73.5258077761606
At time: 502.79746747016907 and batch: 400, loss is 4.3239332294464115 and perplexity is 75.48494477721056
At time: 503.93565678596497 and batch: 450, loss is 4.268550844192505 and perplexity is 71.41806468893299
At time: 505.07259821891785 and batch: 500, loss is 4.339882879257202 and perplexity is 76.69855582039854
At time: 506.2374749183655 and batch: 550, loss is 4.337902297973633 and perplexity is 76.54679842979584
At time: 507.37497210502625 and batch: 600, loss is 4.2819615077972415 and perplexity is 72.38227925759621
At time: 508.51298689842224 and batch: 650, loss is 4.298836522102356 and perplexity is 73.61409548222359
At time: 509.6508524417877 and batch: 700, loss is 4.316952438354492 and perplexity is 74.95983511998875
At time: 510.7890238761902 and batch: 750, loss is 4.273247303962708 and perplexity is 71.75426561571636
At time: 511.9259557723999 and batch: 800, loss is 4.241416940689087 and perplexity is 69.50626835688605
At time: 513.063482761383 and batch: 850, loss is 4.212946190834045 and perplexity is 67.55527764635954
At time: 514.2009909152985 and batch: 900, loss is 4.265291423797607 and perplexity is 71.18566214686471
At time: 515.3385021686554 and batch: 950, loss is 4.233762798309326 and perplexity is 68.9762883412891
At time: 516.4762723445892 and batch: 1000, loss is 4.2591157817840575 and perplexity is 70.74739964998315
At time: 517.6138045787811 and batch: 1050, loss is 4.195047092437744 and perplexity is 66.35685640984568
At time: 518.7510049343109 and batch: 1100, loss is 4.185509419441223 and perplexity is 65.72697498871429
At time: 519.8886983394623 and batch: 1150, loss is 4.208859972953796 and perplexity is 67.27979528672232
At time: 521.0259351730347 and batch: 1200, loss is 4.181918153762817 and perplexity is 65.49135529898027
At time: 522.1632943153381 and batch: 1250, loss is 4.255297145843506 and perplexity is 70.47775624963016
At time: 523.3010475635529 and batch: 1300, loss is 4.228782644271851 and perplexity is 68.63362975490345
At time: 524.4397621154785 and batch: 1350, loss is 4.205053510665894 and perplexity is 67.02418407906924
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.623508707682292 and perplexity of 101.85077049912962
Annealing...
Finished 16 epochs...
Completing Train Step...
At time: 527.8465638160706 and batch: 50, loss is 4.314294042587281 and perplexity is 74.76082685016638
At time: 528.9837076663971 and batch: 100, loss is 4.3308315849304195 and perplexity is 76.00746695973912
At time: 530.1214849948883 and batch: 150, loss is 4.304266300201416 and perplexity is 74.01489081581414
At time: 531.2595942020416 and batch: 200, loss is 4.296415891647339 and perplexity is 73.43611845598977
At time: 532.39679646492 and batch: 250, loss is 4.298596572875977 and perplexity is 73.59643395598157
At time: 533.5342664718628 and batch: 300, loss is 4.308018531799316 and perplexity is 74.2931335169221
At time: 534.6990623474121 and batch: 350, loss is 4.297886571884155 and perplexity is 73.5441989605219
At time: 535.836110830307 and batch: 400, loss is 4.320041313171386 and perplexity is 75.19173463687606
At time: 536.9742176532745 and batch: 450, loss is 4.2555622959136965 and perplexity is 70.49644590931943
At time: 538.1119267940521 and batch: 500, loss is 4.328936576843262 and perplexity is 75.86356858252256
At time: 539.2493758201599 and batch: 550, loss is 4.3208482837677 and perplexity is 75.25243664488752
At time: 540.386461019516 and batch: 600, loss is 4.264720067977906 and perplexity is 71.14500142149497
At time: 541.5234475135803 and batch: 650, loss is 4.282191128730774 and perplexity is 72.39890165248241
At time: 542.660561800003 and batch: 700, loss is 4.286678981781006 and perplexity is 72.72454746280413
At time: 543.798291683197 and batch: 750, loss is 4.2364270210266115 and perplexity is 69.16030155288627
At time: 544.9358389377594 and batch: 800, loss is 4.203073706626892 and perplexity is 66.89162059687735
At time: 546.0733909606934 and batch: 850, loss is 4.1651546049118044 and perplexity is 64.40263863807088
At time: 547.2117190361023 and batch: 900, loss is 4.207134761810303 and perplexity is 67.16382350083481
At time: 548.3491299152374 and batch: 950, loss is 4.167714743614197 and perplexity is 64.56772956344673
At time: 549.4875257015228 and batch: 1000, loss is 4.186265292167664 and perplexity is 65.77667499757402
At time: 550.6255719661713 and batch: 1050, loss is 4.11581974029541 and perplexity is 61.30244575654316
At time: 551.7636680603027 and batch: 1100, loss is 4.09583683013916 and perplexity is 60.089602914172836
At time: 552.9016354084015 and batch: 1150, loss is 4.111739411354065 and perplexity is 61.05282123436352
At time: 554.0396065711975 and batch: 1200, loss is 4.0728272485733035 and perplexity is 58.72275193424397
At time: 555.177191734314 and batch: 1250, loss is 4.133947958946228 and perplexity is 62.42388402454123
At time: 556.3152656555176 and batch: 1300, loss is 4.107736735343933 and perplexity is 60.808934995872704
At time: 557.4533281326294 and batch: 1350, loss is 4.079023728370666 and perplexity is 59.087755982453864
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.581007486979167 and perplexity of 97.61268819614175
Finished 17 epochs...
Completing Train Step...
At time: 560.8727757930756 and batch: 50, loss is 4.29025369644165 and perplexity is 72.98498218137922
At time: 562.0097017288208 and batch: 100, loss is 4.296412830352783 and perplexity is 73.43589364674426
At time: 563.1744847297668 and batch: 150, loss is 4.261389417648315 and perplexity is 70.90843647530886
At time: 564.3119475841522 and batch: 200, loss is 4.255004587173462 and perplexity is 70.45714038681587
At time: 565.4501888751984 and batch: 250, loss is 4.258730878829956 and perplexity is 70.72017400681426
At time: 566.5881979465485 and batch: 300, loss is 4.26689998626709 and perplexity is 71.30026087625691
At time: 567.7255318164825 and batch: 350, loss is 4.257519826889038 and perplexity is 70.63458004265081
At time: 568.8631203174591 and batch: 400, loss is 4.282224073410034 and perplexity is 72.40128685036571
At time: 570.0003461837769 and batch: 450, loss is 4.219372296333313 and perplexity is 67.99079282207077
At time: 571.138325214386 and batch: 500, loss is 4.293544311523437 and perplexity is 73.22554324435099
At time: 572.2758686542511 and batch: 550, loss is 4.28788571357727 and perplexity is 72.8123594587042
At time: 573.4144186973572 and batch: 600, loss is 4.232940473556519 and perplexity is 68.91959074714184
At time: 574.5519907474518 and batch: 650, loss is 4.2517199087142945 and perplexity is 70.22609100469175
At time: 575.6897263526917 and batch: 700, loss is 4.258556580543518 and perplexity is 70.70784867584148
At time: 576.8274564743042 and batch: 750, loss is 4.2111199712753296 and perplexity is 67.43201945953938
At time: 577.9652488231659 and batch: 800, loss is 4.179003000259399 and perplexity is 65.30071595162384
At time: 579.1026828289032 and batch: 850, loss is 4.14392493724823 and perplexity is 63.049802958799766
At time: 580.2413203716278 and batch: 900, loss is 4.1896820688247685 and perplexity is 66.00180359333373
At time: 581.3783173561096 and batch: 950, loss is 4.152859025001526 and perplexity is 63.61561919369095
At time: 582.5158975124359 and batch: 1000, loss is 4.17392698764801 and perplexity is 64.97008853828976
At time: 583.6533260345459 and batch: 1050, loss is 4.106441512107849 and perplexity is 60.730224834922886
At time: 584.7908926010132 and batch: 1100, loss is 4.090345687866211 and perplexity is 59.76054662970898
At time: 585.9285876750946 and batch: 1150, loss is 4.109154076576233 and perplexity is 60.8951831138031
At time: 587.0670809745789 and batch: 1200, loss is 4.0737701559066775 and perplexity is 58.7781481603283
At time: 588.2046773433685 and batch: 1250, loss is 4.139179844856262 and perplexity is 62.75133450867447
At time: 589.3423981666565 and batch: 1300, loss is 4.115673246383667 and perplexity is 61.293465979222304
At time: 590.4796595573425 and batch: 1350, loss is 4.090588126182556 and perplexity is 59.77503663241271
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.578197835286458 and perplexity of 97.33881546517851
Finished 18 epochs...
Completing Train Step...
At time: 593.8705444335938 and batch: 50, loss is 4.277409753799438 and perplexity is 72.05356161707607
At time: 595.0365648269653 and batch: 100, loss is 4.280915851593018 and perplexity is 72.30663183570539
At time: 596.1755692958832 and batch: 150, loss is 4.24487566947937 and perplexity is 69.7470879130502
At time: 597.3140165805817 and batch: 200, loss is 4.23784752368927 and perplexity is 69.25861375523358
At time: 598.452394247055 and batch: 250, loss is 4.2419370174407955 and perplexity is 69.54242635280804
At time: 599.5903205871582 and batch: 300, loss is 4.249989790916443 and perplexity is 70.10469663832878
At time: 600.7287030220032 and batch: 350, loss is 4.241054191589355 and perplexity is 69.4810595931185
At time: 601.8674812316895 and batch: 400, loss is 4.266371660232544 and perplexity is 71.26260104137766
At time: 603.0061206817627 and batch: 450, loss is 4.203739762306213 and perplexity is 66.93618898154011
At time: 604.1442306041718 and batch: 500, loss is 4.27824140548706 and perplexity is 72.113510007829
At time: 605.282418012619 and batch: 550, loss is 4.273671255111695 and perplexity is 71.78469236834148
At time: 606.421225309372 and batch: 600, loss is 4.218555879592896 and perplexity is 67.93530665361692
At time: 607.5608479976654 and batch: 650, loss is 4.238173604011536 and perplexity is 69.2812013088048
At time: 608.7004823684692 and batch: 700, loss is 4.246266512870789 and perplexity is 69.8441626815961
At time: 609.8387742042542 and batch: 750, loss is 4.199576015472412 and perplexity is 66.65806306137863
At time: 610.9772727489471 and batch: 800, loss is 4.1680665731430055 and perplexity is 64.59045039401046
At time: 612.1156535148621 and batch: 850, loss is 4.134125494956971 and perplexity is 62.4349674957145
At time: 613.2543385028839 and batch: 900, loss is 4.18111629486084 and perplexity is 65.43886152184517
At time: 614.3926346302032 and batch: 950, loss is 4.145791602134705 and perplexity is 63.16760572702121
At time: 615.531049489975 and batch: 1000, loss is 4.16795735836029 and perplexity is 64.58339654720437
At time: 616.6694118976593 and batch: 1050, loss is 4.10145519733429 and perplexity is 60.42815854230007
At time: 617.8076198101044 and batch: 1100, loss is 4.086736326217651 and perplexity is 59.545238001703225
At time: 618.9460301399231 and batch: 1150, loss is 4.1068248414993285 and perplexity is 60.75350897751627
At time: 620.0853190422058 and batch: 1200, loss is 4.073020105361938 and perplexity is 58.734078107731435
At time: 621.2522239685059 and batch: 1250, loss is 4.139975891113282 and perplexity is 62.801307361345316
At time: 622.3907594680786 and batch: 1300, loss is 4.117569742202758 and perplexity is 61.40981907789819
At time: 623.5293655395508 and batch: 1350, loss is 4.093711876869202 and perplexity is 59.96205088501657
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.577270914713542 and perplexity of 97.24863191753036
Finished 19 epochs...
Completing Train Step...
At time: 626.9238255023956 and batch: 50, loss is 4.266946420669556 and perplexity is 71.30357173813474
At time: 628.091272354126 and batch: 100, loss is 4.269328470230103 and perplexity is 71.47362283452058
At time: 629.2323923110962 and batch: 150, loss is 4.233222436904907 and perplexity is 68.93902628564449
At time: 630.3734731674194 and batch: 200, loss is 4.225649995803833 and perplexity is 68.41896113601123
At time: 631.5143673419952 and batch: 250, loss is 4.23008517742157 and perplexity is 68.72308557978592
At time: 632.6553988456726 and batch: 300, loss is 4.2382035827636715 and perplexity is 69.28327830389921
At time: 633.7958834171295 and batch: 350, loss is 4.229981060028076 and perplexity is 68.71593068372354
At time: 634.9368543624878 and batch: 400, loss is 4.255452690124511 and perplexity is 70.48871951416734
At time: 636.0785460472107 and batch: 450, loss is 4.192979707717895 and perplexity is 66.21981296841633
At time: 637.2197730541229 and batch: 500, loss is 4.267711610794067 and perplexity is 71.35815340708496
At time: 638.3610143661499 and batch: 550, loss is 4.2636778450012205 and perplexity is 71.07089109278928
At time: 639.5021076202393 and batch: 600, loss is 4.208466401100159 and perplexity is 67.25332106307538
At time: 640.6431829929352 and batch: 650, loss is 4.228683686256408 and perplexity is 68.6268382431531
At time: 641.7839829921722 and batch: 700, loss is 4.237697138786316 and perplexity is 69.2481990884492
At time: 642.9253842830658 and batch: 750, loss is 4.191506361961364 and perplexity is 66.12232012594995
At time: 644.0663733482361 and batch: 800, loss is 4.160525455474853 and perplexity is 64.10519817900281
At time: 645.2075393199921 and batch: 850, loss is 4.1271318387985225 and perplexity is 61.999842132913706
At time: 646.3485040664673 and batch: 900, loss is 4.17476815700531 and perplexity is 65.02476237766462
At time: 647.4900979995728 and batch: 950, loss is 4.14029450416565 and perplexity is 62.821319865529645
At time: 648.6310498714447 and batch: 1000, loss is 4.163006024360657 and perplexity is 64.26441292896108
At time: 649.8003666400909 and batch: 1050, loss is 4.0971304798126225 and perplexity is 60.167388111911066
At time: 650.9418103694916 and batch: 1100, loss is 4.083008193969727 and perplexity is 59.32365877467315
At time: 652.0831246376038 and batch: 1150, loss is 4.103778443336487 and perplexity is 60.56871122606482
At time: 653.223849773407 and batch: 1200, loss is 4.070773229598999 and perplexity is 58.6022580782445
At time: 654.3647658824921 and batch: 1250, loss is 4.138713603019714 and perplexity is 62.72208403065551
At time: 655.5058243274689 and batch: 1300, loss is 4.116882538795471 and perplexity is 61.36763253801413
At time: 656.6471095085144 and batch: 1350, loss is 4.0936880731582646 and perplexity is 59.9606235826777
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.577031656901042 and perplexity of 97.22536720583216
Finished 20 epochs...
Completing Train Step...
At time: 660.0684452056885 and batch: 50, loss is 4.258218812942505 and perplexity is 70.68396988838884
At time: 661.2094240188599 and batch: 100, loss is 4.259697389602661 and perplexity is 70.78855885886408
At time: 662.3516850471497 and batch: 150, loss is 4.223775081634521 and perplexity is 68.2908016379005
At time: 663.4930906295776 and batch: 200, loss is 4.21587739944458 and perplexity is 67.75358675858327
At time: 664.63503241539 and batch: 250, loss is 4.2205011892318725 and perplexity is 68.06759048526742
At time: 665.7765412330627 and batch: 300, loss is 4.228876552581787 and perplexity is 68.64007532572012
At time: 666.917763710022 and batch: 350, loss is 4.220963311195374 and perplexity is 68.0990532830983
At time: 668.0604512691498 and batch: 400, loss is 4.246531200408936 and perplexity is 69.8626520079094
At time: 669.2023458480835 and batch: 450, loss is 4.184221119880676 and perplexity is 65.64235347635282
At time: 670.3448114395142 and batch: 500, loss is 4.2592637252807615 and perplexity is 70.75786704194228
At time: 671.4873294830322 and batch: 550, loss is 4.25557222366333 and perplexity is 70.49714578385858
At time: 672.6289188861847 and batch: 600, loss is 4.200362062454223 and perplexity is 66.71048002906211
At time: 673.7704365253448 and batch: 650, loss is 4.2214432716369625 and perplexity is 68.1317459797568
At time: 674.9125809669495 and batch: 700, loss is 4.2305486249923705 and perplexity is 68.75494250829367
At time: 676.0547223091125 and batch: 750, loss is 4.184777703285217 and perplexity is 65.67889909033046
At time: 677.1963837146759 and batch: 800, loss is 4.154201207160949 and perplexity is 63.70106026875022
At time: 678.37832903862 and batch: 850, loss is 4.121278734207153 and perplexity is 61.638010524379446
At time: 679.5229678153992 and batch: 900, loss is 4.169269666671753 and perplexity is 64.66820551085856
At time: 680.6661996841431 and batch: 950, loss is 4.135488362312317 and perplexity is 62.520116084683
At time: 681.8081977367401 and batch: 1000, loss is 4.158409080505371 and perplexity is 63.969671005907486
At time: 682.9631009101868 and batch: 1050, loss is 4.092954168319702 and perplexity is 59.9166343348425
At time: 684.105072259903 and batch: 1100, loss is 4.079095959663391 and perplexity is 59.09202412159743
At time: 685.2467887401581 and batch: 1150, loss is 4.100407118797302 and perplexity is 60.36485826392822
At time: 686.3907806873322 and batch: 1200, loss is 4.067952694892884 and perplexity is 58.437201259146065
At time: 687.5346076488495 and batch: 1250, loss is 4.136474852561951 and perplexity is 62.58182200074463
At time: 688.6792097091675 and batch: 1300, loss is 4.114970345497131 and perplexity is 61.25039788572039
At time: 689.8260180950165 and batch: 1350, loss is 4.092347598075866 and perplexity is 59.88030170760347
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.576998697916666 and perplexity of 97.22216280928065
Finished 21 epochs...
Completing Train Step...
At time: 693.2702164649963 and batch: 50, loss is 4.250424032211304 and perplexity is 70.13514560319332
At time: 694.4149572849274 and batch: 100, loss is 4.25140230178833 and perplexity is 70.20379025342923
At time: 695.559446811676 and batch: 150, loss is 4.215714368820191 and perplexity is 67.74254174939121
At time: 696.7045729160309 and batch: 200, loss is 4.207427110671997 and perplexity is 67.18346163863606
At time: 697.8515501022339 and batch: 250, loss is 4.21237099647522 and perplexity is 67.51643140488898
At time: 698.9974417686462 and batch: 300, loss is 4.220840549468994 and perplexity is 68.09069383887282
At time: 700.1430249214172 and batch: 350, loss is 4.213291845321655 and perplexity is 67.57863246735657
At time: 701.2889456748962 and batch: 400, loss is 4.238985290527344 and perplexity is 69.33745875432243
At time: 702.4347641468048 and batch: 450, loss is 4.17689368724823 and perplexity is 65.16312146776139
At time: 703.5808825492859 and batch: 500, loss is 4.251996917724609 and perplexity is 70.24554695927219
At time: 704.7265827655792 and batch: 550, loss is 4.248381099700928 and perplexity is 69.99201049158911
At time: 705.8715369701385 and batch: 600, loss is 4.1933106470108035 and perplexity is 66.24173133312063
At time: 707.0157148838043 and batch: 650, loss is 4.214736981391907 and perplexity is 67.67636338694336
At time: 708.1893305778503 and batch: 700, loss is 4.224264736175537 and perplexity is 68.3242487271234
At time: 709.3348996639252 and batch: 750, loss is 4.178818445205689 and perplexity is 65.28866548650538
At time: 710.4802160263062 and batch: 800, loss is 4.148492798805237 and perplexity is 63.33846451099702
At time: 711.6257612705231 and batch: 850, loss is 4.115861549377441 and perplexity is 61.305008809105566
At time: 712.7715666294098 and batch: 900, loss is 4.16423547744751 and perplexity is 64.34347159931606
At time: 713.9170610904694 and batch: 950, loss is 4.130885591506958 and perplexity is 62.23301156464313
At time: 715.0628170967102 and batch: 1000, loss is 4.153876242637634 and perplexity is 63.68036304717881
At time: 716.2067730426788 and batch: 1050, loss is 4.08880250453949 and perplexity is 59.66839627128993
At time: 717.3522543907166 and batch: 1100, loss is 4.075082025527954 and perplexity is 58.855308028071946
At time: 718.4971675872803 and batch: 1150, loss is 4.09687036037445 and perplexity is 60.151739440069214
At time: 719.643413066864 and batch: 1200, loss is 4.064572625160217 and perplexity is 58.24001288687027
At time: 720.7883534431458 and batch: 1250, loss is 4.133629508018494 and perplexity is 62.404008245658915
At time: 721.9336416721344 and batch: 1300, loss is 4.1124013233184815 and perplexity is 61.09324620460974
At time: 723.0787599086761 and batch: 1350, loss is 4.090156478881836 and perplexity is 59.74924046702297
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.5771781412760415 and perplexity of 97.23961024614738
Annealing...
Finished 22 epochs...
Completing Train Step...
At time: 726.5119044780731 and batch: 50, loss is 4.252061862945556 and perplexity is 70.25010921998691
At time: 727.6837792396545 and batch: 100, loss is 4.265687046051025 and perplexity is 71.213830350551
At time: 728.8233425617218 and batch: 150, loss is 4.237781658172607 and perplexity is 69.25405215108309
At time: 729.9626832008362 and batch: 200, loss is 4.233128657341004 and perplexity is 68.9325615169598
At time: 731.1033613681793 and batch: 250, loss is 4.2379079437255855 and perplexity is 69.26279848961147
At time: 732.2441523075104 and batch: 300, loss is 4.244527630805969 and perplexity is 69.72281745287373
At time: 733.3860468864441 and batch: 350, loss is 4.237358150482177 and perplexity is 69.22472873718762
At time: 734.5279853343964 and batch: 400, loss is 4.262571611404419 and perplexity is 70.99231355587675
At time: 735.6685616970062 and batch: 450, loss is 4.196250720024109 and perplexity is 66.4367734382869
At time: 736.8391442298889 and batch: 500, loss is 4.270955142974853 and perplexity is 71.58998164194666
At time: 737.9809417724609 and batch: 550, loss is 4.265817861557007 and perplexity is 71.22314683315815
At time: 739.1226353645325 and batch: 600, loss is 4.213986964225769 and perplexity is 67.62562398275196
At time: 740.2631723880768 and batch: 650, loss is 4.231516027450562 and perplexity is 68.82148839182481
At time: 741.4068133831024 and batch: 700, loss is 4.23627628326416 and perplexity is 69.14987726946602
At time: 742.548476934433 and batch: 750, loss is 4.188359990119934 and perplexity is 65.91460167092626
At time: 743.6896634101868 and batch: 800, loss is 4.154761500358582 and perplexity is 63.736761540156564
At time: 744.8324909210205 and batch: 850, loss is 4.116855030059814 and perplexity is 61.365944415251946
At time: 745.9723107814789 and batch: 900, loss is 4.161187272071839 and perplexity is 64.14763810528547
At time: 747.1099877357483 and batch: 950, loss is 4.125493936538696 and perplexity is 61.898375570215386
At time: 748.2475852966309 and batch: 1000, loss is 4.1486027050018315 and perplexity is 63.345426183288005
At time: 749.3858380317688 and batch: 1050, loss is 4.0801907682418825 and perplexity is 59.15675400347569
At time: 750.5236344337463 and batch: 1100, loss is 4.059739780426026 and perplexity is 57.95922699110144
At time: 751.661630153656 and batch: 1150, loss is 4.077820844650269 and perplexity is 59.01672301347372
At time: 752.7991178035736 and batch: 1200, loss is 4.045505814552307 and perplexity is 57.14008101027413
At time: 753.9368913173676 and batch: 1250, loss is 4.109129023551941 and perplexity is 60.89365752441171
At time: 755.0746550559998 and batch: 1300, loss is 4.0861236143112185 and perplexity is 59.50876510023974
At time: 756.2130901813507 and batch: 1350, loss is 4.064065408706665 and perplexity is 58.21048008447379
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.562310791015625 and perplexity of 95.8046086693695
Finished 23 epochs...
Completing Train Step...
At time: 759.597546339035 and batch: 50, loss is 4.249750719070435 and perplexity is 70.08793858235913
At time: 760.7624974250793 and batch: 100, loss is 4.256817226409912 and perplexity is 70.58496958307713
At time: 761.9004855155945 and batch: 150, loss is 4.225051317214966 and perplexity is 68.3780124276871
At time: 763.0380651950836 and batch: 200, loss is 4.219221601486206 and perplexity is 67.98054773190228
At time: 764.1748549938202 and batch: 250, loss is 4.224029684066773 and perplexity is 68.30819085567255
At time: 765.3436393737793 and batch: 300, loss is 4.230892043113709 and perplexity is 68.7785582562884
At time: 766.4847002029419 and batch: 350, loss is 4.223394560813904 and perplexity is 68.26482050951425
At time: 767.6262240409851 and batch: 400, loss is 4.248444509506226 and perplexity is 69.99644881206183
At time: 768.7678771018982 and batch: 450, loss is 4.182644109725953 and perplexity is 65.53891640043722
At time: 769.9096567630768 and batch: 500, loss is 4.257622108459473 and perplexity is 70.64180502790968
At time: 771.051677942276 and batch: 550, loss is 4.253216733932495 and perplexity is 70.33128589822734
At time: 772.1938409805298 and batch: 600, loss is 4.201667218208313 and perplexity is 66.79760443902511
At time: 773.33465051651 and batch: 650, loss is 4.220219769477844 and perplexity is 68.04843761582006
At time: 774.4770684242249 and batch: 700, loss is 4.226501317024231 and perplexity is 68.47723244978754
At time: 775.6192755699158 and batch: 750, loss is 4.180054664611816 and perplexity is 65.36942651066745
At time: 776.7608287334442 and batch: 800, loss is 4.14725049495697 and perplexity is 63.25982774828162
At time: 777.9030938148499 and batch: 850, loss is 4.111431579589844 and perplexity is 61.03403012909024
At time: 779.0429892539978 and batch: 900, loss is 4.157244486808777 and perplexity is 63.89521569378957
At time: 780.1854290962219 and batch: 950, loss is 4.123082122802734 and perplexity is 61.74926809978201
At time: 781.3270192146301 and batch: 1000, loss is 4.147453560829162 and perplexity is 63.27267496474951
At time: 782.4693975448608 and batch: 1050, loss is 4.080646300315857 and perplexity is 59.18370794104195
At time: 783.6111831665039 and batch: 1100, loss is 4.062023291587829 and perplexity is 58.09172875992248
At time: 784.7525527477264 and batch: 1150, loss is 4.081152296066284 and perplexity is 59.21366222348531
At time: 785.8935844898224 and batch: 1200, loss is 4.049845261573791 and perplexity is 57.388576140400964
At time: 787.0350172519684 and batch: 1250, loss is 4.114376382827759 and perplexity is 61.214028238067826
At time: 788.1878671646118 and batch: 1300, loss is 4.091824913024903 and perplexity is 59.84901134726788
At time: 789.3346586227417 and batch: 1350, loss is 4.069711332321167 and perplexity is 58.54006152893412
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.561075439453125 and perplexity of 95.68632936965611
Finished 24 epochs...
Completing Train Step...
At time: 792.7425389289856 and batch: 50, loss is 4.248844652175904 and perplexity is 70.02446298241613
At time: 793.8792150020599 and batch: 100, loss is 4.254137907028198 and perplexity is 70.39610303590123
At time: 795.0434877872467 and batch: 150, loss is 4.22090295791626 and perplexity is 68.09494340595164
At time: 796.1809871196747 and batch: 200, loss is 4.214663853645325 and perplexity is 67.67141454794296
At time: 797.3188712596893 and batch: 250, loss is 4.219002304077148 and perplexity is 67.96564140843714
At time: 798.455961227417 and batch: 300, loss is 4.225809440612793 and perplexity is 68.4298710539406
At time: 799.5946674346924 and batch: 350, loss is 4.218175563812256 and perplexity is 67.90947469689571
At time: 800.7313706874847 and batch: 400, loss is 4.243095021247864 and perplexity is 69.62300339253247
At time: 801.8685727119446 and batch: 450, loss is 4.177605676651001 and perplexity is 65.20953344015354
At time: 803.0054607391357 and batch: 500, loss is 4.2526356220245365 and perplexity is 70.29042742331276
At time: 804.1431608200073 and batch: 550, loss is 4.248463716506958 and perplexity is 69.99779324681666
At time: 805.2807796001434 and batch: 600, loss is 4.196955947875977 and perplexity is 66.48364302623071
At time: 806.4176678657532 and batch: 650, loss is 4.2157896041870115 and perplexity is 67.74763857609751
At time: 807.5544891357422 and batch: 700, loss is 4.222706265449524 and perplexity is 68.21785031654476
At time: 808.6919348239899 and batch: 750, loss is 4.176664452552796 and perplexity is 65.14818553144102
At time: 809.832065820694 and batch: 800, loss is 4.144254431724549 and perplexity is 63.07058094353527
At time: 810.9740989208221 and batch: 850, loss is 4.109348526000977 and perplexity is 60.90702529844495
At time: 812.1154022216797 and batch: 900, loss is 4.155853724479675 and perplexity is 63.80641439985343
At time: 813.2573676109314 and batch: 950, loss is 4.122339539527893 and perplexity is 61.70343114704096
At time: 814.3993287086487 and batch: 1000, loss is 4.14705156326294 and perplexity is 63.24724461521706
At time: 815.5406255722046 and batch: 1050, loss is 4.081074748039246 and perplexity is 59.20907049884808
At time: 816.6811423301697 and batch: 1100, loss is 4.063109683990478 and perplexity is 58.15487346645819
At time: 817.8230628967285 and batch: 1150, loss is 4.082767071723938 and perplexity is 59.309356245239314
At time: 818.9655137062073 and batch: 1200, loss is 4.051834926605225 and perplexity is 57.502873852925674
At time: 820.1064686775208 and batch: 1250, loss is 4.116814589500427 and perplexity is 61.3634627923119
At time: 821.2471859455109 and batch: 1300, loss is 4.094322547912598 and perplexity is 59.998679155968624
At time: 822.388751745224 and batch: 1350, loss is 4.072071084976196 and perplexity is 58.6783647110255
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.560657958984375 and perplexity of 95.64639053344003
Finished 25 epochs...
Completing Train Step...
At time: 825.8238272666931 and batch: 50, loss is 4.247319326400757 and perplexity is 69.91773428284954
At time: 826.9651732444763 and batch: 100, loss is 4.251807613372803 and perplexity is 70.23225043012289
At time: 828.1073384284973 and batch: 150, loss is 4.2180358409881595 and perplexity is 67.89998685615754
At time: 829.2494292259216 and batch: 200, loss is 4.211540522575379 and perplexity is 67.46038404695204
At time: 830.3914663791656 and batch: 250, loss is 4.2156725072860715 and perplexity is 67.73970600202323
At time: 831.5335791110992 and batch: 300, loss is 4.222483615875245 and perplexity is 68.20266333196406
At time: 832.6765763759613 and batch: 350, loss is 4.214823651313782 and perplexity is 67.68222914625967
At time: 833.8189029693604 and batch: 400, loss is 4.239708395004272 and perplexity is 69.38761511312482
At time: 834.9624087810516 and batch: 450, loss is 4.17445029258728 and perplexity is 65.00409660404493
At time: 836.1047327518463 and batch: 500, loss is 4.249631032943726 and perplexity is 70.07955053043791
At time: 837.2453737258911 and batch: 550, loss is 4.2456002521514895 and perplexity is 69.79764375811554
At time: 838.386803150177 and batch: 600, loss is 4.194154014587403 and perplexity is 66.29762102600948
At time: 839.529278755188 and batch: 650, loss is 4.213098106384277 and perplexity is 67.56554112310538
At time: 840.6719167232513 and batch: 700, loss is 4.2204103899002074 and perplexity is 68.06141027412707
At time: 841.8136491775513 and batch: 750, loss is 4.174652261734009 and perplexity is 65.01722675186767
At time: 842.9556615352631 and batch: 800, loss is 4.142455778121948 and perplexity is 62.957240776309206
At time: 844.096732378006 and batch: 850, loss is 4.1080078125 and perplexity is 60.825421143442895
At time: 845.2390325069427 and batch: 900, loss is 4.154900016784668 and perplexity is 63.745590740055924
At time: 846.3809723854065 and batch: 950, loss is 4.121742253303528 and perplexity is 61.666587541805036
At time: 847.522186756134 and batch: 1000, loss is 4.146631207466125 and perplexity is 63.22066385638995
At time: 848.6627769470215 and batch: 1050, loss is 4.0810548257827755 and perplexity is 59.20789093231008
At time: 849.8036386966705 and batch: 1100, loss is 4.06345115184784 and perplexity is 58.17473487731963
At time: 850.9455456733704 and batch: 1150, loss is 4.083484830856324 and perplexity is 59.35194135841893
At time: 852.1187736988068 and batch: 1200, loss is 4.052751221656799 and perplexity is 57.55558759867242
At time: 853.2604999542236 and batch: 1250, loss is 4.117945990562439 and perplexity is 61.432928768813554
At time: 854.4017536640167 and batch: 1300, loss is 4.095598888397217 and perplexity is 60.07530679027251
At time: 855.5430154800415 and batch: 1350, loss is 4.073216438293457 and perplexity is 58.74561067354055
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.560483805338541 and perplexity of 95.6297348161868
Finished 26 epochs...
Completing Train Step...
At time: 858.95441198349 and batch: 50, loss is 4.245648088455201 and perplexity is 69.80098269926133
At time: 860.1267030239105 and batch: 100, loss is 4.249652576446533 and perplexity is 70.08106030569438
At time: 861.2703356742859 and batch: 150, loss is 4.215681829452515 and perplexity is 67.74033748578078
At time: 862.414299249649 and batch: 200, loss is 4.209065799713135 and perplexity is 67.29364469419559
At time: 863.5583004951477 and batch: 250, loss is 4.213062000274658 and perplexity is 67.56310163831157
At time: 864.7035303115845 and batch: 300, loss is 4.219924011230469 and perplexity is 68.02831470507927
At time: 865.8471689224243 and batch: 350, loss is 4.21228593826294 and perplexity is 67.51068882216454
At time: 866.9912571907043 and batch: 400, loss is 4.2371938610076905 and perplexity is 69.21335677705414
At time: 868.1368095874786 and batch: 450, loss is 4.1720646953582765 and perplexity is 64.84920783587748
At time: 869.2813529968262 and batch: 500, loss is 4.247370338439941 and perplexity is 69.92130102002292
At time: 870.4265451431274 and batch: 550, loss is 4.243458814620972 and perplexity is 69.64833638749097
At time: 871.5722377300262 and batch: 600, loss is 4.192070126533508 and perplexity is 66.15960805728464
At time: 872.7162666320801 and batch: 650, loss is 4.211099367141724 and perplexity is 67.43063009551452
At time: 873.8608334064484 and batch: 700, loss is 4.218702473640442 and perplexity is 67.94526629518482
At time: 875.0057306289673 and batch: 750, loss is 4.173121953010559 and perplexity is 64.9178064139023
At time: 876.1508846282959 and batch: 800, loss is 4.141071028709412 and perplexity is 62.870121107505625
At time: 877.2950339317322 and batch: 850, loss is 4.106920323371887 and perplexity is 60.7593101132652
At time: 878.4399421215057 and batch: 900, loss is 4.154053993225098 and perplexity is 63.69168327517915
At time: 879.584184885025 and batch: 950, loss is 4.1211351299285885 and perplexity is 61.62915967787087
At time: 880.7277765274048 and batch: 1000, loss is 4.146135220527649 and perplexity is 63.18931500782773
At time: 881.9032549858093 and batch: 1050, loss is 4.080867795944214 and perplexity is 59.19681832551366
At time: 883.0483696460724 and batch: 1100, loss is 4.063441605567932 and perplexity is 58.17417952766769
At time: 884.1930637359619 and batch: 1150, loss is 4.083730154037475 and perplexity is 59.36650355162925
At time: 885.33717918396 and batch: 1200, loss is 4.053143997192382 and perplexity is 57.57819846562428
At time: 886.4825847148895 and batch: 1250, loss is 4.118492341041565 and perplexity is 61.46650184937969
At time: 887.6269798278809 and batch: 1300, loss is 4.096261110305786 and perplexity is 60.11510315014939
At time: 888.77223944664 and batch: 1350, loss is 4.073782730102539 and perplexity is 58.77888725292238
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.560401204427083 and perplexity of 95.62183603915604
Finished 27 epochs...
Completing Train Step...
At time: 892.1875603199005 and batch: 50, loss is 4.243980951309204 and perplexity is 69.68471183484463
At time: 893.3624124526978 and batch: 100, loss is 4.247680406570435 and perplexity is 69.94298474865478
At time: 894.5078077316284 and batch: 150, loss is 4.21359450340271 and perplexity is 67.59908878205779
At time: 895.6535971164703 and batch: 200, loss is 4.2069184112548825 and perplexity is 67.14929414209035
At time: 896.7980995178223 and batch: 250, loss is 4.21083589553833 and perplexity is 67.41286637950552
At time: 897.9440829753876 and batch: 300, loss is 4.217772927284241 and perplexity is 67.88213736565778
At time: 899.0891876220703 and batch: 350, loss is 4.210172128677368 and perplexity is 67.36813480011273
At time: 900.2356894016266 and batch: 400, loss is 4.2351057767868046 and perplexity is 69.06898424235574
At time: 901.3819713592529 and batch: 450, loss is 4.170098876953125 and perplexity is 64.72185129048816
At time: 902.5276160240173 and batch: 500, loss is 4.245503206253051 and perplexity is 69.79087051173137
At time: 903.6749868392944 and batch: 550, loss is 4.24167236328125 and perplexity is 69.52402409563324
At time: 904.8191831111908 and batch: 600, loss is 4.1903666973114015 and perplexity is 66.04700577982958
At time: 905.9635169506073 and batch: 650, loss is 4.20946355342865 and perplexity is 67.3204163153062
At time: 907.108412027359 and batch: 700, loss is 4.217284364700317 and perplexity is 67.84898079341401
At time: 908.2528374195099 and batch: 750, loss is 4.171823935508728 and perplexity is 64.8335966297068
At time: 909.3965926170349 and batch: 800, loss is 4.139878544807434 and perplexity is 62.795194183623764
At time: 910.5731754302979 and batch: 850, loss is 4.105933585166931 and perplexity is 60.699386150163654
At time: 911.7198202610016 and batch: 900, loss is 4.1532468557357785 and perplexity is 63.64029607090918
At time: 912.8650732040405 and batch: 950, loss is 4.120498480796814 and perplexity is 61.589936014050586
At time: 914.0108580589294 and batch: 1000, loss is 4.145582823753357 and perplexity is 63.15441907313595
At time: 915.1566078662872 and batch: 1050, loss is 4.080548934936523 and perplexity is 59.17794577739005
At time: 916.301568031311 and batch: 1100, loss is 4.06322338104248 and perplexity is 58.1614858800297
At time: 917.44766664505 and batch: 1150, loss is 4.083701324462891 and perplexity is 59.364792065258115
At time: 918.5940458774567 and batch: 1200, loss is 4.053224039077759 and perplexity is 57.5828073176342
At time: 919.7388849258423 and batch: 1250, loss is 4.118706421852112 and perplexity is 61.479662056540754
At time: 920.8838033676147 and batch: 1300, loss is 4.09658061504364 and perplexity is 60.13431327912265
At time: 922.0302109718323 and batch: 1350, loss is 4.074031677246094 and perplexity is 58.79352191055784
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.560364990234375 and perplexity of 95.61837323426037
Finished 28 epochs...
Completing Train Step...
At time: 925.4610493183136 and batch: 50, loss is 4.242349033355713 and perplexity is 69.57108484269891
At time: 926.6055762767792 and batch: 100, loss is 4.24583664894104 and perplexity is 69.81414564743814
At time: 927.7505867481232 and batch: 150, loss is 4.211691255569458 and perplexity is 67.47055331902433
At time: 928.8958425521851 and batch: 200, loss is 4.204978580474854 and perplexity is 67.01916213230194
At time: 930.0412361621857 and batch: 250, loss is 4.208916888237 and perplexity is 67.28362464429841
At time: 931.1862552165985 and batch: 300, loss is 4.215866498947143 and perplexity is 67.7528482148097
At time: 932.3312332630157 and batch: 350, loss is 4.208302702903747 and perplexity is 67.24231271676247
At time: 933.4770405292511 and batch: 400, loss is 4.233279910087585 and perplexity is 68.94298854475656
At time: 934.6210813522339 and batch: 450, loss is 4.168476414680481 and perplexity is 64.61692766887909
At time: 935.7658388614655 and batch: 500, loss is 4.243860540390014 and perplexity is 69.6763215397908
At time: 936.9120192527771 and batch: 550, loss is 4.240182256698608 and perplexity is 69.42050303753663
At time: 938.0571553707123 and batch: 600, loss is 4.1888903141021725 and perplexity is 65.94956703563831
At time: 939.232349395752 and batch: 650, loss is 4.208037114143371 and perplexity is 67.22445628562186
At time: 940.3776009082794 and batch: 700, loss is 4.2160306596755985 and perplexity is 67.76397148470464
At time: 941.5230424404144 and batch: 750, loss is 4.170653223991394 and perplexity is 64.75773960343331
At time: 942.6683926582336 and batch: 800, loss is 4.138798732757568 and perplexity is 62.727423772508864
At time: 943.8138773441315 and batch: 850, loss is 4.105008888244629 and perplexity is 60.64328355754993
At time: 944.9588010311127 and batch: 900, loss is 4.152456002235413 and perplexity is 63.58998581663974
At time: 946.103896856308 and batch: 950, loss is 4.119842600822449 and perplexity is 61.54955365283518
At time: 947.249109506607 and batch: 1000, loss is 4.145003190040589 and perplexity is 63.11782324984191
At time: 948.3934059143066 and batch: 1050, loss is 4.0801472568511965 and perplexity is 59.15418006683872
At time: 949.5385251045227 and batch: 1100, loss is 4.062886419296265 and perplexity is 58.141890985735415
At time: 950.6841084957123 and batch: 1150, loss is 4.0835258531570435 and perplexity is 59.354376161545915
At time: 951.82936668396 and batch: 1200, loss is 4.053128399848938 and perplexity is 57.5773004056916
At time: 952.9730110168457 and batch: 1250, loss is 4.118729004859924 and perplexity is 61.48105046790646
At time: 954.1174097061157 and batch: 1300, loss is 4.096673545837402 and perplexity is 60.13990186825998
At time: 955.2628977298737 and batch: 1350, loss is 4.074088344573974 and perplexity is 58.79685367674147
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.560351969401042 and perplexity of 95.61712821146452
Finished 29 epochs...
Completing Train Step...
At time: 958.7019829750061 and batch: 50, loss is 4.240784826278687 and perplexity is 69.46234632638125
At time: 959.8439245223999 and batch: 100, loss is 4.24412425994873 and perplexity is 69.69469897169785
At time: 960.9865119457245 and batch: 150, loss is 4.2099510860443115 and perplexity is 67.35324521588944
At time: 962.1292154788971 and batch: 200, loss is 4.203208107948303 and perplexity is 66.90061152325954
At time: 963.2715420722961 and batch: 250, loss is 4.207143864631653 and perplexity is 67.16443488390398
At time: 964.4137794971466 and batch: 300, loss is 4.214132800102234 and perplexity is 67.63548694406629
At time: 965.5561833381653 and batch: 350, loss is 4.206611742973328 and perplexity is 67.12870474066773
At time: 966.6970038414001 and batch: 400, loss is 4.231614618301392 and perplexity is 68.82827389540954
At time: 967.837644815445 and batch: 450, loss is 4.166796307563782 and perplexity is 64.50845545682701
At time: 969.0090565681458 and batch: 500, loss is 4.24237024307251 and perplexity is 69.57256044135414
At time: 970.1506907939911 and batch: 550, loss is 4.238746566772461 and perplexity is 69.32090823139463
At time: 971.2926127910614 and batch: 600, loss is 4.187483515739441 and perplexity is 65.85685452190643
At time: 972.4344925880432 and batch: 650, loss is 4.206692109107971 and perplexity is 67.13409983197974
At time: 973.5761449337006 and batch: 700, loss is 4.2148398542404175 and perplexity is 67.6833258053376
At time: 974.717483997345 and batch: 750, loss is 4.169535408020019 and perplexity is 64.68539281056792
At time: 975.8598885536194 and batch: 800, loss is 4.13775607585907 and perplexity is 62.66205467607918
At time: 977.000542640686 and batch: 850, loss is 4.104109797477722 and perplexity is 60.58878424481416
At time: 978.1416730880737 and batch: 900, loss is 4.15167543888092 and perplexity is 63.54036917098545
At time: 979.2836978435516 and batch: 950, loss is 4.119176750183105 and perplexity is 61.5085844843713
At time: 980.4234981536865 and batch: 1000, loss is 4.144384984970093 and perplexity is 63.078815550091406
At time: 981.5640025138855 and batch: 1050, loss is 4.079668297767639 and perplexity is 59.12585441891998
At time: 982.7063548564911 and batch: 1100, loss is 4.062477474212646 and perplexity is 58.11811900631286
At time: 983.8491320610046 and batch: 1150, loss is 4.083249716758728 and perplexity is 59.33798852060462
At time: 984.9908046722412 and batch: 1200, loss is 4.052925505638123 and perplexity is 57.565619489800085
At time: 986.1322596073151 and batch: 1250, loss is 4.118624768257141 and perplexity is 61.47464222606264
At time: 987.275318145752 and batch: 1300, loss is 4.096674628257752 and perplexity is 60.139966964948826
At time: 988.4164283275604 and batch: 1350, loss is 4.0740416765213014 and perplexity is 58.79410980610312
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.5603564453125 and perplexity of 95.61755618622209
Annealing...
Finished 30 epochs...
Completing Train Step...
At time: 991.8283631801605 and batch: 50, loss is 4.2413089561462405 and perplexity is 69.49876315950253
At time: 992.9997200965881 and batch: 100, loss is 4.248097019195557 and perplexity is 69.9721299498476
At time: 994.1417093276978 and batch: 150, loss is 4.217105236053467 and perplexity is 67.83682818576688
At time: 995.2839736938477 and batch: 200, loss is 4.212887148857117 and perplexity is 67.5512891669604
At time: 996.4250955581665 and batch: 250, loss is 4.218240442276001 and perplexity is 67.91388070221369
At time: 997.5977900028229 and batch: 300, loss is 4.224986481666565 and perplexity is 68.37357924546822
At time: 998.7395052909851 and batch: 350, loss is 4.218840761184692 and perplexity is 67.95466292890795
At time: 999.8804473876953 and batch: 400, loss is 4.2435488033294675 and perplexity is 69.6546042333448
At time: 1001.0226726531982 and batch: 450, loss is 4.17830578327179 and perplexity is 65.25520305118665
At time: 1002.1652410030365 and batch: 500, loss is 4.252987451553345 and perplexity is 70.31516202219885
At time: 1003.306948184967 and batch: 550, loss is 4.249367742538452 and perplexity is 70.06110168598582
At time: 1004.4483070373535 and batch: 600, loss is 4.197494530677796 and perplexity is 66.51945961720108
At time: 1005.5900542736053 and batch: 650, loss is 4.2157504272460935 and perplexity is 67.74498448285365
At time: 1006.7312366962433 and batch: 700, loss is 4.222524337768554 and perplexity is 68.20544073009378
At time: 1007.8722071647644 and batch: 750, loss is 4.1774080371856686 and perplexity is 65.19664673633244
At time: 1009.0145859718323 and batch: 800, loss is 4.1433823823928835 and perplexity is 63.015604260249695
At time: 1010.1559326648712 and batch: 850, loss is 4.105021715164185 and perplexity is 60.64406142905856
At time: 1011.3163199424744 and batch: 900, loss is 4.1506166696548465 and perplexity is 63.47313018505961
At time: 1012.4608452320099 and batch: 950, loss is 4.11599223613739 and perplexity is 61.313021085613286
At time: 1013.6047689914703 and batch: 1000, loss is 4.1403306245803835 and perplexity is 62.82358903863881
At time: 1014.7451558113098 and batch: 1050, loss is 4.0733663892745975 and perplexity is 58.754420295988
At time: 1015.8848412036896 and batch: 1100, loss is 4.0556712293624875 and perplexity is 57.72389596924613
At time: 1017.0239491462708 and batch: 1150, loss is 4.075295338630676 and perplexity is 58.86786397556552
At time: 1018.1630914211273 and batch: 1200, loss is 4.045294966697693 and perplexity is 57.12803441682446
At time: 1019.3014349937439 and batch: 1250, loss is 4.111692771911621 and perplexity is 61.04997383122272
At time: 1020.4398412704468 and batch: 1300, loss is 4.089999628067017 and perplexity is 59.7398694849132
At time: 1021.5811913013458 and batch: 1350, loss is 4.067972803115845 and perplexity is 58.43837633923257
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.555991617838542 and perplexity of 95.20111156561369
Finished 31 epochs...
Completing Train Step...
At time: 1024.966684103012 and batch: 50, loss is 4.240250415802002 and perplexity is 69.42523483803666
At time: 1026.1321091651917 and batch: 100, loss is 4.244739942550659 and perplexity is 69.73762199742558
At time: 1027.2718048095703 and batch: 150, loss is 4.212296142578125 and perplexity is 67.51137772602651
At time: 1028.4118809700012 and batch: 200, loss is 4.207703852653504 and perplexity is 67.20205669583223
At time: 1029.550169467926 and batch: 250, loss is 4.213204345703125 and perplexity is 67.57271962148454
At time: 1030.689127445221 and batch: 300, loss is 4.22008828163147 and perplexity is 68.03949066152958
At time: 1031.827026128769 and batch: 350, loss is 4.2130113792419435 and perplexity is 67.5596816108966
At time: 1032.9655175209045 and batch: 400, loss is 4.23789333820343 and perplexity is 69.26178687766117
At time: 1034.107913017273 and batch: 450, loss is 4.172798724174499 and perplexity is 64.89682649773515
At time: 1035.2501001358032 and batch: 500, loss is 4.247606039047241 and perplexity is 69.93778345552028
At time: 1036.3896386623383 and batch: 550, loss is 4.243940591812134 and perplexity is 69.68189945167504
At time: 1037.528796195984 and batch: 600, loss is 4.192559185028077 and perplexity is 66.19197188886068
At time: 1038.6685173511505 and batch: 650, loss is 4.211518898010254 and perplexity is 67.45892526125671
At time: 1039.809072971344 and batch: 700, loss is 4.218723340034485 and perplexity is 67.94668408267668
At time: 1040.953293800354 and batch: 750, loss is 4.173880481719971 and perplexity is 64.9670671142851
At time: 1042.095773935318 and batch: 800, loss is 4.140346245765686 and perplexity is 62.824570425229744
At time: 1043.2394785881042 and batch: 850, loss is 4.102875361442566 and perplexity is 60.51403741080055
At time: 1044.3836090564728 and batch: 900, loss is 4.149052863121033 and perplexity is 63.3739480603943
At time: 1045.528152704239 and batch: 950, loss is 4.115183992385864 and perplexity is 61.2634852406489
At time: 1046.672176361084 and batch: 1000, loss is 4.14030592918396 and perplexity is 62.82203760435945
At time: 1047.8164687156677 and batch: 1050, loss is 4.074355344772339 and perplexity is 58.812554544310494
At time: 1048.9601192474365 and batch: 1100, loss is 4.057091226577759 and perplexity is 57.80592196533705
At time: 1050.1174936294556 and batch: 1150, loss is 4.076982288360596 and perplexity is 58.96725491298702
At time: 1051.2759912014008 and batch: 1200, loss is 4.04788733959198 and perplexity is 57.276323712278646
At time: 1052.4155683517456 and batch: 1250, loss is 4.114685492515564 and perplexity is 61.23295301199059
At time: 1053.5546317100525 and batch: 1300, loss is 4.092797226905823 and perplexity is 59.907231671388075
At time: 1054.6940817832947 and batch: 1350, loss is 4.070460348129273 and perplexity is 58.583925385737125
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.55507080078125 and perplexity of 95.11348910652967
Finished 32 epochs...
Completing Train Step...
At time: 1058.1824781894684 and batch: 50, loss is 4.2401335906982425 and perplexity is 69.41712470151616
At time: 1059.3226311206818 and batch: 100, loss is 4.243898649215698 and perplexity is 69.67897687317814
At time: 1060.4624419212341 and batch: 150, loss is 4.210613899230957 and perplexity is 67.3979026331095
At time: 1061.601704120636 and batch: 200, loss is 4.205787043571473 and perplexity is 67.07336655983951
At time: 1062.7416768074036 and batch: 250, loss is 4.2111976528167725 and perplexity is 67.4372578862155
At time: 1063.8813645839691 and batch: 300, loss is 4.217980227470398 and perplexity is 67.89621080403325
At time: 1065.021803855896 and batch: 350, loss is 4.210613679885864 and perplexity is 67.39788784971194
At time: 1066.1625061035156 and batch: 400, loss is 4.235476288795471 and perplexity is 69.0945798718952
At time: 1067.3029289245605 and batch: 450, loss is 4.170476984977722 and perplexity is 64.74632776891275
At time: 1068.443259716034 and batch: 500, loss is 4.245363426208496 and perplexity is 69.78111582251303
At time: 1069.5833461284637 and batch: 550, loss is 4.241828212738037 and perplexity is 69.53486022140241
At time: 1070.7234976291656 and batch: 600, loss is 4.190525493621826 and perplexity is 66.0574946334356
At time: 1071.8636977672577 and batch: 650, loss is 4.2098508024215695 and perplexity is 67.34649112712368
At time: 1073.004267692566 and batch: 700, loss is 4.217301287651062 and perplexity is 67.85012900808962
At time: 1074.151447057724 and batch: 750, loss is 4.172640905380249 and perplexity is 64.88658536696934
At time: 1075.2930390834808 and batch: 800, loss is 4.139319558143615 and perplexity is 62.76010231637985
At time: 1076.4322023391724 and batch: 850, loss is 4.102294292449951 and perplexity is 60.47888479408008
At time: 1077.5772049427032 and batch: 900, loss is 4.148695912361145 and perplexity is 63.35133071835592
At time: 1078.7170150279999 and batch: 950, loss is 4.11514760017395 and perplexity is 61.26125576747939
At time: 1079.8618829250336 and batch: 1000, loss is 4.140672206878662 and perplexity is 62.845052130066094
At time: 1081.0020248889923 and batch: 1050, loss is 4.075099587440491 and perplexity is 58.85634164892
At time: 1082.1457016468048 and batch: 1100, loss is 4.058074750900269 and perplexity is 57.86280346315814
At time: 1083.2849028110504 and batch: 1150, loss is 4.078101739883423 and perplexity is 59.033302858135244
At time: 1084.4795060157776 and batch: 1200, loss is 4.04944149017334 and perplexity is 57.36540895208163
At time: 1085.6281154155731 and batch: 1250, loss is 4.116355714797973 and perplexity is 61.3353111111227
At time: 1086.7679097652435 and batch: 1300, loss is 4.094295191764831 and perplexity is 59.9970378456859
At time: 1087.9129428863525 and batch: 1350, loss is 4.071760406494141 and perplexity is 58.660137437305075
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.554734293619791 and perplexity of 95.08148812087641
Finished 33 epochs...
Completing Train Step...
At time: 1091.3681666851044 and batch: 50, loss is 4.239948463439942 and perplexity is 69.404274889003
At time: 1092.516152381897 and batch: 100, loss is 4.24332555770874 and perplexity is 69.63905588360127
At time: 1093.6579008102417 and batch: 150, loss is 4.209573249816895 and perplexity is 67.32780152688925
At time: 1094.7994883060455 and batch: 200, loss is 4.204614953994751 and perplexity is 66.99479662051748
At time: 1095.941383600235 and batch: 250, loss is 4.209938888549805 and perplexity is 67.35242368006126
At time: 1097.0823786258698 and batch: 300, loss is 4.216686887741089 and perplexity is 67.80845469859234
At time: 1098.2246901988983 and batch: 350, loss is 4.209200158119201 and perplexity is 67.30268676846086
At time: 1099.3677756786346 and batch: 400, loss is 4.234030246734619 and perplexity is 68.99473840809925
At time: 1100.5101990699768 and batch: 450, loss is 4.169143748283386 and perplexity is 64.66006310729198
At time: 1101.6522810459137 and batch: 500, loss is 4.244087133407593 and perplexity is 69.69211149662172
At time: 1102.7944893836975 and batch: 550, loss is 4.24066237449646 and perplexity is 69.45384105902912
At time: 1103.936811208725 and batch: 600, loss is 4.189409308433532 and perplexity is 65.98380337054884
At time: 1105.0784978866577 and batch: 650, loss is 4.208925256729126 and perplexity is 67.28418770913744
At time: 1106.2202117443085 and batch: 700, loss is 4.216440372467041 and perplexity is 67.7917409389827
At time: 1107.3620777130127 and batch: 750, loss is 4.171984658241272 and perplexity is 64.84401769994682
At time: 1108.504592180252 and batch: 800, loss is 4.138797903060913 and perplexity is 62.7273717277968
At time: 1109.6463997364044 and batch: 850, loss is 4.102051882743836 and perplexity is 60.464225902191586
At time: 1110.7880368232727 and batch: 900, loss is 4.1485983085632325 and perplexity is 63.34514768962345
At time: 1111.9301362037659 and batch: 950, loss is 4.115212659835816 and perplexity is 61.26524153372
At time: 1113.102866411209 and batch: 1000, loss is 4.140965399742126 and perplexity is 62.863480552263574
At time: 1114.2454717159271 and batch: 1050, loss is 4.075625739097595 and perplexity is 58.88731715880302
At time: 1115.38827252388 and batch: 1100, loss is 4.0587386846542355 and perplexity is 57.90123328749357
At time: 1116.530217885971 and batch: 1150, loss is 4.078846445083618 and perplexity is 59.077281639339425
At time: 1117.672254562378 and batch: 1200, loss is 4.050402436256409 and perplexity is 57.42056051171138
At time: 1118.8136570453644 and batch: 1250, loss is 4.1173634481430055 and perplexity is 61.39715190363824
At time: 1119.9557657241821 and batch: 1300, loss is 4.095175004005432 and perplexity is 60.04984720173473
At time: 1121.0980243682861 and batch: 1350, loss is 4.072521986961365 and perplexity is 58.70482886808228
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.55455810546875 and perplexity of 95.06473736497185
Finished 34 epochs...
Completing Train Step...
At time: 1124.494618177414 and batch: 50, loss is 4.239712085723877 and perplexity is 69.38787120382881
At time: 1125.6638631820679 and batch: 100, loss is 4.242825937271118 and perplexity is 69.60427147824863
At time: 1126.8055021762848 and batch: 150, loss is 4.208786783218383 and perplexity is 67.27487127650237
At time: 1127.9478032588959 and batch: 200, loss is 4.203745160102844 and perplexity is 66.93655029045063
At time: 1129.0900676250458 and batch: 250, loss is 4.209007449150086 and perplexity is 67.28971818669615
At time: 1130.232373714447 and batch: 300, loss is 4.215748009681701 and perplexity is 67.74482070518938
At time: 1131.3743975162506 and batch: 350, loss is 4.208206815719604 and perplexity is 67.23586534985566
At time: 1132.5169322490692 and batch: 400, loss is 4.233007683753967 and perplexity is 68.92422300210966
At time: 1133.6589970588684 and batch: 450, loss is 4.168234329223633 and perplexity is 64.60128674372089
At time: 1134.8017992973328 and batch: 500, loss is 4.24318902015686 and perplexity is 69.62954818648932
At time: 1135.9460241794586 and batch: 550, loss is 4.239854116439819 and perplexity is 69.39772711275792
At time: 1137.0885038375854 and batch: 600, loss is 4.188696346282959 and perplexity is 65.93677618248937
At time: 1138.2308156490326 and batch: 650, loss is 4.20830620765686 and perplexity is 67.24254838488024
At time: 1139.373639345169 and batch: 700, loss is 4.215933899879456 and perplexity is 67.75741497384641
At time: 1140.5155613422394 and batch: 750, loss is 4.171573672294617 and perplexity is 64.81737319558093
At time: 1141.686448097229 and batch: 800, loss is 4.138430943489075 and perplexity is 62.7043575412213
At time: 1142.829082250595 and batch: 850, loss is 4.101906743049621 and perplexity is 60.45545077975793
At time: 1143.9716229438782 and batch: 900, loss is 4.148557014465332 and perplexity is 63.342531962900665
At time: 1145.1139330863953 and batch: 950, loss is 4.115261888504028 and perplexity is 61.268257614206604
At time: 1146.2563779354095 and batch: 1000, loss is 4.141161556243897 and perplexity is 62.875812842187706
At time: 1147.399957895279 and batch: 1050, loss is 4.075975403785706 and perplexity is 58.90791157455118
At time: 1148.5421645641327 and batch: 1100, loss is 4.0591985130310055 and perplexity is 57.927864039927734
At time: 1149.6847512722015 and batch: 1150, loss is 4.079360356330872 and perplexity is 59.10764992146355
At time: 1150.8268871307373 and batch: 1200, loss is 4.051050782203674 and perplexity is 57.4578009704546
At time: 1151.9691143035889 and batch: 1250, loss is 4.1180374050140385 and perplexity is 61.4385448830002
At time: 1153.111055612564 and batch: 1300, loss is 4.0957444429397585 and perplexity is 60.08405166048277
At time: 1154.2535302639008 and batch: 1350, loss is 4.072991452217102 and perplexity is 58.73239521579477
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.554440104166667 and perplexity of 95.05352026400983
Finished 35 epochs...
Completing Train Step...
At time: 1157.6496086120605 and batch: 50, loss is 4.239447727203369 and perplexity is 69.36953035324305
At time: 1158.8179981708527 and batch: 100, loss is 4.242365102767945 and perplexity is 69.57220281812326
At time: 1159.9608047008514 and batch: 150, loss is 4.208137893676758 and perplexity is 67.23123147635306
At time: 1161.1029875278473 and batch: 200, loss is 4.2030301189422605 and perplexity is 66.88870500955659
At time: 1162.2447323799133 and batch: 250, loss is 4.208260092735291 and perplexity is 67.23944757153278
At time: 1163.3872876167297 and batch: 300, loss is 4.215001363754272 and perplexity is 67.69425818920271
At time: 1164.529615163803 and batch: 350, loss is 4.207435569763184 and perplexity is 67.18402995206799
At time: 1165.6720259189606 and batch: 400, loss is 4.232197942733765 and perplexity is 68.86843482149672
At time: 1166.8141791820526 and batch: 450, loss is 4.167512445449829 and perplexity is 64.55466895139212
At time: 1167.9565725326538 and batch: 500, loss is 4.242516670227051 and perplexity is 69.58274849929967
At time: 1169.0983555316925 and batch: 550, loss is 4.239264392852784 and perplexity is 69.35681370118051
At time: 1170.2400810718536 and batch: 600, loss is 4.188140182495117 and perplexity is 65.9001147311205
At time: 1171.4147832393646 and batch: 650, loss is 4.207814149856567 and perplexity is 67.20946930351332
At time: 1172.5571875572205 and batch: 700, loss is 4.215527710914611 and perplexity is 67.72989824847107
At time: 1173.6994132995605 and batch: 750, loss is 4.171230826377869 and perplexity is 64.79515463283587
At time: 1174.8416666984558 and batch: 800, loss is 4.138124737739563 and perplexity is 62.685160045764476
At time: 1175.9834175109863 and batch: 850, loss is 4.10178346157074 and perplexity is 60.44799820177122
At time: 1177.124830007553 and batch: 900, loss is 4.148519039154053 and perplexity is 63.34012655620546
At time: 1178.2672193050385 and batch: 950, loss is 4.11529881477356 and perplexity is 61.27052006417267
At time: 1179.409613609314 and batch: 1000, loss is 4.141292705535888 and perplexity is 62.8840595012853
At time: 1180.5519390106201 and batch: 1050, loss is 4.076229815483093 and perplexity is 58.92290034290255
At time: 1181.6940727233887 and batch: 1100, loss is 4.059533047676086 and perplexity is 57.947246159179045
At time: 1182.8357629776 and batch: 1150, loss is 4.07973153591156 and perplexity is 59.1295935464377
At time: 1183.977464914322 and batch: 1200, loss is 4.05149667263031 and perplexity is 57.48342656652227
At time: 1185.1198761463165 and batch: 1250, loss is 4.118485908508301 and perplexity is 61.46610646533362
At time: 1186.2618629932404 and batch: 1300, loss is 4.096132335662841 and perplexity is 60.10736234762589
At time: 1187.4037170410156 and batch: 1350, loss is 4.073304667472839 and perplexity is 58.750793979218614
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.5543701171875 and perplexity of 95.04686798805646
Finished 36 epochs...
Completing Train Step...
At time: 1190.824233531952 and batch: 50, loss is 4.239177103042603 and perplexity is 69.3507598223026
At time: 1191.9621365070343 and batch: 100, loss is 4.241947031021118 and perplexity is 69.54312272496671
At time: 1193.1009533405304 and batch: 150, loss is 4.20758487701416 and perplexity is 67.19406176378212
At time: 1194.2394468784332 and batch: 200, loss is 4.202435326576233 and perplexity is 66.84893194797272
At time: 1195.3779017925262 and batch: 250, loss is 4.207639636993409 and perplexity is 67.1977414099577
At time: 1196.5159528255463 and batch: 300, loss is 4.214389801025391 and perplexity is 67.65287156048464
At time: 1197.654475927353 and batch: 350, loss is 4.2068098497390745 and perplexity is 67.14200470861597
At time: 1198.792763710022 and batch: 400, loss is 4.231549701690674 and perplexity is 68.82380594217042
At time: 1199.9590077400208 and batch: 450, loss is 4.166913690567017 and perplexity is 64.51602809750352
At time: 1201.0978789329529 and batch: 500, loss is 4.2419641399383545 and perplexity is 69.54431254267601
At time: 1202.2362504005432 and batch: 550, loss is 4.238763446807861 and perplexity is 69.32207838065563
At time: 1203.3748006820679 and batch: 600, loss is 4.187702522277832 and perplexity is 65.87127918313453
At time: 1204.5129120349884 and batch: 650, loss is 4.2074281692504885 and perplexity is 67.18353275764117
At time: 1205.6514372825623 and batch: 700, loss is 4.21521448135376 and perplexity is 67.70868656442285
At time: 1206.7903048992157 and batch: 750, loss is 4.170979218482971 and perplexity is 64.77885371118543
At time: 1207.930432319641 and batch: 800, loss is 4.13790449142456 and perplexity is 62.67135539052706
At time: 1209.0691764354706 and batch: 850, loss is 4.101681923866272 and perplexity is 60.44186076239013
At time: 1210.207528591156 and batch: 900, loss is 4.148482875823975 and perplexity is 63.3378360077188
At time: 1211.3461935520172 and batch: 950, loss is 4.115306167602539 and perplexity is 61.27097057748446
At time: 1212.4843218326569 and batch: 1000, loss is 4.141373066902161 and perplexity is 62.88911315328006
At time: 1213.6230053901672 and batch: 1050, loss is 4.076396088600159 and perplexity is 58.932698451767614
At time: 1214.7621223926544 and batch: 1100, loss is 4.059766235351563 and perplexity is 57.96076031841763
At time: 1215.9007713794708 and batch: 1150, loss is 4.079998669624328 and perplexity is 59.14539116424042
At time: 1217.0391459465027 and batch: 1200, loss is 4.051820378303528 and perplexity is 57.50203728985374
At time: 1218.1768341064453 and batch: 1250, loss is 4.118811807632446 and perplexity is 61.48614148011483
At time: 1219.3149967193604 and batch: 1300, loss is 4.096408505439758 and perplexity is 60.123964476874114
At time: 1220.4541456699371 and batch: 1350, loss is 4.073512578010559 and perplexity is 58.763010158278504
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.55431396484375 and perplexity of 95.0415310334955
Finished 37 epochs...
Completing Train Step...
At time: 1223.870643377304 and batch: 50, loss is 4.2388965511322025 and perplexity is 69.33130606316901
At time: 1225.0082001686096 and batch: 100, loss is 4.24154990196228 and perplexity is 69.51551061323917
At time: 1226.1461353302002 and batch: 150, loss is 4.207089195251465 and perplexity is 67.1607631462449
At time: 1227.2839663028717 and batch: 200, loss is 4.201900386810303 and perplexity is 66.81318135902218
At time: 1228.4493699073792 and batch: 250, loss is 4.207092304229736 and perplexity is 67.16097194792279
At time: 1229.5876157283783 and batch: 300, loss is 4.2138489818573 and perplexity is 67.6162934827227
At time: 1230.7260656356812 and batch: 350, loss is 4.206269235610962 and perplexity is 67.10571660209602
At time: 1231.8637578487396 and batch: 400, loss is 4.23100133895874 and perplexity is 68.78607587774798
At time: 1233.0016095638275 and batch: 450, loss is 4.166405143737793 and perplexity is 64.48322701713006
At time: 1234.139746427536 and batch: 500, loss is 4.241499881744385 and perplexity is 69.51203351921446
At time: 1235.2776176929474 and batch: 550, loss is 4.238352165222168 and perplexity is 69.29357334853489
At time: 1236.4160284996033 and batch: 600, loss is 4.187332220077515 and perplexity is 65.8468914192153
At time: 1237.554307937622 and batch: 650, loss is 4.2070779037475585 and perplexity is 67.16000480450693
At time: 1238.6926889419556 and batch: 700, loss is 4.214924535751343 and perplexity is 67.68905757431524
At time: 1239.8304495811462 and batch: 750, loss is 4.170729813575744 and perplexity is 64.76269956173114
At time: 1240.9684162139893 and batch: 800, loss is 4.13768729686737 and perplexity is 62.657744991350334
At time: 1242.106424331665 and batch: 850, loss is 4.101574268341064 and perplexity is 60.43535421236456
At time: 1243.2452909946442 and batch: 900, loss is 4.148433165550232 and perplexity is 63.334687544808716
At time: 1244.3835201263428 and batch: 950, loss is 4.115304193496704 and perplexity is 61.2708496222233
At time: 1245.5213661193848 and batch: 1000, loss is 4.141417770385742 and perplexity is 62.891924578557145
At time: 1246.659140586853 and batch: 1050, loss is 4.076517686843872 and perplexity is 58.939865000107645
At time: 1247.7971017360687 and batch: 1100, loss is 4.05993754863739 and perplexity is 57.97069061728861
At time: 1248.9354119300842 and batch: 1150, loss is 4.08019603729248 and perplexity is 59.15706570422691
At time: 1250.0736157894135 and batch: 1200, loss is 4.052050471305847 and perplexity is 57.515269628529104
At time: 1251.2114427089691 and batch: 1250, loss is 4.119049806594848 and perplexity is 61.500776859522674
At time: 1252.3497965335846 and batch: 1300, loss is 4.096618723869324 and perplexity is 60.13660497085157
At time: 1253.4879350662231 and batch: 1350, loss is 4.073673148155212 and perplexity is 58.77244650089701
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.55427734375 and perplexity of 95.03805057240687
Finished 38 epochs...
Completing Train Step...
At time: 1256.8803639411926 and batch: 50, loss is 4.238620357513428 and perplexity is 69.31215984300667
At time: 1258.0551557540894 and batch: 100, loss is 4.241178503036499 and perplexity is 69.48969742106495
At time: 1259.199227809906 and batch: 150, loss is 4.20664047241211 and perplexity is 67.1306333383847
At time: 1260.3434562683105 and batch: 200, loss is 4.201426181793213 and perplexity is 66.78150572418004
At time: 1261.4875383377075 and batch: 250, loss is 4.2066062688827515 and perplexity is 67.12833727306348
At time: 1262.6326122283936 and batch: 300, loss is 4.213373851776123 and perplexity is 67.58417457864437
At time: 1263.777215719223 and batch: 350, loss is 4.20579017162323 and perplexity is 67.0735763691298
At time: 1264.9222345352173 and batch: 400, loss is 4.230517482757568 and perplexity is 68.7528013590705
At time: 1266.0664882659912 and batch: 450, loss is 4.165956063270569 and perplexity is 64.45427536071132
At time: 1267.2108397483826 and batch: 500, loss is 4.241088199615478 and perplexity is 69.48342254698768
At time: 1268.357459783554 and batch: 550, loss is 4.237972106933594 and perplexity is 69.26724275553583
At time: 1269.5021660327911 and batch: 600, loss is 4.1869805669784546 and perplexity is 65.82374022661713
At time: 1270.6453936100006 and batch: 650, loss is 4.206766171455383 and perplexity is 67.13907212513229
At time: 1271.7903306484222 and batch: 700, loss is 4.2146685552597045 and perplexity is 67.67173271358664
At time: 1272.934276342392 and batch: 750, loss is 4.170510096549988 and perplexity is 64.74847165711715
At time: 1274.0786592960358 and batch: 800, loss is 4.137492942810058 and perplexity is 62.64556838771374
At time: 1275.222972869873 and batch: 850, loss is 4.101467881202698 and perplexity is 60.42892500997203
At time: 1276.3677394390106 and batch: 900, loss is 4.1483747053146365 and perplexity is 63.33098509227765
At time: 1277.5119585990906 and batch: 950, loss is 4.115283970832825 and perplexity is 61.26961057495424
At time: 1278.6564903259277 and batch: 1000, loss is 4.141434240341186 and perplexity is 62.8929604142828
At time: 1279.8011600971222 and batch: 1050, loss is 4.076595010757447 and perplexity is 58.9444226373399
At time: 1280.946450471878 and batch: 1100, loss is 4.060056381225586 and perplexity is 57.97757983381774
At time: 1282.0911722183228 and batch: 1150, loss is 4.080340619087219 and perplexity is 59.16561935729429
At time: 1283.2345869541168 and batch: 1200, loss is 4.0522194099426265 and perplexity is 57.524987000570825
At time: 1284.3785154819489 and batch: 1250, loss is 4.119227900505066 and perplexity is 61.511730748736525
At time: 1285.5223336219788 and batch: 1300, loss is 4.096776313781739 and perplexity is 60.14608263993475
At time: 1286.6667699813843 and batch: 1350, loss is 4.073790364265442 and perplexity is 58.77933598223574
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.55425048828125 and perplexity of 95.03549831528085
Finished 39 epochs...
Completing Train Step...
At time: 1290.1136116981506 and batch: 50, loss is 4.238344593048096 and perplexity is 69.29304864752196
At time: 1291.2867114543915 and batch: 100, loss is 4.240823373794556 and perplexity is 69.46502397888666
At time: 1292.430678844452 and batch: 150, loss is 4.206225643157959 and perplexity is 67.10279136305846
At time: 1293.5747737884521 and batch: 200, loss is 4.200986919403076 and perplexity is 66.75217756220951
At time: 1294.7179543972015 and batch: 250, loss is 4.206163053512573 and perplexity is 67.09859155457629
At time: 1295.8617672920227 and batch: 300, loss is 4.212939691543579 and perplexity is 67.55483858641442
At time: 1297.004412651062 and batch: 350, loss is 4.205355315208435 and perplexity is 67.04441533507335
At time: 1298.1479942798615 and batch: 400, loss is 4.230083231925964 and perplexity is 68.72295187945498
At time: 1299.2918021678925 and batch: 450, loss is 4.16555121421814 and perplexity is 64.42818638981046
At time: 1300.4359438419342 and batch: 500, loss is 4.240717840194702 and perplexity is 69.45769347165647
At time: 1301.5758697986603 and batch: 550, loss is 4.237629556655884 and perplexity is 69.24351930576289
At time: 1302.7148246765137 and batch: 600, loss is 4.186683692932129 and perplexity is 65.80420176688607
At time: 1303.8544142246246 and batch: 650, loss is 4.206495471000672 and perplexity is 67.12090000749032
At time: 1304.9935104846954 and batch: 700, loss is 4.214444227218628 and perplexity is 67.65655374894811
At time: 1306.1332502365112 and batch: 750, loss is 4.170322198867797 and perplexity is 64.73630671228567
At time: 1307.2726168632507 and batch: 800, loss is 4.137321329116821 and perplexity is 62.63481847280045
At time: 1308.4116463661194 and batch: 850, loss is 4.101363286972046 and perplexity is 60.422604823584784
At time: 1309.5503392219543 and batch: 900, loss is 4.148306512832642 and perplexity is 63.32666654246504
At time: 1310.6921255588531 and batch: 950, loss is 4.115242357254028 and perplexity is 61.26706098023602
At time: 1311.8309049606323 and batch: 1000, loss is 4.141427073478699 and perplexity is 62.89250967069929
At time: 1312.9705300331116 and batch: 1050, loss is 4.076633596420288 and perplexity is 58.94669709083855
At time: 1314.1103813648224 and batch: 1100, loss is 4.060131659507752 and perplexity is 57.981944450710145
At time: 1315.2769930362701 and batch: 1150, loss is 4.080443911552429 and perplexity is 59.17173103561308
At time: 1316.4156141281128 and batch: 1200, loss is 4.05234884262085 and perplexity is 57.53243309557668
At time: 1317.5550470352173 and batch: 1250, loss is 4.119361305236817 and perplexity is 61.51993725205762
At time: 1318.6943151950836 and batch: 1300, loss is 4.0968902921676635 and perplexity is 60.15293838404966
At time: 1319.833676815033 and batch: 1350, loss is 4.073866405487061 and perplexity is 58.78380580469301
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.554231363932292 and perplexity of 95.03368084062674
Finished 40 epochs...
Completing Train Step...
At time: 1323.251942396164 and batch: 50, loss is 4.238065729141235 and perplexity is 69.27372801129708
At time: 1324.3928606510162 and batch: 100, loss is 4.240477495193481 and perplexity is 69.4410016682103
At time: 1325.5342469215393 and batch: 150, loss is 4.205835657119751 and perplexity is 67.07662731344072
At time: 1326.67693734169 and batch: 200, loss is 4.200569024085999 and perplexity is 66.72428796767292
At time: 1327.819013118744 and batch: 250, loss is 4.205751104354858 and perplexity is 67.07095603890605
At time: 1328.9603135585785 and batch: 300, loss is 4.212533016204834 and perplexity is 67.52737128506398
At time: 1330.1020250320435 and batch: 350, loss is 4.204957194328308 and perplexity is 67.01772886600533
At time: 1331.2440502643585 and batch: 400, loss is 4.229689445495605 and perplexity is 68.69589504120815
At time: 1332.385847568512 and batch: 450, loss is 4.165179810523987 and perplexity is 64.40426196646231
At time: 1333.5272262096405 and batch: 500, loss is 4.240381479263306 and perplexity is 69.43433454592291
At time: 1334.669962644577 and batch: 550, loss is 4.237326183319092 and perplexity is 69.2225158543645
At time: 1335.8119027614594 and batch: 600, loss is 4.186411027908325 and perplexity is 65.78626170856927
At time: 1336.9539296627045 and batch: 650, loss is 4.206227087974549 and perplexity is 67.10288831435469
At time: 1338.0954480171204 and batch: 700, loss is 4.214218277931213 and perplexity is 67.64126852574724
At time: 1339.2376117706299 and batch: 750, loss is 4.170118570327759 and perplexity is 64.72312589470322
At time: 1340.37992811203 and batch: 800, loss is 4.137137598991394 and perplexity is 62.62331162685586
At time: 1341.5223531723022 and batch: 850, loss is 4.101249966621399 and perplexity is 60.41575810076301
At time: 1342.6647052764893 and batch: 900, loss is 4.148228006362915 and perplexity is 63.32169518457965
At time: 1343.8340129852295 and batch: 950, loss is 4.115198755264283 and perplexity is 61.26438967270899
At time: 1344.9759511947632 and batch: 1000, loss is 4.14140374660492 and perplexity is 62.891042602175666
At time: 1346.1172189712524 and batch: 1050, loss is 4.076657066345215 and perplexity is 58.94808058162907
At time: 1347.2589175701141 and batch: 1100, loss is 4.060182075500489 and perplexity is 57.98486774169014
At time: 1348.4016699790955 and batch: 1150, loss is 4.080517520904541 and perplexity is 59.17608678870809
At time: 1349.544004201889 and batch: 1200, loss is 4.0524364185333255 and perplexity is 57.537471771532076
At time: 1350.685490846634 and batch: 1250, loss is 4.119465022087097 and perplexity is 61.526318237080986
At time: 1351.8274431228638 and batch: 1300, loss is 4.096985268592834 and perplexity is 60.15865176641491
At time: 1352.9692902565002 and batch: 1350, loss is 4.073933625221253 and perplexity is 58.78775736930408
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.554217529296875 and perplexity of 95.03236609339454
Finished 41 epochs...
Completing Train Step...
At time: 1356.3957681655884 and batch: 50, loss is 4.237795114517212 and perplexity is 69.25498406374417
At time: 1357.5373003482819 and batch: 100, loss is 4.240147399902344 and perplexity is 69.41808330337801
At time: 1358.6798496246338 and batch: 150, loss is 4.20546724319458 and perplexity is 67.0519199014417
At time: 1359.8219623565674 and batch: 200, loss is 4.200178828239441 and perplexity is 66.69825750646258
At time: 1360.964553117752 and batch: 250, loss is 4.205364789962768 and perplexity is 67.04505056744739
At time: 1362.1070275306702 and batch: 300, loss is 4.212157535552978 and perplexity is 67.50202082327758
At time: 1363.2498805522919 and batch: 350, loss is 4.20458423614502 and perplexity is 66.99273871602946
At time: 1364.3916730880737 and batch: 400, loss is 4.229321303367615 and perplexity is 68.67060984278244
At time: 1365.5332653522491 and batch: 450, loss is 4.164834504127502 and perplexity is 64.38202660207216
At time: 1366.675597190857 and batch: 500, loss is 4.240063343048096 and perplexity is 69.41224848289939
At time: 1367.8183579444885 and batch: 550, loss is 4.2370288276672365 and perplexity is 69.20193520807696
At time: 1368.9615731239319 and batch: 600, loss is 4.186177382469177 and perplexity is 65.77089284406492
At time: 1370.1042215824127 and batch: 650, loss is 4.205995149612427 and perplexity is 67.08732638511937
At time: 1371.24649477005 and batch: 700, loss is 4.214026737213135 and perplexity is 67.6283137093291
At time: 1372.3888549804688 and batch: 750, loss is 4.169953045845031 and perplexity is 64.71241351937365
At time: 1373.5585227012634 and batch: 800, loss is 4.136984848976136 and perplexity is 62.613746645593416
At time: 1374.7007026672363 and batch: 850, loss is 4.101141085624695 and perplexity is 60.40918033090793
At time: 1375.8431568145752 and batch: 900, loss is 4.148143033981324 and perplexity is 63.31631481792794
At time: 1376.9854934215546 and batch: 950, loss is 4.1151344060897825 and perplexity is 61.26044748664687
At time: 1378.1278908252716 and batch: 1000, loss is 4.14136579990387 and perplexity is 62.8886561398628
At time: 1379.2705235481262 and batch: 1050, loss is 4.076652598381043 and perplexity is 58.9478172043054
At time: 1380.4128904342651 and batch: 1100, loss is 4.060200462341308 and perplexity is 57.98593391002496
At time: 1381.5548751354218 and batch: 1150, loss is 4.080563888549805 and perplexity is 59.178830708122454
At time: 1382.6975219249725 and batch: 1200, loss is 4.052501749992371 and perplexity is 57.541230901306065
At time: 1383.839982509613 and batch: 1250, loss is 4.11953489780426 and perplexity is 61.53061758290037
At time: 1384.9825947284698 and batch: 1300, loss is 4.097045469284057 and perplexity is 60.162273467847676
At time: 1386.1248288154602 and batch: 1350, loss is 4.073970804214477 and perplexity is 58.789943079568
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.55420654296875 and perplexity of 95.03132204237326
Finished 42 epochs...
Completing Train Step...
At time: 1389.5217201709747 and batch: 50, loss is 4.237516632080078 and perplexity is 69.23570045219665
At time: 1390.690851688385 and batch: 100, loss is 4.239819936752319 and perplexity is 69.39535516066853
At time: 1391.8328049182892 and batch: 150, loss is 4.20511342048645 and perplexity is 67.0281996061939
At time: 1392.9746112823486 and batch: 200, loss is 4.199810810089112 and perplexity is 66.67371585326877
At time: 1394.1160991191864 and batch: 250, loss is 4.204994034767151 and perplexity is 67.02019787402638
At time: 1395.2586145401 and batch: 300, loss is 4.211793923377991 and perplexity is 67.477480728479
At time: 1396.4007968902588 and batch: 350, loss is 4.204236278533935 and perplexity is 66.96943213779163
At time: 1397.5432715415955 and batch: 400, loss is 4.228979034423828 and perplexity is 68.6471100475368
At time: 1398.6852009296417 and batch: 450, loss is 4.164514374732971 and perplexity is 64.36141932155147
At time: 1399.8318843841553 and batch: 500, loss is 4.2397703933715825 and perplexity is 69.39191716533212
At time: 1400.9736506938934 and batch: 550, loss is 4.236765556335449 and perplexity is 69.18371872047715
At time: 1402.143234014511 and batch: 600, loss is 4.185926175117492 and perplexity is 65.75437278732235
At time: 1403.2853028774261 and batch: 650, loss is 4.205746955871582 and perplexity is 67.07067779674375
At time: 1404.4275755882263 and batch: 700, loss is 4.213812208175659 and perplexity is 67.61380702839072
At time: 1405.5695803165436 and batch: 750, loss is 4.169757075309754 and perplexity is 64.69973303559833
At time: 1406.7113893032074 and batch: 800, loss is 4.136809105873108 and perplexity is 62.60274367834186
At time: 1407.8535721302032 and batch: 850, loss is 4.101021862030029 and perplexity is 60.40197856059705
At time: 1408.9958474636078 and batch: 900, loss is 4.148053150177002 and perplexity is 63.3106239624382
At time: 1410.137767314911 and batch: 950, loss is 4.1150745677947995 and perplexity is 61.256781875592424
At time: 1411.2795004844666 and batch: 1000, loss is 4.141317090988159 and perplexity is 62.88559297621403
At time: 1412.4211637973785 and batch: 1050, loss is 4.076643309593201 and perplexity is 58.94726965308069
At time: 1413.5626103878021 and batch: 1100, loss is 4.060210471153259 and perplexity is 57.986514283237675
At time: 1414.7043254375458 and batch: 1150, loss is 4.080595698356628 and perplexity is 59.18071320523608
At time: 1415.845956325531 and batch: 1200, loss is 4.052544655799866 and perplexity is 57.54369980724698
At time: 1416.9874532222748 and batch: 1250, loss is 4.119598870277405 and perplexity is 61.534553974590274
At time: 1418.129959344864 and batch: 1300, loss is 4.097107195854187 and perplexity is 60.165987193256655
At time: 1419.2723650932312 and batch: 1350, loss is 4.074006652832031 and perplexity is 58.792050655530076
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.5541984049479165 and perplexity of 95.0305486786415
Finished 43 epochs...
Completing Train Step...
At time: 1422.6668510437012 and batch: 50, loss is 4.237254285812378 and perplexity is 69.21753910697615
At time: 1423.8325605392456 and batch: 100, loss is 4.2395103073120115 and perplexity is 69.37387164182678
At time: 1424.9709770679474 and batch: 150, loss is 4.204777660369873 and perplexity is 67.0056979878646
At time: 1426.1099574565887 and batch: 200, loss is 4.199480609893799 and perplexity is 66.6517038136617
At time: 1427.248250246048 and batch: 250, loss is 4.2046447324752805 and perplexity is 66.99679165346859
At time: 1428.3869111537933 and batch: 300, loss is 4.21145652294159 and perplexity is 67.45471763738831
At time: 1429.525298833847 and batch: 350, loss is 4.203906083106995 and perplexity is 66.94732278795892
At time: 1430.6638851165771 and batch: 400, loss is 4.228651266098023 and perplexity is 68.62461338625306
At time: 1431.8299968242645 and batch: 450, loss is 4.164202423095703 and perplexity is 64.34134480271949
At time: 1432.9687139987946 and batch: 500, loss is 4.23948296546936 and perplexity is 69.37197485827514
At time: 1434.1073544025421 and batch: 550, loss is 4.23649230003357 and perplexity is 69.16481641605385
At time: 1435.2453708648682 and batch: 600, loss is 4.185666995048523 and perplexity is 65.73733277275976
At time: 1436.383838891983 and batch: 650, loss is 4.205511379241943 and perplexity is 67.0548793734635
At time: 1437.5220487117767 and batch: 700, loss is 4.213613786697388 and perplexity is 67.600392327775
At time: 1438.6604356765747 and batch: 750, loss is 4.1695769739151 and perplexity is 64.68808157269874
At time: 1439.798630952835 and batch: 800, loss is 4.136649713516236 and perplexity is 62.5927660746783
At time: 1440.9373137950897 and batch: 850, loss is 4.100904664993286 and perplexity is 60.39490004249512
At time: 1442.074862241745 and batch: 900, loss is 4.14795955657959 and perplexity is 63.30469877067144
At time: 1443.2125754356384 and batch: 950, loss is 4.115006723403931 and perplexity is 61.252626087514535
At time: 1444.3506762981415 and batch: 1000, loss is 4.1412633228302 and perplexity is 62.88221182461751
At time: 1445.4894571304321 and batch: 1050, loss is 4.076624064445496 and perplexity is 58.94613521508567
At time: 1446.6281743049622 and batch: 1100, loss is 4.060205626487732 and perplexity is 57.98623335865137
At time: 1447.7683563232422 and batch: 1150, loss is 4.08061445236206 and perplexity is 59.18182309106039
At time: 1448.9063580036163 and batch: 1200, loss is 4.05257351398468 and perplexity is 57.545360437932196
At time: 1450.0444161891937 and batch: 1250, loss is 4.119644975662231 and perplexity is 61.5373911142846
At time: 1451.1825289726257 and batch: 1300, loss is 4.097152738571167 and perplexity is 60.16872737818047
At time: 1452.320565700531 and batch: 1350, loss is 4.074029669761658 and perplexity is 58.79340388359616
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.554194742838542 and perplexity of 95.0302006670155
Finished 44 epochs...
Completing Train Step...
At time: 1455.748445034027 and batch: 50, loss is 4.236991767883301 and perplexity is 69.19937064683154
At time: 1456.892504453659 and batch: 100, loss is 4.239207725524903 and perplexity is 69.35288354723446
At time: 1458.036864042282 and batch: 150, loss is 4.204453544616699 and perplexity is 66.98398390472259
At time: 1459.180716753006 and batch: 200, loss is 4.199158868789673 and perplexity is 66.63026267031833
At time: 1460.3556337356567 and batch: 250, loss is 4.204308323860168 and perplexity is 66.9742571461852
At time: 1461.5001266002655 and batch: 300, loss is 4.211129441261291 and perplexity is 67.43265804284071
At time: 1462.6441287994385 and batch: 350, loss is 4.203586874008178 and perplexity is 66.92595600380098
At time: 1463.789032459259 and batch: 400, loss is 4.2283369827270505 and perplexity is 68.60304920023638
At time: 1464.9334318637848 and batch: 450, loss is 4.163906240463257 and perplexity is 64.32229083570707
At time: 1466.077790737152 and batch: 500, loss is 4.239210233688355 and perplexity is 69.35305749582041
At time: 1467.2224259376526 and batch: 550, loss is 4.2362308692932125 and perplexity is 69.14673697025596
At time: 1468.3671069145203 and batch: 600, loss is 4.185426445007324 and perplexity is 65.72152155642357
At time: 1469.5107476711273 and batch: 650, loss is 4.205286192893982 and perplexity is 67.03978123007609
At time: 1470.6558499336243 and batch: 700, loss is 4.213419179916382 and perplexity is 67.58723811302059
At time: 1471.799614906311 and batch: 750, loss is 4.169403920173645 and perplexity is 64.67688802672548
At time: 1472.9428379535675 and batch: 800, loss is 4.136492257118225 and perplexity is 62.582911219066055
At time: 1474.0875778198242 and batch: 850, loss is 4.10078498840332 and perplexity is 60.387672619292005
At time: 1475.232430934906 and batch: 900, loss is 4.14786244392395 and perplexity is 63.29855138175881
At time: 1476.3762826919556 and batch: 950, loss is 4.114929223060608 and perplexity is 61.247879171909524
At time: 1477.5203306674957 and batch: 1000, loss is 4.141198906898499 and perplexity is 62.87816133881467
At time: 1478.6646721363068 and batch: 1050, loss is 4.07658839225769 and perplexity is 58.94403251498405
At time: 1479.809809923172 and batch: 1100, loss is 4.060186862945557 and perplexity is 57.98514534172372
At time: 1480.954342365265 and batch: 1150, loss is 4.08061972618103 and perplexity is 59.1821352061047
At time: 1482.0997853279114 and batch: 1200, loss is 4.052593178749085 and perplexity is 57.54649206501433
At time: 1483.2443013191223 and batch: 1250, loss is 4.119679236412049 and perplexity is 61.53949946756267
At time: 1484.3879308700562 and batch: 1300, loss is 4.0971865940094 and perplexity is 60.17076445129655
At time: 1485.5319192409515 and batch: 1350, loss is 4.074036455154419 and perplexity is 58.79380282128672
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.554192301432292 and perplexity of 95.02996865997291
Finished 45 epochs...
Completing Train Step...
At time: 1488.9935684204102 and batch: 50, loss is 4.236806621551514 and perplexity is 69.18655982316942
At time: 1490.1377263069153 and batch: 100, loss is 4.23891206741333 and perplexity is 69.33238183555079
At time: 1491.2823157310486 and batch: 150, loss is 4.204140462875366 and perplexity is 66.96301572494868
At time: 1492.426019191742 and batch: 200, loss is 4.1988441324234005 and perplexity is 66.60929500337843
At time: 1493.5697884559631 and batch: 250, loss is 4.2039859056472775 and perplexity is 66.9526669066167
At time: 1494.713721036911 and batch: 300, loss is 4.210814580917359 and perplexity is 67.4114295151232
At time: 1495.8588004112244 and batch: 350, loss is 4.203283081054687 and perplexity is 66.9056274579522
At time: 1497.004114151001 and batch: 400, loss is 4.228036909103394 and perplexity is 68.5824663230127
At time: 1498.1476938724518 and batch: 450, loss is 4.163636598587036 and perplexity is 64.30494919064523
At time: 1499.292423248291 and batch: 500, loss is 4.238959140777588 and perplexity is 69.33564562083389
At time: 1500.436158657074 and batch: 550, loss is 4.235992584228516 and perplexity is 69.1302622984755
At time: 1501.5806241035461 and batch: 600, loss is 4.185406332015991 and perplexity is 65.72019971332328
At time: 1502.725298166275 and batch: 650, loss is 4.205080251693726 and perplexity is 67.02597639860525
At time: 1503.8709802627563 and batch: 700, loss is 4.213244609832763 and perplexity is 67.57544043300258
At time: 1505.0143058300018 and batch: 750, loss is 4.169243173599243 and perplexity is 64.66649227409542
At time: 1506.1590831279755 and batch: 800, loss is 4.136346483230591 and perplexity is 62.573788929710155
At time: 1507.304016828537 and batch: 850, loss is 4.100664968490601 and perplexity is 60.38042533101306
At time: 1508.4503245353699 and batch: 900, loss is 4.147756295204163 and perplexity is 63.29183267816245
At time: 1509.5947906970978 and batch: 950, loss is 4.114840631484985 and perplexity is 61.24245336613401
At time: 1510.7390341758728 and batch: 1000, loss is 4.141126937866211 and perplexity is 62.87363622122722
At time: 1511.8835396766663 and batch: 1050, loss is 4.076540703773499 and perplexity is 58.941221630445206
At time: 1513.0268733501434 and batch: 1100, loss is 4.060146770477295 and perplexity is 57.98282062072667
At time: 1514.1707060337067 and batch: 1150, loss is 4.080607180595398 and perplexity is 59.18139273621692
At time: 1515.315545797348 and batch: 1200, loss is 4.052591509819031 and perplexity is 57.546396024024375
At time: 1516.4592781066895 and batch: 1250, loss is 4.119686794281006 and perplexity is 61.53996457679296
At time: 1517.6039245128632 and batch: 1300, loss is 4.097196578979492 and perplexity is 60.17136525757955
At time: 1518.747181892395 and batch: 1350, loss is 4.074034314155579 and perplexity is 58.793676943957855
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.554193929036458 and perplexity of 95.03012333127168
Annealing...
Finished 46 epochs...
Completing Train Step...
At time: 1522.1942582130432 and batch: 50, loss is 4.2369174385070805 and perplexity is 69.19422729193008
At time: 1523.366804599762 and batch: 100, loss is 4.239421415328979 and perplexity is 69.36770513488649
At time: 1524.5109071731567 and batch: 150, loss is 4.204929094314576 and perplexity is 67.01584569336256
At time: 1525.654584646225 and batch: 200, loss is 4.200077242851258 and perplexity is 66.69148228222038
At time: 1526.7978346347809 and batch: 250, loss is 4.205652985572815 and perplexity is 67.06437544123443
At time: 1527.94136428833 and batch: 300, loss is 4.212325325012207 and perplexity is 67.51334790110394
At time: 1529.0857396125793 and batch: 350, loss is 4.204684133529663 and perplexity is 66.99943144970503
At time: 1530.2312066555023 and batch: 400, loss is 4.229540700912476 and perplexity is 68.6856776588465
At time: 1531.3755297660828 and batch: 450, loss is 4.165373344421386 and perplexity is 64.41672758051035
At time: 1532.5195486545563 and batch: 500, loss is 4.240083904266357 and perplexity is 69.41367569796304
At time: 1533.663061618805 and batch: 550, loss is 4.237149324417114 and perplexity is 69.21027431876254
At time: 1534.8080983161926 and batch: 600, loss is 4.186318874359131 and perplexity is 65.78019955039359
At time: 1535.9518604278564 and batch: 650, loss is 4.20611732006073 and perplexity is 67.09552297453959
At time: 1537.0961589813232 and batch: 700, loss is 4.213873982429504 and perplexity is 67.61798394988134
At time: 1538.2411541938782 and batch: 750, loss is 4.170630512237548 and perplexity is 64.7562688582935
At time: 1539.3857004642487 and batch: 800, loss is 4.137179551124572 and perplexity is 62.62593886347398
At time: 1540.5294375419617 and batch: 850, loss is 4.10014307975769 and perplexity is 60.348921688757486
At time: 1541.6733779907227 and batch: 900, loss is 4.146653637886048 and perplexity is 63.222081938332046
At time: 1542.8168513774872 and batch: 950, loss is 4.113248629570007 and perplexity is 61.14503283051259
At time: 1543.9607944488525 and batch: 1000, loss is 4.13932276725769 and perplexity is 62.7603037210307
At time: 1545.1064257621765 and batch: 1050, loss is 4.073795757293701 and perplexity is 58.77965298171056
At time: 1546.2502415180206 and batch: 1100, loss is 4.057235522270203 and perplexity is 57.81426371269901
At time: 1547.4229950904846 and batch: 1150, loss is 4.077941632270813 and perplexity is 59.02385193355279
At time: 1548.5665173530579 and batch: 1200, loss is 4.049699659347534 and perplexity is 57.38022084424282
At time: 1549.710829257965 and batch: 1250, loss is 4.116991791725159 and perplexity is 61.37433749791851
At time: 1550.8547151088715 and batch: 1300, loss is 4.094931826591492 and perplexity is 60.03524621057232
At time: 1551.9996073246002 and batch: 1350, loss is 4.072501397132873 and perplexity is 58.703620158167844
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.5543603515625 and perplexity of 95.04593980051841
Annealing...
Finished 47 epochs...
Completing Train Step...
At time: 1555.4390313625336 and batch: 50, loss is 4.237089643478393 and perplexity is 69.20614390787671
At time: 1556.6154499053955 and batch: 100, loss is 4.239315547943115 and perplexity is 69.36036174600002
At time: 1557.762068271637 and batch: 150, loss is 4.204712753295898 and perplexity is 67.00134898521058
At time: 1558.909443616867 and batch: 200, loss is 4.199977202415466 and perplexity is 66.6848107709853
At time: 1560.056221485138 and batch: 250, loss is 4.205561413764953 and perplexity is 67.05823451630424
At time: 1561.202675819397 and batch: 300, loss is 4.21231620311737 and perplexity is 67.51273205425315
At time: 1562.3492712974548 and batch: 350, loss is 4.20466178894043 and perplexity is 66.99793439165607
At time: 1563.4962539672852 and batch: 400, loss is 4.229433045387268 and perplexity is 68.67828366415326
At time: 1564.6430180072784 and batch: 450, loss is 4.165252952575684 and perplexity is 64.40897279859844
At time: 1565.7901620864868 and batch: 500, loss is 4.239999113082885 and perplexity is 69.4077902797708
At time: 1566.9370124340057 and batch: 550, loss is 4.2370364952087405 and perplexity is 69.20246581882155
At time: 1568.0842411518097 and batch: 600, loss is 4.186211466789246 and perplexity is 65.77313463843261
At time: 1569.232437133789 and batch: 650, loss is 4.206092877388 and perplexity is 67.09388300067266
At time: 1570.3800039291382 and batch: 700, loss is 4.213813533782959 and perplexity is 67.61389665780634
At time: 1571.5272295475006 and batch: 750, loss is 4.170683250427246 and perplexity is 64.7596840767401
At time: 1572.6736817359924 and batch: 800, loss is 4.137186164855957 and perplexity is 62.62635305598102
At time: 1573.8204329013824 and batch: 850, loss is 4.100026960372925 and perplexity is 60.34191441594771
At time: 1574.9685842990875 and batch: 900, loss is 4.146504020690918 and perplexity is 63.21262353534966
At time: 1576.1476428508759 and batch: 950, loss is 4.113048534393311 and perplexity is 61.13279922834748
At time: 1577.294852256775 and batch: 1000, loss is 4.139093999862671 and perplexity is 62.74594785197781
At time: 1578.4428095817566 and batch: 1050, loss is 4.073441290855408 and perplexity is 58.75882125976529
At time: 1579.590130329132 and batch: 1100, loss is 4.056846013069153 and perplexity is 57.79174891017704
At time: 1580.7379088401794 and batch: 1150, loss is 4.077567110061645 and perplexity is 59.00175032916226
At time: 1581.8852849006653 and batch: 1200, loss is 4.049275126457214 and perplexity is 57.35586622327521
At time: 1583.0322177410126 and batch: 1250, loss is 4.116570692062378 and perplexity is 61.34849822593095
At time: 1584.1789343357086 and batch: 1300, loss is 4.094579758644104 and perplexity is 60.014113444971045
At time: 1585.326754808426 and batch: 1350, loss is 4.072262840270996 and perplexity is 58.68961767702248
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.554380289713541 and perplexity of 95.04783485971394
Annealing...
Finished 48 epochs...
Completing Train Step...
At time: 1588.8082513809204 and batch: 50, loss is 4.2371180057525635 and perplexity is 69.2081067793401
At time: 1589.9560868740082 and batch: 100, loss is 4.2393037128448485 and perplexity is 69.35954086416056
At time: 1591.1041209697723 and batch: 150, loss is 4.204683399200439 and perplexity is 66.99938225008259
At time: 1592.2515177726746 and batch: 200, loss is 4.199962553977966 and perplexity is 66.68383394985696
At time: 1593.4000449180603 and batch: 250, loss is 4.205549893379211 and perplexity is 67.05746198402537
At time: 1594.5476653575897 and batch: 300, loss is 4.212315268516541 and perplexity is 67.51266895682724
At time: 1595.694965839386 and batch: 350, loss is 4.204655513763428 and perplexity is 66.99751396907811
At time: 1596.8428268432617 and batch: 400, loss is 4.229414319992065 and perplexity is 68.67699764819038
At time: 1597.9907932281494 and batch: 450, loss is 4.165232353210449 and perplexity is 64.40764602830872
At time: 1599.1391952037811 and batch: 500, loss is 4.239983625411988 and perplexity is 69.40671532308151
At time: 1600.2868027687073 and batch: 550, loss is 4.237015676498413 and perplexity is 69.20102512772846
At time: 1601.4349415302277 and batch: 600, loss is 4.186191992759705 and perplexity is 65.77185378293741
At time: 1602.5831615924835 and batch: 650, loss is 4.206086430549622 and perplexity is 67.09345045864703
At time: 1603.7311930656433 and batch: 700, loss is 4.213800597190857 and perplexity is 67.61302197006256
At time: 1604.9086527824402 and batch: 750, loss is 4.170687570571899 and perplexity is 64.7599638485473
At time: 1606.056556224823 and batch: 800, loss is 4.13718430519104 and perplexity is 62.626236592057644
At time: 1607.2042660713196 and batch: 850, loss is 4.100007839202881 and perplexity is 60.3407606189724
At time: 1608.351960659027 and batch: 900, loss is 4.146480317115784 and perplexity is 63.211125187936446
At time: 1609.499713420868 and batch: 950, loss is 4.113017601966858 and perplexity is 61.130908271777564
At time: 1610.6471090316772 and batch: 1000, loss is 4.139058861732483 and perplexity is 62.74374311542882
At time: 1611.7947041988373 and batch: 1050, loss is 4.073386516571045 and perplexity is 58.75560287552391
At time: 1612.9411618709564 and batch: 1100, loss is 4.05678542137146 and perplexity is 57.78824731608276
At time: 1614.0890972614288 and batch: 1150, loss is 4.0775091123580935 and perplexity is 58.99832846236881
At time: 1615.236534357071 and batch: 1200, loss is 4.049208807945251 and perplexity is 57.35206259370185
At time: 1616.3839735984802 and batch: 1250, loss is 4.11650444984436 and perplexity is 61.344434499932966
At time: 1617.5320727825165 and batch: 1300, loss is 4.094524388313293 and perplexity is 60.010790535652404
At time: 1618.6796531677246 and batch: 1350, loss is 4.072225022315979 and perplexity is 58.68739819766954
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.554382731119792 and perplexity of 95.04806691037534
Annealing...
Finished 49 epochs...
Completing Train Step...
At time: 1622.1600677967072 and batch: 50, loss is 4.2371226406097415 and perplexity is 69.20842754977394
At time: 1623.3081424236298 and batch: 100, loss is 4.239302606582641 and perplexity is 69.35946413436425
At time: 1624.4568274021149 and batch: 150, loss is 4.204679746627807 and perplexity is 66.99913753041955
At time: 1625.6039457321167 and batch: 200, loss is 4.199961133003235 and perplexity is 66.6837391938813
At time: 1626.751924753189 and batch: 250, loss is 4.205549249649048 and perplexity is 67.0574188171283
At time: 1627.9002244472504 and batch: 300, loss is 4.212315835952759 and perplexity is 67.51270726597166
At time: 1629.0473039150238 and batch: 350, loss is 4.204655089378357 and perplexity is 66.99748553633941
At time: 1630.194798707962 and batch: 400, loss is 4.229412307739258 and perplexity is 68.67685945284812
At time: 1631.3420124053955 and batch: 450, loss is 4.165230150222778 and perplexity is 64.40750413921492
At time: 1632.4893426895142 and batch: 500, loss is 4.239982023239135 and perplexity is 69.40660412161554
At time: 1633.6371371746063 and batch: 550, loss is 4.237013444900513 and perplexity is 69.2008706990384
At time: 1634.8159441947937 and batch: 600, loss is 4.186189889907837 and perplexity is 65.77171547461727
At time: 1635.9631066322327 and batch: 650, loss is 4.206086196899414 and perplexity is 67.09343478225023
At time: 1637.1113021373749 and batch: 700, loss is 4.213799433708191 and perplexity is 67.61294330352929
At time: 1638.2585670948029 and batch: 750, loss is 4.170689263343811 and perplexity is 64.76007347248792
At time: 1639.4062912464142 and batch: 800, loss is 4.137184848785401 and perplexity is 62.626270635335935
At time: 1640.5549364089966 and batch: 850, loss is 4.100005497932434 and perplexity is 60.34061934509821
At time: 1641.7026839256287 and batch: 900, loss is 4.146477322578431 and perplexity is 63.21093590014435
At time: 1642.850429058075 and batch: 950, loss is 4.1130131196975706 and perplexity is 61.13063426719899
At time: 1643.9988687038422 and batch: 1000, loss is 4.13905354976654 and perplexity is 62.74340982368749
At time: 1645.1458892822266 and batch: 1050, loss is 4.0733778238296505 and perplexity is 58.75509213048254
At time: 1646.2943224906921 and batch: 1100, loss is 4.056775708198547 and perplexity is 57.78768601157026
At time: 1647.4410617351532 and batch: 1150, loss is 4.077499876022339 and perplexity is 58.99778353651472
At time: 1648.5881316661835 and batch: 1200, loss is 4.049197988510132 and perplexity is 57.35144208013847
At time: 1649.7362213134766 and batch: 1250, loss is 4.116493344306946 and perplexity is 61.34375324080336
At time: 1650.883898973465 and batch: 1300, loss is 4.094515147209168 and perplexity is 60.010235972250804
At time: 1652.0309677124023 and batch: 1350, loss is 4.072218532562256 and perplexity is 58.68701733214446
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.554383544921875 and perplexity of 95.04814426072168
Annealing...
Model not improving. Stopping early with 95.02996865997291loss at 49 epochs.
Finished Training.
Improved accuracyfrom -118.37137219218255 to -95.02996865997291
<pretraining.langmodel.trainer.TrainLangModel object at 0x7feac5170978>
SETTINGS FOR THIS RUN
{'lr': 0.0, 'data': 'wikitext', 'dropout': 1.0, 'anneal': 2.0, 'wordvec_source': '', 'num_layers': 1, 'wordvec_dim': 200, 'batch_size': 80, 'seq_len': 20, 'tune_wordvecs': True}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.6028249263763428 and batch: 50, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 2.642472267150879 and batch: 100, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 3.7126426696777344 and batch: 150, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 4.753389596939087 and batch: 200, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 5.7932045459747314 and batch: 250, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 6.833421468734741 and batch: 300, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 7.876368284225464 and batch: 350, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 8.918577432632446 and batch: 400, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 9.960713386535645 and batch: 450, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 11.003855466842651 and batch: 500, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 12.046705961227417 and batch: 550, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 13.088714361190796 and batch: 600, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 14.127938747406006 and batch: 650, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 15.168293714523315 and batch: 700, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 16.210533380508423 and batch: 750, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 17.534200191497803 and batch: 800, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 18.578272104263306 and batch: 850, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 19.62205457687378 and batch: 900, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 20.66487765312195 and batch: 950, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 21.707613229751587 and batch: 1000, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 22.750852823257446 and batch: 1050, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 23.794244050979614 and batch: 1100, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 24.83728551864624 and batch: 1150, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 25.881577730178833 and batch: 1200, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 26.924283504486084 and batch: 1250, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 27.966925859451294 and batch: 1300, loss is 9.926758766174316 and perplexity is 20470.882020515448
At time: 29.010031700134277 and batch: 1350, loss is 9.926758766174316 and perplexity is 20470.882020515448
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 1 epochs...
Completing Train Step...
At time: 32.277586698532104 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 33.339882135391235 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 34.40061926841736 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 35.46180200576782 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 36.52590537071228 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 37.58942103385925 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 38.65230655670166 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 39.71638774871826 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 40.7802517414093 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 41.87027287483215 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 42.93540811538696 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 43.99961495399475 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 45.0635039806366 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 46.14005756378174 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 47.25615668296814 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 48.39773201942444 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 49.54191470146179 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 50.68595337867737 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 51.831024408340454 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 52.97539019584656 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 54.11999154090881 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 55.264893770217896 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 56.40923094749451 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 57.554134368896484 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 58.69821310043335 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 59.84288191795349 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 60.99015784263611 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 2 epochs...
Completing Train Step...
At time: 64.47438740730286 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 65.59387874603271 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 66.7135763168335 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 67.83351612091064 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 68.95312356948853 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 70.07155394554138 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 71.19112777709961 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 72.31185269355774 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 73.43829035758972 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 74.56666374206543 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 75.70483303070068 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 76.84912109375 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 77.99299955368042 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 79.13714075088501 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 80.28232884407043 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 81.42661046981812 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 82.57133412361145 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 83.71555161476135 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 84.86009478569031 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 86.00461769104004 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 87.1491448879242 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 88.29359292984009 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 89.43871426582336 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 90.58266997337341 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 91.72656297683716 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 92.87084221839905 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 94.01577162742615 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 3 epochs...
Completing Train Step...
At time: 97.46444368362427 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 98.57556509971619 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 99.69423985481262 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 100.8126049041748 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 101.93663597106934 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 103.07080888748169 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 104.20547389984131 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 105.34766244888306 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 106.4903335571289 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 107.63376760482788 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 108.77744674682617 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 109.9207592010498 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 111.06525373458862 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 112.20857191085815 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 113.35226488113403 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 114.49526286125183 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 115.6391224861145 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 116.78356695175171 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 117.92764496803284 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 119.0718891620636 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 120.21657228469849 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 121.40617370605469 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 122.56077122688293 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 123.7082781791687 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 124.8502459526062 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 125.99193096160889 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 127.13318109512329 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 4 epochs...
Completing Train Step...
At time: 130.62192273139954 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 131.73456978797913 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 132.85032725334167 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 133.96892714500427 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 135.09348344802856 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 136.22777485847473 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 137.36238622665405 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 138.49732303619385 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 139.6408929824829 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 140.78410935401917 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 141.92666959762573 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 143.0701732635498 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 144.212797164917 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 145.35725617408752 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 146.50030541419983 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 147.64308428764343 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 148.78637146949768 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 149.96834588050842 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 151.11109924316406 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 152.2543957233429 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 153.39758968353271 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 154.54116654396057 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 155.6843225955963 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 156.8276081085205 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 157.97025156021118 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 159.11353588104248 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 160.25872206687927 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 5 epochs...
Completing Train Step...
At time: 163.70721459388733 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 164.86524200439453 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 166.00050354003906 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 167.1375334262848 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 168.27368474006653 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 169.41264963150024 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 170.55829572677612 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 171.70420670509338 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 172.85103797912598 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 173.9978997707367 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 175.1436471939087 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 176.2899947166443 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 177.4358410835266 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 178.6257245540619 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 179.7729332447052 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 180.919442653656 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 182.06483912467957 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 183.21038484573364 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 184.35588812828064 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 185.50204515457153 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 186.64925575256348 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 187.79549527168274 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 188.94109225273132 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 190.08729195594788 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 191.23302364349365 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 192.3785161972046 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 193.52467012405396 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 6 epochs...
Completing Train Step...
At time: 196.9699158668518 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 198.1204969882965 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 199.24089431762695 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 200.3677852153778 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 201.50370597839355 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 202.6410253047943 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 203.7799220085144 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 204.92578673362732 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 206.0715413093567 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 207.21790075302124 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 208.39519715309143 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 209.5413966178894 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 210.68805050849915 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 211.8339443206787 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 212.98006582260132 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 214.1265254020691 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 215.2727873325348 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 216.41906929016113 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 217.56495666503906 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 218.71101760864258 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 219.85746264457703 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 221.00352120399475 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 222.15010929107666 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 223.29643535614014 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 224.4425311088562 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 225.5877513885498 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 226.73410391807556 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 7 epochs...
Completing Train Step...
At time: 230.19859838485718 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 231.31740927696228 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 232.43694734573364 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 233.56210494041443 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 234.6877624988556 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 235.8233036994934 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 237.00951075553894 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 238.15302109718323 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 239.29732656478882 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 240.44264101982117 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 241.58794045448303 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 242.7333116531372 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 243.87861728668213 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 245.02294874191284 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 246.16759252548218 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 247.31282424926758 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 248.45823192596436 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 249.60276341438293 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 250.7476201057434 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 251.89302706718445 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 253.03787279129028 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 254.18321895599365 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 255.3285939693451 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 256.47360944747925 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 257.61820816993713 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 258.7637355327606 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 259.9089090824127 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 8 epochs...
Completing Train Step...
At time: 263.3872113227844 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 264.506849527359 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 265.6614782810211 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 266.7891809940338 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 267.9271705150604 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 269.0716609954834 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 270.21588611602783 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 271.3607602119446 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 272.5060043334961 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 273.6504819393158 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 274.7952470779419 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 275.9401617050171 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 277.08433198928833 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 278.2297124862671 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 279.37516617774963 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 280.5190176963806 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 281.663813829422 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 282.80775451660156 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 283.95267128944397 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 285.09651350975037 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 286.24066710472107 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 287.3860442638397 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 288.5306890010834 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 289.67551136016846 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 290.82001090049744 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 291.96563506126404 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 293.1108822822571 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 9 epochs...
Completing Train Step...
At time: 296.55819177627563 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 297.71339559555054 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 298.8446841239929 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 299.98948669433594 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 301.1328248977661 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 302.2769091129303 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 303.421080827713 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 304.56585931777954 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 305.70965099334717 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 306.8549108505249 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 307.99948167800903 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 309.1438477039337 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 310.2875349521637 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 311.43169260025024 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 312.57709765434265 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 313.72211384773254 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 314.8659317493439 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 316.0105881690979 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 317.1549208164215 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 318.2988576889038 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 319.4438433647156 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 320.5876817703247 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 321.7322657108307 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 322.8767399787903 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 324.0540888309479 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 325.1982021331787 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 326.3428750038147 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 10 epochs...
Completing Train Step...
At time: 329.79133796691895 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 330.9484419822693 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 332.08376932144165 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 333.2277045249939 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 334.3709907531738 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 335.5160458087921 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 336.65973114967346 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 337.80349826812744 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 338.9475815296173 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 340.0912458896637 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 341.2347729206085 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 342.37886357307434 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 343.52273631095886 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 344.66637921333313 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 345.8099093437195 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 346.9529664516449 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 348.0973973274231 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 349.2416272163391 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 350.3855757713318 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 351.52957558631897 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 352.7039330005646 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 353.8491668701172 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 354.9935517311096 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 356.1377658843994 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 357.2822811603546 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 358.4258759021759 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 359.57460832595825 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 11 epochs...
Completing Train Step...
At time: 363.0624783039093 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 364.1832399368286 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 365.3132891654968 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 366.45576071739197 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 367.6029055118561 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 368.74882435798645 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 369.89558243751526 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 371.04216384887695 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 372.1889979839325 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 373.3360242843628 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 374.4828691482544 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 375.6294672489166 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 376.7760088443756 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 377.92218708992004 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 379.0685873031616 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 380.21464824676514 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 381.3912904262543 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 382.53784251213074 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 383.68508434295654 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 384.8316955566406 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 385.978568315506 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 387.12492203712463 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 388.2714614868164 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 389.4176163673401 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 390.5647292137146 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 391.7119371891022 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 392.85840702056885 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 12 epochs...
Completing Train Step...
At time: 396.3109543323517 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 397.43684911727905 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 398.58089089393616 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 399.7261369228363 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 400.87272024154663 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 402.0190086364746 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 403.1655285358429 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 404.31178879737854 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 405.4581916332245 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 406.604159116745 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 407.7504503726959 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 408.89718770980835 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 410.0435552597046 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 411.220805644989 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 412.36734342575073 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 413.51364970207214 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 414.65981006622314 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 415.80565118789673 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 416.95202112197876 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 418.09906220436096 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 419.2460243701935 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 420.39386677742004 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 421.53967547416687 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 422.6865327358246 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 423.8325831890106 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 424.97914576530457 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 426.1250276565552 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 13 epochs...
Completing Train Step...
At time: 429.5822985172272 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 430.7399640083313 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 431.86688017845154 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 433.01111602783203 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 434.1577641963959 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 435.3046844005585 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 436.4505910873413 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 437.59778475761414 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 438.7442057132721 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 439.92202138900757 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 441.06867694854736 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 442.215167760849 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 443.3614811897278 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 444.5078408718109 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 445.65486574172974 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 446.80207562446594 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 447.94745206832886 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 449.0947449207306 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 450.24085426330566 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 451.3869833946228 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 452.53374099731445 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 453.68045568466187 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 454.82655787467957 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 455.9736065864563 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 457.1199288368225 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 458.2660276889801 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 459.41372632980347 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 14 epochs...
Completing Train Step...
At time: 462.847448348999 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 463.9968659877777 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 465.1214187145233 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 466.2621958255768 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 467.4061539173126 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 468.58173847198486 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 469.7258005142212 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 470.87007999420166 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 472.0152382850647 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 473.1591522693634 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 474.30516743659973 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 475.4506347179413 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 476.5948762893677 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 477.7391278743744 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 478.8831911087036 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 480.0284540653229 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 481.17582988739014 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 482.3208227157593 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 483.46505975723267 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 484.6096603870392 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 485.75464630126953 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 486.8991255760193 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 488.04497146606445 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 489.18955731391907 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 490.33376145362854 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 491.47901368141174 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 492.6241421699524 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 15 epochs...
Completing Train Step...
At time: 496.11395478248596 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 497.24100732803345 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 498.40775299072266 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 499.55228304862976 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 500.6969864368439 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 501.8412055969238 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 502.9866347312927 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 504.13168573379517 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 505.275839805603 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 506.4199547767639 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 507.5644955635071 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 508.70945715904236 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 509.8545620441437 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 510.999596118927 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 512.1447043418884 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 513.2888309955597 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 514.4331789016724 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 515.576954126358 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 516.7225248813629 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 517.8667786121368 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 519.0119078159332 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 520.1564104557037 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 521.3005657196045 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 522.4445776939392 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 523.5894162654877 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 524.7342157363892 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 525.879275560379 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 16 epochs...
Completing Train Step...
At time: 529.343772649765 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 530.4674386978149 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 531.6114900112152 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 532.7556874752045 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 533.8999223709106 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 535.044671535492 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 536.1890745162964 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 537.3343551158905 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 538.4795303344727 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 539.6240484714508 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 540.7696239948273 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 541.9154944419861 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 543.0604174137115 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 544.2050292491913 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 545.3505759239197 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 546.4954347610474 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 547.6402318477631 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 548.7857418060303 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 549.9304578304291 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 551.0757055282593 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 552.2210714817047 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 553.3662195205688 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 554.5110030174255 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 555.7017645835876 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 556.8460793495178 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 557.9916534423828 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 559.1362597942352 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 17 epochs...
Completing Train Step...
At time: 562.5675411224365 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 563.7305009365082 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 564.8669238090515 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 566.0110783576965 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 567.1545844078064 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 568.2986450195312 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 569.4427471160889 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 570.5871360301971 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 571.7317092418671 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 572.8758680820465 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 574.0209114551544 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 575.1648309230804 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 576.308607339859 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 577.4536054134369 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 578.5974318981171 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 579.7415237426758 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 580.8859677314758 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 582.0300936698914 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 583.1736602783203 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 584.3177936077118 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 585.4918835163116 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 586.6358785629272 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 587.7807569503784 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 588.9249122142792 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 590.0686061382294 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 591.2118752002716 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 592.3560490608215 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 18 epochs...
Completing Train Step...
At time: 595.8137807846069 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 596.9752852916718 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 598.1210675239563 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 599.268114566803 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 600.4145414829254 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 601.5611209869385 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 602.7115046977997 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 603.8581781387329 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 605.0042736530304 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 606.1506972312927 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 607.2969632148743 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 608.4435992240906 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 609.5908858776093 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 610.7366738319397 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 611.8826515674591 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 613.0289800167084 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 614.2092041969299 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 615.3559155464172 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 616.5031182765961 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 617.648519039154 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 618.7955079078674 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 619.9413409233093 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 621.087690114975 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 622.2347500324249 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 623.3811616897583 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 624.5276410579681 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 625.674019575119 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 19 epochs...
Completing Train Step...
At time: 629.139886379242 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 630.2671666145325 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 631.4074866771698 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 632.5540814399719 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 633.6993753910065 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 634.8462493419647 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 635.9928460121155 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 637.1394608020782 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 638.2868709564209 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 639.4330656528473 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 640.5794277191162 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 641.7256050109863 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 642.9028589725494 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 644.0490438938141 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 645.1948912143707 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 646.3406143188477 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 647.4874272346497 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 648.6330046653748 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 649.7797811031342 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 650.9267053604126 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 652.072851896286 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 653.2192544937134 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 654.3666560649872 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 655.5135180950165 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 656.6598014831543 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 657.8059253692627 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 658.9520976543427 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 20 epochs...
Completing Train Step...
At time: 662.4459583759308 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 663.5740592479706 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 664.7106430530548 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 665.8499960899353 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 666.9966416358948 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 668.1434123516083 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 669.2898843288422 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 670.4372787475586 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 671.5840253829956 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 672.7606151103973 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 673.9068675041199 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 675.054657459259 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 676.2005953788757 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 677.3477985858917 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 678.4946687221527 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 679.6409850120544 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 680.7870755195618 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 681.9337952136993 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 683.0799086093903 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 684.2266507148743 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 685.373865365982 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 686.5205538272858 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 687.6668643951416 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 688.8139345645905 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 689.9609415531158 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 691.1079504489899 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 692.2547206878662 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 21 epochs...
Completing Train Step...
At time: 695.6892807483673 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 696.845401763916 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 697.9786248207092 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 699.1242182254791 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 700.268812417984 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 701.4427523612976 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 702.5878729820251 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 703.7329022884369 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 704.8766868114471 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 706.0219447612762 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 707.1668031215668 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 708.311625957489 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 709.456191778183 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 710.600695848465 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 711.7453889846802 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 712.8906953334808 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 714.0355379581451 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 715.1803755760193 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 716.3250772953033 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 717.4693744182587 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 718.6141152381897 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 719.7593340873718 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 720.9047362804413 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 722.0507056713104 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 723.1954572200775 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 724.3404333591461 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 725.4853930473328 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 22 epochs...
Completing Train Step...
At time: 728.9289379119873 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 730.0784616470337 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 731.2023086547852 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 732.3381636142731 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 733.4831824302673 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 734.6291663646698 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 735.7738554477692 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 736.9186811447144 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 738.0635676383972 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 739.2081077098846 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 740.3537020683289 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 741.4995427131653 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 742.6450309753418 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 743.7898933887482 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 744.9356398582458 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 746.0806667804718 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 747.2261879444122 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 748.3716588020325 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 749.5169551372528 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 750.6623394489288 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 751.8075613975525 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 752.9525611400604 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 754.0971968173981 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 755.2428398132324 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 756.3879721164703 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 757.5327982902527 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 758.6773729324341 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 23 epochs...
Completing Train Step...
At time: 762.1470601558685 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 763.2743158340454 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 764.4082388877869 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 765.5433542728424 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 766.6880390644073 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 767.8324193954468 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 768.9775102138519 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 770.12229347229 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 771.2671489715576 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 772.4120626449585 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 773.557407617569 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 774.702024936676 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 775.847188949585 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 776.9919390678406 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 778.1370029449463 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 779.2823157310486 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 780.4277808666229 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 781.5733389854431 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 782.7187418937683 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 783.8640019893646 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 785.0087306499481 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 786.1536531448364 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 787.2991108894348 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 788.49023604393 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 789.6346848011017 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 790.7800154685974 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 791.9253206253052 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 24 epochs...
Completing Train Step...
At time: 795.3932385444641 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 796.5121171474457 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 797.6346719264984 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 798.7666337490082 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 799.911196231842 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 801.0545480251312 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 802.1985874176025 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 803.3432042598724 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 804.4871170520782 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 805.6317484378815 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 806.7754344940186 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 807.9203147888184 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 809.0639231204987 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 810.2089729309082 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 811.3530271053314 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 812.4976079463959 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 813.6418380737305 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 814.7861557006836 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 815.9295661449432 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 817.104513168335 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 818.2488334178925 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 819.3934643268585 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 820.5369689464569 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 821.6809084415436 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 822.8238067626953 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 823.9686965942383 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 825.1115491390228 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 25 epochs...
Completing Train Step...
At time: 828.5398783683777 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 829.6968410015106 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 830.8307852745056 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 831.9766762256622 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 833.1231768131256 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 834.269312620163 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 835.4153463840485 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 836.5622520446777 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 837.7088265419006 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 838.8550641536713 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 840.002473115921 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 841.1488599777222 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 842.2956218719482 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 843.4431095123291 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 844.5895864963531 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 845.7822301387787 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 846.9290595054626 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 848.0757853984833 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 849.2226865291595 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 850.3685021400452 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 851.5156588554382 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 852.6616747379303 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 853.8091213703156 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 854.9555571079254 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 856.103166103363 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 857.249959230423 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 858.3960084915161 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 26 epochs...
Completing Train Step...
At time: 861.8430206775665 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 863.0063483715057 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 864.1508431434631 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 865.297660112381 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 866.4441468715668 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 867.5918936729431 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 868.7384521961212 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 869.8849062919617 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 871.0322396755219 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 872.1786687374115 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 873.3256778717041 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 874.4735708236694 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 875.6510944366455 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 876.798033952713 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 877.9448111057281 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 879.0918788909912 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 880.2389867305756 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 881.3851726055145 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 882.532835483551 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 883.6784298419952 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 884.8257765769958 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 885.9727694988251 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 887.1199421882629 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 888.2677910327911 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 889.415186882019 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 890.5619280338287 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 891.7093579769135 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 27 epochs...
Completing Train Step...
At time: 895.1877865791321 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 896.3155465126038 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 897.4508385658264 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 898.5915594100952 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 899.7385041713715 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 900.8838739395142 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 902.0279288291931 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 903.1733603477478 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 904.3636131286621 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 905.5017800331116 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 906.6482090950012 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 907.7961294651031 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 908.9440805912018 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 910.0918214321136 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 911.23934674263 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 912.386949300766 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 913.5339508056641 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 914.6814448833466 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 915.8286402225494 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 916.9767048358917 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 918.123809337616 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 919.2709558010101 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 920.4180200099945 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 921.5651879310608 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 922.7111010551453 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 923.8591237068176 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 925.0060460567474 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 28 epochs...
Completing Train Step...
At time: 928.479819059372 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 929.6061782836914 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 930.7333397865295 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 931.8665523529053 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 933.0388705730438 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 934.1836035251617 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 935.3291895389557 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 936.4746081829071 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 937.6194877624512 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 938.764654636383 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 939.908490896225 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 941.0544362068176 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 942.1995437145233 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 943.3452444076538 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 944.4904222488403 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 945.6356296539307 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 946.7808089256287 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 947.9253118038177 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 949.0710909366608 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 950.2167854309082 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 951.3619410991669 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 952.5080935955048 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 953.6527559757233 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 954.7976388931274 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 955.9423575401306 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 957.0877199172974 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 958.23290848732 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 29 epochs...
Completing Train Step...
At time: 961.6944286823273 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 962.8534178733826 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 963.9826986789703 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 965.1247179508209 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 966.2689564228058 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 967.4141364097595 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 968.5587840080261 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 969.704421043396 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 970.8488411903381 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 971.9941694736481 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 973.1385464668274 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 974.2841572761536 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 975.42920088768 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 976.5732469558716 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 977.7183513641357 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 978.8629672527313 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 980.0078535079956 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 981.1535515785217 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 982.2973058223724 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 983.4423837661743 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 984.5878677368164 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 985.7325761318207 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 986.8780474662781 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 988.0231277942657 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 989.1678557395935 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 990.312264919281 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 991.4575674533844 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 30 epochs...
Completing Train Step...
At time: 994.8927667140961 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 996.0483334064484 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 997.1813249588013 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 998.3262934684753 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 999.4702172279358 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1000.6150169372559 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1001.7590274810791 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1002.9041063785553 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1004.0488178730011 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1005.1924819946289 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1006.3364794254303 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1007.4819300174713 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1008.6268017292023 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1009.7711043357849 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1010.9160087108612 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1012.0612349510193 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1013.2063901424408 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1014.3508324623108 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1015.4960517883301 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1016.6404671669006 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1017.7852072715759 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1018.9294946193695 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1020.1194450855255 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1021.2640018463135 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1022.409791469574 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1023.5546853542328 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1024.698612689972 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 31 epochs...
Completing Train Step...
At time: 1028.1811394691467 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1029.3077805042267 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1030.4429852962494 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1031.5859241485596 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1032.7301547527313 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1033.8732388019562 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1035.0173544883728 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1036.1614518165588 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1037.305579662323 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1038.4489650726318 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1039.5929667949677 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1040.7364444732666 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1041.8800683021545 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1043.0243360996246 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1044.1673374176025 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1045.31076836586 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1046.4544892311096 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1047.59809756279 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1048.7725057601929 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1049.916340827942 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1051.0609211921692 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1052.2054743766785 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1053.3491458892822 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1054.492784023285 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1055.6357779502869 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1056.7808034420013 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1057.9250853061676 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 32 epochs...
Completing Train Step...
At time: 1061.3942377567291 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1062.5218253135681 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1063.6586904525757 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1064.8040754795074 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1065.9506797790527 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1067.096613407135 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1068.2427945137024 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1069.3901464939117 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1070.5357570648193 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1071.6832139492035 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1072.8296239376068 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1073.9757874011993 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1075.1225810050964 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1076.2691440582275 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1077.4151854515076 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1078.6045038700104 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1079.7517232894897 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1080.8977913856506 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1082.0445799827576 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1083.1910736560822 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1084.336653470993 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1085.484652042389 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1086.6313517093658 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1087.7778890132904 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1088.9248616695404 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1090.070806980133 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1091.2174496650696 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 33 epochs...
Completing Train Step...
At time: 1094.650468826294 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1095.798167705536 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1096.9403393268585 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1098.08682847023 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1099.2333512306213 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1100.3802361488342 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1101.5273594856262 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1102.674233675003 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1103.8206806182861 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1104.9671306610107 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1106.1137764453888 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1107.2905960083008 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1108.4367928504944 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1109.5831644535065 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1110.7300412654877 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1111.8766062259674 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1113.0225443840027 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1114.1697840690613 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1115.3161931037903 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1116.4623115062714 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1117.608662366867 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1118.7551562786102 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1119.9013814926147 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1121.0483138561249 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1122.1955695152283 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1123.3411586284637 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1124.4876735210419 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 34 epochs...
Completing Train Step...
At time: 1127.9289240837097 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1129.088312625885 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1130.2192118167877 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1131.355542898178 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1132.4962391853333 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1133.6432082653046 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1134.7897109985352 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1135.936499118805 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1137.1259801387787 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1138.272839307785 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1139.4201686382294 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1140.56693983078 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1141.7132251262665 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1142.8612201213837 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1144.0078630447388 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1145.1536145210266 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1146.3007009029388 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1147.4474506378174 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1148.5947754383087 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1149.7424583435059 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1150.889503479004 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1152.0360848903656 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1153.1830019950867 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1154.329669713974 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1155.4770152568817 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1156.6242413520813 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1157.7714138031006 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 35 epochs...
Completing Train Step...
At time: 1161.2456920146942 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1162.3655469417572 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1163.4891233444214 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1164.6286280155182 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1165.8031861782074 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1166.9476385116577 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1168.0924634933472 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1169.2375671863556 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1170.382554769516 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1171.5284223556519 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1172.6736698150635 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1173.8178279399872 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1174.963222503662 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1176.1085522174835 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1177.2537305355072 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1178.3993248939514 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1179.544001340866 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1180.6878442764282 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1181.8329617977142 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1182.978300333023 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1184.124160528183 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1185.2697167396545 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1186.4140725135803 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1187.5596451759338 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1188.7039277553558 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1189.84903216362 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1190.993721485138 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 36 epochs...
Completing Train Step...
At time: 1194.4662809371948 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1195.5929985046387 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1196.7281062602997 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1197.87300157547 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1199.0181739330292 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1200.1640975475311 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1201.3080837726593 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1202.4522202014923 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1203.5968027114868 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1204.7418448925018 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1205.8865656852722 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1207.0312559604645 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1208.1759278774261 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1209.3209598064423 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1210.4655215740204 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1211.6105699539185 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1212.7559530735016 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1213.9016542434692 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1215.046499490738 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1216.1923611164093 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1217.3371279239655 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1218.4823050498962 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1219.6272277832031 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1220.7722582817078 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1221.9167020320892 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1223.0609271526337 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1224.2063436508179 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 37 epochs...
Completing Train Step...
At time: 1227.6622250080109 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1228.8227784633636 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1229.9635119438171 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1231.107595205307 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1232.2521588802338 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1233.3968710899353 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1234.540999174118 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1235.686388015747 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1236.8308100700378 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1237.9752860069275 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1239.1198825836182 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1240.2647240161896 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1241.4089045524597 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1242.5531384944916 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1243.6975235939026 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1244.8412742614746 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1245.9854123592377 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1247.1301760673523 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1248.2757868766785 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1249.4201788902283 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1250.5644438266754 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1251.709477186203 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1252.8852100372314 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1254.0301220417023 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1255.1742403507233 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1256.3191061019897 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1257.464637517929 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 38 epochs...
Completing Train Step...
At time: 1260.9269170761108 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1262.092252254486 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1263.2301607131958 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1264.3747112751007 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1265.5183625221252 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1266.6624801158905 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1267.8065071105957 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1268.9505927562714 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1270.0947887897491 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1271.2386457920074 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1272.382649898529 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1273.527102947235 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1274.6714277267456 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1275.8160116672516 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1276.9604258537292 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1278.104355096817 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1279.2480943202972 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1280.3918595314026 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1281.570033788681 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1282.714138507843 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1283.8582818508148 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1285.0018365383148 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1286.1456470489502 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1287.2899012565613 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1288.4330348968506 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1289.5780506134033 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1290.7226934432983 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 39 epochs...
Completing Train Step...
At time: 1294.2003655433655 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1295.3334362506866 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1296.475332736969 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1297.6220610141754 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1298.7687044143677 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1299.9150190353394 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1301.0617988109589 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1302.2085506916046 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1303.355717420578 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1304.5026288032532 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1305.6488499641418 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1306.7953987121582 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1307.9426424503326 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1309.089679479599 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1310.267272233963 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1311.4135875701904 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1312.5602848529816 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1313.7075953483582 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1314.8543047904968 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1316.001098871231 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1317.1466989517212 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1318.294546365738 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1319.4408378601074 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1320.5877027511597 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1321.7348339557648 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1322.881492614746 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1324.0275514125824 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 40 epochs...
Completing Train Step...
At time: 1327.5238308906555 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1328.6579947471619 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1329.8030242919922 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1330.949539899826 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1332.096461057663 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1333.2429394721985 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1334.3901734352112 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1335.537009716034 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1336.683738708496 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1337.8311879634857 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1338.9787015914917 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1340.155870437622 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1341.3017044067383 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1342.4476566314697 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1343.5950932502747 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1344.7421464920044 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1345.8887357711792 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1347.0371053218842 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1348.184003353119 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1349.3304204940796 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1350.4780294895172 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1351.6251015663147 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1352.7718532085419 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1353.9190664291382 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1355.0652058124542 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1356.2123560905457 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1357.3591032028198 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 41 epochs...
Completing Train Step...
At time: 1360.7992837429047 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1361.9543976783752 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1363.0844626426697 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1364.2283713817596 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1365.3753457069397 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1366.5222165584564 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1367.669350862503 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1368.8471286296844 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1369.9936499595642 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1371.1407101154327 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1372.2891592979431 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1373.4367289543152 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1374.5835375785828 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1375.7309379577637 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1376.8771605491638 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1378.023686170578 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1379.1702899932861 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1380.3188064098358 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1381.4660966396332 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1382.6140875816345 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1383.7607307434082 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1384.9071898460388 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1386.0546987056732 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1387.201619386673 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1388.3489129543304 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1389.495691537857 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1390.6426169872284 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 42 epochs...
Completing Train Step...
At time: 1394.1132318973541 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1395.2829241752625 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1396.4278836250305 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1397.6028792858124 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1398.747704744339 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1399.8919365406036 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1401.0372200012207 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1402.1822299957275 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1403.3269798755646 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1404.4718990325928 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1405.61625790596 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1406.761220216751 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1407.9065330028534 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1409.0518827438354 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1410.1967425346375 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1411.3415145874023 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1412.4869301319122 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1413.6320941448212 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1414.7778053283691 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1415.9238674640656 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1417.0691306591034 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1418.2136635780334 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1419.35959815979 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1420.5038681030273 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1421.6491358280182 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1422.7947580814362 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1423.9404296875 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 43 epochs...
Completing Train Step...
At time: 1427.4008898735046 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1428.5278618335724 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1429.666128873825 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1430.8111793994904 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1431.955738544464 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1433.1008024215698 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1434.244967699051 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1435.388961315155 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1436.5354397296906 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1437.6807289123535 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1438.825578212738 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1439.970870256424 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1441.1161620616913 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1442.2606129646301 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1443.4060196876526 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1444.5507514476776 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1445.695493221283 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1446.8394865989685 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1447.9848592281342 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1449.131022453308 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1450.27529835701 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1451.4202435016632 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1452.5647797584534 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1453.7095177173615 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1454.8535561561584 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1455.9982087612152 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1457.1426451206207 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 44 epochs...
Completing Train Step...
At time: 1460.6207406520844 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1461.7377035617828 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1462.8676829338074 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1464.0115571022034 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1465.156580209732 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1466.3016092777252 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1467.4455604553223 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1468.589859008789 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1469.7336268424988 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1470.8782875537872 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1472.0232288837433 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1473.168174982071 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1474.3125371932983 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1475.457288980484 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1476.6021893024445 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1477.746819972992 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1478.891933441162 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1480.0368494987488 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1481.181492805481 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1482.326818704605 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1483.4711468219757 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1484.655925989151 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1485.7990946769714 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1486.944333076477 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1488.0885252952576 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1489.2324159145355 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1490.3774688243866 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 45 epochs...
Completing Train Step...
At time: 1493.834080696106 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1495.0205628871918 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1496.1645431518555 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1497.3089017868042 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1498.4524261951447 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1499.5973813533783 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1500.742166519165 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1501.8865449428558 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1503.0301582813263 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1504.17373585701 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1505.3175959587097 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1506.461743593216 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1507.6065895557404 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1508.7516798973083 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1509.8960559368134 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1511.039555311203 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1512.1851823329926 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1513.3750030994415 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1514.5191521644592 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1515.663859128952 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1516.8080310821533 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1517.9521844387054 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1519.0968914031982 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1520.240774154663 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1521.3843986988068 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1522.528831243515 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1523.6728343963623 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 46 epochs...
Completing Train Step...
At time: 1527.1200275421143 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1528.2887744903564 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1529.4257137775421 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1530.57213306427 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1531.7185761928558 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1532.8645603656769 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1534.0103528499603 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1535.1568658351898 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1536.3040134906769 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1537.450754404068 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1538.5970377922058 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1539.741928100586 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1540.8888494968414 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1542.034817457199 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1543.2263989448547 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1544.3730647563934 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1545.51935505867 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1546.6646211147308 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1547.8116643428802 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1548.9577450752258 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1550.1045007705688 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1551.251244544983 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1552.3978247642517 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1553.543781042099 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1554.690967798233 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1555.8373606204987 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1556.984617471695 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 47 epochs...
Completing Train Step...
At time: 1560.5007772445679 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1561.6221179962158 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1562.75155210495 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1563.8952362537384 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1565.0427572727203 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1566.188419342041 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1567.3350608348846 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1568.4824521541595 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1569.629468202591 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1570.7772998809814 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1571.9700329303741 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1573.1162641048431 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1574.2631611824036 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1575.4091391563416 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1576.5562229156494 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1577.7028362751007 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1578.8498859405518 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1579.9962968826294 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1581.143426656723 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1582.289715051651 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1583.4365301132202 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1584.5835065841675 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1585.7307589054108 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1586.8776540756226 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1588.0240106582642 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1589.1706883907318 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1590.3169264793396 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 48 epochs...
Completing Train Step...
At time: 1593.8215367794037 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1594.9537596702576 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1596.098468542099 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1597.2449107170105 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1598.3918392658234 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1599.5380806922913 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1600.729744195938 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1601.8777294158936 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1603.024037361145 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1604.1699328422546 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1605.3165760040283 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1606.4633820056915 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1607.6093773841858 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1608.756673336029 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1609.903652191162 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1611.0500497817993 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1612.1969158649445 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1613.3439075946808 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1614.4901220798492 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1615.6363728046417 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1616.7829449176788 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1617.9298386573792 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1619.0768127441406 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1620.2245535850525 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1621.3709633350372 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1622.5175433158875 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1623.6638128757477 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished 49 epochs...
Completing Train Step...
At time: 1627.1068322658539 and batch: 50, loss is 9.928560352325439 and perplexity is 20507.795319324676
At time: 1628.2752401828766 and batch: 100, loss is 9.929049224853516 and perplexity is 20517.823468111223
At time: 1629.4175090789795 and batch: 150, loss is 9.928414421081543 and perplexity is 20504.8028095998
At time: 1630.60737657547 and batch: 200, loss is 9.928589992523193 and perplexity is 20508.403183442
At time: 1631.75217628479 and batch: 250, loss is 9.929133243560791 and perplexity is 20519.547421536266
At time: 1632.8974647521973 and batch: 300, loss is 9.929787425994872 and perplexity is 20532.975340690267
At time: 1634.0423922538757 and batch: 350, loss is 9.929511852264405 and perplexity is 20527.317771652535
At time: 1635.1878628730774 and batch: 400, loss is 9.928939933776855 and perplexity is 20515.58117562715
At time: 1636.3330516815186 and batch: 450, loss is 9.929233684539795 and perplexity is 20521.608528476074
At time: 1637.47820186615 and batch: 500, loss is 9.929227828979492 and perplexity is 20521.488363311633
At time: 1638.6230449676514 and batch: 550, loss is 9.929603385925294 and perplexity is 20529.196798192188
At time: 1639.7675318717957 and batch: 600, loss is 9.929653930664063 and perplexity is 20530.234467305636
At time: 1640.9131166934967 and batch: 650, loss is 9.929660930633545 and perplexity is 20530.378178823357
At time: 1642.058338880539 and batch: 700, loss is 9.928673992156982 and perplexity is 20510.12595415405
At time: 1643.20272898674 and batch: 750, loss is 9.929122238159179 and perplexity is 20519.32159691864
At time: 1644.3484148979187 and batch: 800, loss is 9.928987007141114 and perplexity is 20516.54693578343
At time: 1645.4929873943329 and batch: 850, loss is 9.929661121368408 and perplexity is 20530.38209468259
At time: 1646.6385214328766 and batch: 900, loss is 9.928555011749268 and perplexity is 20507.68579617412
At time: 1647.7833704948425 and batch: 950, loss is 9.928323936462402 and perplexity is 20502.947524265666
At time: 1648.9287066459656 and batch: 1000, loss is 9.929207935333253 and perplexity is 20521.080120142557
At time: 1650.0733456611633 and batch: 1050, loss is 9.929080486297607 and perplexity is 20518.464894928355
At time: 1651.2181763648987 and batch: 1100, loss is 9.929389934539795 and perplexity is 20524.81528032961
At time: 1652.3636133670807 and batch: 1150, loss is 9.928657989501954 and perplexity is 20509.797740309965
At time: 1653.5090022087097 and batch: 1200, loss is 9.92877025604248 and perplexity is 20512.100433604446
At time: 1654.653908252716 and batch: 1250, loss is 9.927406883239746 and perplexity is 20484.153848881986
At time: 1655.7994892597198 and batch: 1300, loss is 9.92904972076416 and perplexity is 20517.833643120797
At time: 1656.9443295001984 and batch: 1350, loss is 9.928527526855468 and perplexity is 20507.122152353826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 9.997347005208333 and perplexity of 21968.107142603632
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7feac5170978>
Saving Model Parameters and Results...
/home-nfs/siddsach/Interpreting-Attention/interpreting_language/trained_models/langmodel/



RESULTS:
[{'params': {'lr': 29.228843599931064, 'data': 'wikitext', 'dropout': 0.2464177359755153, 'anneal': 6.926870369946397, 'wordvec_source': '', 'num_layers': 1, 'wordvec_dim': 200, 'batch_size': 80, 'seq_len': 20, 'tune_wordvecs': True}, 'best_accuracy': -175.5903074762128}, {'params': {'lr': 11.536897931568085, 'data': 'wikitext', 'dropout': 0.4563768022406083, 'anneal': 7.971243729914938, 'wordvec_source': '', 'num_layers': 1, 'wordvec_dim': 200, 'batch_size': 80, 'seq_len': 20, 'tune_wordvecs': True}, 'best_accuracy': -118.37137219218255}, {'params': {'lr': 24.25140582114941, 'data': 'wikitext', 'dropout': 0.21040662221197415, 'anneal': 2.5866975937895478, 'wordvec_source': '', 'num_layers': 1, 'wordvec_dim': 200, 'batch_size': 80, 'seq_len': 20, 'tune_wordvecs': True}, 'best_accuracy': -166.33778815050115}, {'params': {'lr': 21.779401101626867, 'data': 'wikitext', 'dropout': 0.5430837354688028, 'anneal': 7.65681972637775, 'wordvec_source': '', 'num_layers': 1, 'wordvec_dim': 200, 'batch_size': 80, 'seq_len': 20, 'tune_wordvecs': True}, 'best_accuracy': -166.31254430004427}, {'params': {'lr': 1.9255212810427624, 'data': 'wikitext', 'dropout': 0.002372384860573895, 'anneal': 6.455311187146002, 'wordvec_source': '', 'num_layers': 1, 'wordvec_dim': 200, 'batch_size': 80, 'seq_len': 20, 'tune_wordvecs': True}, 'best_accuracy': -95.02996865997291}, {'params': {'lr': 0.0, 'data': 'wikitext', 'dropout': 1.0, 'anneal': 2.0, 'wordvec_source': '', 'num_layers': 1, 'wordvec_dim': 200, 'batch_size': 80, 'seq_len': 20, 'tune_wordvecs': True}, 'best_accuracy': -21968.107142603632}]
