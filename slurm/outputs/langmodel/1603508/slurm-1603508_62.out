Building Bayesian Optimizer for 
 data:wikitext 
 choices:[{'type': 'continuous', 'name': 'lr', 'domain': [0, 30]}, {'type': 'continuous', 'name': 'dropout', 'domain': [0, 1]}, {'type': 'continuous', 'name': 'anneal', 'domain': [2, 8]}]
SETTINGS FOR THIS RUN
{'wordvec_dim': 200, 'dropout': 0.8424821444842271, 'num_layers': 1, 'wordvec_source': 'glove', 'tune_wordvecs': True, 'batch_size': 80, 'seq_len': 20, 'lr': 14.231441702412651, 'data': 'wikitext', 'anneal': 5.252339304104469}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.7082233428955078 and batch: 50, loss is 7.507961187362671 and perplexity is 1822.4940285518237
At time: 2.7330915927886963 and batch: 100, loss is 6.804772787094116 and perplexity is 902.1427681598544
At time: 3.7589004039764404 and batch: 150, loss is 6.663559637069702 and perplexity is 783.33436623704
At time: 4.786803722381592 and batch: 200, loss is 6.62092695236206 and perplexity is 750.640582782309
At time: 5.813076972961426 and batch: 250, loss is 6.609073581695557 and perplexity is 741.7954873773274
At time: 6.8404340744018555 and batch: 300, loss is 6.591950540542602 and perplexity is 729.2018213528931
At time: 7.867324352264404 and batch: 350, loss is 6.586222791671753 and perplexity is 725.0370751403261
At time: 8.895737409591675 and batch: 400, loss is 6.613482580184937 and perplexity is 745.0732831490784
At time: 9.923598289489746 and batch: 450, loss is 6.5856279945373535 and perplexity is 724.6059533933992
At time: 10.95059323310852 and batch: 500, loss is 6.566757030487061 and perplexity is 711.0601536306792
At time: 11.976880073547363 and batch: 550, loss is 6.531609764099121 and perplexity is 686.5024294530359
At time: 13.001665115356445 and batch: 600, loss is 6.491463689804077 and perplexity is 659.4879428982205
At time: 14.02706003189087 and batch: 650, loss is 6.531952829360962 and perplexity is 686.7379849919013
At time: 15.052399635314941 and batch: 700, loss is 6.53225248336792 and perplexity is 686.9437996158827
At time: 16.07835030555725 and batch: 750, loss is 6.521543359756469 and perplexity is 679.6264844999739
At time: 17.105430603027344 and batch: 800, loss is 6.489596900939941 and perplexity is 658.2579665606463
At time: 18.1317298412323 and batch: 850, loss is 6.486436653137207 and perplexity is 656.1809918741261
At time: 19.158146142959595 and batch: 900, loss is 6.547454557418823 and perplexity is 697.4665512990475
At time: 20.184529542922974 and batch: 950, loss is 6.524625015258789 and perplexity is 681.7240895835698
At time: 21.211206197738647 and batch: 1000, loss is 6.537916688919068 and perplexity is 690.8458310204915
At time: 22.237765073776245 and batch: 1050, loss is 6.537731142044067 and perplexity is 690.7176586267998
At time: 23.264379262924194 and batch: 1100, loss is 6.556969127655029 and perplexity is 704.1343159452983
At time: 24.29085659980774 and batch: 1150, loss is 6.546091451644897 and perplexity is 696.5164782879625
At time: 25.31805443763733 and batch: 1200, loss is 6.515997114181519 and perplexity is 675.8675427603706
At time: 26.342231512069702 and batch: 1250, loss is 6.531737766265869 and perplexity is 686.5903088757418
At time: 27.36617159843445 and batch: 1300, loss is 6.4908539581298825 and perplexity is 659.0859547755853
At time: 28.39342212677002 and batch: 1350, loss is 6.508259010314942 and perplexity is 670.6577923053819
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 6.061518961588542 and perplexity of 429.02661712705526
Finished 1 epochs...
Completing Train Step...
At time: 31.5091814994812 and batch: 50, loss is 6.481190910339356 and perplexity is 652.747847730215
At time: 32.52318334579468 and batch: 100, loss is 6.588376531600952 and perplexity is 726.6002992240053
At time: 33.537699699401855 and batch: 150, loss is 6.610344123840332 and perplexity is 742.7385687923199
At time: 34.55215358734131 and batch: 200, loss is 6.6223521900177005 and perplexity is 751.7111867580658
At time: 35.56725883483887 and batch: 250, loss is 6.6938844871521 and perplexity is 807.4527077695631
At time: 36.582165479660034 and batch: 300, loss is 6.736019268035888 and perplexity is 842.201475795142
At time: 37.59904623031616 and batch: 350, loss is 6.751627931594848 and perplexity is 855.4502440806139
At time: 38.616339683532715 and batch: 400, loss is 6.774056262969971 and perplexity is 874.8533418278253
At time: 39.63598823547363 and batch: 450, loss is 6.721172704696655 and perplexity is 829.7900398026642
At time: 40.654290437698364 and batch: 500, loss is 6.675677566528321 and perplexity is 792.8845039120255
At time: 41.67212963104248 and batch: 550, loss is 6.627171392440796 and perplexity is 755.3425783080709
At time: 42.69073152542114 and batch: 600, loss is 6.585474882125855 and perplexity is 724.4950157216728
At time: 43.70928168296814 and batch: 650, loss is 6.601772689819336 and perplexity is 736.399440675261
At time: 44.734116077423096 and batch: 700, loss is 6.588971767425537 and perplexity is 727.0329264971101
At time: 45.75360035896301 and batch: 750, loss is 6.579700117111206 and perplexity is 720.3232842293365
At time: 46.77494025230408 and batch: 800, loss is 6.526504993438721 and perplexity is 683.0069214668672
At time: 47.79719305038452 and batch: 850, loss is 6.5557710075378415 and perplexity is 703.2911836439071
At time: 48.86237549781799 and batch: 900, loss is 6.578652248382569 and perplexity is 719.5688753150685
At time: 49.88104176521301 and batch: 950, loss is 6.529240312576294 and perplexity is 684.8777208204492
At time: 50.90352702140808 and batch: 1000, loss is 6.486857175827026 and perplexity is 656.4569888972756
At time: 51.92735409736633 and batch: 1050, loss is 6.466584911346436 and perplexity is 643.2831026154586
At time: 52.9473979473114 and batch: 1100, loss is 6.447853517532349 and perplexity is 631.3456649433328
At time: 53.96565532684326 and batch: 1150, loss is 6.46518030166626 and perplexity is 642.3801752211616
At time: 54.9844172000885 and batch: 1200, loss is 6.438288288116455 and perplexity is 625.3354889976184
At time: 56.002989768981934 and batch: 1250, loss is 6.413352594375611 and perplexity is 609.9351221473908
At time: 57.02308464050293 and batch: 1300, loss is 6.37872724533081 and perplexity is 589.1773520246724
At time: 58.045334577560425 and batch: 1350, loss is 6.42700234413147 and perplexity is 618.3176635789448
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 6.040169270833333 and perplexity of 419.96411654645703
Finished 2 epochs...
Completing Train Step...
At time: 61.17050743103027 and batch: 50, loss is 6.439615383148193 and perplexity is 626.1659195264729
At time: 62.2202033996582 and batch: 100, loss is 6.488193302154541 and perplexity is 657.3346845886084
At time: 63.23892259597778 and batch: 150, loss is 6.43531231880188 and perplexity is 623.4772761346983
At time: 64.25870037078857 and batch: 200, loss is 6.4183014869689945 and perplexity is 612.9611070169689
At time: 65.27781653404236 and batch: 250, loss is 6.459316921234131 and perplexity is 638.6246765896332
At time: 66.2976622581482 and batch: 300, loss is 6.4500205707550045 and perplexity is 632.7153081099764
At time: 67.31592130661011 and batch: 350, loss is 6.458813705444336 and perplexity is 638.3033914132873
At time: 68.33582496643066 and batch: 400, loss is 6.480280656814575 and perplexity is 652.1539520398547
At time: 69.35585832595825 and batch: 450, loss is 6.461609916687012 and perplexity is 640.0907202425151
At time: 70.3762857913971 and batch: 500, loss is 6.477905035018921 and perplexity is 650.6065196820399
At time: 71.3961329460144 and batch: 550, loss is 6.439505462646484 and perplexity is 626.0970948371371
At time: 72.41681575775146 and batch: 600, loss is 6.3823873329162595 and perplexity is 591.3377439364933
At time: 73.43759536743164 and batch: 650, loss is 6.4285287761688235 and perplexity is 619.2622041750086
At time: 74.50044631958008 and batch: 700, loss is 6.427630987167358 and perplexity is 618.706486874844
At time: 75.52447032928467 and batch: 750, loss is 6.382160530090332 and perplexity is 591.2036420730068
At time: 76.54577589035034 and batch: 800, loss is 6.347589817047119 and perplexity is 571.1145583105608
At time: 77.56593465805054 and batch: 850, loss is 6.389499502182007 and perplexity is 595.558429388057
At time: 78.59390592575073 and batch: 900, loss is 6.4172875118255615 and perplexity is 612.339894690716
At time: 79.61288714408875 and batch: 950, loss is 6.382318840026856 and perplexity is 591.2972428928302
At time: 80.63402318954468 and batch: 1000, loss is 6.2846823501586915 and perplexity is 536.2939099028492
At time: 81.65387868881226 and batch: 1050, loss is 6.2488118934631345 and perplexity is 517.3977357131324
At time: 82.67361044883728 and batch: 1100, loss is 6.2866629695892335 and perplexity is 537.357156637275
At time: 83.69349837303162 and batch: 1150, loss is 6.312522144317627 and perplexity is 551.4339925021163
At time: 84.71366620063782 and batch: 1200, loss is 6.312911586761475 and perplexity is 551.6487861259393
At time: 85.73920249938965 and batch: 1250, loss is 6.310783834457397 and perplexity is 550.4762620130267
At time: 86.7591814994812 and batch: 1300, loss is 6.277977628707886 and perplexity is 532.7102358142726
At time: 87.78687953948975 and batch: 1350, loss is 6.287805271148682 and perplexity is 537.9713312748216
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.959852294921875 and perplexity of 387.552876482097
Finished 3 epochs...
Completing Train Step...
At time: 90.90113377571106 and batch: 50, loss is 6.335270338058471 and perplexity is 564.1218859885604
At time: 91.95757031440735 and batch: 100, loss is 6.360398445129395 and perplexity is 578.4768017448869
At time: 92.98186469078064 and batch: 150, loss is 6.316714172363281 and perplexity is 553.7504712436299
At time: 94.00863790512085 and batch: 200, loss is 6.30622615814209 and perplexity is 547.9730780756794
At time: 95.03348207473755 and batch: 250, loss is 6.357499399185181 and perplexity is 576.8021994662834
At time: 96.06238532066345 and batch: 300, loss is 6.337340850830078 and perplexity is 565.2911175950192
At time: 97.08535408973694 and batch: 350, loss is 6.352947006225586 and perplexity is 574.1823370405474
At time: 98.10642838478088 and batch: 400, loss is 6.3858802700042725 and perplexity is 593.4068610180208
At time: 99.1271984577179 and batch: 450, loss is 6.366851043701172 and perplexity is 582.2215490120415
At time: 100.15363836288452 and batch: 500, loss is 6.382929086685181 and perplexity is 591.6581901816193
At time: 101.22306394577026 and batch: 550, loss is 6.337315864562989 and perplexity is 565.2769932566298
At time: 102.24987053871155 and batch: 600, loss is 6.287436332702637 and perplexity is 537.772889576481
At time: 103.26944923400879 and batch: 650, loss is 6.329285621643066 and perplexity is 560.7558588827288
At time: 104.29060626029968 and batch: 700, loss is 6.305021228790284 and perplexity is 547.3132068588413
At time: 105.31926703453064 and batch: 750, loss is 6.274207849502563 and perplexity is 530.7058163280589
At time: 106.34823298454285 and batch: 800, loss is 6.254546785354615 and perplexity is 520.3734804236856
At time: 107.37036228179932 and batch: 850, loss is 6.290090131759643 and perplexity is 539.2019261129459
At time: 108.40251278877258 and batch: 900, loss is 6.323725423812866 and perplexity is 557.6465974377049
At time: 109.43005013465881 and batch: 950, loss is 6.300855598449707 and perplexity is 545.0380443914281
At time: 110.45042729377747 and batch: 1000, loss is 6.282951440811157 and perplexity is 535.3664366787721
At time: 111.47640752792358 and batch: 1050, loss is 6.284145135879516 and perplexity is 536.0058825297506
At time: 112.49625325202942 and batch: 1100, loss is 6.3004305458068846 and perplexity is 544.806423759189
At time: 113.51822900772095 and batch: 1150, loss is 6.272069654464722 and perplexity is 529.5722760819646
At time: 114.54506659507751 and batch: 1200, loss is 6.272982063293457 and perplexity is 530.0556830009499
At time: 115.56614947319031 and batch: 1250, loss is 6.262515773773194 and perplexity is 524.5368977416614
At time: 116.58729672431946 and batch: 1300, loss is 6.20538182258606 and perplexity is 495.40807782581504
At time: 117.60836291313171 and batch: 1350, loss is 6.230958299636841 and perplexity is 508.24229861135086
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.915434163411458 and perplexity of 370.7152187539313
Finished 4 epochs...
Completing Train Step...
At time: 120.77679014205933 and batch: 50, loss is 6.270830774307251 and perplexity is 528.9166057295365
At time: 121.79506397247314 and batch: 100, loss is 6.310017118453979 and perplexity is 550.0543648117754
At time: 122.81257438659668 and batch: 150, loss is 6.281860189437866 and perplexity is 534.7825359687022
At time: 123.82987022399902 and batch: 200, loss is 6.261851863861084 and perplexity is 524.18876807214
At time: 124.84993505477905 and batch: 250, loss is 6.3036229705810545 and perplexity is 546.548456458193
At time: 125.8704206943512 and batch: 300, loss is 6.309922533035278 and perplexity is 550.0023401497974
At time: 126.93359661102295 and batch: 350, loss is 6.318072414398193 and perplexity is 554.5031094272274
At time: 127.953604221344 and batch: 400, loss is 6.3751488780975345 and perplexity is 587.0728267214453
At time: 128.97172141075134 and batch: 450, loss is 6.328260288238526 and perplexity is 560.1811918318324
At time: 129.99186730384827 and batch: 500, loss is 6.339301338195801 and perplexity is 566.4004507505266
At time: 131.0115668773651 and batch: 550, loss is 6.299128360748291 and perplexity is 544.0974466842046
At time: 132.0320611000061 and batch: 600, loss is 6.243930997848511 and perplexity is 514.878524378943
At time: 133.05051970481873 and batch: 650, loss is 6.2668138599395755 and perplexity is 526.7962545024279
At time: 134.06938314437866 and batch: 700, loss is 6.241576461791992 and perplexity is 513.6676504111816
At time: 135.08806610107422 and batch: 750, loss is 6.213725233078003 and perplexity is 499.55876213337655
At time: 136.10791063308716 and batch: 800, loss is 6.14403190612793 and perplexity is 465.9283682591075
At time: 137.12676215171814 and batch: 850, loss is 6.18853274345398 and perplexity is 487.1308356926463
At time: 138.14422869682312 and batch: 900, loss is 6.2350239562988286 and perplexity is 510.3128435088326
At time: 139.16214275360107 and batch: 950, loss is 6.244728851318359 and perplexity is 515.2894859179133
At time: 140.18125367164612 and batch: 1000, loss is 6.234977426528931 and perplexity is 510.28909932205846
At time: 141.2000551223755 and batch: 1050, loss is 6.222967052459717 and perplexity is 504.1969938202755
At time: 142.21818137168884 and batch: 1100, loss is 6.2176069641113285 and perplexity is 501.5016833925585
At time: 143.2367537021637 and batch: 1150, loss is 6.239013566970825 and perplexity is 512.3528598048352
At time: 144.25465059280396 and batch: 1200, loss is 6.244387111663818 and perplexity is 515.1134211528768
At time: 145.27421474456787 and batch: 1250, loss is 6.241418981552124 and perplexity is 513.5867642755336
At time: 146.29382395744324 and batch: 1300, loss is 6.19858344078064 and perplexity is 492.0515270478788
At time: 147.31567239761353 and batch: 1350, loss is 6.197606925964355 and perplexity is 491.571265970534
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.936783447265625 and perplexity of 378.7148121395944
Annealing...
Finished 5 epochs...
Completing Train Step...
At time: 150.4530303478241 and batch: 50, loss is 6.1587482357025145 and perplexity is 472.8358252291187
At time: 151.47793793678284 and batch: 100, loss is 6.095223035812378 and perplexity is 443.733002491893
At time: 152.5296037197113 and batch: 150, loss is 6.0160624790191655 and perplexity is 409.96118275918326
At time: 153.55470442771912 and batch: 200, loss is 6.0037824821472165 and perplexity is 404.9576453063449
At time: 154.57732605934143 and batch: 250, loss is 6.011371517181397 and perplexity is 408.0425740742219
At time: 155.59940099716187 and batch: 300, loss is 6.012640428543091 and perplexity is 408.5606725735383
At time: 156.62057399749756 and batch: 350, loss is 6.0099093627929685 and perplexity is 407.44638879754814
At time: 157.64129614830017 and batch: 400, loss is 6.041729679107666 and perplexity is 420.61994357472844
At time: 158.66138243675232 and batch: 450, loss is 6.001866149902344 and perplexity is 404.1823550069965
At time: 159.6891462802887 and batch: 500, loss is 6.009851655960083 and perplexity is 407.42287703528115
At time: 160.70833110809326 and batch: 550, loss is 5.972828769683838 and perplexity is 392.61471800243544
At time: 161.72740054130554 and batch: 600, loss is 5.926308221817017 and perplexity is 374.7683949931115
At time: 162.75477600097656 and batch: 650, loss is 5.953849153518677 and perplexity is 385.2333110689241
At time: 163.77646708488464 and batch: 700, loss is 5.964380798339843 and perplexity is 389.3118908531271
At time: 164.79928851127625 and batch: 750, loss is 5.9357129669189455 and perplexity is 378.3096222887819
At time: 165.82359981536865 and batch: 800, loss is 5.913931694030762 and perplexity is 370.1586487082221
At time: 166.84510207176208 and batch: 850, loss is 5.901556940078735 and perplexity is 365.6062519957954
At time: 167.8654568195343 and batch: 900, loss is 5.938464221954345 and perplexity is 379.35188164525533
At time: 168.88441944122314 and batch: 950, loss is 5.901100549697876 and perplexity is 365.43943088987226
At time: 169.90499877929688 and batch: 1000, loss is 5.909889011383057 and perplexity is 368.6652354939741
At time: 170.92500281333923 and batch: 1050, loss is 5.876791152954102 and perplexity is 356.6629267389074
At time: 171.949857711792 and batch: 1100, loss is 5.85464861869812 and perplexity is 348.85229834051745
At time: 172.97102785110474 and batch: 1150, loss is 5.8514109706878665 and perplexity is 347.7246638177801
At time: 173.992116689682 and batch: 1200, loss is 5.838547248840332 and perplexity is 343.28027742426843
At time: 175.02005815505981 and batch: 1250, loss is 5.852246465682984 and perplexity is 348.0153074328145
At time: 176.05113101005554 and batch: 1300, loss is 5.808294095993042 and perplexity is 333.0504886292884
At time: 177.07300209999084 and batch: 1350, loss is 5.8062397003173825 and perplexity is 332.3669734913442
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.6171476236979165 and perplexity of 275.10356415469647
Finished 6 epochs...
Completing Train Step...
At time: 180.20157432556152 and batch: 50, loss is 5.920814962387085 and perplexity is 372.7153391202732
At time: 181.2512276172638 and batch: 100, loss is 5.933834810256958 and perplexity is 377.5997643722406
At time: 182.27451467514038 and batch: 150, loss is 5.896687364578247 and perplexity is 363.8302324883187
At time: 183.30402135849 and batch: 200, loss is 5.890625982284546 and perplexity is 361.63158850164257
At time: 184.32901239395142 and batch: 250, loss is 5.9067122173309325 and perplexity is 367.49592028682525
At time: 185.35302472114563 and batch: 300, loss is 5.921496686935424 and perplexity is 372.9695149456001
At time: 186.38260650634766 and batch: 350, loss is 5.924587411880493 and perplexity is 374.12404437658756
At time: 187.40851306915283 and batch: 400, loss is 5.960245485305786 and perplexity is 387.7052885078948
At time: 188.44105195999146 and batch: 450, loss is 5.927278900146485 and perplexity is 375.13235116630875
At time: 189.4706757068634 and batch: 500, loss is 5.942924222946167 and perplexity is 381.0475699886594
At time: 190.4935691356659 and batch: 550, loss is 5.907442417144775 and perplexity is 367.7643637361574
At time: 191.5153350830078 and batch: 600, loss is 5.859844598770142 and perplexity is 350.66964529128614
At time: 192.53572463989258 and batch: 650, loss is 5.890560493469239 and perplexity is 361.6079064527969
At time: 193.55685830116272 and batch: 700, loss is 5.900324440002441 and perplexity is 365.15591983653394
At time: 194.5778467655182 and batch: 750, loss is 5.877292642593384 and perplexity is 356.84183435779204
At time: 195.59984683990479 and batch: 800, loss is 5.849597091674805 and perplexity is 347.094505036428
At time: 196.62221312522888 and batch: 850, loss is 5.848038940429688 and perplexity is 346.5541004266245
At time: 197.64487600326538 and batch: 900, loss is 5.889844045639038 and perplexity is 361.34892603689195
At time: 198.66787147521973 and batch: 950, loss is 5.859606761932373 and perplexity is 350.58625304901517
At time: 199.6900827884674 and batch: 1000, loss is 5.871072044372559 and perplexity is 354.6289545317905
At time: 200.71223187446594 and batch: 1050, loss is 5.844306869506836 and perplexity is 345.263146409607
At time: 201.73526430130005 and batch: 1100, loss is 5.8322892665863035 and perplexity is 341.1387433699964
At time: 202.75632166862488 and batch: 1150, loss is 5.834200553894043 and perplexity is 341.7913810107224
At time: 203.77771973609924 and batch: 1200, loss is 5.8204664134979245 and perplexity is 337.1292586027184
At time: 204.83010816574097 and batch: 1250, loss is 5.843787307739258 and perplexity is 345.08380747184094
At time: 205.85186457633972 and batch: 1300, loss is 5.808762845993042 and perplexity is 333.20664264157057
At time: 206.87299847602844 and batch: 1350, loss is 5.802505912780762 and perplexity is 331.12829973949266
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.604278157552083 and perplexity of 271.5858124937921
Finished 7 epochs...
Completing Train Step...
At time: 209.99812698364258 and batch: 50, loss is 5.88930082321167 and perplexity is 361.15268650184714
At time: 211.0574014186859 and batch: 100, loss is 5.905998983383179 and perplexity is 367.2339031716738
At time: 212.07935428619385 and batch: 150, loss is 5.870504665374756 and perplexity is 354.4278025810686
At time: 213.10116386413574 and batch: 200, loss is 5.8633059310913085 and perplexity is 351.88553254957424
At time: 214.12339186668396 and batch: 250, loss is 5.881488237380982 and perplexity is 358.34214324125674
At time: 215.14893770217896 and batch: 300, loss is 5.898394021987915 and perplexity is 364.4516962124474
At time: 216.1770167350769 and batch: 350, loss is 5.902884912490845 and perplexity is 366.09208953016355
At time: 217.19872283935547 and batch: 400, loss is 5.939200801849365 and perplexity is 379.6314075483553
At time: 218.2203540802002 and batch: 450, loss is 5.906752071380615 and perplexity is 367.51056677934963
At time: 219.24988293647766 and batch: 500, loss is 5.925742788314819 and perplexity is 374.55654828527474
At time: 220.27474212646484 and batch: 550, loss is 5.89325140953064 and perplexity is 362.5822733580264
At time: 221.2942819595337 and batch: 600, loss is 5.8432614040374755 and perplexity is 344.90237433242777
At time: 222.3134002685547 and batch: 650, loss is 5.874942684173584 and perplexity is 356.00425540790627
At time: 223.3326404094696 and batch: 700, loss is 5.885055370330811 and perplexity is 359.62267987208764
At time: 224.35155177116394 and batch: 750, loss is 5.862305240631104 and perplexity is 351.5335801811264
At time: 225.3699288368225 and batch: 800, loss is 5.83054859161377 and perplexity is 340.5454482140698
At time: 226.38984155654907 and batch: 850, loss is 5.8305168724060055 and perplexity is 340.53464655355566
At time: 227.4094307422638 and batch: 900, loss is 5.874905862808228 and perplexity is 355.991147086484
At time: 228.4288294315338 and batch: 950, loss is 5.847141466140747 and perplexity is 346.24321655777123
At time: 229.4493751525879 and batch: 1000, loss is 5.858702726364136 and perplexity is 350.26945382698256
At time: 230.49434399604797 and batch: 1050, loss is 5.834185647964477 and perplexity is 341.7862863304416
At time: 231.52561378479004 and batch: 1100, loss is 5.824770679473877 and perplexity is 338.5834800327713
At time: 232.54715538024902 and batch: 1150, loss is 5.828302030563354 and perplexity is 339.7812508036953
At time: 233.5658736228943 and batch: 1200, loss is 5.813685941696167 and perplexity is 334.85109541002674
At time: 234.58542108535767 and batch: 1250, loss is 5.839219446182251 and perplexity is 343.51110708713765
At time: 235.60525703430176 and batch: 1300, loss is 5.804868440628052 and perplexity is 331.9115243993881
At time: 236.62551856040955 and batch: 1350, loss is 5.792174282073975 and perplexity is 327.7248164708076
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.598039143880208 and perplexity of 269.89665969947174
Finished 8 epochs...
Completing Train Step...
At time: 239.71637725830078 and batch: 50, loss is 5.873881950378418 and perplexity is 355.6268298723708
At time: 240.73745107650757 and batch: 100, loss is 5.890861759185791 and perplexity is 361.7168629294468
At time: 241.7591516971588 and batch: 150, loss is 5.855625886917114 and perplexity is 349.19338724533526
At time: 242.7801079750061 and batch: 200, loss is 5.847406816482544 and perplexity is 346.3351045043396
At time: 243.80974340438843 and batch: 250, loss is 5.867448024749756 and perplexity is 353.34609819405813
At time: 244.8328206539154 and batch: 300, loss is 5.882563581466675 and perplexity is 358.7276916070705
At time: 245.85518527030945 and batch: 350, loss is 5.888359689712525 and perplexity is 360.81295350240333
At time: 246.87763333320618 and batch: 400, loss is 5.924300212860107 and perplexity is 374.01661174555136
At time: 247.89859867095947 and batch: 450, loss is 5.893052434921264 and perplexity is 362.51013586882084
At time: 248.92409372329712 and batch: 500, loss is 5.912848901748657 and perplexity is 369.7580606961893
At time: 249.9499089717865 and batch: 550, loss is 5.880947208404541 and perplexity is 358.1483221944124
At time: 250.9717080593109 and batch: 600, loss is 5.830567655563354 and perplexity is 340.55194041720904
At time: 251.99154925346375 and batch: 650, loss is 5.8610091876983645 and perplexity is 351.0782691708956
At time: 253.02586555480957 and batch: 700, loss is 5.87199912071228 and perplexity is 354.9578750885918
At time: 254.0518753528595 and batch: 750, loss is 5.851685867309571 and perplexity is 347.82026529280597
At time: 255.071715593338 and batch: 800, loss is 5.820446662902832 and perplexity is 337.1226001649921
At time: 256.1200535297394 and batch: 850, loss is 5.818018350601196 and perplexity is 336.3049543593206
At time: 257.1409158706665 and batch: 900, loss is 5.8663922214508055 and perplexity is 352.97323108971005
At time: 258.1618764400482 and batch: 950, loss is 5.837974481582641 and perplexity is 343.083714019064
At time: 259.1828775405884 and batch: 1000, loss is 5.849611177444458 and perplexity is 347.09939416410725
At time: 260.20262718200684 and batch: 1050, loss is 5.826002941131592 and perplexity is 339.0009606429982
At time: 261.23063349723816 and batch: 1100, loss is 5.815165271759033 and perplexity is 335.34681727977915
At time: 262.25042057037354 and batch: 1150, loss is 5.821900405883789 and perplexity is 337.6130461835581
At time: 263.27006316185 and batch: 1200, loss is 5.8052847290039065 and perplexity is 332.0497240722705
At time: 264.2979986667633 and batch: 1250, loss is 5.830433988571167 and perplexity is 340.50642290581226
At time: 265.31989455223083 and batch: 1300, loss is 5.7970543956756595 and perplexity is 329.3280596278086
At time: 266.3405599594116 and batch: 1350, loss is 5.7828403759002684 and perplexity is 324.6800954583021
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.591406656901042 and perplexity of 268.11249687706015
Finished 9 epochs...
Completing Train Step...
At time: 269.47770714759827 and batch: 50, loss is 5.861677627563477 and perplexity is 351.31302233222897
At time: 270.4991385936737 and batch: 100, loss is 5.877959508895874 and perplexity is 357.0798795157694
At time: 271.527893781662 and batch: 150, loss is 5.845685596466065 and perplexity is 345.73949832174407
At time: 272.5511054992676 and batch: 200, loss is 5.835516624450683 and perplexity is 342.2414987121425
At time: 273.57367157936096 and batch: 250, loss is 5.855123376846313 and perplexity is 349.0179581327269
At time: 274.60695481300354 and batch: 300, loss is 5.871444625854492 and perplexity is 354.7611073305205
At time: 275.6306493282318 and batch: 350, loss is 5.8769568252563475 and perplexity is 356.7220208020956
At time: 276.65416979789734 and batch: 400, loss is 5.913475980758667 and perplexity is 369.99000092965935
At time: 277.67992877960205 and batch: 450, loss is 5.882963304519653 and perplexity is 358.871111997456
At time: 278.7091660499573 and batch: 500, loss is 5.901968698501587 and perplexity is 365.7568244471122
At time: 279.73897314071655 and batch: 550, loss is 5.871252756118775 and perplexity is 354.69304594028347
At time: 280.7605412006378 and batch: 600, loss is 5.8206105804443355 and perplexity is 337.1778650021109
At time: 281.7823667526245 and batch: 650, loss is 5.8506378650665285 and perplexity is 347.45593981490777
At time: 282.83963680267334 and batch: 700, loss is 5.8612008380889895 and perplexity is 351.14555990626405
At time: 283.86693143844604 and batch: 750, loss is 5.843342294692993 and perplexity is 344.93027484000714
At time: 284.88776111602783 and batch: 800, loss is 5.8108689498901365 and perplexity is 333.9091499672096
At time: 285.9108567237854 and batch: 850, loss is 5.808368949890137 and perplexity is 333.0754196893735
At time: 286.93386149406433 and batch: 900, loss is 5.856230421066284 and perplexity is 349.4045503938256
At time: 287.9559757709503 and batch: 950, loss is 5.825903768539429 and perplexity is 338.96734270600194
At time: 288.9789528846741 and batch: 1000, loss is 5.8362344455718995 and perplexity is 342.48725508247895
At time: 290.00309801101685 and batch: 1050, loss is 5.81144528388977 and perplexity is 334.10164862955816
At time: 291.0266447067261 and batch: 1100, loss is 5.796129674911499 and perplexity is 329.02366389506824
At time: 292.0550253391266 and batch: 1150, loss is 5.800281953811646 and perplexity is 330.39270225985337
At time: 293.0793058872223 and batch: 1200, loss is 5.783677110671997 and perplexity is 324.951880273906
At time: 294.10227608680725 and batch: 1250, loss is 5.806098957061767 and perplexity is 332.3201983731544
At time: 295.1263325214386 and batch: 1300, loss is 5.769015035629272 and perplexity is 320.2221698358001
At time: 296.1486186981201 and batch: 1350, loss is 5.749591598510742 and perplexity is 314.0623705507651
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.558375244140625 and perplexity of 259.4010304058447
Finished 10 epochs...
Completing Train Step...
At time: 299.2512722015381 and batch: 50, loss is 5.825575256347657 and perplexity is 338.8560060900295
At time: 300.30247020721436 and batch: 100, loss is 5.837888135910034 and perplexity is 343.0540915039228
At time: 301.32580518722534 and batch: 150, loss is 5.806501140594483 and perplexity is 332.45387896479326
At time: 302.353089094162 and batch: 200, loss is 5.796422281265259 and perplexity is 329.119952396288
At time: 303.38004779815674 and batch: 250, loss is 5.813556432723999 and perplexity is 334.8077319968671
At time: 304.4117476940155 and batch: 300, loss is 5.828324823379517 and perplexity is 339.78899546354126
At time: 305.4375991821289 and batch: 350, loss is 5.8357100009918215 and perplexity is 342.3076865887825
At time: 306.4691073894501 and batch: 400, loss is 5.873563051223755 and perplexity is 355.51343885805943
At time: 307.49992656707764 and batch: 450, loss is 5.839337558746338 and perplexity is 343.5516824609715
At time: 308.54947209358215 and batch: 500, loss is 5.8619356536865235 and perplexity is 351.40368196513094
At time: 309.57097125053406 and batch: 550, loss is 5.827804918289185 and perplexity is 339.6123833499076
At time: 310.5903730392456 and batch: 600, loss is 5.776116504669189 and perplexity is 322.5043113485772
At time: 311.6189024448395 and batch: 650, loss is 5.807057771682739 and perplexity is 332.63898464224457
At time: 312.6394793987274 and batch: 700, loss is 5.817646131515503 and perplexity is 336.1797985308339
At time: 313.6683406829834 and batch: 750, loss is 5.798906106948852 and perplexity is 329.93844506278634
At time: 314.6885509490967 and batch: 800, loss is 5.767453775405884 and perplexity is 319.7226097724909
At time: 315.7103695869446 and batch: 850, loss is 5.759567537307739 and perplexity is 317.2111172767386
At time: 316.73150062561035 and batch: 900, loss is 5.810700817108154 and perplexity is 333.8530136122093
At time: 317.75194907188416 and batch: 950, loss is 5.783474187850953 and perplexity is 324.88594681158554
At time: 318.7719533443451 and batch: 1000, loss is 5.7936163330078125 and perplexity is 328.19775326595817
At time: 319.7928104400635 and batch: 1050, loss is 5.767768688201905 and perplexity is 319.82331036860626
At time: 320.8139793872833 and batch: 1100, loss is 5.755909156799317 and perplexity is 316.05275845883057
At time: 321.8338177204132 and batch: 1150, loss is 5.762809476852417 and perplexity is 318.24116531642085
At time: 322.85345792770386 and batch: 1200, loss is 5.749220781326294 and perplexity is 313.9459324167411
At time: 323.87447595596313 and batch: 1250, loss is 5.767598180770874 and perplexity is 319.7687827663845
At time: 324.8949842453003 and batch: 1300, loss is 5.736538677215576 and perplexity is 309.98957789347713
At time: 325.9278030395508 and batch: 1350, loss is 5.7192050552368165 and perplexity is 304.66263669998983
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.5397041829427085 and perplexity of 254.60267250424621
Finished 11 epochs...
Completing Train Step...
At time: 329.0227825641632 and batch: 50, loss is 5.794741115570068 and perplexity is 328.56711206102847
At time: 330.07067942619324 and batch: 100, loss is 5.808045721054077 and perplexity is 332.96777750661295
At time: 331.0932950973511 and batch: 150, loss is 5.777036657333374 and perplexity is 322.80120112088565
At time: 332.11449217796326 and batch: 200, loss is 5.765792169570923 and perplexity is 319.1917979406704
At time: 333.13611364364624 and batch: 250, loss is 5.785500993728638 and perplexity is 325.54509531554635
At time: 334.1953320503235 and batch: 300, loss is 5.7985546875 and perplexity is 329.82251864685895
At time: 335.21708488464355 and batch: 350, loss is 5.806999778747558 and perplexity is 332.6196944905211
At time: 336.2386372089386 and batch: 400, loss is 5.841210231781006 and perplexity is 344.19564521037626
At time: 337.2601463794708 and batch: 450, loss is 5.808621273040772 and perplexity is 333.1594729325122
At time: 338.2824294567108 and batch: 500, loss is 5.829925928115845 and perplexity is 340.33346899679174
At time: 339.30414032936096 and batch: 550, loss is 5.79869010925293 and perplexity is 329.86718681494233
At time: 340.32510018348694 and batch: 600, loss is 5.745719881057739 and perplexity is 312.8487606826464
At time: 341.34642791748047 and batch: 650, loss is 5.773631181716919 and perplexity is 321.7037791839204
At time: 342.36867928504944 and batch: 700, loss is 5.785006399154663 and perplexity is 325.3841222892934
At time: 343.39087104797363 and batch: 750, loss is 5.76180624961853 and perplexity is 317.9220572081682
At time: 344.41141748428345 and batch: 800, loss is 5.7222265625 and perplexity is 305.5845691810445
At time: 345.4338209629059 and batch: 850, loss is 5.709843740463257 and perplexity is 301.82390173471174
At time: 346.4558720588684 and batch: 900, loss is 5.753046216964722 and perplexity is 315.1492124428998
At time: 347.4768283367157 and batch: 950, loss is 5.7224791431427 and perplexity is 305.66176367643465
At time: 348.49958992004395 and batch: 1000, loss is 5.736516771316528 and perplexity is 309.9827873674543
At time: 349.5228898525238 and batch: 1050, loss is 5.7097068119049075 and perplexity is 301.7825762523557
At time: 350.54660654067993 and batch: 1100, loss is 5.694719886779785 and perplexity is 297.2935060803497
At time: 351.5764138698578 and batch: 1150, loss is 5.701363906860352 and perplexity is 299.2753063748332
At time: 352.6003448963165 and batch: 1200, loss is 5.68671064376831 and perplexity is 294.92192012622274
At time: 353.62788558006287 and batch: 1250, loss is 5.706576471328735 and perplexity is 300.83937105568856
At time: 354.6607880592346 and batch: 1300, loss is 5.675458374023438 and perplexity is 291.62197985435654
At time: 355.6853678226471 and batch: 1350, loss is 5.659718618392945 and perplexity is 287.0678555760663
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.480005289713541 and perplexity of 239.8479760979867
Finished 12 epochs...
Completing Train Step...
At time: 358.81745529174805 and batch: 50, loss is 5.731620273590088 and perplexity is 308.4686673217263
At time: 359.8410084247589 and batch: 100, loss is 5.738348197937012 and perplexity is 310.5510182739088
At time: 360.8919177055359 and batch: 150, loss is 5.707239274978638 and perplexity is 301.0388345841338
At time: 361.9169237613678 and batch: 200, loss is 5.69319787979126 and perplexity is 296.84136745280955
At time: 362.9449701309204 and batch: 250, loss is 5.713103656768799 and perplexity is 302.80942788699576
At time: 363.9681272506714 and batch: 300, loss is 5.726731147766113 and perplexity is 306.96420594175817
At time: 364.9909679889679 and batch: 350, loss is 5.736623048782349 and perplexity is 310.01573330321804
At time: 366.0130376815796 and batch: 400, loss is 5.769013872146607 and perplexity is 320.22179726307303
At time: 367.03481101989746 and batch: 450, loss is 5.736368808746338 and perplexity is 309.93692491056794
At time: 368.05947732925415 and batch: 500, loss is 5.758382835388184 and perplexity is 316.835539175173
At time: 369.08632254600525 and batch: 550, loss is 5.729389238357544 and perplexity is 307.78122999039306
At time: 370.1089036464691 and batch: 600, loss is 5.677212543487549 and perplexity is 292.13398316547676
At time: 371.128945350647 and batch: 650, loss is 5.70611162185669 and perplexity is 300.6995585312895
At time: 372.1493134498596 and batch: 700, loss is 5.723716535568237 and perplexity is 306.0402213296116
At time: 373.1758372783661 and batch: 750, loss is 5.691015567779541 and perplexity is 296.1942733085188
At time: 374.20096492767334 and batch: 800, loss is 5.659972286224365 and perplexity is 287.1406846932723
At time: 375.2315905094147 and batch: 850, loss is 5.65506763458252 and perplexity is 285.7358076950519
At time: 376.25117015838623 and batch: 900, loss is 5.699009475708007 and perplexity is 298.5715121130588
At time: 377.2710597515106 and batch: 950, loss is 5.669588489532471 and perplexity is 289.91520669886876
At time: 378.28962540626526 and batch: 1000, loss is 5.683253040313721 and perplexity is 293.90395794528337
At time: 379.3138847351074 and batch: 1050, loss is 5.655324783325195 and perplexity is 285.809293746756
At time: 380.3401391506195 and batch: 1100, loss is 5.642523946762085 and perplexity is 282.17401264894
At time: 381.36019945144653 and batch: 1150, loss is 5.650796241760254 and perplexity is 284.51792070554615
At time: 382.3796172142029 and batch: 1200, loss is 5.6365617084503175 and perplexity is 280.49662938851395
At time: 383.409197807312 and batch: 1250, loss is 5.6510679721832275 and perplexity is 284.5952433854694
At time: 384.43161249160767 and batch: 1300, loss is 5.620166797637939 and perplexity is 275.93540477027335
At time: 385.4580419063568 and batch: 1350, loss is 5.605193319320679 and perplexity is 271.8344712104001
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.434567464192709 and perplexity of 229.1936923543025
Finished 13 epochs...
Completing Train Step...
At time: 388.63184881210327 and batch: 50, loss is 5.67664873123169 and perplexity is 291.96932086908737
At time: 389.65707206726074 and batch: 100, loss is 5.681137619018554 and perplexity is 293.28288440162123
At time: 390.685266494751 and batch: 150, loss is 5.6509873580932615 and perplexity is 284.57230192363016
At time: 391.71444964408875 and batch: 200, loss is 5.64210352897644 and perplexity is 282.0554066091667
At time: 392.7398245334625 and batch: 250, loss is 5.661565580368042 and perplexity is 287.59854892394355
At time: 393.77037477493286 and batch: 300, loss is 5.67569787979126 and perplexity is 291.6918333653808
At time: 394.80086064338684 and batch: 350, loss is 5.686674337387085 and perplexity is 294.91121277293286
At time: 395.83116602897644 and batch: 400, loss is 5.716529169082642 and perplexity is 303.84848394459533
At time: 396.85364532470703 and batch: 450, loss is 5.686170110702514 and perplexity is 294.76254815335744
At time: 397.8756613731384 and batch: 500, loss is 5.707681570053101 and perplexity is 301.172012027585
At time: 398.89752769470215 and batch: 550, loss is 5.681520233154297 and perplexity is 293.395120049068
At time: 399.91802191734314 and batch: 600, loss is 5.630662698745727 and perplexity is 278.84684787236534
At time: 400.94846534729004 and batch: 650, loss is 5.659914836883545 and perplexity is 287.1241891240485
At time: 401.96994519233704 and batch: 700, loss is 5.683833627700806 and perplexity is 294.0746444206935
At time: 402.99043560028076 and batch: 750, loss is 5.649341306686401 and perplexity is 284.1042665964776
At time: 404.0126631259918 and batch: 800, loss is 5.619803371429444 and perplexity is 275.835140832703
At time: 405.0415036678314 and batch: 850, loss is 5.609188766479492 and perplexity is 272.9227440967422
At time: 406.0657684803009 and batch: 900, loss is 5.655725631713867 and perplexity is 285.9238829065276
At time: 407.0870747566223 and batch: 950, loss is 5.6254435157775875 and perplexity is 277.39528643063477
At time: 408.10792088508606 and batch: 1000, loss is 5.635886602401733 and perplexity is 280.3073283237429
At time: 409.12886452674866 and batch: 1050, loss is 5.6065172100067135 and perplexity is 272.19458866044994
At time: 410.1512761116028 and batch: 1100, loss is 5.594859752655029 and perplexity is 269.03991531241337
At time: 411.1765069961548 and batch: 1150, loss is 5.602589511871338 and perplexity is 271.12758728347063
At time: 412.2422800064087 and batch: 1200, loss is 5.58449200630188 and perplexity is 266.26498744214496
At time: 413.2638053894043 and batch: 1250, loss is 5.5983921241760255 and perplexity is 269.99194471813024
At time: 414.29271817207336 and batch: 1300, loss is 5.570438871383667 and perplexity is 262.54929933369704
At time: 415.3135850429535 and batch: 1350, loss is 5.55305287361145 and perplexity is 258.0240696046703
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.389320068359375 and perplexity of 219.05439289453594
Finished 14 epochs...
Completing Train Step...
At time: 418.4122259616852 and batch: 50, loss is 5.6225741004943846 and perplexity is 276.60046503793774
At time: 419.46025943756104 and batch: 100, loss is 5.627202138900757 and perplexity is 277.88354940504865
At time: 420.48299980163574 and batch: 150, loss is 5.592578411102295 and perplexity is 268.4268429538857
At time: 421.5053732395172 and batch: 200, loss is 5.581576728820801 and perplexity is 265.4898814936722
At time: 422.5272648334503 and batch: 250, loss is 5.600496501922607 and perplexity is 270.56070799484985
At time: 423.5505349636078 and batch: 300, loss is 5.616361103057861 and perplexity is 274.8872745925885
At time: 424.5719859600067 and batch: 350, loss is 5.621753168106079 and perplexity is 276.3734879367419
At time: 425.59443759918213 and batch: 400, loss is 5.6534033203125 and perplexity is 285.2606490292036
At time: 426.6168727874756 and batch: 450, loss is 5.621085166931152 and perplexity is 276.18893177081213
At time: 427.6438720226288 and batch: 500, loss is 5.643915891647339 and perplexity is 282.5670568070403
At time: 428.6664650440216 and batch: 550, loss is 5.617189636230469 and perplexity is 275.1151221949304
At time: 429.6962285041809 and batch: 600, loss is 5.572231092453003 and perplexity is 263.02026763329235
At time: 430.71698927879333 and batch: 650, loss is 5.602440853118896 and perplexity is 271.0872847903258
At time: 431.7380542755127 and batch: 700, loss is 5.62002290725708 and perplexity is 275.89570317619564
At time: 432.76766896247864 and batch: 750, loss is 5.592543277740479 and perplexity is 268.4174123821558
At time: 433.7933919429779 and batch: 800, loss is 5.560870990753174 and perplexity is 260.04923819350665
At time: 434.81540060043335 and batch: 850, loss is 5.551102199554443 and perplexity is 257.52123933443534
At time: 435.8369379043579 and batch: 900, loss is 5.593213853836059 and perplexity is 268.5974670459665
At time: 436.85950922966003 and batch: 950, loss is 5.5701296997070315 and perplexity is 262.468139073496
At time: 437.91020464897156 and batch: 1000, loss is 5.5835686206817625 and perplexity is 266.0192356608921
At time: 438.9316074848175 and batch: 1050, loss is 5.551781778335571 and perplexity is 257.69630478302133
At time: 439.9532814025879 and batch: 1100, loss is 5.547373237609864 and perplexity is 256.5627406462749
At time: 440.97547817230225 and batch: 1150, loss is 5.556286859512329 and perplexity is 258.8598665571962
At time: 441.9974739551544 and batch: 1200, loss is 5.546269702911377 and perplexity is 256.2797709218041
At time: 443.0256905555725 and batch: 1250, loss is 5.556794490814209 and perplexity is 258.99130528664523
At time: 444.0479304790497 and batch: 1300, loss is 5.533554248809814 and perplexity is 253.04168773496338
At time: 445.0769467353821 and batch: 1350, loss is 5.512572813034057 and perplexity is 247.78781940268615
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.353697509765625 and perplexity of 211.38846555473737
Finished 15 epochs...
Completing Train Step...
At time: 448.16633319854736 and batch: 50, loss is 5.580837173461914 and perplexity is 265.29360961498884
At time: 449.2145495414734 and batch: 100, loss is 5.591402015686035 and perplexity is 268.1112525122038
At time: 450.2352862358093 and batch: 150, loss is 5.564029722213745 and perplexity is 260.8719626021558
At time: 451.25865292549133 and batch: 200, loss is 5.554768733978271 and perplexity is 258.46718293097115
At time: 452.2802782058716 and batch: 250, loss is 5.571492977142334 and perplexity is 262.8261999777009
At time: 453.30327439308167 and batch: 300, loss is 5.5889351940155025 and perplexity is 267.4506849505553
At time: 454.3253650665283 and batch: 350, loss is 5.5936641502380375 and perplexity is 268.7184427543767
At time: 455.34751653671265 and batch: 400, loss is 5.626152667999268 and perplexity is 277.59207168139267
At time: 456.37585043907166 and batch: 450, loss is 5.597654037475586 and perplexity is 269.7927407784406
At time: 457.39935851097107 and batch: 500, loss is 5.618890342712402 and perplexity is 275.58341036401424
At time: 458.42153453826904 and batch: 550, loss is 5.5962560176849365 and perplexity is 269.41582871410975
At time: 459.44247817993164 and batch: 600, loss is 5.552189931869507 and perplexity is 257.80150590814577
At time: 460.464421749115 and batch: 650, loss is 5.574475908279419 and perplexity is 263.611362894522
At time: 461.49030470848083 and batch: 700, loss is 5.59643632888794 and perplexity is 269.4644117861978
At time: 462.51641368865967 and batch: 750, loss is 5.573977012634277 and perplexity is 263.47988113412987
At time: 463.5376567840576 and batch: 800, loss is 5.538004083633423 and perplexity is 254.17019041200086
At time: 464.5871591567993 and batch: 850, loss is 5.528154869079589 and perplexity is 251.67910144602243
At time: 465.61030626296997 and batch: 900, loss is 5.571287031173706 and perplexity is 262.77207755470437
At time: 466.6328339576721 and batch: 950, loss is 5.543823528289795 and perplexity is 255.65363198496132
At time: 467.65481781959534 and batch: 1000, loss is 5.557949094772339 and perplexity is 259.2905103712986
At time: 468.67621898651123 and batch: 1050, loss is 5.526698150634766 and perplexity is 251.31274276228064
At time: 469.6996855735779 and batch: 1100, loss is 5.515594253540039 and perplexity is 248.53762773733223
At time: 470.7306237220764 and batch: 1150, loss is 5.523773307800293 and perplexity is 250.57876639340822
At time: 471.757794380188 and batch: 1200, loss is 5.509755563735962 and perplexity is 247.09072175239612
At time: 472.78158712387085 and batch: 1250, loss is 5.521602849960328 and perplexity is 250.03548554272948
At time: 473.8051519393921 and batch: 1300, loss is 5.499556407928467 and perplexity is 244.58341293403663
At time: 474.82722783088684 and batch: 1350, loss is 5.47944902420044 and perplexity is 239.71459404185447
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.335902099609375 and perplexity of 207.65999433795642
Finished 16 epochs...
Completing Train Step...
At time: 477.93109154701233 and batch: 50, loss is 5.548726415634155 and perplexity is 256.9101507095893
At time: 478.9537901878357 and batch: 100, loss is 5.558556394577026 and perplexity is 259.4480252721475
At time: 479.97661542892456 and batch: 150, loss is 5.529832105636597 and perplexity is 252.10158103566815
At time: 480.9996745586395 and batch: 200, loss is 5.519538478851318 and perplexity is 249.51985192284175
At time: 482.02125573158264 and batch: 250, loss is 5.53880018234253 and perplexity is 254.3726155369807
At time: 483.04380345344543 and batch: 300, loss is 5.556355037689209 and perplexity is 258.87751575260364
At time: 484.0668959617615 and batch: 350, loss is 5.5602756786346434 and perplexity is 259.894473801725
At time: 485.09701228141785 and batch: 400, loss is 5.590588102340698 and perplexity is 267.8931219674716
At time: 486.12074518203735 and batch: 450, loss is 5.558589563369751 and perplexity is 259.4566309926405
At time: 487.1430299282074 and batch: 500, loss is 5.584664945602417 and perplexity is 266.311039104787
At time: 488.1703155040741 and batch: 550, loss is 5.558979444503784 and perplexity is 259.557807960378
At time: 489.19458055496216 and batch: 600, loss is 5.514108209609986 and perplexity is 248.1685641944799
At time: 490.2589662075043 and batch: 650, loss is 5.537485332489013 and perplexity is 254.03837352788565
At time: 491.2813413143158 and batch: 700, loss is 5.55912302017212 and perplexity is 259.59507682151445
At time: 492.3041477203369 and batch: 750, loss is 5.532954082489014 and perplexity is 252.88986619986966
At time: 493.3256516456604 and batch: 800, loss is 5.501102628707886 and perplexity is 244.96188541501945
At time: 494.34885597229004 and batch: 850, loss is 5.492438869476318 and perplexity is 242.84876163440393
At time: 495.3716707229614 and batch: 900, loss is 5.536700458526611 and perplexity is 253.83906364985114
At time: 496.3937246799469 and batch: 950, loss is 5.512804107666016 and perplexity is 247.84513802366777
At time: 497.41618633270264 and batch: 1000, loss is 5.528864641189575 and perplexity is 251.8577996628982
At time: 498.44018483161926 and batch: 1050, loss is 5.494646148681641 and perplexity is 243.38538868098408
At time: 499.4649317264557 and batch: 1100, loss is 5.485451545715332 and perplexity is 241.15781319373457
At time: 500.4891974925995 and batch: 1150, loss is 5.4987514686584475 and perplexity is 244.38661735504124
At time: 501.5148911476135 and batch: 1200, loss is 5.480295362472535 and perplexity is 239.91755955379696
At time: 502.53963136672974 and batch: 1250, loss is 5.492899856567383 and perplexity is 242.96073758634952
At time: 503.5704131126404 and batch: 1300, loss is 5.4713262176513675 and perplexity is 237.77532558146882
At time: 504.5944309234619 and batch: 1350, loss is 5.452336273193359 and perplexity is 233.30258828327936
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.320233561197917 and perplexity of 204.43162371237068
Finished 17 epochs...
Completing Train Step...
At time: 507.7255218029022 and batch: 50, loss is 5.5237089538574216 and perplexity is 250.562641180657
At time: 508.75066781044006 and batch: 100, loss is 5.535167808532715 and perplexity is 253.45031519425467
At time: 509.78429317474365 and batch: 150, loss is 5.506284627914429 and perplexity is 246.23457239436556
At time: 510.8089392185211 and batch: 200, loss is 5.496386566162109 and perplexity is 243.80934969349704
At time: 511.83338618278503 and batch: 250, loss is 5.517940816879272 and perplexity is 249.12152182730588
At time: 512.8582713603973 and batch: 300, loss is 5.533928985595703 and perplexity is 253.13652953296653
At time: 513.8848898410797 and batch: 350, loss is 5.535471506118775 and perplexity is 253.52729913249163
At time: 514.9091091156006 and batch: 400, loss is 5.568893146514893 and perplexity is 262.14378384086905
At time: 515.9339544773102 and batch: 450, loss is 5.537998237609863 and perplexity is 254.16870453142286
At time: 516.985746383667 and batch: 500, loss is 5.562989521026611 and perplexity is 260.60074436218986
At time: 518.0100512504578 and batch: 550, loss is 5.536022090911866 and perplexity is 253.66692584267182
At time: 519.0340120792389 and batch: 600, loss is 5.491346597671509 and perplexity is 242.58364959279965
At time: 520.0585668087006 and batch: 650, loss is 5.516925783157348 and perplexity is 248.868783372521
At time: 521.0829503536224 and batch: 700, loss is 5.536131563186646 and perplexity is 253.69469685813073
At time: 522.1074464321136 and batch: 750, loss is 5.51312334060669 and perplexity is 247.92427098616298
At time: 523.1317048072815 and batch: 800, loss is 5.482802572250367 and perplexity is 240.51983790857537
At time: 524.1560966968536 and batch: 850, loss is 5.475179290771484 and perplexity is 238.693258592951
At time: 525.1814141273499 and batch: 900, loss is 5.515834121704102 and perplexity is 248.59725115239183
At time: 526.2051365375519 and batch: 950, loss is 5.49175235748291 and perplexity is 242.68210026101895
At time: 527.236546754837 and batch: 1000, loss is 5.509918222427368 and perplexity is 247.13091647477674
At time: 528.2661292552948 and batch: 1050, loss is 5.478123073577881 and perplexity is 239.39695496005533
At time: 529.2910804748535 and batch: 1100, loss is 5.468857870101929 and perplexity is 237.18913719521063
At time: 530.3128547668457 and batch: 1150, loss is 5.479723615646362 and perplexity is 239.780426656964
At time: 531.3357353210449 and batch: 1200, loss is 5.461548547744751 and perplexity is 235.4617659789207
At time: 532.362562417984 and batch: 1250, loss is 5.474498481750488 and perplexity is 238.53080937397146
At time: 533.3846917152405 and batch: 1300, loss is 5.455806169509888 and perplexity is 234.113530203534
At time: 534.4058647155762 and batch: 1350, loss is 5.431146478652954 and perplexity is 228.41096366208947
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.311457926432292 and perplexity of 202.6454552919549
Finished 18 epochs...
Completing Train Step...
At time: 537.5004580020905 and batch: 50, loss is 5.50812985420227 and perplexity is 246.6893503554095
At time: 538.5496127605438 and batch: 100, loss is 5.520044422149658 and perplexity is 249.64612676098517
At time: 539.5724496841431 and batch: 150, loss is 5.491521368026733 and perplexity is 242.62604972844605
At time: 540.5950970649719 and batch: 200, loss is 5.48416431427002 and perplexity is 240.84758698261209
At time: 541.6177816390991 and batch: 250, loss is 5.499590415954589 and perplexity is 244.59173087457035
At time: 542.6692519187927 and batch: 300, loss is 5.515278911590576 and perplexity is 248.4592657533464
At time: 543.6916010379791 and batch: 350, loss is 5.514197845458984 and perplexity is 248.19080999142173
At time: 544.7151687145233 and batch: 400, loss is 5.5494362735748295 and perplexity is 257.0925851637227
At time: 545.7434253692627 and batch: 450, loss is 5.512972822189331 and perplexity is 247.88695662558908
At time: 546.7675082683563 and batch: 500, loss is 5.540451288223267 and perplexity is 254.7929585783328
At time: 547.7899351119995 and batch: 550, loss is 5.515341529846191 and perplexity is 248.4748243262796
At time: 548.8133704662323 and batch: 600, loss is 5.468595371246338 and perplexity is 237.12688348925906
At time: 549.8456540107727 and batch: 650, loss is 5.495565481185913 and perplexity is 243.60924366267764
At time: 550.869015455246 and batch: 700, loss is 5.518437547683716 and perplexity is 249.2452989006449
At time: 551.8922934532166 and batch: 750, loss is 5.4913732624053955 and perplexity is 242.59011810750152
At time: 552.91579246521 and batch: 800, loss is 5.462128410339355 and perplexity is 235.59834104302993
At time: 553.9390993118286 and batch: 850, loss is 5.45461651802063 and perplexity is 233.83518229500197
At time: 554.9618570804596 and batch: 900, loss is 5.49867036819458 and perplexity is 244.36679829068933
At time: 555.9916031360626 and batch: 950, loss is 5.469563999176025 and perplexity is 237.3566824883836
At time: 557.014087677002 and batch: 1000, loss is 5.487902736663818 and perplexity is 241.7496621136138
At time: 558.0364525318146 and batch: 1050, loss is 5.453830499649047 and perplexity is 233.6514557614704
At time: 559.0683033466339 and batch: 1100, loss is 5.447136468887329 and perplexity is 232.09260903405135
At time: 560.0919780731201 and batch: 1150, loss is 5.455772762298584 and perplexity is 234.10570925400017
At time: 561.1148192882538 and batch: 1200, loss is 5.437336339950561 and perplexity is 229.8291806009086
At time: 562.1385505199432 and batch: 1250, loss is 5.449480695724487 and perplexity is 232.63732497626754
At time: 563.1620376110077 and batch: 1300, loss is 5.43116340637207 and perplexity is 228.41483017145092
At time: 564.1841192245483 and batch: 1350, loss is 5.40916181564331 and perplexity is 223.44422171667
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.289173583984375 and perplexity of 198.17957893802813
Finished 19 epochs...
Completing Train Step...
At time: 567.2733297348022 and batch: 50, loss is 5.483445434570313 and perplexity is 240.67450876027087
At time: 568.3215687274933 and batch: 100, loss is 5.495437030792236 and perplexity is 243.57795396905556
At time: 569.3440852165222 and batch: 150, loss is 5.464436693191528 and perplexity is 236.14279679084717
At time: 570.365918636322 and batch: 200, loss is 5.451577005386352 and perplexity is 233.1255163697128
At time: 571.3875553607941 and batch: 250, loss is 5.4756260681152344 and perplexity is 238.79992515932457
At time: 572.4098229408264 and batch: 300, loss is 5.491566848754883 and perplexity is 242.63708478879522
At time: 573.4321327209473 and batch: 350, loss is 5.490525970458984 and perplexity is 242.38466050772644
At time: 574.4546403884888 and batch: 400, loss is 5.523908376693726 and perplexity is 250.6126140759357
At time: 575.477331161499 and batch: 450, loss is 5.486832571029663 and perplexity is 241.49108831622493
At time: 576.5013556480408 and batch: 500, loss is 5.514127445220947 and perplexity is 248.17333791434626
At time: 577.5262720584869 and batch: 550, loss is 5.490194311141968 and perplexity is 242.30428470619572
At time: 578.5517086982727 and batch: 600, loss is 5.442404489517212 and perplexity is 230.99694596813046
At time: 579.5782783031464 and batch: 650, loss is 5.468107233047485 and perplexity is 237.01116104602332
At time: 580.6068389415741 and batch: 700, loss is 5.4915719413757325 and perplexity is 242.63832045061844
At time: 581.6314623355865 and batch: 750, loss is 5.465128383636475 and perplexity is 236.30619100962576
At time: 582.6561849117279 and batch: 800, loss is 5.436706953048706 and perplexity is 229.68457463629778
At time: 583.6805872917175 and batch: 850, loss is 5.4275048637390135 and perplexity is 227.58069157346495
At time: 584.7048535346985 and batch: 900, loss is 5.470391702651978 and perplexity is 237.5532247676628
At time: 585.736654996872 and batch: 950, loss is 5.446777925491333 and perplexity is 232.00940867818306
At time: 586.760636806488 and batch: 1000, loss is 5.462448635101318 and perplexity is 235.67379754658498
At time: 587.7851850986481 and batch: 1050, loss is 5.430912237167359 and perplexity is 228.35746660449485
At time: 588.8082885742188 and batch: 1100, loss is 5.42443286895752 and perplexity is 226.88263763458122
At time: 589.831211566925 and batch: 1150, loss is 5.432274341583252 and perplexity is 228.66872525342518
At time: 590.8527455329895 and batch: 1200, loss is 5.4152116870880125 and perplexity is 224.8001279266299
At time: 591.8787698745728 and batch: 1250, loss is 5.4286331462860105 and perplexity is 227.83761180785356
At time: 592.9011914730072 and batch: 1300, loss is 5.4084078979492185 and perplexity is 223.2758266502615
At time: 593.9226651191711 and batch: 1350, loss is 5.386276817321777 and perplexity is 218.3887687304995
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.272015380859375 and perplexity of 194.80817975573447
Finished 20 epochs...
Completing Train Step...
At time: 597.0134429931641 and batch: 50, loss is 5.459540100097656 and perplexity is 234.98932794140433
At time: 598.0357131958008 and batch: 100, loss is 5.472134056091309 and perplexity is 237.96748723687864
At time: 599.0577306747437 and batch: 150, loss is 5.44103217124939 and perplexity is 230.6801620532593
At time: 600.0786139965057 and batch: 200, loss is 5.431983900070191 and perplexity is 228.60232000675973
At time: 601.0996603965759 and batch: 250, loss is 5.45355408668518 and perplexity is 233.58688039521687
At time: 602.1209406852722 and batch: 300, loss is 5.469525651931763 and perplexity is 237.34758068821844
At time: 603.1434099674225 and batch: 350, loss is 5.46746792793274 and perplexity is 236.85968702273283
At time: 604.1715958118439 and batch: 400, loss is 5.50159987449646 and perplexity is 245.08372196974963
At time: 605.1935880184174 and batch: 450, loss is 5.468086071014405 and perplexity is 237.00614546106297
At time: 606.215639591217 and batch: 500, loss is 5.4947983932495115 and perplexity is 243.422445605096
At time: 607.2373924255371 and batch: 550, loss is 5.471451921463013 and perplexity is 237.80521672488553
At time: 608.2651145458221 and batch: 600, loss is 5.4259411716461186 and perplexity is 227.22510353311446
At time: 609.2884628772736 and batch: 650, loss is 5.451744585037232 and perplexity is 233.16458673596492
At time: 610.311372756958 and batch: 700, loss is 5.474722270965576 and perplexity is 238.58419597002498
At time: 611.3334329128265 and batch: 750, loss is 5.4500913906097415 and perplexity is 232.77943879042272
At time: 612.3555352687836 and batch: 800, loss is 5.418103656768799 and perplexity is 225.45118404434876
At time: 613.377946138382 and batch: 850, loss is 5.410667810440064 and perplexity is 223.78098106720665
At time: 614.4086911678314 and batch: 900, loss is 5.454679975509643 and perplexity is 233.85002135933337
At time: 615.4323770999908 and batch: 950, loss is 5.430902948379517 and perplexity is 228.3553454502869
At time: 616.4529716968536 and batch: 1000, loss is 5.447477159500122 and perplexity is 232.17169427828293
At time: 617.4750323295593 and batch: 1050, loss is 5.4127282047271725 and perplexity is 224.2425334488235
At time: 618.4967124462128 and batch: 1100, loss is 5.4058827304840085 and perplexity is 222.71272905411573
At time: 619.5187656879425 and batch: 1150, loss is 5.416397161483765 and perplexity is 225.06678074626555
At time: 620.5851006507874 and batch: 1200, loss is 5.3997093868255615 and perplexity is 221.34208193137934
At time: 621.6069457530975 and batch: 1250, loss is 5.412849245071411 and perplexity is 224.2696774849936
At time: 622.6304817199707 and batch: 1300, loss is 5.393965253829956 and perplexity is 220.0743081915805
At time: 623.6505997180939 and batch: 1350, loss is 5.370055866241455 and perplexity is 214.87487162048606
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.264910074869792 and perplexity of 193.42891388504685
Finished 21 epochs...
Completing Train Step...
At time: 626.7562801837921 and batch: 50, loss is 5.44491208076477 and perplexity is 231.5769187514841
At time: 627.7781720161438 and batch: 100, loss is 5.459970769882202 and perplexity is 235.09055254026293
At time: 628.8001685142517 and batch: 150, loss is 5.4257406234741214 and perplexity is 227.1795385231115
At time: 629.8209533691406 and batch: 200, loss is 5.417858486175537 and perplexity is 225.3959168190311
At time: 630.8428177833557 and batch: 250, loss is 5.441009178161621 and perplexity is 230.67485806502444
At time: 631.8643214702606 and batch: 300, loss is 5.454741277694702 and perplexity is 233.864357316027
At time: 632.893239736557 and batch: 350, loss is 5.453524541854859 and perplexity is 233.57997921241784
At time: 633.9149041175842 and batch: 400, loss is 5.488247451782226 and perplexity is 241.8330112420414
At time: 634.9367854595184 and batch: 450, loss is 5.450133180618286 and perplexity is 232.7891668484251
At time: 635.9676327705383 and batch: 500, loss is 5.478682107925415 and perplexity is 239.53082349564153
At time: 636.991128206253 and batch: 550, loss is 5.4584703540802 and perplexity is 234.73808345154998
At time: 638.0132250785828 and batch: 600, loss is 5.409687032699585 and perplexity is 223.56160925731245
At time: 639.0350480079651 and batch: 650, loss is 5.439802408218384 and perplexity is 230.39665447727717
At time: 640.0630397796631 and batch: 700, loss is 5.458542108535767 and perplexity is 234.75492755924148
At time: 641.0861220359802 and batch: 750, loss is 5.430929183959961 and perplexity is 228.36133656391215
At time: 642.1082882881165 and batch: 800, loss is 5.401348476409912 and perplexity is 221.70517892541022
At time: 643.1310505867004 and batch: 850, loss is 5.392332410812378 and perplexity is 219.71525461294092
At time: 644.1530735492706 and batch: 900, loss is 5.438215475082398 and perplexity is 230.03132034895398
At time: 645.1833238601685 and batch: 950, loss is 5.417087306976319 and perplexity is 225.22216318259777
At time: 646.2311971187592 and batch: 1000, loss is 5.427710962295532 and perplexity is 227.62760045925057
At time: 647.2529265880585 and batch: 1050, loss is 5.395777616500855 and perplexity is 220.47352430548798
At time: 648.2763867378235 and batch: 1100, loss is 5.38950665473938 and perplexity is 219.09526927409962
At time: 649.2989459037781 and batch: 1150, loss is 5.397562789916992 and perplexity is 220.8674592965597
At time: 650.3216941356659 and batch: 1200, loss is 5.378344125747681 and perplexity is 216.6632111915449
At time: 651.3495268821716 and batch: 1250, loss is 5.39343523979187 and perplexity is 219.95769662443058
At time: 652.3723647594452 and batch: 1300, loss is 5.377513160705567 and perplexity is 216.4832464197051
At time: 653.3936231136322 and batch: 1350, loss is 5.35129672050476 and perplexity is 210.8815751087999
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.247882080078125 and perplexity of 190.1630914612286
Finished 22 epochs...
Completing Train Step...
At time: 656.4655468463898 and batch: 50, loss is 5.424348430633545 and perplexity is 226.863480853715
At time: 657.5178780555725 and batch: 100, loss is 5.440833950042725 and perplexity is 230.6344408847858
At time: 658.5397019386292 and batch: 150, loss is 5.407617607116699 and perplexity is 223.0994435175032
At time: 659.5612280368805 and batch: 200, loss is 5.397514162063598 and perplexity is 220.85671924726446
At time: 660.5845084190369 and batch: 250, loss is 5.420882940292358 and perplexity is 226.07864835223688
At time: 661.6140866279602 and batch: 300, loss is 5.43404483795166 and perplexity is 229.0739410117181
At time: 662.6363182067871 and batch: 350, loss is 5.429246139526367 and perplexity is 227.97731753875053
At time: 663.6592307090759 and batch: 400, loss is 5.458950548171997 and perplexity is 234.8508303603765
At time: 664.6811482906342 and batch: 450, loss is 5.424687061309815 and perplexity is 226.94031679642677
At time: 665.7128822803497 and batch: 500, loss is 5.457003974914551 and perplexity is 234.3941206681563
At time: 666.7357802391052 and batch: 550, loss is 5.436030521392822 and perplexity is 229.52926125451168
At time: 667.7580440044403 and batch: 600, loss is 5.388161268234253 and perplexity is 218.80069965490878
At time: 668.7900259494781 and batch: 650, loss is 5.41505051612854 and perplexity is 224.7638995938784
At time: 669.8173260688782 and batch: 700, loss is 5.42599889755249 and perplexity is 227.2382206867624
At time: 670.8438191413879 and batch: 750, loss is 5.403206520080566 and perplexity is 222.11749976630603
At time: 671.8946425914764 and batch: 800, loss is 5.370829267501831 and perplexity is 215.04112039724035
At time: 672.9176025390625 and batch: 850, loss is 5.363921136856079 and perplexity is 213.56070757330954
At time: 673.9400990009308 and batch: 900, loss is 5.410965957641602 and perplexity is 223.84771068759974
At time: 674.9618620872498 and batch: 950, loss is 5.3883046054840085 and perplexity is 218.83206419324156
At time: 675.9828586578369 and batch: 1000, loss is 5.392938156127929 and perplexity is 219.84838641709052
At time: 677.0050683021545 and batch: 1050, loss is 5.365333137512207 and perplexity is 213.86246842565072
At time: 678.027574300766 and batch: 1100, loss is 5.358659172058106 and perplexity is 212.43991003250915
At time: 679.0504155158997 and batch: 1150, loss is 5.368171243667603 and perplexity is 214.47029494379333
At time: 680.0729773044586 and batch: 1200, loss is 5.350956182479859 and perplexity is 210.80977413989817
At time: 681.0957553386688 and batch: 1250, loss is 5.369905157089233 and perplexity is 214.84249045088094
At time: 682.1176059246063 and batch: 1300, loss is 5.3521749210357665 and perplexity is 211.06685276359954
At time: 683.1397738456726 and batch: 1350, loss is 5.325035638809204 and perplexity is 205.4156811045994
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.22399658203125 and perplexity of 185.67476762340632
Finished 23 epochs...
Completing Train Step...
At time: 686.2425637245178 and batch: 50, loss is 5.393502073287964 and perplexity is 219.97239765754398
At time: 687.2919962406158 and batch: 100, loss is 5.412940711975097 and perplexity is 224.29019167615442
At time: 688.3146860599518 and batch: 150, loss is 5.376728019714355 and perplexity is 216.31334325672742
At time: 689.3370532989502 and batch: 200, loss is 5.366415758132934 and perplexity is 214.09412571982332
At time: 690.3595776557922 and batch: 250, loss is 5.3896276473999025 and perplexity is 219.12177979739403
At time: 691.382303237915 and batch: 300, loss is 5.40192626953125 and perplexity is 221.83331566745764
At time: 692.4046070575714 and batch: 350, loss is 5.400961513519287 and perplexity is 221.61940384546355
At time: 693.4294066429138 and batch: 400, loss is 5.427403249740601 and perplexity is 227.55756736432414
At time: 694.4581825733185 and batch: 450, loss is 5.394463357925415 and perplexity is 220.18395541139358
At time: 695.4833836555481 and batch: 500, loss is 5.432790613174438 and perplexity is 228.78681089957564
At time: 696.5085990428925 and batch: 550, loss is 5.406472454071045 and perplexity is 222.84410673802418
At time: 697.5334823131561 and batch: 600, loss is 5.355626516342163 and perplexity is 211.7966288432638
At time: 698.5845265388489 and batch: 650, loss is 5.381873092651367 and perplexity is 217.42915920077232
At time: 699.6096577644348 and batch: 700, loss is 5.393096590042115 and perplexity is 219.88322061686435
At time: 700.6408636569977 and batch: 750, loss is 5.370376472473144 and perplexity is 214.94377288785864
At time: 701.66357421875 and batch: 800, loss is 5.34000973701477 and perplexity is 208.5147405903207
At time: 702.6869542598724 and batch: 850, loss is 5.3306850242614745 and perplexity is 206.57943762451697
At time: 703.709056854248 and batch: 900, loss is 5.377479438781738 and perplexity is 216.47594631124673
At time: 704.7319848537445 and batch: 950, loss is 5.350530776977539 and perplexity is 210.7201135744374
At time: 705.7550177574158 and batch: 1000, loss is 5.357951240539551 and perplexity is 212.2895703457783
At time: 706.777378320694 and batch: 1050, loss is 5.326691808700562 and perplexity is 205.75616624364906
At time: 707.7995073795319 and batch: 1100, loss is 5.317879896163941 and perplexity is 203.95102595273661
At time: 708.8224618434906 and batch: 1150, loss is 5.326345834732056 and perplexity is 205.68499227914856
At time: 709.8453814983368 and batch: 1200, loss is 5.31164665222168 and perplexity is 202.68370332455237
At time: 710.868114233017 and batch: 1250, loss is 5.329553956985474 and perplexity is 206.34591447281852
At time: 711.8980021476746 and batch: 1300, loss is 5.315638694763184 and perplexity is 203.49444246657748
At time: 712.9270107746124 and batch: 1350, loss is 5.286665964126587 and perplexity is 197.68324246216324
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.193378092447917 and perplexity of 180.0758394526303
Finished 24 epochs...
Completing Train Step...
At time: 716.0510711669922 and batch: 50, loss is 5.36029200553894 and perplexity is 212.7870723822976
At time: 717.083003282547 and batch: 100, loss is 5.377741661071777 and perplexity is 216.53271857277775
At time: 718.1051018238068 and batch: 150, loss is 5.342775964736939 and perplexity is 209.09233836139015
At time: 719.12735247612 and batch: 200, loss is 5.332155742645264 and perplexity is 206.88348132767183
At time: 720.1511397361755 and batch: 250, loss is 5.350652389526367 and perplexity is 210.74574134283597
At time: 721.1755058765411 and batch: 300, loss is 5.362289791107178 and perplexity is 213.21260023978803
At time: 722.2008540630341 and batch: 350, loss is 5.3627955341339115 and perplexity is 213.32045829750243
At time: 723.228654384613 and batch: 400, loss is 5.389450922012329 and perplexity is 219.08305883752257
At time: 724.2774646282196 and batch: 450, loss is 5.353342523574829 and perplexity is 211.31343888607552
At time: 725.3065223693848 and batch: 500, loss is 5.395260801315308 and perplexity is 220.3596096790558
At time: 726.3291122913361 and batch: 550, loss is 5.365194149017334 and perplexity is 213.83274606863523
At time: 727.3513603210449 and batch: 600, loss is 5.3174957752227785 and perplexity is 203.8726991371448
At time: 728.3750395774841 and batch: 650, loss is 5.344223833084106 and perplexity is 209.39529580806288
At time: 729.3972055912018 and batch: 700, loss is 5.356455821990966 and perplexity is 211.9723458354374
At time: 730.4281384944916 and batch: 750, loss is 5.333572607040406 and perplexity is 207.17681492420007
At time: 731.4511008262634 and batch: 800, loss is 5.306994428634644 and perplexity is 201.74296338222925
At time: 732.4828457832336 and batch: 850, loss is 5.295828714370727 and perplexity is 199.5028883900505
At time: 733.5151925086975 and batch: 900, loss is 5.343989877700806 and perplexity is 209.34631238156243
At time: 734.5465295314789 and batch: 950, loss is 5.319295263290405 and perplexity is 204.23989591057625
At time: 735.5698509216309 and batch: 1000, loss is 5.329120435714722 and perplexity is 206.25647851735704
At time: 736.5963640213013 and batch: 1050, loss is 5.296460723876953 and perplexity is 199.62901596474723
At time: 737.6261835098267 and batch: 1100, loss is 5.289116773605347 and perplexity is 198.16832060083118
At time: 738.6503658294678 and batch: 1150, loss is 5.299457340240479 and perplexity is 200.2281247418858
At time: 739.6765341758728 and batch: 1200, loss is 5.286732292175293 and perplexity is 197.69635484075204
At time: 740.7041854858398 and batch: 1250, loss is 5.30390778541565 and perplexity is 201.1212148838543
At time: 741.7335884571075 and batch: 1300, loss is 5.292870035171509 and perplexity is 198.91349568590508
At time: 742.7567753791809 and batch: 1350, loss is 5.2634814262390135 and perplexity is 193.15276923587797
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.174722900390625 and perplexity of 176.74763079064337
Finished 25 epochs...
Completing Train Step...
At time: 745.9127304553986 and batch: 50, loss is 5.337365083694458 and perplexity is 207.96401994286592
At time: 746.94286942482 and batch: 100, loss is 5.35806640625 and perplexity is 212.31402023283536
At time: 747.9684171676636 and batch: 150, loss is 5.321939706802368 and perplexity is 204.78071154122992
At time: 748.9979560375214 and batch: 200, loss is 5.310293264389038 and perplexity is 202.40957920656297
At time: 750.0511138439178 and batch: 250, loss is 5.330979518890381 and perplexity is 206.64028311823563
At time: 751.0760588645935 and batch: 300, loss is 5.3429833602905275 and perplexity is 209.1357076798022
At time: 752.1126775741577 and batch: 350, loss is 5.339716320037842 and perplexity is 208.45356780049804
At time: 753.1404311656952 and batch: 400, loss is 5.368944835662842 and perplexity is 214.63627163802215
At time: 754.171952009201 and batch: 450, loss is 5.331583757400512 and perplexity is 206.7651808652544
At time: 755.202978849411 and batch: 500, loss is 5.37536114692688 and perplexity is 216.01787241579137
At time: 756.2399253845215 and batch: 550, loss is 5.346598796844482 and perplexity is 209.89319305713124
At time: 757.2687654495239 and batch: 600, loss is 5.301675291061401 and perplexity is 200.67271373153037
At time: 758.2938690185547 and batch: 650, loss is 5.32617748260498 and perplexity is 205.65036768783446
At time: 759.3240797519684 and batch: 700, loss is 5.338276672363281 and perplexity is 208.1536840216472
At time: 760.3473813533783 and batch: 750, loss is 5.316482181549072 and perplexity is 203.66615975024868
At time: 761.3705446720123 and batch: 800, loss is 5.2905510139465335 and perplexity is 198.45274551867146
At time: 762.3925786018372 and batch: 850, loss is 5.279119091033936 and perplexity is 196.1969675371395
At time: 763.4158248901367 and batch: 900, loss is 5.326335878372192 and perplexity is 205.68294441554153
At time: 764.4376041889191 and batch: 950, loss is 5.303605480194092 and perplexity is 201.0604240795806
At time: 765.4602572917938 and batch: 1000, loss is 5.31419939994812 and perplexity is 203.20176464600112
At time: 766.4925529956818 and batch: 1050, loss is 5.28208101272583 and perplexity is 196.77894905754047
At time: 767.5149478912354 and batch: 1100, loss is 5.273708333969116 and perplexity is 195.13826019597224
At time: 768.5385909080505 and batch: 1150, loss is 5.285978031158447 and perplexity is 197.54729640867228
At time: 769.5704419612885 and batch: 1200, loss is 5.272806911468506 and perplexity is 194.9624374347038
At time: 770.6009950637817 and batch: 1250, loss is 5.290911836624145 and perplexity is 198.52436468982248
At time: 771.6277890205383 and batch: 1300, loss is 5.278524427413941 and perplexity is 196.08033102137532
At time: 772.658186674118 and batch: 1350, loss is 5.250715427398681 and perplexity is 190.70265356935502
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.174864095052083 and perplexity of 176.77258837443367
Annealing...
Finished 26 epochs...
Completing Train Step...
At time: 775.7620983123779 and batch: 50, loss is 5.3234288692474365 and perplexity is 205.08589046042704
At time: 776.813658952713 and batch: 100, loss is 5.33838737487793 and perplexity is 208.17672843341538
At time: 777.8377330303192 and batch: 150, loss is 5.300584058761597 and perplexity is 200.45385262049206
At time: 778.8622844219208 and batch: 200, loss is 5.292078695297241 and perplexity is 198.75614977049835
At time: 779.8868939876556 and batch: 250, loss is 5.306823186874389 and perplexity is 201.70841951982104
At time: 780.9119236469269 and batch: 300, loss is 5.318352146148682 and perplexity is 204.04736456779494
At time: 781.9358999729156 and batch: 350, loss is 5.31125057220459 and perplexity is 202.60344025622373
At time: 782.9621274471283 and batch: 400, loss is 5.340452461242676 and perplexity is 208.6070755558105
At time: 783.9903342723846 and batch: 450, loss is 5.300763082504273 and perplexity is 200.4897418318365
At time: 785.0151438713074 and batch: 500, loss is 5.335054759979248 and perplexity is 207.48411032243376
At time: 786.0466017723083 and batch: 550, loss is 5.309832811355591 and perplexity is 202.31640055566098
At time: 787.0736606121063 and batch: 600, loss is 5.26489520072937 and perplexity is 193.42603681761713
At time: 788.0990908145905 and batch: 650, loss is 5.279638776779175 and perplexity is 196.2989548027964
At time: 789.1246218681335 and batch: 700, loss is 5.28570897102356 and perplexity is 197.4941514563685
At time: 790.1514208316803 and batch: 750, loss is 5.261820564270019 and perplexity is 192.832235402157
At time: 791.176421880722 and batch: 800, loss is 5.236563100814819 and perplexity is 188.0227753206059
At time: 792.2096645832062 and batch: 850, loss is 5.209629421234131 and perplexity is 183.02621999406924
At time: 793.2402966022491 and batch: 900, loss is 5.2509490013122555 and perplexity is 190.74720193694392
At time: 794.2625660896301 and batch: 950, loss is 5.220675134658814 and perplexity is 185.0590817045656
At time: 795.2852048873901 and batch: 1000, loss is 5.23255955696106 and perplexity is 187.2715227338879
At time: 796.3078458309174 and batch: 1050, loss is 5.197908964157104 and perplexity is 180.8935911441621
At time: 797.3306746482849 and batch: 1100, loss is 5.183636312484741 and perplexity is 178.3300973718301
At time: 798.3538572788239 and batch: 1150, loss is 5.189313039779663 and perplexity is 179.3453075123639
At time: 799.3770115375519 and batch: 1200, loss is 5.166933517456055 and perplexity is 175.3762239522588
At time: 800.3999333381653 and batch: 1250, loss is 5.181486330032349 and perplexity is 177.9471026552376
At time: 801.4251446723938 and batch: 1300, loss is 5.174422931671143 and perplexity is 176.69461998135333
At time: 802.4483692646027 and batch: 1350, loss is 5.159196233749389 and perplexity is 174.02452433718813
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.104637858072917 and perplexity of 164.78438439035014
Finished 27 epochs...
Completing Train Step...
At time: 805.5413117408752 and batch: 50, loss is 5.282707138061523 and perplexity is 196.90219592304263
At time: 806.6079657077789 and batch: 100, loss is 5.300676136016846 and perplexity is 200.4723107108175
At time: 807.6303513050079 and batch: 150, loss is 5.263363208770752 and perplexity is 193.12993655414868
At time: 808.6533346176147 and batch: 200, loss is 5.256525897979737 and perplexity is 191.81395118209767
At time: 809.6753573417664 and batch: 250, loss is 5.27258002281189 and perplexity is 194.91820768698733
At time: 810.6981449127197 and batch: 300, loss is 5.287162990570068 and perplexity is 197.78152068251407
At time: 811.7216093540192 and batch: 350, loss is 5.281818485260009 and perplexity is 196.72729595919273
At time: 812.7438967227936 and batch: 400, loss is 5.311530694961548 and perplexity is 202.6602020402401
At time: 813.7665939331055 and batch: 450, loss is 5.273587064743042 and perplexity is 195.11459736499637
At time: 814.7903759479523 and batch: 500, loss is 5.311380777359009 and perplexity is 202.62982198592948
At time: 815.815269947052 and batch: 550, loss is 5.287076606750488 and perplexity is 197.764436297233
At time: 816.8398013114929 and batch: 600, loss is 5.243928308486939 and perplexity is 189.4127144197419
At time: 817.8646216392517 and batch: 650, loss is 5.258042736053467 and perplexity is 192.10512266048823
At time: 818.8898589611053 and batch: 700, loss is 5.267515411376953 and perplexity is 193.93351834271124
At time: 819.9160940647125 and batch: 750, loss is 5.245868711471558 and perplexity is 189.7806082318206
At time: 820.9427585601807 and batch: 800, loss is 5.219694366455078 and perplexity is 184.87767061707223
At time: 821.9676079750061 and batch: 850, loss is 5.196626787185669 and perplexity is 180.66180217630983
At time: 822.9928848743439 and batch: 900, loss is 5.2400213146209715 and perplexity is 188.67412388024533
At time: 824.0230407714844 and batch: 950, loss is 5.212211322784424 and perplexity is 183.49938624670455
At time: 825.0497751235962 and batch: 1000, loss is 5.225915060043335 and perplexity is 186.03132249447086
At time: 826.0823006629944 and batch: 1050, loss is 5.194751586914062 and perplexity is 180.3233425547663
At time: 827.1071543693542 and batch: 1100, loss is 5.184585218429565 and perplexity is 178.49939617298338
At time: 828.1941871643066 and batch: 1150, loss is 5.192336254119873 and perplexity is 179.88832723680144
At time: 829.2182674407959 and batch: 1200, loss is 5.172419872283935 and perplexity is 176.34104439879488
At time: 830.2439773082733 and batch: 1250, loss is 5.189816970825195 and perplexity is 179.43570795657186
At time: 831.2743937969208 and batch: 1300, loss is 5.182150936126709 and perplexity is 178.06540669257348
At time: 832.3037829399109 and batch: 1350, loss is 5.161920003890991 and perplexity is 174.49917326432328
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.099451090494791 and perplexity of 163.93189882143704
Finished 28 epochs...
Completing Train Step...
At time: 835.4579925537109 and batch: 50, loss is 5.272181482315063 and perplexity is 194.8405403654697
At time: 836.4897298812866 and batch: 100, loss is 5.289329662322998 and perplexity is 198.2105128914549
At time: 837.5158681869507 and batch: 150, loss is 5.251391954421997 and perplexity is 190.83171271899153
At time: 838.5407543182373 and batch: 200, loss is 5.243986196517945 and perplexity is 189.42367946619657
At time: 839.5663816928864 and batch: 250, loss is 5.2616258716583255 and perplexity is 192.79469604506411
At time: 840.5908915996552 and batch: 300, loss is 5.276161556243896 and perplexity is 195.61756540326877
At time: 841.6159522533417 and batch: 350, loss is 5.270780582427978 and perplexity is 194.56777937450107
At time: 842.6408722400665 and batch: 400, loss is 5.301887273788452 and perplexity is 200.71525738973293
At time: 843.66575050354 and batch: 450, loss is 5.263734645843506 and perplexity is 193.2016854967273
At time: 844.6906218528748 and batch: 500, loss is 5.302479906082153 and perplexity is 200.83424298697187
At time: 845.7161991596222 and batch: 550, loss is 5.279043264389038 and perplexity is 196.1820911433728
At time: 846.7412650585175 and batch: 600, loss is 5.236371860504151 and perplexity is 187.98682122468668
At time: 847.7660229206085 and batch: 650, loss is 5.2508023166656494 and perplexity is 190.71922430303155
At time: 848.7911241054535 and batch: 700, loss is 5.261708040237426 and perplexity is 192.81053836215776
At time: 849.8233234882355 and batch: 750, loss is 5.239476890563965 and perplexity is 188.57143310447105
At time: 850.8486287593842 and batch: 800, loss is 5.213943910598755 and perplexity is 183.81759062616754
At time: 851.8732535839081 and batch: 850, loss is 5.1913474178314205 and perplexity is 179.71053504913127
At time: 852.8997535705566 and batch: 900, loss is 5.234911069869995 and perplexity is 187.7124123126783
At time: 853.9701285362244 and batch: 950, loss is 5.2092359828948975 and perplexity is 182.95422462583642
At time: 854.9949111938477 and batch: 1000, loss is 5.22379506111145 and perplexity is 185.6373540433873
At time: 856.019597530365 and batch: 1050, loss is 5.1933596897125245 and perplexity is 180.07252559509843
At time: 857.1954007148743 and batch: 1100, loss is 5.185499382019043 and perplexity is 178.66264842997404
At time: 858.2198746204376 and batch: 1150, loss is 5.1932500553131105 and perplexity is 180.05278453407328
At time: 859.2434892654419 and batch: 1200, loss is 5.174232025146484 and perplexity is 176.6608910451662
At time: 860.2684662342072 and batch: 1250, loss is 5.191834402084351 and perplexity is 179.79807256275123
At time: 861.2941148281097 and batch: 1300, loss is 5.184396724700928 and perplexity is 178.4657533270716
At time: 862.3182301521301 and batch: 1350, loss is 5.160976448059082 and perplexity is 174.33460120539928
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.096506754557292 and perplexity of 163.44993811572868
Finished 29 epochs...
Completing Train Step...
At time: 865.4620385169983 and batch: 50, loss is 5.26433554649353 and perplexity is 193.31781540290174
At time: 866.5135519504547 and batch: 100, loss is 5.280842361450195 and perplexity is 196.53535945370308
At time: 867.5379333496094 and batch: 150, loss is 5.243769302368164 and perplexity is 189.3825990335042
At time: 868.56312084198 and batch: 200, loss is 5.235541076660156 and perplexity is 187.83070966718824
At time: 869.5868589878082 and batch: 250, loss is 5.2528335475921635 and perplexity is 191.1070128003797
At time: 870.6113920211792 and batch: 300, loss is 5.269129114151001 and perplexity is 194.2467220401132
At time: 871.6356685161591 and batch: 350, loss is 5.262538938522339 and perplexity is 192.9708108836567
At time: 872.6674783229828 and batch: 400, loss is 5.294551658630371 and perplexity is 199.24827469375902
At time: 873.7004089355469 and batch: 450, loss is 5.256540832519531 and perplexity is 191.81681585657591
At time: 874.726765871048 and batch: 500, loss is 5.295403995513916 and perplexity is 199.41817374259048
At time: 875.7520155906677 and batch: 550, loss is 5.271819286346435 and perplexity is 194.76998268584893
At time: 876.7773153781891 and batch: 600, loss is 5.228423376083374 and perplexity is 186.4985335561727
At time: 877.8020915985107 and batch: 650, loss is 5.244153032302856 and perplexity is 189.4552847508141
At time: 878.826827287674 and batch: 700, loss is 5.255260229110718 and perplexity is 191.57133180572683
At time: 879.8518762588501 and batch: 750, loss is 5.232780141830444 and perplexity is 187.31283655470398
At time: 880.8774931430817 and batch: 800, loss is 5.207075834274292 and perplexity is 182.55944285703586
At time: 881.9090664386749 and batch: 850, loss is 5.184210748672485 and perplexity is 178.43256606116833
At time: 882.9341344833374 and batch: 900, loss is 5.22831561088562 and perplexity is 186.47843658771956
At time: 883.9608204364777 and batch: 950, loss is 5.202430152893067 and perplexity is 181.71329683661267
At time: 884.9859755039215 and batch: 1000, loss is 5.218595275878906 and perplexity is 184.67458493677495
At time: 886.0106339454651 and batch: 1050, loss is 5.188706655502319 and perplexity is 179.2365883038136
At time: 887.0349860191345 and batch: 1100, loss is 5.180994958877563 and perplexity is 177.85968606067053
At time: 888.0606327056885 and batch: 1150, loss is 5.189043140411377 and perplexity is 179.29690885883792
At time: 889.0931262969971 and batch: 1200, loss is 5.170641212463379 and perplexity is 176.02767244207806
At time: 890.1216402053833 and batch: 1250, loss is 5.188160305023193 and perplexity is 179.1386890540032
At time: 891.1505255699158 and batch: 1300, loss is 5.180121240615844 and perplexity is 177.70435467275232
At time: 892.1807990074158 and batch: 1350, loss is 5.154914922714234 and perplexity is 173.28106384916367
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.090260416666666 and perplexity of 162.43215658692722
Finished 30 epochs...
Completing Train Step...
At time: 895.3290390968323 and batch: 50, loss is 5.255873498916626 and perplexity is 191.68885275154136
At time: 896.353816986084 and batch: 100, loss is 5.270835266113282 and perplexity is 194.57841934863245
At time: 897.3788340091705 and batch: 150, loss is 5.234209451675415 and perplexity is 187.58075606046302
At time: 898.4047889709473 and batch: 200, loss is 5.225827932357788 and perplexity is 186.01511472198575
At time: 899.4290993213654 and batch: 250, loss is 5.244032068252563 and perplexity is 189.43236885824876
At time: 900.4808423519135 and batch: 300, loss is 5.258885316848755 and perplexity is 192.2670549584604
At time: 901.5052578449249 and batch: 350, loss is 5.253956699371338 and perplexity is 191.3217755648333
At time: 902.5357983112335 and batch: 400, loss is 5.2867886924743654 and perplexity is 197.70750528873202
At time: 903.5622067451477 and batch: 450, loss is 5.248864021301269 and perplexity is 190.34991214831072
At time: 904.5921320915222 and batch: 500, loss is 5.2878491497039795 and perplexity is 197.91727684928983
At time: 905.6219127178192 and batch: 550, loss is 5.265419712066651 and perplexity is 193.52751757843143
At time: 906.6546025276184 and batch: 600, loss is 5.2215640830993655 and perplexity is 185.22366282788522
At time: 907.6857395172119 and batch: 650, loss is 5.238004302978515 and perplexity is 188.29394951270115
At time: 908.7130267620087 and batch: 700, loss is 5.249493837356567 and perplexity is 190.4698353399179
At time: 909.7380690574646 and batch: 750, loss is 5.227446727752685 and perplexity is 186.31647899081386
At time: 910.7629499435425 and batch: 800, loss is 5.202087078094483 and perplexity is 181.6509662765339
At time: 911.7877531051636 and batch: 850, loss is 5.178985548019409 and perplexity is 177.5026517107562
At time: 912.8128728866577 and batch: 900, loss is 5.223279857635498 and perplexity is 185.54173766637757
At time: 913.8387267589569 and batch: 950, loss is 5.197702569961548 and perplexity is 180.8562596095751
At time: 914.865531206131 and batch: 1000, loss is 5.214967365264893 and perplexity is 184.0058159005999
At time: 915.8915300369263 and batch: 1050, loss is 5.185243787765503 and perplexity is 178.61698911909045
At time: 916.9185209274292 and batch: 1100, loss is 5.1785530090332035 and perplexity is 177.4258914958259
At time: 917.9494240283966 and batch: 1150, loss is 5.186819620132447 and perplexity is 178.89868144347875
At time: 918.9733965396881 and batch: 1200, loss is 5.168542699813843 and perplexity is 175.65866346521156
At time: 920.0018639564514 and batch: 1250, loss is 5.18562985420227 and perplexity is 178.68596045652825
At time: 921.0352206230164 and batch: 1300, loss is 5.177732076644897 and perplexity is 177.28029660493036
At time: 922.0626420974731 and batch: 1350, loss is 5.151658172607422 and perplexity is 172.7176486751633
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.087052001953125 and perplexity of 161.9118420046021
Finished 31 epochs...
Completing Train Step...
At time: 925.2011168003082 and batch: 50, loss is 5.2503648948669435 and perplexity is 190.63581780013027
At time: 926.2543771266937 and batch: 100, loss is 5.264364280700684 and perplexity is 193.3233703168636
At time: 927.2866415977478 and batch: 150, loss is 5.227833604812622 and perplexity is 186.3885745075751
At time: 928.3194215297699 and batch: 200, loss is 5.218826122283936 and perplexity is 184.71722132184675
At time: 929.351110458374 and batch: 250, loss is 5.237295885086059 and perplexity is 188.16060594688565
At time: 930.382166147232 and batch: 300, loss is 5.252850227355957 and perplexity is 191.11020044679694
At time: 931.4115784168243 and batch: 350, loss is 5.248323335647583 and perplexity is 190.24702050015725
At time: 932.4361991882324 and batch: 400, loss is 5.282152719497681 and perplexity is 196.7930599466627
At time: 933.4612009525299 and batch: 450, loss is 5.244582796096802 and perplexity is 189.53672327118198
At time: 934.4917652606964 and batch: 500, loss is 5.283403224945069 and perplexity is 197.03930467323104
At time: 935.5165798664093 and batch: 550, loss is 5.261155347824097 and perplexity is 192.70400288378232
At time: 936.5459413528442 and batch: 600, loss is 5.217442760467529 and perplexity is 184.46186723530622
At time: 937.5707705020905 and batch: 650, loss is 5.23403431892395 and perplexity is 187.54790740305404
At time: 938.5986764431 and batch: 700, loss is 5.245457944869995 and perplexity is 189.7026687049078
At time: 939.6276392936707 and batch: 750, loss is 5.223294687271118 and perplexity is 185.54448920314155
At time: 940.6528842449188 and batch: 800, loss is 5.198793745040893 and perplexity is 181.0537131616106
At time: 941.6773955821991 and batch: 850, loss is 5.175443391799927 and perplexity is 176.8750218268053
At time: 942.7078981399536 and batch: 900, loss is 5.219231481552124 and perplexity is 184.7921133375644
At time: 943.7376582622528 and batch: 950, loss is 5.1949733638763425 and perplexity is 180.36333855283783
At time: 944.7621276378632 and batch: 1000, loss is 5.21207290649414 and perplexity is 183.47398870014857
At time: 945.7880575656891 and batch: 1050, loss is 5.182707395553589 and perplexity is 178.16452044056098
At time: 946.8152136802673 and batch: 1100, loss is 5.176525297164917 and perplexity is 177.0664874170009
At time: 947.840589761734 and batch: 1150, loss is 5.184733572006226 and perplexity is 178.52587916121186
At time: 948.866185426712 and batch: 1200, loss is 5.166605882644653 and perplexity is 175.31877400801454
At time: 949.894718170166 and batch: 1250, loss is 5.183884582519531 and perplexity is 178.37437688771976
At time: 950.9231712818146 and batch: 1300, loss is 5.175465154647827 and perplexity is 176.87887117288878
At time: 951.9515299797058 and batch: 1350, loss is 5.148878030776977 and perplexity is 172.23813598072908
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0845853678385415 and perplexity of 161.51295688562385
Finished 32 epochs...
Completing Train Step...
At time: 955.0948753356934 and batch: 50, loss is 5.245377798080444 and perplexity is 189.6874652543039
At time: 956.120283126831 and batch: 100, loss is 5.259111871719361 and perplexity is 192.31061893084703
At time: 957.1448471546173 and batch: 150, loss is 5.2227638244628904 and perplexity is 185.44601667456607
At time: 958.1684150695801 and batch: 200, loss is 5.214129552841187 and perplexity is 183.85171810354248
At time: 959.1915776729584 and batch: 250, loss is 5.2325136089324955 and perplexity is 187.26291817429487
At time: 960.2141718864441 and batch: 300, loss is 5.248061561584473 and perplexity is 190.19722528243898
At time: 961.2395951747894 and batch: 350, loss is 5.244302835464477 and perplexity is 189.48366787734355
At time: 962.2620372772217 and batch: 400, loss is 5.277921180725098 and perplexity is 195.9620818812266
At time: 963.285653591156 and batch: 450, loss is 5.240166101455689 and perplexity is 188.70144338713973
At time: 964.308944940567 and batch: 500, loss is 5.279832096099853 and perplexity is 196.3369068517028
At time: 965.3322298526764 and batch: 550, loss is 5.257918577194214 and perplexity is 192.08127258823168
At time: 966.3551650047302 and batch: 600, loss is 5.213220281600952 and perplexity is 183.68462300270048
At time: 967.3788461685181 and batch: 650, loss is 5.230774059295654 and perplexity is 186.9374482006517
At time: 968.4022831916809 and batch: 700, loss is 5.242626552581787 and perplexity is 189.16630571702348
At time: 969.4258308410645 and batch: 750, loss is 5.219905157089233 and perplexity is 184.91664520609748
At time: 970.449254989624 and batch: 800, loss is 5.195013523101807 and perplexity is 180.3705819502599
At time: 971.472512960434 and batch: 850, loss is 5.171979322433471 and perplexity is 176.26337448804432
At time: 972.4955568313599 and batch: 900, loss is 5.216226186752319 and perplexity is 184.23759222737056
At time: 973.5189113616943 and batch: 950, loss is 5.191093215942383 and perplexity is 179.66485809747144
At time: 974.5438883304596 and batch: 1000, loss is 5.2096161460876464 and perplexity is 183.0237903103156
At time: 975.5670435428619 and batch: 1050, loss is 5.180427112579346 and perplexity is 177.75871776628807
At time: 976.5920174121857 and batch: 1100, loss is 5.174928560256958 and perplexity is 176.7839844228798
At time: 977.6596739292145 and batch: 1150, loss is 5.182623701095581 and perplexity is 178.14960968156916
At time: 978.6880357265472 and batch: 1200, loss is 5.164649019241333 and perplexity is 174.97603457174455
At time: 979.7113859653473 and batch: 1250, loss is 5.181964588165283 and perplexity is 178.03222765855463
At time: 980.7355511188507 and batch: 1300, loss is 5.174051532745361 and perplexity is 176.62900797416955
At time: 981.7589952945709 and batch: 1350, loss is 5.146156616210938 and perplexity is 171.77004183665048
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.082482503255208 and perplexity of 161.17367386698828
Finished 33 epochs...
Completing Train Step...
At time: 984.8645603656769 and batch: 50, loss is 5.241384391784668 and perplexity is 188.93147662586586
At time: 985.8868527412415 and batch: 100, loss is 5.254826164245605 and perplexity is 191.4881954660145
At time: 986.9094169139862 and batch: 150, loss is 5.218280544281006 and perplexity is 184.61647115516766
At time: 987.932163476944 and batch: 200, loss is 5.209467754364014 and perplexity is 182.99663310960744
At time: 988.9542837142944 and batch: 250, loss is 5.228610525131225 and perplexity is 186.533439845391
At time: 989.9774026870728 and batch: 300, loss is 5.244233808517456 and perplexity is 189.47058884964744
At time: 991.0001308917999 and batch: 350, loss is 5.240531044006348 and perplexity is 188.77032114064957
At time: 992.022741317749 and batch: 400, loss is 5.274695901870728 and perplexity is 195.33106766768293
At time: 993.0456519126892 and batch: 450, loss is 5.237112560272217 and perplexity is 188.1261146004844
At time: 994.070131778717 and batch: 500, loss is 5.276569833755493 and perplexity is 195.69744796211282
At time: 995.0928893089294 and batch: 550, loss is 5.254980249404907 and perplexity is 191.5177032284131
At time: 996.115641117096 and batch: 600, loss is 5.210192594528198 and perplexity is 183.12932450341205
At time: 997.1383867263794 and batch: 650, loss is 5.227868213653564 and perplexity is 186.39502531173048
At time: 998.1610870361328 and batch: 700, loss is 5.239358406066895 and perplexity is 188.54909163664288
At time: 999.1931772232056 and batch: 750, loss is 5.217123146057129 and perplexity is 184.4029199850656
At time: 1000.2162764072418 and batch: 800, loss is 5.191796045303345 and perplexity is 179.79117621971832
At time: 1001.2383010387421 and batch: 850, loss is 5.1691058731079105 and perplexity is 175.757617594893
At time: 1002.2611508369446 and batch: 900, loss is 5.213447179794311 and perplexity is 183.72630544046376
At time: 1003.2845792770386 and batch: 950, loss is 5.188592157363892 and perplexity is 179.21606722294993
At time: 1004.332905292511 and batch: 1000, loss is 5.207165765762329 and perplexity is 182.57586143764982
At time: 1005.3553817272186 and batch: 1050, loss is 5.177938423156738 and perplexity is 177.31688155021104
At time: 1006.3839664459229 and batch: 1100, loss is 5.17271653175354 and perplexity is 176.3933653998723
At time: 1007.4063320159912 and batch: 1150, loss is 5.180320081710815 and perplexity is 177.7396931144673
At time: 1008.4297475814819 and batch: 1200, loss is 5.162431735992431 and perplexity is 174.58849294488215
At time: 1009.4542768001556 and batch: 1250, loss is 5.179887180328369 and perplexity is 177.66276600772932
At time: 1010.4856925010681 and batch: 1300, loss is 5.171708059310913 and perplexity is 176.21556721915573
At time: 1011.5133218765259 and batch: 1350, loss is 5.143587083816528 and perplexity is 171.32923971995413
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0807958984375 and perplexity of 160.90206668353386
Finished 34 epochs...
Completing Train Step...
At time: 1014.5908794403076 and batch: 50, loss is 5.237695016860962 and perplexity is 188.23572181307134
At time: 1015.6395959854126 and batch: 100, loss is 5.250612230300903 and perplexity is 190.6829746243905
At time: 1016.6624021530151 and batch: 150, loss is 5.214570207595825 and perplexity is 183.93275108974734
At time: 1017.6847820281982 and batch: 200, loss is 5.205334892272949 and perplexity is 182.24189395254137
At time: 1018.707855463028 and batch: 250, loss is 5.225159673690796 and perplexity is 185.8908500344829
At time: 1019.732613325119 and batch: 300, loss is 5.240476016998291 and perplexity is 188.7599339604576
At time: 1020.7578234672546 and batch: 350, loss is 5.2373488235473635 and perplexity is 188.17056714350548
At time: 1021.7890777587891 and batch: 400, loss is 5.271025514602661 and perplexity is 194.61544112053573
At time: 1022.8137850761414 and batch: 450, loss is 5.232928142547608 and perplexity is 187.3405610404193
At time: 1023.8387362957001 and batch: 500, loss is 5.273828716278076 and perplexity is 195.1617528043198
At time: 1024.8630499839783 and batch: 550, loss is 5.252087469100952 and perplexity is 190.96448514363055
At time: 1025.8929824829102 and batch: 600, loss is 5.206740474700927 and perplexity is 182.49823006488728
At time: 1026.9226441383362 and batch: 650, loss is 5.225092782974243 and perplexity is 185.87841607818615
At time: 1027.9558374881744 and batch: 700, loss is 5.236819190979004 and perplexity is 188.07093227000558
At time: 1028.9811069965363 and batch: 750, loss is 5.214510984420777 and perplexity is 183.92185833078747
At time: 1030.0505623817444 and batch: 800, loss is 5.189178295135498 and perplexity is 179.32114332075471
At time: 1031.077380180359 and batch: 850, loss is 5.166365766525269 and perplexity is 175.27668219800782
At time: 1032.1029362678528 and batch: 900, loss is 5.2111408901214595 and perplexity is 183.3030676017227
At time: 1033.1351535320282 and batch: 950, loss is 5.185766220092773 and perplexity is 178.71032878811317
At time: 1034.160923242569 and batch: 1000, loss is 5.205250005722046 and perplexity is 182.22642472330773
At time: 1035.1929700374603 and batch: 1050, loss is 5.175765619277954 and perplexity is 176.9320250025161
At time: 1036.219603061676 and batch: 1100, loss is 5.170773229598999 and perplexity is 176.05091264520246
At time: 1037.2454679012299 and batch: 1150, loss is 5.178510274887085 and perplexity is 177.41830951385938
At time: 1038.2704393863678 and batch: 1200, loss is 5.160466604232788 and perplexity is 174.24574043974647
At time: 1039.2957270145416 and batch: 1250, loss is 5.177845439910889 and perplexity is 177.3003948175274
At time: 1040.3211514949799 and batch: 1300, loss is 5.169361124038696 and perplexity is 175.80248561643526
At time: 1041.3513984680176 and batch: 1350, loss is 5.140775680541992 and perplexity is 170.84824059246034
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.079418538411458 and perplexity of 160.68059916404323
Finished 35 epochs...
Completing Train Step...
At time: 1044.4677460193634 and batch: 50, loss is 5.233813858032226 and perplexity is 187.50656498150806
At time: 1045.5246005058289 and batch: 100, loss is 5.247409343719482 and perplexity is 190.07321569926694
At time: 1046.5490982532501 and batch: 150, loss is 5.211190824508667 and perplexity is 183.3122209566083
At time: 1047.5743913650513 and batch: 200, loss is 5.201817178726197 and perplexity is 181.60194541113523
At time: 1048.6011822223663 and batch: 250, loss is 5.221698656082153 and perplexity is 185.24859060593988
At time: 1049.6328313350677 and batch: 300, loss is 5.237139549255371 and perplexity is 188.13119200153886
At time: 1050.6556344032288 and batch: 350, loss is 5.23436559677124 and perplexity is 187.61004816244247
At time: 1051.6776411533356 and batch: 400, loss is 5.268096647262573 and perplexity is 194.0462722281244
At time: 1052.6995975971222 and batch: 450, loss is 5.229931440353393 and perplexity is 186.77999751056285
At time: 1053.7289552688599 and batch: 500, loss is 5.271159591674805 and perplexity is 194.64153633842136
At time: 1054.7574751377106 and batch: 550, loss is 5.249233589172364 and perplexity is 190.42027236074247
At time: 1055.7815687656403 and batch: 600, loss is 5.204077987670899 and perplexity is 182.0129771707613
At time: 1056.8305118083954 and batch: 650, loss is 5.2226560592651365 and perplexity is 185.4260331246914
At time: 1057.8574306964874 and batch: 700, loss is 5.234573783874512 and perplexity is 187.64911022088148
At time: 1058.88436460495 and batch: 750, loss is 5.2120456123352055 and perplexity is 183.46898100028136
At time: 1059.906574010849 and batch: 800, loss is 5.1870299911499025 and perplexity is 178.93632050006002
At time: 1060.928474187851 and batch: 850, loss is 5.164698095321655 and perplexity is 174.98462192038664
At time: 1061.9510715007782 and batch: 900, loss is 5.208868236541748 and perplexity is 182.8869562465456
At time: 1062.973834991455 and batch: 950, loss is 5.1833337306976315 and perplexity is 178.2761460950204
At time: 1063.9963598251343 and batch: 1000, loss is 5.203258895874024 and perplexity is 181.86395287485695
At time: 1065.0196285247803 and batch: 1050, loss is 5.173763990402222 and perplexity is 176.57822695654656
At time: 1066.0435991287231 and batch: 1100, loss is 5.168964052200318 and perplexity is 175.7326932574872
At time: 1067.0715668201447 and batch: 1150, loss is 5.17661958694458 and perplexity is 177.0831837642201
At time: 1068.1014852523804 and batch: 1200, loss is 5.1584095287322995 and perplexity is 173.8876722089815
At time: 1069.1258845329285 and batch: 1250, loss is 5.175815515518188 and perplexity is 176.9408534655924
At time: 1070.1511554718018 and batch: 1300, loss is 5.166947679519653 and perplexity is 175.3787076590832
At time: 1071.1791348457336 and batch: 1350, loss is 5.138155212402344 and perplexity is 170.40112430412378
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.07805419921875 and perplexity of 160.4615258042636
Finished 36 epochs...
Completing Train Step...
At time: 1074.3221189975739 and batch: 50, loss is 5.231022787094116 and perplexity is 186.98395052356327
At time: 1075.3471410274506 and batch: 100, loss is 5.244128170013428 and perplexity is 189.45057451724475
At time: 1076.3764114379883 and batch: 150, loss is 5.207546892166138 and perplexity is 182.64545918106828
At time: 1077.4018692970276 and batch: 200, loss is 5.19897720336914 and perplexity is 181.08693202019515
At time: 1078.4264545440674 and batch: 250, loss is 5.218305940628052 and perplexity is 184.62115979867644
At time: 1079.456476688385 and batch: 300, loss is 5.23388900756836 and perplexity is 187.52065654236893
At time: 1080.484840631485 and batch: 350, loss is 5.231686086654663 and perplexity is 187.10801803818995
At time: 1081.5092344284058 and batch: 400, loss is 5.264990911483765 and perplexity is 193.44455065549312
At time: 1082.562703371048 and batch: 450, loss is 5.22677565574646 and perplexity is 186.1914891607433
At time: 1083.5916616916656 and batch: 500, loss is 5.268185720443726 and perplexity is 194.06355731669007
At time: 1084.6264474391937 and batch: 550, loss is 5.2470025539398195 and perplexity is 189.99591158206124
At time: 1085.6522281169891 and batch: 600, loss is 5.201712770462036 and perplexity is 181.5829856570414
At time: 1086.6774349212646 and batch: 650, loss is 5.22002010345459 and perplexity is 184.9379019240257
At time: 1087.7019901275635 and batch: 700, loss is 5.232153911590576 and perplexity is 187.19557231317717
At time: 1088.7270991802216 and batch: 750, loss is 5.2096959400177 and perplexity is 183.03839508051604
At time: 1089.750158548355 and batch: 800, loss is 5.18478084564209 and perplexity is 178.53431892810323
At time: 1090.774908542633 and batch: 850, loss is 5.16232346534729 and perplexity is 174.56959115938955
At time: 1091.7997844219208 and batch: 900, loss is 5.206899261474609 and perplexity is 182.52721067084946
At time: 1092.8247616291046 and batch: 950, loss is 5.180929384231567 and perplexity is 177.8480233571132
At time: 1093.8491325378418 and batch: 1000, loss is 5.201087694168091 and perplexity is 181.46951790401923
At time: 1094.8740890026093 and batch: 1050, loss is 5.171711196899414 and perplexity is 176.21612011196052
At time: 1095.8993685245514 and batch: 1100, loss is 5.167208223342896 and perplexity is 175.42440745123278
At time: 1096.924129486084 and batch: 1150, loss is 5.174859094619751 and perplexity is 176.77170443727735
At time: 1097.9491214752197 and batch: 1200, loss is 5.156542158126831 and perplexity is 173.56326247211848
At time: 1098.974163532257 and batch: 1250, loss is 5.173313732147217 and perplexity is 176.49873904859152
At time: 1099.999177455902 and batch: 1300, loss is 5.164505920410156 and perplexity is 174.9509974971442
At time: 1101.0291349887848 and batch: 1350, loss is 5.135608711242676 and perplexity is 169.9677496721669
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.077099609375 and perplexity of 160.30842394778293
Finished 37 epochs...
Completing Train Step...
At time: 1104.1809873580933 and batch: 50, loss is 5.228235311508179 and perplexity is 186.4634630865449
At time: 1105.207180261612 and batch: 100, loss is 5.241155099868775 and perplexity is 188.88816113175386
At time: 1106.2326498031616 and batch: 150, loss is 5.204179344177246 and perplexity is 182.03142630519127
At time: 1107.2577688694 and batch: 200, loss is 5.195880117416382 and perplexity is 180.5269578185275
At time: 1108.310608625412 and batch: 250, loss is 5.215447797775268 and perplexity is 184.09423951574564
At time: 1109.3360242843628 and batch: 300, loss is 5.23093282699585 and perplexity is 186.96713018559086
At time: 1110.3612596988678 and batch: 350, loss is 5.228763818740845 and perplexity is 186.5620364214798
At time: 1111.3863804340363 and batch: 400, loss is 5.262086725234985 and perplexity is 192.88356664689192
At time: 1112.4116928577423 and batch: 450, loss is 5.224162569046021 and perplexity is 185.70558978177058
At time: 1113.4387137889862 and batch: 500, loss is 5.265858488082886 and perplexity is 193.61245144373527
At time: 1114.4705386161804 and batch: 550, loss is 5.2449612712860105 and perplexity is 189.6084717950456
At time: 1115.4969120025635 and batch: 600, loss is 5.199217453002929 and perplexity is 181.13044331587412
At time: 1116.5224328041077 and batch: 650, loss is 5.217735013961792 and perplexity is 184.51578473896964
At time: 1117.5538699626923 and batch: 700, loss is 5.230134572982788 and perplexity is 186.81794247637535
At time: 1118.5813806056976 and batch: 750, loss is 5.207553071975708 and perplexity is 182.64658789871245
At time: 1119.6068751811981 and batch: 800, loss is 5.182521839141845 and perplexity is 178.13146393846583
At time: 1120.6321532726288 and batch: 850, loss is 5.160212116241455 and perplexity is 174.20140263322264
At time: 1121.6579911708832 and batch: 900, loss is 5.20427188873291 and perplexity is 182.04827310218323
At time: 1122.6832282543182 and batch: 950, loss is 5.178642730712891 and perplexity is 177.44181115898974
At time: 1123.709929227829 and batch: 1000, loss is 5.19893445968628 and perplexity is 181.07919186322525
At time: 1124.7348341941833 and batch: 1050, loss is 5.169745292663574 and perplexity is 175.8700363901978
At time: 1125.7606551647186 and batch: 1100, loss is 5.165393486022949 and perplexity is 175.10634691764992
At time: 1126.7855868339539 and batch: 1150, loss is 5.1728162097930905 and perplexity is 176.41094882105094
At time: 1127.811679840088 and batch: 1200, loss is 5.154524536132812 and perplexity is 173.21343044946732
At time: 1128.8366796970367 and batch: 1250, loss is 5.170781478881836 and perplexity is 176.05236494496484
At time: 1129.8618667125702 and batch: 1300, loss is 5.161789388656616 and perplexity is 174.47638250235187
At time: 1130.885056734085 and batch: 1350, loss is 5.133079156875611 and perplexity is 169.53835033217572
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.076103515625 and perplexity of 160.1488212314469
Finished 38 epochs...
Completing Train Step...
At time: 1134.0199177265167 and batch: 50, loss is 5.22564621925354 and perplexity is 185.98131640894374
At time: 1135.0708010196686 and batch: 100, loss is 5.2384065246582034 and perplexity is 188.3697006547038
At time: 1136.0944085121155 and batch: 150, loss is 5.201054172515869 and perplexity is 181.4634348479088
At time: 1137.1180419921875 and batch: 200, loss is 5.192990188598633 and perplexity is 180.0060008875434
At time: 1138.1404237747192 and batch: 250, loss is 5.212561569213867 and perplexity is 183.56366750802647
At time: 1139.163001537323 and batch: 300, loss is 5.2281601524353025 and perplexity is 186.44944919217625
At time: 1140.1856307983398 and batch: 350, loss is 5.226040954589844 and perplexity is 186.0547442977604
At time: 1141.2089593410492 and batch: 400, loss is 5.259500169754029 and perplexity is 192.3853072659521
At time: 1142.2302916049957 and batch: 450, loss is 5.221596269607544 and perplexity is 185.22962462676793
At time: 1143.2524514198303 and batch: 500, loss is 5.263491611480713 and perplexity is 193.15473655353642
At time: 1144.2749123573303 and batch: 550, loss is 5.242610988616943 and perplexity is 189.16336156220305
At time: 1145.2974138259888 and batch: 600, loss is 5.196751928329467 and perplexity is 180.68441181554343
At time: 1146.3197090625763 and batch: 650, loss is 5.215582075119019 and perplexity is 184.11896086094876
At time: 1147.3416538238525 and batch: 700, loss is 5.227791967391968 and perplexity is 186.38081392965964
At time: 1148.3708600997925 and batch: 750, loss is 5.205531597137451 and perplexity is 182.27774534555394
At time: 1149.3981628417969 and batch: 800, loss is 5.180246238708496 and perplexity is 177.72656876647306
At time: 1150.4244439601898 and batch: 850, loss is 5.1579655742645265 and perplexity is 173.81049113372296
At time: 1151.4496035575867 and batch: 900, loss is 5.202315006256104 and perplexity is 181.69237436618963
At time: 1152.4742922782898 and batch: 950, loss is 5.176147546768188 and perplexity is 176.99961311282442
At time: 1153.5001366138458 and batch: 1000, loss is 5.196885395050049 and perplexity is 180.70852878081894
At time: 1154.529655456543 and batch: 1050, loss is 5.167561779022217 and perplexity is 175.48644071223833
At time: 1155.557098865509 and batch: 1100, loss is 5.163514757156372 and perplexity is 174.7776784051589
At time: 1156.5821375846863 and batch: 1150, loss is 5.170377130508423 and perplexity is 175.98119284769436
At time: 1157.6070983409882 and batch: 1200, loss is 5.152793445587158 and perplexity is 172.91384170007595
At time: 1158.6319127082825 and batch: 1250, loss is 5.168738021850586 and perplexity is 175.6929768240996
At time: 1159.6566405296326 and batch: 1300, loss is 5.159489707946777 and perplexity is 174.07560353964118
At time: 1160.688057899475 and batch: 1350, loss is 5.130785846710205 and perplexity is 169.14999179343218
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.075194091796875 and perplexity of 160.00324428297898
Finished 39 epochs...
Completing Train Step...
At time: 1163.8210468292236 and batch: 50, loss is 5.223222751617431 and perplexity is 185.53114241908324
At time: 1164.8748710155487 and batch: 100, loss is 5.235516996383667 and perplexity is 187.82618670622358
At time: 1165.9032006263733 and batch: 150, loss is 5.198413419723511 and perplexity is 180.98486694349887
At time: 1166.9301600456238 and batch: 200, loss is 5.190105762481689 and perplexity is 179.487534975152
At time: 1167.9553489685059 and batch: 250, loss is 5.209923515319824 and perplexity is 183.080054838763
At time: 1168.9816465377808 and batch: 300, loss is 5.225477094650269 and perplexity is 185.94986505226427
At time: 1170.0069255828857 and batch: 350, loss is 5.223442220687867 and perplexity is 185.5718652349826
At time: 1171.0324878692627 and batch: 400, loss is 5.256933565139771 and perplexity is 191.89216337201844
At time: 1172.0558092594147 and batch: 450, loss is 5.218988580703735 and perplexity is 184.74723262746107
At time: 1173.08180809021 and batch: 500, loss is 5.26130145072937 and perplexity is 192.732159555297
At time: 1174.1075932979584 and batch: 550, loss is 5.240576553344726 and perplexity is 188.77891214855427
At time: 1175.140955209732 and batch: 600, loss is 5.1943206691741945 and perplexity is 180.24565476727224
At time: 1176.1660821437836 and batch: 650, loss is 5.213164396286011 and perplexity is 183.6743580165278
At time: 1177.1925721168518 and batch: 700, loss is 5.2255207061767575 and perplexity is 185.95797478656726
At time: 1178.2177317142487 and batch: 750, loss is 5.203548488616943 and perplexity is 181.91662698245963
At time: 1179.2430620193481 and batch: 800, loss is 5.178029155731201 and perplexity is 177.3329706972636
At time: 1180.2690784931183 and batch: 850, loss is 5.1556628322601314 and perplexity is 173.410710887025
At time: 1181.2948694229126 and batch: 900, loss is 5.199885511398316 and perplexity is 181.25148945763502
At time: 1182.3207333087921 and batch: 950, loss is 5.173785877227783 and perplexity is 176.58209173569165
At time: 1183.3661425113678 and batch: 1000, loss is 5.194691553115844 and perplexity is 180.31251738454665
At time: 1184.394674539566 and batch: 1050, loss is 5.165493793487549 and perplexity is 175.12391227229799
At time: 1185.4171488285065 and batch: 1100, loss is 5.161314630508423 and perplexity is 174.39356807805854
At time: 1186.4857347011566 and batch: 1150, loss is 5.168003797531128 and perplexity is 175.56402611292444
At time: 1187.5156316757202 and batch: 1200, loss is 5.150709953308105 and perplexity is 172.55395208975293
At time: 1188.5459427833557 and batch: 1250, loss is 5.166131296157837 and perplexity is 175.23558982759045
At time: 1189.5826025009155 and batch: 1300, loss is 5.1571800327301025 and perplexity is 173.67400938687751
At time: 1190.6057019233704 and batch: 1350, loss is 5.128476858139038 and perplexity is 168.75987695424308
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.074471028645833 and perplexity of 159.88759364938537
Finished 40 epochs...
Completing Train Step...
At time: 1193.7500586509705 and batch: 50, loss is 5.22095106124878 and perplexity is 185.11015147135186
At time: 1194.7734587192535 and batch: 100, loss is 5.232721891403198 and perplexity is 187.30192581972656
At time: 1195.798879146576 and batch: 150, loss is 5.195525531768799 and perplexity is 180.46295689785768
At time: 1196.8251388072968 and batch: 200, loss is 5.187344408035278 and perplexity is 178.99258994620064
At time: 1197.8516609668732 and batch: 250, loss is 5.207283916473389 and perplexity is 182.5974341798934
At time: 1198.8780937194824 and batch: 300, loss is 5.22276123046875 and perplexity is 185.44553562930938
At time: 1199.9041380882263 and batch: 350, loss is 5.22090217590332 and perplexity is 185.10110251883148
At time: 1200.929853439331 and batch: 400, loss is 5.25435622215271 and perplexity is 191.39822824402054
At time: 1201.9547278881073 and batch: 450, loss is 5.216534824371338 and perplexity is 184.29446365504887
At time: 1202.9791860580444 and batch: 500, loss is 5.2590141773223875 and perplexity is 192.2918321785942
At time: 1204.0047953128815 and batch: 550, loss is 5.238506221771241 and perplexity is 188.3884815062255
At time: 1205.0297775268555 and batch: 600, loss is 5.191805038452149 and perplexity is 179.7927931157901
At time: 1206.0563015937805 and batch: 650, loss is 5.21095456123352 and perplexity is 183.26891612678256
At time: 1207.0821483135223 and batch: 700, loss is 5.223469247817993 and perplexity is 185.57688077770973
At time: 1208.1086168289185 and batch: 750, loss is 5.201562910079956 and perplexity is 181.5557756003373
At time: 1209.1328256130219 and batch: 800, loss is 5.175880584716797 and perplexity is 176.95236723972053
At time: 1210.1575274467468 and batch: 850, loss is 5.15381272315979 and perplexity is 173.09017875385373
At time: 1211.1820402145386 and batch: 900, loss is 5.197653646469116 and perplexity is 180.84741170616383
At time: 1212.2520258426666 and batch: 950, loss is 5.171540651321411 and perplexity is 176.1860697944498
At time: 1213.2773957252502 and batch: 1000, loss is 5.192408838272095 and perplexity is 179.90138475240718
At time: 1214.3017477989197 and batch: 1050, loss is 5.163122644424439 and perplexity is 174.70915928668572
At time: 1215.33344912529 and batch: 1100, loss is 5.159390468597412 and perplexity is 174.0583292471644
At time: 1216.3583250045776 and batch: 1150, loss is 5.165787858963013 and perplexity is 175.17541774144436
At time: 1217.383197069168 and batch: 1200, loss is 5.148544692993164 and perplexity is 172.1807320701709
At time: 1218.409420967102 and batch: 1250, loss is 5.1637801170349125 and perplexity is 174.82406354277705
At time: 1219.4346249103546 and batch: 1300, loss is 5.154971551895142 and perplexity is 173.290876891726
At time: 1220.4589755535126 and batch: 1350, loss is 5.126469392776489 and perplexity is 168.4214371634051
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.07350830078125 and perplexity of 159.7337394795094
Finished 41 epochs...
Completing Train Step...
At time: 1223.614322423935 and batch: 50, loss is 5.218778553009034 and perplexity is 184.70843466655558
At time: 1224.6385684013367 and batch: 100, loss is 5.229909257888794 and perplexity is 186.7758543158335
At time: 1225.6633760929108 and batch: 150, loss is 5.192569208145142 and perplexity is 179.93023782816113
At time: 1226.6878757476807 and batch: 200, loss is 5.184561653137207 and perplexity is 178.49518983208878
At time: 1227.713371515274 and batch: 250, loss is 5.204889602661133 and perplexity is 182.16076159536507
At time: 1228.7388129234314 and batch: 300, loss is 5.220107812881469 and perplexity is 184.954123432791
At time: 1229.7723939418793 and batch: 350, loss is 5.218461322784424 and perplexity is 184.64984886142432
At time: 1230.797144651413 and batch: 400, loss is 5.2519572067260745 and perplexity is 190.9396112763781
At time: 1231.8222510814667 and batch: 450, loss is 5.213865718841553 and perplexity is 183.803218167663
At time: 1232.847573041916 and batch: 500, loss is 5.256578063964843 and perplexity is 191.8239576068135
At time: 1233.872465133667 and batch: 550, loss is 5.236130809783935 and perplexity is 187.94151232713003
At time: 1234.897178888321 and batch: 600, loss is 5.189926195144653 and perplexity is 179.4553077700286
At time: 1235.9222071170807 and batch: 650, loss is 5.208612518310547 and perplexity is 182.84019469672975
At time: 1236.9476432800293 and batch: 700, loss is 5.221182985305786 and perplexity is 185.15308794748256
At time: 1237.9734334945679 and batch: 750, loss is 5.198998165130615 and perplexity is 181.09072796105505
At time: 1239.0437581539154 and batch: 800, loss is 5.173518161773682 and perplexity is 176.53482430820918
At time: 1240.0683197975159 and batch: 850, loss is 5.151334228515625 and perplexity is 172.66170687482307
At time: 1241.0931234359741 and batch: 900, loss is 5.195403776168823 and perplexity is 180.4409858598428
At time: 1242.1181766986847 and batch: 950, loss is 5.169055318832397 and perplexity is 175.74873252046066
At time: 1243.142971277237 and batch: 1000, loss is 5.189759693145752 and perplexity is 179.4254305899456
At time: 1244.167004585266 and batch: 1050, loss is 5.160962467193603 and perplexity is 174.3321638738296
At time: 1245.1924278736115 and batch: 1100, loss is 5.1575979804992675 and perplexity is 173.74661122249347
At time: 1246.2171730995178 and batch: 1150, loss is 5.163430070877075 and perplexity is 174.7628777605851
At time: 1247.242655992508 and batch: 1200, loss is 5.146430177688599 and perplexity is 171.8170379309806
At time: 1248.2674324512482 and batch: 1250, loss is 5.161468162536621 and perplexity is 174.42034513178527
At time: 1249.2926383018494 and batch: 1300, loss is 5.152706851959229 and perplexity is 172.89886911147863
At time: 1250.3182425498962 and batch: 1350, loss is 5.124050006866455 and perplexity is 168.0144532354957
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.072476806640625 and perplexity of 159.56906001073108
Finished 42 epochs...
Completing Train Step...
At time: 1253.4365603923798 and batch: 50, loss is 5.215898132324218 and perplexity is 184.17716218213167
At time: 1254.4874804019928 and batch: 100, loss is 5.227004804611206 and perplexity is 186.23415961786657
At time: 1255.511693239212 and batch: 150, loss is 5.189431161880493 and perplexity is 179.3664934080978
At time: 1256.536149263382 and batch: 200, loss is 5.181845712661743 and perplexity is 178.01106524571648
At time: 1257.5611414909363 and batch: 250, loss is 5.202136163711548 and perplexity is 181.65988294514239
At time: 1258.595200061798 and batch: 300, loss is 5.217093210220337 and perplexity is 184.39739981197496
At time: 1259.6188323497772 and batch: 350, loss is 5.215956916809082 and perplexity is 184.18798925996322
At time: 1260.6420183181763 and batch: 400, loss is 5.249786262512207 and perplexity is 190.52554165572886
At time: 1261.6653277873993 and batch: 450, loss is 5.211183490753174 and perplexity is 183.31087659453058
At time: 1262.6942245960236 and batch: 500, loss is 5.254153547286987 and perplexity is 191.35944056458817
At time: 1263.721711397171 and batch: 550, loss is 5.233662300109863 and perplexity is 187.47814902947573
At time: 1264.7699332237244 and batch: 600, loss is 5.1874935340881345 and perplexity is 179.01928439499932
At time: 1265.7919018268585 and batch: 650, loss is 5.2063163471221925 and perplexity is 182.42084394440045
At time: 1266.814043045044 and batch: 700, loss is 5.218696670532227 and perplexity is 184.69331090163206
At time: 1267.8359253406525 and batch: 750, loss is 5.196384010314941 and perplexity is 180.6179469930449
At time: 1268.8612730503082 and batch: 800, loss is 5.17135347366333 and perplexity is 176.15309478470792
At time: 1269.887098789215 and batch: 850, loss is 5.149158039093018 and perplexity is 172.28637084390922
At time: 1270.9234251976013 and batch: 900, loss is 5.192993812561035 and perplexity is 180.00665322370477
At time: 1271.9483730793 and batch: 950, loss is 5.166788911819458 and perplexity is 175.35086539528945
At time: 1272.9841451644897 and batch: 1000, loss is 5.1875957679748534 and perplexity is 179.03758716780652
At time: 1274.0175116062164 and batch: 1050, loss is 5.159059238433838 and perplexity is 174.0006854255098
At time: 1275.0422911643982 and batch: 1100, loss is 5.1553781127929685 and perplexity is 173.3613445099387
At time: 1276.06663107872 and batch: 1150, loss is 5.161269016265869 and perplexity is 174.38561342896844
At time: 1277.0918176174164 and batch: 1200, loss is 5.144406757354736 and perplexity is 171.4697313348375
At time: 1278.1176025867462 and batch: 1250, loss is 5.159095249176025 and perplexity is 174.00695143215415
At time: 1279.1421406269073 and batch: 1300, loss is 5.150342502593994 and perplexity is 172.4905586645278
At time: 1280.1672735214233 and batch: 1350, loss is 5.1216819286346436 and perplexity is 167.6170525897799
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.072123616536459 and perplexity of 159.51271174921405
Finished 43 epochs...
Completing Train Step...
At time: 1283.2978389263153 and batch: 50, loss is 5.213427600860595 and perplexity is 183.72270831052174
At time: 1284.3495182991028 and batch: 100, loss is 5.224407663345337 and perplexity is 185.75111074141327
At time: 1285.381450176239 and batch: 150, loss is 5.186726741790771 and perplexity is 178.88206640221904
At time: 1286.4056684970856 and batch: 200, loss is 5.1793894195556645 and perplexity is 177.57435445776662
At time: 1287.4337904453278 and batch: 250, loss is 5.1997785568237305 and perplexity is 181.23210481834354
At time: 1288.4601695537567 and batch: 300, loss is 5.214718151092529 and perplexity is 183.95996475709487
At time: 1289.4915146827698 and batch: 350, loss is 5.21367844581604 and perplexity is 183.768800005795
At time: 1290.5157001018524 and batch: 400, loss is 5.247421808242798 and perplexity is 190.07558488606108
At time: 1291.5711810588837 and batch: 450, loss is 5.209040174484253 and perplexity is 182.91840415698064
At time: 1292.5973539352417 and batch: 500, loss is 5.25222846031189 and perplexity is 190.991411355772
At time: 1293.626587152481 and batch: 550, loss is 5.231636734008789 and perplexity is 187.09878399029975
At time: 1294.661075592041 and batch: 600, loss is 5.18511176109314 and perplexity is 178.59340846906105
At time: 1295.6854529380798 and batch: 650, loss is 5.204212026596069 and perplexity is 182.03737562972347
At time: 1296.7095835208893 and batch: 700, loss is 5.2164417743682865 and perplexity is 184.27731585245738
At time: 1297.7361505031586 and batch: 750, loss is 5.194344873428345 and perplexity is 180.2500175317082
At time: 1298.7654032707214 and batch: 800, loss is 5.169329471588135 and perplexity is 175.79692112501613
At time: 1299.7909004688263 and batch: 850, loss is 5.147297286987305 and perplexity is 171.96608669369192
At time: 1300.8138382434845 and batch: 900, loss is 5.190703001022339 and perplexity is 179.59476386603112
At time: 1301.846566438675 and batch: 950, loss is 5.164661254882812 and perplexity is 174.97817552886903
At time: 1302.872126340866 and batch: 1000, loss is 5.1855323791503904 and perplexity is 178.6685438821171
At time: 1303.9054157733917 and batch: 1050, loss is 5.157210998535156 and perplexity is 173.67938742566224
At time: 1304.9299545288086 and batch: 1100, loss is 5.15362470626831 and perplexity is 173.05763793570634
At time: 1305.955111026764 and batch: 1150, loss is 5.159208784103393 and perplexity is 174.02670842027942
At time: 1306.9796051979065 and batch: 1200, loss is 5.142304496765137 and perplexity is 171.10963591616675
At time: 1308.004658460617 and batch: 1250, loss is 5.157014789581299 and perplexity is 173.64531331768083
At time: 1309.0296730995178 and batch: 1300, loss is 5.148538885116577 and perplexity is 172.1797320686322
At time: 1310.054140329361 and batch: 1350, loss is 5.119816427230835 and perplexity is 167.30465422326503
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.071197916666667 and perplexity of 159.36511917646993
Finished 44 epochs...
Completing Train Step...
At time: 1313.1733376979828 and batch: 50, loss is 5.211013889312744 and perplexity is 183.27978944210102
At time: 1314.2002868652344 and batch: 100, loss is 5.222057867050171 and perplexity is 185.31514588447274
At time: 1315.2255153656006 and batch: 150, loss is 5.184266214370727 and perplexity is 178.44246322250805
At time: 1316.250623703003 and batch: 200, loss is 5.176911869049072 and perplexity is 177.13494957458244
At time: 1317.301516532898 and batch: 250, loss is 5.197610149383545 and perplexity is 180.8395455419003
At time: 1318.326426267624 and batch: 300, loss is 5.212643747329712 and perplexity is 183.5787530442018
At time: 1319.352040052414 and batch: 350, loss is 5.211716861724853 and perplexity is 183.40867537409568
At time: 1320.3774473667145 and batch: 400, loss is 5.245351076126099 and perplexity is 189.6823965022413
At time: 1321.4028680324554 and batch: 450, loss is 5.207132291793823 and perplexity is 182.56975000130177
At time: 1322.4282948970795 and batch: 500, loss is 5.250288858413696 and perplexity is 190.62132307975338
At time: 1323.4546794891357 and batch: 550, loss is 5.229347715377807 and perplexity is 186.6710011761123
At time: 1324.481669664383 and batch: 600, loss is 5.182818021774292 and perplexity is 178.1842311983639
At time: 1325.5075805187225 and batch: 650, loss is 5.202071151733398 and perplexity is 181.64807326069138
At time: 1326.5336501598358 and batch: 700, loss is 5.21449652671814 and perplexity is 183.91919926247337
At time: 1327.5588881969452 and batch: 750, loss is 5.192402286529541 and perplexity is 179.90020608871038
At time: 1328.5842311382294 and batch: 800, loss is 5.167332906723022 and perplexity is 175.44628132293624
At time: 1329.612450838089 and batch: 850, loss is 5.145267925262451 and perplexity is 171.61745916471094
At time: 1330.6348795890808 and batch: 900, loss is 5.188578214645386 and perplexity is 179.21356848119257
At time: 1331.6572637557983 and batch: 950, loss is 5.162693510055542 and perplexity is 174.63420166647055
At time: 1332.677787065506 and batch: 1000, loss is 5.183558683395386 and perplexity is 178.3162543060858
At time: 1333.7003545761108 and batch: 1050, loss is 5.155560359954834 and perplexity is 173.39294200214204
At time: 1334.7226734161377 and batch: 1100, loss is 5.1518439674377445 and perplexity is 172.7497417026596
At time: 1335.7450108528137 and batch: 1150, loss is 5.157136316299439 and perplexity is 173.6664171450421
At time: 1336.767832994461 and batch: 1200, loss is 5.140199251174927 and perplexity is 170.74978702776053
At time: 1337.7920596599579 and batch: 1250, loss is 5.155007190704346 and perplexity is 173.29705288227618
At time: 1338.8150243759155 and batch: 1300, loss is 5.14651948928833 and perplexity is 171.8323838707744
At time: 1339.8377785682678 and batch: 1350, loss is 5.117881422042847 and perplexity is 166.98123186225604
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.07010009765625 and perplexity of 159.1902611178528
Finished 45 epochs...
Completing Train Step...
At time: 1342.9620628356934 and batch: 50, loss is 5.208547372817993 and perplexity is 182.82828387016008
At time: 1343.9845504760742 and batch: 100, loss is 5.219357013702393 and perplexity is 184.81531214497193
At time: 1345.008586883545 and batch: 150, loss is 5.1816706943511965 and perplexity is 177.97991277602443
At time: 1346.031069278717 and batch: 200, loss is 5.174506397247314 and perplexity is 176.70936851510535
At time: 1347.053913116455 and batch: 250, loss is 5.195527515411377 and perplexity is 180.4633148722178
At time: 1348.0764174461365 and batch: 300, loss is 5.210442667007446 and perplexity is 183.17512583420108
At time: 1349.1086077690125 and batch: 350, loss is 5.209349241256714 and perplexity is 182.97494689506786
At time: 1350.130375623703 and batch: 400, loss is 5.243003692626953 and perplexity is 189.23766136079507
At time: 1351.152595281601 and batch: 450, loss is 5.204847793579102 and perplexity is 182.15314578034693
At time: 1352.1751189231873 and batch: 500, loss is 5.248308067321777 and perplexity is 190.24411576883998
At time: 1353.1976997852325 and batch: 550, loss is 5.227230272293091 and perplexity is 186.27615413614882
At time: 1354.236266374588 and batch: 600, loss is 5.1806465435028075 and perplexity is 177.79772780572887
At time: 1355.2622425556183 and batch: 650, loss is 5.200238800048828 and perplexity is 181.31553486434032
At time: 1356.2894186973572 and batch: 700, loss is 5.212732229232788 and perplexity is 183.5949971602801
At time: 1357.3206660747528 and batch: 750, loss is 5.190393161773682 and perplexity is 179.53912697902288
At time: 1358.3486151695251 and batch: 800, loss is 5.165330781936645 and perplexity is 175.09536737839505
At time: 1359.379676580429 and batch: 850, loss is 5.143266658782959 and perplexity is 171.2743503370014
At time: 1360.4084250926971 and batch: 900, loss is 5.18654655456543 and perplexity is 178.84983704275734
At time: 1361.4330999851227 and batch: 950, loss is 5.160634937286377 and perplexity is 174.27507422616333
At time: 1362.4580221176147 and batch: 1000, loss is 5.181586408615113 and perplexity is 177.96491224024243
At time: 1363.4833738803864 and batch: 1050, loss is 5.15380166053772 and perplexity is 173.08826393321365
At time: 1364.5087971687317 and batch: 1100, loss is 5.149791812896728 and perplexity is 172.3955960408647
At time: 1365.542240858078 and batch: 1150, loss is 5.15502233505249 and perplexity is 173.29967737305049
At time: 1366.5671200752258 and batch: 1200, loss is 5.137694015502929 and perplexity is 170.3225539535317
At time: 1367.592669725418 and batch: 1250, loss is 5.152708749771119 and perplexity is 172.89919724131954
At time: 1368.6248593330383 and batch: 1300, loss is 5.1444402694702145 and perplexity is 171.47547774456163
At time: 1369.649922132492 and batch: 1350, loss is 5.115569324493408 and perplexity is 166.5956009452062
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0685009765625 and perplexity of 158.9359000446626
Finished 46 epochs...
Completing Train Step...
At time: 1372.7836287021637 and batch: 50, loss is 5.206129159927368 and perplexity is 182.38670029407174
At time: 1373.837316274643 and batch: 100, loss is 5.216761999130249 and perplexity is 184.33633546132702
At time: 1374.8638064861298 and batch: 150, loss is 5.179057722091675 and perplexity is 177.51546326229342
At time: 1375.8897006511688 and batch: 200, loss is 5.172101840972901 and perplexity is 176.28497134222198
At time: 1376.9158432483673 and batch: 250, loss is 5.193203144073486 and perplexity is 180.04433823286774
At time: 1377.9422056674957 and batch: 300, loss is 5.208112897872925 and perplexity is 182.74886681517836
At time: 1378.9744641780853 and batch: 350, loss is 5.206812715530395 and perplexity is 182.5114143646202
At time: 1380.004183292389 and batch: 400, loss is 5.240645828247071 and perplexity is 188.79199024224462
At time: 1381.036815404892 and batch: 450, loss is 5.2024293136596675 and perplexity is 181.71314433680888
At time: 1382.0730555057526 and batch: 500, loss is 5.245997896194458 and perplexity is 189.8051265707702
At time: 1383.1024374961853 and batch: 550, loss is 5.2251103973388675 and perplexity is 185.88169023721883
At time: 1384.1283597946167 and batch: 600, loss is 5.178548107147217 and perplexity is 177.42502177646628
At time: 1385.1653108596802 and batch: 650, loss is 5.198116979598999 and perplexity is 180.9312237184024
At time: 1386.1986107826233 and batch: 700, loss is 5.210634355545044 and perplexity is 183.21024177175033
At time: 1387.2256150245667 and batch: 750, loss is 5.187980442047119 and perplexity is 179.1064715337164
At time: 1388.2569077014923 and batch: 800, loss is 5.163108797073364 and perplexity is 174.70674004437117
At time: 1389.289100408554 and batch: 850, loss is 5.1410808181762695 and perplexity is 170.90038077497658
At time: 1390.315588235855 and batch: 900, loss is 5.184322862625122 and perplexity is 178.45257196287807
At time: 1391.3497309684753 and batch: 950, loss is 5.158582105636596 and perplexity is 173.91768379472552
At time: 1392.376009464264 and batch: 1000, loss is 5.179556379318237 and perplexity is 177.60400470495614
At time: 1393.4114196300507 and batch: 1050, loss is 5.15174729347229 and perplexity is 172.73304210731908
At time: 1394.4427156448364 and batch: 1100, loss is 5.147567672729492 and perplexity is 172.01259015832719
At time: 1395.5128691196442 and batch: 1150, loss is 5.1527071285247805 and perplexity is 172.8989169293564
At time: 1396.538003206253 and batch: 1200, loss is 5.135530843734741 and perplexity is 169.9545152223441
At time: 1397.5774545669556 and batch: 1250, loss is 5.1504116630554195 and perplexity is 172.50248860369186
At time: 1398.6152024269104 and batch: 1300, loss is 5.142351484298706 and perplexity is 171.11767612482163
At time: 1399.652455329895 and batch: 1350, loss is 5.11344783782959 and perplexity is 166.2425452334588
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.067303873697917 and perplexity of 158.74575125996915
Finished 47 epochs...
Completing Train Step...
At time: 1402.806390762329 and batch: 50, loss is 5.203720369338989 and perplexity is 181.94789763099146
At time: 1403.863109111786 and batch: 100, loss is 5.214096632003784 and perplexity is 183.84566565065103
At time: 1404.9119613170624 and batch: 150, loss is 5.176800479888916 and perplexity is 177.11521976017917
At time: 1405.9716041088104 and batch: 200, loss is 5.170018033981323 and perplexity is 175.91800995756506
At time: 1407.0198941230774 and batch: 250, loss is 5.191034774780274 and perplexity is 179.65435858117908
At time: 1408.0518367290497 and batch: 300, loss is 5.205834531784058 and perplexity is 182.33297195452877
At time: 1409.0774374008179 and batch: 350, loss is 5.204560432434082 and perplexity is 182.1008095638642
At time: 1410.104207277298 and batch: 400, loss is 5.238538751602173 and perplexity is 188.39460985135494
At time: 1411.128140926361 and batch: 450, loss is 5.200231275558472 and perplexity is 181.31417056247966
At time: 1412.1535623073578 and batch: 500, loss is 5.243806667327881 and perplexity is 189.38967543889223
At time: 1413.181943655014 and batch: 550, loss is 5.223039426803589 and perplexity is 185.49713307441095
At time: 1414.2082242965698 and batch: 600, loss is 5.176423749923706 and perplexity is 177.04850771660267
At time: 1415.234171628952 and batch: 650, loss is 5.19637318611145 and perplexity is 180.6159919582134
At time: 1416.2598276138306 and batch: 700, loss is 5.208903732299805 and perplexity is 182.89344807291184
At time: 1417.2925775051117 and batch: 750, loss is 5.1859765625 and perplexity is 178.74792310256734
At time: 1418.3186695575714 and batch: 800, loss is 5.161128187179566 and perplexity is 174.3610565915638
At time: 1419.3452427387238 and batch: 850, loss is 5.138874521255493 and perplexity is 170.52373943521022
At time: 1420.3748636245728 and batch: 900, loss is 5.182315063476563 and perplexity is 178.09463449434983
At time: 1421.4279141426086 and batch: 950, loss is 5.156807851791382 and perplexity is 173.6093832580852
At time: 1422.4557671546936 and batch: 1000, loss is 5.177698860168457 and perplexity is 177.27440807593345
At time: 1423.4886507987976 and batch: 1050, loss is 5.150009050369262 and perplexity is 172.433050892576
At time: 1424.5178554058075 and batch: 1100, loss is 5.145710334777832 and perplexity is 171.69340115914275
At time: 1425.5521502494812 and batch: 1150, loss is 5.150796918869019 and perplexity is 172.5689589935167
At time: 1426.5798528194427 and batch: 1200, loss is 5.133591041564942 and perplexity is 169.62515663347804
At time: 1427.607672214508 and batch: 1250, loss is 5.148509492874146 and perplexity is 172.17467139457818
At time: 1428.6334471702576 and batch: 1300, loss is 5.140411539077759 and perplexity is 170.78603898974796
At time: 1429.6749908924103 and batch: 1350, loss is 5.111318378448487 and perplexity is 165.88891514006372
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.066944580078125 and perplexity of 158.6887251695412
Finished 48 epochs...
Completing Train Step...
At time: 1432.8744173049927 and batch: 50, loss is 5.201401224136353 and perplexity is 181.5264229564616
At time: 1433.9074113368988 and batch: 100, loss is 5.211677570343017 and perplexity is 183.40146913537197
At time: 1434.9556076526642 and batch: 150, loss is 5.174375810623169 and perplexity is 176.68629414185116
At time: 1436.0043351650238 and batch: 200, loss is 5.167881879806519 and perplexity is 175.54262305107034
At time: 1437.0435857772827 and batch: 250, loss is 5.189013319015503 and perplexity is 179.2915620544649
At time: 1438.0698618888855 and batch: 300, loss is 5.203837623596192 and perplexity is 181.96923304738746
At time: 1439.1037764549255 and batch: 350, loss is 5.202194585800171 and perplexity is 181.67049620494438
At time: 1440.1268229484558 and batch: 400, loss is 5.236186504364014 and perplexity is 187.95197994223042
At time: 1441.1506688594818 and batch: 450, loss is 5.19808259010315 and perplexity is 180.92500169182216
At time: 1442.1748402118683 and batch: 500, loss is 5.241866598129272 and perplexity is 189.02260255157435
At time: 1443.2014772891998 and batch: 550, loss is 5.221000499725342 and perplexity is 185.11930326146026
At time: 1444.2263417243958 and batch: 600, loss is 5.174663057327271 and perplexity is 176.73705398745352
At time: 1445.2499465942383 and batch: 650, loss is 5.194618177413941 and perplexity is 180.29928731241037
At time: 1446.2740454673767 and batch: 700, loss is 5.206845769882202 and perplexity is 182.51744726082555
At time: 1447.3443195819855 and batch: 750, loss is 5.183915977478027 and perplexity is 178.3799770317866
At time: 1448.3720071315765 and batch: 800, loss is 5.159214191436767 and perplexity is 174.02764944325202
At time: 1449.400538444519 and batch: 850, loss is 5.136896619796753 and perplexity is 170.18679361489313
At time: 1450.4253604412079 and batch: 900, loss is 5.180361957550049 and perplexity is 177.74713626912467
At time: 1451.4569146633148 and batch: 950, loss is 5.154805707931518 and perplexity is 173.26214002882597
At time: 1452.4816517829895 and batch: 1000, loss is 5.175953569412232 and perplexity is 176.96528252565338
At time: 1453.505360841751 and batch: 1050, loss is 5.148045454025269 and perplexity is 172.0947941927542
At time: 1454.5324909687042 and batch: 1100, loss is 5.143949708938599 and perplexity is 171.3913792724223
At time: 1455.5562572479248 and batch: 1150, loss is 5.148533449172974 and perplexity is 172.17879611186305
At time: 1456.5800845623016 and batch: 1200, loss is 5.131571321487427 and perplexity is 169.28290703950609
At time: 1457.6026985645294 and batch: 1250, loss is 5.146750736236572 and perplexity is 171.87212417988914
At time: 1458.6263871192932 and batch: 1300, loss is 5.138419914245605 and perplexity is 170.44623576610107
At time: 1459.6503820419312 and batch: 1350, loss is 5.109459285736084 and perplexity is 165.58079876405634
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.065816243489583 and perplexity of 158.50977185351638
Finished 49 epochs...
Completing Train Step...
At time: 1462.7895131111145 and batch: 50, loss is 5.199344186782837 and perplexity is 181.15340011628223
At time: 1463.8283274173737 and batch: 100, loss is 5.209098110198974 and perplexity is 182.92900197245427
At time: 1464.8653349876404 and batch: 150, loss is 5.172346229553223 and perplexity is 176.32805864090784
At time: 1465.8967499732971 and batch: 200, loss is 5.165966968536377 and perplexity is 175.20679614578242
At time: 1466.9348330497742 and batch: 250, loss is 5.186925172805786 and perplexity is 178.917565674185
At time: 1467.9656944274902 and batch: 300, loss is 5.201771945953369 and perplexity is 181.5937312373697
At time: 1468.9997169971466 and batch: 350, loss is 5.199939279556275 and perplexity is 181.26123527835554
At time: 1470.0348982810974 and batch: 400, loss is 5.233766841888428 and perplexity is 187.49774935312576
At time: 1471.0865247249603 and batch: 450, loss is 5.195888299942016 and perplexity is 180.528434991031
At time: 1472.1225559711456 and batch: 500, loss is 5.2399897861480715 and perplexity is 188.6681753670179
At time: 1473.1496250629425 and batch: 550, loss is 5.219394426345826 and perplexity is 184.8222267036913
At time: 1474.2252011299133 and batch: 600, loss is 5.172875318527222 and perplexity is 176.42137655710476
At time: 1475.2537295818329 and batch: 650, loss is 5.192720727920532 and perplexity is 179.95750288292814
At time: 1476.2797503471375 and batch: 700, loss is 5.205029649734497 and perplexity is 182.1862744633678
At time: 1477.3110370635986 and batch: 750, loss is 5.182132844924927 and perplexity is 178.06218530451008
At time: 1478.3344604969025 and batch: 800, loss is 5.157249689102173 and perplexity is 173.68610730963812
At time: 1479.3575642108917 and batch: 850, loss is 5.134707431793213 and perplexity is 169.81463024437772
At time: 1480.385648727417 and batch: 900, loss is 5.178398675918579 and perplexity is 177.39851091829564
At time: 1481.4138457775116 and batch: 950, loss is 5.152811470031739 and perplexity is 172.9169584041212
At time: 1482.4442863464355 and batch: 1000, loss is 5.174128580093384 and perplexity is 176.64261729509212
At time: 1483.4736306667328 and batch: 1050, loss is 5.146098966598511 and perplexity is 171.76013964574352
At time: 1484.4971334934235 and batch: 1100, loss is 5.142098541259766 and perplexity is 171.0743985734147
At time: 1485.5200831890106 and batch: 1150, loss is 5.146304912567139 and perplexity is 171.79551659681974
At time: 1486.543925523758 and batch: 1200, loss is 5.129666976928711 and perplexity is 168.96084081646325
At time: 1487.5733218193054 and batch: 1250, loss is 5.1450396919250485 and perplexity is 171.57829480872505
At time: 1488.5986022949219 and batch: 1300, loss is 5.136555032730103 and perplexity is 170.12866993499347
At time: 1489.633883714676 and batch: 1350, loss is 5.107541151046753 and perplexity is 165.26349690120082
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.065163167317708 and perplexity of 158.40628669403355
Finished Training.
Improved accuracyfrom -10000000 to -158.40628669403355
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fec19d50898>
SETTINGS FOR THIS RUN
{'wordvec_dim': 200, 'dropout': 0.0652534720959691, 'num_layers': 1, 'wordvec_source': 'glove', 'tune_wordvecs': True, 'batch_size': 80, 'seq_len': 20, 'lr': 13.283216954066178, 'data': 'wikitext', 'anneal': 4.474904618324195}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.535015344619751 and batch: 50, loss is 7.348214311599731 and perplexity is 1553.4201253814422
At time: 2.5613739490509033 and batch: 100, loss is 6.4171493625640865 and perplexity is 612.2553062295441
At time: 3.5892693996429443 and batch: 150, loss is 6.018094425201416 and perplexity is 410.79504871783143
At time: 4.618594408035278 and batch: 200, loss is 5.841889209747315 and perplexity is 344.42942582653586
At time: 5.656603574752808 and batch: 250, loss is 5.806705770492553 and perplexity is 332.52191592912015
At time: 6.712824583053589 and batch: 300, loss is 5.785359659194946 and perplexity is 325.49908780260614
At time: 7.743587017059326 and batch: 350, loss is 5.762586011886596 and perplexity is 318.1700575106383
At time: 8.773914813995361 and batch: 400, loss is 5.772484703063965 and perplexity is 321.3351640135994
At time: 9.807176351547241 and batch: 450, loss is 5.745886211395264 and perplexity is 312.90080125044756
At time: 10.866107702255249 and batch: 500, loss is 5.769906806945801 and perplexity is 320.507862148948
At time: 11.931548833847046 and batch: 550, loss is 5.721149921417236 and perplexity is 305.2557413261579
At time: 12.99520230293274 and batch: 600, loss is 5.679188957214356 and perplexity is 292.711931724472
At time: 14.045628547668457 and batch: 650, loss is 5.707637786865234 and perplexity is 301.1588260454666
At time: 15.088979959487915 and batch: 700, loss is 5.695976629257202 and perplexity is 297.6673623290094
At time: 16.128999710083008 and batch: 750, loss is 5.67720947265625 and perplexity is 292.13308607267504
At time: 17.172459602355957 and batch: 800, loss is 5.617296209335327 and perplexity is 275.14444363010665
At time: 18.216049194335938 and batch: 850, loss is 5.631029224395752 and perplexity is 278.94907112711707
At time: 19.24636435508728 and batch: 900, loss is 5.676954441070556 and perplexity is 292.0585924080229
At time: 20.285813093185425 and batch: 950, loss is 5.641634473800659 and perplexity is 281.9231380838829
At time: 21.3407461643219 and batch: 1000, loss is 5.650727119445801 and perplexity is 284.4982548480461
At time: 22.386160850524902 and batch: 1050, loss is 5.62684398651123 and perplexity is 277.78404256818834
At time: 23.424042224884033 and batch: 1100, loss is 5.614572019577026 and perplexity is 274.39591798058393
At time: 24.460890769958496 and batch: 1150, loss is 5.617419910430908 and perplexity is 275.1784814044383
At time: 25.4958438873291 and batch: 1200, loss is 5.592779006958008 and perplexity is 268.4806936670787
At time: 26.52702569961548 and batch: 1250, loss is 5.627868137359619 and perplexity is 278.0686810625518
At time: 27.560184478759766 and batch: 1300, loss is 5.583934154510498 and perplexity is 266.11649246486354
At time: 28.596020221710205 and batch: 1350, loss is 5.559589204788208 and perplexity is 259.7161242657768
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.2938818359375 and perplexity of 199.11485836548422
Finished 1 epochs...
Completing Train Step...
At time: 31.781134605407715 and batch: 50, loss is 5.552207641601562 and perplexity is 257.8060715441668
At time: 32.80340504646301 and batch: 100, loss is 5.568473558425904 and perplexity is 262.0338145040922
At time: 33.827563762664795 and batch: 150, loss is 5.509350395202636 and perplexity is 246.9906286457232
At time: 34.85626006126404 and batch: 200, loss is 5.491298561096191 and perplexity is 242.57199698492312
At time: 35.89103150367737 and batch: 250, loss is 5.491939210891724 and perplexity is 242.7274504755
At time: 36.922361612319946 and batch: 300, loss is 5.47676944732666 and perplexity is 239.0731201824341
At time: 37.950308084487915 and batch: 350, loss is 5.47192156791687 and perplexity is 237.91692733182106
At time: 39.000571489334106 and batch: 400, loss is 5.495792474746704 and perplexity is 243.66454766892733
At time: 40.024993896484375 and batch: 450, loss is 5.456727800369262 and perplexity is 234.3293959165382
At time: 41.06299924850464 and batch: 500, loss is 5.4996288299560545 and perplexity is 244.60112680214493
At time: 42.098122119903564 and batch: 550, loss is 5.4662925910949705 and perplexity is 236.58146064407745
At time: 43.126418352127075 and batch: 600, loss is 5.452415657043457 and perplexity is 233.32110947610718
At time: 44.1583046913147 and batch: 650, loss is 5.471753396987915 and perplexity is 237.87691998526816
At time: 45.19933557510376 and batch: 700, loss is 5.478557567596436 and perplexity is 239.50099410560225
At time: 46.23262000083923 and batch: 750, loss is 5.444665260314942 and perplexity is 231.5197678855193
At time: 47.25735521316528 and batch: 800, loss is 5.386557483673096 and perplexity is 218.45007171182777
At time: 48.29269480705261 and batch: 850, loss is 5.38990161895752 and perplexity is 219.1818211571499
At time: 49.321720361709595 and batch: 900, loss is 5.429121656417847 and perplexity is 227.9489399798911
At time: 50.352585792541504 and batch: 950, loss is 5.400686388015747 and perplexity is 221.5584390822514
At time: 51.386892557144165 and batch: 1000, loss is 5.402516851425171 and perplexity is 221.9643651010615
At time: 52.41656136512756 and batch: 1050, loss is 5.39145709991455 and perplexity is 219.52301960113346
At time: 53.44607162475586 and batch: 1100, loss is 5.372483205795288 and perplexity is 215.39707942692417
At time: 54.46984267234802 and batch: 1150, loss is 5.366153573989868 and perplexity is 214.03800099276418
At time: 55.49717450141907 and batch: 1200, loss is 5.357057828903198 and perplexity is 212.09999307123633
At time: 56.53060293197632 and batch: 1250, loss is 5.385745830535889 and perplexity is 218.27283796169425
At time: 57.559181690216064 and batch: 1300, loss is 5.347064151763916 and perplexity is 209.99089061733304
At time: 58.586857080459595 and batch: 1350, loss is 5.331530647277832 and perplexity is 206.75419983273724
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.203406168619792 and perplexity of 181.89073845089737
Finished 2 epochs...
Completing Train Step...
At time: 61.760910987854004 and batch: 50, loss is 5.366317262649536 and perplexity is 214.07303945388597
At time: 62.82529664039612 and batch: 100, loss is 5.40151967048645 and perplexity is 221.74313678776792
At time: 63.85429883003235 and batch: 150, loss is 5.3554956912994385 and perplexity is 211.76892235263742
At time: 64.88557648658752 and batch: 200, loss is 5.345660400390625 and perplexity is 209.69632241488083
At time: 65.91249799728394 and batch: 250, loss is 5.369055700302124 and perplexity is 214.66006852994673
At time: 66.9405722618103 and batch: 300, loss is 5.350454330444336 and perplexity is 210.70400536799454
At time: 67.97785830497742 and batch: 350, loss is 5.344188222885132 and perplexity is 209.3878393326789
At time: 69.02249240875244 and batch: 400, loss is 5.362196464538574 and perplexity is 213.19270276792037
At time: 70.0688591003418 and batch: 450, loss is 5.312214918136597 and perplexity is 202.79891429679478
At time: 71.09679746627808 and batch: 500, loss is 5.369576168060303 and perplexity is 214.77182125390715
At time: 72.1299455165863 and batch: 550, loss is 5.346877641677857 and perplexity is 209.95172885039818
At time: 73.1664388179779 and batch: 600, loss is 5.315320663452148 and perplexity is 203.42973515227277
At time: 74.20299983024597 and batch: 650, loss is 5.330314273834229 and perplexity is 206.50286240578214
At time: 75.23454999923706 and batch: 700, loss is 5.342923469543457 and perplexity is 209.12318276109733
At time: 76.26664996147156 and batch: 750, loss is 5.306825199127197 and perplexity is 201.708825408563
At time: 77.29174542427063 and batch: 800, loss is 5.244056587219238 and perplexity is 189.43701360112985
At time: 78.32542562484741 and batch: 850, loss is 5.251341056823731 and perplexity is 190.82200009031783
At time: 79.35859966278076 and batch: 900, loss is 5.298748388290405 and perplexity is 200.08622292911735
At time: 80.3863570690155 and batch: 950, loss is 5.252447328567505 and perplexity is 191.0332178877074
At time: 81.41631269454956 and batch: 1000, loss is 5.261460371017456 and perplexity is 192.76279103953473
At time: 82.43964767456055 and batch: 1050, loss is 5.23421425819397 and perplexity is 187.58165767301435
At time: 83.47025442123413 and batch: 1100, loss is 5.227951107025146 and perplexity is 186.41047686423147
At time: 84.4943859577179 and batch: 1150, loss is 5.229783449172974 and perplexity is 186.75235776352233
At time: 85.52331137657166 and batch: 1200, loss is 5.226608390808106 and perplexity is 186.16034845723325
At time: 86.54480838775635 and batch: 1250, loss is 5.25725567817688 and perplexity is 191.95398429568786
At time: 87.57533478736877 and batch: 1300, loss is 5.249511756896973 and perplexity is 190.47324850240932
At time: 88.59848070144653 and batch: 1350, loss is 5.222440309524536 and perplexity is 185.3860318214348
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.169361165364584 and perplexity of 175.80249288162918
Finished 3 epochs...
Completing Train Step...
At time: 91.7337589263916 and batch: 50, loss is 5.279406175613404 and perplexity is 196.2533007468688
At time: 92.75888133049011 and batch: 100, loss is 5.30383131980896 and perplexity is 201.10583661610193
At time: 93.78635358810425 and batch: 150, loss is 5.259737024307251 and perplexity is 192.43087999879268
At time: 94.81158590316772 and batch: 200, loss is 5.250820684432983 and perplexity is 190.72272742154178
At time: 95.8414523601532 and batch: 250, loss is 5.260894536972046 and perplexity is 192.65375014211156
At time: 96.86812949180603 and batch: 300, loss is 5.248797655105591 and perplexity is 190.33727976797982
At time: 97.89437770843506 and batch: 350, loss is 5.252659101486206 and perplexity is 191.0736778338375
At time: 98.93070411682129 and batch: 400, loss is 5.261930990219116 and perplexity is 192.85353026049856
At time: 99.96149802207947 and batch: 450, loss is 5.218137493133545 and perplexity is 184.5900634460003
At time: 100.99310445785522 and batch: 500, loss is 5.275916204452515 and perplexity is 195.56957617053428
At time: 102.02924084663391 and batch: 550, loss is 5.245957527160645 and perplexity is 189.79746447585438
At time: 103.05530643463135 and batch: 600, loss is 5.232481031417847 and perplexity is 187.25681771320438
At time: 104.09385800361633 and batch: 650, loss is 5.254908599853516 and perplexity is 191.50398156247473
At time: 105.13394927978516 and batch: 700, loss is 5.271243982315063 and perplexity is 194.6579629554104
At time: 106.17326712608337 and batch: 750, loss is 5.225899410247803 and perplexity is 186.02841116509214
At time: 107.19935870170593 and batch: 800, loss is 5.180791120529175 and perplexity is 177.8234351308095
At time: 108.22821235656738 and batch: 850, loss is 5.179198846817017 and perplexity is 177.54051685108914
At time: 109.2576174736023 and batch: 900, loss is 5.225412349700928 and perplexity is 185.9378261274056
At time: 110.28944134712219 and batch: 950, loss is 5.1859103775024415 and perplexity is 178.73609306320319
At time: 111.32745289802551 and batch: 1000, loss is 5.186021289825439 and perplexity is 178.75591819789392
At time: 112.35706448554993 and batch: 1050, loss is 5.158596382141114 and perplexity is 173.92016674904775
At time: 113.38856339454651 and batch: 1100, loss is 5.1489136695861815 and perplexity is 172.24427445217825
At time: 114.42502474784851 and batch: 1150, loss is 5.165133628845215 and perplexity is 175.06085018811848
At time: 115.51337218284607 and batch: 1200, loss is 5.1498030662536625 and perplexity is 172.3975360809568
At time: 116.54670643806458 and batch: 1250, loss is 5.1940945053100585 and perplexity is 180.20489432293988
At time: 117.58840680122375 and batch: 1300, loss is 5.183579893112182 and perplexity is 178.32003638344804
At time: 118.61827898025513 and batch: 1350, loss is 5.153678483963013 and perplexity is 173.06694482677455
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.163168538411458 and perplexity of 174.7171775705683
Finished 4 epochs...
Completing Train Step...
At time: 121.72493863105774 and batch: 50, loss is 5.211578617095947 and perplexity is 183.3833218623642
At time: 122.74684548377991 and batch: 100, loss is 5.236643934249878 and perplexity is 188.03797446169554
At time: 123.77018928527832 and batch: 150, loss is 5.1912405395507815 and perplexity is 179.69132892250968
At time: 124.80184698104858 and batch: 200, loss is 5.182007865905762 and perplexity is 178.0399326578263
At time: 125.82956957817078 and batch: 250, loss is 5.195339956283569 and perplexity is 180.42947050428842
At time: 126.85480189323425 and batch: 300, loss is 5.1767263603210445 and perplexity is 177.10209254312488
At time: 127.88209819793701 and batch: 350, loss is 5.190789203643799 and perplexity is 179.61024607277076
At time: 128.91076374053955 and batch: 400, loss is 5.2053458118438725 and perplexity is 182.24388396669258
At time: 129.93961882591248 and batch: 450, loss is 5.164630556106568 and perplexity is 174.97280399546096
At time: 130.96905779838562 and batch: 500, loss is 5.220631418228149 and perplexity is 185.05099175888446
At time: 131.99155449867249 and batch: 550, loss is 5.187395286560059 and perplexity is 179.00169705680003
At time: 133.01452255249023 and batch: 600, loss is 5.1829971504211425 and perplexity is 178.21615195746443
At time: 134.03656220436096 and batch: 650, loss is 5.2020769119262695 and perplexity is 181.64911959164155
At time: 135.05883479118347 and batch: 700, loss is 5.218368892669678 and perplexity is 184.63278244344386
At time: 136.09044241905212 and batch: 750, loss is 5.175050172805786 and perplexity is 176.8054848811538
At time: 137.12506318092346 and batch: 800, loss is 5.129039525985718 and perplexity is 168.85485943010153
At time: 138.1558301448822 and batch: 850, loss is 5.127448930740356 and perplexity is 168.586493181156
At time: 139.18360495567322 and batch: 900, loss is 5.176754026412964 and perplexity is 177.10699233367507
At time: 140.20944261550903 and batch: 950, loss is 5.127560052871704 and perplexity is 168.60522791249716
At time: 141.2806842327118 and batch: 1000, loss is 5.132831869125366 and perplexity is 169.49643075825406
At time: 142.31129240989685 and batch: 1050, loss is 5.108313970565796 and perplexity is 165.3912651219196
At time: 143.33354330062866 and batch: 1100, loss is 5.098268651962281 and perplexity is 163.73817398399072
At time: 144.35607743263245 and batch: 1150, loss is 5.113410568237304 and perplexity is 166.23634955703338
At time: 145.3792371749878 and batch: 1200, loss is 5.107338819503784 and perplexity is 165.23006226543114
At time: 146.4016261100769 and batch: 1250, loss is 5.142462253570557 and perplexity is 171.1366317550381
At time: 147.43263292312622 and batch: 1300, loss is 5.144700326919556 and perplexity is 171.52007701886387
At time: 148.4642961025238 and batch: 1350, loss is 5.109660062789917 and perplexity is 165.61404692662592
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.15752685546875 and perplexity of 173.73425392892958
Finished 5 epochs...
Completing Train Step...
At time: 151.59408020973206 and batch: 50, loss is 5.162262372970581 and perplexity is 174.55892661392895
At time: 152.64203214645386 and batch: 100, loss is 5.189941024780273 and perplexity is 179.45796904658573
At time: 153.66927886009216 and batch: 150, loss is 5.143719511032105 and perplexity is 171.35192987648105
At time: 154.69437384605408 and batch: 200, loss is 5.138520727157593 and perplexity is 170.4634198136383
At time: 155.71780276298523 and batch: 250, loss is 5.078357915878296 and perplexity is 160.51026804440713
At time: 156.74086022377014 and batch: 300, loss is 5.096092891693115 and perplexity is 163.38230625231432
At time: 157.76356983184814 and batch: 350, loss is 5.1391572093963624 and perplexity is 170.5719512882237
At time: 158.78721261024475 and batch: 400, loss is 5.15537540435791 and perplexity is 173.3608749726313
At time: 159.81140065193176 and batch: 450, loss is 5.117433204650879 and perplexity is 166.9064047406645
At time: 160.83538556098938 and batch: 500, loss is 5.189337291717529 and perplexity is 179.3496570363602
At time: 161.85891604423523 and batch: 550, loss is 5.157557687759399 and perplexity is 173.73961063652186
At time: 162.89012384414673 and batch: 600, loss is 5.1374079132080075 and perplexity is 170.2738312501396
At time: 163.91183733940125 and batch: 650, loss is 5.16594482421875 and perplexity is 175.2029163537959
At time: 164.93425989151 and batch: 700, loss is 5.175091753005981 and perplexity is 176.81283664145352
At time: 165.9565999507904 and batch: 750, loss is 5.133695030212403 and perplexity is 169.6427966412561
At time: 167.02185225486755 and batch: 800, loss is 5.092738008499145 and perplexity is 162.83509612515434
At time: 168.04594683647156 and batch: 850, loss is 5.090933580398559 and perplexity is 162.5415368349122
At time: 169.06858777999878 and batch: 900, loss is 5.144040927886963 and perplexity is 171.40701412688495
At time: 170.09145164489746 and batch: 950, loss is 5.093080606460571 and perplexity is 162.89089265447825
At time: 171.11852288246155 and batch: 1000, loss is 5.072592420578003 and perplexity is 159.58750948453016
At time: 172.1463143825531 and batch: 1050, loss is 5.069181957244873 and perplexity is 159.04416918274026
At time: 173.17165875434875 and batch: 1100, loss is 5.060866661071778 and perplexity is 157.72715308947647
At time: 174.19565272331238 and batch: 1150, loss is 5.07386116027832 and perplexity is 159.79011299186698
At time: 175.21799206733704 and batch: 1200, loss is 5.0635966777801515 and perplexity is 158.158339157558
At time: 176.239976644516 and batch: 1250, loss is 5.10266357421875 and perplexity is 164.45937417760572
At time: 177.26294827461243 and batch: 1300, loss is 5.096297788619995 and perplexity is 163.41578621462548
At time: 178.2865788936615 and batch: 1350, loss is 5.0798384475708005 and perplexity is 160.7480845872429
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1667472330729165 and perplexity of 175.3435571433153
Annealing...
Finished 6 epochs...
Completing Train Step...
At time: 181.38360714912415 and batch: 50, loss is 5.077397441864013 and perplexity is 160.3561761154176
At time: 182.43366813659668 and batch: 100, loss is 5.037571773529053 and perplexity is 154.0953818775798
At time: 183.45701551437378 and batch: 150, loss is 4.988148775100708 and perplexity is 146.66466275264483
At time: 184.48055124282837 and batch: 200, loss is 4.968678970336914 and perplexity is 143.83674919715557
At time: 185.50515270233154 and batch: 250, loss is 4.9299330902099605 and perplexity is 138.3702537055943
At time: 186.52921223640442 and batch: 300, loss is 4.91222993850708 and perplexity is 135.94221945457065
At time: 187.55263447761536 and batch: 350, loss is 4.920087718963623 and perplexity is 137.0146314408181
At time: 188.582994222641 and batch: 400, loss is 4.923163938522339 and perplexity is 137.43676748857592
At time: 189.6074297428131 and batch: 450, loss is 4.876321935653687 and perplexity is 131.14740710367818
At time: 190.63116669654846 and batch: 500, loss is 4.913582162857056 and perplexity is 136.12616817584754
At time: 191.65438604354858 and batch: 550, loss is 4.896764678955078 and perplexity is 133.85601120311722
At time: 192.6816213130951 and batch: 600, loss is 4.8553845405578615 and perplexity is 128.43006829047414
At time: 193.7501585483551 and batch: 650, loss is 4.853117685317994 and perplexity is 128.13926564549035
At time: 194.7737855911255 and batch: 700, loss is 4.876051368713379 and perplexity is 131.11192775099528
At time: 195.79781651496887 and batch: 750, loss is 4.827209196090698 and perplexity is 124.86200857118888
At time: 196.82634568214417 and batch: 800, loss is 4.793322372436523 and perplexity is 120.70171930324275
At time: 197.85372948646545 and batch: 850, loss is 4.762870178222657 and perplexity is 117.08148884545794
At time: 198.87613534927368 and batch: 900, loss is 4.816905460357666 and perplexity is 123.58206883609166
At time: 199.90005707740784 and batch: 950, loss is 4.7770398902893065 and perplexity is 118.75230939818431
At time: 200.92287492752075 and batch: 1000, loss is 4.768055992126465 and perplexity is 117.69022869977226
At time: 201.94635820388794 and batch: 1050, loss is 4.723889799118042 and perplexity is 112.60541432241057
At time: 202.97007489204407 and batch: 1100, loss is 4.686501760482788 and perplexity is 108.4730505914202
At time: 204.00214219093323 and batch: 1150, loss is 4.691117248535156 and perplexity is 108.97486382609111
At time: 205.03160285949707 and batch: 1200, loss is 4.680230255126953 and perplexity is 107.79489004020725
At time: 206.05878734588623 and batch: 1250, loss is 4.716553010940552 and perplexity is 111.7822755396878
At time: 207.08284163475037 and batch: 1300, loss is 4.70103081703186 and perplexity is 110.06056630420817
At time: 208.106365442276 and batch: 1350, loss is 4.694148054122925 and perplexity is 109.30564646803326
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.884639485677083 and perplexity of 132.2427813226575
Finished 7 epochs...
Completing Train Step...
At time: 211.23024797439575 and batch: 50, loss is 4.865955867767334 and perplexity is 129.79494614034576
At time: 212.26491737365723 and batch: 100, loss is 4.882274971008301 and perplexity is 131.93046071522184
At time: 213.2918860912323 and batch: 150, loss is 4.860867490768433 and perplexity is 129.1361779736037
At time: 214.32194113731384 and batch: 200, loss is 4.848774280548096 and perplexity is 127.58391188403252
At time: 215.3543496131897 and batch: 250, loss is 4.81881046295166 and perplexity is 123.81771738207654
At time: 216.37913727760315 and batch: 300, loss is 4.81028603553772 and perplexity is 122.7667281426809
At time: 217.40869665145874 and batch: 350, loss is 4.8286732006073 and perplexity is 125.04494098995931
At time: 218.4400191307068 and batch: 400, loss is 4.830842485427857 and perplexity is 125.31649351323037
At time: 219.50784873962402 and batch: 450, loss is 4.789893026351929 and perplexity is 120.28850027524308
At time: 220.5348415374756 and batch: 500, loss is 4.838605222702026 and perplexity is 126.29307810923139
At time: 221.56008672714233 and batch: 550, loss is 4.820409164428711 and perplexity is 124.01582326362907
At time: 222.58931469917297 and batch: 600, loss is 4.787718753814698 and perplexity is 120.02724441619273
At time: 223.61255526542664 and batch: 650, loss is 4.790375347137451 and perplexity is 120.3465319129927
At time: 224.64207100868225 and batch: 700, loss is 4.818606119155884 and perplexity is 123.79241858463655
At time: 225.66533994674683 and batch: 750, loss is 4.774162101745605 and perplexity is 118.41105662483277
At time: 226.68845891952515 and batch: 800, loss is 4.739795083999634 and perplexity is 114.4107546836597
At time: 227.7205708026886 and batch: 850, loss is 4.718454713821411 and perplexity is 111.99505447213929
At time: 228.74397206306458 and batch: 900, loss is 4.771419620513916 and perplexity is 118.08676141443614
At time: 229.76608228683472 and batch: 950, loss is 4.734577198028564 and perplexity is 113.8153271991571
At time: 230.79340362548828 and batch: 1000, loss is 4.7257395362854 and perplexity is 112.81389750262788
At time: 231.81912684440613 and batch: 1050, loss is 4.6886162757873535 and perplexity is 108.70266118903766
At time: 232.84260249137878 and batch: 1100, loss is 4.657536716461181 and perplexity is 105.37619075889204
At time: 233.86583065986633 and batch: 1150, loss is 4.672682495117187 and perplexity is 106.9843428357726
At time: 234.88925337791443 and batch: 1200, loss is 4.661578884124756 and perplexity is 105.80300102788037
At time: 235.9132285118103 and batch: 1250, loss is 4.705260686874389 and perplexity is 110.52709415492825
At time: 236.94336414337158 and batch: 1300, loss is 4.6957155418396 and perplexity is 109.47711607938122
At time: 237.96674299240112 and batch: 1350, loss is 4.680871334075928 and perplexity is 107.86401723064482
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.863560384114583 and perplexity of 129.48439657536332
Finished 8 epochs...
Completing Train Step...
At time: 241.13834643363953 and batch: 50, loss is 4.818836660385132 and perplexity is 123.820961130979
At time: 242.1625497341156 and batch: 100, loss is 4.836569061279297 and perplexity is 126.03618664063178
At time: 243.19157004356384 and batch: 150, loss is 4.811983089447022 and perplexity is 122.97524678224954
At time: 244.21718001365662 and batch: 200, loss is 4.804202613830566 and perplexity is 122.02215344100104
At time: 245.26652145385742 and batch: 250, loss is 4.7750016212463375 and perplexity is 118.51050675529258
At time: 246.29032278060913 and batch: 300, loss is 4.766438055038452 and perplexity is 117.49996727087756
At time: 247.31473922729492 and batch: 350, loss is 4.790210399627686 and perplexity is 120.32668268932974
At time: 248.3448042869568 and batch: 400, loss is 4.791192779541015 and perplexity is 120.44494728631247
At time: 249.36859226226807 and batch: 450, loss is 4.7499582386016845 and perplexity is 115.57945766663144
At time: 250.3977828025818 and batch: 500, loss is 4.803953561782837 and perplexity is 121.99176735783344
At time: 251.42866802215576 and batch: 550, loss is 4.785434246063232 and perplexity is 119.7533542171971
At time: 252.4596724510193 and batch: 600, loss is 4.754370594024659 and perplexity is 116.09056207137824
At time: 253.4835307598114 and batch: 650, loss is 4.754034299850463 and perplexity is 116.05152805549855
At time: 254.50681591033936 and batch: 700, loss is 4.784629783630371 and perplexity is 119.65705588191013
At time: 255.53350257873535 and batch: 750, loss is 4.738897018432617 and perplexity is 114.30805244795529
At time: 256.5703661441803 and batch: 800, loss is 4.7056003665924075 and perplexity is 110.56464434426198
At time: 257.5946295261383 and batch: 850, loss is 4.687096776962281 and perplexity is 108.53761305006157
At time: 258.6182641983032 and batch: 900, loss is 4.73793155670166 and perplexity is 114.19774565483857
At time: 259.64190220832825 and batch: 950, loss is 4.704630432128906 and perplexity is 110.45745587656545
At time: 260.66533970832825 and batch: 1000, loss is 4.697618865966797 and perplexity is 109.6856849398991
At time: 261.69349551200867 and batch: 1050, loss is 4.65802149772644 and perplexity is 105.42728754635823
At time: 262.7213430404663 and batch: 1100, loss is 4.632128810882568 and perplexity is 102.73252961916018
At time: 263.74465012550354 and batch: 1150, loss is 4.649462080001831 and perplexity is 104.52874235039842
At time: 264.7687315940857 and batch: 1200, loss is 4.637396459579468 and perplexity is 103.27511631835094
At time: 265.7921793460846 and batch: 1250, loss is 4.686002864837646 and perplexity is 108.41894735592139
At time: 266.82408618927 and batch: 1300, loss is 4.673844728469849 and perplexity is 107.10875589172585
At time: 267.8478627204895 and batch: 1350, loss is 4.652754878997802 and perplexity is 104.87350178852066
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.856546630859375 and perplexity of 128.57940238030022
Finished 9 epochs...
Completing Train Step...
At time: 270.9456751346588 and batch: 50, loss is 4.781942386627197 and perplexity is 119.33592156949089
At time: 272.00037717819214 and batch: 100, loss is 4.799003620147705 and perplexity is 121.38940728296694
At time: 273.0315988063812 and batch: 150, loss is 4.77485466003418 and perplexity is 118.49309158727482
At time: 274.0657858848572 and batch: 200, loss is 4.767013111114502 and perplexity is 117.56755577271912
At time: 275.0991244316101 and batch: 250, loss is 4.737691202163696 and perplexity is 114.17030100680013
At time: 276.12320375442505 and batch: 300, loss is 4.727123041152954 and perplexity is 112.97008409649402
At time: 277.14797592163086 and batch: 350, loss is 4.753839826583862 and perplexity is 116.02896133012702
At time: 278.1742265224457 and batch: 400, loss is 4.755918731689453 and perplexity is 116.27042543374738
At time: 279.2035620212555 and batch: 450, loss is 4.714899635314941 and perplexity is 111.59761015262767
At time: 280.2282783985138 and batch: 500, loss is 4.775848369598389 and perplexity is 118.61089782857813
At time: 281.25638008117676 and batch: 550, loss is 4.751406145095825 and perplexity is 115.74692712477686
At time: 282.28391766548157 and batch: 600, loss is 4.719252109527588 and perplexity is 112.08439446261696
At time: 283.30775117874146 and batch: 650, loss is 4.720389642715454 and perplexity is 112.21196672624559
At time: 284.33223271369934 and batch: 700, loss is 4.751325025558471 and perplexity is 115.7375381684174
At time: 285.35582160949707 and batch: 750, loss is 4.709831914901733 and perplexity is 111.03349526115696
At time: 286.38031458854675 and batch: 800, loss is 4.682829542160034 and perplexity is 108.07544436276856
At time: 287.41157031059265 and batch: 850, loss is 4.66760175704956 and perplexity is 106.44216191841647
At time: 288.4363203048706 and batch: 900, loss is 4.712972116470337 and perplexity is 111.38271083382419
At time: 289.4606144428253 and batch: 950, loss is 4.679840869903565 and perplexity is 107.75292447378476
At time: 290.4969413280487 and batch: 1000, loss is 4.673572607040406 and perplexity is 107.07961326931257
At time: 291.5270051956177 and batch: 1050, loss is 4.63321120262146 and perplexity is 102.8437866615251
At time: 292.5501666069031 and batch: 1100, loss is 4.603556928634643 and perplexity is 99.83880432467011
At time: 293.5734956264496 and batch: 1150, loss is 4.627065725326538 and perplexity is 102.21370057856271
At time: 294.60008788108826 and batch: 1200, loss is 4.614694194793701 and perplexity is 100.9569506502921
At time: 295.63108086586 and batch: 1250, loss is 4.66223876953125 and perplexity is 105.872841925182
At time: 296.6553490161896 and batch: 1300, loss is 4.654063320159912 and perplexity is 105.010812406918
At time: 297.6797466278076 and batch: 1350, loss is 4.633065242767334 and perplexity is 102.82877669287922
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.8465478515625 and perplexity of 127.30017134580571
Finished 10 epochs...
Completing Train Step...
At time: 300.79080414772034 and batch: 50, loss is 4.754054489135743 and perplexity is 116.05387107655743
At time: 301.84080719947815 and batch: 100, loss is 4.770166511535645 and perplexity is 117.93887850954218
At time: 302.87189412117004 and batch: 150, loss is 4.745094184875488 and perplexity is 115.01863800907196
At time: 303.89646434783936 and batch: 200, loss is 4.738857612609864 and perplexity is 114.30354813384993
At time: 304.9220039844513 and batch: 250, loss is 4.713644218444824 and perplexity is 111.45759653629464
At time: 305.95400953292847 and batch: 300, loss is 4.704637460708618 and perplexity is 110.45823223832723
At time: 306.9780111312866 and batch: 350, loss is 4.729906511306763 and perplexity is 113.28497098968019
At time: 308.00284218788147 and batch: 400, loss is 4.7327227210998535 and perplexity is 113.60445489008264
At time: 309.0312407016754 and batch: 450, loss is 4.695009651184082 and perplexity is 109.3998644749484
At time: 310.05607891082764 and batch: 500, loss is 4.750210227966309 and perplexity is 115.60858613060992
At time: 311.0797097682953 and batch: 550, loss is 4.735131540298462 and perplexity is 113.87843733667818
At time: 312.1120343208313 and batch: 600, loss is 4.697574605941773 and perplexity is 109.68083035617163
At time: 313.14475750923157 and batch: 650, loss is 4.699594421386719 and perplexity is 109.90258927198948
At time: 314.1684412956238 and batch: 700, loss is 4.7330365562438965 and perplexity is 113.64011355572555
At time: 315.1923506259918 and batch: 750, loss is 4.691972875595093 and perplexity is 109.06814556993481
At time: 316.21977376937866 and batch: 800, loss is 4.669210443496704 and perplexity is 106.61353178493322
At time: 317.24340534210205 and batch: 850, loss is 4.6540328407287594 and perplexity is 105.00761178586781
At time: 318.2670691013336 and batch: 900, loss is 4.695007734298706 and perplexity is 109.39965476814898
At time: 319.29145669937134 and batch: 950, loss is 4.662960147857666 and perplexity is 105.949243852737
At time: 320.31509256362915 and batch: 1000, loss is 4.657764310836792 and perplexity is 105.40017651664029
At time: 321.3494791984558 and batch: 1050, loss is 4.616894378662109 and perplexity is 101.17931904048542
At time: 322.37859535217285 and batch: 1100, loss is 4.586378135681152 and perplexity is 98.1383419406099
At time: 323.4286892414093 and batch: 1150, loss is 4.615674924850464 and perplexity is 101.05601073389474
At time: 324.452378988266 and batch: 1200, loss is 4.601411190032959 and perplexity is 99.62480602260085
At time: 325.4755585193634 and batch: 1250, loss is 4.644814500808716 and perplexity is 104.0440639055167
At time: 326.50805163383484 and batch: 1300, loss is 4.638952407836914 and perplexity is 103.43593213372367
At time: 327.5319981575012 and batch: 1350, loss is 4.616511716842651 and perplexity is 101.14060898507235
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.84478271484375 and perplexity of 127.0756673374851
Finished 11 epochs...
Completing Train Step...
At time: 330.6479721069336 and batch: 50, loss is 4.7373616409301755 and perplexity is 114.13268110094067
At time: 331.67860770225525 and batch: 100, loss is 4.752485752105713 and perplexity is 115.8719557974455
At time: 332.70492124557495 and batch: 150, loss is 4.725847778320312 and perplexity is 112.82610936936666
At time: 333.72887110710144 and batch: 200, loss is 4.718973245620727 and perplexity is 112.05314252819981
At time: 334.7577712535858 and batch: 250, loss is 4.693839597702026 and perplexity is 109.27193563896782
At time: 335.782408952713 and batch: 300, loss is 4.685653657913208 and perplexity is 108.38109331859503
At time: 336.8063519001007 and batch: 350, loss is 4.712296237945557 and perplexity is 111.30745508627642
At time: 337.8387711048126 and batch: 400, loss is 4.7151570129394536 and perplexity is 111.62633657704087
At time: 338.86233615875244 and batch: 450, loss is 4.676885709762574 and perplexity is 107.43496736478463
At time: 339.8880867958069 and batch: 500, loss is 4.736812973022461 and perplexity is 114.07007733750766
At time: 340.92155361175537 and batch: 550, loss is 4.718728561401367 and perplexity is 112.02572824655121
At time: 341.9483451843262 and batch: 600, loss is 4.680005130767822 and perplexity is 107.77062551603952
At time: 342.9803066253662 and batch: 650, loss is 4.681311044692993 and perplexity is 107.91145661325625
At time: 344.00709676742554 and batch: 700, loss is 4.719354600906372 and perplexity is 112.09588273546
At time: 345.0389006137848 and batch: 750, loss is 4.677533416748047 and perplexity is 107.50457628428909
At time: 346.06929421424866 and batch: 800, loss is 4.656417903900146 and perplexity is 105.25836048032589
At time: 347.09309577941895 and batch: 850, loss is 4.643256797790527 and perplexity is 103.88212031590113
At time: 348.1157033443451 and batch: 900, loss is 4.680554208755493 and perplexity is 107.82981624290339
At time: 349.1991515159607 and batch: 950, loss is 4.649119815826416 and perplexity is 104.4929720283898
At time: 350.22715973854065 and batch: 1000, loss is 4.644996671676636 and perplexity is 104.06301942946003
At time: 351.25129866600037 and batch: 1050, loss is 4.603149433135986 and perplexity is 99.79812874943624
At time: 352.2757468223572 and batch: 1100, loss is 4.574580564498901 and perplexity is 96.98735066640832
At time: 353.29928040504456 and batch: 1150, loss is 4.6002976608276365 and perplexity is 99.51393263335504
At time: 354.32243728637695 and batch: 1200, loss is 4.588994760513305 and perplexity is 98.39546941948439
At time: 355.35436058044434 and batch: 1250, loss is 4.632341690063477 and perplexity is 102.75440156387644
At time: 356.378555059433 and batch: 1300, loss is 4.6237662887573245 and perplexity is 101.87700870917583
At time: 357.4054071903229 and batch: 1350, loss is 4.6028382682800295 and perplexity is 99.76707990998356
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.8455908203125 and perplexity of 127.17839938277879
Annealing...
Finished 12 epochs...
Completing Train Step...
At time: 360.5683252811432 and batch: 50, loss is 4.7183203125 and perplexity is 111.98000320030482
At time: 361.5947756767273 and batch: 100, loss is 4.737180738449097 and perplexity is 114.11203608318112
At time: 362.6203637123108 and batch: 150, loss is 4.7134746742248534 and perplexity is 111.43870114687735
At time: 363.6471366882324 and batch: 200, loss is 4.703823366165161 and perplexity is 110.36834538734396
At time: 364.6758642196655 and batch: 250, loss is 4.67470890045166 and perplexity is 107.20135628314321
At time: 365.711124420166 and batch: 300, loss is 4.666611824035645 and perplexity is 106.33684344597802
At time: 366.7405216693878 and batch: 350, loss is 4.686366186141968 and perplexity is 108.45834542593366
At time: 367.76437735557556 and batch: 400, loss is 4.682750988006592 and perplexity is 108.06695492117355
At time: 368.7952010631561 and batch: 450, loss is 4.63897931098938 and perplexity is 103.43871492380904
At time: 369.82858061790466 and batch: 500, loss is 4.6942026233673095 and perplexity is 109.31161135731625
At time: 370.8528788089752 and batch: 550, loss is 4.677157611846924 and perplexity is 107.46418312807667
At time: 371.8763499259949 and batch: 600, loss is 4.6361218929290775 and perplexity is 103.14356914990175
At time: 372.90036249160767 and batch: 650, loss is 4.630791673660278 and perplexity is 102.59525392853756
At time: 373.9244472980499 and batch: 700, loss is 4.65672794342041 and perplexity is 105.29099979138972
At time: 374.9478633403778 and batch: 750, loss is 4.621081581115723 and perplexity is 101.603865544222
At time: 376.00328040122986 and batch: 800, loss is 4.593437423706055 and perplexity is 98.83357981768668
At time: 377.0345935821533 and batch: 850, loss is 4.564026756286621 and perplexity is 95.96914718145965
At time: 378.0588290691376 and batch: 900, loss is 4.5953187084198 and perplexity is 99.01968892782412
At time: 379.0820987224579 and batch: 950, loss is 4.5663971424102785 and perplexity is 96.19690094177378
At time: 380.1058213710785 and batch: 1000, loss is 4.555516033172608 and perplexity is 95.1558461413972
At time: 381.13711524009705 and batch: 1050, loss is 4.510484132766724 and perplexity is 90.96584739913446
At time: 382.1633939743042 and batch: 1100, loss is 4.475857315063476 and perplexity is 87.86990031643805
At time: 383.1912684440613 and batch: 1150, loss is 4.495049467086792 and perplexity is 89.57259977112255
At time: 384.2151255607605 and batch: 1200, loss is 4.476747913360596 and perplexity is 87.94819195805442
At time: 385.23918628692627 and batch: 1250, loss is 4.513020305633545 and perplexity is 91.19684531462015
At time: 386.26837158203125 and batch: 1300, loss is 4.509452714920044 and perplexity is 90.87207196982767
At time: 387.29650044441223 and batch: 1350, loss is 4.503020420074463 and perplexity is 90.2894318749931
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.784197591145833 and perplexity of 119.60535217541756
Finished 13 epochs...
Completing Train Step...
At time: 390.40517830848694 and batch: 50, loss is 4.677231016159058 and perplexity is 107.47207175204423
At time: 391.45560669898987 and batch: 100, loss is 4.6934677028656 and perplexity is 109.23130552587035
At time: 392.4790120124817 and batch: 150, loss is 4.672418966293335 and perplexity is 106.95615309230256
At time: 393.5070946216583 and batch: 200, loss is 4.6648775100708 and perplexity is 106.15258180336805
At time: 394.53372502326965 and batch: 250, loss is 4.635243062973022 and perplexity is 103.05296331095266
At time: 395.5578646659851 and batch: 300, loss is 4.6324270153045655 and perplexity is 102.76316948201983
At time: 396.5813491344452 and batch: 350, loss is 4.6498795509338375 and perplexity is 104.57238917189467
At time: 397.6051375865936 and batch: 400, loss is 4.652949533462524 and perplexity is 104.89391787085115
At time: 398.62879824638367 and batch: 450, loss is 4.609891738891601 and perplexity is 100.4732716998126
At time: 399.65906834602356 and batch: 500, loss is 4.665730695724488 and perplexity is 106.24318830985406
At time: 400.68434500694275 and batch: 550, loss is 4.651488704681396 and perplexity is 104.74079768507745
At time: 401.7520270347595 and batch: 600, loss is 4.614068374633789 and perplexity is 100.89378952110732
At time: 402.77553248405457 and batch: 650, loss is 4.610208444595337 and perplexity is 100.50509719742516
At time: 403.79934763908386 and batch: 700, loss is 4.640014352798462 and perplexity is 103.54583374509909
At time: 404.8288869857788 and batch: 750, loss is 4.604117364883423 and perplexity is 99.89477329170248
At time: 405.8531222343445 and batch: 800, loss is 4.577950839996338 and perplexity is 97.31477620512695
At time: 406.87705159187317 and batch: 850, loss is 4.548806676864624 and perplexity is 94.51954862515781
At time: 407.9004111289978 and batch: 900, loss is 4.585880031585694 and perplexity is 98.08947100298528
At time: 408.92411255836487 and batch: 950, loss is 4.558419342041016 and perplexity is 95.43251438572304
At time: 409.9473946094513 and batch: 1000, loss is 4.549874668121338 and perplexity is 94.6205486006233
At time: 410.9715025424957 and batch: 1050, loss is 4.510362749099731 and perplexity is 90.95480630112412
At time: 411.9950575828552 and batch: 1100, loss is 4.478403329849243 and perplexity is 88.09390341846992
At time: 413.0190818309784 and batch: 1150, loss is 4.5005678367614745 and perplexity is 90.06826085208237
At time: 414.043119430542 and batch: 1200, loss is 4.484813947677612 and perplexity is 88.6604537950214
At time: 415.06635332107544 and batch: 1250, loss is 4.522765064239502 and perplexity is 92.0898806980557
At time: 416.08955812454224 and batch: 1300, loss is 4.518320875167847 and perplexity is 91.6815239360915
At time: 417.11303973197937 and batch: 1350, loss is 4.50760443687439 and perplexity is 90.7042702341442
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.780332438151041 and perplexity of 119.1439514568691
Finished 14 epochs...
Completing Train Step...
At time: 420.2291090488434 and batch: 50, loss is 4.664679183959961 and perplexity is 106.1315310621882
At time: 421.28410720825195 and batch: 100, loss is 4.679472732543945 and perplexity is 107.71326389739555
At time: 422.3169369697571 and batch: 150, loss is 4.653383808135986 and perplexity is 104.93948053542223
At time: 423.3393557071686 and batch: 200, loss is 4.650223188400268 and perplexity is 104.60833033778022
At time: 424.3787262439728 and batch: 250, loss is 4.6212260532379155 and perplexity is 101.61854553069902
At time: 425.40205240249634 and batch: 300, loss is 4.619615602493286 and perplexity is 101.4550255741403
At time: 426.424658536911 and batch: 350, loss is 4.637459764480591 and perplexity is 103.28165434632037
At time: 427.44830989837646 and batch: 400, loss is 4.641138067245484 and perplexity is 103.6622550943326
At time: 428.50016927719116 and batch: 450, loss is 4.599079542160034 and perplexity is 99.39278665439689
At time: 429.5257487297058 and batch: 500, loss is 4.654252347946167 and perplexity is 105.03066424453546
At time: 430.5486390590668 and batch: 550, loss is 4.642158365249633 and perplexity is 103.76807546128562
At time: 431.57094264030457 and batch: 600, loss is 4.604812526702881 and perplexity is 99.96424046672473
At time: 432.59384393692017 and batch: 650, loss is 4.602640943527222 and perplexity is 99.74739533779251
At time: 433.6164996623993 and batch: 700, loss is 4.63297324180603 and perplexity is 102.81931678174094
At time: 434.63892126083374 and batch: 750, loss is 4.598038139343262 and perplexity is 99.28933260442754
At time: 435.66852951049805 and batch: 800, loss is 4.572577562332153 and perplexity is 96.79327922052451
At time: 436.69831585884094 and batch: 850, loss is 4.543701295852661 and perplexity is 94.0382200447271
At time: 437.7213444709778 and batch: 900, loss is 4.582359142303467 and perplexity is 97.74471611387936
At time: 438.7441346645355 and batch: 950, loss is 4.555459966659546 and perplexity is 95.15051123446284
At time: 439.76773619651794 and batch: 1000, loss is 4.547565498352051 and perplexity is 94.40230576709554
At time: 440.79123711586 and batch: 1050, loss is 4.510599479675293 and perplexity is 90.9763406335868
At time: 441.82261776924133 and batch: 1100, loss is 4.479673023223877 and perplexity is 88.2058267030763
At time: 442.8456428050995 and batch: 1150, loss is 4.502416524887085 and perplexity is 90.23492298209835
At time: 443.86877942085266 and batch: 1200, loss is 4.488116483688355 and perplexity is 88.95374216754578
At time: 444.8911077976227 and batch: 1250, loss is 4.526122703552246 and perplexity is 92.39960498203008
At time: 445.91419982910156 and batch: 1300, loss is 4.52027850151062 and perplexity is 91.86117789277948
At time: 446.9371569156647 and batch: 1350, loss is 4.506920251846314 and perplexity is 90.6422329553761
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.779163004557292 and perplexity of 119.00470195493565
Finished 15 epochs...
Completing Train Step...
At time: 450.04157853126526 and batch: 50, loss is 4.655520219802856 and perplexity is 105.16391412185526
At time: 451.0642409324646 and batch: 100, loss is 4.669903926849365 and perplexity is 106.68749213656669
At time: 452.08789348602295 and batch: 150, loss is 4.6434955883026126 and perplexity is 103.90692934257011
At time: 453.111367225647 and batch: 200, loss is 4.64055624961853 and perplexity is 103.60196010911248
At time: 454.16673254966736 and batch: 250, loss is 4.612565908432007 and perplexity is 100.7423138344271
At time: 455.1930818557739 and batch: 300, loss is 4.611314182281494 and perplexity is 100.61629093527115
At time: 456.2161350250244 and batch: 350, loss is 4.629360933303833 and perplexity is 102.4485717154649
At time: 457.23949813842773 and batch: 400, loss is 4.6334632205963135 and perplexity is 102.86970841060193
At time: 458.2620584964752 and batch: 450, loss is 4.591671628952026 and perplexity is 98.6592139933582
At time: 459.2852728366852 and batch: 500, loss is 4.648190994262695 and perplexity is 104.39596176230036
At time: 460.3083083629608 and batch: 550, loss is 4.636340351104736 and perplexity is 103.16610416723893
At time: 461.3312757015228 and batch: 600, loss is 4.599774847030639 and perplexity is 99.46191897429495
At time: 462.35748863220215 and batch: 650, loss is 4.597594633102417 and perplexity is 99.24530692932059
At time: 463.38523960113525 and batch: 700, loss is 4.628897123336792 and perplexity is 102.401066064443
At time: 464.4085428714752 and batch: 750, loss is 4.593318910598755 and perplexity is 98.8218674370859
At time: 465.43190932273865 and batch: 800, loss is 4.568515768051148 and perplexity is 96.40092220871117
At time: 466.4618422985077 and batch: 850, loss is 4.539462985992432 and perplexity is 93.64050035447755
At time: 467.49345207214355 and batch: 900, loss is 4.579500122070312 and perplexity is 97.46566109488143
At time: 468.51576232910156 and batch: 950, loss is 4.552823753356933 and perplexity is 94.90000453062586
At time: 469.53914070129395 and batch: 1000, loss is 4.5454934883117675 and perplexity is 94.20690574702998
At time: 470.5617790222168 and batch: 1050, loss is 4.5099396133422855 and perplexity is 90.91632821156846
At time: 471.5935206413269 and batch: 1100, loss is 4.479647359848022 and perplexity is 88.20356307283936
At time: 472.6180970668793 and batch: 1150, loss is 4.503093738555908 and perplexity is 90.29605200171457
At time: 473.64228558540344 and batch: 1200, loss is 4.4888377857208255 and perplexity is 89.01792782840806
At time: 474.6654152870178 and batch: 1250, loss is 4.526155309677124 and perplexity is 92.40261782420713
At time: 475.68815088272095 and batch: 1300, loss is 4.519470205307007 and perplexity is 91.78695685176315
At time: 476.71052598953247 and batch: 1350, loss is 4.5048912906646725 and perplexity is 90.45850982986478
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.777734375 and perplexity of 118.83480970570606
Finished 16 epochs...
Completing Train Step...
At time: 479.8358929157257 and batch: 50, loss is 4.648118352890014 and perplexity is 104.38837857176566
At time: 480.8588285446167 and batch: 100, loss is 4.661760473251343 and perplexity is 105.8222154469393
At time: 481.8818573951721 and batch: 150, loss is 4.6366041469573975 and perplexity is 103.19332254754356
At time: 482.9049196243286 and batch: 200, loss is 4.632799205780029 and perplexity is 102.80142407348517
At time: 483.92807817459106 and batch: 250, loss is 4.605635690689087 and perplexity is 100.04656130651227
At time: 484.9520196914673 and batch: 300, loss is 4.60416808128357 and perplexity is 99.89983972347186
At time: 485.9754230976105 and batch: 350, loss is 4.6225439548492435 and perplexity is 101.7525570632054
At time: 486.9987676143646 and batch: 400, loss is 4.627310333251953 and perplexity is 102.23870591793758
At time: 488.02701449394226 and batch: 450, loss is 4.585508394241333 and perplexity is 98.05302406541301
At time: 489.06069111824036 and batch: 500, loss is 4.642524461746216 and perplexity is 103.8060715448613
At time: 490.083612203598 and batch: 550, loss is 4.631897974014282 and perplexity is 102.70881790062651
At time: 491.1071939468384 and batch: 600, loss is 4.596042585372925 and perplexity is 99.0913929478573
At time: 492.1302852630615 and batch: 650, loss is 4.5928239822387695 and perplexity is 98.77296979371796
At time: 493.15353417396545 and batch: 700, loss is 4.624921426773072 and perplexity is 101.9947587105246
At time: 494.1768567562103 and batch: 750, loss is 4.589246826171875 and perplexity is 98.42027466442777
At time: 495.20053219795227 and batch: 800, loss is 4.564625968933106 and perplexity is 96.0266703407042
At time: 496.2262179851532 and batch: 850, loss is 4.535718154907227 and perplexity is 93.29048827501397
At time: 497.2560636997223 and batch: 900, loss is 4.576583013534546 and perplexity is 97.1817574731203
At time: 498.2802402973175 and batch: 950, loss is 4.550155105590821 and perplexity is 94.64708746890655
At time: 499.3120777606964 and batch: 1000, loss is 4.543435659408569 and perplexity is 94.01324338384825
At time: 500.3363983631134 and batch: 1050, loss is 4.508278408050537 and perplexity is 90.76542290308879
At time: 501.3595600128174 and batch: 1100, loss is 4.478562049865722 and perplexity is 88.10788679396364
At time: 502.3828480243683 and batch: 1150, loss is 4.502401828765869 and perplexity is 90.23359688847653
At time: 503.4154415130615 and batch: 1200, loss is 4.48859299659729 and perplexity is 88.99613987471182
At time: 504.4381744861603 and batch: 1250, loss is 4.524720811843872 and perplexity is 92.27016149602328
At time: 505.4618616104126 and batch: 1300, loss is 4.517785129547119 and perplexity is 91.6324191161617
At time: 506.4850914478302 and batch: 1350, loss is 4.5018476867675785 and perplexity is 90.18360851439174
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7764892578125 and perplexity of 118.68693851925006
Finished 17 epochs...
Completing Train Step...
At time: 509.567351102829 and batch: 50, loss is 4.64159574508667 and perplexity is 103.70970987012801
At time: 510.6234018802643 and batch: 100, loss is 4.654635009765625 and perplexity is 105.07086316041878
At time: 511.64984703063965 and batch: 150, loss is 4.628932065963745 and perplexity is 102.40464428921007
At time: 512.6729714870453 and batch: 200, loss is 4.625838069915772 and perplexity is 102.08829436954885
At time: 513.6982362270355 and batch: 250, loss is 4.599775905609131 and perplexity is 99.46202426259883
At time: 514.7270231246948 and batch: 300, loss is 4.597841358184814 and perplexity is 99.26979625679172
At time: 515.7500793933868 and batch: 350, loss is 4.616950283050537 and perplexity is 101.18497556654876
At time: 516.7731673717499 and batch: 400, loss is 4.6228470039367675 and perplexity is 101.78339775566246
At time: 517.796647310257 and batch: 450, loss is 4.580427255630493 and perplexity is 97.5560666827991
At time: 518.8200619220734 and batch: 500, loss is 4.63865439414978 and perplexity is 103.40511140293427
At time: 519.8433861732483 and batch: 550, loss is 4.626662979125976 and perplexity is 102.17254268765774
At time: 520.8668260574341 and batch: 600, loss is 4.591910676956177 and perplexity is 98.6828011006675
At time: 521.8912951946259 and batch: 650, loss is 4.588552846908569 and perplexity is 98.35199672919762
At time: 522.9150342941284 and batch: 700, loss is 4.620279321670532 and perplexity is 101.52238557183016
At time: 523.937769651413 and batch: 750, loss is 4.585294780731201 and perplexity is 98.03208085171967
At time: 524.9613220691681 and batch: 800, loss is 4.561191310882569 and perplexity is 95.6974173237945
At time: 525.9943585395813 and batch: 850, loss is 4.532067213058472 and perplexity is 92.9505111233255
At time: 527.0178883075714 and batch: 900, loss is 4.573876152038574 and perplexity is 96.9190556248679
At time: 528.0408012866974 and batch: 950, loss is 4.547368459701538 and perplexity is 94.38370669658993
At time: 529.0650660991669 and batch: 1000, loss is 4.541006422042846 and perplexity is 93.78514007086646
At time: 530.0889246463776 and batch: 1050, loss is 4.506028366088867 and perplexity is 90.5614264792092
At time: 531.1142392158508 and batch: 1100, loss is 4.4768937397003175 and perplexity is 87.96101805614155
At time: 532.1843638420105 and batch: 1150, loss is 4.5015678977966305 and perplexity is 90.1583796649106
At time: 533.2127075195312 and batch: 1200, loss is 4.4874520778656 and perplexity is 88.89466041259826
At time: 534.236275434494 and batch: 1250, loss is 4.523833484649658 and perplexity is 92.18832398620684
At time: 535.2601840496063 and batch: 1300, loss is 4.515599870681763 and perplexity is 91.43239718937649
At time: 536.2835340499878 and batch: 1350, loss is 4.4995621490478515 and perplexity is 89.97772584136065
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7759696451822915 and perplexity of 118.62528330675548
Finished 18 epochs...
Completing Train Step...
At time: 539.3620085716248 and batch: 50, loss is 4.63596363067627 and perplexity is 103.12724670793274
At time: 540.4113874435425 and batch: 100, loss is 4.6486427593231205 and perplexity is 104.4431348650516
At time: 541.4341180324554 and batch: 150, loss is 4.623245706558228 and perplexity is 101.82398715418088
At time: 542.4567773342133 and batch: 200, loss is 4.6202945804595945 and perplexity is 101.52393469231554
At time: 543.4791419506073 and batch: 250, loss is 4.59504807472229 and perplexity is 98.99289448918583
At time: 544.5023174285889 and batch: 300, loss is 4.592271432876587 and perplexity is 98.71840792770791
At time: 545.5246696472168 and batch: 350, loss is 4.611151647567749 and perplexity is 100.59993862417103
At time: 546.5470564365387 and batch: 400, loss is 4.617953453063965 and perplexity is 101.28653223062982
At time: 547.5698256492615 and batch: 450, loss is 4.575498399734497 and perplexity is 97.07640993887406
At time: 548.5934903621674 and batch: 500, loss is 4.634362745285034 and perplexity is 102.96228388375833
At time: 549.6173825263977 and batch: 550, loss is 4.6226311302185055 and perplexity is 101.76142776658854
At time: 550.6399166584015 and batch: 600, loss is 4.588666543960572 and perplexity is 98.36317969700748
At time: 551.6631455421448 and batch: 650, loss is 4.584604063034058 and perplexity is 97.96439173831304
At time: 552.6856968402863 and batch: 700, loss is 4.616739683151245 and perplexity is 101.16366826462115
At time: 553.7086358070374 and batch: 750, loss is 4.5814417552948 and perplexity is 97.65508749949979
At time: 554.7313303947449 and batch: 800, loss is 4.55790605545044 and perplexity is 95.38354272510745
At time: 555.7544846534729 and batch: 850, loss is 4.528193559646606 and perplexity is 92.59114952926777
At time: 556.7883856296539 and batch: 900, loss is 4.57111930847168 and perplexity is 96.65223291308908
At time: 557.8368966579437 and batch: 950, loss is 4.544590330123901 and perplexity is 94.12186041922396
At time: 558.8689317703247 and batch: 1000, loss is 4.538951587677002 and perplexity is 93.5926250030707
At time: 559.8996016979218 and batch: 1050, loss is 4.504032287597656 and perplexity is 90.3808390569753
At time: 560.9225511550903 and batch: 1100, loss is 4.475317611694336 and perplexity is 87.82248943024955
At time: 561.9450695514679 and batch: 1150, loss is 4.499697332382202 and perplexity is 89.98989015254472
At time: 562.9674081802368 and batch: 1200, loss is 4.486314563751221 and perplexity is 88.79359897199079
At time: 563.9899477958679 and batch: 1250, loss is 4.521759405136108 and perplexity is 91.99731622315588
At time: 565.0160505771637 and batch: 1300, loss is 4.513401222229004 and perplexity is 91.23159032350911
At time: 566.0441963672638 and batch: 1350, loss is 4.496246547698974 and perplexity is 89.67988959816502
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.775388997395833 and perplexity of 118.55642379208246
Finished 19 epochs...
Completing Train Step...
At time: 569.1490981578827 and batch: 50, loss is 4.630927429199219 and perplexity is 102.60918274796322
At time: 570.1717448234558 and batch: 100, loss is 4.643609933853149 and perplexity is 103.91881131692286
At time: 571.1945745944977 and batch: 150, loss is 4.618354711532593 and perplexity is 101.3271824645252
At time: 572.22411942482 and batch: 200, loss is 4.615223922729492 and perplexity is 101.0104445347154
At time: 573.2531156539917 and batch: 250, loss is 4.590365695953369 and perplexity is 98.53045576329276
At time: 574.2824983596802 and batch: 300, loss is 4.587318105697632 and perplexity is 98.23063240784187
At time: 575.3107645511627 and batch: 350, loss is 4.606878986358643 and perplexity is 100.17102612018758
At time: 576.3333184719086 and batch: 400, loss is 4.613565855026245 and perplexity is 100.8431011506102
At time: 577.3563594818115 and batch: 450, loss is 4.571046447753906 and perplexity is 96.64519101856645
At time: 578.3788447380066 and batch: 500, loss is 4.630018930435181 and perplexity is 102.51600476470792
At time: 579.4114198684692 and batch: 550, loss is 4.618883218765259 and perplexity is 101.38074876716568
At time: 580.4343402385712 and batch: 600, loss is 4.584331369400024 and perplexity is 97.9376811143981
At time: 581.4570360183716 and batch: 650, loss is 4.580824184417724 and perplexity is 97.59479718015074
At time: 582.48326420784 and batch: 700, loss is 4.613248338699341 and perplexity is 100.8110869023315
At time: 583.5562994480133 and batch: 750, loss is 4.577780866622925 and perplexity is 97.29823669001087
At time: 584.5791344642639 and batch: 800, loss is 4.554592227935791 and perplexity is 95.06798126368388
At time: 585.6013453006744 and batch: 850, loss is 4.525260591506958 and perplexity is 92.31998049714069
At time: 586.6243302822113 and batch: 900, loss is 4.568177013397217 and perplexity is 96.36827147827543
At time: 587.646852016449 and batch: 950, loss is 4.541670036315918 and perplexity is 93.84739788372136
At time: 588.6695473194122 and batch: 1000, loss is 4.536243371963501 and perplexity is 93.3394989001256
At time: 589.6923480033875 and batch: 1050, loss is 4.502316951751709 and perplexity is 90.22593845521278
At time: 590.7150304317474 and batch: 1100, loss is 4.473946990966797 and perplexity is 87.70220055993313
At time: 591.7383120059967 and batch: 1150, loss is 4.498358383178711 and perplexity is 89.8694788910733
At time: 592.760799407959 and batch: 1200, loss is 4.484271469116211 and perplexity is 88.61237044286658
At time: 593.7828900814056 and batch: 1250, loss is 4.519687194824218 and perplexity is 91.80687582024223
At time: 594.8063611984253 and batch: 1300, loss is 4.510919933319092 and perplexity is 91.00549900514596
At time: 595.8338980674744 and batch: 1350, loss is 4.493441591262817 and perplexity is 89.42869387586782
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.774603271484375 and perplexity of 118.46330752466187
Finished 20 epochs...
Completing Train Step...
At time: 598.9397609233856 and batch: 50, loss is 4.626020812988282 and perplexity is 102.10695200285393
At time: 599.9617650508881 and batch: 100, loss is 4.638638925552368 and perplexity is 103.40351188326684
At time: 600.9909906387329 and batch: 150, loss is 4.613516998291016 and perplexity is 100.83817440627091
At time: 602.0134329795837 and batch: 200, loss is 4.61011194229126 and perplexity is 100.49539869194575
At time: 603.0371766090393 and batch: 250, loss is 4.585813837051392 and perplexity is 98.0829782310277
At time: 604.060004234314 and batch: 300, loss is 4.583088655471801 and perplexity is 97.81604818709938
At time: 605.0826108455658 and batch: 350, loss is 4.60253381729126 and perplexity is 99.7367103471146
At time: 606.105610370636 and batch: 400, loss is 4.609381856918335 and perplexity is 100.42205524806013
At time: 607.1283812522888 and batch: 450, loss is 4.567012224197388 and perplexity is 96.25608810412622
At time: 608.1575381755829 and batch: 500, loss is 4.6261083984375 and perplexity is 102.11589547776686
At time: 609.1831402778625 and batch: 550, loss is 4.615966119766235 and perplexity is 101.08544201534038
At time: 610.2316274642944 and batch: 600, loss is 4.580691776275635 and perplexity is 97.58187568985262
At time: 611.2547421455383 and batch: 650, loss is 4.576869239807129 and perplexity is 97.20957742653573
At time: 612.277058839798 and batch: 700, loss is 4.609564924240113 and perplexity is 100.44044092761898
At time: 613.3001747131348 and batch: 750, loss is 4.574342107772827 and perplexity is 96.9642261375071
At time: 614.3230886459351 and batch: 800, loss is 4.551328258514404 and perplexity is 94.75818813257136
At time: 615.3457970619202 and batch: 850, loss is 4.521872444152832 and perplexity is 92.00771609710766
At time: 616.373297214508 and batch: 900, loss is 4.566028480529785 and perplexity is 96.16144334770819
At time: 617.3997633457184 and batch: 950, loss is 4.5387743377685545 and perplexity is 93.57603718899522
At time: 618.4221539497375 and batch: 1000, loss is 4.534151391983032 and perplexity is 93.14443863925811
At time: 619.444582939148 and batch: 1050, loss is 4.499700384140015 and perplexity is 89.9901647803141
At time: 620.4676549434662 and batch: 1100, loss is 4.472110157012939 and perplexity is 87.54125404138385
At time: 621.4903371334076 and batch: 1150, loss is 4.49693263053894 and perplexity is 89.74143854293148
At time: 622.511922121048 and batch: 1200, loss is 4.482503452301025 and perplexity is 88.45584069627661
At time: 623.536459684372 and batch: 1250, loss is 4.517438678741455 and perplexity is 91.60067848933436
At time: 624.5595421791077 and batch: 1300, loss is 4.508674802780152 and perplexity is 90.80140897023128
At time: 625.5824489593506 and batch: 1350, loss is 4.490177364349365 and perplexity is 89.1372542478005
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.774621988932291 and perplexity of 118.46552487620194
Annealing...
Finished 21 epochs...
Completing Train Step...
At time: 628.6603376865387 and batch: 50, loss is 4.624488363265991 and perplexity is 101.95059806548565
At time: 629.7087128162384 and batch: 100, loss is 4.640635662078857 and perplexity is 103.61018772234259
At time: 630.7316207885742 and batch: 150, loss is 4.615899429321289 and perplexity is 101.0787008070244
At time: 631.7545573711395 and batch: 200, loss is 4.612969551086426 and perplexity is 100.7829859373411
At time: 632.7857818603516 and batch: 250, loss is 4.589216537475586 and perplexity is 98.41729368776497
At time: 633.8087661266327 and batch: 300, loss is 4.587846536636352 and perplexity is 98.28255423047675
At time: 634.8374564647675 and batch: 350, loss is 4.603664474487305 and perplexity is 99.84954215140394
At time: 635.9042618274689 and batch: 400, loss is 4.60753791809082 and perplexity is 100.23705373940062
At time: 636.9263458251953 and batch: 450, loss is 4.5606249332427975 and perplexity is 95.64323179262358
At time: 637.9595592021942 and batch: 500, loss is 4.618742246627807 and perplexity is 101.36645791364529
At time: 638.9864950180054 and batch: 550, loss is 4.608697919845581 and perplexity is 100.3533963634085
At time: 640.0145444869995 and batch: 600, loss is 4.574271287918091 and perplexity is 96.9573593882514
At time: 641.0372352600098 and batch: 650, loss is 4.569123163223266 and perplexity is 96.45949344959226
At time: 642.0597770214081 and batch: 700, loss is 4.595985660552978 and perplexity is 99.08575234870204
At time: 643.0831587314606 and batch: 750, loss is 4.558943710327148 and perplexity is 95.48256929218864
At time: 644.1092953681946 and batch: 800, loss is 4.536319208145142 and perplexity is 93.34657767972891
At time: 645.1370363235474 and batch: 850, loss is 4.4989173412323 and perplexity is 89.91972620183259
At time: 646.1605229377747 and batch: 900, loss is 4.537782678604126 and perplexity is 93.48328764971187
At time: 647.1824078559875 and batch: 950, loss is 4.5120840263366695 and perplexity is 91.1114995563796
At time: 648.2052364349365 and batch: 1000, loss is 4.507921094894409 and perplexity is 90.73299701680688
At time: 649.2279241085052 and batch: 1050, loss is 4.471057863235473 and perplexity is 87.44918337567482
At time: 650.2505035400391 and batch: 1100, loss is 4.440201482772827 and perplexity is 84.7920240849907
At time: 651.2853124141693 and batch: 1150, loss is 4.461271467208863 and perplexity is 86.59754506686181
At time: 652.3080766201019 and batch: 1200, loss is 4.445081386566162 and perplexity is 85.20681224499718
At time: 653.3305771350861 and batch: 1250, loss is 4.478367128372192 and perplexity is 88.0907143467719
At time: 654.3545560836792 and batch: 1300, loss is 4.4734918403625485 and perplexity is 87.66229193326107
At time: 655.3784515857697 and batch: 1350, loss is 4.461652069091797 and perplexity is 86.6305105285322
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.758123372395834 and perplexity of 116.5270427171218
Finished 22 epochs...
Completing Train Step...
At time: 658.4613196849823 and batch: 50, loss is 4.617787933349609 and perplexity is 101.26976870013256
At time: 659.517881155014 and batch: 100, loss is 4.630289182662964 and perplexity is 102.54371368740941
At time: 660.5398967266083 and batch: 150, loss is 4.606022624969483 and perplexity is 100.08528024107596
At time: 661.5890336036682 and batch: 200, loss is 4.603237752914429 and perplexity is 99.80694328729967
At time: 662.61119556427 and batch: 250, loss is 4.578570432662964 and perplexity is 97.37509041000801
At time: 663.6427793502808 and batch: 300, loss is 4.577231874465943 and perplexity is 97.24483538097097
At time: 664.6696813106537 and batch: 350, loss is 4.593701696395874 and perplexity is 98.85970228524488
At time: 665.6926209926605 and batch: 400, loss is 4.5987609767913815 and perplexity is 99.36112859752295
At time: 666.7154529094696 and batch: 450, loss is 4.552796516418457 and perplexity is 94.89741978024158
At time: 667.7379341125488 and batch: 500, loss is 4.61161244392395 and perplexity is 100.64630539132132
At time: 668.7613253593445 and batch: 550, loss is 4.602193031311035 and perplexity is 99.7027272653224
At time: 669.7855608463287 and batch: 600, loss is 4.568065967559814 and perplexity is 96.35757077701524
At time: 670.8091475963593 and batch: 650, loss is 4.563379364013672 and perplexity is 95.9070376039324
At time: 671.8318028450012 and batch: 700, loss is 4.591553363800049 and perplexity is 98.64754673634987
At time: 672.8545844554901 and batch: 750, loss is 4.555652093887329 and perplexity is 95.16879399466025
At time: 673.8766505718231 and batch: 800, loss is 4.533226642608643 and perplexity is 93.05834319238936
At time: 674.9002344608307 and batch: 850, loss is 4.497215166091919 and perplexity is 89.76679727209786
At time: 675.9232506752014 and batch: 900, loss is 4.537005386352539 and perplexity is 93.41065204777128
At time: 676.9473659992218 and batch: 950, loss is 4.511263875961304 and perplexity is 91.0368050603647
At time: 677.9699921607971 and batch: 1000, loss is 4.508320083618164 and perplexity is 90.76920568243338
At time: 678.9931235313416 and batch: 1050, loss is 4.472400531768799 and perplexity is 87.56667750264081
At time: 680.0155396461487 and batch: 1100, loss is 4.442549486160278 and perplexity is 84.99134996211279
At time: 681.0381031036377 and batch: 1150, loss is 4.463891592025757 and perplexity is 86.82473895196705
At time: 682.0601234436035 and batch: 1200, loss is 4.449027490615845 and perplexity is 85.54371147438903
At time: 683.0828442573547 and batch: 1250, loss is 4.482780828475952 and perplexity is 88.48037964212098
At time: 684.1054046154022 and batch: 1300, loss is 4.477963590621949 and perplexity is 88.05517358958792
At time: 685.1286108493805 and batch: 1350, loss is 4.464471187591553 and perplexity is 86.87507677204448
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.756760660807291 and perplexity of 116.36835811086478
Finished 23 epochs...
Completing Train Step...
At time: 688.239091873169 and batch: 50, loss is 4.614958944320679 and perplexity is 100.9836824936872
At time: 689.2669246196747 and batch: 100, loss is 4.626175746917725 and perplexity is 102.12277305972881
At time: 690.2899134159088 and batch: 150, loss is 4.601794900894165 and perplexity is 99.66304047773606
At time: 691.3138327598572 and batch: 200, loss is 4.598884410858155 and perplexity is 99.37339390266757
At time: 692.3363251686096 and batch: 250, loss is 4.573817052841187 and perplexity is 96.9133279557209
At time: 693.3633615970612 and batch: 300, loss is 4.5727031040191655 and perplexity is 96.80543157488688
At time: 694.3908326625824 and batch: 350, loss is 4.589491119384766 and perplexity is 98.44432100659863
At time: 695.4132297039032 and batch: 400, loss is 4.594614877700805 and perplexity is 98.95002034929031
At time: 696.4374122619629 and batch: 450, loss is 4.549029922485351 and perplexity is 94.54065205599812
At time: 697.467933177948 and batch: 500, loss is 4.608032302856445 and perplexity is 100.28662166352423
At time: 698.4909801483154 and batch: 550, loss is 4.5991177654266355 and perplexity is 99.39658584398771
At time: 699.5144989490509 and batch: 600, loss is 4.565438442230224 and perplexity is 96.10472114897247
At time: 700.537736415863 and batch: 650, loss is 4.560766639709473 and perplexity is 95.65678601740031
At time: 701.5607318878174 and batch: 700, loss is 4.589541673660278 and perplexity is 98.44929791372634
At time: 702.5836424827576 and batch: 750, loss is 4.554316387176514 and perplexity is 95.04176125598887
At time: 703.6124873161316 and batch: 800, loss is 4.532028875350952 and perplexity is 92.94694768212376
At time: 704.6349620819092 and batch: 850, loss is 4.496426162719726 and perplexity is 89.69599890008921
At time: 705.6584005355835 and batch: 900, loss is 4.53672643661499 and perplexity is 93.38459880483987
At time: 706.6813213825226 and batch: 950, loss is 4.511213541030884 and perplexity is 91.03222284444004
At time: 707.7045693397522 and batch: 1000, loss is 4.508879461288452 and perplexity is 90.81999415288571
At time: 708.7278969287872 and batch: 1050, loss is 4.473262615203858 and perplexity is 87.64219983337684
At time: 709.7509088516235 and batch: 1100, loss is 4.443878755569458 and perplexity is 85.10440148498145
At time: 710.7743563652039 and batch: 1150, loss is 4.465482740402222 and perplexity is 86.96299996210817
At time: 711.7980198860168 and batch: 1200, loss is 4.451037473678589 and perplexity is 85.71582580107196
At time: 712.8219466209412 and batch: 1250, loss is 4.4850405406951905 and perplexity is 88.68054591106734
At time: 713.8477292060852 and batch: 1300, loss is 4.480157012939453 and perplexity is 88.24852774865438
At time: 714.8707823753357 and batch: 1350, loss is 4.4655563926696775 and perplexity is 86.96940522011812
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.756170247395834 and perplexity of 116.29967294988214
Finished 24 epochs...
Completing Train Step...
At time: 717.9853963851929 and batch: 50, loss is 4.612646865844726 and perplexity is 100.75047000165314
At time: 719.0078451633453 and batch: 100, loss is 4.623254308700561 and perplexity is 101.82486306237868
At time: 720.0305454730988 and batch: 150, loss is 4.5987122535705565 and perplexity is 99.35628752125024
At time: 721.0625829696655 and batch: 200, loss is 4.595755500793457 and perplexity is 99.06294942002843
At time: 722.0850718021393 and batch: 250, loss is 4.5707845115661625 and perplexity is 96.61987946081851
At time: 723.1079857349396 and batch: 300, loss is 4.569657096862793 and perplexity is 96.51101017002782
At time: 724.1311070919037 and batch: 350, loss is 4.586517095565796 and perplexity is 98.15198018084727
At time: 725.1541056632996 and batch: 400, loss is 4.5919059467315675 and perplexity is 98.68233430995724
At time: 726.1771383285522 and batch: 450, loss is 4.546485548019409 and perplexity is 94.30041099612939
At time: 727.200296163559 and batch: 500, loss is 4.605618906021118 and perplexity is 100.0448820722921
At time: 728.2231340408325 and batch: 550, loss is 4.597181987762451 and perplexity is 99.20436226429638
At time: 729.2462961673737 and batch: 600, loss is 4.563742046356201 and perplexity is 95.9418277014913
At time: 730.2688798904419 and batch: 650, loss is 4.55905707359314 and perplexity is 95.49339412164626
At time: 731.292078256607 and batch: 700, loss is 4.588464527130127 and perplexity is 98.34331068621754
At time: 732.3207705020905 and batch: 750, loss is 4.553541555404663 and perplexity is 94.96814840218688
At time: 733.350399017334 and batch: 800, loss is 4.531356925964356 and perplexity is 92.88451301645958
At time: 734.3743596076965 and batch: 850, loss is 4.496285619735718 and perplexity is 89.68339364256121
At time: 735.397926568985 and batch: 900, loss is 4.536454095840454 and perplexity is 93.35916983370161
At time: 736.4207644462585 and batch: 950, loss is 4.5111162471771244 and perplexity is 91.02336639950904
At time: 737.4440085887909 and batch: 1000, loss is 4.509011850357056 and perplexity is 90.83201852325226
At time: 738.4731640815735 and batch: 1050, loss is 4.47368709564209 and perplexity is 87.67941012973246
At time: 739.5243244171143 and batch: 1100, loss is 4.444565744400024 and perplexity is 85.16288734549987
At time: 740.5467472076416 and batch: 1150, loss is 4.466374635696411 and perplexity is 87.0405964513709
At time: 741.5692083835602 and batch: 1200, loss is 4.452171335220337 and perplexity is 85.81307080023075
At time: 742.5917892456055 and batch: 1250, loss is 4.486400175094604 and perplexity is 88.80120103668946
At time: 743.614661693573 and batch: 1300, loss is 4.481417655944824 and perplexity is 88.35984779056844
At time: 744.6377925872803 and batch: 1350, loss is 4.4658526515960695 and perplexity is 86.99517449973865
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7557421875 and perplexity of 116.24990037757482
Finished 25 epochs...
Completing Train Step...
At time: 747.7223222255707 and batch: 50, loss is 4.610681238174439 and perplexity is 100.55262659695923
At time: 748.7710855007172 and batch: 100, loss is 4.620956029891968 and perplexity is 101.5911098553276
At time: 749.7930684089661 and batch: 150, loss is 4.5962427043914795 and perplexity is 99.11122500448089
At time: 750.8157818317413 and batch: 200, loss is 4.593259334564209 and perplexity is 98.81598019746855
At time: 751.8381145000458 and batch: 250, loss is 4.568185110092163 and perplexity is 96.36905174593082
At time: 752.8608934879303 and batch: 300, loss is 4.567406425476074 and perplexity is 96.29403985696148
At time: 753.8887896537781 and batch: 350, loss is 4.584416399002075 and perplexity is 97.94600907050544
At time: 754.9116122722626 and batch: 400, loss is 4.589751415252685 and perplexity is 98.46994899186141
At time: 755.9340019226074 and batch: 450, loss is 4.544438829421997 and perplexity is 94.10760197141568
At time: 756.9658288955688 and batch: 500, loss is 4.603654890060425 and perplexity is 99.84858515535436
At time: 757.9878935813904 and batch: 550, loss is 4.595617485046387 and perplexity is 99.04927811650654
At time: 759.0102019309998 and batch: 600, loss is 4.562381200790405 and perplexity is 95.81135448777182
At time: 760.0323674678802 and batch: 650, loss is 4.55770788192749 and perplexity is 95.36464210527724
At time: 761.0648994445801 and batch: 700, loss is 4.587326374053955 and perplexity is 98.23144461707028
At time: 762.0872647762299 and batch: 750, loss is 4.552662239074707 and perplexity is 94.88467806226595
At time: 763.109582901001 and batch: 800, loss is 4.5308081150054935 and perplexity is 92.83355096335332
At time: 764.1323392391205 and batch: 850, loss is 4.4957200050354 and perplexity is 89.63268173979338
At time: 765.1811275482178 and batch: 900, loss is 4.536077461242676 and perplexity is 93.32401416115927
At time: 766.2120432853699 and batch: 950, loss is 4.510916585922241 and perplexity is 91.00519437413509
At time: 767.2351734638214 and batch: 1000, loss is 4.50908332824707 and perplexity is 90.83851123632196
At time: 768.2573885917664 and batch: 1050, loss is 4.473864183425904 and perplexity is 87.6949384570564
At time: 769.2794954776764 and batch: 1100, loss is 4.444883232116699 and perplexity is 85.18992980874644
At time: 770.3014726638794 and batch: 1150, loss is 4.46685227394104 and perplexity is 87.08218029929887
At time: 771.333128452301 and batch: 1200, loss is 4.4527555847167966 and perplexity is 85.86322169252567
At time: 772.3641271591187 and batch: 1250, loss is 4.4870319747924805 and perplexity is 88.85732333583445
At time: 773.386173248291 and batch: 1300, loss is 4.482155246734619 and perplexity is 88.42504524205046
At time: 774.4165732860565 and batch: 1350, loss is 4.465814304351807 and perplexity is 86.9918385384953
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.755447998046875 and perplexity of 116.21570591302888
Finished 26 epochs...
Completing Train Step...
At time: 777.49338722229 and batch: 50, loss is 4.608916702270508 and perplexity is 100.37535432473497
At time: 778.5403273105621 and batch: 100, loss is 4.618994550704956 and perplexity is 101.39203631089433
At time: 779.5639567375183 and batch: 150, loss is 4.594089365005493 and perplexity is 98.89803451819881
At time: 780.5881526470184 and batch: 200, loss is 4.591140985488892 and perplexity is 98.60687501427131
At time: 781.6171836853027 and batch: 250, loss is 4.566285810470581 and perplexity is 96.18619175034763
At time: 782.6404745578766 and batch: 300, loss is 4.565487632751465 and perplexity is 96.109448706574
At time: 783.6620669364929 and batch: 350, loss is 4.5825450992584225 and perplexity is 97.76289411376123
At time: 784.6837379932404 and batch: 400, loss is 4.587991857528687 and perplexity is 98.29683777678218
At time: 785.7057726383209 and batch: 450, loss is 4.542774000167847 and perplexity is 93.95105922724261
At time: 786.7283084392548 and batch: 500, loss is 4.602033987045288 and perplexity is 99.68687137919876
At time: 787.7504439353943 and batch: 550, loss is 4.594393739700317 and perplexity is 98.92814115889138
At time: 788.7722988128662 and batch: 600, loss is 4.561219663619995 and perplexity is 95.70013064600514
At time: 789.7947151660919 and batch: 650, loss is 4.556505241394043 and perplexity is 95.25002165863637
At time: 790.8163726329803 and batch: 700, loss is 4.586494340896606 and perplexity is 98.14974679041808
At time: 791.8642756938934 and batch: 750, loss is 4.551928234100342 and perplexity is 94.81505779051581
At time: 792.8859040737152 and batch: 800, loss is 4.530330123901368 and perplexity is 92.78918795523468
At time: 793.909257888794 and batch: 850, loss is 4.495302267074585 and perplexity is 89.5952465856879
At time: 794.9315059185028 and batch: 900, loss is 4.535626058578491 and perplexity is 93.28189695915829
At time: 795.9540445804596 and batch: 950, loss is 4.510606689453125 and perplexity is 90.97699655515522
At time: 796.9761867523193 and batch: 1000, loss is 4.508957548141479 and perplexity is 90.8270862773183
At time: 797.9987306594849 and batch: 1050, loss is 4.4738506412506105 and perplexity is 87.69375088486866
At time: 799.0212621688843 and batch: 1100, loss is 4.444948558807373 and perplexity is 85.1954951667208
At time: 800.0434010028839 and batch: 1150, loss is 4.467002696990967 and perplexity is 87.09528045171155
At time: 801.0655946731567 and batch: 1200, loss is 4.453110437393189 and perplexity is 85.89369589315298
At time: 802.0949013233185 and batch: 1250, loss is 4.487438335418701 and perplexity is 88.89343879084194
At time: 803.1211605072021 and batch: 1300, loss is 4.482595090866089 and perplexity is 88.46394703401039
At time: 804.1497280597687 and batch: 1350, loss is 4.4655688285827635 and perplexity is 86.9704867708076
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.755142822265625 and perplexity of 116.1802451053484
Finished 27 epochs...
Completing Train Step...
At time: 807.3148243427277 and batch: 50, loss is 4.607320804595947 and perplexity is 100.21529328467714
At time: 808.3438112735748 and batch: 100, loss is 4.617227849960327 and perplexity is 101.21306506571133
At time: 809.3701958656311 and batch: 150, loss is 4.592287340164185 and perplexity is 98.71997828230398
At time: 810.3940489292145 and batch: 200, loss is 4.589250602722168 and perplexity is 98.42064635424673
At time: 811.4169042110443 and batch: 250, loss is 4.564427995681763 and perplexity is 96.00766151024331
At time: 812.4395525455475 and batch: 300, loss is 4.5637912940979 and perplexity is 95.94655273618777
At time: 813.4626712799072 and batch: 350, loss is 4.580962839126587 and perplexity is 97.6083300965199
At time: 814.4864943027496 and batch: 400, loss is 4.586386995315552 and perplexity is 98.13921141429168
At time: 815.5096483230591 and batch: 450, loss is 4.541263990402221 and perplexity is 93.80929926671693
At time: 816.532341003418 and batch: 500, loss is 4.6006302165985105 and perplexity is 99.54703206933381
At time: 817.5821070671082 and batch: 550, loss is 4.593284273147583 and perplexity is 98.81844455875813
At time: 818.6075465679169 and batch: 600, loss is 4.560091428756714 and perplexity is 95.59221930830323
At time: 819.6376938819885 and batch: 650, loss is 4.555407066345214 and perplexity is 95.14547787564402
At time: 820.6606748104095 and batch: 700, loss is 4.585690221786499 and perplexity is 98.07085442705126
At time: 821.6876595020294 and batch: 750, loss is 4.551167449951172 and perplexity is 94.74295142961223
At time: 822.7115557193756 and batch: 800, loss is 4.5298413562774655 and perplexity is 92.74384668588888
At time: 823.7341668605804 and batch: 850, loss is 4.494849452972412 and perplexity is 89.554685778492
At time: 824.7570819854736 and batch: 900, loss is 4.5350736618042 and perplexity is 93.23038256967948
At time: 825.7805936336517 and batch: 950, loss is 4.510176801681519 and perplexity is 90.93789506206777
At time: 826.8036391735077 and batch: 1000, loss is 4.508856658935547 and perplexity is 90.8179232669388
At time: 827.8273584842682 and batch: 1050, loss is 4.473689460754395 and perplexity is 87.6796175016295
At time: 828.850846529007 and batch: 1100, loss is 4.444730825424195 and perplexity is 85.17694728264665
At time: 829.8790864944458 and batch: 1150, loss is 4.4669036769866945 and perplexity is 87.08665670363793
At time: 830.9042422771454 and batch: 1200, loss is 4.453229436874389 and perplexity is 85.90391780659179
At time: 831.92902302742 and batch: 1250, loss is 4.48756781578064 and perplexity is 88.90494949065929
At time: 832.9525790214539 and batch: 1300, loss is 4.482954959869385 and perplexity is 88.49578819543707
At time: 833.9764082431793 and batch: 1350, loss is 4.465209331512451 and perplexity is 86.93922675488858
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.754842122395833 and perplexity of 116.14531497277923
Finished 28 epochs...
Completing Train Step...
At time: 837.1151535511017 and batch: 50, loss is 4.605866613388062 and perplexity is 100.06966699618378
At time: 838.1402792930603 and batch: 100, loss is 4.615596027374267 and perplexity is 101.04803798421237
At time: 839.1656584739685 and batch: 150, loss is 4.59068510055542 and perplexity is 98.56193187084492
At time: 840.190179347992 and batch: 200, loss is 4.587507619857788 and perplexity is 98.24925026776255
At time: 841.215350151062 and batch: 250, loss is 4.562777881622314 and perplexity is 95.84936855480379
At time: 842.2405323982239 and batch: 300, loss is 4.562283220291138 and perplexity is 95.8019673033117
At time: 843.2918391227722 and batch: 350, loss is 4.579587125778199 and perplexity is 97.4741413376892
At time: 844.3162956237793 and batch: 400, loss is 4.584867601394653 and perplexity is 97.99021251574173
At time: 845.3411238193512 and batch: 450, loss is 4.539874505996704 and perplexity is 93.6790432236204
At time: 846.576788187027 and batch: 500, loss is 4.599367017745972 and perplexity is 99.42136376139183
At time: 847.6014852523804 and batch: 550, loss is 4.592259893417358 and perplexity is 98.71726877723708
At time: 848.6271765232086 and batch: 600, loss is 4.5590370082855225 and perplexity is 95.49147803654128
At time: 849.6513521671295 and batch: 650, loss is 4.554397096633911 and perplexity is 95.04943233453007
At time: 850.6753900051117 and batch: 700, loss is 4.58497745513916 and perplexity is 98.00097769879866
At time: 851.7002372741699 and batch: 750, loss is 4.550422601699829 and perplexity is 94.6724085830322
At time: 852.7243316173553 and batch: 800, loss is 4.529356079101563 and perplexity is 92.69885113242735
At time: 853.7525870800018 and batch: 850, loss is 4.494355554580689 and perplexity is 89.51046578420565
At time: 854.7853004932404 and batch: 900, loss is 4.53447301864624 and perplexity is 93.17440119237374
At time: 855.81023645401 and batch: 950, loss is 4.509648971557617 and perplexity is 90.88990796728098
At time: 856.8350331783295 and batch: 1000, loss is 4.508561849594116 and perplexity is 90.79115324101113
At time: 857.8670997619629 and batch: 1050, loss is 4.47338005065918 and perplexity is 87.6524927393839
At time: 858.8925921916962 and batch: 1100, loss is 4.44443943977356 and perplexity is 85.15213155809222
At time: 859.9261636734009 and batch: 1150, loss is 4.466697540283203 and perplexity is 87.06870679743774
At time: 860.9513306617737 and batch: 1200, loss is 4.453199520111084 and perplexity is 85.9013478778579
At time: 861.9787187576294 and batch: 1250, loss is 4.487621440887451 and perplexity is 88.90971715590389
At time: 863.0078883171082 and batch: 1300, loss is 4.483046979904175 and perplexity is 88.50393195563433
At time: 864.0322709083557 and batch: 1350, loss is 4.4647260189056395 and perplexity is 86.89721808304957
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7546175130208335 and perplexity of 116.11923057568379
Finished 29 epochs...
Completing Train Step...
At time: 867.1860935688019 and batch: 50, loss is 4.604484796524048 and perplexity is 99.93148453616631
At time: 868.2108111381531 and batch: 100, loss is 4.614073934555054 and perplexity is 100.89435048419261
At time: 869.2438404560089 and batch: 150, loss is 4.58919753074646 and perplexity is 98.41542311469927
At time: 870.2947759628296 and batch: 200, loss is 4.585902118682862 and perplexity is 98.09163753858864
At time: 871.3198347091675 and batch: 250, loss is 4.561237993240357 and perplexity is 95.70188480914499
At time: 872.3440899848938 and batch: 300, loss is 4.560877027511597 and perplexity is 95.66734594259977
At time: 873.3690667152405 and batch: 350, loss is 4.57835545539856 and perplexity is 97.35415922939515
At time: 874.4034125804901 and batch: 400, loss is 4.583429861068725 and perplexity is 97.84942926479123
At time: 875.4277930259705 and batch: 450, loss is 4.5385387420654295 and perplexity is 93.55399367349875
At time: 876.459666967392 and batch: 500, loss is 4.598198747634887 and perplexity is 99.30528057516764
At time: 877.4843547344208 and batch: 550, loss is 4.5912532711029055 and perplexity is 98.6179477694222
At time: 878.5091183185577 and batch: 600, loss is 4.558015003204345 and perplexity is 95.39393511395033
At time: 879.5338485240936 and batch: 650, loss is 4.553373317718506 and perplexity is 94.95217252455116
At time: 880.5591933727264 and batch: 700, loss is 4.58426791191101 and perplexity is 97.9314664322609
At time: 881.5840840339661 and batch: 750, loss is 4.549600343704224 and perplexity is 94.5945954337379
At time: 882.6165754795074 and batch: 800, loss is 4.5288023853302 and perplexity is 92.64753856297888
At time: 883.6416132450104 and batch: 850, loss is 4.493776607513428 and perplexity is 89.45865896070202
At time: 884.683278799057 and batch: 900, loss is 4.533802556991577 and perplexity is 93.11195226632252
At time: 885.7109389305115 and batch: 950, loss is 4.509069633483887 and perplexity is 90.83726723294086
At time: 886.733811378479 and batch: 1000, loss is 4.508178167343139 and perplexity is 90.75632496888902
At time: 887.7564873695374 and batch: 1050, loss is 4.472935924530029 and perplexity is 87.6135726204338
At time: 888.7788488864899 and batch: 1100, loss is 4.444094276428222 and perplexity is 85.1227452353335
At time: 889.8024723529816 and batch: 1150, loss is 4.466422414779663 and perplexity is 87.04475527062652
At time: 890.8250567913055 and batch: 1200, loss is 4.453003816604614 and perplexity is 85.88453832776533
At time: 891.8482966423035 and batch: 1250, loss is 4.487551546096801 and perplexity is 88.90350304700603
At time: 892.8711395263672 and batch: 1300, loss is 4.482993268966675 and perplexity is 88.49917845413526
At time: 893.8940057754517 and batch: 1350, loss is 4.464145593643188 and perplexity is 86.84679537715917
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.754390055338542 and perplexity of 116.09282136822995
Finished 30 epochs...
Completing Train Step...
At time: 897.0097184181213 and batch: 50, loss is 4.60308876991272 and perplexity is 99.79207485689656
At time: 898.05996966362 and batch: 100, loss is 4.612636766433716 and perplexity is 100.74945248638524
At time: 899.0824494361877 and batch: 150, loss is 4.587780866622925 and perplexity is 98.2761002257404
At time: 900.1067032814026 and batch: 200, loss is 4.584371194839478 and perplexity is 97.9415816032564
At time: 901.1293647289276 and batch: 250, loss is 4.559751262664795 and perplexity is 95.55970760664606
At time: 902.1574864387512 and batch: 300, loss is 4.559553852081299 and perplexity is 95.54084497091193
At time: 903.1846477985382 and batch: 350, loss is 4.577142429351807 and perplexity is 97.23613769455979
At time: 904.2127692699432 and batch: 400, loss is 4.582082185745239 and perplexity is 97.71764882212452
At time: 905.2355308532715 and batch: 450, loss is 4.537262516021729 and perplexity is 93.43467378604957
At time: 906.2584133148193 and batch: 500, loss is 4.597103090286255 and perplexity is 99.19653559924214
At time: 907.2814450263977 and batch: 550, loss is 4.590320301055908 and perplexity is 98.5259830848758
At time: 908.3080937862396 and batch: 600, loss is 4.557124042510987 and perplexity is 95.30898071851234
At time: 909.3315253257751 and batch: 650, loss is 4.552475709915161 and perplexity is 94.86698095357785
At time: 910.3583364486694 and batch: 700, loss is 4.583586015701294 and perplexity is 97.86471009952064
At time: 911.3870666027069 and batch: 750, loss is 4.548838958740235 and perplexity is 94.52259994272019
At time: 912.4182546138763 and batch: 800, loss is 4.528246755599976 and perplexity is 92.59607513475052
At time: 913.4507088661194 and batch: 850, loss is 4.4932770252227785 and perplexity is 89.41397816073754
At time: 914.4802720546722 and batch: 900, loss is 4.5331504344940186 and perplexity is 93.05125166172414
At time: 915.5523912906647 and batch: 950, loss is 4.508483676910401 and perplexity is 90.78405613030836
At time: 916.584144115448 and batch: 1000, loss is 4.5077393531799315 and perplexity is 90.71650854473631
At time: 917.6111586093903 and batch: 1050, loss is 4.47252366065979 and perplexity is 87.5774601543438
At time: 918.636396408081 and batch: 1100, loss is 4.443740644454956 and perplexity is 85.09264843287556
At time: 919.6611120700836 and batch: 1150, loss is 4.466081657409668 and perplexity is 87.01509918180105
At time: 920.6859078407288 and batch: 1200, loss is 4.452782020568848 and perplexity is 85.86549158995419
At time: 921.7113034725189 and batch: 1250, loss is 4.487412757873535 and perplexity is 88.89116514397364
At time: 922.7365870475769 and batch: 1300, loss is 4.482834243774414 and perplexity is 88.48510597423575
At time: 923.761287689209 and batch: 1350, loss is 4.4635556697845455 and perplexity is 86.7955774893319
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.754193522135417 and perplexity of 116.07000751609978
Finished 31 epochs...
Completing Train Step...
At time: 926.913773059845 and batch: 50, loss is 4.601810245513916 and perplexity is 99.66456978092866
At time: 927.9381182193756 and batch: 100, loss is 4.611269140243531 and perplexity is 100.611759074538
At time: 928.9645142555237 and batch: 150, loss is 4.586488046646118 and perplexity is 98.14912901327067
At time: 929.9890871047974 and batch: 200, loss is 4.582891664505005 and perplexity is 97.79678120697162
At time: 931.0214042663574 and batch: 250, loss is 4.558432168960572 and perplexity is 95.43373849875887
At time: 932.0467460155487 and batch: 300, loss is 4.5582513332366945 and perplexity is 95.41648222989711
At time: 933.0713937282562 and batch: 350, loss is 4.576009883880615 and perplexity is 97.12607568405772
At time: 934.0984997749329 and batch: 400, loss is 4.580774698257446 and perplexity is 97.58996770787218
At time: 935.1262865066528 and batch: 450, loss is 4.536073007583618 and perplexity is 93.32359852874386
At time: 936.1510925292969 and batch: 500, loss is 4.596067543029785 and perplexity is 99.09386606770181
At time: 937.1768305301666 and batch: 550, loss is 4.589436979293823 and perplexity is 98.43899136638143
At time: 938.2009453773499 and batch: 600, loss is 4.5562531280517575 and perplexity is 95.22601088416873
At time: 939.2318127155304 and batch: 650, loss is 4.551600074768066 and perplexity is 94.7839484491511
At time: 940.258279800415 and batch: 700, loss is 4.582885284423828 and perplexity is 97.79615725755907
At time: 941.3102624416351 and batch: 750, loss is 4.548082971572876 and perplexity is 94.45116907395021
At time: 942.334367275238 and batch: 800, loss is 4.527684917449951 and perplexity is 92.54406573899676
At time: 943.3610079288483 and batch: 850, loss is 4.492754411697388 and perplexity is 89.36726141485669
At time: 944.3855683803558 and batch: 900, loss is 4.532493953704834 and perplexity is 92.99018534922227
At time: 945.41943359375 and batch: 950, loss is 4.507887725830078 and perplexity is 90.72996939210724
At time: 946.4472279548645 and batch: 1000, loss is 4.507248401641846 and perplexity is 90.67198206640238
At time: 947.4732737541199 and batch: 1050, loss is 4.472073993682861 and perplexity is 87.53808831536044
At time: 948.4978940486908 and batch: 1100, loss is 4.443331451416015 and perplexity is 85.05783623641177
At time: 949.529595375061 and batch: 1150, loss is 4.465652112960815 and perplexity is 86.97773035534169
At time: 950.5551931858063 and batch: 1200, loss is 4.452514410018921 and perplexity is 85.84251615290184
At time: 951.5801289081573 and batch: 1250, loss is 4.4871883201599125 and perplexity is 88.87121685276561
At time: 952.6051046848297 and batch: 1300, loss is 4.482592487335205 and perplexity is 88.46371671569204
At time: 953.6296212673187 and batch: 1350, loss is 4.462941942214965 and perplexity is 86.74232499344302
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.754000651041666 and perplexity of 116.0476231255189
Finished 32 epochs...
Completing Train Step...
At time: 956.744619846344 and batch: 50, loss is 4.60061728477478 and perplexity is 99.54574475298593
At time: 957.7684075832367 and batch: 100, loss is 4.609966173171997 and perplexity is 100.48075063383162
At time: 958.7934105396271 and batch: 150, loss is 4.585246028900147 and perplexity is 98.02730172477267
At time: 959.8295767307281 and batch: 200, loss is 4.58144326210022 and perplexity is 97.65523464682578
At time: 960.8575537204742 and batch: 250, loss is 4.557165603637696 and perplexity is 95.31294194945254
At time: 961.8818686008453 and batch: 300, loss is 4.55702883720398 and perplexity is 95.29990722967152
At time: 962.9059805870056 and batch: 350, loss is 4.574964570999145 and perplexity is 97.0246015913466
At time: 963.9299221038818 and batch: 400, loss is 4.579498300552368 and perplexity is 97.46548355959247
At time: 964.9540939331055 and batch: 450, loss is 4.534921398162842 and perplexity is 93.21618805282608
At time: 965.978844165802 and batch: 500, loss is 4.5950577926635745 and perplexity is 98.99385650099644
At time: 967.0034394264221 and batch: 550, loss is 4.588543348312378 and perplexity is 98.35106252773288
At time: 968.0546677112579 and batch: 600, loss is 4.5553875923156735 and perplexity is 95.14362502783845
At time: 969.0819013118744 and batch: 650, loss is 4.550720195770264 and perplexity is 94.70058672307607
At time: 970.108122587204 and batch: 700, loss is 4.582082777023316 and perplexity is 97.71770660044501
At time: 971.1319046020508 and batch: 750, loss is 4.547315607070923 and perplexity is 94.37871840122723
At time: 972.1558890342712 and batch: 800, loss is 4.527124519348145 and perplexity is 92.4922187490574
At time: 973.1801974773407 and batch: 850, loss is 4.492241172790528 and perplexity is 89.32140642758736
At time: 974.2108144760132 and batch: 900, loss is 4.531830358505249 and perplexity is 92.92849797860123
At time: 975.2362401485443 and batch: 950, loss is 4.507277450561523 and perplexity is 90.67461602778312
At time: 976.2613143920898 and batch: 1000, loss is 4.50674108505249 and perplexity is 90.62599433186699
At time: 977.2866015434265 and batch: 1050, loss is 4.471613454818725 and perplexity is 87.4977829054153
At time: 978.3108220100403 and batch: 1100, loss is 4.442858934402466 and perplexity is 85.0176544556895
At time: 979.3386235237122 and batch: 1150, loss is 4.465204658508301 and perplexity is 86.9388204884704
At time: 980.3633239269257 and batch: 1200, loss is 4.452196159362793 and perplexity is 85.81520106256576
At time: 981.3872890472412 and batch: 1250, loss is 4.486913089752197 and perplexity is 88.84676015728459
At time: 982.4111788272858 and batch: 1300, loss is 4.482291889190674 and perplexity is 88.43712868294583
At time: 983.4354069232941 and batch: 1350, loss is 4.46229058265686 and perplexity is 86.68584294802329
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.753779703776042 and perplexity of 116.02198555288714
Finished 33 epochs...
Completing Train Step...
At time: 986.568196773529 and batch: 50, loss is 4.5994375133514405 and perplexity is 99.42837277767624
At time: 987.6261122226715 and batch: 100, loss is 4.60869649887085 and perplexity is 100.35325376386936
At time: 988.6584103107452 and batch: 150, loss is 4.584007301330566 and perplexity is 97.90594778130992
At time: 989.6868467330933 and batch: 200, loss is 4.580073852539062 and perplexity is 97.52159615859922
At time: 990.7206435203552 and batch: 250, loss is 4.555926780700684 and perplexity is 95.19493919812037
At time: 991.7462823390961 and batch: 300, loss is 4.555884218215942 and perplexity is 95.19088755119793
At time: 992.7707915306091 and batch: 350, loss is 4.573926725387573 and perplexity is 96.92395727003796
At time: 993.82746052742 and batch: 400, loss is 4.57829062461853 and perplexity is 97.34784788789997
At time: 994.8599278926849 and batch: 450, loss is 4.5338203239440915 and perplexity is 93.11360659665313
At time: 995.8841822147369 and batch: 500, loss is 4.594049263000488 and perplexity is 98.89406858824502
At time: 996.9082593917847 and batch: 550, loss is 4.587611236572266 and perplexity is 98.2594310597162
At time: 997.9320788383484 and batch: 600, loss is 4.554520120620728 and perplexity is 95.06112641395188
At time: 998.9601378440857 and batch: 650, loss is 4.549836101531983 and perplexity is 94.61689947914842
At time: 999.9932658672333 and batch: 700, loss is 4.58131887435913 and perplexity is 97.64308828822722
At time: 1001.0178558826447 and batch: 750, loss is 4.546545381546021 and perplexity is 94.3060534910837
At time: 1002.0482964515686 and batch: 800, loss is 4.526539478302002 and perplexity is 92.4381228303498
At time: 1003.0733911991119 and batch: 850, loss is 4.491720352172852 and perplexity is 89.27489810981676
At time: 1004.0990672111511 and batch: 900, loss is 4.531188869476319 and perplexity is 92.86890448300342
At time: 1005.1273851394653 and batch: 950, loss is 4.506640920639038 and perplexity is 90.61691728690724
At time: 1006.1523327827454 and batch: 1000, loss is 4.506257381439209 and perplexity is 90.58216881108731
At time: 1007.1770088672638 and batch: 1050, loss is 4.471137075424195 and perplexity is 87.45611069125219
At time: 1008.2088735103607 and batch: 1100, loss is 4.442373380661011 and perplexity is 84.9763838358416
At time: 1009.2386426925659 and batch: 1150, loss is 4.464833164215088 and perplexity is 86.90652921118426
At time: 1010.2645728588104 and batch: 1200, loss is 4.451841278076172 and perplexity is 85.78475225677627
At time: 1011.2954561710358 and batch: 1250, loss is 4.486577367782592 and perplexity is 88.81693735433677
At time: 1012.3207919597626 and batch: 1300, loss is 4.481952476501465 and perplexity is 88.40711709271898
At time: 1013.3451104164124 and batch: 1350, loss is 4.461631717681885 and perplexity is 86.62874749344174
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.7535408528645835 and perplexity of 115.99427690513826
Finished 34 epochs...
Completing Train Step...
At time: 1016.477222442627 and batch: 50, loss is 4.598292493820191 and perplexity is 99.31459050278033
At time: 1017.5280766487122 and batch: 100, loss is 4.607490062713623 and perplexity is 100.23225697216128
At time: 1018.5585975646973 and batch: 150, loss is 4.5827484226226805 and perplexity is 97.78277361520712
At time: 1019.6100451946259 and batch: 200, loss is 4.578754291534424 and perplexity is 97.39299533017788
At time: 1020.6385896205902 and batch: 250, loss is 4.554655857086182 and perplexity is 95.07403055101456
At time: 1021.6627957820892 and batch: 300, loss is 4.554796390533447 and perplexity is 95.08739257115667
At time: 1022.6880581378937 and batch: 350, loss is 4.572918710708618 and perplexity is 96.82630572373193
At time: 1023.7209496498108 and batch: 400, loss is 4.577120761871338 and perplexity is 97.23403085527048
At time: 1024.748390197754 and batch: 450, loss is 4.532728509902954 and perplexity is 93.01199933176268
At time: 1025.778522491455 and batch: 500, loss is 4.593029384613037 and perplexity is 98.7932600799922
At time: 1026.8024315834045 and batch: 550, loss is 4.586619358062745 and perplexity is 98.1620179606565
At time: 1027.8306126594543 and batch: 600, loss is 4.553666620254517 and perplexity is 94.98002632214738
At time: 1028.8546731472015 and batch: 650, loss is 4.548954744338989 and perplexity is 94.53354493217421
At time: 1029.8870873451233 and batch: 700, loss is 4.580562467575073 and perplexity is 97.56925832009426
At time: 1030.9191002845764 and batch: 750, loss is 4.545779266357422 and perplexity is 94.23383185970418
At time: 1031.9440093040466 and batch: 800, loss is 4.5259528064727785 and perplexity is 92.3839078924823
At time: 1032.9694192409515 and batch: 850, loss is 4.491190738677979 and perplexity is 89.22762943719272
At time: 1033.9945023059845 and batch: 900, loss is 4.530552654266358 and perplexity is 92.80983866471723
At time: 1035.029764175415 and batch: 950, loss is 4.505979070663452 and perplexity is 90.55696232519678
At time: 1036.0590343475342 and batch: 1000, loss is 4.505820255279541 and perplexity is 90.5425816284275
At time: 1037.0855736732483 and batch: 1050, loss is 4.470635614395142 and perplexity is 87.41226585414533
At time: 1038.1100718975067 and batch: 1100, loss is 4.441844415664673 and perplexity is 84.93144618954582
At time: 1039.1384644508362 and batch: 1150, loss is 4.464430341720581 and perplexity is 86.87152835633755
At time: 1040.166577577591 and batch: 1200, loss is 4.451478261947631 and perplexity is 85.75361665982807
At time: 1041.1943514347076 and batch: 1250, loss is 4.486166639328003 and perplexity is 88.78046520150406
At time: 1042.2181956768036 and batch: 1300, loss is 4.481560697555542 and perplexity is 88.37248782952341
At time: 1043.2445061206818 and batch: 1350, loss is 4.4609356784820555 and perplexity is 86.56847146902557
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.753309326171875 and perplexity of 115.96742424250735
Finished 35 epochs...
Completing Train Step...
At time: 1046.4279654026031 and batch: 50, loss is 4.597151575088501 and perplexity is 99.20134524025045
At time: 1047.4657571315765 and batch: 100, loss is 4.6063367366790775 and perplexity is 100.11672313759023
At time: 1048.492841720581 and batch: 150, loss is 4.581507291793823 and perplexity is 97.66148768176679
At time: 1049.514788866043 and batch: 200, loss is 4.577520370483398 and perplexity is 97.27289417592722
At time: 1050.5376279354095 and batch: 250, loss is 4.553516445159912 and perplexity is 94.96576375867656
At time: 1051.562031507492 and batch: 300, loss is 4.553736486434937 and perplexity is 94.98666244562027
At time: 1052.5888843536377 and batch: 350, loss is 4.5719085216522215 and perplexity is 96.72854223743435
At time: 1053.6205730438232 and batch: 400, loss is 4.576017093658447 and perplexity is 97.12677594400951
At time: 1054.6589014530182 and batch: 450, loss is 4.531675224304199 and perplexity is 92.91408270849219
At time: 1055.696658372879 and batch: 500, loss is 4.592001667022705 and perplexity is 98.6917806638242
At time: 1056.7218182086945 and batch: 550, loss is 4.585613994598389 and perplexity is 98.06337904649997
At time: 1057.746232509613 and batch: 600, loss is 4.552871484756469 and perplexity is 94.9045343487645
At time: 1058.7725954055786 and batch: 650, loss is 4.548073482513428 and perplexity is 94.45027282544417
At time: 1059.7969315052032 and batch: 700, loss is 4.579826288223266 and perplexity is 97.49745627958052
At time: 1060.8218834400177 and batch: 750, loss is 4.545038528442383 and perplexity is 94.16405513389
At time: 1061.8459708690643 and batch: 800, loss is 4.525372667312622 and perplexity is 92.33032791317042
At time: 1062.8707909584045 and batch: 850, loss is 4.490657138824463 and perplexity is 89.18003028777443
At time: 1063.8966085910797 and batch: 900, loss is 4.529865236282348 and perplexity is 92.74606143584462
At time: 1064.9223153591156 and batch: 950, loss is 4.505340423583984 and perplexity is 90.49914684948978
At time: 1065.9466602802277 and batch: 1000, loss is 4.505402345657348 and perplexity is 90.50475091780635
At time: 1066.9709730148315 and batch: 1050, loss is 4.470148038864136 and perplexity is 87.36965616077116
At time: 1067.9969234466553 and batch: 1100, loss is 4.441344680786133 and perplexity is 84.88901358700889
At time: 1069.0209753513336 and batch: 1150, loss is 4.464007425308227 and perplexity is 86.83479672898093
At time: 1070.0457150936127 and batch: 1200, loss is 4.4511041164398195 and perplexity is 85.72153833073175
At time: 1071.072599887848 and batch: 1250, loss is 4.48572904586792 and perplexity is 88.74162394950751
At time: 1072.0987861156464 and batch: 1300, loss is 4.481169509887695 and perplexity is 88.33792436294924
At time: 1073.1240103244781 and batch: 1350, loss is 4.460253810882568 and perplexity is 86.50946335334106
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.753015543619791 and perplexity of 115.9333600406339
Finished 36 epochs...
Completing Train Step...
At time: 1076.3942503929138 and batch: 50, loss is 4.596015043258667 and perplexity is 99.08866379897421
At time: 1077.4203383922577 and batch: 100, loss is 4.605220460891724 and perplexity is 100.00502761674367
At time: 1078.444444179535 and batch: 150, loss is 4.580262823104858 and perplexity is 97.54002661115435
At time: 1079.468321800232 and batch: 200, loss is 4.576311244964599 and perplexity is 97.15535011437449
At time: 1080.4940893650055 and batch: 250, loss is 4.552370471954346 and perplexity is 94.85699787126244
At time: 1081.5180323123932 and batch: 300, loss is 4.552704133987427 and perplexity is 94.88865333084296
At time: 1082.5426306724548 and batch: 350, loss is 4.570966777801513 and perplexity is 96.63749160750896
At time: 1083.567718744278 and batch: 400, loss is 4.574979286193848 and perplexity is 97.02602933775472
At time: 1084.5920383930206 and batch: 450, loss is 4.530645503997802 and perplexity is 92.81845643338525
At time: 1085.6168081760406 and batch: 500, loss is 4.59100022315979 and perplexity is 98.59299585773303
At time: 1086.6411068439484 and batch: 550, loss is 4.584623689651489 and perplexity is 97.9663144668199
At time: 1087.6653320789337 and batch: 600, loss is 4.552098884582519 and perplexity is 94.83123940650644
At time: 1088.697228193283 and batch: 650, loss is 4.5471998310089115 and perplexity is 94.36779223737939
At time: 1089.7250757217407 and batch: 700, loss is 4.5791006183624265 and perplexity is 97.42673097876313
At time: 1090.7578432559967 and batch: 750, loss is 4.544292936325073 and perplexity is 94.09387332340178
At time: 1091.7859156131744 and batch: 800, loss is 4.524795255661011 and perplexity is 92.27703069473452
At time: 1092.8187165260315 and batch: 850, loss is 4.490122804641723 and perplexity is 89.13239107793653
At time: 1093.843300819397 and batch: 900, loss is 4.529167346954345 and perplexity is 92.68135753006307
At time: 1094.8773410320282 and batch: 950, loss is 4.504695978164673 and perplexity is 90.44084387741049
At time: 1095.9063863754272 and batch: 1000, loss is 4.504875001907348 and perplexity is 90.45703638515057
At time: 1096.9340579509735 and batch: 1050, loss is 4.469642667770386 and perplexity is 87.32551321729996
At time: 1098.024010181427 and batch: 1100, loss is 4.440842943191528 and perplexity is 84.84643226074276
At time: 1099.0531013011932 and batch: 1150, loss is 4.463638467788696 and perplexity is 86.80276428743929
At time: 1100.085431098938 and batch: 1200, loss is 4.450703239440918 and perplexity is 85.68718142461128
At time: 1101.1097362041473 and batch: 1250, loss is 4.485274772644043 and perplexity is 88.70132016106297
At time: 1102.1368944644928 and batch: 1300, loss is 4.480763168334961 and perplexity is 88.30203628550062
At time: 1103.1716504096985 and batch: 1350, loss is 4.4595707988739015 and perplexity is 86.45039652498022
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.752660319010417 and perplexity of 115.89218497173184
Finished 37 epochs...
Completing Train Step...
At time: 1106.4499554634094 and batch: 50, loss is 4.594906702041626 and perplexity is 98.97890058752618
At time: 1107.502381324768 and batch: 100, loss is 4.604133586883545 and perplexity is 99.89639379787097
At time: 1108.527141571045 and batch: 150, loss is 4.5790289115905765 and perplexity is 97.4197450728641
At time: 1109.5522632598877 and batch: 200, loss is 4.575123767852784 and perplexity is 97.04004883218889
At time: 1110.5778226852417 and batch: 250, loss is 4.55127781867981 and perplexity is 94.75340866577426
At time: 1111.6129052639008 and batch: 300, loss is 4.551728811264038 and perplexity is 94.79615138801375
At time: 1112.658293247223 and batch: 350, loss is 4.570065364837647 and perplexity is 96.55042056915555
At time: 1113.6941411495209 and batch: 400, loss is 4.5739913749694825 and perplexity is 96.93022356590697
At time: 1114.7187333106995 and batch: 450, loss is 4.5296347713470455 and perplexity is 92.72468918366816
At time: 1115.7437562942505 and batch: 500, loss is 4.589977960586548 and perplexity is 98.49225942639825
At time: 1116.774632692337 and batch: 550, loss is 4.583680009841919 and perplexity is 97.87390924116984
At time: 1117.7995579242706 and batch: 600, loss is 4.551342658996582 and perplexity is 94.75955270599596
At time: 1118.833590745926 and batch: 650, loss is 4.546352262496948 and perplexity is 94.28784295416912
At time: 1119.8611612319946 and batch: 700, loss is 4.578379068374634 and perplexity is 97.35645807796895
At time: 1120.8870224952698 and batch: 750, loss is 4.543552265167237 and perplexity is 94.02420650858713
At time: 1121.9123179912567 and batch: 800, loss is 4.524220199584961 and perplexity is 92.22398148215157
At time: 1122.939602613449 and batch: 850, loss is 4.489569463729858 and perplexity is 89.08308412241672
At time: 1124.0298671722412 and batch: 900, loss is 4.528495111465454 and perplexity is 92.61907476905935
At time: 1125.0567798614502 and batch: 950, loss is 4.504054288864136 and perplexity is 90.3828275717749
At time: 1126.084049463272 and batch: 1000, loss is 4.504312810897827 and perplexity is 90.40619654473652
At time: 1127.1097569465637 and batch: 1050, loss is 4.469145107269287 and perplexity is 87.282074298826
At time: 1128.1371545791626 and batch: 1100, loss is 4.440363149642945 and perplexity is 84.80573325426484
At time: 1129.162653207779 and batch: 1150, loss is 4.463270664215088 and perplexity is 86.77084379113144
At time: 1130.1878435611725 and batch: 1200, loss is 4.4502822780609135 and perplexity is 85.65111802165261
At time: 1131.2146990299225 and batch: 1250, loss is 4.484793462753296 and perplexity is 88.65863761093784
At time: 1132.24001455307 and batch: 1300, loss is 4.480346269607544 and perplexity is 88.26523095152643
At time: 1133.2656359672546 and batch: 1350, loss is 4.458932142257691 and perplexity is 86.3952020343049
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.752305501302083 and perplexity of 115.85107166654208
Finished 38 epochs...
Completing Train Step...
At time: 1136.4847865104675 and batch: 50, loss is 4.593838434219361 and perplexity is 98.87322107000948
At time: 1137.5385482311249 and batch: 100, loss is 4.603071250915527 and perplexity is 99.79032661513108
At time: 1138.5639326572418 and batch: 150, loss is 4.577801780700684 and perplexity is 97.30027161417797
At time: 1139.5905883312225 and batch: 200, loss is 4.57397232055664 and perplexity is 96.9283766350064
At time: 1140.6161623001099 and batch: 250, loss is 4.550191831588745 and perplexity is 94.65056354147522
At time: 1141.6446568965912 and batch: 300, loss is 4.550748243331909 and perplexity is 94.70324288086918
At time: 1142.6702678203583 and batch: 350, loss is 4.569166250228882 and perplexity is 96.46364968986755
At time: 1143.6963725090027 and batch: 400, loss is 4.573001890182495 and perplexity is 96.83436001987097
At time: 1144.7225425243378 and batch: 450, loss is 4.528633117675781 and perplexity is 92.63185765861101
At time: 1145.747339963913 and batch: 500, loss is 4.588949556350708 and perplexity is 98.39102163521586
At time: 1146.7734928131104 and batch: 550, loss is 4.582743091583252 and perplexity is 97.78225233277503
At time: 1147.796228647232 and batch: 600, loss is 4.550600318908692 and perplexity is 94.68923499436903
At time: 1148.8213455677032 and batch: 650, loss is 4.545521516799926 and perplexity is 94.20954626117683
At time: 1149.8458487987518 and batch: 700, loss is 4.577670307159424 and perplexity is 97.28748004379825
At time: 1150.917860031128 and batch: 750, loss is 4.542813682556153 and perplexity is 93.95478750362959
At time: 1151.9438285827637 and batch: 800, loss is 4.523640041351318 and perplexity is 92.17049249749314
At time: 1152.9708414077759 and batch: 850, loss is 4.48901707649231 and perplexity is 89.03388935219856
At time: 1153.9956781864166 and batch: 900, loss is 4.527823600769043 and perplexity is 92.55690094718976
At time: 1155.0226151943207 and batch: 950, loss is 4.503409976959229 and perplexity is 90.32461159660811
At time: 1156.0495989322662 and batch: 1000, loss is 4.503727436065674 and perplexity is 90.35329051904726
At time: 1157.0762586593628 and batch: 1050, loss is 4.4686261081695555 and perplexity is 87.23678673396148
At time: 1158.1027119159698 and batch: 1100, loss is 4.439867887496948 and perplexity is 84.76374258387361
At time: 1159.1276924610138 and batch: 1150, loss is 4.462912244796753 and perplexity is 86.7397490085912
At time: 1160.1530220508575 and batch: 1200, loss is 4.449855337142944 and perplexity is 85.61455785976923
At time: 1161.1791543960571 and batch: 1250, loss is 4.484310750961304 and perplexity is 88.61585136864372
At time: 1162.2049071788788 and batch: 1300, loss is 4.479922866821289 and perplexity is 88.22786711734601
At time: 1163.2298200130463 and batch: 1350, loss is 4.45827431678772 and perplexity is 86.33838775891095
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.751997477213542 and perplexity of 115.8153922411288
Finished 39 epochs...
Completing Train Step...
At time: 1166.3817596435547 and batch: 50, loss is 4.592802200317383 and perplexity is 98.77081835208615
At time: 1167.406495809555 and batch: 100, loss is 4.6020361518859865 and perplexity is 99.68708718562864
At time: 1168.4325783252716 and batch: 150, loss is 4.576632499694824 and perplexity is 97.1865667441419
At time: 1169.458112001419 and batch: 200, loss is 4.572834568023682 and perplexity is 96.818158841151
At time: 1170.4846360683441 and batch: 250, loss is 4.549170322418213 and perplexity is 94.55392648904245
At time: 1171.5109415054321 and batch: 300, loss is 4.5497826480865475 and perplexity is 94.6118420150455
At time: 1172.536874294281 and batch: 350, loss is 4.568232431411743 and perplexity is 96.37361216452778
At time: 1173.5613622665405 and batch: 400, loss is 4.572009086608887 and perplexity is 96.73827022823204
At time: 1174.5902738571167 and batch: 450, loss is 4.527652006149292 and perplexity is 92.54102004354421
At time: 1175.6148705482483 and batch: 500, loss is 4.587908554077148 and perplexity is 98.28864965197431
At time: 1176.6829359531403 and batch: 550, loss is 4.58180832862854 and perplexity is 97.69089181253342
At time: 1177.7083060741425 and batch: 600, loss is 4.549856967926026 and perplexity is 94.61887381325461
At time: 1178.7323422431946 and batch: 650, loss is 4.5446914958953855 and perplexity is 94.13138281150879
At time: 1179.7568616867065 and batch: 700, loss is 4.5769609928131105 and perplexity is 97.21849710667227
At time: 1180.7826328277588 and batch: 750, loss is 4.542082843780517 and perplexity is 93.88614678746904
At time: 1181.8072624206543 and batch: 800, loss is 4.5230296611785885 and perplexity is 92.11425062257075
At time: 1182.8318343162537 and batch: 850, loss is 4.488466606140137 and perplexity is 88.98489232271481
At time: 1183.8572931289673 and batch: 900, loss is 4.527111835479737 and perplexity is 92.49104559736608
At time: 1184.8821201324463 and batch: 950, loss is 4.5027617168426515 and perplexity is 90.26607672832486
At time: 1185.9071061611176 and batch: 1000, loss is 4.503117790222168 and perplexity is 90.2982237983395
At time: 1186.9323015213013 and batch: 1050, loss is 4.468079071044922 and perplexity is 87.18907802339196
At time: 1187.9565587043762 and batch: 1100, loss is 4.439389238357544 and perplexity is 84.72318019978266
At time: 1188.9812500476837 and batch: 1150, loss is 4.462546367645263 and perplexity is 86.70801872135054
At time: 1190.0075755119324 and batch: 1200, loss is 4.449399328231811 and perplexity is 85.57552575863181
At time: 1191.0329270362854 and batch: 1250, loss is 4.483796701431275 and perplexity is 88.57031013812149
At time: 1192.058170557022 and batch: 1300, loss is 4.47948920249939 and perplexity is 88.18961413425646
At time: 1193.0831263065338 and batch: 1350, loss is 4.457636375427246 and perplexity is 86.28332649515899
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.751728108723959 and perplexity of 115.7841994252198
Finished 40 epochs...
Completing Train Step...
At time: 1196.2076029777527 and batch: 50, loss is 4.591762456893921 and perplexity is 98.66817541368168
At time: 1197.230764389038 and batch: 100, loss is 4.601032609939575 and perplexity is 99.58709719259006
At time: 1198.2560966014862 and batch: 150, loss is 4.575511770248413 and perplexity is 97.07770790904135
At time: 1199.2832913398743 and batch: 200, loss is 4.571770515441894 and perplexity is 96.7151940189794
At time: 1200.3097577095032 and batch: 250, loss is 4.548184013366699 and perplexity is 94.46071307166528
At time: 1201.336401939392 and batch: 300, loss is 4.548833017349243 and perplexity is 94.52203834866471
At time: 1202.3876872062683 and batch: 350, loss is 4.567270736694336 and perplexity is 96.28097472242084
At time: 1203.4127020835876 and batch: 400, loss is 4.571043500900268 and perplexity is 96.64490621975338
At time: 1204.437266111374 and batch: 450, loss is 4.526670932769775 and perplexity is 92.45027503330161
At time: 1205.461256980896 and batch: 500, loss is 4.586857328414917 and perplexity is 98.18538039031309
At time: 1206.4860816001892 and batch: 550, loss is 4.5809056854248045 and perplexity is 97.60275157854802
At time: 1207.5116028785706 and batch: 600, loss is 4.549160747528076 and perplexity is 94.55302114991859
At time: 1208.5357336997986 and batch: 650, loss is 4.543868799209594 and perplexity is 94.05397308157106
At time: 1209.5606653690338 and batch: 700, loss is 4.57625262260437 and perplexity is 97.14965480537975
At time: 1210.5839006900787 and batch: 750, loss is 4.541351175308227 and perplexity is 93.81747837819832
At time: 1211.6085526943207 and batch: 800, loss is 4.522389698028564 and perplexity is 92.05531975538318
At time: 1212.6343204975128 and batch: 850, loss is 4.487933912277222 and perplexity is 88.93750323973977
At time: 1213.6588270664215 and batch: 900, loss is 4.526388950347901 and perplexity is 92.42420935604885
At time: 1214.683049440384 and batch: 950, loss is 4.502097473144532 and perplexity is 90.20613796488085
At time: 1215.7079281806946 and batch: 1000, loss is 4.502493619918823 and perplexity is 90.24187991451856
At time: 1216.7326610088348 and batch: 1050, loss is 4.467516813278198 and perplexity is 87.14006906622431
At time: 1217.757042646408 and batch: 1100, loss is 4.438915376663208 and perplexity is 84.68304264064062
At time: 1218.7823135852814 and batch: 1150, loss is 4.46218994140625 and perplexity is 86.67711921536988
At time: 1219.806248664856 and batch: 1200, loss is 4.448947591781616 and perplexity is 85.53687690460734
At time: 1220.8313448429108 and batch: 1250, loss is 4.483301639556885 and perplexity is 88.52647320626134
At time: 1221.855972290039 and batch: 1300, loss is 4.479046869277954 and perplexity is 88.15061356439902
At time: 1222.8796164989471 and batch: 1350, loss is 4.456989021301269 and perplexity is 86.22748870311189
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.751484375 and perplexity of 115.75598234998446
Finished 41 epochs...
Completing Train Step...
At time: 1225.9585888385773 and batch: 50, loss is 4.590751276016236 and perplexity is 98.56845446792094
At time: 1227.008897304535 and batch: 100, loss is 4.600076627731323 and perplexity is 99.49193919142763
At time: 1228.032387495041 and batch: 150, loss is 4.574397010803223 and perplexity is 96.96954991350641
At time: 1229.0840837955475 and batch: 200, loss is 4.570684089660644 and perplexity is 96.61017719558025
At time: 1230.1079914569855 and batch: 250, loss is 4.5472234439849855 and perplexity is 94.3700205681083
At time: 1231.1327631473541 and batch: 300, loss is 4.547851848602295 and perplexity is 94.42934176167272
At time: 1232.1573178768158 and batch: 350, loss is 4.566329355239868 and perplexity is 96.19038024706892
At time: 1233.1819052696228 and batch: 400, loss is 4.570080652236938 and perplexity is 96.55189658526874
At time: 1234.2108867168427 and batch: 450, loss is 4.525710859298706 and perplexity is 92.36155857082458
At time: 1235.236746788025 and batch: 500, loss is 4.585836172103882 and perplexity is 98.08516894395963
At time: 1236.2605600357056 and batch: 550, loss is 4.580016880035401 and perplexity is 97.51604026737303
At time: 1237.284993171692 and batch: 600, loss is 4.548456230163574 and perplexity is 94.48643036458895
At time: 1238.3087708950043 and batch: 650, loss is 4.5430317211151126 and perplexity is 93.97527550361008
At time: 1239.3337700366974 and batch: 700, loss is 4.57552170753479 and perplexity is 97.07867260281887
At time: 1240.3575155735016 and batch: 750, loss is 4.54062328338623 and perplexity is 93.74921424101572
At time: 1241.3808157444 and batch: 800, loss is 4.521715135574341 and perplexity is 91.99324363242945
At time: 1242.4061424732208 and batch: 850, loss is 4.487415056228638 and perplexity is 88.89136944767141
At time: 1243.4307119846344 and batch: 900, loss is 4.525649995803833 and perplexity is 92.355937294645
At time: 1244.4549260139465 and batch: 950, loss is 4.501426267623901 and perplexity is 90.14561142223123
At time: 1245.480455160141 and batch: 1000, loss is 4.50185658454895 and perplexity is 90.18441095199351
At time: 1246.5043046474457 and batch: 1050, loss is 4.466920833587647 and perplexity is 87.08815082747228
At time: 1247.5285573005676 and batch: 1100, loss is 4.438456449508667 and perplexity is 84.64418820920247
At time: 1248.553683757782 and batch: 1150, loss is 4.461809310913086 and perplexity is 86.64413353881231
At time: 1249.578917503357 and batch: 1200, loss is 4.44847710609436 and perplexity is 85.49664249389053
At time: 1250.6051604747772 and batch: 1250, loss is 4.482787876129151 and perplexity is 88.48100322334899
At time: 1251.631183385849 and batch: 1300, loss is 4.478587532043457 and perplexity is 88.11013200340108
At time: 1252.6564493179321 and batch: 1350, loss is 4.456372280120849 and perplexity is 86.17432505573494
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.751246337890625 and perplexity of 115.72843140975613
Finished 42 epochs...
Completing Train Step...
At time: 1255.7606959342957 and batch: 50, loss is 4.589745674133301 and perplexity is 98.4693836657513
At time: 1256.8118360042572 and batch: 100, loss is 4.59914716720581 and perplexity is 99.39950832341826
At time: 1257.837996006012 and batch: 150, loss is 4.573303327560425 and perplexity is 96.86355391529345
At time: 1258.862791776657 and batch: 200, loss is 4.5696159362792965 and perplexity is 96.50703780228845
At time: 1259.8880043029785 and batch: 250, loss is 4.546278009414673 and perplexity is 94.28084205113119
At time: 1260.911859512329 and batch: 300, loss is 4.546888933181763 and perplexity is 94.3384580560229
At time: 1261.9352893829346 and batch: 350, loss is 4.565368165969849 and perplexity is 96.09796750587887
At time: 1262.9590663909912 and batch: 400, loss is 4.5691606807708744 and perplexity is 96.46311244111743
At time: 1263.9841663837433 and batch: 450, loss is 4.524758005142212 and perplexity is 92.27359339148903
At time: 1265.0085716247559 and batch: 500, loss is 4.584808683395385 and perplexity is 97.98443929854736
At time: 1266.0336210727692 and batch: 550, loss is 4.579171667098999 and perplexity is 97.43365327081467
At time: 1267.0575635433197 and batch: 600, loss is 4.547716884613037 and perplexity is 94.4165980609953
At time: 1268.0818500518799 and batch: 650, loss is 4.542200021743774 and perplexity is 93.8971488195129
At time: 1269.1056139469147 and batch: 700, loss is 4.574778232574463 and perplexity is 97.00652386427053
At time: 1270.1309733390808 and batch: 750, loss is 4.539979763031006 and perplexity is 93.68890412084164
At time: 1271.1546230316162 and batch: 800, loss is 4.520951566696167 and perplexity is 91.92302726551728
At time: 1272.1808083057404 and batch: 850, loss is 4.486915321350097 and perplexity is 88.84695842774923
At time: 1273.2036855220795 and batch: 900, loss is 4.524922914505005 and perplexity is 92.28881142574151
At time: 1274.2275395393372 and batch: 950, loss is 4.500770463943481 and perplexity is 90.08651297909314
At time: 1275.2524211406708 and batch: 1000, loss is 4.5012289237976075 and perplexity is 90.12782349757586
At time: 1276.278048992157 and batch: 1050, loss is 4.46633547782898 and perplexity is 87.03718819396441
At time: 1277.302754163742 and batch: 1100, loss is 4.4380134582519535 and perplexity is 84.6066998780087
At time: 1278.3286950588226 and batch: 1150, loss is 4.461436986923218 and perplexity is 86.61187985409734
At time: 1279.352722644806 and batch: 1200, loss is 4.44800952911377 and perplexity is 85.45667557647603
At time: 1280.402399301529 and batch: 1250, loss is 4.4822955894470216 and perplexity is 88.43745592359802
At time: 1281.4279582500458 and batch: 1300, loss is 4.4781178283691405 and perplexity is 88.06875606862954
At time: 1282.45183634758 and batch: 1350, loss is 4.455753240585327 and perplexity is 86.12099624960123
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.750987548828125 and perplexity of 115.69848603242215
Finished 43 epochs...
Completing Train Step...
At time: 1285.557514667511 and batch: 50, loss is 4.58874402999878 and perplexity is 98.37080176540589
At time: 1286.58225107193 and batch: 100, loss is 4.598198728561401 and perplexity is 99.3052786810698
At time: 1287.6084215641022 and batch: 150, loss is 4.5722003746032716 and perplexity is 96.75677686791683
At time: 1288.632225036621 and batch: 200, loss is 4.568542585372925 and perplexity is 96.40350745792625
At time: 1289.65771818161 and batch: 250, loss is 4.545328912734985 and perplexity is 94.19140286691247
At time: 1290.682326078415 and batch: 300, loss is 4.5459152030944825 and perplexity is 94.24664257003126
At time: 1291.7072505950928 and batch: 350, loss is 4.564425668716431 and perplexity is 96.00743810400326
At time: 1292.730792760849 and batch: 400, loss is 4.568249578475952 and perplexity is 96.37526470321173
At time: 1293.7560379505157 and batch: 450, loss is 4.523823795318603 and perplexity is 92.1874307473438
At time: 1294.7966437339783 and batch: 500, loss is 4.583819904327393 and perplexity is 97.88760221910819
At time: 1295.827853679657 and batch: 550, loss is 4.57832592010498 and perplexity is 97.35128388818333
At time: 1296.8527400493622 and batch: 600, loss is 4.546931800842285 and perplexity is 94.34250221169812
At time: 1297.8781487941742 and batch: 650, loss is 4.541362257003784 and perplexity is 93.81851804069221
At time: 1298.904358625412 and batch: 700, loss is 4.574041299819946 and perplexity is 96.93506291362475
At time: 1299.9295525550842 and batch: 750, loss is 4.539309940338135 and perplexity is 93.62617017944555
At time: 1300.9615952968597 and batch: 800, loss is 4.5202185249328615 and perplexity is 91.85566853891835
At time: 1301.9966213703156 and batch: 850, loss is 4.486432952880859 and perplexity is 88.80411179118002
At time: 1303.0270111560822 and batch: 900, loss is 4.524212141036987 and perplexity is 92.22323829376698
At time: 1304.052218914032 and batch: 950, loss is 4.500137300491333 and perplexity is 90.02949154539218
At time: 1305.0858130455017 and batch: 1000, loss is 4.500595417022705 and perplexity is 90.0707449925017
At time: 1306.1175727844238 and batch: 1050, loss is 4.465765295028686 and perplexity is 86.98757523184325
At time: 1307.2123818397522 and batch: 1100, loss is 4.4375879764556885 and perplexity is 84.57070892465926
At time: 1308.2502028942108 and batch: 1150, loss is 4.46104621887207 and perplexity is 86.57804131054199
At time: 1309.289888381958 and batch: 1200, loss is 4.447529306411743 and perplexity is 85.41564719299357
At time: 1310.3137426376343 and batch: 1250, loss is 4.481780958175659 and perplexity is 88.3919549523356
At time: 1311.3398759365082 and batch: 1300, loss is 4.477639169692993 and perplexity is 88.02661128172838
At time: 1312.364562034607 and batch: 1350, loss is 4.455160970687866 and perplexity is 86.07000447791953
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.750734456380209 and perplexity of 115.66920732463825
Finished 44 epochs...
Completing Train Step...
At time: 1315.4712827205658 and batch: 50, loss is 4.5877501583099365 and perplexity is 98.2730823788321
At time: 1316.4960238933563 and batch: 100, loss is 4.5972488975524906 and perplexity is 99.2110002294164
At time: 1317.5233404636383 and batch: 150, loss is 4.571110973358154 and perplexity is 96.65142730911265
At time: 1318.5480470657349 and batch: 200, loss is 4.5674768161773684 and perplexity is 96.30081830052438
At time: 1319.5734839439392 and batch: 250, loss is 4.544384899139405 and perplexity is 94.1025268586996
At time: 1320.598976612091 and batch: 300, loss is 4.54495379447937 and perplexity is 94.1560765783572
At time: 1321.623343706131 and batch: 350, loss is 4.563526792526245 and perplexity is 95.92117807816057
At time: 1322.6481049060822 and batch: 400, loss is 4.567339010238648 and perplexity is 96.28754839021613
At time: 1323.6740431785583 and batch: 450, loss is 4.522885961532593 and perplexity is 92.10101478838023
At time: 1324.698341369629 and batch: 500, loss is 4.582867727279663 and perplexity is 97.7944402514003
At time: 1325.723159790039 and batch: 550, loss is 4.577475385665894 and perplexity is 97.26851847095543
At time: 1326.7517035007477 and batch: 600, loss is 4.546106910705566 and perplexity is 94.26471210070895
At time: 1327.7797846794128 and batch: 650, loss is 4.540520286560058 and perplexity is 93.73955886673777
At time: 1328.8117609024048 and batch: 700, loss is 4.573314809799195 and perplexity is 96.86466613213292
At time: 1329.8384499549866 and batch: 750, loss is 4.538627119064331 and perplexity is 93.56226206005707
At time: 1330.8668377399445 and batch: 800, loss is 4.519526510238648 and perplexity is 91.79212505559052
At time: 1331.893346786499 and batch: 850, loss is 4.4860060596466065 and perplexity is 88.76621000726568
At time: 1332.945185661316 and batch: 900, loss is 4.523494234085083 and perplexity is 92.15705434966816
At time: 1333.9726638793945 and batch: 950, loss is 4.499517669677735 and perplexity is 89.97372377779597
At time: 1334.998369216919 and batch: 1000, loss is 4.499940767288208 and perplexity is 90.01179949963719
At time: 1336.0241494178772 and batch: 1050, loss is 4.465185813903808 and perplexity is 86.93718217621995
At time: 1337.052390575409 and batch: 1100, loss is 4.4371318340301515 and perplexity is 84.53214143316426
At time: 1338.081018447876 and batch: 1150, loss is 4.460585498809815 and perplexity is 86.53816225720482
At time: 1339.1062529087067 and batch: 1200, loss is 4.447077054977417 and perplexity is 85.37702657780916
At time: 1340.1335673332214 and batch: 1250, loss is 4.481282520294189 and perplexity is 88.34790803180896
At time: 1341.1603343486786 and batch: 1300, loss is 4.477149238586426 and perplexity is 87.983494869554
At time: 1342.1863384246826 and batch: 1350, loss is 4.454561920166015 and perplexity is 86.01845963734459
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.750452473958333 and perplexity of 115.63659523965387
Finished 45 epochs...
Completing Train Step...
At time: 1345.2812132835388 and batch: 50, loss is 4.586748294830322 and perplexity is 98.17467546994285
At time: 1346.3340692520142 and batch: 100, loss is 4.596283845901489 and perplexity is 99.11530267381663
At time: 1347.3608238697052 and batch: 150, loss is 4.5700368976593015 and perplexity is 96.5476720902348
At time: 1348.3895645141602 and batch: 200, loss is 4.566414737701416 and perplexity is 96.1985935691435
At time: 1349.4150214195251 and batch: 250, loss is 4.54347071647644 and perplexity is 94.01653927027404
At time: 1350.4414744377136 and batch: 300, loss is 4.544019498825073 and perplexity is 94.06814804720283
At time: 1351.4673700332642 and batch: 350, loss is 4.562621526718139 and perplexity is 95.83438320751496
At time: 1352.4938778877258 and batch: 400, loss is 4.566440391540527 and perplexity is 96.20106146404096
At time: 1353.5259327888489 and batch: 450, loss is 4.521952028274536 and perplexity is 92.01503874176252
At time: 1354.5571265220642 and batch: 500, loss is 4.581916437149048 and perplexity is 97.70145360121379
At time: 1355.5830318927765 and batch: 550, loss is 4.5766260623931885 and perplexity is 97.18594112691048
At time: 1356.6086332798004 and batch: 600, loss is 4.545270299911499 and perplexity is 94.18588220463468
At time: 1357.6358404159546 and batch: 650, loss is 4.539677982330322 and perplexity is 93.66063488347942
At time: 1358.7075304985046 and batch: 700, loss is 4.572600326538086 and perplexity is 96.79548266774536
At time: 1359.734875679016 and batch: 750, loss is 4.537931842803955 and perplexity is 93.4972330495629
At time: 1360.7624654769897 and batch: 800, loss is 4.518831806182861 and perplexity is 91.72837883896649
At time: 1361.7886126041412 and batch: 850, loss is 4.485610942840577 and perplexity is 88.73114391394184
At time: 1362.8146572113037 and batch: 900, loss is 4.522789449691772 and perplexity is 92.09212637882685
At time: 1363.839988231659 and batch: 950, loss is 4.4988913822174075 and perplexity is 89.91739200461787
At time: 1364.8683621883392 and batch: 1000, loss is 4.499295301437378 and perplexity is 89.95371870349021
At time: 1365.8944325447083 and batch: 1050, loss is 4.464617166519165 and perplexity is 86.88775962828028
At time: 1366.919501543045 and batch: 1100, loss is 4.436682138442993 and perplexity is 84.49413624821118
At time: 1367.9466049671173 and batch: 1150, loss is 4.460057668685913 and perplexity is 86.49249686114439
At time: 1368.9723680019379 and batch: 1200, loss is 4.446636161804199 and perplexity is 85.3393927265051
At time: 1369.9986157417297 and batch: 1250, loss is 4.48076473236084 and perplexity is 88.30217439227857
At time: 1371.032330751419 and batch: 1300, loss is 4.47662914276123 and perplexity is 87.93774691887653
At time: 1372.0600700378418 and batch: 1350, loss is 4.453938856124878 and perplexity is 85.96488132136484
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.750142008463541 and perplexity of 115.60069963935773
Finished 46 epochs...
Completing Train Step...
At time: 1375.2943170070648 and batch: 50, loss is 4.585760307312012 and perplexity is 98.07772801528799
At time: 1376.3659358024597 and batch: 100, loss is 4.595312690734863 and perplexity is 99.01909306032647
At time: 1377.3929946422577 and batch: 150, loss is 4.568970546722412 and perplexity is 96.44477326252814
At time: 1378.4186341762543 and batch: 200, loss is 4.565339612960815 and perplexity is 96.09522365891729
At time: 1379.4442172050476 and batch: 250, loss is 4.5425536251068115 and perplexity is 93.93035703803797
At time: 1380.4722611904144 and batch: 300, loss is 4.543048992156982 and perplexity is 93.97689856854397
At time: 1381.4984395503998 and batch: 350, loss is 4.561765661239624 and perplexity is 95.7523969568783
At time: 1382.5245883464813 and batch: 400, loss is 4.565534677505493 and perplexity is 96.11397025830502
At time: 1383.5518634319305 and batch: 450, loss is 4.520991659164428 and perplexity is 91.92671276045024
At time: 1384.5772988796234 and batch: 500, loss is 4.580988883972168 and perplexity is 97.61087232351045
At time: 1385.6492958068848 and batch: 550, loss is 4.575828590393066 and perplexity is 97.10846895510593
At time: 1386.6753814220428 and batch: 600, loss is 4.544401617050171 and perplexity is 94.10410006949684
At time: 1387.7070512771606 and batch: 650, loss is 4.538827562332154 and perplexity is 93.58101786528393
At time: 1388.7475309371948 and batch: 700, loss is 4.57188138961792 and perplexity is 96.7259178309113
At time: 1389.7763137817383 and batch: 750, loss is 4.537219867706299 and perplexity is 93.43068903958186
At time: 1390.8048589229584 and batch: 800, loss is 4.518106689453125 and perplexity is 91.66188916617915
At time: 1391.8361864089966 and batch: 850, loss is 4.485255041122437 and perplexity is 88.69956996631471
At time: 1392.8615272045135 and batch: 900, loss is 4.5221022605896 and perplexity is 92.02886341248353
At time: 1393.8941249847412 and batch: 950, loss is 4.49827470779419 and perplexity is 89.86195934247534
At time: 1394.9195766448975 and batch: 1000, loss is 4.498628215789795 and perplexity is 89.89373187919567
At time: 1395.945806503296 and batch: 1050, loss is 4.464018878936767 and perplexity is 86.83579130818276
At time: 1396.972051858902 and batch: 1100, loss is 4.436187629699707 and perplexity is 84.45236348842874
At time: 1397.9968519210815 and batch: 1150, loss is 4.459422626495361 and perplexity is 86.43758791306605
At time: 1399.039410352707 and batch: 1200, loss is 4.446200914382935 and perplexity is 85.30225705807683
At time: 1400.069783449173 and batch: 1250, loss is 4.480216226577759 and perplexity is 88.25375341977146
At time: 1401.0952215194702 and batch: 1300, loss is 4.476062822341919 and perplexity is 87.88796007615157
At time: 1402.1208562850952 and batch: 1350, loss is 4.45322018623352 and perplexity is 85.90312314397447
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.749850260416666 and perplexity of 115.56697828033008
Finished 47 epochs...
Completing Train Step...
At time: 1405.2580001354218 and batch: 50, loss is 4.5847807884216305 and perplexity is 97.98170606330667
At time: 1406.2845838069916 and batch: 100, loss is 4.594304704666138 and perplexity is 98.91933348056381
At time: 1407.3095364570618 and batch: 150, loss is 4.567898683547973 and perplexity is 96.3414530441615
At time: 1408.3341221809387 and batch: 200, loss is 4.564228868484497 and perplexity is 95.98854567699499
At time: 1409.3611822128296 and batch: 250, loss is 4.541671466827393 and perplexity is 93.84753213359691
At time: 1410.3875977993011 and batch: 300, loss is 4.542123775482178 and perplexity is 93.88998978586915
At time: 1411.4599905014038 and batch: 350, loss is 4.560833921432495 and perplexity is 95.6632221872982
At time: 1412.4855411052704 and batch: 400, loss is 4.564636344909668 and perplexity is 96.02766671635419
At time: 1413.5122170448303 and batch: 450, loss is 4.520039138793945 and perplexity is 91.83919238304273
At time: 1414.540410041809 and batch: 500, loss is 4.580073137283325 and perplexity is 97.521526405743
At time: 1415.5660781860352 and batch: 550, loss is 4.5750297260284425 and perplexity is 97.03092343805365
At time: 1416.5913333892822 and batch: 600, loss is 4.543568887710571 and perplexity is 94.02576944302426
At time: 1417.6178696155548 and batch: 650, loss is 4.537985172271728 and perplexity is 93.50221934019665
At time: 1418.6428904533386 and batch: 700, loss is 4.571197471618652 and perplexity is 96.65978785103052
At time: 1419.668716430664 and batch: 750, loss is 4.536516647338868 and perplexity is 93.36500977231194
At time: 1420.6948909759521 and batch: 800, loss is 4.517401552200317 and perplexity is 91.59727773610562
At time: 1421.7218759059906 and batch: 850, loss is 4.484811429977417 and perplexity is 88.66023057486059
At time: 1422.7467362880707 and batch: 900, loss is 4.521361541748047 and perplexity is 91.96072113963551
At time: 1423.7719247341156 and batch: 950, loss is 4.497691259384156 and perplexity is 89.809544817247
At time: 1424.7967100143433 and batch: 1000, loss is 4.4979556274414065 and perplexity is 89.83329073082515
At time: 1425.8230426311493 and batch: 1050, loss is 4.463420124053955 and perplexity is 86.78381351666522
At time: 1426.8485667705536 and batch: 1100, loss is 4.4356918621063235 and perplexity is 84.4105051202951
At time: 1427.8743801116943 and batch: 1150, loss is 4.458805379867553 and perplexity is 86.38425106609874
At time: 1428.900237083435 and batch: 1200, loss is 4.44568998336792 and perplexity is 85.25868462149761
At time: 1429.928169965744 and batch: 1250, loss is 4.479629735946656 and perplexity is 88.20200859564159
At time: 1430.9565308094025 and batch: 1300, loss is 4.475500516891479 and perplexity is 87.83855408910243
At time: 1431.983145236969 and batch: 1350, loss is 4.452576847076416 and perplexity is 85.84787607434549
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.749566650390625 and perplexity of 115.53420697396561
Finished 48 epochs...
Completing Train Step...
At time: 1435.1594095230103 and batch: 50, loss is 4.58381196975708 and perplexity is 97.886825526127
At time: 1436.1864240169525 and batch: 100, loss is 4.5933297252655025 and perplexity is 98.82293616842861
At time: 1437.236984014511 and batch: 150, loss is 4.566848964691162 and perplexity is 96.24037466543011
At time: 1438.261778831482 and batch: 200, loss is 4.563174409866333 and perplexity is 95.88738307302408
At time: 1439.289276599884 and batch: 250, loss is 4.5407352638244625 and perplexity is 93.75971290692199
At time: 1440.3233358860016 and batch: 300, loss is 4.541111574172974 and perplexity is 93.79500229662716
At time: 1441.3575866222382 and batch: 350, loss is 4.559935512542725 and perplexity is 95.57731609323854
At time: 1442.3814556598663 and batch: 400, loss is 4.56373969078064 and perplexity is 95.94160170353285
At time: 1443.405527830124 and batch: 450, loss is 4.519098234176636 and perplexity is 91.75282110281984
At time: 1444.4300773143768 and batch: 500, loss is 4.579145755767822 and perplexity is 97.43112866786507
At time: 1445.4557690620422 and batch: 550, loss is 4.57421721458435 and perplexity is 96.9521167223441
At time: 1446.4800879955292 and batch: 600, loss is 4.542785682678223 and perplexity is 93.95215681787815
At time: 1447.5057837963104 and batch: 650, loss is 4.5371857929229735 and perplexity is 93.42750546333701
At time: 1448.531895160675 and batch: 700, loss is 4.570517692565918 and perplexity is 96.59410288017071
At time: 1449.55592918396 and batch: 750, loss is 4.5357852554321285 and perplexity is 93.29674832576956
At time: 1450.579349040985 and batch: 800, loss is 4.516693935394287 and perplexity is 91.53248488995001
At time: 1451.6045463085175 and batch: 850, loss is 4.484341506958008 and perplexity is 88.61857687938904
At time: 1452.6282618045807 and batch: 900, loss is 4.520621852874756 and perplexity is 91.89272396890432
At time: 1453.6537697315216 and batch: 950, loss is 4.497123708724976 and perplexity is 89.75858781259396
At time: 1454.6777470111847 and batch: 1000, loss is 4.497341022491455 and perplexity is 89.77809570897585
At time: 1455.7012958526611 and batch: 1050, loss is 4.462837791442871 and perplexity is 86.73329118376896
At time: 1456.7262494564056 and batch: 1100, loss is 4.4351317405700685 and perplexity is 84.363238217332
At time: 1457.7508282661438 and batch: 1150, loss is 4.4582428359985355 and perplexity is 86.33566980110935
At time: 1458.774109840393 and batch: 1200, loss is 4.4451387500762936 and perplexity is 85.21170014702692
At time: 1459.7981524467468 and batch: 1250, loss is 4.479035348892212 and perplexity is 88.14959804117696
At time: 1460.8245663642883 and batch: 1300, loss is 4.474942770004272 and perplexity is 87.7895760689213
At time: 1461.8480665683746 and batch: 1350, loss is 4.451934280395508 and perplexity is 85.79273080870601
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.749302164713542 and perplexity of 115.50365387161494
Finished 49 epochs...
Completing Train Step...
At time: 1464.974118232727 and batch: 50, loss is 4.582891263961792 and perplexity is 97.79674203514251
At time: 1466.0248730182648 and batch: 100, loss is 4.592395420074463 and perplexity is 98.7306485053074
At time: 1467.0487883090973 and batch: 150, loss is 4.565827131271362 and perplexity is 96.14208326153617
At time: 1468.0729775428772 and batch: 200, loss is 4.562089529037475 and perplexity is 95.7834130971131
At time: 1469.1072463989258 and batch: 250, loss is 4.539810495376587 and perplexity is 93.67304696188592
At time: 1470.1312911510468 and batch: 300, loss is 4.540112380981445 and perplexity is 93.70132977519923
At time: 1471.1660795211792 and batch: 350, loss is 4.559062824249268 and perplexity is 95.49394327289735
At time: 1472.2005507946014 and batch: 400, loss is 4.562811679840088 and perplexity is 95.8526081473816
At time: 1473.236388683319 and batch: 450, loss is 4.518192768096924 and perplexity is 91.66977963688224
At time: 1474.2671537399292 and batch: 500, loss is 4.578236722946167 and perplexity is 97.34260081751209
At time: 1475.292566537857 and batch: 550, loss is 4.57339771270752 and perplexity is 96.87269682754861
At time: 1476.3174738883972 and batch: 600, loss is 4.542024002075196 and perplexity is 93.88062252901598
At time: 1477.3400795459747 and batch: 650, loss is 4.536374969482422 and perplexity is 93.35178295485605
At time: 1478.3629262447357 and batch: 700, loss is 4.5698270511627195 and perplexity is 96.52741402510985
At time: 1479.3876128196716 and batch: 750, loss is 4.535028848648071 and perplexity is 93.2262047156016
At time: 1480.4122500419617 and batch: 800, loss is 4.515996894836426 and perplexity is 91.46870526669431
At time: 1481.4381144046783 and batch: 850, loss is 4.483834524154663 and perplexity is 88.57366017181552
At time: 1482.4634704589844 and batch: 900, loss is 4.519892826080322 and perplexity is 91.82575612455992
At time: 1483.4875090122223 and batch: 950, loss is 4.496526851654052 and perplexity is 89.70503074932779
At time: 1484.510841846466 and batch: 1000, loss is 4.496741914749146 and perplexity is 89.72432506555951
At time: 1485.53555893898 and batch: 1050, loss is 4.4622572231292725 and perplexity is 86.68295119748801
At time: 1486.5605483055115 and batch: 1100, loss is 4.434584293365479 and perplexity is 84.3170664378587
At time: 1487.584800004959 and batch: 1150, loss is 4.457685451507569 and perplexity is 86.28756104652734
At time: 1488.608715057373 and batch: 1200, loss is 4.44455506324768 and perplexity is 85.16197771258405
At time: 1489.6807889938354 and batch: 1250, loss is 4.47840648651123 and perplexity is 88.09418150158503
At time: 1490.7078075408936 and batch: 1300, loss is 4.474384145736694 and perplexity is 87.74054837659317
At time: 1491.7327499389648 and batch: 1350, loss is 4.451292085647583 and perplexity is 85.73765285484974
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.749040934244792 and perplexity of 115.47348473869167
Finished Training.
Improved accuracyfrom -158.40628669403355 to -115.47348473869167
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fec0ef11828>
SETTINGS FOR THIS RUN
{'wordvec_dim': 200, 'dropout': 0.11823445326580329, 'num_layers': 1, 'wordvec_source': 'glove', 'tune_wordvecs': True, 'batch_size': 80, 'seq_len': 20, 'lr': 4.326240833377234, 'data': 'wikitext', 'anneal': 2.4098571973066725}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.5182559490203857 and batch: 50, loss is 7.413130788803101 and perplexity is 1657.6078516353998
At time: 2.545088529586792 and batch: 100, loss is 6.649262056350708 and perplexity is 772.2142646121372
At time: 3.5727925300598145 and batch: 150, loss is 6.314983997344971 and perplexity is 552.7932143616745
At time: 4.600239038467407 and batch: 200, loss is 6.084965171813965 and perplexity is 439.20451571012296
At time: 5.626482009887695 and batch: 250, loss is 5.955972299575806 and perplexity is 386.05208653677846
At time: 6.667279243469238 and batch: 300, loss is 5.853241844177246 and perplexity is 348.361886845739
At time: 7.705154180526733 and batch: 350, loss is 5.761443758010865 and perplexity is 317.8068340155203
At time: 8.732516527175903 and batch: 400, loss is 5.726908721923828 and perplexity is 307.0187196920503
At time: 9.759313583374023 and batch: 450, loss is 5.6377551460266115 and perplexity is 280.8315844402664
At time: 10.785988092422485 and batch: 500, loss is 5.605614185333252 and perplexity is 271.94890117853146
At time: 11.81448769569397 and batch: 550, loss is 5.528986730575562 and perplexity is 251.88855070416471
At time: 12.843235731124878 and batch: 600, loss is 5.442384176254272 and perplexity is 230.9922537140863
At time: 13.89964771270752 and batch: 650, loss is 5.436372632980347 and perplexity is 229.60779930808596
At time: 14.93504810333252 and batch: 700, loss is 5.422998380661011 and perplexity is 226.55741046926443
At time: 15.961959600448608 and batch: 750, loss is 5.369759759902954 and perplexity is 214.81125522808793
At time: 17.000296115875244 and batch: 800, loss is 5.307456922531128 and perplexity is 201.8362898512498
At time: 18.02763032913208 and batch: 850, loss is 5.275648784637451 and perplexity is 195.51728398293787
At time: 19.054630517959595 and batch: 900, loss is 5.316968469619751 and perplexity is 203.76522425912844
At time: 20.082807064056396 and batch: 950, loss is 5.256469440460205 and perplexity is 191.80312214789546
At time: 21.11131453514099 and batch: 1000, loss is 5.258886079788208 and perplexity is 192.26720164663823
At time: 22.138980388641357 and batch: 1050, loss is 5.199194726943969 and perplexity is 181.12632698151407
At time: 23.16716742515564 and batch: 1100, loss is 5.166758232116699 and perplexity is 175.34548576538378
At time: 24.19584083557129 and batch: 1150, loss is 5.1710842418670655 and perplexity is 176.1056751543041
At time: 25.22351050376892 and batch: 1200, loss is 5.14558702468872 and perplexity is 171.67223093582376
At time: 26.251015424728394 and batch: 1250, loss is 5.172103843688965 and perplexity is 176.28532439131948
At time: 27.28022003173828 and batch: 1300, loss is 5.150882930755615 and perplexity is 172.5838026136024
At time: 28.3076491355896 and batch: 1350, loss is 5.1029919910430905 and perplexity is 164.5133942730748
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.810550537109375 and perplexity of 122.79920443004676
Finished 1 epochs...
Completing Train Step...
At time: 31.422916889190674 and batch: 50, loss is 5.072741641998291 and perplexity is 159.61132513621413
At time: 32.47470736503601 and batch: 100, loss is 5.073769779205322 and perplexity is 159.77551186703064
At time: 33.498525857925415 and batch: 150, loss is 4.996674489974976 and perplexity is 147.9204293970153
At time: 34.52099370956421 and batch: 200, loss is 4.97478479385376 and perplexity is 144.71767766303338
At time: 35.543137550354004 and batch: 250, loss is 4.972584409713745 and perplexity is 144.39959326259762
At time: 36.56657028198242 and batch: 300, loss is 4.944073219299316 and perplexity is 140.340725486021
At time: 37.59008240699768 and batch: 350, loss is 4.924825286865234 and perplexity is 137.66528760769546
At time: 38.61302208900452 and batch: 400, loss is 4.935135278701782 and perplexity is 139.09195743885238
At time: 39.63795781135559 and batch: 450, loss is 4.881271638870239 and perplexity is 131.79815702736687
At time: 40.660990953445435 and batch: 500, loss is 4.934724416732788 and perplexity is 139.03482158162691
At time: 41.69169020652771 and batch: 550, loss is 4.904809532165527 and perplexity is 134.93720636154396
At time: 42.71549391746521 and batch: 600, loss is 4.835842018127441 and perplexity is 125.94458619702125
At time: 43.73904514312744 and batch: 650, loss is 4.8543571090698245 and perplexity is 128.2981829574754
At time: 44.762006521224976 and batch: 700, loss is 4.865980815887451 and perplexity is 129.79818432064576
At time: 45.785168409347534 and batch: 750, loss is 4.813974771499634 and perplexity is 123.22041844513615
At time: 46.80933952331543 and batch: 800, loss is 4.777941694259644 and perplexity is 118.85944900448654
At time: 47.83263897895813 and batch: 850, loss is 4.743079319000244 and perplexity is 114.78712419329668
At time: 48.855802059173584 and batch: 900, loss is 4.7898712062835695 and perplexity is 120.28587560057963
At time: 49.9272141456604 and batch: 950, loss is 4.741698179244995 and perplexity is 114.6286965632158
At time: 50.950154304504395 and batch: 1000, loss is 4.76118730545044 and perplexity is 116.8846212937323
At time: 51.97344088554382 and batch: 1050, loss is 4.693909988403321 and perplexity is 109.27962763786867
At time: 52.99617791175842 and batch: 1100, loss is 4.6690340328216555 and perplexity is 106.59472567866946
At time: 54.020840644836426 and batch: 1150, loss is 4.685861434936523 and perplexity is 108.40361475918638
At time: 55.043614864349365 and batch: 1200, loss is 4.670468072891236 and perplexity is 106.74769644338663
At time: 56.066173791885376 and batch: 1250, loss is 4.716222972869873 and perplexity is 111.74538922041222
At time: 57.10315275192261 and batch: 1300, loss is 4.704029474258423 and perplexity is 110.39109554098307
At time: 58.12916541099548 and batch: 1350, loss is 4.657749767303467 and perplexity is 105.3986436368074
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.593841959635417 and perplexity of 98.87356963986498
Finished 2 epochs...
Completing Train Step...
At time: 61.23497533798218 and batch: 50, loss is 4.71399754524231 and perplexity is 111.49698444992717
At time: 62.263325691223145 and batch: 100, loss is 4.7249170017242434 and perplexity is 112.72114232535228
At time: 63.28785967826843 and batch: 150, loss is 4.668406295776367 and perplexity is 106.52783321816295
At time: 64.31065583229065 and batch: 200, loss is 4.658240327835083 and perplexity is 105.45036073560807
At time: 65.3336935043335 and batch: 250, loss is 4.666829538345337 and perplexity is 106.35999701878434
At time: 66.35652756690979 and batch: 300, loss is 4.651017684936523 and perplexity is 104.6914743183257
At time: 67.38028597831726 and batch: 350, loss is 4.641153573989868 and perplexity is 103.663862570888
At time: 68.40310215950012 and batch: 400, loss is 4.650525054931641 and perplexity is 104.63991285822506
At time: 69.42591881752014 and batch: 450, loss is 4.600341205596924 and perplexity is 99.51826603894033
At time: 70.45006728172302 and batch: 500, loss is 4.670415782928467 and perplexity is 106.74211475624836
At time: 71.47400546073914 and batch: 550, loss is 4.653378953933716 and perplexity is 104.93897113919392
At time: 72.50288009643555 and batch: 600, loss is 4.586424751281738 and perplexity is 98.14291682498963
At time: 73.52977538108826 and batch: 650, loss is 4.61183650970459 and perplexity is 100.66885931099378
At time: 74.5525484085083 and batch: 700, loss is 4.6349578380584715 and perplexity is 103.02357422974642
At time: 75.6018705368042 and batch: 750, loss is 4.581874599456787 and perplexity is 97.69736608337134
At time: 76.63597059249878 and batch: 800, loss is 4.553489456176758 and perplexity is 94.96320076386473
At time: 77.67037343978882 and batch: 850, loss is 4.521514396667481 and perplexity is 91.97477886262507
At time: 78.692626953125 and batch: 900, loss is 4.565076131820678 and perplexity is 96.06990771510925
At time: 79.71681308746338 and batch: 950, loss is 4.519511957168579 and perplexity is 91.79078920808315
At time: 80.73930096626282 and batch: 1000, loss is 4.5460685348510745 and perplexity is 94.26109468124491
At time: 81.76244592666626 and batch: 1050, loss is 4.481211986541748 and perplexity is 88.34167674209583
At time: 82.78730177879333 and batch: 1100, loss is 4.4577054691314695 and perplexity is 86.28928833575974
At time: 83.81022691726685 and batch: 1150, loss is 4.482497434616089 and perplexity is 88.45530839849815
At time: 84.83321738243103 and batch: 1200, loss is 4.4600222778320315 and perplexity is 86.48943587199197
At time: 85.85770606994629 and batch: 1250, loss is 4.511438770294189 and perplexity is 91.05272827405308
At time: 86.880704164505 and batch: 1300, loss is 4.507347002029419 and perplexity is 90.68092279974877
At time: 87.90430188179016 and batch: 1350, loss is 4.460982542037964 and perplexity is 86.5725284704902
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.5168839518229165 and perplexity of 91.54987921838409
Finished 3 epochs...
Completing Train Step...
At time: 91.0231077671051 and batch: 50, loss is 4.527798862457275 and perplexity is 92.55461127403929
At time: 92.04610753059387 and batch: 100, loss is 4.540488710403443 and perplexity is 93.7365989784771
At time: 93.07466626167297 and batch: 150, loss is 4.494736614227295 and perplexity is 89.5445811102392
At time: 94.09857130050659 and batch: 200, loss is 4.488924560546875 and perplexity is 89.02565267876705
At time: 95.12198328971863 and batch: 250, loss is 4.495397720336914 and perplexity is 89.60379915244238
At time: 96.14455127716064 and batch: 300, loss is 4.4893801879882815 and perplexity is 89.06622445122122
At time: 97.16735768318176 and batch: 350, loss is 4.484169826507569 and perplexity is 88.60336410809819
At time: 98.18933081626892 and batch: 400, loss is 4.493229217529297 and perplexity is 89.40970358685625
At time: 99.21273589134216 and batch: 450, loss is 4.440816211700439 and perplexity is 84.84416421940904
At time: 100.23574995994568 and batch: 500, loss is 4.513109827041626 and perplexity is 91.2050097500657
At time: 101.25801515579224 and batch: 550, loss is 4.504494390487671 and perplexity is 90.42261395531271
At time: 102.30706238746643 and batch: 600, loss is 4.437124643325806 and perplexity is 84.53153358971292
At time: 103.3294448852539 and batch: 650, loss is 4.464080829620361 and perplexity is 86.84117101145112
At time: 104.35135102272034 and batch: 700, loss is 4.491895475387573 and perplexity is 89.29053358599516
At time: 105.37418866157532 and batch: 750, loss is 4.441662864685059 and perplexity is 84.91602820190778
At time: 106.39721059799194 and batch: 800, loss is 4.412650022506714 and perplexity is 82.48776856300658
At time: 107.41884875297546 and batch: 850, loss is 4.384993181228638 and perplexity is 80.23767608866784
At time: 108.4416995048523 and batch: 900, loss is 4.423935403823853 and perplexity is 83.42394711527082
At time: 109.46343064308167 and batch: 950, loss is 4.385084867477417 and perplexity is 80.24503311746318
At time: 110.48591542243958 and batch: 1000, loss is 4.409414625167846 and perplexity is 82.22131912344071
At time: 111.50849986076355 and batch: 1050, loss is 4.348570947647095 and perplexity is 77.3678212207414
At time: 112.53187441825867 and batch: 1100, loss is 4.322839593887329 and perplexity is 75.40243688243417
At time: 113.5539619922638 and batch: 1150, loss is 4.3520596408843994 and perplexity is 77.63820518453575
At time: 114.57746005058289 and batch: 1200, loss is 4.327889995574951 and perplexity is 75.78421272611675
At time: 115.59939432144165 and batch: 1250, loss is 4.376752395629882 and perplexity is 79.57917162673435
At time: 116.62245774269104 and batch: 1300, loss is 4.379386644363404 and perplexity is 79.78907931194996
At time: 117.64548563957214 and batch: 1350, loss is 4.334872608184814 and perplexity is 76.31523633401093
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.482223714192708 and perplexity of 88.43109968739346
Finished 4 epochs...
Completing Train Step...
At time: 120.72302913665771 and batch: 50, loss is 4.406863574981689 and perplexity is 82.01183572692095
At time: 121.76978468894958 and batch: 100, loss is 4.416298866271973 and perplexity is 82.78930333512014
At time: 122.7910566329956 and batch: 150, loss is 4.380459108352661 and perplexity is 79.87469612851812
At time: 123.81405186653137 and batch: 200, loss is 4.3749417972564695 and perplexity is 79.43521607020475
At time: 124.83546686172485 and batch: 250, loss is 4.377239198684692 and perplexity is 79.61792044133692
At time: 125.85759472846985 and batch: 300, loss is 4.379027452468872 and perplexity is 79.76042486791906
At time: 126.8808126449585 and batch: 350, loss is 4.375730781555176 and perplexity is 79.49791393901309
At time: 127.92942428588867 and batch: 400, loss is 4.38568772315979 and perplexity is 80.2934238765167
At time: 128.95169234275818 and batch: 450, loss is 4.329334745407104 and perplexity is 75.89378108510827
At time: 129.97476387023926 and batch: 500, loss is 4.403036346435547 and perplexity is 81.69855756406895
At time: 130.99646997451782 and batch: 550, loss is 4.399939527511597 and perplexity is 81.44594327718409
At time: 132.01882362365723 and batch: 600, loss is 4.332334070205689 and perplexity is 76.12175289462412
At time: 133.0424988269806 and batch: 650, loss is 4.3587440013885494 and perplexity is 78.15890527166496
At time: 134.06725692749023 and batch: 700, loss is 4.389200038909912 and perplexity is 80.57593557854929
At time: 135.09528279304504 and batch: 750, loss is 4.341597394943237 and perplexity is 76.83016949206055
At time: 136.12201952934265 and batch: 800, loss is 4.311777572631836 and perplexity is 74.57292999310815
At time: 137.14333844184875 and batch: 850, loss is 4.287940721511841 and perplexity is 72.81636482637175
At time: 138.16703057289124 and batch: 900, loss is 4.324048318862915 and perplexity is 75.49363279539966
At time: 139.19754648208618 and batch: 950, loss is 4.290287590026855 and perplexity is 72.98745594601361
At time: 140.22798776626587 and batch: 1000, loss is 4.313738336563111 and perplexity is 74.71929334959087
At time: 141.2571222782135 and batch: 1050, loss is 4.253404579162598 and perplexity is 70.34449853573689
At time: 142.2878942489624 and batch: 1100, loss is 4.225553951263428 and perplexity is 68.412390183891
At time: 143.31761145591736 and batch: 1150, loss is 4.259019365310669 and perplexity is 70.74057876403567
At time: 144.347838640213 and batch: 1200, loss is 4.230367650985718 and perplexity is 68.74250077671974
At time: 145.3791651725769 and batch: 1250, loss is 4.28059157371521 and perplexity is 72.28318819591458
At time: 146.4162404537201 and batch: 1300, loss is 4.284673013687134 and perplexity is 72.5788105616087
At time: 147.44839119911194 and batch: 1350, loss is 4.241505279541015 and perplexity is 69.51240873204739
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.465205891927083 and perplexity of 86.93892772051063
Finished 5 epochs...
Completing Train Step...
At time: 150.5452582836151 and batch: 50, loss is 4.317926359176636 and perplexity is 75.03287562629819
At time: 151.59454369544983 and batch: 100, loss is 4.322788152694702 and perplexity is 75.39855819091711
At time: 152.61726188659668 and batch: 150, loss is 4.295232105255127 and perplexity is 73.34923721282732
At time: 153.6669909954071 and batch: 200, loss is 4.289591550827026 and perplexity is 72.93667149161521
At time: 154.6898365020752 and batch: 250, loss is 4.28945333480835 and perplexity is 72.926591171913
At time: 155.7128722667694 and batch: 300, loss is 4.294721231460572 and perplexity is 73.3117745798382
At time: 156.73587489128113 and batch: 350, loss is 4.29382022857666 and perplexity is 73.24575020805837
At time: 157.76056623458862 and batch: 400, loss is 4.304959363937378 and perplexity is 74.06620563272512
At time: 158.78371119499207 and batch: 450, loss is 4.247396368980407 and perplexity is 69.92312113296774
At time: 159.80825018882751 and batch: 500, loss is 4.320276231765747 and perplexity is 75.20940064844054
At time: 160.83152508735657 and batch: 550, loss is 4.317877445220947 and perplexity is 75.02920556130405
At time: 161.85403060913086 and batch: 600, loss is 4.252628049850464 and perplexity is 70.28989517397582
At time: 162.87751269340515 and batch: 650, loss is 4.276457767486573 and perplexity is 71.98500025254168
At time: 163.9019169807434 and batch: 700, loss is 4.3113967800140385 and perplexity is 74.54453857784296
At time: 164.9252278804779 and batch: 750, loss is 4.264560956954956 and perplexity is 71.13368236805798
At time: 165.94825506210327 and batch: 800, loss is 4.235850439071656 and perplexity is 69.12043646486117
At time: 166.9724986553192 and batch: 850, loss is 4.209792613983154 and perplexity is 67.34257245398409
At time: 167.99492359161377 and batch: 900, loss is 4.246444187164307 and perplexity is 69.85657329634785
At time: 169.01847863197327 and batch: 950, loss is 4.217865705490112 and perplexity is 67.88843564074013
At time: 170.0430657863617 and batch: 1000, loss is 4.240799684524536 and perplexity is 69.46337842266776
At time: 171.06595873832703 and batch: 1050, loss is 4.1787692642211915 and perplexity is 65.28545460461805
At time: 172.08876943588257 and batch: 1100, loss is 4.151270060539246 and perplexity is 63.51461650164141
At time: 173.1126139163971 and batch: 1150, loss is 4.183949108123779 and perplexity is 65.62450041268858
At time: 174.13650131225586 and batch: 1200, loss is 4.155127635002136 and perplexity is 63.76010204924814
At time: 175.15945529937744 and batch: 1250, loss is 4.205772519111633 and perplexity is 67.07239236249549
At time: 176.18315958976746 and batch: 1300, loss is 4.212559638023376 and perplexity is 67.52916901041823
At time: 177.20618319511414 and batch: 1350, loss is 4.167052321434021 and perplexity is 64.52497263039417
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.458438313802083 and perplexity of 86.35254815782818
Finished 6 epochs...
Completing Train Step...
At time: 180.300053358078 and batch: 50, loss is 4.24631633758545 and perplexity is 69.84764273376801
At time: 181.3218765258789 and batch: 100, loss is 4.248939809799194 and perplexity is 70.0311266609306
At time: 182.34386134147644 and batch: 150, loss is 4.229321765899658 and perplexity is 68.67064160514724
At time: 183.36765956878662 and batch: 200, loss is 4.22188247680664 and perplexity is 68.16167636711957
At time: 184.39071345329285 and batch: 250, loss is 4.219594159126282 and perplexity is 68.00587912274493
At time: 185.4146056175232 and batch: 300, loss is 4.228671989440918 and perplexity is 68.62603553238307
At time: 186.4391450881958 and batch: 350, loss is 4.229639883041382 and perplexity is 68.692490388427
At time: 187.46196174621582 and batch: 400, loss is 4.239081077575683 and perplexity is 69.3441007029371
At time: 188.48476934432983 and batch: 450, loss is 4.181042408943176 and perplexity is 65.43402669012592
At time: 189.5076003074646 and batch: 500, loss is 4.254789772033692 and perplexity is 70.442006751881
At time: 190.53192400932312 and batch: 550, loss is 4.251274032592773 and perplexity is 70.19478584723471
At time: 191.55518674850464 and batch: 600, loss is 4.188480572700501 and perplexity is 65.92255030291642
At time: 192.57796216011047 and batch: 650, loss is 4.211255140304566 and perplexity is 67.44113479619088
At time: 193.60119700431824 and batch: 700, loss is 4.247994756698608 and perplexity is 69.96497479098055
At time: 194.64225101470947 and batch: 750, loss is 4.202323517799377 and perplexity is 66.84145806848795
At time: 195.67539954185486 and batch: 800, loss is 4.17164267539978 and perplexity is 64.82184594991513
At time: 196.69987511634827 and batch: 850, loss is 4.148628520965576 and perplexity is 63.347061527622635
At time: 197.72385001182556 and batch: 900, loss is 4.183796019554138 and perplexity is 65.61445482073923
At time: 198.7469937801361 and batch: 950, loss is 4.158605546951294 and perplexity is 63.98224013448244
At time: 199.77666091918945 and batch: 1000, loss is 4.180418815612793 and perplexity is 65.39323518747823
At time: 200.80100870132446 and batch: 1050, loss is 4.117952971458435 and perplexity is 61.43335762719695
At time: 201.82389283180237 and batch: 1100, loss is 4.089550309181213 and perplexity is 59.713033262780385
At time: 202.8569314479828 and batch: 1150, loss is 4.1221575355529785 and perplexity is 61.69220189922122
At time: 203.88324069976807 and batch: 1200, loss is 4.096998071670532 and perplexity is 60.15942198723825
At time: 204.90623664855957 and batch: 1250, loss is 4.1442071008682255 and perplexity is 63.06759582957497
At time: 205.92913913726807 and batch: 1300, loss is 4.152166380882263 and perplexity is 63.571571465624096
At time: 206.95334005355835 and batch: 1350, loss is 4.107772006988525 and perplexity is 60.811079864842185
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.451547037760417 and perplexity of 85.7595146373299
Finished 7 epochs...
Completing Train Step...
At time: 210.06090188026428 and batch: 50, loss is 4.188424024581909 and perplexity is 65.91882261212199
At time: 211.0840117931366 and batch: 100, loss is 4.191316242218018 and perplexity is 66.1097501623551
At time: 212.11813879013062 and batch: 150, loss is 4.17315972328186 and perplexity is 64.92025842336905
At time: 213.141916513443 and batch: 200, loss is 4.166461744308472 and perplexity is 64.4868769078704
At time: 214.1663465499878 and batch: 250, loss is 4.16339430809021 and perplexity is 64.28937059990587
At time: 215.19102478027344 and batch: 300, loss is 4.173839716911316 and perplexity is 64.96441879820473
At time: 216.21505403518677 and batch: 350, loss is 4.178723821640014 and perplexity is 65.28248793245463
At time: 217.23818278312683 and batch: 400, loss is 4.185290594100952 and perplexity is 65.71259383458525
At time: 218.26296210289001 and batch: 450, loss is 4.128300867080688 and perplexity is 62.07236408370347
At time: 219.28646993637085 and batch: 500, loss is 4.202295503616333 and perplexity is 66.83958558587483
At time: 220.3107407093048 and batch: 550, loss is 4.198203468322754 and perplexity is 66.5666344862905
At time: 221.33601236343384 and batch: 600, loss is 4.1355167007446285 and perplexity is 62.521887831864944
At time: 222.3584988117218 and batch: 650, loss is 4.158378720283508 and perplexity is 63.96772890198476
At time: 223.38261365890503 and batch: 700, loss is 4.194741702079773 and perplexity is 66.33659475972655
At time: 224.40520572662354 and batch: 750, loss is 4.152473244667053 and perplexity is 63.59108227207597
At time: 225.4283857345581 and batch: 800, loss is 4.120512533187866 and perplexity is 61.590801505997405
At time: 226.45163416862488 and batch: 850, loss is 4.098500218391418 and perplexity is 60.24985817291133
At time: 227.47658801078796 and batch: 900, loss is 4.132611365318298 and perplexity is 62.34050439367805
At time: 228.49991464614868 and batch: 950, loss is 4.107995238304138 and perplexity is 60.824656317492575
At time: 229.5241870880127 and batch: 1000, loss is 4.130446934700013 and perplexity is 62.20571861705984
At time: 230.55443358421326 and batch: 1050, loss is 4.070475969314575 and perplexity is 58.58484054323924
At time: 231.6066460609436 and batch: 1100, loss is 4.040092830657959 and perplexity is 56.831618277120015
At time: 232.63083028793335 and batch: 1150, loss is 4.070400748252869 and perplexity is 58.58043389507212
At time: 233.6540253162384 and batch: 1200, loss is 4.045231900215149 and perplexity is 57.12443166624674
At time: 234.67698550224304 and batch: 1250, loss is 4.094420413970948 and perplexity is 60.00455127753982
At time: 235.70146918296814 and batch: 1300, loss is 4.100513296127319 and perplexity is 60.37126798368299
At time: 236.72459936141968 and batch: 1350, loss is 4.057732725143433 and perplexity is 57.843016278067395
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.459090169270834 and perplexity of 86.40885588884275
Annealing...
Finished 8 epochs...
Completing Train Step...
At time: 239.7950038909912 and batch: 50, loss is 4.135653629302978 and perplexity is 62.5304494499827
At time: 240.8452000617981 and batch: 100, loss is 4.141575298309326 and perplexity is 62.901832593220185
At time: 241.87125611305237 and batch: 150, loss is 4.122170572280884 and perplexity is 61.69300616891376
At time: 242.8959641456604 and batch: 200, loss is 4.111304287910461 and perplexity is 61.02626149934706
At time: 243.92054295539856 and batch: 250, loss is 4.09969202041626 and perplexity is 60.32170688209232
At time: 244.9468560218811 and batch: 300, loss is 4.102518486976623 and perplexity is 60.492445349074465
At time: 245.9710214138031 and batch: 350, loss is 4.10564112663269 and perplexity is 60.6816366922776
At time: 246.9956033229828 and batch: 400, loss is 4.107755527496338 and perplexity is 60.81007773738398
At time: 248.02167558670044 and batch: 450, loss is 4.043109250068665 and perplexity is 57.003305083161656
At time: 249.0470154285431 and batch: 500, loss is 4.114094262123108 and perplexity is 61.19676092913399
At time: 250.07212686538696 and batch: 550, loss is 4.105970635414123 and perplexity is 60.70163511908709
At time: 251.09718585014343 and batch: 600, loss is 4.042659726142883 and perplexity is 56.977686492194344
At time: 252.12147665023804 and batch: 650, loss is 4.057916879653931 and perplexity is 57.853669311287746
At time: 253.1643214225769 and batch: 700, loss is 4.085164275169372 and perplexity is 59.45170338773962
At time: 254.19592690467834 and batch: 750, loss is 4.041618804931641 and perplexity is 56.91840806719452
At time: 255.22342538833618 and batch: 800, loss is 4.012802448272705 and perplexity is 55.301633571993726
At time: 256.2585597038269 and batch: 850, loss is 3.9749070262908934 and perplexity is 53.24516627499935
At time: 257.3415536880493 and batch: 900, loss is 4.005446166992187 and perplexity is 54.896311858259836
At time: 258.37148451805115 and batch: 950, loss is 3.980698833465576 and perplexity is 53.554446793041535
At time: 259.3998370170593 and batch: 1000, loss is 3.996801328659058 and perplexity is 54.42378750823624
At time: 260.42800641059875 and batch: 1050, loss is 3.934634289741516 and perplexity is 51.14344285447021
At time: 261.45653343200684 and batch: 1100, loss is 3.900019145011902 and perplexity is 49.40339492506012
At time: 262.4859220981598 and batch: 1150, loss is 3.9255320262908935 and perplexity is 50.68003399807897
At time: 263.51452565193176 and batch: 1200, loss is 3.892928819656372 and perplexity is 49.05434767295945
At time: 264.54299688339233 and batch: 1250, loss is 3.938534150123596 and perplexity is 51.34328456516547
At time: 265.5765709877014 and batch: 1300, loss is 3.941299796104431 and perplexity is 51.485478452107614
At time: 266.6145303249359 and batch: 1350, loss is 3.8972021627426146 and perplexity is 49.264422271164754
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.399239501953125 and perplexity of 81.38894898631378
Finished 9 epochs...
Completing Train Step...
At time: 269.71521973609924 and batch: 50, loss is 4.065305943489075 and perplexity is 58.282737019073146
At time: 270.76385045051575 and batch: 100, loss is 4.069535779953003 and perplexity is 58.52978558450982
At time: 271.7894706726074 and batch: 150, loss is 4.054520111083985 and perplexity is 57.65748716701564
At time: 272.81392765045166 and batch: 200, loss is 4.046013212203979 and perplexity is 57.169081109864145
At time: 273.8379147052765 and batch: 250, loss is 4.037183523178101 and perplexity is 56.66651790529902
At time: 274.8637149333954 and batch: 300, loss is 4.0450131225585935 and perplexity is 57.11193548394733
At time: 275.8934419155121 and batch: 350, loss is 4.0510183572769165 and perplexity is 57.45593793567102
At time: 276.9230070114136 and batch: 400, loss is 4.054315633773804 and perplexity is 57.64569872440354
At time: 277.9491891860962 and batch: 450, loss is 3.993616557121277 and perplexity is 54.250735890004464
At time: 278.97267842292786 and batch: 500, loss is 4.066319537162781 and perplexity is 58.34184198174985
At time: 279.99843311309814 and batch: 550, loss is 4.064084897041321 and perplexity is 58.21161452084422
At time: 281.022047996521 and batch: 600, loss is 4.00152364730835 and perplexity is 54.68140176451558
At time: 282.0459623336792 and batch: 650, loss is 4.01888653755188 and perplexity is 55.63911925340382
At time: 283.07023644447327 and batch: 700, loss is 4.048638138771057 and perplexity is 57.31934287645816
At time: 284.12303853034973 and batch: 750, loss is 4.0072698974609375 and perplexity is 54.996519282710246
At time: 285.147456407547 and batch: 800, loss is 3.9805690670013427 and perplexity is 53.54749767272837
At time: 286.172860622406 and batch: 850, loss is 3.94502893447876 and perplexity is 51.677833361646556
At time: 287.206027507782 and batch: 900, loss is 3.979265208244324 and perplexity is 53.47772479584437
At time: 288.23026037216187 and batch: 950, loss is 3.9562529802322386 and perplexity is 52.26113510683179
At time: 289.26404094696045 and batch: 1000, loss is 3.9732819747924806 and perplexity is 53.15871040440794
At time: 290.28866243362427 and batch: 1050, loss is 3.914445219039917 and perplexity is 50.121257477058286
At time: 291.31274485588074 and batch: 1100, loss is 3.8807501220703124 and perplexity is 48.4605527709591
At time: 292.33832597732544 and batch: 1150, loss is 3.907941608428955 and perplexity is 49.79634602909551
At time: 293.36240816116333 and batch: 1200, loss is 3.878999266624451 and perplexity is 48.37577958268575
At time: 294.387088060379 and batch: 1250, loss is 3.9262914276123047 and perplexity is 50.718535099909815
At time: 295.4115209579468 and batch: 1300, loss is 3.9300805377960204 and perplexity is 50.9110777700893
At time: 296.43517899513245 and batch: 1350, loss is 3.888419051170349 and perplexity is 48.833622006641846
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.3980704752604165 and perplexity of 81.29385872481363
Finished 10 epochs...
Completing Train Step...
At time: 299.5487837791443 and batch: 50, loss is 4.033148441314697 and perplexity is 56.43832456565827
At time: 300.5727741718292 and batch: 100, loss is 4.0352885389328 and perplexity is 56.55923742614472
At time: 301.5977087020874 and batch: 150, loss is 4.0219527435302735 and perplexity is 55.809982069920345
At time: 302.6222631931305 and batch: 200, loss is 4.013493194580078 and perplexity is 55.33984616726044
At time: 303.64570784568787 and batch: 250, loss is 4.00574987411499 and perplexity is 54.91298679120657
At time: 304.66901326179504 and batch: 300, loss is 4.014574675559998 and perplexity is 55.39972753276451
At time: 305.69215965270996 and batch: 350, loss is 4.022088994979859 and perplexity is 55.81758677894324
At time: 306.71734642982483 and batch: 400, loss is 4.0257075548172 and perplexity is 56.019931934914354
At time: 307.7531735897064 and batch: 450, loss is 3.965822114944458 and perplexity is 52.763629331974535
At time: 308.79020595550537 and batch: 500, loss is 4.039744911193847 and perplexity is 56.811848890221114
At time: 309.8426949977875 and batch: 550, loss is 4.038234367370605 and perplexity is 56.72609688517913
At time: 310.8653736114502 and batch: 600, loss is 3.9756585121154786 and perplexity is 53.28519430104602
At time: 311.89016008377075 and batch: 650, loss is 3.9942003726959228 and perplexity is 54.28241756177988
At time: 312.9131531715393 and batch: 700, loss is 4.025092573165893 and perplexity is 55.98549129593291
At time: 313.9376277923584 and batch: 750, loss is 3.98501567363739 and perplexity is 53.7861324956205
At time: 314.96858763694763 and batch: 800, loss is 3.958307032585144 and perplexity is 52.36859253817691
At time: 315.992094039917 and batch: 850, loss is 3.9233920526504518 and perplexity is 50.57169602277646
At time: 317.0229206085205 and batch: 900, loss is 3.958036017417908 and perplexity is 52.35440177835469
At time: 318.04598236083984 and batch: 950, loss is 3.9364993381500244 and perplexity is 51.23891685531347
At time: 319.06935715675354 and batch: 1000, loss is 3.9540250396728513 and perplexity is 52.144830012774634
At time: 320.09364914894104 and batch: 1050, loss is 3.8966786241531373 and perplexity is 49.238637195347565
At time: 321.11653995513916 and batch: 1100, loss is 3.862687282562256 and perplexity is 47.59307571874421
At time: 322.1393313407898 and batch: 1150, loss is 3.89092782497406 and perplexity is 48.956288324957505
At time: 323.16512751579285 and batch: 1200, loss is 3.863265452384949 and perplexity is 47.62060055514206
At time: 324.18761467933655 and batch: 1250, loss is 3.9107847929000856 and perplexity is 49.938127687038566
At time: 325.21255254745483 and batch: 1300, loss is 3.9167770910263062 and perplexity is 50.23827020962557
At time: 326.23584961891174 and batch: 1350, loss is 3.8750693225860595 and perplexity is 48.186038556124245
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.3989111328125 and perplexity of 81.36222775453281
Annealing...
Finished 11 epochs...
Completing Train Step...
At time: 329.3184931278229 and batch: 50, loss is 4.015466465950012 and perplexity is 55.44915451336505
At time: 330.3409686088562 and batch: 100, loss is 4.022012028694153 and perplexity is 55.81329087193394
At time: 331.3635778427124 and batch: 150, loss is 4.012284936904908 and perplexity is 55.273021752072054
At time: 332.38777899742126 and batch: 200, loss is 4.001623568534851 and perplexity is 54.686865870232204
At time: 333.41113924980164 and batch: 250, loss is 3.9914789485931395 and perplexity is 54.13489291188801
At time: 334.4340543746948 and batch: 300, loss is 3.9986604690551757 and perplexity is 54.5250630836885
At time: 335.48350977897644 and batch: 350, loss is 4.003901405334473 and perplexity is 54.81157560605838
At time: 336.50649976730347 and batch: 400, loss is 4.000628414154053 and perplexity is 54.632471066192196
At time: 337.5305151939392 and batch: 450, loss is 3.9406941509246827 and perplexity is 51.454305960943415
At time: 338.5536673069 and batch: 500, loss is 4.012603769302368 and perplexity is 55.290647391775316
At time: 339.57643246650696 and batch: 550, loss is 4.008402199745178 and perplexity is 55.05882723618122
At time: 340.6000757217407 and batch: 600, loss is 3.9478522443771364 and perplexity is 51.823942058113985
At time: 341.62361216545105 and batch: 650, loss is 3.9611955642700196 and perplexity is 52.52007955921674
At time: 342.646466255188 and batch: 700, loss is 3.9895521068572997 and perplexity is 54.030683970170784
At time: 343.66936588287354 and batch: 750, loss is 3.9465263414382936 and perplexity is 51.75527407463723
At time: 344.6942820549011 and batch: 800, loss is 3.9202355670928957 and perplexity is 50.41231886283941
At time: 345.7165675163269 and batch: 850, loss is 3.878841347694397 and perplexity is 48.36814073450877
At time: 346.7398293018341 and batch: 900, loss is 3.907209153175354 and perplexity is 49.759885788213914
At time: 347.7641694545746 and batch: 950, loss is 3.886552939414978 and perplexity is 48.74257798613712
At time: 348.78593277931213 and batch: 1000, loss is 3.8997425079345702 and perplexity is 49.389730004476775
At time: 349.808247089386 and batch: 1050, loss is 3.8424052572250367 and perplexity is 46.637514862336424
At time: 350.8319642543793 and batch: 1100, loss is 3.804049162864685 and perplexity is 44.88255381872051
At time: 351.8570034503937 and batch: 1150, loss is 3.8326941108703614 and perplexity is 46.186803135736746
At time: 352.87915992736816 and batch: 1200, loss is 3.7998373126983642 and perplexity is 44.693912769740265
At time: 353.9024860858917 and batch: 1250, loss is 3.845765624046326 and perplexity is 46.79449763203098
At time: 354.9253249168396 and batch: 1300, loss is 3.8487723112106322 and perplexity is 46.935405774620456
At time: 355.9473922252655 and batch: 1350, loss is 3.8059196615219117 and perplexity is 44.9665851411087
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.375687255859375 and perplexity of 79.4944538122969
Finished 12 epochs...
Completing Train Step...
At time: 359.0180230140686 and batch: 50, loss is 3.9897403049468996 and perplexity is 54.040853398577234
At time: 360.0665600299835 and batch: 100, loss is 3.9913239669799805 and perplexity is 54.12650364896388
At time: 361.090411901474 and batch: 150, loss is 3.98138373374939 and perplexity is 53.59113881260257
At time: 362.13854360580444 and batch: 200, loss is 3.971366772651672 and perplexity is 53.056998159283644
At time: 363.160608291626 and batch: 250, loss is 3.9616896295547486 and perplexity is 52.54603431842293
At time: 364.1845245361328 and batch: 300, loss is 3.970926856994629 and perplexity is 53.03366268827353
At time: 365.2065272331238 and batch: 350, loss is 3.976868538856506 and perplexity is 53.349709835940565
At time: 366.2287130355835 and batch: 400, loss is 3.975349235534668 and perplexity is 53.26871698649984
At time: 367.25252199172974 and batch: 450, loss is 3.9168488073348997 and perplexity is 50.24187324211167
At time: 368.2752857208252 and batch: 500, loss is 3.9903095245361326 and perplexity is 54.07162326752584
At time: 369.29817271232605 and batch: 550, loss is 3.9881040143966673 and perplexity is 53.95249916714528
At time: 370.32195377349854 and batch: 600, loss is 3.928273777961731 and perplexity is 50.81917672621132
At time: 371.3443512916565 and batch: 650, loss is 3.943324213027954 and perplexity is 51.58981209776848
At time: 372.36702060699463 and batch: 700, loss is 3.973227367401123 and perplexity is 53.15580762516215
At time: 373.39167976379395 and batch: 750, loss is 3.93177659034729 and perplexity is 50.99749890010161
At time: 374.4154884815216 and batch: 800, loss is 3.906601324081421 and perplexity is 49.72964947210828
At time: 375.43789649009705 and batch: 850, loss is 3.8667176580429077 and perplexity is 47.785280753218636
At time: 376.4641258716583 and batch: 900, loss is 3.8962569761276247 and perplexity is 49.21788019757631
At time: 377.4869017601013 and batch: 950, loss is 3.87782678604126 and perplexity is 48.31909315878796
At time: 378.509628534317 and batch: 1000, loss is 3.8921897983551026 and perplexity is 49.018108857386906
At time: 379.5319278240204 and batch: 1050, loss is 3.8363382053375243 and perplexity is 46.35541924942941
At time: 380.5557384490967 and batch: 1100, loss is 3.798742203712463 and perplexity is 44.644994854364185
At time: 381.5786945819855 and batch: 1150, loss is 3.8287309885025023 and perplexity is 46.00412141723701
At time: 382.6112401485443 and batch: 1200, loss is 3.797186040878296 and perplexity is 44.575574001725
At time: 383.63404083251953 and batch: 1250, loss is 3.844046630859375 and perplexity is 46.714127307225894
At time: 384.67295026779175 and batch: 1300, loss is 3.8463586139678956 and perplexity is 46.822254526477664
At time: 385.7081296443939 and batch: 1350, loss is 3.805322542190552 and perplexity is 44.93974273871195
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.374767659505208 and perplexity of 79.42138460463242
Finished 13 epochs...
Completing Train Step...
At time: 388.7684531211853 and batch: 50, loss is 3.9742550897598266 and perplexity is 53.210465118706736
At time: 389.8160855770111 and batch: 100, loss is 3.975031280517578 and perplexity is 53.25178262300563
At time: 390.8380162715912 and batch: 150, loss is 3.965515513420105 and perplexity is 52.747454402546666
At time: 391.86077761650085 and batch: 200, loss is 3.9553129625320436 and perplexity is 52.21203179740486
At time: 392.88502860069275 and batch: 250, loss is 3.9461358165740967 and perplexity is 51.73506629933394
At time: 393.90763306617737 and batch: 300, loss is 3.9557883071899416 and perplexity is 52.23685640745321
At time: 394.93074798583984 and batch: 350, loss is 3.9621155309677123 and perplexity is 52.56841851507692
At time: 395.9526002407074 and batch: 400, loss is 3.961194624900818 and perplexity is 52.52003022349471
At time: 396.9756956100464 and batch: 450, loss is 3.9031471252441405 and perplexity is 49.55816970782528
At time: 397.9978497028351 and batch: 500, loss is 3.9772091770172118 and perplexity is 53.36788587852436
At time: 399.0215380191803 and batch: 550, loss is 3.976051697731018 and perplexity is 53.30614939231667
At time: 400.04375433921814 and batch: 600, loss is 3.9160195636749267 and perplexity is 50.20022775677427
At time: 401.0676007270813 and batch: 650, loss is 3.931858162879944 and perplexity is 51.00165906492119
At time: 402.0900466442108 and batch: 700, loss is 3.9628637075424193 and perplexity is 52.60776369111347
At time: 403.1129639148712 and batch: 750, loss is 3.9218047857284546 and perplexity is 50.491488914374834
At time: 404.1365671157837 and batch: 800, loss is 3.8969378089904785 and perplexity is 49.25140075750938
At time: 405.1594798564911 and batch: 850, loss is 3.85792914390564 and perplexity is 47.367159162755584
At time: 406.1814270019531 and batch: 900, loss is 3.8873822259902955 and perplexity is 48.78301631687229
At time: 407.2036864757538 and batch: 950, loss is 3.8701673889160157 and perplexity is 47.950411776544044
At time: 408.22786045074463 and batch: 1000, loss is 3.8851969194412233 and perplexity is 48.67652687025302
At time: 409.2506628036499 and batch: 1050, loss is 3.8299620580673217 and perplexity is 46.06079056564497
At time: 410.2752523422241 and batch: 1100, loss is 3.792392144203186 and perplexity is 44.36239469377869
At time: 411.29761385917664 and batch: 1150, loss is 3.8231367683410644 and perplexity is 45.747482749598134
At time: 412.31992506980896 and batch: 1200, loss is 3.7920878458023073 and perplexity is 44.3488973417297
At time: 413.3719916343689 and batch: 1250, loss is 3.8394982194900513 and perplexity is 46.502134719697246
At time: 414.39520239830017 and batch: 1300, loss is 3.8411574792861938 and perplexity is 46.579357891207145
At time: 415.418160200119 and batch: 1350, loss is 3.8011943340301513 and perplexity is 44.75460453346516
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.375323486328125 and perplexity of 79.46554141114079
Annealing...
Finished 14 epochs...
Completing Train Step...
At time: 418.50345754623413 and batch: 50, loss is 3.9695012521743775 and perplexity is 52.95811150896777
At time: 419.5266489982605 and batch: 100, loss is 3.9759914541244505 and perplexity is 53.30293813435491
At time: 420.55064272880554 and batch: 150, loss is 3.968066806793213 and perplexity is 52.88220044866987
At time: 421.574688911438 and batch: 200, loss is 3.958530831336975 and perplexity is 52.3803138753835
At time: 422.5971224308014 and batch: 250, loss is 3.950181269645691 and perplexity is 51.94478199369188
At time: 423.6211814880371 and batch: 300, loss is 3.9579384565353393 and perplexity is 52.34929428586064
At time: 424.64408016204834 and batch: 350, loss is 3.961059808731079 and perplexity is 52.51295015145023
At time: 425.6674885749817 and batch: 400, loss is 3.9572077703475954 and perplexity is 52.31105735088917
At time: 426.6919331550598 and batch: 450, loss is 3.898291139602661 and perplexity is 49.31809930826276
At time: 427.71498560905457 and batch: 500, loss is 3.9726975107192994 and perplexity is 53.12765012569261
At time: 428.73971724510193 and batch: 550, loss is 3.968469386100769 and perplexity is 52.903494014195374
At time: 429.76365995407104 and batch: 600, loss is 3.9088716602325437 and perplexity is 49.84268075403931
At time: 430.7872848510742 and batch: 650, loss is 3.921588411331177 and perplexity is 50.480565030760324
At time: 431.8111324310303 and batch: 700, loss is 3.9518363904953 and perplexity is 52.03082807408583
At time: 432.83557534217834 and batch: 750, loss is 3.9097539043426512 and perplexity is 49.886673568913935
At time: 433.85877799987793 and batch: 800, loss is 3.884373679161072 and perplexity is 48.63647088274899
At time: 434.88269329071045 and batch: 850, loss is 3.8443316555023195 and perplexity is 46.727443882367986
At time: 435.91421937942505 and batch: 900, loss is 3.868697514533997 and perplexity is 47.879982468464675
At time: 436.93777084350586 and batch: 950, loss is 3.849764986038208 and perplexity is 46.982020503260976
At time: 437.95995354652405 and batch: 1000, loss is 3.8625435781478883 and perplexity is 47.586236875067875
At time: 438.98228311538696 and batch: 1050, loss is 3.8070672655105593 and perplexity is 45.01821859528473
At time: 440.03117179870605 and batch: 1100, loss is 3.768698649406433 and perplexity is 43.32364887915964
At time: 441.0537009239197 and batch: 1150, loss is 3.796985764503479 and perplexity is 44.56664746127598
At time: 442.0760004520416 and batch: 1200, loss is 3.7630847883224487 and perplexity is 43.081117338845566
At time: 443.0998582839966 and batch: 1250, loss is 3.810662589073181 and perplexity is 45.18036496701968
At time: 444.12269020080566 and batch: 1300, loss is 3.8106946611404418 and perplexity is 45.18181401796067
At time: 445.1462571620941 and batch: 1350, loss is 3.771188569068909 and perplexity is 43.431655692697596
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.36176513671875 and perplexity of 78.39539094949706
Finished 15 epochs...
Completing Train Step...
At time: 448.225923538208 and batch: 50, loss is 3.9594346141815184 and perplexity is 52.42767570363595
At time: 449.2500374317169 and batch: 100, loss is 3.9627182865142823 and perplexity is 52.60011397225799
At time: 450.27555799484253 and batch: 150, loss is 3.9533215665817263 and perplexity is 52.10816042756482
At time: 451.29972100257874 and batch: 200, loss is 3.943769860267639 and perplexity is 51.61280807879287
At time: 452.32340455055237 and batch: 250, loss is 3.9348401975631715 and perplexity is 51.15397477364539
At time: 453.3544535636902 and batch: 300, loss is 3.9432959222793578 and perplexity is 51.58835260400948
At time: 454.3797347545624 and batch: 350, loss is 3.947484402656555 and perplexity is 51.80488255575499
At time: 455.4036967754364 and batch: 400, loss is 3.944329147338867 and perplexity is 51.64168252886176
At time: 456.42697739601135 and batch: 450, loss is 3.88621150970459 and perplexity is 48.72593866259311
At time: 457.452228307724 and batch: 500, loss is 3.961610279083252 and perplexity is 52.54186493124809
At time: 458.47577953338623 and batch: 550, loss is 3.9583020639419555 and perplexity is 52.36833233797273
At time: 459.50052070617676 and batch: 600, loss is 3.8991602754592893 and perplexity is 49.3609820695256
At time: 460.52953696250916 and batch: 650, loss is 3.9130393171310427 and perplexity is 50.0508414161318
At time: 461.55827260017395 and batch: 700, loss is 3.944062123298645 and perplexity is 51.6278947990586
At time: 462.58223700523376 and batch: 750, loss is 3.903284902572632 and perplexity is 49.56499817044541
At time: 463.60793828964233 and batch: 800, loss is 3.8782210636138914 and perplexity is 48.33814804976159
At time: 464.63202452659607 and batch: 850, loss is 3.8386401987075804 and perplexity is 46.46225203421179
At time: 465.6826927661896 and batch: 900, loss is 3.8641272830963134 and perplexity is 47.66165914142806
At time: 466.7097465991974 and batch: 950, loss is 3.8465494298934937 and perplexity is 46.83118981078388
At time: 467.7407147884369 and batch: 1000, loss is 3.860079789161682 and perplexity is 47.46913874054179
At time: 468.7641146183014 and batch: 1050, loss is 3.8054945611953737 and perplexity is 44.94747389346852
At time: 469.78979539871216 and batch: 1100, loss is 3.767937707901001 and perplexity is 43.290694656268826
At time: 470.814724445343 and batch: 1150, loss is 3.796715874671936 and perplexity is 44.55462099928312
At time: 471.8397264480591 and batch: 1200, loss is 3.7637037897109984 and perplexity is 43.10779286554086
At time: 472.8744282722473 and batch: 1250, loss is 3.8118323612213136 and perplexity is 45.23324662331478
At time: 473.9060354232788 and batch: 1300, loss is 3.81155339717865 and perplexity is 45.220629933857104
At time: 474.92981719970703 and batch: 1350, loss is 3.7723689794540407 and perplexity is 43.48295314018424
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.361278076171875 and perplexity of 78.35721694478913
Finished 16 epochs...
Completing Train Step...
At time: 477.99311113357544 and batch: 50, loss is 3.9522105407714845 and perplexity is 52.05029906509104
At time: 479.04289746284485 and batch: 100, loss is 3.9548860788345337 and perplexity is 52.18974808883103
At time: 480.0664474964142 and batch: 150, loss is 3.9452342224121093 and perplexity is 51.688443286264835
At time: 481.0906894207001 and batch: 200, loss is 3.9357879400253295 and perplexity is 51.20247854855949
At time: 482.1157159805298 and batch: 250, loss is 3.9268154430389406 and perplexity is 50.74511935939126
At time: 483.13930106163025 and batch: 300, loss is 3.935517201423645 and perplexity is 51.188617937500354
At time: 484.1644916534424 and batch: 350, loss is 3.93996298789978 and perplexity is 51.41669822532104
At time: 485.18836784362793 and batch: 400, loss is 3.937194323539734 and perplexity is 51.274539531098235
At time: 486.2138259410858 and batch: 450, loss is 3.879415121078491 and perplexity is 48.39590104960373
At time: 487.23816180229187 and batch: 500, loss is 3.955345344543457 and perplexity is 52.213722555389374
At time: 488.2622356414795 and batch: 550, loss is 3.9524373054504394 and perplexity is 52.062103572820156
At time: 489.2879846096039 and batch: 600, loss is 3.8932816123962404 and perplexity is 49.07165674375518
At time: 490.3114483356476 and batch: 650, loss is 3.907563877105713 and perplexity is 49.77753994146512
At time: 491.36022090911865 and batch: 700, loss is 3.9391716432571413 and perplexity is 51.376025991637874
At time: 492.3856785297394 and batch: 750, loss is 3.898980875015259 and perplexity is 49.35212748170678
At time: 493.4142770767212 and batch: 800, loss is 3.87408730506897 and perplexity is 48.13874224888496
At time: 494.44294238090515 and batch: 850, loss is 3.8345551013946535 and perplexity is 46.272836367404345
At time: 495.46805357933044 and batch: 900, loss is 3.8605509996414185 and perplexity is 47.4915119670158
At time: 496.4990122318268 and batch: 950, loss is 3.8436656951904298 and perplexity is 46.696335618850426
At time: 497.5241298675537 and batch: 1000, loss is 3.8573240280151366 and perplexity is 47.33850521241288
At time: 498.5474269390106 and batch: 1050, loss is 3.8032361698150634 and perplexity is 44.84607944313255
At time: 499.5719668865204 and batch: 1100, loss is 3.7660480546951294 and perplexity is 43.208967498639126
At time: 500.597403049469 and batch: 1150, loss is 3.7949583387374877 and perplexity is 44.476383424644794
At time: 501.62167382240295 and batch: 1200, loss is 3.7623235988616943 and perplexity is 43.04833692400563
At time: 502.64780950546265 and batch: 1250, loss is 3.8107286167144774 and perplexity is 45.1833482184388
At time: 503.67219066619873 and batch: 1300, loss is 3.810277934074402 and perplexity is 45.16298945579131
At time: 504.6966609954834 and batch: 1350, loss is 3.7714584922790526 and perplexity is 43.44338048694989
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.361232503255208 and perplexity of 78.35364605923957
Finished 17 epochs...
Completing Train Step...
At time: 507.75643253326416 and batch: 50, loss is 3.9459244775772095 and perplexity is 51.72413381758889
At time: 508.80418372154236 and batch: 100, loss is 3.948360996246338 and perplexity is 51.85031429339862
At time: 509.8269281387329 and batch: 150, loss is 3.9387874937057497 and perplexity is 51.35629370461816
At time: 510.85198998451233 and batch: 200, loss is 3.929334125518799 and perplexity is 50.87309129514437
At time: 511.8746783733368 and batch: 250, loss is 3.920383081436157 and perplexity is 50.41975595147389
At time: 512.8990151882172 and batch: 300, loss is 3.9293873167037963 and perplexity is 50.875797367123795
At time: 513.9219827651978 and batch: 350, loss is 3.9339382743835447 and perplexity is 51.107858617808105
At time: 514.9447066783905 and batch: 400, loss is 3.9314653205871584 and perplexity is 50.981627391140215
At time: 515.969081401825 and batch: 450, loss is 3.873877773284912 and perplexity is 48.12865670899673
At time: 516.9940333366394 and batch: 500, loss is 3.9501779317855834 and perplexity is 51.94460860956564
At time: 518.0439214706421 and batch: 550, loss is 3.9475511074066163 and perplexity is 51.808338302753924
At time: 519.06667304039 and batch: 600, loss is 3.888364915847778 and perplexity is 48.83097845431763
At time: 520.0893774032593 and batch: 650, loss is 3.902922873497009 and perplexity is 49.5470574477021
At time: 521.1136124134064 and batch: 700, loss is 3.934866232872009 and perplexity is 51.15530660051408
At time: 522.1377635002136 and batch: 750, loss is 3.8950948905944824 and perplexity is 49.16071803112297
At time: 523.1666557788849 and batch: 800, loss is 3.87012309551239 and perplexity is 47.9482879366376
At time: 524.1933138370514 and batch: 850, loss is 3.830789008140564 and perplexity is 46.098896293372455
At time: 525.2162935733795 and batch: 900, loss is 3.8570012760162355 and perplexity is 47.323229080564246
At time: 526.2395095825195 and batch: 950, loss is 3.8406934356689453 and perplexity is 46.557748051824
At time: 527.2622780799866 and batch: 1000, loss is 3.8544208097457884 and perplexity is 47.20127050678109
At time: 528.2872049808502 and batch: 1050, loss is 3.8006742095947263 and perplexity is 44.73133262271889
At time: 529.3105380535126 and batch: 1100, loss is 3.7637490892410277 and perplexity is 43.109745672528554
At time: 530.3366289138794 and batch: 1150, loss is 3.792680411338806 and perplexity is 44.37518475761528
At time: 531.3600172996521 and batch: 1200, loss is 3.7603558111190796 and perplexity is 42.96371022526441
At time: 532.382809638977 and batch: 1250, loss is 3.8090385723114015 and perplexity is 45.107050844805
At time: 533.4161665439606 and batch: 1300, loss is 3.8084041404724123 and perplexity is 45.07844257154544
At time: 534.4484457969666 and batch: 1350, loss is 3.769813857078552 and perplexity is 43.37199069534584
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.361354573567708 and perplexity of 78.36321129710345
Annealing...
Finished 18 epochs...
Completing Train Step...
At time: 537.5556950569153 and batch: 50, loss is 3.945443534851074 and perplexity is 51.69926345275359
At time: 538.5786824226379 and batch: 100, loss is 3.953059597015381 and perplexity is 52.09451146325924
At time: 539.6012165546417 and batch: 150, loss is 3.945348496437073 and perplexity is 51.69435027022424
At time: 540.6252253055573 and batch: 200, loss is 3.9379463958740235 and perplexity is 51.31311619813673
At time: 541.6477863788605 and batch: 250, loss is 3.9294237804412844 and perplexity is 50.87765252266624
At time: 542.6696984767914 and batch: 300, loss is 3.9382760524749756 and perplexity is 51.33003469410059
At time: 543.7170178890228 and batch: 350, loss is 3.941009073257446 and perplexity is 51.470512622793294
At time: 544.7416100502014 and batch: 400, loss is 3.9351811170578004 and perplexity is 51.17141713392487
At time: 545.9975063800812 and batch: 450, loss is 3.8772646093368532 and perplexity is 48.29193692425246
At time: 547.0203592777252 and batch: 500, loss is 3.9543542289733886 and perplexity is 52.161998358556005
At time: 548.0443956851959 and batch: 550, loss is 3.947968726158142 and perplexity is 51.82997895477106
At time: 549.0665140151978 and batch: 600, loss is 3.888271646499634 and perplexity is 48.826424233175864
At time: 550.0894742012024 and batch: 650, loss is 3.900709910392761 and perplexity is 49.43753286926885
At time: 551.1129701137543 and batch: 700, loss is 3.931544818878174 and perplexity is 50.985680504496656
At time: 552.1352152824402 and batch: 750, loss is 3.892410683631897 and perplexity is 49.0289374318221
At time: 553.1575298309326 and batch: 800, loss is 3.8658794355392456 and perplexity is 47.74524283823243
At time: 554.1810982227325 and batch: 850, loss is 3.8271055221557617 and perplexity is 45.92940400783034
At time: 555.204030752182 and batch: 900, loss is 3.8519835233688355 and perplexity is 47.086367575754714
At time: 556.2353029251099 and batch: 950, loss is 3.8333885192871096 and perplexity is 46.21888677886357
At time: 557.2595431804657 and batch: 1000, loss is 3.846051993370056 and perplexity is 46.80790005960263
At time: 558.2834579944611 and batch: 1050, loss is 3.7915528059005736 and perplexity is 44.32517525875037
At time: 559.3059775829315 and batch: 1100, loss is 3.754070854187012 and perplexity is 42.694531929913424
At time: 560.3281054496765 and batch: 1150, loss is 3.78212571144104 and perplexity is 43.9092810616338
At time: 561.3582291603088 and batch: 1200, loss is 3.7475491094589235 and perplexity is 42.41699508731044
At time: 562.3818616867065 and batch: 1250, loss is 3.7962606525421143 and perplexity is 44.5343433655824
At time: 563.4036786556244 and batch: 1300, loss is 3.796494860649109 and perplexity is 44.54477489136457
At time: 564.42649102211 and batch: 1350, loss is 3.7563374614715577 and perplexity is 42.79141342166606
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.3541861979166665 and perplexity of 77.80348292973365
Finished 19 epochs...
Completing Train Step...
At time: 567.4867687225342 and batch: 50, loss is 3.941884822845459 and perplexity is 51.515607646109466
At time: 568.5336320400238 and batch: 100, loss is 3.947418761253357 and perplexity is 51.80148212217737
At time: 569.5914731025696 and batch: 150, loss is 3.9381821012496947 and perplexity is 51.32521240098109
At time: 570.6142010688782 and batch: 200, loss is 3.929859366416931 and perplexity is 50.89981894191913
At time: 571.6384541988373 and batch: 250, loss is 3.9207528972625734 and perplexity is 50.438405423411176
At time: 572.661465883255 and batch: 300, loss is 3.929923062324524 and perplexity is 50.903061155339714
At time: 573.6909091472626 and batch: 350, loss is 3.9338534259796143 and perplexity is 51.103522381540046
At time: 574.7150146961212 and batch: 400, loss is 3.929919271469116 and perplexity is 50.90286818956081
At time: 575.7425081729889 and batch: 450, loss is 3.8707373762130737 and perplexity is 47.977750692822696
At time: 576.7663450241089 and batch: 500, loss is 3.948283667564392 and perplexity is 51.84630493195715
At time: 577.7894520759583 and batch: 550, loss is 3.9429189586639404 and perplexity is 51.568909337030796
At time: 578.8125984668732 and batch: 600, loss is 3.883478355407715 and perplexity is 48.592944982881775
At time: 579.8454339504242 and batch: 650, loss is 3.8966057968139647 and perplexity is 49.23505140698944
At time: 580.8779683113098 and batch: 700, loss is 3.9282525634765624 and perplexity is 50.818098634975996
At time: 581.9032597541809 and batch: 750, loss is 3.8897028493881227 and perplexity is 48.896354783038646
At time: 582.9256629943848 and batch: 800, loss is 3.863363571166992 and perplexity is 47.62527325970499
At time: 583.9495804309845 and batch: 850, loss is 3.824820795059204 and perplexity is 45.824587637960036
At time: 584.974437713623 and batch: 900, loss is 3.8503248167037962 and perplexity is 47.00832984277039
At time: 585.9968545436859 and batch: 950, loss is 3.832315592765808 and perplexity is 46.16932390287016
At time: 587.0207705497742 and batch: 1000, loss is 3.8453725290298464 and perplexity is 46.77610656316875
At time: 588.043378829956 and batch: 1050, loss is 3.7914418935775758 and perplexity is 44.32025932321909
At time: 589.065712928772 and batch: 1100, loss is 3.7545213985443113 and perplexity is 42.71377204429901
At time: 590.0879292488098 and batch: 1150, loss is 3.782876243591309 and perplexity is 43.94224875887654
At time: 591.1100203990936 and batch: 1200, loss is 3.7486096954345705 and perplexity is 42.462005822086994
At time: 592.1325669288635 and batch: 1250, loss is 3.797779583930969 and perplexity is 44.602039377385616
At time: 593.1547245979309 and batch: 1300, loss is 3.7976098012924195 and perplexity is 44.59446736827147
At time: 594.1761028766632 and batch: 1350, loss is 3.757303466796875 and perplexity is 42.83277012709203
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.353804117838542 and perplexity of 77.77376144725224
Finished 20 epochs...
Completing Train Step...
At time: 597.2316451072693 and batch: 50, loss is 3.9386925220489504 and perplexity is 51.351416543917644
At time: 598.2782037258148 and batch: 100, loss is 3.943810534477234 and perplexity is 51.614907431660924
At time: 599.2995674610138 and batch: 150, loss is 3.93439368724823 and perplexity is 51.131139094821165
At time: 600.3211102485657 and batch: 200, loss is 3.9259588623046877 and perplexity is 50.70167067909851
At time: 601.3429596424103 and batch: 250, loss is 3.9167171812057493 and perplexity is 50.23526053402768
At time: 602.3651556968689 and batch: 300, loss is 3.9261258316040037 and perplexity is 50.71013700831481
At time: 603.3867568969727 and batch: 350, loss is 3.930088481903076 and perplexity is 50.9114822147479
At time: 604.4086301326752 and batch: 400, loss is 3.9263224744796754 and perplexity is 50.72010977598655
At time: 605.4300789833069 and batch: 450, loss is 3.867361083030701 and perplexity is 47.81603689047651
At time: 606.4514462947845 and batch: 500, loss is 3.9451946878433226 and perplexity is 51.68639984634178
At time: 607.4726657867432 and batch: 550, loss is 3.9400839757919313 and perplexity is 51.42291939959648
At time: 608.4940359592438 and batch: 600, loss is 3.8806700801849363 and perplexity is 48.45667405218099
At time: 609.5155968666077 and batch: 650, loss is 3.89408052444458 and perplexity is 49.110876345980095
At time: 610.5369789600372 and batch: 700, loss is 3.9261364698410035 and perplexity is 50.71067647764009
At time: 611.5583477020264 and batch: 750, loss is 3.8878976106643677 and perplexity is 48.80816481585583
At time: 612.5801119804382 and batch: 800, loss is 3.861624531745911 and perplexity is 47.542523005898175
At time: 613.601077079773 and batch: 850, loss is 3.823093457221985 and perplexity is 45.74550141783233
At time: 614.6225898265839 and batch: 900, loss is 3.848873200416565 and perplexity is 46.94014128931633
At time: 615.6696863174438 and batch: 950, loss is 3.8312342882156374 and perplexity is 46.119427784167414
At time: 616.6941294670105 and batch: 1000, loss is 3.8444229412078856 and perplexity is 46.731709624749776
At time: 617.7165234088898 and batch: 1050, loss is 3.7907846069335935 and perplexity is 44.29113778035713
At time: 618.7396152019501 and batch: 1100, loss is 3.754170341491699 and perplexity is 42.698779705116365
At time: 619.7628054618835 and batch: 1150, loss is 3.782648687362671 and perplexity is 43.93225056408999
At time: 620.7884290218353 and batch: 1200, loss is 3.7485075426101684 and perplexity is 42.4576684298047
At time: 621.8116638660431 and batch: 1250, loss is 3.79774525642395 and perplexity is 44.60050832684455
At time: 622.8361155986786 and batch: 1300, loss is 3.7974931240081786 and perplexity is 44.589264510460325
At time: 623.8594863414764 and batch: 1350, loss is 3.7571892881393434 and perplexity is 42.827879818090324
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.3537064615885415 and perplexity of 77.766166724203
Finished 21 epochs...
Completing Train Step...
At time: 626.9288878440857 and batch: 50, loss is 3.9358072423934938 and perplexity is 51.20346688718997
At time: 627.9779462814331 and batch: 100, loss is 3.940746579170227 and perplexity is 51.457003690648655
At time: 629.0010197162628 and batch: 150, loss is 3.931285514831543 and perplexity is 50.972461425176064
At time: 630.0261542797089 and batch: 200, loss is 3.9228232526779174 and perplexity is 50.54293902273343
At time: 631.049998998642 and batch: 250, loss is 3.9135261583328247 and perplexity is 50.07521416026366
At time: 632.0734434127808 and batch: 300, loss is 3.923120422363281 and perplexity is 50.55796108396022
At time: 633.0978899002075 and batch: 350, loss is 3.927115521430969 and perplexity is 50.7603491581644
At time: 634.1205108165741 and batch: 400, loss is 3.9234723901748656 and perplexity is 50.57575899084255
At time: 635.1429789066315 and batch: 450, loss is 3.8646660900115966 and perplexity is 47.687346492607105
At time: 636.165643453598 and batch: 500, loss is 3.9427289819717406 and perplexity is 51.559113376746126
At time: 637.188051700592 and batch: 550, loss is 3.9377033281326295 and perplexity is 51.30064515059464
At time: 638.2106187343597 and batch: 600, loss is 3.8783000564575194 and perplexity is 48.341966568347594
At time: 639.2333376407623 and batch: 650, loss is 3.891905331611633 and perplexity is 49.0041668187064
At time: 640.2553157806396 and batch: 700, loss is 3.924285306930542 and perplexity is 50.616889588368174
At time: 641.3018715381622 and batch: 750, loss is 3.88626398563385 and perplexity is 48.728495668593546
At time: 642.3239843845367 and batch: 800, loss is 3.859933114051819 and perplexity is 47.46217670999269
At time: 643.3466839790344 and batch: 850, loss is 3.821476926803589 and perplexity is 45.67161216149131
At time: 644.3690497875214 and batch: 900, loss is 3.8474251556396486 and perplexity is 46.87221905198359
At time: 645.3915176391602 and batch: 950, loss is 3.830080580711365 and perplexity is 46.06625013586449
At time: 646.4137246608734 and batch: 1000, loss is 3.8433274698257445 and perplexity is 46.68054440435146
At time: 647.4362926483154 and batch: 1050, loss is 3.7899177169799803 and perplexity is 44.25275887552823
At time: 648.4595396518707 and batch: 1100, loss is 3.7535507583618166 and perplexity is 42.6723324555254
At time: 649.48242020607 and batch: 1150, loss is 3.781983675956726 and perplexity is 43.903044828526006
At time: 650.5054059028625 and batch: 1200, loss is 3.747979564666748 and perplexity is 42.43525763406823
At time: 651.5281732082367 and batch: 1250, loss is 3.797307462692261 and perplexity is 44.5809867773867
At time: 652.5501563549042 and batch: 1300, loss is 3.7971876430511475 and perplexity is 44.57564541955673
At time: 653.5732734203339 and batch: 1350, loss is 3.7567180585861206 and perplexity is 42.80770280979284
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.353694254557292 and perplexity of 77.76521743596962
Finished 22 epochs...
Completing Train Step...
At time: 656.6502277851105 and batch: 50, loss is 3.933153290748596 and perplexity is 51.06775552737001
At time: 657.6728885173798 and batch: 100, loss is 3.9379956197738646 and perplexity is 51.31564209199567
At time: 658.6968336105347 and batch: 150, loss is 3.928553133010864 and perplexity is 50.833375302952284
At time: 659.7201700210571 and batch: 200, loss is 3.9200685024261475 and perplexity is 50.403897449068516
At time: 660.7435886859894 and batch: 250, loss is 3.91074369430542 and perplexity is 49.93607534234492
At time: 661.7655348777771 and batch: 300, loss is 3.9205027770996095 and perplexity is 50.425791338811244
At time: 662.7912838459015 and batch: 350, loss is 3.9245168113708497 and perplexity is 50.62860897955564
At time: 663.8195252418518 and batch: 400, loss is 3.9209459257125854 and perplexity is 50.44814241035865
At time: 664.8430776596069 and batch: 450, loss is 3.862271761894226 and perplexity is 47.57330392020791
At time: 665.8658428192139 and batch: 500, loss is 3.9405648279190064 and perplexity is 51.44765216569523
At time: 666.9136877059937 and batch: 550, loss is 3.935591869354248 and perplexity is 51.192440228371694
At time: 667.9372956752777 and batch: 600, loss is 3.8761626863479615 and perplexity is 48.238752236873914
At time: 668.9609503746033 and batch: 650, loss is 3.8899052000045775 and perplexity is 48.906249991688405
At time: 669.9844045639038 and batch: 700, loss is 3.922554759979248 and perplexity is 50.5293704342515
At time: 671.0082685947418 and batch: 750, loss is 3.884698996543884 and perplexity is 48.65229574607778
At time: 672.0310771465302 and batch: 800, loss is 3.858275318145752 and perplexity is 47.383559291572304
At time: 673.062178850174 and batch: 850, loss is 3.8199207067489622 and perplexity is 45.60059235827258
At time: 674.0859062671661 and batch: 900, loss is 3.8459875059127806 and perplexity is 46.80488163447371
At time: 675.1089832782745 and batch: 950, loss is 3.8288828897476197 and perplexity is 46.011110031336976
At time: 676.1321694850922 and batch: 1000, loss is 3.842165584564209 and perplexity is 46.62633846444699
At time: 677.1596910953522 and batch: 1050, loss is 3.788939323425293 and perplexity is 44.209483435125385
At time: 678.1829254627228 and batch: 1100, loss is 3.7527454042434694 and perplexity is 42.637979951664825
At time: 679.2063574790955 and batch: 1150, loss is 3.781136131286621 and perplexity is 43.86585080090662
At time: 680.229832649231 and batch: 1200, loss is 3.7472638940811156 and perplexity is 42.40489883313199
At time: 681.2528004646301 and batch: 1250, loss is 3.796641960144043 and perplexity is 44.551327887212416
At time: 682.2764015197754 and batch: 1300, loss is 3.796219606399536 and perplexity is 44.532515440089895
At time: 683.2996020317078 and batch: 1350, loss is 3.756049642562866 and perplexity is 42.77909901599807
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.353711751302083 and perplexity of 77.7665780860362
Annealing...
Finished 23 epochs...
Completing Train Step...
At time: 686.3736398220062 and batch: 50, loss is 3.933579668998718 and perplexity is 51.08953435028768
At time: 687.3969852924347 and batch: 100, loss is 3.942116575241089 and perplexity is 51.52754789513101
At time: 688.4200665950775 and batch: 150, loss is 3.9350208234786987 and perplexity is 51.16321534168964
At time: 689.4428596496582 and batch: 200, loss is 3.9284629964828492 and perplexity is 50.82879356548926
At time: 690.4657742977142 and batch: 250, loss is 3.9189028358459472 and perplexity is 50.34517754086654
At time: 691.489000082016 and batch: 300, loss is 3.929599905014038 and perplexity is 50.88661411663479
At time: 692.5456774234772 and batch: 350, loss is 3.932872467041016 and perplexity is 51.05341650438803
At time: 693.5686118602753 and batch: 400, loss is 3.926817817687988 and perplexity is 50.745239861383695
At time: 694.5914878845215 and batch: 450, loss is 3.868228940963745 and perplexity is 47.85755242960792
At time: 695.6240174770355 and batch: 500, loss is 3.946621952056885 and perplexity is 51.760222664971984
At time: 696.6469917297363 and batch: 550, loss is 3.939405608177185 and perplexity is 51.38804758571197
At time: 697.6698780059814 and batch: 600, loss is 3.878902487754822 and perplexity is 48.37109805596041
At time: 698.6927635669708 and batch: 650, loss is 3.891459379196167 and perplexity is 48.98231816423791
At time: 699.715879201889 and batch: 700, loss is 3.921732816696167 and perplexity is 50.48785522153716
At time: 700.7383289337158 and batch: 750, loss is 3.8848104238510133 and perplexity is 48.65771724242418
At time: 701.7616999149323 and batch: 800, loss is 3.8567476320266723 and perplexity is 47.31122735008898
At time: 702.7853691577911 and batch: 850, loss is 3.8194306325912475 and perplexity is 45.578250161495106
At time: 703.8086597919464 and batch: 900, loss is 3.844428234100342 and perplexity is 46.731956971317715
At time: 704.8319756984711 and batch: 950, loss is 3.8257485961914064 and perplexity is 45.86712347159925
At time: 705.8560121059418 and batch: 1000, loss is 3.8394577741622924 and perplexity is 46.50025396365117
At time: 706.879308462143 and batch: 1050, loss is 3.7858348846435548 and perplexity is 44.07245061528385
At time: 707.9029996395111 and batch: 1100, loss is 3.7487164115905762 and perplexity is 42.46653744591906
At time: 708.926109790802 and batch: 1150, loss is 3.776900820732117 and perplexity is 43.68045817482897
At time: 709.9494843482971 and batch: 1200, loss is 3.7429520750045775 and perplexity is 42.22245020680872
At time: 710.9732003211975 and batch: 1250, loss is 3.7924828338623047 and perplexity is 44.366418086668475
At time: 711.996262550354 and batch: 1300, loss is 3.7929705572128296 and perplexity is 44.38806190241662
At time: 713.0189983844757 and batch: 1350, loss is 3.7511177110671996 and perplexity is 42.568634854228684
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348348388671875 and perplexity of 77.35060423370409
Finished 24 epochs...
Completing Train Step...
At time: 716.0741393566132 and batch: 50, loss is 3.9329143953323364 and perplexity is 51.055557131784255
At time: 717.1209599971771 and batch: 100, loss is 3.9386425018310547 and perplexity is 51.348847999112984
At time: 718.1435475349426 and batch: 150, loss is 3.9301470041275026 and perplexity is 50.91446175511977
At time: 719.1915855407715 and batch: 200, loss is 3.9224564981460572 and perplexity is 50.524405569615006
At time: 720.2142615318298 and batch: 250, loss is 3.9126818656921385 and perplexity is 50.03295386800461
At time: 721.2365336418152 and batch: 300, loss is 3.923359227180481 and perplexity is 50.57003601033279
At time: 722.2589898109436 and batch: 350, loss is 3.9273437738418577 and perplexity is 50.771936652623765
At time: 723.281430721283 and batch: 400, loss is 3.922292318344116 and perplexity is 50.51611116362099
At time: 724.3133678436279 and batch: 450, loss is 3.863644185066223 and perplexity is 47.63863944861783
At time: 725.3368611335754 and batch: 500, loss is 3.9422455167770387 and perplexity is 51.53419236466518
At time: 726.3582110404968 and batch: 550, loss is 3.9358664751052856 and perplexity is 51.20649989721266
At time: 727.3801710605621 and batch: 600, loss is 3.8759230613708495 and perplexity is 48.22719441180033
At time: 728.4022529125214 and batch: 650, loss is 3.888887338638306 and perplexity is 48.85649553511785
At time: 729.4245009422302 and batch: 700, loss is 3.9198430299758913 and perplexity is 50.39253403992421
At time: 730.4460411071777 and batch: 750, loss is 3.883299217224121 and perplexity is 48.58424091062118
At time: 731.4674971103668 and batch: 800, loss is 3.855457887649536 and perplexity is 47.250247293434434
At time: 732.4889674186707 and batch: 850, loss is 3.8183953666687014 and perplexity is 45.5310889686937
At time: 733.5104484558105 and batch: 900, loss is 3.843990659713745 and perplexity is 46.71151273717434
At time: 734.5333499908447 and batch: 950, loss is 3.8255731534957884 and perplexity is 45.8590771256741
At time: 735.5538458824158 and batch: 1000, loss is 3.839626407623291 and perplexity is 46.50809612362109
At time: 736.5820779800415 and batch: 1050, loss is 3.786283826828003 and perplexity is 44.092241039582824
At time: 737.6148915290833 and batch: 1100, loss is 3.7494824600219725 and perplexity is 42.499081333822
At time: 738.638763666153 and batch: 1150, loss is 3.7777823114395144 and perplexity is 43.71897906821542
At time: 739.6612660884857 and batch: 1200, loss is 3.7439759016036986 and perplexity is 42.265700811192104
At time: 740.6868422031403 and batch: 1250, loss is 3.7935466527938844 and perplexity is 44.41364103603566
At time: 741.709568977356 and batch: 1300, loss is 3.7939448499679567 and perplexity is 44.43132994398932
At time: 742.734082698822 and batch: 1350, loss is 3.7519158697128296 and perplexity is 42.60262494110664
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.347898356119791 and perplexity of 77.31580177558249
Finished 25 epochs...
Completing Train Step...
At time: 745.7940256595612 and batch: 50, loss is 3.9314750099182127 and perplexity is 50.98212137139886
At time: 746.8411643505096 and batch: 100, loss is 3.936826205253601 and perplexity is 51.25566790919146
At time: 747.8650453090668 and batch: 150, loss is 3.9281837797164916 and perplexity is 50.81460329528492
At time: 748.8889367580414 and batch: 200, loss is 3.9203121519088744 and perplexity is 50.41617982884638
At time: 749.917562007904 and batch: 250, loss is 3.9105028390884398 and perplexity is 49.924049426393644
At time: 750.940589427948 and batch: 300, loss is 3.9212077140808104 and perplexity is 50.461350876076146
At time: 751.9641401767731 and batch: 350, loss is 3.925334277153015 and perplexity is 50.6700130558972
At time: 752.9875075817108 and batch: 400, loss is 3.9204372930526734 and perplexity is 50.42248936203901
At time: 754.0092537403107 and batch: 450, loss is 3.861856861114502 and perplexity is 47.55356981344859
At time: 755.0325195789337 and batch: 500, loss is 3.9405539989471436 and perplexity is 51.447095043534055
At time: 756.0555648803711 and batch: 550, loss is 3.934428038597107 and perplexity is 51.132895548586795
At time: 757.0787682533264 and batch: 600, loss is 3.8745627212524414 and perplexity is 48.1616336270367
At time: 758.1013453006744 and batch: 650, loss is 3.8876962804794313 and perplexity is 48.798339248131924
At time: 759.1239504814148 and batch: 700, loss is 3.918903880119324 and perplexity is 50.34523011502254
At time: 760.1467704772949 and batch: 750, loss is 3.88253559589386 and perplexity is 48.5471551095038
At time: 761.1702809333801 and batch: 800, loss is 3.8547236251831056 and perplexity is 47.2155659444819
At time: 762.1974720954895 and batch: 850, loss is 3.817758312225342 and perplexity is 45.502092423324896
At time: 763.225638628006 and batch: 900, loss is 3.8435163927078246 and perplexity is 46.68936426044748
At time: 764.2479810714722 and batch: 950, loss is 3.825253977775574 and perplexity is 45.84444235735974
At time: 765.2702970504761 and batch: 1000, loss is 3.8393618297576904 and perplexity is 46.495792738489
At time: 766.2927000522614 and batch: 1050, loss is 3.7862175798416136 and perplexity is 44.089320158241655
At time: 767.3152031898499 and batch: 1100, loss is 3.749540672302246 and perplexity is 42.50155537426503
At time: 768.3377311229706 and batch: 1150, loss is 3.7778795289993288 and perplexity is 43.72322952728429
At time: 769.359941482544 and batch: 1200, loss is 3.744178171157837 and perplexity is 42.27425074031655
At time: 770.4200830459595 and batch: 1250, loss is 3.793762502670288 and perplexity is 44.423228749680106
At time: 771.4444007873535 and batch: 1300, loss is 3.794113903045654 and perplexity is 44.438841831998545
At time: 772.4667642116547 and batch: 1350, loss is 3.752022566795349 and perplexity is 42.607170759403985
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.347914225260417 and perplexity of 77.3170287206487
Annealing...
Finished 26 epochs...
Completing Train Step...
At time: 775.5460090637207 and batch: 50, loss is 3.9317208242416384 and perplexity is 50.99465504748602
At time: 776.5678427219391 and batch: 100, loss is 3.9389341068267822 and perplexity is 51.36382376311206
At time: 777.591011762619 and batch: 150, loss is 3.931478533744812 and perplexity is 50.982301023870775
At time: 778.6145210266113 and batch: 200, loss is 3.9251693964004515 and perplexity is 50.661659234723224
At time: 779.6370685100555 and batch: 250, loss is 3.915279016494751 and perplexity is 50.16306588142414
At time: 780.659775018692 and batch: 300, loss is 3.926580696105957 and perplexity is 50.73320849633173
At time: 781.682163476944 and batch: 350, loss is 3.9311911058425903 and perplexity is 50.967649393781564
At time: 782.7057192325592 and batch: 400, loss is 3.925520534515381 and perplexity is 50.67945159785171
At time: 783.7298753261566 and batch: 450, loss is 3.8664931297302245 and perplexity is 47.77455280916868
At time: 784.753080368042 and batch: 500, loss is 3.945278539657593 and perplexity is 51.69073402645389
At time: 785.7765064239502 and batch: 550, loss is 3.9376016330718993 and perplexity is 51.29542839363426
At time: 786.7991201877594 and batch: 600, loss is 3.8777157640457154 and perplexity is 48.313728974419305
At time: 787.8211719989777 and batch: 650, loss is 3.8900467348098755 and perplexity is 48.91317241812942
At time: 788.8435792922974 and batch: 700, loss is 3.919564576148987 and perplexity is 50.37850399942327
At time: 789.8748004436493 and batch: 750, loss is 3.8828585290908815 and perplexity is 48.56283512917278
At time: 790.897762298584 and batch: 800, loss is 3.8538600826263427 and perplexity is 47.174810893340336
At time: 791.9206576347351 and batch: 850, loss is 3.8165361404418947 and perplexity is 45.44651501936277
At time: 792.9435775279999 and batch: 900, loss is 3.842067904472351 and perplexity is 46.62178422185581
At time: 793.9663605690002 and batch: 950, loss is 3.823576683998108 and perplexity is 45.76761221083797
At time: 794.989007472992 and batch: 1000, loss is 3.8371376419067382 and perplexity is 46.39249228355381
At time: 796.0131287574768 and batch: 1050, loss is 3.784102034568787 and perplexity is 43.99614579743841
At time: 797.0619902610779 and batch: 1100, loss is 3.7466640853881836 and perplexity is 42.37947163267924
At time: 798.0844011306763 and batch: 1150, loss is 3.7745499134063722 and perplexity is 43.57789007699932
At time: 799.1069955825806 and batch: 1200, loss is 3.7413679218292235 and perplexity is 42.15561632976851
At time: 800.1292548179626 and batch: 1250, loss is 3.7914584255218506 and perplexity is 44.32099202933298
At time: 801.1520028114319 and batch: 1300, loss is 3.7930547761917115 and perplexity is 44.391800377087634
At time: 802.1746785640717 and batch: 1350, loss is 3.7508020067214964 and perplexity is 42.55519787238294
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.345118815104167 and perplexity of 77.10119772194247
Finished 27 epochs...
Completing Train Step...
At time: 805.2509636878967 and batch: 50, loss is 3.932522473335266 and perplexity is 51.035551256499005
At time: 806.2731461524963 and batch: 100, loss is 3.9369669818878172 and perplexity is 51.26288401752202
At time: 807.2950508594513 and batch: 150, loss is 3.9280738830566406 and perplexity is 50.80901924695086
At time: 808.3177316188812 and batch: 200, loss is 3.9211867952346804 and perplexity is 50.46029529388248
At time: 809.3404099941254 and batch: 250, loss is 3.9114730405807494 and perplexity is 49.9725093177775
At time: 810.3625433444977 and batch: 300, loss is 3.9223769092559815 and perplexity is 50.52038454827042
At time: 811.3854944705963 and batch: 350, loss is 3.9273630380630493 and perplexity is 50.77291474386282
At time: 812.4080970287323 and batch: 400, loss is 3.9224097967147826 and perplexity is 50.52204606265721
At time: 813.4408347606659 and batch: 450, loss is 3.8635466957092284 and perplexity is 47.6339954146655
At time: 814.464284658432 and batch: 500, loss is 3.9423863315582275 and perplexity is 51.54144965164139
At time: 815.4861569404602 and batch: 550, loss is 3.9351829576492308 and perplexity is 51.171511319683404
At time: 816.5083565711975 and batch: 600, loss is 3.875527510643005 and perplexity is 48.20812188227399
At time: 817.5305638313293 and batch: 650, loss is 3.8881477022171023 and perplexity is 48.820372852080496
At time: 818.5526030063629 and batch: 700, loss is 3.9181025409698487 and perplexity is 50.30490267127977
At time: 819.5740809440613 and batch: 750, loss is 3.8817102909088135 and perplexity is 48.50710542925573
At time: 820.5961089134216 and batch: 800, loss is 3.853063473701477 and perplexity is 47.137245982212086
At time: 821.6183302402496 and batch: 850, loss is 3.816153607368469 and perplexity is 45.429133549001534
At time: 822.6660945415497 and batch: 900, loss is 3.842082209587097 and perplexity is 46.62245115659905
At time: 823.687902212143 and batch: 950, loss is 3.823703508377075 and perplexity is 45.773417027921795
At time: 824.716313123703 and batch: 1000, loss is 3.8377033042907716 and perplexity is 46.418742194933955
At time: 825.7375264167786 and batch: 1050, loss is 3.7849177503585816 and perplexity is 44.03204878958349
At time: 826.759051322937 and batch: 1100, loss is 3.747727780342102 and perplexity is 42.42457444636969
At time: 827.7803425788879 and batch: 1150, loss is 3.775698742866516 and perplexity is 43.6279824091948
At time: 828.8020577430725 and batch: 1200, loss is 3.7426625537872313 and perplexity is 42.21022768105115
At time: 829.8229978084564 and batch: 1250, loss is 3.7928177404403685 and perplexity is 44.381279180330935
At time: 830.8453555107117 and batch: 1300, loss is 3.794297375679016 and perplexity is 44.44699589133352
At time: 831.8675811290741 and batch: 1350, loss is 3.751853108406067 and perplexity is 42.59995122859753
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.34484375 and perplexity of 77.07999278946188
Finished 28 epochs...
Completing Train Step...
At time: 834.9232215881348 and batch: 50, loss is 3.931980695724487 and perplexity is 51.007908826175544
At time: 835.9704532623291 and batch: 100, loss is 3.9358878803253172 and perplexity is 51.20759599534107
At time: 836.9933459758759 and batch: 150, loss is 3.926768217086792 and perplexity is 50.74272292939991
At time: 838.0158410072327 and batch: 200, loss is 3.9196734714508055 and perplexity is 50.38399028053115
At time: 839.0389628410339 and batch: 250, loss is 3.909928002357483 and perplexity is 49.89535949582822
At time: 840.0612940788269 and batch: 300, loss is 3.92075252532959 and perplexity is 50.43838666370805
At time: 841.0831372737885 and batch: 350, loss is 3.9259023761749265 and perplexity is 50.69880681883438
At time: 842.1060354709625 and batch: 400, loss is 3.921130590438843 and perplexity is 50.457459262987605
At time: 843.1290230751038 and batch: 450, loss is 3.8622967624664306 and perplexity is 47.574493294895035
At time: 844.1517906188965 and batch: 500, loss is 3.941218900680542 and perplexity is 51.48131368096182
At time: 845.1876783370972 and batch: 550, loss is 3.9341893768310547 and perplexity is 51.120693537566474
At time: 846.224057674408 and batch: 600, loss is 3.8746668672561646 and perplexity is 48.16664972991074
At time: 847.259703874588 and batch: 650, loss is 3.8873912715911865 and perplexity is 48.78345759056394
At time: 848.3102788925171 and batch: 700, loss is 3.9175351667404175 and perplexity is 50.27636906127298
At time: 849.3336553573608 and batch: 750, loss is 3.88127640247345 and perplexity is 48.48606332247052
At time: 850.3565535545349 and batch: 800, loss is 3.8526970624923704 and perplexity is 47.119977530788084
At time: 851.3799312114716 and batch: 850, loss is 3.815897812843323 and perplexity is 45.417514511464006
At time: 852.4030072689056 and batch: 900, loss is 3.842042956352234 and perplexity is 46.62062111049176
At time: 853.426408290863 and batch: 950, loss is 3.823719997406006 and perplexity is 45.774171793342084
At time: 854.4504809379578 and batch: 1000, loss is 3.8378232097625733 and perplexity is 46.42430838981923
At time: 855.4727058410645 and batch: 1050, loss is 3.7851546573638917 and perplexity is 44.042481526145295
At time: 856.4967250823975 and batch: 1100, loss is 3.7480643510818483 and perplexity is 42.438855719969126
At time: 857.5196182727814 and batch: 1150, loss is 3.7760503816604616 and perplexity is 43.643326397924184
At time: 858.5422794818878 and batch: 1200, loss is 3.7430760860443115 and perplexity is 42.22768658143641
At time: 859.5650599002838 and batch: 1250, loss is 3.7932442378997804 and perplexity is 44.400211720199884
At time: 860.587161064148 and batch: 1300, loss is 3.79463885307312 and perplexity is 44.46217612737245
At time: 861.6099696159363 and batch: 1350, loss is 3.752126703262329 and perplexity is 42.611607950667576
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.344762369791667 and perplexity of 77.07372025882376
Finished 29 epochs...
Completing Train Step...
At time: 864.6660475730896 and batch: 50, loss is 3.931360583305359 and perplexity is 50.97628799368742
At time: 865.7142050266266 and batch: 100, loss is 3.9350392866134642 and perplexity is 51.16415998375003
At time: 866.7378804683685 and batch: 150, loss is 3.9258314752578736 and perplexity is 50.69521235436435
At time: 867.7618472576141 and batch: 200, loss is 3.918670687675476 and perplexity is 50.33349135652403
At time: 868.7850277423859 and batch: 250, loss is 3.908914623260498 and perplexity is 49.84482219252688
At time: 869.8081398010254 and batch: 300, loss is 3.9197334575653078 and perplexity is 50.387012710992224
At time: 870.8313155174255 and batch: 350, loss is 3.924965887069702 and perplexity is 50.65135016338939
At time: 871.8539457321167 and batch: 400, loss is 3.920276246070862 and perplexity is 50.414369626158845
At time: 872.8849046230316 and batch: 450, loss is 3.861473870277405 and perplexity is 47.53536071911951
At time: 873.9159750938416 and batch: 500, loss is 3.9404635047912597 and perplexity is 51.44243959274414
At time: 874.9642744064331 and batch: 550, loss is 3.933531255722046 and perplexity is 51.08706099839815
At time: 875.9962816238403 and batch: 600, loss is 3.874072189331055 and perplexity is 48.13801460177304
At time: 877.0200245380402 and batch: 650, loss is 3.8868639993667604 and perplexity is 48.75774220846411
At time: 878.043642282486 and batch: 700, loss is 3.917126774787903 and perplexity is 50.255840788822645
At time: 879.0678999423981 and batch: 750, loss is 3.880959572792053 and perplexity is 48.47070393175979
At time: 880.0915772914886 and batch: 800, loss is 3.8523990058898927 and perplexity is 47.105935203184615
At time: 881.1146116256714 and batch: 850, loss is 3.815654158592224 and perplexity is 45.4064496890292
At time: 882.1379251480103 and batch: 900, loss is 3.8419201278686526 and perplexity is 46.614895121961574
At time: 883.1610391139984 and batch: 950, loss is 3.823646569252014 and perplexity is 45.77081080380393
At time: 884.1851732730865 and batch: 1000, loss is 3.8377828884124754 and perplexity is 46.422436536765666
At time: 885.2081713676453 and batch: 1050, loss is 3.7852005434036253 and perplexity is 44.04450250756963
At time: 886.2363259792328 and batch: 1100, loss is 3.748164710998535 and perplexity is 42.44311509372509
At time: 887.2598206996918 and batch: 1150, loss is 3.776155462265015 and perplexity is 43.64791270600859
At time: 888.2835974693298 and batch: 1200, loss is 3.743231706619263 and perplexity is 42.23425858965766
At time: 889.3072733879089 and batch: 1250, loss is 3.793399119377136 and perplexity is 44.40708902315569
At time: 890.3307893276215 and batch: 1300, loss is 3.794753603935242 and perplexity is 44.46727849315972
At time: 891.3542022705078 and batch: 1350, loss is 3.7522074508666994 and perplexity is 42.61504887484929
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.344722493489583 and perplexity of 77.07064690514942
Finished 30 epochs...
Completing Train Step...
At time: 894.4314286708832 and batch: 50, loss is 3.9307682037353517 and perplexity is 50.94609962449453
At time: 895.45401263237 and batch: 100, loss is 3.934303979873657 and perplexity is 51.1265524603046
At time: 896.4765243530273 and batch: 150, loss is 3.9250529623031616 and perplexity is 50.65576083355719
At time: 897.5037095546722 and batch: 200, loss is 3.9178665590286257 and perplexity is 50.29303302326074
At time: 898.5283238887787 and batch: 250, loss is 3.908112244606018 and perplexity is 49.80484381220762
At time: 899.5524077415466 and batch: 300, loss is 3.9189200019836425 and perplexity is 50.34604178053431
At time: 900.600919008255 and batch: 350, loss is 3.9242229318618773 and perplexity is 50.61373245486873
At time: 901.6239693164825 and batch: 400, loss is 3.9195910358428954 and perplexity is 50.3798370168542
At time: 902.6465699672699 and batch: 450, loss is 3.8608194065093993 and perplexity is 47.50426072584922
At time: 903.6699371337891 and batch: 500, loss is 3.9398149394989015 and perplexity is 51.40908662882657
At time: 904.6956770420074 and batch: 550, loss is 3.9329929542541504 and perplexity is 51.059568158854056
At time: 905.7193863391876 and batch: 600, loss is 3.873570456504822 and perplexity is 48.113868237675945
At time: 906.7433581352234 and batch: 650, loss is 3.886412835121155 and perplexity is 48.73574942003615
At time: 907.7670478820801 and batch: 700, loss is 3.9167518424987793 and perplexity is 50.23700178329029
At time: 908.7918736934662 and batch: 750, loss is 3.8806863164901735 and perplexity is 48.457460815918736
At time: 909.8208146095276 and batch: 800, loss is 3.852122359275818 and perplexity is 47.09290530812911
At time: 910.8476099967957 and batch: 850, loss is 3.8154065227508545 and perplexity is 45.395206816783364
At time: 911.8729190826416 and batch: 900, loss is 3.841748685836792 and perplexity is 46.60690405464889
At time: 912.898199558258 and batch: 950, loss is 3.8235219383239745 and perplexity is 45.76510670063755
At time: 913.9255225658417 and batch: 1000, loss is 3.8376718950271607 and perplexity is 46.417284239320644
At time: 914.9488387107849 and batch: 1050, loss is 3.785160608291626 and perplexity is 44.04274362054994
At time: 915.9725487232208 and batch: 1100, loss is 3.7481620693206787 and perplexity is 42.443002972835885
At time: 917.0054173469543 and batch: 1150, loss is 3.776153302192688 and perplexity is 43.647818423462056
At time: 918.0342085361481 and batch: 1200, loss is 3.7432754230499268 and perplexity is 42.23610496105302
At time: 919.0571806430817 and batch: 1250, loss is 3.793445897102356 and perplexity is 44.40916633434941
At time: 920.0807163715363 and batch: 1300, loss is 3.7947747564315795 and perplexity is 44.46821909705321
At time: 921.1038892269135 and batch: 1350, loss is 3.752210955619812 and perplexity is 42.615198230336205
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.344707438151041 and perplexity of 77.0694865892031
Finished 31 epochs...
Completing Train Step...
At time: 924.1842665672302 and batch: 50, loss is 3.930212082862854 and perplexity is 50.917775311721755
At time: 925.2073795795441 and batch: 100, loss is 3.93363263130188 and perplexity is 51.09224024134881
At time: 926.2556409835815 and batch: 150, loss is 3.924355025291443 and perplexity is 50.62041863796252
At time: 927.2792747020721 and batch: 200, loss is 3.9171605014801028 and perplexity is 50.257535780679255
At time: 928.3031275272369 and batch: 250, loss is 3.907412600517273 and perplexity is 49.77001033458282
At time: 929.3262734413147 and batch: 300, loss is 3.918222107887268 and perplexity is 50.31091783302326
At time: 930.3495166301727 and batch: 350, loss is 3.923575758934021 and perplexity is 50.58098721450562
At time: 931.373297214508 and batch: 400, loss is 3.918993978500366 and perplexity is 50.349766343099425
At time: 932.3963840007782 and batch: 450, loss is 3.8602475547790527 and perplexity is 47.47710309796264
At time: 933.42001080513 and batch: 500, loss is 3.9392951679229737 and perplexity is 51.38237259005294
At time: 934.4428350925446 and batch: 550, loss is 3.932511177062988 and perplexity is 51.03497474827236
At time: 935.4661710262299 and batch: 600, loss is 3.8731136560440063 and perplexity is 48.091894819609195
At time: 936.4894289970398 and batch: 650, loss is 3.8859981727600097 and perplexity is 48.715544728461516
At time: 937.5141823291779 and batch: 700, loss is 3.916398115158081 and perplexity is 50.219234724777266
At time: 938.5375578403473 and batch: 750, loss is 3.880385985374451 and perplexity is 48.44290971782994
At time: 939.5612533092499 and batch: 800, loss is 3.851825704574585 and perplexity is 47.078937048352145
At time: 940.5846283435822 and batch: 850, loss is 3.81514928817749 and perplexity is 45.383531101888224
At time: 941.6079890727997 and batch: 900, loss is 3.8415421438217163 and perplexity is 46.59727876481659
At time: 942.6309049129486 and batch: 950, loss is 3.823365249633789 and perplexity is 45.75793638778057
At time: 943.6541037559509 and batch: 1000, loss is 3.8375224971771242 and perplexity is 46.4103501148353
At time: 944.6812372207642 and batch: 1050, loss is 3.7850804996490477 and perplexity is 44.039215557459144
At time: 945.7062203884125 and batch: 1100, loss is 3.7481095790863037 and perplexity is 42.44077518813124
At time: 946.7296254634857 and batch: 1150, loss is 3.776099705696106 and perplexity is 43.645479116001006
At time: 947.7529733181 and batch: 1200, loss is 3.7432705974578857 and perplexity is 42.23590114733284
At time: 948.7763612270355 and batch: 1250, loss is 3.793448052406311 and perplexity is 44.40926204970439
At time: 949.799574136734 and batch: 1300, loss is 3.7947557973861694 and perplexity is 44.467376030059945
At time: 950.8240089416504 and batch: 1350, loss is 3.7521805238723753 and perplexity is 42.61390139511928
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.3446952311197915 and perplexity of 77.06854580531399
Finished 32 epochs...
Completing Train Step...
At time: 953.8842480182648 and batch: 50, loss is 3.9296676445007326 and perplexity is 50.89006126650744
At time: 954.9319138526917 and batch: 100, loss is 3.933008465766907 and perplexity is 51.06036017613957
At time: 955.9553959369659 and batch: 150, loss is 3.9237155723571777 and perplexity is 50.5880596098711
At time: 956.9786674976349 and batch: 200, loss is 3.9165202522277833 and perplexity is 50.22536872953631
At time: 958.0018796920776 and batch: 250, loss is 3.9067775297164915 and perplexity is 49.73841288863436
At time: 959.0375332832336 and batch: 300, loss is 3.9176014471054077 and perplexity is 50.27970150780141
At time: 960.0666346549988 and batch: 350, loss is 3.922988748550415 and perplexity is 50.55130436272112
At time: 961.0895917415619 and batch: 400, loss is 3.918444638252258 and perplexity is 50.32211478571641
At time: 962.1118032932281 and batch: 450, loss is 3.8597250032424926 and perplexity is 47.452300345709915
At time: 963.1356611251831 and batch: 500, loss is 3.9388176250457763 and perplexity is 51.35784116187964
At time: 964.158929347992 and batch: 550, loss is 3.9320580768585205 and perplexity is 51.01185602872271
At time: 965.1815423965454 and batch: 600, loss is 3.872679705619812 and perplexity is 48.071029848960784
At time: 966.203771352768 and batch: 650, loss is 3.8855988597869873 and perplexity is 48.696095862814204
At time: 967.2258310317993 and batch: 700, loss is 3.91605920791626 and perplexity is 50.202217946167956
At time: 968.2480161190033 and batch: 750, loss is 3.8800979375839235 and perplexity is 48.42895785421722
At time: 969.2705488204956 and batch: 800, loss is 3.8515321159362794 and perplexity is 47.065117236100434
At time: 970.2951545715332 and batch: 850, loss is 3.814886622428894 and perplexity is 45.37161196816003
At time: 971.3281123638153 and batch: 900, loss is 3.8413181686401368 and perplexity is 46.58684329953037
At time: 972.350832939148 and batch: 950, loss is 3.823189687728882 and perplexity is 45.7499037424376
At time: 973.3737616539001 and batch: 1000, loss is 3.8373518991470337 and perplexity is 46.40243327584767
At time: 974.395435333252 and batch: 1050, loss is 3.784971442222595 and perplexity is 44.034413015828626
At time: 975.4173784255981 and batch: 1100, loss is 3.748023996353149 and perplexity is 42.43714314601571
At time: 976.4441845417023 and batch: 1150, loss is 3.7760122442245483 and perplexity is 43.64166198509906
At time: 977.4664866924286 and batch: 1200, loss is 3.743230314254761 and perplexity is 42.23419978421617
At time: 978.5145406723022 and batch: 1250, loss is 3.7934092569351194 and perplexity is 44.4075392048774
At time: 979.5445857048035 and batch: 1300, loss is 3.794704375267029 and perplexity is 44.465089482141934
At time: 980.5671422481537 and batch: 1350, loss is 3.752126612663269 and perplexity is 42.61160409009614
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.344706624348959 and perplexity of 77.06942386991993
Annealing...
Finished 33 epochs...
Completing Train Step...
At time: 983.622346162796 and batch: 50, loss is 3.929912762641907 and perplexity is 50.90253687266556
At time: 984.6698236465454 and batch: 100, loss is 3.9341490125656127 and perplexity is 51.11863012996719
At time: 985.7017612457275 and batch: 150, loss is 3.925237121582031 and perplexity is 50.665090420981564
At time: 986.7259607315063 and batch: 200, loss is 3.9187924385070803 and perplexity is 50.339619874022695
At time: 987.7479629516602 and batch: 250, loss is 3.909102191925049 and perplexity is 49.854172396135496
At time: 988.7706334590912 and batch: 300, loss is 3.9200597047805785 and perplexity is 50.403454015394054
At time: 989.7930278778076 and batch: 350, loss is 3.9258721446990967 and perplexity is 50.697274142249086
At time: 990.8151187896729 and batch: 400, loss is 3.921185531616211 and perplexity is 50.460231531361664
At time: 991.8380522727966 and batch: 450, loss is 3.8621455430984497 and perplexity is 47.56729965400959
At time: 992.8654959201813 and batch: 500, loss is 3.9414807558059692 and perplexity is 51.49479609195509
At time: 993.8992581367493 and batch: 550, loss is 3.9338096714019777 and perplexity is 51.101286417419686
At time: 994.9218590259552 and batch: 600, loss is 3.8747028303146362 and perplexity is 48.1683819810997
At time: 995.9441962242126 and batch: 650, loss is 3.8870792627334594 and perplexity is 48.76823909396146
At time: 996.9667823314667 and batch: 700, loss is 3.916838216781616 and perplexity is 50.24134115569358
At time: 997.9895141124725 and batch: 750, loss is 3.880255093574524 and perplexity is 48.43656935314321
At time: 999.0119223594666 and batch: 800, loss is 3.851101031303406 and perplexity is 47.044832559835804
At time: 1000.0344870090485 and batch: 850, loss is 3.8133879041671754 and perplexity is 45.30366363516204
At time: 1001.0567049980164 and batch: 900, loss is 3.8395441246032713 and perplexity is 46.50426945445377
At time: 1002.0800225734711 and batch: 950, loss is 3.8217586278915405 and perplexity is 45.68447971664275
At time: 1003.102370262146 and batch: 1000, loss is 3.83558132648468 and perplexity is 46.32034708724803
At time: 1004.150506734848 and batch: 1050, loss is 3.783038468360901 and perplexity is 43.949377858299435
At time: 1005.1732499599457 and batch: 1100, loss is 3.745516510009766 and perplexity is 42.330865889194655
At time: 1006.197018623352 and batch: 1150, loss is 3.772973589897156 and perplexity is 43.509251337031394
At time: 1007.2197914123535 and batch: 1200, loss is 3.740446591377258 and perplexity is 42.116794963122295
At time: 1008.2430717945099 and batch: 1250, loss is 3.790847363471985 and perplexity is 44.2939174260652
At time: 1009.2655298709869 and batch: 1300, loss is 3.7930248975753784 and perplexity is 44.39047403133062
At time: 1010.2974355220795 and batch: 1350, loss is 3.750849723815918 and perplexity is 42.55722853122612
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.344017333984375 and perplexity of 77.01631896309529
Finished 34 epochs...
Completing Train Step...
At time: 1013.4276330471039 and batch: 50, loss is 3.930408825874329 and perplexity is 50.92779401369666
At time: 1014.4507191181183 and batch: 100, loss is 3.9334936332702637 and perplexity is 51.08513901406414
At time: 1015.4814836978912 and batch: 150, loss is 3.923847885131836 and perplexity is 50.59475349923645
At time: 1016.5034801959991 and batch: 200, loss is 3.917277765274048 and perplexity is 50.26342951555334
At time: 1017.5253582000732 and batch: 250, loss is 3.9076695108413695 and perplexity is 49.7827984066917
At time: 1018.5551118850708 and batch: 300, loss is 3.91845401763916 and perplexity is 50.3225867785142
At time: 1019.5790793895721 and batch: 350, loss is 3.9242116594314576 and perplexity is 50.61316191830702
At time: 1020.6009290218353 and batch: 400, loss is 3.9198473405838015 and perplexity is 50.392751262848236
At time: 1021.6229615211487 and batch: 450, loss is 3.860840187072754 and perplexity is 47.505247901405845
At time: 1022.6447532176971 and batch: 500, loss is 3.9401901006698608 and perplexity is 51.42837694022584
At time: 1023.6670994758606 and batch: 550, loss is 3.9328246879577637 and perplexity is 51.050977277223055
At time: 1024.6886403560638 and batch: 600, loss is 3.8735860443115233 and perplexity is 48.11461823319907
At time: 1025.710274219513 and batch: 650, loss is 3.886167635917664 and perplexity is 48.723800918038265
At time: 1026.7317869663239 and batch: 700, loss is 3.9160919189453125 and perplexity is 50.20386013923646
At time: 1027.7535424232483 and batch: 750, loss is 3.879724049568176 and perplexity is 48.41085423183501
At time: 1028.7745831012726 and batch: 800, loss is 3.8507349061965943 and perplexity is 47.027611418228425
At time: 1029.819477558136 and batch: 850, loss is 3.813343057632446 and perplexity is 45.30163196839441
At time: 1030.8408114910126 and batch: 900, loss is 3.839660897254944 and perplexity is 46.50970019838708
At time: 1031.862535238266 and batch: 950, loss is 3.8219005489349365 and perplexity is 45.69096376577176
At time: 1032.8841218948364 and batch: 1000, loss is 3.8359188795089723 and perplexity is 46.335985299708064
At time: 1033.906230211258 and batch: 1050, loss is 3.783549036979675 and perplexity is 43.97182276079238
At time: 1034.9281978607178 and batch: 1100, loss is 3.7462140798568724 and perplexity is 42.360404926413885
At time: 1035.9501476287842 and batch: 1150, loss is 3.773707389831543 and perplexity is 43.54119013972024
At time: 1036.9781773090363 and batch: 1200, loss is 3.7412753295898438 and perplexity is 42.15171322755138
At time: 1038.0005683898926 and batch: 1250, loss is 3.7917328691482544 and perplexity is 44.33315731237716
At time: 1039.0228691101074 and batch: 1300, loss is 3.7939031457901002 and perplexity is 44.429477010540744
At time: 1040.0515632629395 and batch: 1350, loss is 3.751598525047302 and perplexity is 42.58910737032204
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.343843587239584 and perplexity of 77.00293879079398
Finished 35 epochs...
Completing Train Step...
At time: 1043.1331725120544 and batch: 50, loss is 3.9303846168518066 and perplexity is 50.92656111650806
At time: 1044.157127380371 and batch: 100, loss is 3.9330472993850707 and perplexity is 51.06234307317124
At time: 1045.1839334964752 and batch: 150, loss is 3.9231956386566162 and perplexity is 50.56176400941072
At time: 1046.2128703594208 and batch: 200, loss is 3.916512894630432 and perplexity is 50.22499919285582
At time: 1047.2355892658234 and batch: 250, loss is 3.9069105863571165 and perplexity is 49.74503135506903
At time: 1048.2582333087921 and batch: 300, loss is 3.9176100587844847 and perplexity is 50.280134502319285
At time: 1049.281287431717 and batch: 350, loss is 3.923404083251953 and perplexity is 50.57230443435832
At time: 1050.304405927658 and batch: 400, loss is 3.919158487319946 and perplexity is 50.358050005075704
At time: 1051.336050271988 and batch: 450, loss is 3.8601789808273317 and perplexity is 47.473847517012246
At time: 1052.3599717617035 and batch: 500, loss is 3.9395555877685546 and perplexity is 51.39575532207729
At time: 1053.3839774131775 and batch: 550, loss is 3.932306671142578 and perplexity is 51.0245388609251
At time: 1054.4077050685883 and batch: 600, loss is 3.8730920553207397 and perplexity is 48.09085601111738
At time: 1055.43111038208 and batch: 650, loss is 3.8857464265823363 and perplexity is 48.703282319854864
At time: 1056.4804203510284 and batch: 700, loss is 3.9157538318634035 and perplexity is 50.186889731560875
At time: 1057.5028591156006 and batch: 750, loss is 3.8794946002960207 and perplexity is 48.39974767081199
At time: 1058.5262567996979 and batch: 800, loss is 3.8505515956878664 and perplexity is 47.01899155293518
At time: 1059.5494711399078 and batch: 850, loss is 3.8132912254333498 and perplexity is 45.29928394603894
At time: 1060.5718438625336 and batch: 900, loss is 3.839709787368774 and perplexity is 46.51197411850964
At time: 1061.5947456359863 and batch: 950, loss is 3.8219700765609743 and perplexity is 45.69414066045347
At time: 1062.6183307170868 and batch: 1000, loss is 3.836093096733093 and perplexity is 46.34405852967132
At time: 1063.6418945789337 and batch: 1050, loss is 3.783789358139038 and perplexity is 43.982391390099316
At time: 1064.6655316352844 and batch: 1100, loss is 3.746533031463623 and perplexity is 42.37391800052157
At time: 1065.6889085769653 and batch: 1150, loss is 3.7740368175506593 and perplexity is 43.55553617753711
At time: 1066.7127649784088 and batch: 1200, loss is 3.741657185554504 and perplexity is 42.167812184213666
At time: 1067.7360227108002 and batch: 1250, loss is 3.7921267890930177 and perplexity is 44.35062446736133
At time: 1068.7592344284058 and batch: 1300, loss is 3.794261837005615 and perplexity is 44.44541633213077
At time: 1069.782269001007 and batch: 1350, loss is 3.7519138288497924 and perplexity is 42.60253799507283
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.343787434895833 and perplexity of 76.99861501670134
Finished 36 epochs...
Completing Train Step...
At time: 1072.8436994552612 and batch: 50, loss is 3.930196795463562 and perplexity is 50.91699691730934
At time: 1073.89386510849 and batch: 100, loss is 3.9326540756225588 and perplexity is 51.04226809374348
At time: 1074.9173924922943 and batch: 150, loss is 3.9227215909957884 and perplexity is 50.53780100370688
At time: 1075.9414675235748 and batch: 200, loss is 3.915977020263672 and perplexity is 50.198092113268835
At time: 1076.9696543216705 and batch: 250, loss is 3.9063727474212646 and perplexity is 49.71828373394192
At time: 1078.0069024562836 and batch: 300, loss is 3.9170335292816163 and perplexity is 50.251154875977996
At time: 1079.0361535549164 and batch: 350, loss is 3.9228748178482054 and perplexity is 50.54554534518814
At time: 1080.0605714321136 and batch: 400, loss is 3.9186875009536744 and perplexity is 50.33433763463122
At time: 1081.0902652740479 and batch: 450, loss is 3.8597291803359983 and perplexity is 47.45249855881949
At time: 1082.142527103424 and batch: 500, loss is 3.939142189025879 and perplexity is 51.37451277257243
At time: 1083.166175365448 and batch: 550, loss is 3.9319518852233886 and perplexity is 51.00643928393149
At time: 1084.1906847953796 and batch: 600, loss is 3.8727743244171142 and perplexity is 48.07557848718011
At time: 1085.2142798900604 and batch: 650, loss is 3.885468158721924 and perplexity is 48.68973164713445
At time: 1086.2420063018799 and batch: 700, loss is 3.915535559654236 and perplexity is 50.17593652370185
At time: 1087.270217180252 and batch: 750, loss is 3.8793396615982054 and perplexity is 48.39224925784546
At time: 1088.2942440509796 and batch: 800, loss is 3.850416784286499 and perplexity is 47.01265328403809
At time: 1089.317432641983 and batch: 850, loss is 3.8132172346115114 and perplexity is 45.2959323387867
At time: 1090.3415343761444 and batch: 900, loss is 3.8397114133834838 and perplexity is 46.512049747725214
At time: 1091.365299463272 and batch: 950, loss is 3.821990647315979 and perplexity is 45.695080633094086
At time: 1092.3887379169464 and batch: 1000, loss is 3.836167583465576 and perplexity is 46.34751067572913
At time: 1093.4130461215973 and batch: 1050, loss is 3.783905715942383 and perplexity is 43.987509382300715
At time: 1094.4372298717499 and batch: 1100, loss is 3.7466907835006715 and perplexity is 42.380603099684016
At time: 1095.4617636203766 and batch: 1150, loss is 3.7741963052749634 and perplexity is 43.562483304858944
At time: 1096.499465227127 and batch: 1200, loss is 3.741851181983948 and perplexity is 42.17599338275085
At time: 1097.5237846374512 and batch: 1250, loss is 3.7923216342926027 and perplexity is 44.35926681557008
At time: 1098.547679424286 and batch: 1300, loss is 3.794422912597656 and perplexity is 44.45257598048679
At time: 1099.571320772171 and batch: 1350, loss is 3.752055439949036 and perplexity is 42.608571414498364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.343760172526042 and perplexity of 76.9965158805992
Finished 37 epochs...
Completing Train Step...
At time: 1102.6321523189545 and batch: 50, loss is 3.9299668312072753 and perplexity is 50.905289174213706
At time: 1103.68066239357 and batch: 100, loss is 3.932301917076111 and perplexity is 51.02429628745251
At time: 1104.703778743744 and batch: 150, loss is 3.9223262023925782 and perplexity is 50.51782288297961
At time: 1105.7272865772247 and batch: 200, loss is 3.9155493354797364 and perplexity is 50.176627743408766
At time: 1106.7507860660553 and batch: 250, loss is 3.9059431886672975 and perplexity is 49.696931396301885
At time: 1107.8000168800354 and batch: 300, loss is 3.916587634086609 and perplexity is 50.228753122263555
At time: 1108.8240201473236 and batch: 350, loss is 3.9224700260162355 and perplexity is 50.52508906183748
At time: 1109.8479342460632 and batch: 400, loss is 3.918319025039673 and perplexity is 50.31579406020572
At time: 1110.871666431427 and batch: 450, loss is 3.8593776559829713 and perplexity is 47.43582078145828
At time: 1111.8949782848358 and batch: 500, loss is 3.938822178840637 and perplexity is 51.35807503548529
At time: 1112.9200730323792 and batch: 550, loss is 3.9316714811325073 and perplexity is 50.99213887473531
At time: 1113.9434368610382 and batch: 600, loss is 3.872524881362915 and perplexity is 48.06358786360093
At time: 1114.9668183326721 and batch: 650, loss is 3.8852461910247804 and perplexity is 48.67892529890068
At time: 1115.9901704788208 and batch: 700, loss is 3.9153614377975465 and perplexity is 50.167200557056645
At time: 1117.0138745307922 and batch: 750, loss is 3.8792098999023437 and perplexity is 48.38597020491428
At time: 1118.0369062423706 and batch: 800, loss is 3.8502953338623045 and perplexity is 47.00694392406335
At time: 1119.0601136684418 and batch: 850, loss is 3.8131293869018554 and perplexity is 45.291953369648226
At time: 1120.0833745002747 and batch: 900, loss is 3.839682660102844 and perplexity is 46.51071239293246
At time: 1121.106418132782 and batch: 950, loss is 3.821979627609253 and perplexity is 45.694577089481136
At time: 1122.1290760040283 and batch: 1000, loss is 3.83618586063385 and perplexity is 46.34835778472219
At time: 1123.1515181064606 and batch: 1050, loss is 3.783956913948059 and perplexity is 43.98976151270754
At time: 1124.1740679740906 and batch: 1100, loss is 3.7467685747146606 and perplexity is 42.38390006648459
At time: 1125.197514295578 and batch: 1150, loss is 3.774272418022156 and perplexity is 43.56579909132301
At time: 1126.2208478450775 and batch: 1200, loss is 3.7419541311264037 and perplexity is 42.18033558861118
At time: 1127.24462890625 and batch: 1250, loss is 3.7924225616455076 and perplexity is 44.36374410488326
At time: 1128.2684490680695 and batch: 1300, loss is 3.7944963693618776 and perplexity is 44.45584144281331
At time: 1129.2921016216278 and batch: 1350, loss is 3.752118830680847 and perplexity is 42.611272488632395
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.343749593098958 and perplexity of 76.99570130588262
Finished 38 epochs...
Completing Train Step...
At time: 1132.3729491233826 and batch: 50, loss is 3.9297288846969605 and perplexity is 50.89317787927546
At time: 1133.4099752902985 and batch: 100, loss is 3.931980376243591 and perplexity is 51.00789253012573
At time: 1134.4693336486816 and batch: 150, loss is 3.9219765281677246 and perplexity is 50.50016119052098
At time: 1135.5066328048706 and batch: 200, loss is 3.9151836967468263 and perplexity is 50.15828457850911
At time: 1136.5318639278412 and batch: 250, loss is 3.905576663017273 and perplexity is 49.67871953397886
At time: 1137.5593001842499 and batch: 300, loss is 3.9162151861190795 and perplexity is 50.210049008622406
At time: 1138.5891420841217 and batch: 350, loss is 3.922131447792053 and perplexity is 50.507985262556645
At time: 1139.6161806583405 and batch: 400, loss is 3.918007173538208 and perplexity is 50.30010545066602
At time: 1140.6391959190369 and batch: 450, loss is 3.8590804290771485 and perplexity is 47.42172367434579
At time: 1141.6623277664185 and batch: 500, loss is 3.93855224609375 and perplexity is 51.34421368011716
At time: 1142.6853878498077 and batch: 550, loss is 3.9314307403564452 and perplexity is 50.979864465184264
At time: 1143.708456993103 and batch: 600, loss is 3.8723079633712767 and perplexity is 48.05316313734685
At time: 1144.731234550476 and batch: 650, loss is 3.8850514125823974 and perplexity is 48.66944461700028
At time: 1145.7540163993835 and batch: 700, loss is 3.915206265449524 and perplexity is 50.15941659869566
At time: 1146.7769248485565 and batch: 750, loss is 3.8790894746780396 and perplexity is 48.38014366443745
At time: 1147.7999095916748 and batch: 800, loss is 3.850177230834961 and perplexity is 47.00139258950091
At time: 1148.8231711387634 and batch: 850, loss is 3.813033618927002 and perplexity is 45.28761605868792
At time: 1149.852299451828 and batch: 900, loss is 3.839634141921997 and perplexity is 46.50845583251979
At time: 1150.8856465816498 and batch: 950, loss is 3.821947922706604 and perplexity is 45.693128370328814
At time: 1151.9085075855255 and batch: 1000, loss is 3.836171269416809 and perplexity is 46.34768151070811
At time: 1152.931170463562 and batch: 1050, loss is 3.7839708948135375 and perplexity is 43.990376531944925
At time: 1153.954931974411 and batch: 1100, loss is 3.7468013525009156 and perplexity is 42.38528933967015
At time: 1154.9773902893066 and batch: 1150, loss is 3.774302477836609 and perplexity is 43.567108690843256
At time: 1156.0045356750488 and batch: 1200, loss is 3.7420074701309205 and perplexity is 42.1825855057253
At time: 1157.0269751548767 and batch: 1250, loss is 3.7924737691879273 and perplexity is 44.36601592135798
At time: 1158.049762248993 and batch: 1300, loss is 3.7945262384414673 and perplexity is 44.457169317710694
At time: 1159.0734651088715 and batch: 1350, loss is 3.752143158912659 and perplexity is 42.61230915815741
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.343741455078125 and perplexity of 76.99507471581093
Finished 39 epochs...
Completing Train Step...
At time: 1162.1640458106995 and batch: 50, loss is 3.929492964744568 and perplexity is 50.881172579373654
At time: 1163.1871464252472 and batch: 100, loss is 3.9316813802719115 and perplexity is 50.992643655524994
At time: 1164.209505558014 and batch: 150, loss is 3.9216566467285157 and perplexity is 50.48400970969626
At time: 1165.2319416999817 and batch: 200, loss is 3.9148570823669435 and perplexity is 50.14190483657076
At time: 1166.2547762393951 and batch: 250, loss is 3.9052506637573243 and perplexity is 49.662526947704556
At time: 1167.2771353721619 and batch: 300, loss is 3.915888590812683 and perplexity is 50.19365331980549
At time: 1168.2996492385864 and batch: 350, loss is 3.9218322372436525 and perplexity is 50.49287500127514
At time: 1169.3223276138306 and batch: 400, loss is 3.917729616165161 and perplexity is 50.28614622286606
At time: 1170.3446731567383 and batch: 450, loss is 3.8588163375854494 and perplexity is 47.40920165415396
At time: 1171.3671572208405 and batch: 500, loss is 3.9382748889923094 and perplexity is 51.32997497252971
At time: 1172.389543056488 and batch: 550, loss is 3.9312135553359986 and perplexity is 50.96879360453409
At time: 1173.4130668640137 and batch: 600, loss is 3.8721088218688964 and perplexity is 48.04359471101257
At time: 1174.4355957508087 and batch: 650, loss is 3.884871730804443 and perplexity is 48.66070039027208
At time: 1175.4579911231995 and batch: 700, loss is 3.915059928894043 and perplexity is 50.152076979486054
At time: 1176.49174451828 and batch: 750, loss is 3.8789727783203123 and perplexity is 48.37449820729403
At time: 1177.5270783901215 and batch: 800, loss is 3.8500598239898682 and perplexity is 46.99587462821157
At time: 1178.5497529506683 and batch: 850, loss is 3.812932543754578 and perplexity is 45.28303883641177
At time: 1179.5727608203888 and batch: 900, loss is 3.8395724487304688 and perplexity is 46.50558666595137
At time: 1180.5953795909882 and batch: 950, loss is 3.821902284622192 and perplexity is 45.691043071064094
At time: 1181.6176290512085 and batch: 1000, loss is 3.8361360883712767 and perplexity is 46.346050979496624
At time: 1182.640085220337 and batch: 1050, loss is 3.7839617252349855 and perplexity is 43.98997316058116
At time: 1183.662696838379 and batch: 1100, loss is 3.7468067693710325 and perplexity is 42.38551893589922
At time: 1184.6853654384613 and batch: 1150, loss is 3.7743048906326293 and perplexity is 43.56721380951654
At time: 1185.7469794750214 and batch: 1200, loss is 3.7420316171646117 and perplexity is 42.18360410233668
At time: 1186.7699279785156 and batch: 1250, loss is 3.7924963521957396 and perplexity is 44.367017850755374
At time: 1187.7930386066437 and batch: 1300, loss is 3.7945318603515625 and perplexity is 44.45741925262224
At time: 1188.8161509037018 and batch: 1350, loss is 3.7521459245681763 and perplexity is 42.61242700928831
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.34373779296875 and perplexity of 76.99479275194228
Finished 40 epochs...
Completing Train Step...
At time: 1191.872775554657 and batch: 50, loss is 3.9292613554000853 and perplexity is 50.86938938894721
At time: 1192.9263288974762 and batch: 100, loss is 3.931399116516113 and perplexity is 50.97825231158164
At time: 1193.954280614853 and batch: 150, loss is 3.921357078552246 and perplexity is 50.468888571995656
At time: 1194.9802551269531 and batch: 200, loss is 3.914557332992554 and perplexity is 50.12687708435747
At time: 1196.0029547214508 and batch: 250, loss is 3.9049526834487915 and perplexity is 49.64773069720729
At time: 1197.0257914066315 and batch: 300, loss is 3.915592885017395 and perplexity is 50.178812959930504
At time: 1198.0482232570648 and batch: 350, loss is 3.9215586948394776 and perplexity is 50.47906494775732
At time: 1199.072538614273 and batch: 400, loss is 3.917474527359009 and perplexity is 50.27332042578825
At time: 1200.0950937271118 and batch: 450, loss is 3.8585735845565794 and perplexity is 47.39769432363229
At time: 1201.1173377037048 and batch: 500, loss is 3.9380424451828 and perplexity is 51.31804502418012
At time: 1202.1393682956696 and batch: 550, loss is 3.931010856628418 and perplexity is 50.95846334294422
At time: 1203.1614820957184 and batch: 600, loss is 3.8719208908081053 and perplexity is 48.03456667564502
At time: 1204.1835038661957 and batch: 650, loss is 3.8847004413604735 and perplexity is 48.65236603977257
At time: 1205.2058730125427 and batch: 700, loss is 3.914918789863586 and perplexity is 50.144999063462635
At time: 1206.2283294200897 and batch: 750, loss is 3.8788582372665403 and perplexity is 48.36895765860988
At time: 1207.250853061676 and batch: 800, loss is 3.8499421501159667 and perplexity is 46.99034476695316
At time: 1208.2728333473206 and batch: 850, loss is 3.8128286027908325 and perplexity is 45.27833231831804
At time: 1209.2952661514282 and batch: 900, loss is 3.8395006275177 and perplexity is 46.502246698258205
At time: 1210.32652926445 and batch: 950, loss is 3.821846776008606 and perplexity is 45.68850689500038
At time: 1211.3495645523071 and batch: 1000, loss is 3.8360873460769653 and perplexity is 46.34379202169345
At time: 1212.3980700969696 and batch: 1050, loss is 3.783937315940857 and perplexity is 43.988899409492376
At time: 1213.4205207824707 and batch: 1100, loss is 3.7467943906784056 and perplexity is 42.38499426183587
At time: 1214.4441614151 and batch: 1150, loss is 3.7742892789840696 and perplexity is 43.56653365879497
At time: 1215.4666635990143 and batch: 1200, loss is 3.742036919593811 and perplexity is 42.18382777850382
At time: 1216.492249250412 and batch: 1250, loss is 3.7925009059906007 and perplexity is 44.367219889513294
At time: 1217.5152316093445 and batch: 1300, loss is 3.794522876739502 and perplexity is 44.457019866208434
At time: 1218.5402619838715 and batch: 1350, loss is 3.7521356773376464 and perplexity is 42.61199035216257
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.343734537760417 and perplexity of 76.99454211825925
Finished 41 epochs...
Completing Train Step...
At time: 1221.5953860282898 and batch: 50, loss is 3.9290353298187255 and perplexity is 50.857892904935845
At time: 1222.6421802043915 and batch: 100, loss is 3.9311300563812255 and perplexity is 50.96453794121626
At time: 1223.664288520813 and batch: 150, loss is 3.9210694932937624 and perplexity is 50.45437655045205
At time: 1224.6871564388275 and batch: 200, loss is 3.9142777585983275 and perplexity is 50.112864851884126
At time: 1225.7094457149506 and batch: 250, loss is 3.9046750116348266 and perplexity is 49.63394683554885
At time: 1226.732678413391 and batch: 300, loss is 3.915320725440979 and perplexity is 50.16515817367498
At time: 1227.755290031433 and batch: 350, loss is 3.9213032484054566 and perplexity is 50.46617189743568
At time: 1228.777694940567 and batch: 400, loss is 3.917234544754028 and perplexity is 50.2612571509374
At time: 1229.800103187561 and batch: 450, loss is 3.858345603942871 and perplexity is 47.386889799849804
At time: 1230.8227226734161 and batch: 500, loss is 3.937837872505188 and perplexity is 51.30754782805607
At time: 1231.8456072807312 and batch: 550, loss is 3.9308184576034546 and perplexity is 50.94865992739744
At time: 1232.8678512573242 and batch: 600, loss is 3.871739640235901 and perplexity is 48.02586117191207
At time: 1233.8902723789215 and batch: 650, loss is 3.8845344734191896 and perplexity is 48.644291976778696
At time: 1234.9126574993134 and batch: 700, loss is 3.9147798156738283 and perplexity is 50.138030687070824
At time: 1235.9352021217346 and batch: 750, loss is 3.8787432956695556 and perplexity is 48.363398372874826
At time: 1236.957607269287 and batch: 800, loss is 3.849822859764099 and perplexity is 46.98473960651895
At time: 1238.0057826042175 and batch: 850, loss is 3.8127219581604006 and perplexity is 45.27350388476922
At time: 1239.02814412117 and batch: 900, loss is 3.8394213914871216 and perplexity is 46.49856219079165
At time: 1240.0505821704865 and batch: 950, loss is 3.821783628463745 and perplexity is 45.6856218690537
At time: 1241.0879776477814 and batch: 1000, loss is 3.836029095649719 and perplexity is 46.341092554631295
At time: 1242.113363981247 and batch: 1050, loss is 3.783902311325073 and perplexity is 43.98735962191979
At time: 1243.1357281208038 and batch: 1100, loss is 3.746769094467163 and perplexity is 42.38392209562844
At time: 1244.158034324646 and batch: 1150, loss is 3.7742607593536377 and perplexity is 43.56529117507349
At time: 1245.1803481578827 and batch: 1200, loss is 3.7420290660858155 and perplexity is 42.18349648877597
At time: 1246.2034704685211 and batch: 1250, loss is 3.7924931764602663 and perplexity is 44.36687695306667
At time: 1247.2272272109985 and batch: 1300, loss is 3.7945042705535887 and perplexity is 44.456192698326895
At time: 1248.2576930522919 and batch: 1350, loss is 3.752117419242859 and perplexity is 42.61121234550612
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.343734130859375 and perplexity of 76.99451078910622
Finished 42 epochs...
Completing Train Step...
At time: 1251.339994430542 and batch: 50, loss is 3.9288144731521606 and perplexity is 50.84666184051372
At time: 1252.3625767230988 and batch: 100, loss is 3.9308711099624634 and perplexity is 50.95134256515394
At time: 1253.3852136135101 and batch: 150, loss is 3.9205484867095945 and perplexity is 50.428096334746364
At time: 1254.4081716537476 and batch: 200, loss is 3.9140159368515013 and perplexity is 50.099745931554395
At time: 1255.4307837486267 and batch: 250, loss is 3.9044133758544923 and perplexity is 49.620962517792584
At time: 1256.4579319953918 and batch: 300, loss is 3.915065975189209 and perplexity is 50.152380214663395
At time: 1257.4856736660004 and batch: 350, loss is 3.9210606718063357 and perplexity is 50.45393146976682
At time: 1258.508423089981 and batch: 400, loss is 3.9170058250427244 and perplexity is 50.24976272526305
At time: 1259.5311539173126 and batch: 450, loss is 3.8581266450881957 and perplexity is 47.37651515658405
At time: 1260.5533974170685 and batch: 500, loss is 3.937641906738281 and perplexity is 51.29749429020463
At time: 1261.576078414917 and batch: 550, loss is 3.9306318283081056 and perplexity is 50.93915230212451
At time: 1262.5986762046814 and batch: 600, loss is 3.8715610551834105 and perplexity is 48.01728523676349
At time: 1263.6469702720642 and batch: 650, loss is 3.8843707609176636 and perplexity is 48.63632894989553
At time: 1264.6699132919312 and batch: 700, loss is 3.9146413373947144 and perplexity is 50.13108813957023
At time: 1265.7001278400421 and batch: 750, loss is 3.8786275148391725 and perplexity is 48.357799142599085
At time: 1266.7251522541046 and batch: 800, loss is 3.849701862335205 and perplexity is 46.979054917752606
At time: 1267.7482221126556 and batch: 850, loss is 3.812613034248352 and perplexity is 45.26857278617609
At time: 1268.770846605301 and batch: 900, loss is 3.839337396621704 and perplexity is 46.4946567143406
At time: 1269.793957233429 and batch: 950, loss is 3.8217149209976196 and perplexity is 45.682483033568666
At time: 1270.8166341781616 and batch: 1000, loss is 3.835963935852051 and perplexity is 46.338073076792064
At time: 1271.8394439220428 and batch: 1050, loss is 3.7838593530654907 and perplexity is 43.98547004209363
At time: 1272.8622980117798 and batch: 1100, loss is 3.7467336559295656 and perplexity is 42.38242009802619
At time: 1273.885252714157 and batch: 1150, loss is 3.774222378730774 and perplexity is 43.563619144149946
At time: 1274.9091973304749 and batch: 1200, loss is 3.7420105934143066 and perplexity is 42.182717254099536
At time: 1275.9339425563812 and batch: 1250, loss is 3.792475423812866 and perplexity is 44.36608933053509
At time: 1276.9651863574982 and batch: 1300, loss is 3.7944782304763796 and perplexity is 44.45503507070902
At time: 1277.999806880951 and batch: 1350, loss is 3.7520930480957033 and perplexity is 42.610173874034
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.343734130859375 and perplexity of 76.99451078910622
Finished 43 epochs...
Completing Train Step...
At time: 1281.1182346343994 and batch: 50, loss is 3.928595337867737 and perplexity is 50.83552076355542
At time: 1282.1434988975525 and batch: 100, loss is 3.930619354248047 and perplexity is 50.938516888042464
At time: 1283.1685392856598 and batch: 150, loss is 3.9202938890457153 and perplexity is 50.41525909346082
At time: 1284.1932928562164 and batch: 200, loss is 3.913760805130005 and perplexity is 50.086965527540904
At time: 1285.2182648181915 and batch: 250, loss is 3.9041602277755736 and perplexity is 49.60840265627659
At time: 1286.243218421936 and batch: 300, loss is 3.914816641807556 and perplexity is 50.13987711089187
At time: 1287.267984867096 and batch: 350, loss is 3.9208284282684325 and perplexity is 50.442215230784214
At time: 1288.2929456233978 and batch: 400, loss is 3.9167882680892943 and perplexity is 50.23883172907418
At time: 1289.3168728351593 and batch: 450, loss is 3.857918086051941 and perplexity is 47.36663538653535
At time: 1290.3670403957367 and batch: 500, loss is 3.937453742027283 and perplexity is 51.2878428200781
At time: 1291.391360282898 and batch: 550, loss is 3.930448875427246 and perplexity is 50.92983368992176
At time: 1292.416693687439 and batch: 600, loss is 3.8713898181915285 and perplexity is 48.009063605225016
At time: 1293.4423460960388 and batch: 650, loss is 3.8842119216918944 and perplexity is 48.628604206573236
At time: 1294.4672448635101 and batch: 700, loss is 3.9145060396194458 and perplexity is 50.124305973689474
At time: 1295.4914939403534 and batch: 750, loss is 3.878514928817749 and perplexity is 48.35235503685968
At time: 1296.5157244205475 and batch: 800, loss is 3.8495848035812377 and perplexity is 46.97355592997997
At time: 1297.5400836467743 and batch: 850, loss is 3.812502884864807 and perplexity is 45.26358675539888
At time: 1298.56458902359 and batch: 900, loss is 3.839248924255371 and perplexity is 46.49054340399908
At time: 1299.5893242359161 and batch: 950, loss is 3.8216427516937257 and perplexity is 45.67918627953164
At time: 1300.6142003536224 and batch: 1000, loss is 3.83589467048645 and perplexity is 46.334863564374466
At time: 1301.6389055252075 and batch: 1050, loss is 3.7838103723526 and perplexity is 43.98331565517628
At time: 1302.663313627243 and batch: 1100, loss is 3.746692867279053 and perplexity is 42.38069141156056
At time: 1303.6889986991882 and batch: 1150, loss is 3.7741787433624268 and perplexity is 43.56171827105501
At time: 1304.7146577835083 and batch: 1200, loss is 3.7419859790802 and perplexity is 42.18167896738194
At time: 1305.739179611206 and batch: 1250, loss is 3.7924510192871095 and perplexity is 44.365006610376994
At time: 1306.7647216320038 and batch: 1300, loss is 3.7944456815719603 and perplexity is 44.45358813156982
At time: 1307.8065295219421 and batch: 1350, loss is 3.7520633792877196 and perplexity is 42.608909699720535
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.343737386067708 and perplexity of 76.99476142268728
Annealing...
Finished 44 epochs...
Completing Train Step...
At time: 1310.8902599811554 and batch: 50, loss is 3.9287321758270264 and perplexity is 50.842477468435916
At time: 1311.9407925605774 and batch: 100, loss is 3.9311504888534547 and perplexity is 50.96557928336098
At time: 1312.9652206897736 and batch: 150, loss is 3.920921678543091 and perplexity is 50.4469192005287
At time: 1313.9900603294373 and batch: 200, loss is 3.9147101354599 and perplexity is 50.134537180082184
At time: 1315.014527797699 and batch: 250, loss is 3.9051488637924194 and perplexity is 49.65747156152762
At time: 1316.064707994461 and batch: 300, loss is 3.915797109603882 and perplexity is 50.18906175374986
At time: 1317.0937461853027 and batch: 350, loss is 3.9220066118240355 and perplexity is 50.501680442866096
At time: 1318.124020576477 and batch: 400, loss is 3.9179500675201417 and perplexity is 50.297233093950624
At time: 1319.1496539115906 and batch: 450, loss is 3.8588502740859987 and perplexity is 47.4108105838525
At time: 1320.1740489006042 and batch: 500, loss is 3.9385284852981566 and perplexity is 51.34299371524473
At time: 1321.1983242034912 and batch: 550, loss is 3.931155071258545 and perplexity is 50.965812828826
At time: 1322.2232587337494 and batch: 600, loss is 3.872180533409119 and perplexity is 48.047040114723245
At time: 1323.2472598552704 and batch: 650, loss is 3.88476309299469 and perplexity is 48.65541428550126
At time: 1324.27188539505 and batch: 700, loss is 3.914804139137268 and perplexity is 50.139250232458906
At time: 1325.2960259914398 and batch: 750, loss is 3.878549656867981 and perplexity is 48.35403424903194
At time: 1326.320741891861 and batch: 800, loss is 3.849348816871643 and perplexity is 46.96247210294748
At time: 1327.3452343940735 and batch: 850, loss is 3.81160870552063 and perplexity is 45.22313108108855
At time: 1328.369843006134 and batch: 900, loss is 3.8380517053604124 and perplexity is 46.43491735192344
At time: 1329.3946161270142 and batch: 950, loss is 3.8206870794296264 and perplexity is 45.63555280113112
At time: 1330.4189870357513 and batch: 1000, loss is 3.834858145713806 and perplexity is 46.286861212564055
At time: 1331.4432537555695 and batch: 1050, loss is 3.782553586959839 and perplexity is 43.92807278802128
At time: 1332.4684309959412 and batch: 1100, loss is 3.745120129585266 and perplexity is 42.31409008762338
At time: 1333.4932312965393 and batch: 1150, loss is 3.772367081642151 and perplexity is 43.482870617797076
At time: 1334.5187199115753 and batch: 1200, loss is 3.7402430295944216 and perplexity is 42.10822246579826
At time: 1335.5431461334229 and batch: 1250, loss is 3.790783681869507 and perplexity is 44.29109680823517
At time: 1336.569756269455 and batch: 1300, loss is 3.793089213371277 and perplexity is 44.3933291318113
At time: 1337.5940449237823 and batch: 1350, loss is 3.7510995197296144 and perplexity is 42.56786048086497
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.343690999348959 and perplexity of 76.99118997117856
Finished 45 epochs...
Completing Train Step...
At time: 1340.6655533313751 and batch: 50, loss is 3.9288074159622193 and perplexity is 50.84630300722941
At time: 1341.7147262096405 and batch: 100, loss is 3.930917510986328 and perplexity is 50.9537068144676
At time: 1342.738703250885 and batch: 150, loss is 3.920474247932434 and perplexity is 50.42435275350111
At time: 1343.7627069950104 and batch: 200, loss is 3.914274034500122 and perplexity is 50.11267822700157
At time: 1344.7862231731415 and batch: 250, loss is 3.90472149848938 and perplexity is 49.6362542152473
At time: 1345.8098804950714 and batch: 300, loss is 3.9153561067581175 and perplexity is 50.16693311444531
At time: 1346.8333880901337 and batch: 350, loss is 3.9215055227279665 and perplexity is 50.47638094064474
At time: 1347.8567543029785 and batch: 400, loss is 3.917537636756897 and perplexity is 50.27649324488645
At time: 1348.8806438446045 and batch: 450, loss is 3.8584540414810182 and perplexity is 47.392028596134324
At time: 1349.904491186142 and batch: 500, loss is 3.93809618473053 and perplexity is 51.32080290681311
At time: 1350.928103685379 and batch: 550, loss is 3.930853233337402 and perplexity is 50.95043173524785
At time: 1351.9516382217407 and batch: 600, loss is 3.8718222093582155 and perplexity is 48.02982678883393
At time: 1352.9761979579926 and batch: 650, loss is 3.8844896936416626 and perplexity is 48.642113744976754
At time: 1354.0001792907715 and batch: 700, loss is 3.9145837688446044 and perplexity is 50.12820224857967
At time: 1355.0241150856018 and batch: 750, loss is 3.878381361961365 and perplexity is 48.345897196084984
At time: 1356.0485026836395 and batch: 800, loss is 3.849237895011902 and perplexity is 46.95726322709822
At time: 1357.0720117092133 and batch: 850, loss is 3.8116073989868164 and perplexity is 45.223071995577236
At time: 1358.0958325862885 and batch: 900, loss is 3.8381191635131837 and perplexity is 46.438049871327884
At time: 1359.1202056407928 and batch: 950, loss is 3.8207627534866333 and perplexity is 45.63900635922606
At time: 1360.1437950134277 and batch: 1000, loss is 3.834976625442505 and perplexity is 46.29234559221034
At time: 1361.1680109500885 and batch: 1050, loss is 3.782755045890808 and perplexity is 43.936923382090356
At time: 1362.1905484199524 and batch: 1100, loss is 3.745392293930054 and perplexity is 42.325608041544456
At time: 1363.2138147354126 and batch: 1150, loss is 3.772629237174988 and perplexity is 43.494271387235266
At time: 1364.2368581295013 and batch: 1200, loss is 3.7405460357666014 and perplexity is 42.12098345033582
At time: 1365.2595150470734 and batch: 1250, loss is 3.791102795600891 and perplexity is 44.30523296080497
At time: 1366.2821531295776 and batch: 1300, loss is 3.793420968055725 and perplexity is 44.4080592699701
At time: 1367.3051211833954 and batch: 1350, loss is 3.751368856430054 and perplexity is 42.579327112074644
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.343636474609375 and perplexity of 76.98699216103843
Finished 46 epochs...
Completing Train Step...
At time: 1370.3883006572723 and batch: 50, loss is 3.9288091707229613 and perplexity is 50.846392230404085
At time: 1371.41171002388 and batch: 100, loss is 3.930748314857483 and perplexity is 50.94508637381746
At time: 1372.434076309204 and batch: 150, loss is 3.9201867294311525 and perplexity is 50.40985690318177
At time: 1373.4558551311493 and batch: 200, loss is 3.913965468406677 and perplexity is 50.097217539093705
At time: 1374.4782345294952 and batch: 250, loss is 3.904427556991577 and perplexity is 49.621666204453845
At time: 1375.505922794342 and batch: 300, loss is 3.915045585632324 and perplexity is 50.151357640279045
At time: 1376.531858921051 and batch: 350, loss is 3.9211720275878905 and perplexity is 50.45955011956692
At time: 1377.5539484024048 and batch: 400, loss is 3.91725531578064 and perplexity is 50.262301139689534
At time: 1378.5766816139221 and batch: 450, loss is 3.8581858491897583 and perplexity is 47.37932012363102
At time: 1379.5992891788483 and batch: 500, loss is 3.93787624835968 and perplexity is 51.309516836826816
At time: 1380.6223492622375 and batch: 550, loss is 3.9306480789184572 and perplexity is 50.93998010116632
At time: 1381.64470911026 and batch: 600, loss is 3.8715977096557617 and perplexity is 48.01904531727479
At time: 1382.6667873859406 and batch: 650, loss is 3.884310789108276 and perplexity is 48.63341222870784
At time: 1383.6891884803772 and batch: 700, loss is 3.914436168670654 and perplexity is 50.12080386322288
At time: 1384.7122132778168 and batch: 750, loss is 3.8782818269729615 and perplexity is 48.341085327246844
At time: 1385.7346556186676 and batch: 800, loss is 3.849159474372864 and perplexity is 46.9535809528935
At time: 1386.758100271225 and batch: 850, loss is 3.8115980005264283 and perplexity is 45.22264697032375
At time: 1387.7806279659271 and batch: 900, loss is 3.838154716491699 and perplexity is 46.43970091166678
At time: 1388.8028216362 and batch: 950, loss is 3.8208044815063475 and perplexity is 45.64091082431766
At time: 1389.825010061264 and batch: 1000, loss is 3.835058693885803 and perplexity is 46.29614488884876
At time: 1390.8476927280426 and batch: 1050, loss is 3.782878165245056 and perplexity is 43.94233320074466
At time: 1391.8728592395782 and batch: 1100, loss is 3.7455616092681883 and perplexity is 42.33277502290457
At time: 1392.8948407173157 and batch: 1150, loss is 3.772794232368469 and perplexity is 43.50144832502197
At time: 1393.9425778388977 and batch: 1200, loss is 3.740737142562866 and perplexity is 42.12903382575476
At time: 1394.96643948555 and batch: 1250, loss is 3.791304521560669 and perplexity is 44.314171377972265
At time: 1396.006042957306 and batch: 1300, loss is 3.7936188650131224 and perplexity is 44.41684835942189
At time: 1397.0287909507751 and batch: 1350, loss is 3.751535997390747 and perplexity is 42.58644445649715
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.343603922526042 and perplexity of 76.9844861148428
Finished 47 epochs...
Completing Train Step...
At time: 1400.1105432510376 and batch: 50, loss is 3.9287658739089966 and perplexity is 50.8441907912769
At time: 1401.1329271793365 and batch: 100, loss is 3.9305932235717775 and perplexity is 50.937185847538586
At time: 1402.1555404663086 and batch: 150, loss is 3.919969959259033 and perplexity is 50.39893073410091
At time: 1403.1781940460205 and batch: 200, loss is 3.913727102279663 and perplexity is 50.08527748248379
At time: 1404.2001285552979 and batch: 250, loss is 3.90419472694397 and perplexity is 49.61011413443581
At time: 1405.2221312522888 and batch: 300, loss is 3.91479887008667 and perplexity is 50.13898604690849
At time: 1406.2448046207428 and batch: 350, loss is 3.920922598838806 and perplexity is 50.44696562663364
At time: 1407.2667508125305 and batch: 400, loss is 3.9170379304885863 and perplexity is 50.25137604219778
At time: 1408.2937996387482 and batch: 450, loss is 3.857979645729065 and perplexity is 47.36955135106821
At time: 1409.3160622119904 and batch: 500, loss is 3.937670178413391 and perplexity is 51.29894457679807
At time: 1410.3386623859406 and batch: 550, loss is 3.9304882764816282 and perplexity is 50.93184041860201
At time: 1411.3671169281006 and batch: 600, loss is 3.871435742378235 and perplexity is 48.0112684330527
At time: 1412.3888404369354 and batch: 650, loss is 3.884176812171936 and perplexity is 48.62689690959466
At time: 1413.4159376621246 and batch: 700, loss is 3.914324698448181 and perplexity is 50.11521719744495
At time: 1414.437738418579 and batch: 750, loss is 3.878209433555603 and perplexity is 48.33758587755128
At time: 1415.4608471393585 and batch: 800, loss is 3.8490963840484618 and perplexity is 46.95061872968414
At time: 1416.4828345775604 and batch: 850, loss is 3.8115802431106567 and perplexity is 45.221843940109096
At time: 1417.5054428577423 and batch: 900, loss is 3.8381700134277343 and perplexity is 46.44041130223451
At time: 1418.5275926589966 and batch: 950, loss is 3.82082661151886 and perplexity is 45.64192086942139
At time: 1419.5765943527222 and batch: 1000, loss is 3.8351122903823853 and perplexity is 46.298626266516045
At time: 1420.6144857406616 and batch: 1050, loss is 3.782956013679504 and perplexity is 43.94575417574739
At time: 1421.6523656845093 and batch: 1100, loss is 3.745670533180237 and perplexity is 42.33738632550394
At time: 1422.6768157482147 and batch: 1150, loss is 3.7729014492034914 and perplexity is 43.50611266267355
At time: 1423.7022428512573 and batch: 1200, loss is 3.740863552093506 and perplexity is 42.134359673758865
At time: 1424.7262816429138 and batch: 1250, loss is 3.791436724662781 and perplexity is 44.32003023616703
At time: 1425.7500903606415 and batch: 1300, loss is 3.793741774559021 and perplexity is 44.422307949595
At time: 1426.7747592926025 and batch: 1350, loss is 3.7516430377960206 and perplexity is 42.59100317074989
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.34358642578125 and perplexity of 76.98313914872011
Finished 48 epochs...
Completing Train Step...
At time: 1429.8465149402618 and batch: 50, loss is 3.9286984062194823 and perplexity is 50.84076056691495
At time: 1430.895577430725 and batch: 100, loss is 3.930447368621826 and perplexity is 50.92975694863013
At time: 1431.9195289611816 and batch: 150, loss is 3.9197886276245115 and perplexity is 50.38979264215037
At time: 1432.9439804553986 and batch: 200, loss is 3.913528127670288 and perplexity is 50.075312775356
At time: 1433.9680993556976 and batch: 250, loss is 3.903997874259949 and perplexity is 49.60034921147104
At time: 1434.9929251670837 and batch: 300, loss is 3.91459098815918 and perplexity is 50.128564141147116
At time: 1436.0157027244568 and batch: 350, loss is 3.920721173286438 and perplexity is 50.43680534202183
At time: 1437.0389482975006 and batch: 400, loss is 3.9168583250045774 and perplexity is 50.2423514299408
At time: 1438.0624403953552 and batch: 450, loss is 3.8578093528747557 and perplexity is 47.36148534177264
At time: 1439.0870850086212 and batch: 500, loss is 3.9374740409851072 and perplexity is 51.288883920403
At time: 1440.1114928722382 and batch: 550, loss is 3.930354886054993 and perplexity is 50.925047051774364
At time: 1441.1358244419098 and batch: 600, loss is 3.871307125091553 and perplexity is 48.00509375107062
At time: 1442.160028219223 and batch: 650, loss is 3.884067177772522 and perplexity is 48.621566021186325
At time: 1443.1841938495636 and batch: 700, loss is 3.914233775138855 and perplexity is 50.110660763195945
At time: 1444.2079648971558 and batch: 750, loss is 3.8781496191024782 and perplexity is 48.334694677755266
At time: 1445.2564852237701 and batch: 800, loss is 3.8490415906906126 and perplexity is 46.94804621810976
At time: 1446.280391216278 and batch: 850, loss is 3.8115555238723755 and perplexity is 45.22072610438931
At time: 1447.3045735359192 and batch: 900, loss is 3.838172116279602 and perplexity is 46.440508959642834
At time: 1448.3288617134094 and batch: 950, loss is 3.820835747718811 and perplexity is 45.64233786504148
At time: 1449.3543136119843 and batch: 1000, loss is 3.835145130157471 and perplexity is 46.300146727955074
At time: 1450.3787965774536 and batch: 1050, loss is 3.7830058765411376 and perplexity is 43.94794549143941
At time: 1451.4033315181732 and batch: 1100, loss is 3.7457425880432127 and perplexity is 42.340437049982825
At time: 1452.427312374115 and batch: 1150, loss is 3.772972321510315 and perplexity is 43.50919615050454
At time: 1453.451024055481 and batch: 1200, loss is 3.7409493017196653 and perplexity is 42.13797283426072
At time: 1454.4753358364105 and batch: 1250, loss is 3.7915260362625123 and perplexity is 44.323988705733555
At time: 1455.4993271827698 and batch: 1300, loss is 3.793819670677185 and perplexity is 44.42576840972061
At time: 1456.525456905365 and batch: 1350, loss is 3.7517126417160034 and perplexity is 42.59396777469941
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.343575439453125 and perplexity of 76.9822933913392
Finished 49 epochs...
Completing Train Step...
At time: 1459.581337928772 and batch: 50, loss is 3.9286183738708496 and perplexity is 50.83669182425819
At time: 1460.6277289390564 and batch: 100, loss is 3.93030882358551 and perplexity is 50.92270137237295
At time: 1461.650630235672 and batch: 150, loss is 3.9196272563934325 and perplexity is 50.38166183533468
At time: 1462.6728475093842 and batch: 200, loss is 3.9133537912368777 and perplexity is 50.06658358485491
At time: 1463.6971790790558 and batch: 250, loss is 3.903824191093445 and perplexity is 49.591735213835136
At time: 1464.7195947170258 and batch: 300, loss is 3.9144092655181884 and perplexity is 50.11945547373289
At time: 1465.7416570186615 and batch: 350, loss is 3.9205497550964354 and perplexity is 50.428160297120726
At time: 1466.764566898346 and batch: 400, loss is 3.91670316696167 and perplexity is 50.23455652975822
At time: 1467.786957502365 and batch: 450, loss is 3.8576621913909914 and perplexity is 47.35451606813337
At time: 1468.809155702591 and batch: 500, loss is 3.9373107147216797 and perplexity is 51.28050778267717
At time: 1469.831698179245 and batch: 550, loss is 3.930238490104675 and perplexity is 50.91911992748113
At time: 1470.8541340827942 and batch: 600, loss is 3.871198253631592 and perplexity is 47.99986765092011
At time: 1471.903668642044 and batch: 650, loss is 3.8839720630645753 and perplexity is 48.616941615062316
At time: 1472.927015542984 and batch: 700, loss is 3.914155197143555 and perplexity is 50.10672332263012
At time: 1473.951547384262 and batch: 750, loss is 3.8780960035324097 and perplexity is 48.33210325501695
At time: 1474.9745824337006 and batch: 800, loss is 3.848990364074707 and perplexity is 46.945641290177306
At time: 1475.9968864917755 and batch: 850, loss is 3.811525888442993 and perplexity is 45.21938598861177
At time: 1477.0205583572388 and batch: 900, loss is 3.8381649160385134 and perplexity is 46.440174577985864
At time: 1478.0444808006287 and batch: 950, loss is 3.8208359718322753 and perplexity is 45.64234809410509
At time: 1479.068677663803 and batch: 1000, loss is 3.8351631212234496 and perplexity is 46.300979724442904
At time: 1480.0925388336182 and batch: 1050, loss is 3.783037266731262 and perplexity is 43.94932504745612
At time: 1481.1152296066284 and batch: 1100, loss is 3.7457902097702025 and perplexity is 42.34245342272784
At time: 1482.1380939483643 and batch: 1150, loss is 3.773019051551819 and perplexity is 43.51122938455264
At time: 1483.1605622768402 and batch: 1200, loss is 3.741008701324463 and perplexity is 42.1404758875335
At time: 1484.1835718154907 and batch: 1250, loss is 3.7915874481201173 and perplexity is 44.326710807800254
At time: 1485.2066440582275 and batch: 1300, loss is 3.7938698387145995 and perplexity is 44.42799721923939
At time: 1486.2295985221863 and batch: 1350, loss is 3.751757793426514 and perplexity is 42.595891008620185
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.343569742838541 and perplexity of 76.98185485413308
Finished Training.
Improved accuracyfrom -115.47348473869167 to -76.98185485413308
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fec148f35c0>
SETTINGS FOR THIS RUN
{'wordvec_dim': 200, 'dropout': 0.3924415681187886, 'num_layers': 1, 'wordvec_source': 'glove', 'tune_wordvecs': True, 'batch_size': 80, 'seq_len': 20, 'lr': 15.23571641651625, 'data': 'wikitext', 'anneal': 7.807467530615339}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.648428201675415 and batch: 50, loss is 7.516689348220825 and perplexity is 1838.47067152499
At time: 2.6727488040924072 and batch: 100, loss is 6.5240741729736325 and perplexity is 681.3486705360529
At time: 3.7069854736328125 and batch: 150, loss is 6.207528276443481 and perplexity is 496.47259046037993
At time: 4.732449293136597 and batch: 200, loss is 6.112208290100098 and perplexity is 451.33429255127476
At time: 5.7574262619018555 and batch: 250, loss is 6.130515842437744 and perplexity is 459.673218486029
At time: 6.82696008682251 and batch: 300, loss is 6.141748390197754 and perplexity is 464.8656272626647
At time: 7.852688312530518 and batch: 350, loss is 6.133146705627442 and perplexity is 460.88414803237
At time: 8.8792245388031 and batch: 400, loss is 6.188866233825683 and perplexity is 487.2933162274508
At time: 9.906172037124634 and batch: 450, loss is 6.18124737739563 and perplexity is 483.5948055134524
At time: 10.93360424041748 and batch: 500, loss is 6.201247186660766 and perplexity is 493.36397451308295
At time: 11.960860967636108 and batch: 550, loss is 6.1640974712371825 and perplexity is 475.37191244405807
At time: 12.987074851989746 and batch: 600, loss is 6.148479194641113 and perplexity is 468.00510063037734
At time: 14.013417959213257 and batch: 650, loss is 6.195951585769653 and perplexity is 490.75822141373527
At time: 15.038556337356567 and batch: 700, loss is 6.222407579421997 and perplexity is 503.91498809119037
At time: 16.064754486083984 and batch: 750, loss is 6.199861011505127 and perplexity is 492.6805594048782
At time: 17.08970594406128 and batch: 800, loss is 6.148514862060547 and perplexity is 468.0217934622921
At time: 18.115923166275024 and batch: 850, loss is 6.156645822525024 and perplexity is 471.8427732279599
At time: 19.141988515853882 and batch: 900, loss is 6.208619747161865 and perplexity is 497.0147715889352
At time: 20.168925762176514 and batch: 950, loss is 6.183717060089111 and perplexity is 484.7906072529173
At time: 21.19521737098694 and batch: 1000, loss is 6.194962358474731 and perplexity is 490.2729900275406
At time: 22.22118067741394 and batch: 1050, loss is 6.18807312965393 and perplexity is 486.90699508218967
At time: 23.2466824054718 and batch: 1100, loss is 6.217557411193848 and perplexity is 501.47683313673144
At time: 24.273440837860107 and batch: 1150, loss is 6.202960271835327 and perplexity is 494.2098733650059
At time: 25.299145698547363 and batch: 1200, loss is 6.1920695304870605 and perplexity is 488.85676403711597
At time: 26.326063632965088 and batch: 1250, loss is 6.186330528259277 and perplexity is 486.0592491296589
At time: 27.352302312850952 and batch: 1300, loss is 6.177013683319092 and perplexity is 481.5517409567458
At time: 28.377766370773315 and batch: 1350, loss is 6.194806785583496 and perplexity is 490.19672277369983
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.663541259765625 and perplexity of 288.1673131146691
Finished 1 epochs...
Completing Train Step...
At time: 31.47444462776184 and batch: 50, loss is 5.965243501663208 and perplexity is 389.64789643091626
At time: 32.493608236312866 and batch: 100, loss is 5.973737201690674 and perplexity is 392.97154383008575
At time: 33.51422595977783 and batch: 150, loss is 5.910642137527466 and perplexity is 368.942991500886
At time: 34.534292459487915 and batch: 200, loss is 5.899486112594604 and perplexity is 364.8499278994356
At time: 35.552746534347534 and batch: 250, loss is 5.926153268814087 and perplexity is 374.7103280038474
At time: 36.572556018829346 and batch: 300, loss is 5.8982077407836915 and perplexity is 364.3838120345651
At time: 37.593862533569336 and batch: 350, loss is 5.884894275665284 and perplexity is 359.5647512428795
At time: 38.654850244522095 and batch: 400, loss is 5.946896228790283 and perplexity is 382.5641030087101
At time: 39.67589616775513 and batch: 450, loss is 5.8950129318237305 and perplexity is 363.2215329853686
At time: 40.69585371017456 and batch: 500, loss is 5.919737157821655 and perplexity is 372.3138412331586
At time: 41.71584725379944 and batch: 550, loss is 5.891684474945069 and perplexity is 362.0145755426122
At time: 42.73582458496094 and batch: 600, loss is 5.851445541381836 and perplexity is 347.7366851085096
At time: 43.75443363189697 and batch: 650, loss is 5.882990407943725 and perplexity is 358.8808387652055
At time: 44.77347445487976 and batch: 700, loss is 5.884318237304687 and perplexity is 359.35768779701493
At time: 45.79211354255676 and batch: 750, loss is 5.856198434829712 and perplexity is 349.3933744359567
At time: 46.81594729423523 and batch: 800, loss is 5.796077308654785 and perplexity is 329.0064346085403
At time: 47.84247708320618 and batch: 850, loss is 5.8363207340240475 and perplexity is 342.5168090526652
At time: 48.86177158355713 and batch: 900, loss is 5.864568147659302 and perplexity is 352.3299687271429
At time: 49.88257932662964 and batch: 950, loss is 5.835626211166382 and perplexity is 342.27900588906874
At time: 50.90427112579346 and batch: 1000, loss is 5.846827335357666 and perplexity is 346.1344679865487
At time: 51.92363667488098 and batch: 1050, loss is 5.816537132263184 and perplexity is 335.8071820395129
At time: 52.94224691390991 and batch: 1100, loss is 5.823106832504273 and perplexity is 338.02059734074777
At time: 53.96230912208557 and batch: 1150, loss is 5.810780220031738 and perplexity is 333.8795235700075
At time: 54.98245573043823 and batch: 1200, loss is 5.804593820571899 and perplexity is 331.82038735252286
At time: 56.0015082359314 and batch: 1250, loss is 5.8174100017547605 and perplexity is 336.10042584693554
At time: 57.01940703392029 and batch: 1300, loss is 5.774618110656738 and perplexity is 322.02143467956324
At time: 58.038881063461304 and batch: 1350, loss is 5.780798654556275 and perplexity is 324.0178654520533
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.604099934895833 and perplexity of 271.53741406186634
Finished 2 epochs...
Completing Train Step...
At time: 61.132129430770874 and batch: 50, loss is 5.830078058242798 and perplexity is 340.3852479091029
At time: 62.17681050300598 and batch: 100, loss is 5.834199962615966 and perplexity is 341.7911789170319
At time: 63.19663333892822 and batch: 150, loss is 5.760508270263672 and perplexity is 317.50966863528237
At time: 64.22001671791077 and batch: 200, loss is 5.709419860839843 and perplexity is 301.6959918440205
At time: 65.24108672142029 and batch: 250, loss is 5.734237976074219 and perplexity is 309.27720431139494
At time: 66.26233434677124 and batch: 300, loss is 5.7487217140197755 and perplexity is 313.7892913563247
At time: 67.28265237808228 and batch: 350, loss is 5.739626760482788 and perplexity is 310.94833111496064
At time: 68.30207896232605 and batch: 400, loss is 5.819663066864013 and perplexity is 336.8585357043511
At time: 69.32236051559448 and batch: 450, loss is 5.773211116790772 and perplexity is 321.56867108874894
At time: 70.34264397621155 and batch: 500, loss is 5.810868902206421 and perplexity is 333.909134045181
At time: 71.36344742774963 and batch: 550, loss is 5.7868139266967775 and perplexity is 325.9727949128144
At time: 72.38402152061462 and batch: 600, loss is 5.743075304031372 and perplexity is 312.02250107256594
At time: 73.41191792488098 and batch: 650, loss is 5.767698040008545 and perplexity is 319.8007162276615
At time: 74.432119846344 and batch: 700, loss is 5.792445688247681 and perplexity is 327.8137750806863
At time: 75.45153975486755 and batch: 750, loss is 5.76210283279419 and perplexity is 318.0163615253528
At time: 76.47016787528992 and batch: 800, loss is 5.696542797088623 and perplexity is 297.835939731072
At time: 77.49125385284424 and batch: 850, loss is 5.724106130599975 and perplexity is 306.1594763084188
At time: 78.5114197731018 and batch: 900, loss is 5.771453924179077 and perplexity is 321.0041091630495
At time: 79.53306102752686 and batch: 950, loss is 5.753664846420288 and perplexity is 315.3442333452332
At time: 80.55382657051086 and batch: 1000, loss is 5.770354871749878 and perplexity is 320.6515026191234
At time: 81.57521295547485 and batch: 1050, loss is 5.7396421718597415 and perplexity is 310.95312329383137
At time: 82.59403586387634 and batch: 1100, loss is 5.7310761547088624 and perplexity is 308.3008693507321
At time: 83.61313247680664 and batch: 1150, loss is 5.730424909591675 and perplexity is 308.1001552790663
At time: 84.6334240436554 and batch: 1200, loss is 5.709675703048706 and perplexity is 301.7731882876122
At time: 85.653724193573 and batch: 1250, loss is 5.725380935668945 and perplexity is 306.5500188406397
At time: 86.67268252372742 and batch: 1300, loss is 5.7028916072845455 and perplexity is 299.73285879986065
At time: 87.69355368614197 and batch: 1350, loss is 5.719275636672974 and perplexity is 304.68414098532423
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.5941084798177085 and perplexity of 268.8378688374014
Finished 3 epochs...
Completing Train Step...
At time: 90.79462361335754 and batch: 50, loss is 5.7736671257019045 and perplexity is 321.71534270754756
At time: 91.8128502368927 and batch: 100, loss is 5.773522100448608 and perplexity is 321.66868924152925
At time: 92.83263802528381 and batch: 150, loss is 5.736050395965576 and perplexity is 309.83825274251984
At time: 93.85391163825989 and batch: 200, loss is 5.722936201095581 and perplexity is 305.8015007479518
At time: 94.87386989593506 and batch: 250, loss is 5.756274461746216 and perplexity is 316.16823518580236
At time: 95.89396595954895 and batch: 300, loss is 5.72640170097351 and perplexity is 306.8630942250467
At time: 96.91431212425232 and batch: 350, loss is 5.743471164703369 and perplexity is 312.14604296059275
At time: 97.93415689468384 and batch: 400, loss is 5.7969090938568115 and perplexity is 329.2802111380675
At time: 98.95971632003784 and batch: 450, loss is 5.746198034286499 and perplexity is 312.998386096767
At time: 99.98579001426697 and batch: 500, loss is 5.793422889709473 and perplexity is 328.1342717502936
At time: 101.00674891471863 and batch: 550, loss is 5.758559083938598 and perplexity is 316.8913859009801
At time: 102.03791069984436 and batch: 600, loss is 5.727317886352539 and perplexity is 307.144366534453
At time: 103.06483864784241 and batch: 650, loss is 5.748772678375244 and perplexity is 313.8052838328312
At time: 104.08491325378418 and batch: 700, loss is 5.765507936477661 and perplexity is 319.101085960882
At time: 105.10393929481506 and batch: 750, loss is 5.706078376770019 and perplexity is 300.68956191457454
At time: 106.12342715263367 and batch: 800, loss is 5.628502721786499 and perplexity is 278.24519511776896
At time: 107.14425826072693 and batch: 850, loss is 5.672849149703979 and perplexity is 290.8620645183481
At time: 108.16453266143799 and batch: 900, loss is 5.7193726062774655 and perplexity is 304.7136875185052
At time: 109.18498349189758 and batch: 950, loss is 5.708024225234985 and perplexity is 301.275227860855
At time: 110.20715713500977 and batch: 1000, loss is 5.704219274520874 and perplexity is 300.1310685826875
At time: 111.22733235359192 and batch: 1050, loss is 5.687977991104126 and perplexity is 295.2959255833185
At time: 112.25919961929321 and batch: 1100, loss is 5.692446346282959 and perplexity is 296.6183650259131
At time: 113.28274512290955 and batch: 1150, loss is 5.682021656036377 and perplexity is 293.54227196533714
At time: 114.32755064964294 and batch: 1200, loss is 5.674405813217163 and perplexity is 291.3151914731504
At time: 115.34696984291077 and batch: 1250, loss is 5.6832994365692135 and perplexity is 293.917594304742
At time: 116.36508512496948 and batch: 1300, loss is 5.662728538513184 and perplexity is 287.9332085588016
At time: 117.38544869422913 and batch: 1350, loss is 5.663467435836792 and perplexity is 288.1460402566863
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.570085042317708 and perplexity of 262.45641819333827
Finished 4 epochs...
Completing Train Step...
At time: 120.47140789031982 and batch: 50, loss is 5.737341899871826 and perplexity is 310.23866856988764
At time: 121.49242782592773 and batch: 100, loss is 5.7411338996887205 and perplexity is 311.4173268679708
At time: 122.51348328590393 and batch: 150, loss is 5.690903625488281 and perplexity is 296.161118498654
At time: 123.53543210029602 and batch: 200, loss is 5.676445932388305 and perplexity is 291.91011583207086
At time: 124.5583701133728 and batch: 250, loss is 5.709261198043823 and perplexity is 301.64812771163525
At time: 125.57957148551941 and batch: 300, loss is 5.715863208770752 and perplexity is 303.6462002773837
At time: 126.598801612854 and batch: 350, loss is 5.700100917816162 and perplexity is 298.8975635344324
At time: 127.61873841285706 and batch: 400, loss is 5.748473081588745 and perplexity is 313.71128286010645
At time: 128.64043188095093 and batch: 450, loss is 5.71456244468689 and perplexity is 303.2514849772588
At time: 129.6624367237091 and batch: 500, loss is 5.754819459915161 and perplexity is 315.7085443313016
At time: 130.68342900276184 and batch: 550, loss is 5.730773944854736 and perplexity is 308.2077118672423
At time: 131.70388746261597 and batch: 600, loss is 5.691425189971924 and perplexity is 296.3156259087851
At time: 132.72462391853333 and batch: 650, loss is 5.713893356323243 and perplexity is 303.0486508019621
At time: 133.74468970298767 and batch: 700, loss is 5.731608810424805 and perplexity is 308.46513131467515
At time: 134.76299381256104 and batch: 750, loss is 5.679928493499756 and perplexity is 292.92848288300195
At time: 135.78277015686035 and batch: 800, loss is 5.62328459739685 and perplexity is 276.79705864287126
At time: 136.80396270751953 and batch: 850, loss is 5.650938920974731 and perplexity is 284.5585183951314
At time: 137.8254053592682 and batch: 900, loss is 5.701451835632324 and perplexity is 299.301622441957
At time: 138.8471658229828 and batch: 950, loss is 5.67363787651062 and perplexity is 291.09156572064626
At time: 139.91172695159912 and batch: 1000, loss is 5.700669040679932 and perplexity is 299.06742231996265
At time: 140.932874917984 and batch: 1050, loss is 5.6632560443878175 and perplexity is 288.08513508536316
At time: 141.95075798034668 and batch: 1100, loss is 5.653391370773315 and perplexity is 285.25724031626646
At time: 142.9696192741394 and batch: 1150, loss is 5.658146343231201 and perplexity is 286.61686055405147
At time: 143.98889303207397 and batch: 1200, loss is 5.648740577697754 and perplexity is 283.9336481805799
At time: 145.00679731369019 and batch: 1250, loss is 5.6675020027160645 and perplexity is 289.310933065922
At time: 146.02665519714355 and batch: 1300, loss is 5.632834205627441 and perplexity is 279.4530236406918
At time: 147.04690098762512 and batch: 1350, loss is 5.6453125 and perplexity is 282.9619680227251
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.552655029296875 and perplexity of 257.9214366128844
Finished 5 epochs...
Completing Train Step...
At time: 150.10607886314392 and batch: 50, loss is 5.763980016708374 and perplexity is 318.61389739054556
At time: 151.15167236328125 and batch: 100, loss is 5.726219902038574 and perplexity is 306.80731191208145
At time: 152.17111992835999 and batch: 150, loss is 5.714745655059814 and perplexity is 303.307048884698
At time: 153.1901981830597 and batch: 200, loss is 5.677787075042724 and perplexity is 292.3018715811225
At time: 154.20948576927185 and batch: 250, loss is 5.698860750198365 and perplexity is 298.5271102146843
At time: 155.22885251045227 and batch: 300, loss is 5.6953630542755125 and perplexity is 297.4847771032104
At time: 156.2473967075348 and batch: 350, loss is 5.696613130569458 and perplexity is 297.8568883061155
At time: 157.26837038993835 and batch: 400, loss is 5.7311616706848145 and perplexity is 308.327235127793
At time: 158.28842616081238 and batch: 450, loss is 5.693876419067383 and perplexity is 297.0428543300537
At time: 159.30890130996704 and batch: 500, loss is 5.738365135192871 and perplexity is 310.5562782005069
At time: 160.3285892009735 and batch: 550, loss is 5.7008771800994875 and perplexity is 299.1296765182039
At time: 161.34866166114807 and batch: 600, loss is 5.5992515087127686 and perplexity is 270.2240713491986
At time: 162.36792135238647 and batch: 650, loss is 5.644411306381226 and perplexity is 282.70707937205066
At time: 163.38773918151855 and batch: 700, loss is 5.683421354293824 and perplexity is 293.9534302535368
At time: 164.40640258789062 and batch: 750, loss is 5.651935348510742 and perplexity is 284.84220164989836
At time: 165.44997215270996 and batch: 800, loss is 5.608502025604248 and perplexity is 272.7353812348187
At time: 166.47105312347412 and batch: 850, loss is 5.64331976890564 and perplexity is 282.39866235529047
At time: 167.67142939567566 and batch: 900, loss is 5.681115579605103 and perplexity is 293.2764206901021
At time: 168.69146394729614 and batch: 950, loss is 5.650831871032715 and perplexity is 284.5280580526549
At time: 169.71145153045654 and batch: 1000, loss is 5.668766918182373 and perplexity is 289.6771184877061
At time: 170.73215770721436 and batch: 1050, loss is 5.640669260025025 and perplexity is 281.6511532701947
At time: 171.7508955001831 and batch: 1100, loss is 5.6321031284332275 and perplexity is 279.24879657022706
At time: 172.76943922042847 and batch: 1150, loss is 5.619476728439331 and perplexity is 275.74505593112497
At time: 173.7882161140442 and batch: 1200, loss is 5.614980039596557 and perplexity is 274.50789985226675
At time: 174.806298494339 and batch: 1250, loss is 5.63442624092102 and perplexity is 279.89827705275445
At time: 175.8250298500061 and batch: 1300, loss is 5.608736000061035 and perplexity is 272.7992018133911
At time: 176.8441252708435 and batch: 1350, loss is 5.617902965545654 and perplexity is 275.311439887901
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.5597847493489585 and perplexity of 259.7669153070103
Annealing...
Finished 6 epochs...
Completing Train Step...
At time: 179.95571994781494 and batch: 50, loss is 5.619100637435913 and perplexity is 275.6413701952108
At time: 180.97791957855225 and batch: 100, loss is 5.561923303604126 and perplexity is 260.3230353836227
At time: 182.000634431839 and batch: 150, loss is 5.49508448600769 and perplexity is 243.49209696686182
At time: 183.03195309638977 and batch: 200, loss is 5.46770001411438 and perplexity is 236.91466526267652
At time: 184.0583176612854 and batch: 250, loss is 5.462571430206299 and perplexity is 235.70273891218847
At time: 185.09628343582153 and batch: 300, loss is 5.457289476394653 and perplexity is 234.46105009030413
At time: 186.12853813171387 and batch: 350, loss is 5.4428496837615965 and perplexity is 231.0998073738998
At time: 187.15653204917908 and batch: 400, loss is 5.459523057937622 and perplexity is 234.98532324979558
At time: 188.17870545387268 and batch: 450, loss is 5.415359706878662 and perplexity is 224.83340525729457
At time: 189.20110058784485 and batch: 500, loss is 5.445996570587158 and perplexity is 231.82819779312376
At time: 190.2207260131836 and batch: 550, loss is 5.4050080108642575 and perplexity is 222.5180030381931
At time: 191.26848530769348 and batch: 600, loss is 5.350908060073852 and perplexity is 210.79962971044597
At time: 192.29007172584534 and batch: 650, loss is 5.3532867336273195 and perplexity is 211.3016500492643
At time: 193.3115530014038 and batch: 700, loss is 5.367227039337158 and perplexity is 214.26788673494693
At time: 194.3337001800537 and batch: 750, loss is 5.33344352722168 and perplexity is 207.1500743043597
At time: 195.35573744773865 and batch: 800, loss is 5.300420866012574 and perplexity is 200.42114267431617
At time: 196.37927985191345 and batch: 850, loss is 5.2765483570098874 and perplexity is 195.69324506293967
At time: 197.40121841430664 and batch: 900, loss is 5.319491376876831 and perplexity is 204.2799540568996
At time: 198.4236319065094 and batch: 950, loss is 5.282026128768921 and perplexity is 196.76814934654794
At time: 199.4449906349182 and batch: 1000, loss is 5.298744373321533 and perplexity is 200.08541959077326
At time: 200.4678053855896 and batch: 1050, loss is 5.236652593612671 and perplexity is 188.03960275778527
At time: 201.48989248275757 and batch: 1100, loss is 5.205310573577881 and perplexity is 182.23746212138207
At time: 202.521226644516 and batch: 1150, loss is 5.200070743560791 and perplexity is 181.28506617262687
At time: 203.5497441291809 and batch: 1200, loss is 5.183188714981079 and perplexity is 178.25029512639392
At time: 204.57190561294556 and batch: 1250, loss is 5.169465065002441 and perplexity is 175.82075964591272
At time: 205.59330582618713 and batch: 1300, loss is 5.157290525436402 and perplexity is 173.6932001583891
At time: 206.6147964000702 and batch: 1350, loss is 5.174090604782105 and perplexity is 176.63590936408394
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.172000325520833 and perplexity of 176.26707660197513
Finished 7 epochs...
Completing Train Step...
At time: 209.72063398361206 and batch: 50, loss is 5.339494667053223 and perplexity is 208.4073685653289
At time: 210.74248433113098 and batch: 100, loss is 5.348097667694092 and perplexity is 210.2080317380533
At time: 211.79070520401 and batch: 150, loss is 5.321938552856445 and perplexity is 204.7804752354991
At time: 212.81253600120544 and batch: 200, loss is 5.304201231002808 and perplexity is 201.18024167699832
At time: 213.8346049785614 and batch: 250, loss is 5.318072910308838 and perplexity is 203.99039518489892
At time: 214.85698914527893 and batch: 300, loss is 5.325719165802002 and perplexity is 205.55613626435624
At time: 215.87930822372437 and batch: 350, loss is 5.314723033905029 and perplexity is 203.3081958531387
At time: 216.90064024925232 and batch: 400, loss is 5.345337781906128 and perplexity is 209.62868141684353
At time: 217.93128633499146 and batch: 450, loss is 5.304300804138183 and perplexity is 201.20027482180262
At time: 218.9534559249878 and batch: 500, loss is 5.342035007476807 and perplexity is 208.93746725876284
At time: 219.9727532863617 and batch: 550, loss is 5.308290338516235 and perplexity is 202.00457355701113
At time: 221.00313997268677 and batch: 600, loss is 5.254249534606934 and perplexity is 191.37780952601403
At time: 222.02551817893982 and batch: 650, loss is 5.26197434425354 and perplexity is 192.86189142033192
At time: 223.04699039459229 and batch: 700, loss is 5.2855480289459225 and perplexity is 197.46236889495623
At time: 224.07275342941284 and batch: 750, loss is 5.258739814758301 and perplexity is 192.23908173516918
At time: 225.09676837921143 and batch: 800, loss is 5.22099814414978 and perplexity is 185.118867199467
At time: 226.1200077533722 and batch: 850, loss is 5.208598594665528 and perplexity is 182.83764891248688
At time: 227.1427128314972 and batch: 900, loss is 5.25546483039856 and perplexity is 191.61053155695092
At time: 228.16558384895325 and batch: 950, loss is 5.222985248565674 and perplexity is 185.48708343884098
At time: 229.1875958442688 and batch: 1000, loss is 5.244723997116089 and perplexity is 189.56348793925486
At time: 230.21927070617676 and batch: 1050, loss is 5.18510311126709 and perplexity is 178.59186367382523
At time: 231.24628281593323 and batch: 1100, loss is 5.170195646286011 and perplexity is 175.94925793568027
At time: 232.26897501945496 and batch: 1150, loss is 5.177810249328613 and perplexity is 177.29415562317712
At time: 233.29171228408813 and batch: 1200, loss is 5.164966287612915 and perplexity is 175.03155774070606
At time: 234.3144075870514 and batch: 1250, loss is 5.18230281829834 and perplexity is 178.09245370716206
At time: 235.33608150482178 and batch: 1300, loss is 5.169163599014282 and perplexity is 175.7677636555128
At time: 236.35814547538757 and batch: 1350, loss is 5.176021614074707 and perplexity is 176.9773244782633
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1677254231770835 and perplexity of 175.5151603923591
Finished 8 epochs...
Completing Train Step...
At time: 239.44304037094116 and batch: 50, loss is 5.310889730453491 and perplexity is 202.53034566464638
At time: 240.46496725082397 and batch: 100, loss is 5.320349397659302 and perplexity is 204.45530571985034
At time: 241.4883098602295 and batch: 150, loss is 5.281518325805664 and perplexity is 196.66825526263776
At time: 242.51019191741943 and batch: 200, loss is 5.261952095031738 and perplexity is 192.85760044106826
At time: 243.5329406261444 and batch: 250, loss is 5.2819384765625 and perplexity is 196.75090293995817
At time: 244.55557370185852 and batch: 300, loss is 5.287334384918213 and perplexity is 197.8154222225098
At time: 245.57868242263794 and batch: 350, loss is 5.2875904369354245 and perplexity is 197.86607974560908
At time: 246.6006805896759 and batch: 400, loss is 5.319955492019654 and perplexity is 204.37478548160036
At time: 247.62257170677185 and batch: 450, loss is 5.2730967140197755 and perplexity is 195.01894623427572
At time: 248.64546394348145 and batch: 500, loss is 5.309563865661621 and perplexity is 202.26199574720954
At time: 249.66542506217957 and batch: 550, loss is 5.2764881896972655 and perplexity is 195.68147108049396
At time: 250.68740224838257 and batch: 600, loss is 5.222385969161987 and perplexity is 185.37595815096
At time: 251.71762347221375 and batch: 650, loss is 5.2330120658874515 and perplexity is 187.35628394574013
At time: 252.74219846725464 and batch: 700, loss is 5.263386030197143 and perplexity is 193.1343441050728
At time: 253.76568174362183 and batch: 750, loss is 5.2414953231811525 and perplexity is 188.95243622092497
At time: 254.78782558441162 and batch: 800, loss is 5.196622076034546 and perplexity is 180.66095105326258
At time: 255.81031227111816 and batch: 850, loss is 5.194447679519653 and perplexity is 180.26854928404111
At time: 256.83299350738525 and batch: 900, loss is 5.23704755783081 and perplexity is 188.11388634118074
At time: 257.85527634620667 and batch: 950, loss is 5.206270809173584 and perplexity is 182.41253706252442
At time: 258.87727451324463 and batch: 1000, loss is 5.221122493743897 and perplexity is 185.14188808675593
At time: 259.8994300365448 and batch: 1050, loss is 5.1732666969299315 and perplexity is 176.4904375872818
At time: 260.9223201274872 and batch: 1100, loss is 5.161294822692871 and perplexity is 174.39011375663995
At time: 261.94580602645874 and batch: 1150, loss is 5.170559215545654 and perplexity is 176.0132393072479
At time: 263.01191425323486 and batch: 1200, loss is 5.154416284561157 and perplexity is 173.19468083824515
At time: 264.0414471626282 and batch: 1250, loss is 5.172246713638305 and perplexity is 176.31051206592278
At time: 265.06497502326965 and batch: 1300, loss is 5.164579734802246 and perplexity is 174.96391187529764
At time: 266.087039232254 and batch: 1350, loss is 5.169164533615112 and perplexity is 175.76792792828743
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.1650048828125 and perplexity of 175.03831324897496
Finished 9 epochs...
Completing Train Step...
At time: 269.1535382270813 and batch: 50, loss is 5.2874987697601314 and perplexity is 197.84794275228865
At time: 270.2012174129486 and batch: 100, loss is 5.294535779953003 and perplexity is 199.24511091980744
At time: 271.22338032722473 and batch: 150, loss is 5.256149234771729 and perplexity is 191.7417155290152
At time: 272.2459123134613 and batch: 200, loss is 5.234530429840088 and perplexity is 187.64097505124485
At time: 273.2673063278198 and batch: 250, loss is 5.255391597747803 and perplexity is 191.5964999236052
At time: 274.28986716270447 and batch: 300, loss is 5.263837127685547 and perplexity is 193.22148617593012
At time: 275.3137114048004 and batch: 350, loss is 5.268410215377807 and perplexity is 194.10712849276865
At time: 276.336492061615 and batch: 400, loss is 5.295201253890991 and perplexity is 199.3777474765871
At time: 277.3581211566925 and batch: 450, loss is 5.25225380897522 and perplexity is 190.99625279411913
At time: 278.3804624080658 and batch: 500, loss is 5.288971157073974 and perplexity is 198.13946611825318
At time: 279.4067063331604 and batch: 550, loss is 5.2577723693847656 and perplexity is 192.05319085906453
At time: 280.43160676956177 and batch: 600, loss is 5.202792282104492 and perplexity is 181.7791124456597
At time: 281.4545316696167 and batch: 650, loss is 5.214759225845337 and perplexity is 183.9675210223586
At time: 282.47771096229553 and batch: 700, loss is 5.244576282501221 and perplexity is 189.53548870963954
At time: 283.5007257461548 and batch: 750, loss is 5.224502944946289 and perplexity is 185.76881024782864
At time: 284.52286744117737 and batch: 800, loss is 5.1875872135162355 and perplexity is 179.0360556047269
At time: 285.5452480316162 and batch: 850, loss is 5.178573398590088 and perplexity is 177.4295091680146
At time: 286.5683524608612 and batch: 900, loss is 5.222107458114624 and perplexity is 185.32433608769054
At time: 287.5910527706146 and batch: 950, loss is 5.192191715240479 and perplexity is 179.8623282585434
At time: 288.63865637779236 and batch: 1000, loss is 5.20898551940918 and perplexity is 182.90840701106913
At time: 289.6633679866791 and batch: 1050, loss is 5.166192827224731 and perplexity is 175.24637259212446
At time: 290.6917862892151 and batch: 1100, loss is 5.154239320755005 and perplexity is 173.16403436005743
At time: 291.71493268013 and batch: 1150, loss is 5.1675104236602785 and perplexity is 175.47742877396797
At time: 292.7380619049072 and batch: 1200, loss is 5.149273824691773 and perplexity is 172.3063202794211
At time: 293.7609348297119 and batch: 1250, loss is 5.168568773269653 and perplexity is 175.66324355332026
At time: 294.78382778167725 and batch: 1300, loss is 5.1652180862426755 and perplexity is 175.07563599629924
At time: 295.80642008781433 and batch: 1350, loss is 5.165328941345215 and perplexity is 175.09504509965893
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.146341552734375 and perplexity of 171.8018113285976
Finished 10 epochs...
Completing Train Step...
At time: 298.86417746543884 and batch: 50, loss is 5.271857471466064 and perplexity is 194.7774201429371
At time: 299.91160321235657 and batch: 100, loss is 5.275820932388306 and perplexity is 195.55094474085743
At time: 300.93398356437683 and batch: 150, loss is 5.237358694076538 and perplexity is 188.17242449574474
At time: 301.9568102359772 and batch: 200, loss is 5.2200215053558345 and perplexity is 184.93816118888236
At time: 302.97950434684753 and batch: 250, loss is 5.242054557800293 and perplexity is 189.05813451694902
At time: 304.0103278160095 and batch: 300, loss is 5.250151348114014 and perplexity is 190.59511248664543
At time: 305.0333411693573 and batch: 350, loss is 5.253754510879516 and perplexity is 191.28309641395052
At time: 306.05664587020874 and batch: 400, loss is 5.279885177612305 and perplexity is 196.3473289882774
At time: 307.0809247493744 and batch: 450, loss is 5.2399257564544675 and perplexity is 188.65609538829912
At time: 308.10718393325806 and batch: 500, loss is 5.2776748561859135 and perplexity is 195.9138175562974
At time: 309.13417863845825 and batch: 550, loss is 5.246851758956909 and perplexity is 189.9672633118832
At time: 310.1597194671631 and batch: 600, loss is 5.191458320617675 and perplexity is 179.73046655339684
At time: 311.18268513679504 and batch: 650, loss is 5.203208799362183 and perplexity is 181.85484235339288
At time: 312.20873737335205 and batch: 700, loss is 5.235492944717407 and perplexity is 187.8216692277928
At time: 313.2329936027527 and batch: 750, loss is 5.216014175415039 and perplexity is 184.1985359094026
At time: 314.254540681839 and batch: 800, loss is 5.179717960357666 and perplexity is 177.6327044632491
At time: 315.31642389297485 and batch: 850, loss is 5.170866088867188 and perplexity is 176.0672613631679
At time: 316.3385066986084 and batch: 900, loss is 5.211232738494873 and perplexity is 183.31990446353097
At time: 317.3605182170868 and batch: 950, loss is 5.18462610244751 and perplexity is 178.50669409468276
At time: 318.38194608688354 and batch: 1000, loss is 5.202500553131103 and perplexity is 181.72608994627805
At time: 319.4041385650635 and batch: 1050, loss is 5.156178903579712 and perplexity is 173.50022627759805
At time: 320.43220472335815 and batch: 1100, loss is 5.146813373565674 and perplexity is 171.88289012786646
At time: 321.45906949043274 and batch: 1150, loss is 5.163672170639038 and perplexity is 174.80519293373095
At time: 322.4865047931671 and batch: 1200, loss is 5.141446046829223 and perplexity is 170.96280989059326
At time: 323.50881266593933 and batch: 1250, loss is 5.165406103134155 and perplexity is 175.1085562678397
At time: 324.54280185699463 and batch: 1300, loss is 5.159581546783447 and perplexity is 174.0915911746945
At time: 325.57557463645935 and batch: 1350, loss is 5.159065418243408 and perplexity is 174.0017607199333
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.14232666015625 and perplexity of 171.11342832797706
Finished 11 epochs...
Completing Train Step...
At time: 328.71271300315857 and batch: 50, loss is 5.26028977394104 and perplexity is 192.53727549956992
At time: 329.7349171638489 and batch: 100, loss is 5.261666917800904 and perplexity is 192.80260968605742
At time: 330.75793290138245 and batch: 150, loss is 5.222751684188843 and perplexity is 185.44376532276868
At time: 331.780965089798 and batch: 200, loss is 5.207614488601685 and perplexity is 182.65780578036606
At time: 332.8030264377594 and batch: 250, loss is 5.23203293800354 and perplexity is 187.17292796302897
At time: 333.8255536556244 and batch: 300, loss is 5.239668731689453 and perplexity is 188.60761233065355
At time: 334.8489782810211 and batch: 350, loss is 5.238821096420288 and perplexity is 188.4478096031911
At time: 335.8714623451233 and batch: 400, loss is 5.2682895088195805 and perplexity is 194.08369990338164
At time: 336.8934483528137 and batch: 450, loss is 5.230675458908081 and perplexity is 186.9190170044837
At time: 337.916597366333 and batch: 500, loss is 5.268744306564331 and perplexity is 194.17198880766603
At time: 338.93761944770813 and batch: 550, loss is 5.238422985076904 and perplexity is 188.37280132436624
At time: 339.9601352214813 and batch: 600, loss is 5.182790470123291 and perplexity is 178.17932199624073
At time: 341.0183777809143 and batch: 650, loss is 5.197792730331421 and perplexity is 180.87256641193795
At time: 342.04140853881836 and batch: 700, loss is 5.228535118103028 and perplexity is 186.51937444335454
At time: 343.06457138061523 and batch: 750, loss is 5.212045974731446 and perplexity is 183.4690474887623
At time: 344.08653807640076 and batch: 800, loss is 5.174131240844726 and perplexity is 176.64308729779856
At time: 345.1088824272156 and batch: 850, loss is 5.164227685928345 and perplexity is 174.90232686825075
At time: 346.1326937675476 and batch: 900, loss is 5.204507675170898 and perplexity is 182.0912026769468
At time: 347.1553843021393 and batch: 950, loss is 5.182627239227295 and perplexity is 178.15023999946806
At time: 348.17754077911377 and batch: 1000, loss is 5.204217329025268 and perplexity is 182.03834087257835
At time: 349.2011070251465 and batch: 1050, loss is 5.158515872955323 and perplexity is 173.90616514166675
At time: 350.22397089004517 and batch: 1100, loss is 5.147533550262451 and perplexity is 172.0067207645285
At time: 351.24704909324646 and batch: 1150, loss is 5.160964803695679 and perplexity is 174.33257120176813
At time: 352.26962065696716 and batch: 1200, loss is 5.143986730575562 and perplexity is 171.39772457930044
At time: 353.29337906837463 and batch: 1250, loss is 5.165121459960938 and perplexity is 175.05871990585268
At time: 354.31624364852905 and batch: 1300, loss is 5.1612307071685795 and perplexity is 174.378933001499
At time: 355.33858585357666 and batch: 1350, loss is 5.1560084342956545 and perplexity is 173.47065233903635
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.137911376953125 and perplexity of 170.35957953468122
Finished 12 epochs...
Completing Train Step...
At time: 358.43671202659607 and batch: 50, loss is 5.254388446807861 and perplexity is 191.40439608530002
At time: 359.45791387557983 and batch: 100, loss is 5.253068895339966 and perplexity is 191.151994698418
At time: 360.47952938079834 and batch: 150, loss is 5.217779493331909 and perplexity is 184.5239920673785
At time: 361.5010585784912 and batch: 200, loss is 5.206119003295899 and perplexity is 182.3848478689792
At time: 362.52171635627747 and batch: 250, loss is 5.227480869293213 and perplexity is 186.32284023102304
At time: 363.54940533638 and batch: 300, loss is 5.233355388641358 and perplexity is 187.42061866426047
At time: 364.571209192276 and batch: 350, loss is 5.233467903137207 and perplexity is 187.44170738705247
At time: 365.59274911880493 and batch: 400, loss is 5.2616266250610355 and perplexity is 192.7948412971653
At time: 366.6404278278351 and batch: 450, loss is 5.22418586730957 and perplexity is 185.70991644994567
At time: 367.66294956207275 and batch: 500, loss is 5.2671758079528805 and perplexity is 193.86766903779716
At time: 368.6821460723877 and batch: 550, loss is 5.234563369750976 and perplexity is 187.64715603004183
At time: 369.7047526836395 and batch: 600, loss is 5.17862193107605 and perplexity is 177.4381204721398
At time: 370.7271234989166 and batch: 650, loss is 5.191194086074829 and perplexity is 179.68298182956002
At time: 371.7488625049591 and batch: 700, loss is 5.221723928451538 and perplexity is 185.25327233590866
At time: 372.7706570625305 and batch: 750, loss is 5.206634397506714 and perplexity is 182.4788721914257
At time: 373.79222989082336 and batch: 800, loss is 5.167457466125488 and perplexity is 175.4681361679877
At time: 374.8133957386017 and batch: 850, loss is 5.155178232192993 and perplexity is 173.32669640324303
At time: 375.83542251586914 and batch: 900, loss is 5.193084030151367 and perplexity is 180.0228937227808
At time: 376.85692048072815 and batch: 950, loss is 5.172539749145508 and perplexity is 176.3621848768656
At time: 377.87980556488037 and batch: 1000, loss is 5.193385591506958 and perplexity is 180.07718985704565
At time: 378.9017198085785 and batch: 1050, loss is 5.148543510437012 and perplexity is 172.18052845690724
At time: 379.9244589805603 and batch: 1100, loss is 5.141400671005249 and perplexity is 170.95505248822604
At time: 380.95940685272217 and batch: 1150, loss is 5.156349287033081 and perplexity is 173.5297903638556
At time: 381.986291885376 and batch: 1200, loss is 5.139754161834717 and perplexity is 170.6738050283547
At time: 383.00889325141907 and batch: 1250, loss is 5.1598506355285645 and perplexity is 174.13844356594208
At time: 384.0315365791321 and batch: 1300, loss is 5.156215162277221 and perplexity is 173.5065172838716
At time: 385.053915977478 and batch: 1350, loss is 5.14808536529541 and perplexity is 172.10166285164266
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.135220133463542 and perplexity of 169.90171681175687
Finished 13 epochs...
Completing Train Step...
At time: 388.1367084980011 and batch: 50, loss is 5.245346088409423 and perplexity is 189.68145042254864
At time: 389.18427085876465 and batch: 100, loss is 5.242000093460083 and perplexity is 189.0478378707939
At time: 390.2066762447357 and batch: 150, loss is 5.209525947570801 and perplexity is 183.0072825803797
At time: 391.23267126083374 and batch: 200, loss is 5.197610807418823 and perplexity is 180.8396645407402
At time: 392.26513719558716 and batch: 250, loss is 5.21817873954773 and perplexity is 184.5976772812322
At time: 393.31403636932373 and batch: 300, loss is 5.227712411880493 and perplexity is 186.3659868984721
At time: 394.3354458808899 and batch: 350, loss is 5.225188074111938 and perplexity is 185.8961294878793
At time: 395.35803961753845 and batch: 400, loss is 5.252766056060791 and perplexity is 191.09411513067639
At time: 396.3800675868988 and batch: 450, loss is 5.2159555149078365 and perplexity is 184.1877310467726
At time: 397.4030566215515 and batch: 500, loss is 5.2584256839752195 and perplexity is 192.17870300579008
At time: 398.43003273010254 and batch: 550, loss is 5.227182149887085 and perplexity is 186.26719029511278
At time: 399.45215916633606 and batch: 600, loss is 5.169914665222168 and perplexity is 175.89982647098117
At time: 400.47501945495605 and batch: 650, loss is 5.183414697647095 and perplexity is 178.2905811551053
At time: 401.49714946746826 and batch: 700, loss is 5.212945022583008 and perplexity is 183.63406911178768
At time: 402.519553899765 and batch: 750, loss is 5.199298639297485 and perplexity is 181.1451492223491
At time: 403.54070258140564 and batch: 800, loss is 5.161480407714844 and perplexity is 174.42248095307392
At time: 404.56161308288574 and batch: 850, loss is 5.147995471954346 and perplexity is 172.08619275350605
At time: 405.58472657203674 and batch: 900, loss is 5.1830667304992675 and perplexity is 178.2285526826575
At time: 406.6066863536835 and batch: 950, loss is 5.162665777206421 and perplexity is 174.62935862966026
At time: 407.6276857852936 and batch: 1000, loss is 5.182943859100342 and perplexity is 178.20665483639792
At time: 408.64820289611816 and batch: 1050, loss is 5.13379714012146 and perplexity is 169.6601197362081
At time: 409.66954040527344 and batch: 1100, loss is 5.132020292282104 and perplexity is 169.35892718494043
At time: 410.69121193885803 and batch: 1150, loss is 5.150683717727661 and perplexity is 172.54942509604635
At time: 411.71379685401917 and batch: 1200, loss is 5.130596742630005 and perplexity is 169.1180078640593
At time: 412.73632621765137 and batch: 1250, loss is 5.15361255645752 and perplexity is 173.05553533092277
At time: 413.7582733631134 and batch: 1300, loss is 5.147640371322632 and perplexity is 172.0250956861957
At time: 414.78081798553467 and batch: 1350, loss is 5.138101606369019 and perplexity is 170.39199002060425
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.135423177083333 and perplexity of 169.93621777382867
Annealing...
Finished 14 epochs...
Completing Train Step...
At time: 417.85038709640503 and batch: 50, loss is 5.236969776153565 and perplexity is 188.09925509661667
At time: 418.8988718986511 and batch: 100, loss is 5.239380798339844 and perplexity is 188.55331372663798
At time: 419.9210147857666 and batch: 150, loss is 5.205118207931519 and perplexity is 182.20240926578037
At time: 420.9433023929596 and batch: 200, loss is 5.197051029205323 and perplexity is 180.73846276431095
At time: 421.96560764312744 and batch: 250, loss is 5.209081468582153 and perplexity is 182.92595776342827
At time: 422.98769068717957 and batch: 300, loss is 5.211783485412598 and perplexity is 183.42089514347197
At time: 424.0129406452179 and batch: 350, loss is 5.213311862945557 and perplexity is 183.70144585777638
At time: 425.035973072052 and batch: 400, loss is 5.23978063583374 and perplexity is 188.62871948508442
At time: 426.059344291687 and batch: 450, loss is 5.2006276512145995 and perplexity is 181.3860533311503
At time: 427.0838532447815 and batch: 500, loss is 5.239528465270996 and perplexity is 188.58115887168753
At time: 428.10640716552734 and batch: 550, loss is 5.201017942428589 and perplexity is 181.45686053092078
At time: 429.1304292678833 and batch: 600, loss is 5.146370496749878 and perplexity is 171.80678403485277
At time: 430.1547317504883 and batch: 650, loss is 5.157899494171143 and perplexity is 173.799006099708
At time: 431.1776223182678 and batch: 700, loss is 5.180024490356446 and perplexity is 177.68716256202543
At time: 432.2014412879944 and batch: 750, loss is 5.16414623260498 and perplexity is 174.88808107265476
At time: 433.22428154945374 and batch: 800, loss is 5.127414989471435 and perplexity is 168.58077123876006
At time: 434.2467200756073 and batch: 850, loss is 5.10542181968689 and perplexity is 164.91361967342587
At time: 435.26910042762756 and batch: 900, loss is 5.133591938018799 and perplexity is 169.6253086946721
At time: 436.2918076515198 and batch: 950, loss is 5.112739934921264 and perplexity is 166.12490329664806
At time: 437.3142807483673 and batch: 1000, loss is 5.125702362060547 and perplexity is 168.29230227942023
At time: 438.3369777202606 and batch: 1050, loss is 5.064477367401123 and perplexity is 158.29768891826131
At time: 439.3591253757477 and batch: 1100, loss is 5.053122472763062 and perplexity is 156.51040177117812
At time: 440.382915019989 and batch: 1150, loss is 5.059906558990479 and perplexity is 157.57579159438816
At time: 441.40605211257935 and batch: 1200, loss is 5.034607696533203 and perplexity is 153.63930755460726
At time: 442.428936958313 and batch: 1250, loss is 5.057194757461548 and perplexity is 157.1490561941883
At time: 443.4597704410553 and batch: 1300, loss is 5.060798978805542 and perplexity is 157.71647811956558
At time: 444.48277020454407 and batch: 1350, loss is 5.06835638999939 and perplexity is 158.91292171033945
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.068926188151042 and perplexity of 159.0034958014279
Finished 15 epochs...
Completing Train Step...
At time: 447.5974791049957 and batch: 50, loss is 5.203922014236451 and perplexity is 181.98459019546243
At time: 448.63720059394836 and batch: 100, loss is 5.208816766738892 and perplexity is 182.8775433332051
At time: 449.6599495410919 and batch: 150, loss is 5.176290807723999 and perplexity is 177.02497206300734
At time: 450.6828510761261 and batch: 200, loss is 5.168384561538696 and perplexity is 175.63088730345163
At time: 451.7056887149811 and batch: 250, loss is 5.1825262069702145 and perplexity is 178.13224198782666
At time: 452.7281756401062 and batch: 300, loss is 5.185571413040162 and perplexity is 178.67551814648002
At time: 453.7509207725525 and batch: 350, loss is 5.187391376495361 and perplexity is 179.00099714995184
At time: 454.7736439704895 and batch: 400, loss is 5.216223115921021 and perplexity is 184.23702646567466
At time: 455.7984445095062 and batch: 450, loss is 5.177592668533325 and perplexity is 177.25558401616942
At time: 456.821724653244 and batch: 500, loss is 5.2189775085449215 and perplexity is 184.7451870880853
At time: 457.8441915512085 and batch: 550, loss is 5.183642148971558 and perplexity is 178.33113819612979
At time: 458.867609500885 and batch: 600, loss is 5.129941625595093 and perplexity is 169.0072520591655
At time: 459.89061975479126 and batch: 650, loss is 5.141364221572876 and perplexity is 170.94882138716233
At time: 460.91350626945496 and batch: 700, loss is 5.164951171875 and perplexity is 175.02891202954828
At time: 461.93697786331177 and batch: 750, loss is 5.150551748275757 and perplexity is 172.52665534547882
At time: 462.95965099334717 and batch: 800, loss is 5.113708953857422 and perplexity is 166.28595949436
At time: 463.98286175727844 and batch: 850, loss is 5.094452238082885 and perplexity is 163.11447225320094
At time: 465.00561809539795 and batch: 900, loss is 5.125340623855591 and perplexity is 168.23143553366307
At time: 466.02942633628845 and batch: 950, loss is 5.105487823486328 and perplexity is 164.9245049581346
At time: 467.0517945289612 and batch: 1000, loss is 5.121334838867187 and perplexity is 167.55888452132945
At time: 468.07427740097046 and batch: 1050, loss is 5.062180833816528 and perplexity is 157.93457007619756
At time: 469.0964922904968 and batch: 1100, loss is 5.0553210163116455 and perplexity is 156.8548752364821
At time: 470.1188759803772 and batch: 1150, loss is 5.065094041824341 and perplexity is 158.39533715976364
At time: 471.16827154159546 and batch: 1200, loss is 5.0442138671875 and perplexity is 155.1223045190996
At time: 472.1911597251892 and batch: 1250, loss is 5.068790273666382 and perplexity is 158.9818863917861
At time: 473.2145597934723 and batch: 1300, loss is 5.0708167839050295 and perplexity is 159.30439148188165
At time: 474.2387447357178 and batch: 1350, loss is 5.073455448150635 and perplexity is 159.72529735427614
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.063951416015625 and perplexity of 158.21445392015366
Finished 16 epochs...
Completing Train Step...
At time: 477.34070014953613 and batch: 50, loss is 5.196425218582153 and perplexity is 180.62539009902554
At time: 478.3634307384491 and batch: 100, loss is 5.199057168960572 and perplexity is 181.10141332280986
At time: 479.3950252532959 and batch: 150, loss is 5.1650230884552 and perplexity is 175.04149996297278
At time: 480.417533159256 and batch: 200, loss is 5.157333974838257 and perplexity is 173.70074718799805
At time: 481.4493975639343 and batch: 250, loss is 5.1719287014007564 and perplexity is 176.25445207983057
At time: 482.47207617759705 and batch: 300, loss is 5.175324230194092 and perplexity is 176.85394637088982
At time: 483.5061740875244 and batch: 350, loss is 5.177405633926392 and perplexity is 177.22243418786536
At time: 484.53132033348083 and batch: 400, loss is 5.206414470672607 and perplexity is 182.43874460350168
At time: 485.5537028312683 and batch: 450, loss is 5.168050813674927 and perplexity is 175.5722806504688
At time: 486.57634806632996 and batch: 500, loss is 5.210275259017944 and perplexity is 183.14446342129645
At time: 487.60020089149475 and batch: 550, loss is 5.1765482711791995 and perplexity is 177.07055539174038
At time: 488.62347054481506 and batch: 600, loss is 5.123636455535888 and perplexity is 167.9449850001363
At time: 489.66124391555786 and batch: 650, loss is 5.134819793701172 and perplexity is 169.83371201224307
At time: 490.69828057289124 and batch: 700, loss is 5.159385442733765 and perplexity is 174.05745445593328
At time: 491.7249720096588 and batch: 750, loss is 5.145654392242432 and perplexity is 171.6837964636284
At time: 492.7515199184418 and batch: 800, loss is 5.1091392040252686 and perplexity is 165.52780785987184
At time: 493.774133682251 and batch: 850, loss is 5.091541404724121 and perplexity is 162.6403635665178
At time: 494.7968032360077 and batch: 900, loss is 5.123271312713623 and perplexity is 167.88367228895746
At time: 495.82004714012146 and batch: 950, loss is 5.104040164947509 and perplexity is 164.6859233243078
At time: 496.8865501880646 and batch: 1000, loss is 5.121125192642212 and perplexity is 167.5237601157066
At time: 497.90970826148987 and batch: 1050, loss is 5.063549575805664 and perplexity is 158.15088976294393
At time: 498.934134721756 and batch: 1100, loss is 5.058485908508301 and perplexity is 157.35209040830267
At time: 499.9572341442108 and batch: 1150, loss is 5.069588356018066 and perplexity is 159.10881767362355
At time: 500.9829897880554 and batch: 1200, loss is 5.050006923675537 and perplexity is 156.02354473905518
At time: 502.00647711753845 and batch: 1250, loss is 5.074582767486572 and perplexity is 159.90546030192925
At time: 503.03034687042236 and batch: 1300, loss is 5.075677042007446 and perplexity is 160.08053654615264
At time: 504.05344820022583 and batch: 1350, loss is 5.075268268585205 and perplexity is 160.01511324995784
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.062273763020833 and perplexity of 157.94924749209673
Finished 17 epochs...
Completing Train Step...
At time: 507.1357114315033 and batch: 50, loss is 5.1915661907196045 and perplexity is 179.74985514284947
At time: 508.18484449386597 and batch: 100, loss is 5.193029708862305 and perplexity is 180.0131149127342
At time: 509.2086398601532 and batch: 150, loss is 5.158232517242432 and perplexity is 173.85689481711057
At time: 510.2338659763336 and batch: 200, loss is 5.15058611869812 and perplexity is 172.53258526139825
At time: 511.25776648521423 and batch: 250, loss is 5.165779075622559 and perplexity is 175.17387912286827
At time: 512.282874584198 and batch: 300, loss is 5.1697204971313475 and perplexity is 175.86567565310642
At time: 513.307918548584 and batch: 350, loss is 5.171881084442139 and perplexity is 176.24605957869395
At time: 514.3324151039124 and batch: 400, loss is 5.200975484848023 and perplexity is 181.44915647519448
At time: 515.3554434776306 and batch: 450, loss is 5.1626294994354245 and perplexity is 174.6230235806901
At time: 516.3790836334229 and batch: 500, loss is 5.205469923019409 and perplexity is 182.2665038730286
At time: 517.4019503593445 and batch: 550, loss is 5.172808227539062 and perplexity is 176.40954066966418
At time: 518.4254145622253 and batch: 600, loss is 5.120295143127441 and perplexity is 167.38476479438995
At time: 519.4484732151031 and batch: 650, loss is 5.131528768539429 and perplexity is 169.27570370602848
At time: 520.4725017547607 and batch: 700, loss is 5.156453428268432 and perplexity is 173.54786291162665
At time: 521.495935678482 and batch: 750, loss is 5.143271894454956 and perplexity is 171.27524707566866
At time: 522.563494682312 and batch: 800, loss is 5.107005710601807 and perplexity is 165.17503182688955
At time: 523.5869362354279 and batch: 850, loss is 5.0905421924591066 and perplexity is 162.47793248553447
At time: 524.6107380390167 and batch: 900, loss is 5.122591009140015 and perplexity is 167.76949926730956
At time: 525.6346657276154 and batch: 950, loss is 5.1040765571594235 and perplexity is 164.69191671838448
At time: 526.6582133769989 and batch: 1000, loss is 5.121619415283203 and perplexity is 167.60657461357408
At time: 527.6818006038666 and batch: 1050, loss is 5.065091552734375 and perplexity is 158.39494290001005
At time: 528.7051205635071 and batch: 1100, loss is 5.0606726551055905 and perplexity is 157.6965560488476
At time: 529.7289469242096 and batch: 1150, loss is 5.072382726669312 and perplexity is 159.5540484642967
At time: 530.7529919147491 and batch: 1200, loss is 5.053410005569458 and perplexity is 156.55541011660748
At time: 531.7771651744843 and batch: 1250, loss is 5.077811079025269 and perplexity is 160.42251910891358
At time: 532.8013153076172 and batch: 1300, loss is 5.078348407745361 and perplexity is 160.50874189869648
At time: 533.8301198482513 and batch: 1350, loss is 5.076036195755005 and perplexity is 160.13804039650802
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.061655680338542 and perplexity of 157.8516519617015
Finished 18 epochs...
Completing Train Step...
At time: 536.9135587215424 and batch: 50, loss is 5.187913255691528 and perplexity is 179.0944384268661
At time: 537.9637784957886 and batch: 100, loss is 5.188474206924439 and perplexity is 179.19492985566936
At time: 538.9872641563416 and batch: 150, loss is 5.153347101211548 and perplexity is 173.00960292799303
At time: 540.0113832950592 and batch: 200, loss is 5.145632066726685 and perplexity is 171.67996357711266
At time: 541.0369715690613 and batch: 250, loss is 5.161395988464355 and perplexity is 174.40775695946647
At time: 542.0614812374115 and batch: 300, loss is 5.165788698196411 and perplexity is 175.17556475456718
At time: 543.0890944004059 and batch: 350, loss is 5.168188152313232 and perplexity is 175.59639516430684
At time: 544.1139416694641 and batch: 400, loss is 5.197077264785767 and perplexity is 180.74320460499237
At time: 545.1375606060028 and batch: 450, loss is 5.158836793899536 and perplexity is 173.96198422866658
At time: 546.161180973053 and batch: 500, loss is 5.202118043899536 and perplexity is 181.65659133203513
At time: 547.1848917007446 and batch: 550, loss is 5.170262594223022 and perplexity is 175.96103776983108
At time: 548.208664894104 and batch: 600, loss is 5.118019742965698 and perplexity is 167.0043304578188
At time: 549.2576014995575 and batch: 650, loss is 5.129415626525879 and perplexity is 168.91837777783576
At time: 550.2818982601166 and batch: 700, loss is 5.154520750045776 and perplexity is 173.21277464958533
At time: 551.3061344623566 and batch: 750, loss is 5.141742687225342 and perplexity is 171.0135318889657
At time: 552.3295238018036 and batch: 800, loss is 5.105748701095581 and perplexity is 164.96753568132732
At time: 553.3533234596252 and batch: 850, loss is 5.09013445854187 and perplexity is 162.4116982255524
At time: 554.3771960735321 and batch: 900, loss is 5.12235764503479 and perplexity is 167.73035245613696
At time: 555.4013476371765 and batch: 950, loss is 5.104415674209594 and perplexity is 164.7477760262555
At time: 556.4247007369995 and batch: 1000, loss is 5.122078771591187 and perplexity is 167.68358343677255
At time: 557.4484012126923 and batch: 1050, loss is 5.0660862159729 and perplexity is 158.55257090727721
At time: 558.4721055030823 and batch: 1100, loss is 5.061997413635254 and perplexity is 157.90560434525568
At time: 559.4960179328918 and batch: 1150, loss is 5.074253740310669 and perplexity is 159.85285571455861
At time: 560.5206232070923 and batch: 1200, loss is 5.055393314361572 and perplexity is 156.86621594803387
At time: 561.5505967140198 and batch: 1250, loss is 5.079749488830567 and perplexity is 160.7337852761768
At time: 562.5748763084412 and batch: 1300, loss is 5.079959897994995 and perplexity is 160.76760869588617
At time: 563.5990097522736 and batch: 1350, loss is 5.0762072277069095 and perplexity is 160.16543146043796
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.061170654296875 and perplexity of 157.7751083640996
Finished 19 epochs...
Completing Train Step...
At time: 566.7106680870056 and batch: 50, loss is 5.1849761581420895 and perplexity is 178.56919231776243
At time: 567.7337460517883 and batch: 100, loss is 5.185038900375366 and perplexity is 178.58039649916682
At time: 568.7634139060974 and batch: 150, loss is 5.149578561782837 and perplexity is 172.35883640763473
At time: 569.7935743331909 and batch: 200, loss is 5.141939907073975 and perplexity is 171.04726247790046
At time: 570.8278841972351 and batch: 250, loss is 5.1580460739135745 and perplexity is 173.824483380438
At time: 571.8530640602112 and batch: 300, loss is 5.162814083099366 and perplexity is 174.65525911317593
At time: 572.8764863014221 and batch: 350, loss is 5.165462388992309 and perplexity is 175.11841268058504
At time: 573.9003224372864 and batch: 400, loss is 5.194123783111572 and perplexity is 180.21017040330332
At time: 574.9500057697296 and batch: 450, loss is 5.1559358406066895 and perplexity is 173.45805992152646
At time: 575.9741542339325 and batch: 500, loss is 5.199517011642456 and perplexity is 181.18471063276667
At time: 576.9978392124176 and batch: 550, loss is 5.168291292190552 and perplexity is 175.61450708897667
At time: 578.029953956604 and batch: 600, loss is 5.1163388442993165 and perplexity is 166.72384889805204
At time: 579.0529522895813 and batch: 650, loss is 5.127890176773072 and perplexity is 168.6608977165874
At time: 580.075944185257 and batch: 700, loss is 5.153108081817627 and perplexity is 172.9682552192077
At time: 581.0988388061523 and batch: 750, loss is 5.140654897689819 and perplexity is 170.8276063008322
At time: 582.121853351593 and batch: 800, loss is 5.104874105453491 and perplexity is 164.823318868425
At time: 583.14568400383 and batch: 850, loss is 5.090003976821899 and perplexity is 162.3905078503329
At time: 584.1688735485077 and batch: 900, loss is 5.122261400222778 and perplexity is 167.71421005671974
At time: 585.1924479007721 and batch: 950, loss is 5.104779071807862 and perplexity is 164.80765585181678
At time: 586.2165613174438 and batch: 1000, loss is 5.122449493408203 and perplexity is 167.74575892370066
At time: 587.2394547462463 and batch: 1050, loss is 5.066828889846802 and perplexity is 158.67036749614007
At time: 588.2626595497131 and batch: 1100, loss is 5.062756681442261 and perplexity is 158.02554251401435
At time: 589.2869343757629 and batch: 1150, loss is 5.075459432601929 and perplexity is 160.04570530570015
At time: 590.3104100227356 and batch: 1200, loss is 5.056678142547607 and perplexity is 157.06789161526788
At time: 591.3339002132416 and batch: 1250, loss is 5.080888290405273 and perplexity is 160.91693342886688
At time: 592.3575835227966 and batch: 1300, loss is 5.0809142112731935 and perplexity is 160.9211045895043
At time: 593.3809514045715 and batch: 1350, loss is 5.076008129119873 and perplexity is 160.13354592363007
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.06091796875 and perplexity of 157.73524591110433
Finished 20 epochs...
Completing Train Step...
At time: 596.4702315330505 and batch: 50, loss is 5.182411603927612 and perplexity is 178.1118286606463
At time: 597.4939522743225 and batch: 100, loss is 5.182114639282227 and perplexity is 178.05894359749482
At time: 598.517911195755 and batch: 150, loss is 5.146562700271606 and perplexity is 171.8398090774642
At time: 599.541782617569 and batch: 200, loss is 5.1388951015472415 and perplexity is 170.52724889963054
At time: 600.6067891120911 and batch: 250, loss is 5.15524580001831 and perplexity is 173.3384081068511
At time: 601.6386611461639 and batch: 300, loss is 5.1602787590026855 and perplexity is 174.21301228254958
At time: 602.6634519100189 and batch: 350, loss is 5.163278112411499 and perplexity is 174.73632307949634
At time: 603.6892461776733 and batch: 400, loss is 5.191693735122681 and perplexity is 179.772782692936
At time: 604.7128357887268 and batch: 450, loss is 5.153544034957886 and perplexity is 173.04367771237742
At time: 605.7369215488434 and batch: 500, loss is 5.197382698059082 and perplexity is 180.7984180251829
At time: 606.7608349323273 and batch: 550, loss is 5.166658382415772 and perplexity is 175.3279784451361
At time: 607.7849638462067 and batch: 600, loss is 5.114954996109009 and perplexity is 166.49328796892993
At time: 608.808923959732 and batch: 650, loss is 5.126648111343384 and perplexity is 168.45153989116739
At time: 609.8331742286682 and batch: 700, loss is 5.152027921676636 and perplexity is 172.78152267294567
At time: 610.8565635681152 and batch: 750, loss is 5.1397097873687745 and perplexity is 170.66623163744
At time: 611.8856842517853 and batch: 800, loss is 5.104186325073242 and perplexity is 164.70999559872783
At time: 612.911717414856 and batch: 850, loss is 5.0899170398712155 and perplexity is 162.37639072841907
At time: 613.93559217453 and batch: 900, loss is 5.12219241142273 and perplexity is 167.7026400537217
At time: 614.9594461917877 and batch: 950, loss is 5.105112905502319 and perplexity is 164.862683384956
At time: 615.9831931591034 and batch: 1000, loss is 5.122755222320556 and perplexity is 167.79705149253945
At time: 617.0071935653687 and batch: 1050, loss is 5.067336978912354 and perplexity is 158.7510066590957
At time: 618.0307500362396 and batch: 1100, loss is 5.063192863464355 and perplexity is 158.09448544943203
At time: 619.0540580749512 and batch: 1150, loss is 5.076266279220581 and perplexity is 160.17488975086403
At time: 620.0787489414215 and batch: 1200, loss is 5.057436227798462 and perplexity is 157.18700761161963
At time: 621.1032528877258 and batch: 1250, loss is 5.081510286331177 and perplexity is 161.0170542400091
At time: 622.1276209354401 and batch: 1300, loss is 5.081481666564941 and perplexity is 161.0124460354999
At time: 623.1513864994049 and batch: 1350, loss is 5.075604801177978 and perplexity is 160.06897261311
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.060743408203125 and perplexity of 157.70771396338245
Finished 21 epochs...
Completing Train Step...
At time: 626.2241840362549 and batch: 50, loss is 5.180090970993042 and perplexity is 177.6989757103761
At time: 627.2741844654083 and batch: 100, loss is 5.179572505950928 and perplexity is 177.6068688825991
At time: 628.3031806945801 and batch: 150, loss is 5.143941354751587 and perplexity is 171.3899474427686
At time: 629.3337368965149 and batch: 200, loss is 5.136207847595215 and perplexity is 170.06961404203113
At time: 630.3576490879059 and batch: 250, loss is 5.1528600978851316 and perplexity is 172.92536718907255
At time: 631.384185552597 and batch: 300, loss is 5.158083810806274 and perplexity is 173.83104310008684
At time: 632.4166858196259 and batch: 350, loss is 5.1613688564300535 and perplexity is 174.40302498641643
At time: 633.4415221214294 and batch: 400, loss is 5.189557285308838 and perplexity is 179.38911715183866
At time: 634.4658427238464 and batch: 450, loss is 5.151521444320679 and perplexity is 172.69403490134184
At time: 635.4963102340698 and batch: 500, loss is 5.195597257614136 and perplexity is 180.47590122020884
At time: 636.5365011692047 and batch: 550, loss is 5.165239334106445 and perplexity is 175.07935601908343
At time: 637.5611336231232 and batch: 600, loss is 5.113749570846558 and perplexity is 166.29271366653632
At time: 638.5852584838867 and batch: 650, loss is 5.125516414642334 and perplexity is 168.2610116696004
At time: 639.6093845367432 and batch: 700, loss is 5.150972185134887 and perplexity is 172.59920716122858
At time: 640.6329255104065 and batch: 750, loss is 5.138750286102295 and perplexity is 170.5025557082265
At time: 641.6571590900421 and batch: 800, loss is 5.10327714920044 and perplexity is 164.5603132987985
At time: 642.6812641620636 and batch: 850, loss is 5.089534215927124 and perplexity is 162.3142410550436
At time: 643.705176115036 and batch: 900, loss is 5.121984529495239 and perplexity is 167.66778132903704
At time: 644.7296235561371 and batch: 950, loss is 5.105217599868775 and perplexity is 164.87994448269922
At time: 645.7545130252838 and batch: 1000, loss is 5.122790212631226 and perplexity is 167.80292286622057
At time: 646.7788333892822 and batch: 1050, loss is 5.0675599479675295 and perplexity is 158.78640716752096
At time: 647.8031268119812 and batch: 1100, loss is 5.0634011554718015 and perplexity is 158.12741869691953
At time: 648.8276169300079 and batch: 1150, loss is 5.076798515319824 and perplexity is 160.26016330019934
At time: 649.8513464927673 and batch: 1200, loss is 5.057846660614014 and perplexity is 157.25153555900957
At time: 650.8757357597351 and batch: 1250, loss is 5.0817936992645265 and perplexity is 161.0626950229591
At time: 651.8999552726746 and batch: 1300, loss is 5.08177827835083 and perplexity is 161.06021130819008
At time: 652.9237048625946 and batch: 1350, loss is 5.075044555664062 and perplexity is 159.979319805423
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0607470703125 and perplexity of 157.70829150733775
Annealing...
Finished 22 epochs...
Completing Train Step...
At time: 656.0056836605072 and batch: 50, loss is 5.180048141479492 and perplexity is 177.69136511266834
At time: 657.0570809841156 and batch: 100, loss is 5.17914680480957 and perplexity is 177.53127752660768
At time: 658.0819189548492 and batch: 150, loss is 5.145633773803711 and perplexity is 171.6802566482845
At time: 659.10861992836 and batch: 200, loss is 5.139793024063111 and perplexity is 170.6804379216302
At time: 660.1330516338348 and batch: 250, loss is 5.156118621826172 and perplexity is 173.48976769495246
At time: 661.1576809883118 and batch: 300, loss is 5.159924898147583 and perplexity is 174.15137602302624
At time: 662.182501077652 and batch: 350, loss is 5.16159197807312 and perplexity is 174.44194241740627
At time: 663.2099146842957 and batch: 400, loss is 5.188431463241577 and perplexity is 179.18727056811144
At time: 664.2409117221832 and batch: 450, loss is 5.1494936275482175 and perplexity is 172.3441978634501
At time: 665.2654118537903 and batch: 500, loss is 5.194357919692993 and perplexity is 180.25236913647956
At time: 666.2897038459778 and batch: 550, loss is 5.160063514709472 and perplexity is 174.1755179612164
At time: 667.3138918876648 and batch: 600, loss is 5.110398006439209 and perplexity is 165.73630586534455
At time: 668.3548262119293 and batch: 650, loss is 5.120257139205933 and perplexity is 167.37840363780222
At time: 669.382187128067 and batch: 700, loss is 5.141800470352173 and perplexity is 171.0234138710718
At time: 670.4064726829529 and batch: 750, loss is 5.129752798080444 and perplexity is 168.97534185265891
At time: 671.4306447505951 and batch: 800, loss is 5.095168218612671 and perplexity is 163.23130085797288
At time: 672.4550895690918 and batch: 850, loss is 5.084485483169556 and perplexity is 161.49682502306473
At time: 673.4789018630981 and batch: 900, loss is 5.1130306434631345 and perplexity is 166.17320424546278
At time: 674.5029757022858 and batch: 950, loss is 5.09746413230896 and perplexity is 163.60649638073397
At time: 675.5269117355347 and batch: 1000, loss is 5.112821483612061 and perplexity is 166.13845111741662
At time: 676.5512039661407 and batch: 1050, loss is 5.05831618309021 and perplexity is 157.3253860252411
At time: 677.575174331665 and batch: 1100, loss is 5.050032272338867 and perplexity is 156.02749977748962
At time: 678.6292397975922 and batch: 1150, loss is 5.059687871932983 and perplexity is 157.5413355758718
At time: 679.6532588005066 and batch: 1200, loss is 5.037636508941651 and perplexity is 154.10535762859374
At time: 680.678900718689 and batch: 1250, loss is 5.063171243667602 and perplexity is 158.0910675157365
At time: 681.7033817768097 and batch: 1300, loss is 5.065164575576782 and perplexity is 158.4065097712812
At time: 682.7278504371643 and batch: 1350, loss is 5.062768430709839 and perplexity is 158.0273992093048
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.054156901041667 and perplexity of 156.67238432188762
Finished 23 epochs...
Completing Train Step...
At time: 685.8227701187134 and batch: 50, loss is 5.177354650497437 and perplexity is 177.21339901080682
At time: 686.8483164310455 and batch: 100, loss is 5.175970153808594 and perplexity is 176.96821741237767
At time: 687.8775479793549 and batch: 150, loss is 5.14264630317688 and perplexity is 171.16813228348116
At time: 688.9179656505585 and batch: 200, loss is 5.137229852676391 and perplexity is 170.24351490037967
At time: 689.9449014663696 and batch: 250, loss is 5.1534637832641605 and perplexity is 173.02979122136725
At time: 690.9762403964996 and batch: 300, loss is 5.157144708633423 and perplexity is 173.6678746177324
At time: 692.0155272483826 and batch: 350, loss is 5.158584442138672 and perplexity is 173.9180901542294
At time: 693.040326833725 and batch: 400, loss is 5.18541880607605 and perplexity is 178.6482530985656
At time: 694.0636706352234 and batch: 450, loss is 5.147267332077027 and perplexity is 171.9609355421456
At time: 695.0888378620148 and batch: 500, loss is 5.192584161758423 and perplexity is 179.93292845547242
At time: 696.1126842498779 and batch: 550, loss is 5.158867511749268 and perplexity is 173.967328048832
At time: 697.1359946727753 and batch: 600, loss is 5.109091739654541 and perplexity is 165.519951373087
At time: 698.162618637085 and batch: 650, loss is 5.118878345489502 and perplexity is 167.1477823727115
At time: 699.1859619617462 and batch: 700, loss is 5.140816278457642 and perplexity is 170.85517681571795
At time: 700.2098920345306 and batch: 750, loss is 5.12861364364624 and perplexity is 168.78296243845145
At time: 701.2338008880615 and batch: 800, loss is 5.094162693023682 and perplexity is 163.06725010047586
At time: 702.2597732543945 and batch: 850, loss is 5.0834665107727055 and perplexity is 161.33234802917704
At time: 703.2841727733612 and batch: 900, loss is 5.112302131652832 and perplexity is 166.05218918941517
At time: 704.3342368602753 and batch: 950, loss is 5.096742391586304 and perplexity is 163.4884575116582
At time: 705.359697341919 and batch: 1000, loss is 5.112570428848267 and perplexity is 166.09674650310433
At time: 706.3858880996704 and batch: 1050, loss is 5.05895076751709 and perplexity is 157.42525394912886
At time: 707.4093885421753 and batch: 1100, loss is 5.0510329914093015 and perplexity is 156.18371762408142
At time: 708.4323811531067 and batch: 1150, loss is 5.0606741619110105 and perplexity is 157.696793667052
At time: 709.4556839466095 and batch: 1200, loss is 5.039173173904419 and perplexity is 154.34234797298126
At time: 710.478414773941 and batch: 1250, loss is 5.06471438407898 and perplexity is 158.3352125572896
At time: 711.5018939971924 and batch: 1300, loss is 5.066384382247925 and perplexity is 158.59985298535048
At time: 712.5249977111816 and batch: 1350, loss is 5.063437509536743 and perplexity is 158.13316737586118
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.053562825520833 and perplexity of 156.57933673495478
Finished 24 epochs...
Completing Train Step...
At time: 715.6211817264557 and batch: 50, loss is 5.176204633712769 and perplexity is 177.00971776834814
At time: 716.6437082290649 and batch: 100, loss is 5.17448073387146 and perplexity is 176.70483361435478
At time: 717.666421175003 and batch: 150, loss is 5.141046180725097 and perplexity is 170.89446132390012
At time: 718.689279794693 and batch: 200, loss is 5.13570616722107 and perplexity is 169.98431485268142
At time: 719.712363243103 and batch: 250, loss is 5.152024965286255 and perplexity is 172.78101186406917
At time: 720.7349956035614 and batch: 300, loss is 5.155608253479004 and perplexity is 173.4012466000673
At time: 721.7579197883606 and batch: 350, loss is 5.156955375671386 and perplexity is 173.6349966771576
At time: 722.7812740802765 and batch: 400, loss is 5.183843116760254 and perplexity is 178.36698061209373
At time: 723.8131582736969 and batch: 450, loss is 5.145930385589599 and perplexity is 171.7311865886476
At time: 724.8382425308228 and batch: 500, loss is 5.191444406509399 and perplexity is 179.72796578162271
At time: 725.8611304759979 and batch: 550, loss is 5.1581800365448 and perplexity is 173.8477709253986
At time: 726.8843102455139 and batch: 600, loss is 5.108406295776367 and perplexity is 165.40653561021338
At time: 727.9067559242249 and batch: 650, loss is 5.118209104537964 and perplexity is 167.03595765480293
At time: 728.9290957450867 and batch: 700, loss is 5.140335607528686 and perplexity is 170.7730714335771
At time: 729.9520194530487 and batch: 750, loss is 5.128113374710083 and perplexity is 168.69854668244176
At time: 731.0044121742249 and batch: 800, loss is 5.093886079788208 and perplexity is 163.02214977878631
At time: 732.027444601059 and batch: 850, loss is 5.083155241012573 and perplexity is 161.28213796274747
At time: 733.0506620407104 and batch: 900, loss is 5.112243814468384 and perplexity is 166.04250577562757
At time: 734.073676109314 and batch: 950, loss is 5.096687335968017 and perplexity is 163.4794568013193
At time: 735.0966899394989 and batch: 1000, loss is 5.112899761199952 and perplexity is 166.15145654363604
At time: 736.1194186210632 and batch: 1050, loss is 5.059735536575317 and perplexity is 157.5488449062483
At time: 737.1430461406708 and batch: 1100, loss is 5.05203992843628 and perplexity is 156.34106399801843
At time: 738.1668508052826 and batch: 1150, loss is 5.061629104614258 and perplexity is 157.84745699546352
At time: 739.1916260719299 and batch: 1200, loss is 5.040398750305176 and perplexity is 154.53162227366107
At time: 740.2173638343811 and batch: 1250, loss is 5.065726718902588 and perplexity is 158.49558196683785
At time: 741.2411885261536 and batch: 1300, loss is 5.067140884399414 and perplexity is 158.71987950979755
At time: 742.2648532390594 and batch: 1350, loss is 5.063734607696533 and perplexity is 158.1801554285767
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.053227132161458 and perplexity of 156.52678291287557
Finished 25 epochs...
Completing Train Step...
At time: 745.3632488250732 and batch: 50, loss is 5.175305881500244 and perplexity is 176.85070136174298
At time: 746.4122519493103 and batch: 100, loss is 5.173342151641846 and perplexity is 176.50375512483473
At time: 747.4354953765869 and batch: 150, loss is 5.139880056381226 and perplexity is 170.69529328223825
At time: 748.4587633609772 and batch: 200, loss is 5.134610681533814 and perplexity is 169.7982014296106
At time: 749.4823360443115 and batch: 250, loss is 5.150985250473022 and perplexity is 172.60146224296363
At time: 750.5057816505432 and batch: 300, loss is 5.154539089202881 and perplexity is 173.21595125500025
At time: 751.5287003517151 and batch: 350, loss is 5.155824298858643 and perplexity is 173.43871318531444
At time: 752.552045583725 and batch: 400, loss is 5.182770490646362 and perplexity is 178.17576210215023
At time: 753.5752599239349 and batch: 450, loss is 5.145026445388794 and perplexity is 171.57602200567578
At time: 754.598477602005 and batch: 500, loss is 5.190639190673828 and perplexity is 179.58330422718376
At time: 755.6210849285126 and batch: 550, loss is 5.157690229415894 and perplexity is 173.7626398984489
At time: 756.6702451705933 and batch: 600, loss is 5.10797492980957 and perplexity is 165.3352002469954
At time: 757.6946365833282 and batch: 650, loss is 5.117763576507568 and perplexity is 166.961555029042
At time: 758.7191216945648 and batch: 700, loss is 5.1400419616699216 and perplexity is 170.7229319903423
At time: 759.742525100708 and batch: 750, loss is 5.127837476730346 and perplexity is 168.65200951427806
At time: 760.7661266326904 and batch: 800, loss is 5.093776407241822 and perplexity is 163.00427170488751
At time: 761.7910716533661 and batch: 850, loss is 5.0830103778839115 and perplexity is 161.25877581984236
At time: 762.8152322769165 and batch: 900, loss is 5.112293872833252 and perplexity is 166.05081780000677
At time: 763.837867975235 and batch: 950, loss is 5.096750249862671 and perplexity is 163.48974225418814
At time: 764.8608763217926 and batch: 1000, loss is 5.11328857421875 and perplexity is 166.21607095368037
At time: 765.8847489356995 and batch: 1050, loss is 5.060426683425903 and perplexity is 157.65777193216806
At time: 766.9071600437164 and batch: 1100, loss is 5.052894010543823 and perplexity is 156.47464914167358
At time: 767.9294102191925 and batch: 1150, loss is 5.062433404922485 and perplexity is 157.97446482314862
At time: 768.9519126415253 and batch: 1200, loss is 5.041361694335937 and perplexity is 154.68049924548507
At time: 769.9739420413971 and batch: 1250, loss is 5.066461229324341 and perplexity is 158.61204138868803
At time: 771.0062427520752 and batch: 1300, loss is 5.067650470733643 and perplexity is 158.80078160291595
At time: 772.0280089378357 and batch: 1350, loss is 5.0638699626922605 and perplexity is 158.2015673519116
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.053014322916667 and perplexity of 156.49347611053767
Finished 26 epochs...
Completing Train Step...
At time: 775.0873956680298 and batch: 50, loss is 5.174538698196411 and perplexity is 176.71507648760866
At time: 776.1383721828461 and batch: 100, loss is 5.172386484146118 and perplexity is 176.33515679799024
At time: 777.1597712039948 and batch: 150, loss is 5.138947019577026 and perplexity is 170.53610256824854
At time: 778.1815588474274 and batch: 200, loss is 5.133730030059814 and perplexity is 169.6487342171595
At time: 779.2033679485321 and batch: 250, loss is 5.150159654617309 and perplexity is 172.45902199817442
At time: 780.225626707077 and batch: 300, loss is 5.153693466186524 and perplexity is 173.06953777384828
At time: 781.2483875751495 and batch: 350, loss is 5.1549499988555905 and perplexity is 173.28714198685188
At time: 782.2707304954529 and batch: 400, loss is 5.181945953369141 and perplexity is 178.02891009519658
At time: 783.3179938793182 and batch: 450, loss is 5.1443366432189945 and perplexity is 171.45770930428114
At time: 784.3498468399048 and batch: 500, loss is 5.190006799697876 and perplexity is 179.46977326791958
At time: 785.3719313144684 and batch: 550, loss is 5.157297096252441 and perplexity is 173.69434146820436
At time: 786.3937366008759 and batch: 600, loss is 5.1076732349395755 and perplexity is 165.2853269888827
At time: 787.4149763584137 and batch: 650, loss is 5.117445125579834 and perplexity is 166.90839443191703
At time: 788.436541557312 and batch: 700, loss is 5.139833507537841 and perplexity is 170.6873477986928
At time: 789.4583876132965 and batch: 750, loss is 5.127651681900025 and perplexity is 168.62067775351665
At time: 790.4801030158997 and batch: 800, loss is 5.0937346076965335 and perplexity is 162.99745834284892
At time: 791.5019040107727 and batch: 850, loss is 5.082905139923096 and perplexity is 161.24180616805285
At time: 792.5238289833069 and batch: 900, loss is 5.1123474597930905 and perplexity is 166.05971619692824
At time: 793.5461444854736 and batch: 950, loss is 5.096826171875 and perplexity is 163.50215519561692
At time: 794.5687747001648 and batch: 1000, loss is 5.113647375106812 and perplexity is 166.27572012799715
At time: 795.5907390117645 and batch: 1050, loss is 5.061028451919555 and perplexity is 157.75267396375867
At time: 796.6130554676056 and batch: 1100, loss is 5.053621034622193 and perplexity is 156.58845134271158
At time: 797.635059595108 and batch: 1150, loss is 5.0631069087982175 and perplexity is 158.08089707471748
At time: 798.657609462738 and batch: 1200, loss is 5.042138013839722 and perplexity is 154.80062735676916
At time: 799.6802983283997 and batch: 1250, loss is 5.0670302295684815 and perplexity is 158.70231736005098
At time: 800.7040061950684 and batch: 1300, loss is 5.068013029098511 and perplexity is 158.8583665929628
At time: 801.727041721344 and batch: 1350, loss is 5.063917484283447 and perplexity is 158.20908552075664
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.052872721354166 and perplexity of 156.4713179586508
Finished 27 epochs...
Completing Train Step...
At time: 804.8110976219177 and batch: 50, loss is 5.173857259750366 and perplexity is 176.59469706073727
At time: 805.834014415741 and batch: 100, loss is 5.171554718017578 and perplexity is 176.18854816779367
At time: 806.8572864532471 and batch: 150, loss is 5.138153104782105 and perplexity is 170.40076516364388
At time: 807.8801472187042 and batch: 200, loss is 5.132976150512695 and perplexity is 169.5208877027297
At time: 808.9286272525787 and batch: 250, loss is 5.1494632339477535 and perplexity is 172.33895978236043
At time: 809.9513566493988 and batch: 300, loss is 5.152979211807251 and perplexity is 172.94596623458457
At time: 810.9745571613312 and batch: 350, loss is 5.1542312526702885 and perplexity is 173.1626372635943
At time: 811.9977321624756 and batch: 400, loss is 5.181269397735596 and perplexity is 177.90850436831698
At time: 813.0201711654663 and batch: 450, loss is 5.1437733936309815 and perplexity is 171.36116301253583
At time: 814.0429646968842 and batch: 500, loss is 5.189474773406983 and perplexity is 179.3743160252533
At time: 815.0661752223969 and batch: 550, loss is 5.156962823867798 and perplexity is 173.63628994953305
At time: 816.089010477066 and batch: 600, loss is 5.107441892623902 and perplexity is 165.2470939212239
At time: 817.1119906902313 and batch: 650, loss is 5.117192115783691 and perplexity is 166.86617031485022
At time: 818.1347386837006 and batch: 700, loss is 5.139664058685303 and perplexity is 170.65842747379256
At time: 819.1576993465424 and batch: 750, loss is 5.127503032684326 and perplexity is 168.5956142848967
At time: 820.1805067062378 and batch: 800, loss is 5.093717966079712 and perplexity is 162.99474582417471
At time: 821.2037134170532 and batch: 850, loss is 5.082828073501587 and perplexity is 161.22938031786796
At time: 822.22607254982 and batch: 900, loss is 5.1123972988128665 and perplexity is 166.0679926566514
At time: 823.2485053539276 and batch: 950, loss is 5.096908092498779 and perplexity is 163.51554994280542
At time: 824.2702443599701 and batch: 1000, loss is 5.113969421386718 and perplexity is 166.3292772285728
At time: 825.2924373149872 and batch: 1050, loss is 5.0615665721893315 and perplexity is 157.83758671981852
At time: 826.3161218166351 and batch: 1100, loss is 5.054248733520508 and perplexity is 156.68677259595114
At time: 827.3392264842987 and batch: 1150, loss is 5.063679132461548 and perplexity is 158.17138059067966
At time: 828.3622951507568 and batch: 1200, loss is 5.042783899307251 and perplexity is 154.90064312823299
At time: 829.3850586414337 and batch: 1250, loss is 5.067483797073364 and perplexity is 158.77431590102003
At time: 830.4083943367004 and batch: 1300, loss is 5.068280277252197 and perplexity is 158.90082687159517
At time: 831.4337756633759 and batch: 1350, loss is 5.0639100265502925 and perplexity is 158.2079056440138
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.052769775390625 and perplexity of 156.45521069715994
Finished 28 epochs...
Completing Train Step...
At time: 834.5464971065521 and batch: 50, loss is 5.173231420516967 and perplexity is 176.48421174753457
At time: 835.5704543590546 and batch: 100, loss is 5.170812768936157 and perplexity is 176.05787371921176
At time: 836.5959529876709 and batch: 150, loss is 5.13744927406311 and perplexity is 170.28087406704918
At time: 837.619601726532 and batch: 200, loss is 5.132305908203125 and perplexity is 169.40730569941954
At time: 838.6434187889099 and batch: 250, loss is 5.148851432800293 and perplexity is 172.23355485572873
At time: 839.6694121360779 and batch: 300, loss is 5.152352991104126 and perplexity is 172.83769779351437
At time: 840.6951003074646 and batch: 350, loss is 5.153615398406982 and perplexity is 173.0560271467072
At time: 841.7183227539062 and batch: 400, loss is 5.1806908702850345 and perplexity is 177.8056091815665
At time: 842.7414951324463 and batch: 450, loss is 5.143291797637939 and perplexity is 171.2786560321762
At time: 843.7711184024811 and batch: 500, loss is 5.189006242752075 and perplexity is 179.29029334463033
At time: 844.7939064502716 and batch: 550, loss is 5.156668577194214 and perplexity is 173.58520556487565
At time: 845.816930770874 and batch: 600, loss is 5.107251977920532 and perplexity is 165.2157140482431
At time: 846.8399636745453 and batch: 650, loss is 5.116979856491088 and perplexity is 166.83075517830872
At time: 847.8623855113983 and batch: 700, loss is 5.13951509475708 and perplexity is 170.63300741743447
At time: 848.8849291801453 and batch: 750, loss is 5.127372999191284 and perplexity is 168.57369263356492
At time: 849.9079620838165 and batch: 800, loss is 5.093712062835693 and perplexity is 162.99378362925634
At time: 850.9311511516571 and batch: 850, loss is 5.082762393951416 and perplexity is 161.21879119244264
At time: 851.953934431076 and batch: 900, loss is 5.112429914474487 and perplexity is 166.07340916243686
At time: 852.9770181179047 and batch: 950, loss is 5.096977033615112 and perplexity is 163.5268232759499
At time: 853.999862909317 and batch: 1000, loss is 5.114253740310669 and perplexity is 166.37657451313387
At time: 855.022064447403 and batch: 1050, loss is 5.062047853469848 and perplexity is 157.91356927869367
At time: 856.0449497699738 and batch: 1100, loss is 5.05479549407959 and perplexity is 156.7724661681344
At time: 857.067218542099 and batch: 1150, loss is 5.064170179367065 and perplexity is 158.2490692304821
At time: 858.0904271602631 and batch: 1200, loss is 5.043334560394287 and perplexity is 154.98596437414963
At time: 859.1129550933838 and batch: 1250, loss is 5.067850084304809 and perplexity is 158.83248355800072
At time: 860.1369655132294 and batch: 1300, loss is 5.0684780025482175 and perplexity is 158.93224869096818
At time: 861.159636259079 and batch: 1350, loss is 5.063862924575806 and perplexity is 158.20045391477547
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.052687581380209 and perplexity of 156.44235154442208
Finished 29 epochs...
Completing Train Step...
At time: 864.2181286811829 and batch: 50, loss is 5.172639741897583 and perplexity is 176.37982069880584
At time: 865.2661871910095 and batch: 100, loss is 5.1701369476318355 and perplexity is 175.93893025414974
At time: 866.2899484634399 and batch: 150, loss is 5.136806497573852 and perplexity is 170.17145669385337
At time: 867.3130588531494 and batch: 200, loss is 5.131690511703491 and perplexity is 169.30308510826237
At time: 868.3362061977386 and batch: 250, loss is 5.148296546936035 and perplexity is 172.1380114010961
At time: 869.3594195842743 and batch: 300, loss is 5.151786479949951 and perplexity is 172.73981103943936
At time: 870.3821423053741 and batch: 350, loss is 5.153071908950806 and perplexity is 172.96199857470845
At time: 871.4054327011108 and batch: 400, loss is 5.180182161331177 and perplexity is 177.7151808789235
At time: 872.4279837608337 and batch: 450, loss is 5.142866201400757 and perplexity is 171.2057759904951
At time: 873.4512121677399 and batch: 500, loss is 5.188582305908203 and perplexity is 179.21430169250155
At time: 874.4737586975098 and batch: 550, loss is 5.156401872634888 and perplexity is 173.53891577224366
At time: 875.4965198040009 and batch: 600, loss is 5.107088603973389 and perplexity is 165.18872430967903
At time: 876.5190243721008 and batch: 650, loss is 5.116794147491455 and perplexity is 166.799776082294
At time: 877.5416030883789 and batch: 700, loss is 5.139377288818359 and perplexity is 170.60949479579722
At time: 878.5639572143555 and batch: 750, loss is 5.127251987457275 and perplexity is 168.5532944729444
At time: 879.5871384143829 and batch: 800, loss is 5.093710260391235 and perplexity is 162.9934898422792
At time: 880.6197044849396 and batch: 850, loss is 5.082705478668213 and perplexity is 161.20961564040135
At time: 881.6431057453156 and batch: 900, loss is 5.11245361328125 and perplexity is 166.07734495070565
At time: 882.6661496162415 and batch: 950, loss is 5.097041015625 and perplexity is 163.53728638549543
At time: 883.6912207603455 and batch: 1000, loss is 5.114509153366089 and perplexity is 166.4190746896994
At time: 884.7206947803497 and batch: 1050, loss is 5.062483348846436 and perplexity is 157.98235488483454
At time: 885.7441318035126 and batch: 1100, loss is 5.05527853012085 and perplexity is 156.84821121189105
At time: 886.805495262146 and batch: 1150, loss is 5.064591550827027 and perplexity is 158.31576492266507
At time: 887.8285121917725 and batch: 1200, loss is 5.043813190460205 and perplexity is 155.06016307194167
At time: 888.8524990081787 and batch: 1250, loss is 5.068135690689087 and perplexity is 158.87785360801513
At time: 889.8771650791168 and batch: 1300, loss is 5.06861198425293 and perplexity is 158.95354413114936
At time: 890.899894952774 and batch: 1350, loss is 5.063774089813233 and perplexity is 158.18640083922313
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.052625325520833 and perplexity of 156.43261239454674
Finished 30 epochs...
Completing Train Step...
At time: 893.9607481956482 and batch: 50, loss is 5.172036743164062 and perplexity is 176.2734959503719
At time: 895.0085139274597 and batch: 100, loss is 5.169501657485962 and perplexity is 175.82719348187695
At time: 896.0317153930664 and batch: 150, loss is 5.136194257736206 and perplexity is 170.06730283565915
At time: 897.0545840263367 and batch: 200, loss is 5.131104335784912 and perplexity is 169.2038727976053
At time: 898.0771856307983 and batch: 250, loss is 5.1477725315094 and perplexity is 172.04783205735876
At time: 899.1004528999329 and batch: 300, loss is 5.151252555847168 and perplexity is 172.64760570832993
At time: 900.1230511665344 and batch: 350, loss is 5.152581396102906 and perplexity is 172.8771792963826
At time: 901.1553642749786 and batch: 400, loss is 5.179723768234253 and perplexity is 177.6337361350703
At time: 902.1893849372864 and batch: 450, loss is 5.142479324340821 and perplexity is 171.13955321409827
At time: 903.2159056663513 and batch: 500, loss is 5.188188753128052 and perplexity is 179.1437852827023
At time: 904.2412872314453 and batch: 550, loss is 5.1561541175842285 and perplexity is 173.49592595506724
At time: 905.2647166252136 and batch: 600, loss is 5.106942739486694 and perplexity is 165.16463089842912
At time: 906.288458108902 and batch: 650, loss is 5.116625423431397 and perplexity is 166.77163532093505
At time: 907.3124747276306 and batch: 700, loss is 5.139245090484619 and perplexity is 170.58694199561907
At time: 908.3427886962891 and batch: 750, loss is 5.127133493423462 and perplexity is 168.5333230964376
At time: 909.3736197948456 and batch: 800, loss is 5.09370795249939 and perplexity is 162.99311367136715
At time: 910.4012687206268 and batch: 850, loss is 5.082647933959961 and perplexity is 161.2003391470109
At time: 911.4267184734344 and batch: 900, loss is 5.1124590969085695 and perplexity is 166.07825565946854
At time: 912.4763746261597 and batch: 950, loss is 5.097088985443115 and perplexity is 163.5451314275395
At time: 913.5006444454193 and batch: 1000, loss is 5.114738130569458 and perplexity is 166.45718522706485
At time: 914.524980545044 and batch: 1050, loss is 5.062875661849976 and perplexity is 158.0443455760678
At time: 915.550491809845 and batch: 1100, loss is 5.055707044601441 and perplexity is 156.91543734430704
At time: 916.5744791030884 and batch: 1150, loss is 5.064945211410523 and perplexity is 158.37176487036763
At time: 917.5982668399811 and batch: 1200, loss is 5.044234657287598 and perplexity is 155.1255295608624
At time: 918.6234002113342 and batch: 1250, loss is 5.068339033126831 and perplexity is 158.91016350294638
At time: 919.6470885276794 and batch: 1300, loss is 5.068686828613282 and perplexity is 158.96544135269994
At time: 920.671464920044 and batch: 1350, loss is 5.063636198043823 and perplexity is 158.16458974033486
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.052566731770833 and perplexity of 156.4234466896933
Finished 31 epochs...
Completing Train Step...
At time: 923.75363945961 and batch: 50, loss is 5.171409854888916 and perplexity is 176.1630267920694
At time: 924.7756083011627 and batch: 100, loss is 5.168899631500244 and perplexity is 175.7213727990015
At time: 925.798300743103 and batch: 150, loss is 5.135618124008179 and perplexity is 169.96934954626724
At time: 926.8216183185577 and batch: 200, loss is 5.130557756423951 and perplexity is 169.11141472307878
At time: 927.853588104248 and batch: 250, loss is 5.147287034988404 and perplexity is 171.96432370659716
At time: 928.8763892650604 and batch: 300, loss is 5.1507645606994625 and perplexity is 172.56337506822473
At time: 929.8999435901642 and batch: 350, loss is 5.152134141921997 and perplexity is 172.7998765434369
At time: 930.9425342082977 and batch: 400, loss is 5.179306497573853 and perplexity is 177.5596302508647
At time: 931.9753394126892 and batch: 450, loss is 5.142124090194702 and perplexity is 171.07876939792789
At time: 933.0076818466187 and batch: 500, loss is 5.187820043563843 and perplexity is 179.07774543121056
At time: 934.0322077274323 and batch: 550, loss is 5.155923013687134 and perplexity is 173.455835003215
At time: 935.0557985305786 and batch: 600, loss is 5.106811389923096 and perplexity is 165.14293802094497
At time: 936.0792651176453 and batch: 650, loss is 5.116472663879395 and perplexity is 166.74616130638591
At time: 937.101350069046 and batch: 700, loss is 5.13911958694458 and perplexity is 170.56553407392732
At time: 938.1517310142517 and batch: 750, loss is 5.1270186233520505 and perplexity is 168.5139647734456
At time: 939.1747169494629 and batch: 800, loss is 5.093705501556396 and perplexity is 162.99271418502678
At time: 940.1981525421143 and batch: 850, loss is 5.082593154907227 and perplexity is 161.19150898698817
At time: 941.2216782569885 and batch: 900, loss is 5.112457399368286 and perplexity is 166.07797373517866
At time: 942.2463188171387 and batch: 950, loss is 5.097129249572754 and perplexity is 163.55171656248464
At time: 943.2694997787476 and batch: 1000, loss is 5.1149460983276365 and perplexity is 166.4918065546443
At time: 944.2948970794678 and batch: 1050, loss is 5.0632351207733155 and perplexity is 158.10116623810367
At time: 945.3189373016357 and batch: 1100, loss is 5.056094913482666 and perplexity is 156.97631176432023
At time: 946.3418848514557 and batch: 1150, loss is 5.065277786254883 and perplexity is 158.42444409482727
At time: 947.3646669387817 and batch: 1200, loss is 5.044606561660767 and perplexity is 155.18323215295428
At time: 948.386643409729 and batch: 1250, loss is 5.068537721633911 and perplexity is 158.94174026295838
At time: 949.4086275100708 and batch: 1300, loss is 5.06875846862793 and perplexity is 158.9768300471853
At time: 950.4305527210236 and batch: 1350, loss is 5.063497734069824 and perplexity is 158.1426911588109
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.052514241536458 and perplexity of 156.41523620180192
Finished 32 epochs...
Completing Train Step...
At time: 953.531302690506 and batch: 50, loss is 5.170861463546753 and perplexity is 176.06644699754946
At time: 954.5537407398224 and batch: 100, loss is 5.168350496292114 and perplexity is 175.62490449587176
At time: 955.5761144161224 and batch: 150, loss is 5.13510757446289 and perplexity is 169.88259392055048
At time: 956.5986187458038 and batch: 200, loss is 5.1300641059875485 and perplexity is 169.02795340145397
At time: 957.6220004558563 and batch: 250, loss is 5.1468523979187015 and perplexity is 171.8895978773321
At time: 958.6451370716095 and batch: 300, loss is 5.150331621170044 and perplexity is 172.48868173184343
At time: 959.6683242321014 and batch: 350, loss is 5.151723899841309 and perplexity is 172.7290013015384
At time: 960.6911640167236 and batch: 400, loss is 5.178923854827881 and perplexity is 177.49170134345238
At time: 961.7139620780945 and batch: 450, loss is 5.141798267364502 and perplexity is 171.02303710901452
At time: 962.7367599010468 and batch: 500, loss is 5.187476663589478 and perplexity is 179.01626427587794
At time: 963.7664201259613 and batch: 550, loss is 5.155709638595581 and perplexity is 173.41882779688922
At time: 964.8142068386078 and batch: 600, loss is 5.106694974899292 and perplexity is 165.12371402088712
At time: 965.8369297981262 and batch: 650, loss is 5.1163373374938965 and perplexity is 166.72359767784215
At time: 966.8592274188995 and batch: 700, loss is 5.139002742767334 and perplexity is 170.54560564871488
At time: 967.8815357685089 and batch: 750, loss is 5.126910047531128 and perplexity is 168.4956692246285
At time: 968.904388666153 and batch: 800, loss is 5.0937043476104735 and perplexity is 162.99252610035734
At time: 969.9270997047424 and batch: 850, loss is 5.082539892196655 and perplexity is 161.1829237189377
At time: 970.9493415355682 and batch: 900, loss is 5.112446851730347 and perplexity is 166.07622201408032
At time: 971.9715991020203 and batch: 950, loss is 5.097158460617066 and perplexity is 163.55649414870317
At time: 972.9943015575409 and batch: 1000, loss is 5.115131158828735 and perplexity is 166.52262046292483
At time: 974.0172460079193 and batch: 1050, loss is 5.063565359115601 and perplexity is 158.15338592715273
At time: 975.0395743846893 and batch: 1100, loss is 5.056448907852173 and perplexity is 157.0318903315002
At time: 976.0619473457336 and batch: 1150, loss is 5.065592021942138 and perplexity is 158.47423453145186
At time: 977.0847635269165 and batch: 1200, loss is 5.044935874938965 and perplexity is 155.2343444673759
At time: 978.107339143753 and batch: 1250, loss is 5.06872932434082 and perplexity is 158.97219684832257
At time: 979.1298630237579 and batch: 1300, loss is 5.0688276290893555 and perplexity is 158.98782533832264
At time: 980.1566228866577 and batch: 1350, loss is 5.063370409011841 and perplexity is 158.12255691331364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.052466634114583 and perplexity of 156.40778985291652
Finished 33 epochs...
Completing Train Step...
At time: 983.216470003128 and batch: 50, loss is 5.170376529693604 and perplexity is 175.98108711561756
At time: 984.2639272212982 and batch: 100, loss is 5.16784026145935 and perplexity is 175.53531740926675
At time: 985.2859406471252 and batch: 150, loss is 5.134638271331787 and perplexity is 169.8028861923098
At time: 986.3084833621979 and batch: 200, loss is 5.129606676101685 and perplexity is 168.9506526452077
At time: 987.3310828208923 and batch: 250, loss is 5.146450176239013 and perplexity is 171.82047405703443
At time: 988.3537089824677 and batch: 300, loss is 5.14993145942688 and perplexity is 172.4196721687
At time: 989.3761520385742 and batch: 350, loss is 5.151343326568604 and perplexity is 172.66327776732558
At time: 990.423731803894 and batch: 400, loss is 5.178567991256714 and perplexity is 177.4285497501021
At time: 991.4461805820465 and batch: 450, loss is 5.141494703292847 and perplexity is 170.97112853871002
At time: 992.4680547714233 and batch: 500, loss is 5.187153263092041 and perplexity is 178.9583796874187
At time: 993.4899308681488 and batch: 550, loss is 5.1555101108551025 and perplexity is 173.3842293818091
At time: 994.5117053985596 and batch: 600, loss is 5.1065875434875485 and perplexity is 165.10597550003175
At time: 995.5404171943665 and batch: 650, loss is 5.116213235855103 and perplexity is 166.70290828996477
At time: 996.5620300769806 and batch: 700, loss is 5.138890523910522 and perplexity is 170.526468289621
At time: 997.5840077400208 and batch: 750, loss is 5.126804208755493 and perplexity is 168.47783679299596
At time: 998.6056926250458 and batch: 800, loss is 5.093701753616333 and perplexity is 162.99210329924807
At time: 999.6277797222137 and batch: 850, loss is 5.082487363815307 and perplexity is 161.17445726322043
At time: 1000.6499519348145 and batch: 900, loss is 5.112429656982422 and perplexity is 166.0733663998573
At time: 1001.6723449230194 and batch: 950, loss is 5.097180366516113 and perplexity is 163.56007703999566
At time: 1002.694678068161 and batch: 1000, loss is 5.115296459197998 and perplexity is 166.55014898875302
At time: 1003.7173075675964 and batch: 1050, loss is 5.0638704681396485 and perplexity is 158.2016473145008
At time: 1004.7401258945465 and batch: 1100, loss is 5.056773586273193 and perplexity is 157.0828834754417
At time: 1005.7672181129456 and batch: 1150, loss is 5.0658786010742185 and perplexity is 158.51965644821684
At time: 1006.793655872345 and batch: 1200, loss is 5.045234050750732 and perplexity is 155.28063849558842
At time: 1007.8158767223358 and batch: 1250, loss is 5.068899726867675 and perplexity is 158.99928842053586
At time: 1008.8389053344727 and batch: 1300, loss is 5.068884439468384 and perplexity is 158.99685775350608
At time: 1009.8613157272339 and batch: 1350, loss is 5.0632509422302245 and perplexity is 158.10366764868053
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.052425944010417 and perplexity of 156.40142573313426
Finished 34 epochs...
Completing Train Step...
At time: 1012.9308669567108 and batch: 50, loss is 5.169927816390992 and perplexity is 175.90213977450637
At time: 1013.9782423973083 and batch: 100, loss is 5.167360801696777 and perplexity is 175.45117546060973
At time: 1015.0008487701416 and batch: 150, loss is 5.1341980361938475 and perplexity is 169.72814944736206
At time: 1016.0492920875549 and batch: 200, loss is 5.129175243377685 and perplexity is 168.87777752640136
At time: 1017.071891784668 and batch: 250, loss is 5.146072616577149 and perplexity is 171.75561382202272
At time: 1018.0948133468628 and batch: 300, loss is 5.149555568695068 and perplexity is 172.35487339134264
At time: 1019.1178045272827 and batch: 350, loss is 5.1509865951538085 and perplexity is 172.60169433698962
At time: 1020.1411814689636 and batch: 400, loss is 5.17823392868042 and perplexity is 177.36928741088047
At time: 1021.1762118339539 and batch: 450, loss is 5.141209325790405 and perplexity is 170.92234418636744
At time: 1022.2026917934418 and batch: 500, loss is 5.1868462562561035 and perplexity is 178.9034466743431
At time: 1023.2285270690918 and batch: 550, loss is 5.1553221035003665 and perplexity is 173.3516349355839
At time: 1024.2604637145996 and batch: 600, loss is 5.106486349105835 and perplexity is 165.08926854826294
At time: 1025.284797668457 and batch: 650, loss is 5.1160977172851565 and perplexity is 166.68365212063722
At time: 1026.3095026016235 and batch: 700, loss is 5.138781652450562 and perplexity is 170.50790383464445
At time: 1027.3331933021545 and batch: 750, loss is 5.126699466705322 and perplexity is 168.4601910031061
At time: 1028.356609582901 and batch: 800, loss is 5.0936970520019536 and perplexity is 162.9913369750329
At time: 1029.382342338562 and batch: 850, loss is 5.0824338245391845 and perplexity is 161.16582833044455
At time: 1030.4059126377106 and batch: 900, loss is 5.112405023574829 and perplexity is 166.0692754973191
At time: 1031.4296832084656 and batch: 950, loss is 5.097193126678467 and perplexity is 163.56216410644885
At time: 1032.4545257091522 and batch: 1000, loss is 5.115444774627686 and perplexity is 166.5748527775961
At time: 1033.4781894683838 and batch: 1050, loss is 5.064152326583862 and perplexity is 158.24624406937562
At time: 1034.5013642311096 and batch: 1100, loss is 5.057071695327759 and perplexity is 157.12971828591662
At time: 1035.5265872478485 and batch: 1150, loss is 5.066140079498291 and perplexity is 158.56111133771287
At time: 1036.5507147312164 and batch: 1200, loss is 5.045506525039673 and perplexity is 155.32295424186336
At time: 1037.5747089385986 and batch: 1250, loss is 5.0690501689910885 and perplexity is 159.0232104104994
At time: 1038.5998723506927 and batch: 1300, loss is 5.068929042816162 and perplexity is 159.00394970380924
At time: 1039.6238913536072 and batch: 1350, loss is 5.06313497543335 and perplexity is 158.08533393584068
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0523893229166665 and perplexity of 156.39569824673384
Finished 35 epochs...
Completing Train Step...
At time: 1042.7026431560516 and batch: 50, loss is 5.1695037460327145 and perplexity is 175.82756070557437
At time: 1043.7253243923187 and batch: 100, loss is 5.166907138824463 and perplexity is 175.37159782847286
At time: 1044.748643875122 and batch: 150, loss is 5.133781986236572 and perplexity is 169.65754874576393
At time: 1045.7714757919312 and batch: 200, loss is 5.128765964508057 and perplexity is 168.8086735628707
At time: 1046.794278383255 and batch: 250, loss is 5.145715713500977 and perplexity is 171.69432465289688
At time: 1047.817054271698 and batch: 300, loss is 5.149199953079224 and perplexity is 172.29359220381724
At time: 1048.8409078121185 and batch: 350, loss is 5.150650577545166 and perplexity is 172.54370687136125
At time: 1049.864043712616 and batch: 400, loss is 5.177917623519898 and perplexity is 177.31319346182468
At time: 1050.8871450424194 and batch: 450, loss is 5.140938863754273 and perplexity is 170.87612243203492
At time: 1051.9104413986206 and batch: 500, loss is 5.186552391052246 and perplexity is 178.8508809005196
At time: 1052.9341168403625 and batch: 550, loss is 5.155143213272095 and perplexity is 173.3206267956483
At time: 1053.9566559791565 and batch: 600, loss is 5.106389284133911 and perplexity is 165.0732449407244
At time: 1054.979987859726 and batch: 650, loss is 5.1159890937805175 and perplexity is 166.66554734149793
At time: 1056.00226521492 and batch: 700, loss is 5.138674612045288 and perplexity is 170.48965357629058
At time: 1057.0255944728851 and batch: 750, loss is 5.126594963073731 and perplexity is 168.44258722121336
At time: 1058.0519034862518 and batch: 800, loss is 5.093690004348755 and perplexity is 162.99018827266335
At time: 1059.0759375095367 and batch: 850, loss is 5.082379407882691 and perplexity is 161.15705846354135
At time: 1060.0999937057495 and batch: 900, loss is 5.112374420166016 and perplexity is 166.06419328915655
At time: 1061.1241610050201 and batch: 950, loss is 5.097199468612671 and perplexity is 163.5632014102212
At time: 1062.1494166851044 and batch: 1000, loss is 5.115578508377075 and perplexity is 166.59713094685037
At time: 1063.1734137535095 and batch: 1050, loss is 5.064414043426513 and perplexity is 158.28766519680178
At time: 1064.2002041339874 and batch: 1100, loss is 5.057346315383911 and perplexity is 157.17287518357912
At time: 1065.2244045734406 and batch: 1150, loss is 5.066379880905151 and perplexity is 158.59913907465506
At time: 1066.2538647651672 and batch: 1200, loss is 5.045756874084472 and perplexity is 155.3618440629049
At time: 1067.2777926921844 and batch: 1250, loss is 5.0691831684112545 and perplexity is 159.0443618118078
At time: 1068.3048901557922 and batch: 1300, loss is 5.068962917327881 and perplexity is 159.00933597619505
At time: 1069.3389732837677 and batch: 1350, loss is 5.063020057678223 and perplexity is 158.0671681679509
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.052353108723958 and perplexity of 156.39003460533146
Finished 36 epochs...
Completing Train Step...
At time: 1072.4525516033173 and batch: 50, loss is 5.169098424911499 and perplexity is 175.7563085225114
At time: 1073.4779815673828 and batch: 100, loss is 5.166475286483765 and perplexity is 175.29587954419455
At time: 1074.501959323883 and batch: 150, loss is 5.133386659622192 and perplexity is 169.59049185697396
At time: 1075.5273587703705 and batch: 200, loss is 5.128374938964844 and perplexity is 168.7426779634151
At time: 1076.5512721538544 and batch: 250, loss is 5.145375862121582 and perplexity is 171.63598401396416
At time: 1077.5752086639404 and batch: 300, loss is 5.1488619136810305 and perplexity is 172.23536002453602
At time: 1078.5996894836426 and batch: 350, loss is 5.1503322887420655 and perplexity is 172.48879688049982
At time: 1079.6264667510986 and batch: 400, loss is 5.177616710662842 and perplexity is 177.25984566910728
At time: 1080.6501634120941 and batch: 450, loss is 5.140680923461914 and perplexity is 170.83205227903602
At time: 1081.674996137619 and batch: 500, loss is 5.18627028465271 and perplexity is 178.80043303862172
At time: 1082.698646068573 and batch: 550, loss is 5.154972009658813 and perplexity is 173.29095621801218
At time: 1083.7271485328674 and batch: 600, loss is 5.106295366287231 and perplexity is 165.0577423450117
At time: 1084.7683069705963 and batch: 650, loss is 5.115886116027832 and perplexity is 166.64838538164787
At time: 1085.7923192977905 and batch: 700, loss is 5.1385690879821775 and perplexity is 170.47166376452256
At time: 1086.8174741268158 and batch: 750, loss is 5.126490497589112 and perplexity is 168.42499170378693
At time: 1087.841216802597 and batch: 800, loss is 5.0936806201934814 and perplexity is 162.98865875460518
At time: 1088.8647668361664 and batch: 850, loss is 5.082323713302612 and perplexity is 161.14808313878433
At time: 1089.8904378414154 and batch: 900, loss is 5.112338323593139 and perplexity is 166.05819904908773
At time: 1090.9143950939178 and batch: 950, loss is 5.0971989345550535 and perplexity is 163.56311405807082
At time: 1091.9387466907501 and batch: 1000, loss is 5.115699386596679 and perplexity is 166.61727012860013
At time: 1092.963574886322 and batch: 1050, loss is 5.064657306671142 and perplexity is 158.32617545169717
At time: 1094.013251543045 and batch: 1100, loss is 5.057600002288819 and perplexity is 157.21275294183857
At time: 1095.0389907360077 and batch: 1150, loss is 5.066600351333618 and perplexity is 158.6341093496155
At time: 1096.062663078308 and batch: 1200, loss is 5.045987691879272 and perplexity is 155.3977084800612
At time: 1097.0870506763458 and batch: 1250, loss is 5.069300928115845 and perplexity is 159.06309193167655
At time: 1098.1121027469635 and batch: 1300, loss is 5.0689873790740965 and perplexity is 159.0132256697917
At time: 1099.1359872817993 and batch: 1350, loss is 5.0629048252105715 and perplexity is 158.0489547475171
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0523193359375 and perplexity of 156.38475296727688
Finished 37 epochs...
Completing Train Step...
At time: 1102.2054455280304 and batch: 50, loss is 5.1687085151672365 and perplexity is 175.68779278354808
At time: 1103.2557682991028 and batch: 100, loss is 5.166062250137329 and perplexity is 175.2234909251568
At time: 1104.2806787490845 and batch: 150, loss is 5.133009595870972 and perplexity is 169.52655748436771
At time: 1105.3040900230408 and batch: 200, loss is 5.128000383377075 and perplexity is 168.67948628562567
At time: 1106.3289847373962 and batch: 250, loss is 5.145051126480102 and perplexity is 171.58025674139998
At time: 1107.3527164459229 and batch: 300, loss is 5.14853910446167 and perplexity is 172.17976983541573
At time: 1108.3769397735596 and batch: 350, loss is 5.150029077529907 and perplexity is 172.43650427156723
At time: 1109.4005177021027 and batch: 400, loss is 5.177328996658325 and perplexity is 177.20885286509346
At time: 1110.4249122142792 and batch: 450, loss is 5.1404336738586425 and perplexity is 170.78981934313748
At time: 1111.4485039710999 and batch: 500, loss is 5.185998363494873 and perplexity is 178.7518200276008
At time: 1112.4719367027283 and batch: 550, loss is 5.154807109832763 and perplexity is 173.26238292540603
At time: 1113.4975695610046 and batch: 600, loss is 5.106203937530518 and perplexity is 165.04265201069896
At time: 1114.5215017795563 and batch: 650, loss is 5.115787572860718 and perplexity is 166.63196413107218
At time: 1115.5446128845215 and batch: 700, loss is 5.138464698791504 and perplexity is 170.45386929430072
At time: 1116.5698442459106 and batch: 750, loss is 5.126385793685913 and perplexity is 168.40735787294096
At time: 1117.5937266349792 and batch: 800, loss is 5.093669023513794 and perplexity is 162.98676863829647
At time: 1118.6179320812225 and batch: 850, loss is 5.082267017364502 and perplexity is 161.13894695603074
At time: 1119.6669881343842 and batch: 900, loss is 5.112297191619873 and perplexity is 166.05136888815372
At time: 1120.693091392517 and batch: 950, loss is 5.0971925258636475 and perplexity is 163.5620658359063
At time: 1121.7167036533356 and batch: 1000, loss is 5.115808753967285 and perplexity is 166.63549361784104
At time: 1122.742305278778 and batch: 1050, loss is 5.064883918762207 and perplexity is 158.3620581429588
At time: 1123.7661428451538 and batch: 1100, loss is 5.05783486366272 and perplexity is 157.24968048124583
At time: 1124.789689540863 and batch: 1150, loss is 5.066803941726684 and perplexity is 158.6664090181312
At time: 1125.8150346279144 and batch: 1200, loss is 5.046201210021973 and perplexity is 155.43089225269847
At time: 1126.83984208107 and batch: 1250, loss is 5.0694056224823 and perplexity is 159.07974581308133
At time: 1127.8637533187866 and batch: 1300, loss is 5.0690039539337155 and perplexity is 159.0158613135274
At time: 1128.8897037506104 and batch: 1350, loss is 5.062789087295532 and perplexity is 158.03066354953344
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0522843424479165 and perplexity of 156.37928061480184
Finished 38 epochs...
Completing Train Step...
At time: 1131.9751114845276 and batch: 50, loss is 5.168331604003907 and perplexity is 175.62158657090126
At time: 1133.0250244140625 and batch: 100, loss is 5.165665836334228 and perplexity is 175.1540436805592
At time: 1134.0499196052551 and batch: 150, loss is 5.1326486682891845 and perplexity is 169.46538171460162
At time: 1135.0732431411743 and batch: 200, loss is 5.127640037536621 and perplexity is 168.61871428449928
At time: 1136.0965974330902 and batch: 250, loss is 5.144739999771118 and perplexity is 171.52688184440188
At time: 1137.1223974227905 and batch: 300, loss is 5.148230018615723 and perplexity is 172.12655972927016
At time: 1138.146180152893 and batch: 350, loss is 5.14973967552185 and perplexity is 172.38660802135453
At time: 1139.169310092926 and batch: 400, loss is 5.177052974700928 and perplexity is 177.15994608064122
At time: 1140.1943745613098 and batch: 450, loss is 5.140196037292481 and perplexity is 170.7492382588991
At time: 1141.2175598144531 and batch: 500, loss is 5.185735445022583 and perplexity is 178.7048290498289
At time: 1142.2410292625427 and batch: 550, loss is 5.15464768409729 and perplexity is 173.23476264432855
At time: 1143.2719638347626 and batch: 600, loss is 5.106115064620972 and perplexity is 165.0279848417822
At time: 1144.295354604721 and batch: 650, loss is 5.115692882537842 and perplexity is 166.6161864435961
At time: 1145.3198606967926 and batch: 700, loss is 5.138361196517945 and perplexity is 170.43622784427268
At time: 1146.36887216568 and batch: 750, loss is 5.126280908584595 and perplexity is 168.3896953764302
At time: 1147.3924431800842 and batch: 800, loss is 5.09365535736084 and perplexity is 162.98454125140668
At time: 1148.4181418418884 and batch: 850, loss is 5.082209024429321 and perplexity is 161.12960230648932
At time: 1149.4411361217499 and batch: 900, loss is 5.112251434326172 and perplexity is 166.0437710007288
At time: 1150.4690608978271 and batch: 950, loss is 5.0971807193756105 and perplexity is 163.56013475373237
At time: 1151.4989504814148 and batch: 1000, loss is 5.115908002853393 and perplexity is 166.65203282570403
At time: 1152.5220470428467 and batch: 1050, loss is 5.065095233917236 and perplexity is 158.3955259818323
At time: 1153.5448241233826 and batch: 1100, loss is 5.058052606582642 and perplexity is 157.2839242138605
At time: 1154.5695123672485 and batch: 1150, loss is 5.066992292404175 and perplexity is 158.6962967583644
At time: 1155.5927503108978 and batch: 1200, loss is 5.046399135589599 and perplexity is 155.4616590449412
At time: 1156.625329732895 and batch: 1250, loss is 5.06949891090393 and perplexity is 159.0945868037171
At time: 1157.6487436294556 and batch: 1300, loss is 5.0690137481689455 and perplexity is 159.01741875990538
At time: 1158.672334909439 and batch: 1350, loss is 5.062672815322876 and perplexity is 158.0122900807228
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.052254638671875 and perplexity of 156.3746356286601
Finished 39 epochs...
Completing Train Step...
At time: 1161.7640042304993 and batch: 50, loss is 5.167966022491455 and perplexity is 175.55739430013213
At time: 1162.7874715328217 and batch: 100, loss is 5.165284175872802 and perplexity is 175.087207062686
At time: 1163.8107287883759 and batch: 150, loss is 5.13230224609375 and perplexity is 169.40668531247314
At time: 1164.8344457149506 and batch: 200, loss is 5.127292623519898 and perplexity is 168.56014395434084
At time: 1165.8599634170532 and batch: 250, loss is 5.144440402984619 and perplexity is 171.47550063900954
At time: 1166.8823778629303 and batch: 300, loss is 5.147933006286621 and perplexity is 172.0754436102992
At time: 1167.907202243805 and batch: 350, loss is 5.149462289810181 and perplexity is 172.3387970707501
At time: 1168.930242061615 and batch: 400, loss is 5.1767871379852295 and perplexity is 177.11285672173943
At time: 1169.9538094997406 and batch: 450, loss is 5.139966630935669 and perplexity is 170.71007179091197
At time: 1170.9785673618317 and batch: 500, loss is 5.185481014251709 and perplexity is 178.65936682615438
At time: 1172.0274376869202 and batch: 550, loss is 5.154492750167846 and perplexity is 173.2079247809374
At time: 1173.0502309799194 and batch: 600, loss is 5.106028089523315 and perplexity is 165.01363214085737
At time: 1174.0745339393616 and batch: 650, loss is 5.115600957870483 and perplexity is 166.6008710100245
At time: 1175.096794128418 and batch: 700, loss is 5.138258361816407 and perplexity is 170.41870198679962
At time: 1176.1199645996094 and batch: 750, loss is 5.1261758136749265 and perplexity is 168.37199940650004
At time: 1177.1436388492584 and batch: 800, loss is 5.0936394309997555 and perplexity is 162.9819455214219
At time: 1178.1688282489777 and batch: 850, loss is 5.082150287628174 and perplexity is 161.12013834702378
At time: 1179.191873550415 and batch: 900, loss is 5.112201786041259 and perplexity is 166.0355274169198
At time: 1180.2149538993835 and batch: 950, loss is 5.097164287567138 and perplexity is 163.5574471870053
At time: 1181.2400088310242 and batch: 1000, loss is 5.1159976291656495 and perplexity is 166.66696990220376
At time: 1182.2627160549164 and batch: 1050, loss is 5.06529275894165 and perplexity is 158.42681615216304
At time: 1183.2868750095367 and batch: 1100, loss is 5.058254957199097 and perplexity is 157.31575393315666
At time: 1184.311022758484 and batch: 1150, loss is 5.067166976928711 and perplexity is 158.7240209669339
At time: 1185.3343346118927 and batch: 1200, loss is 5.046583061218262 and perplexity is 155.49025505800316
At time: 1186.3584020137787 and batch: 1250, loss is 5.069581813812256 and perplexity is 159.1077767543971
At time: 1187.383684873581 and batch: 1300, loss is 5.0690176391601565 and perplexity is 159.01803749648792
At time: 1188.407802581787 and batch: 1350, loss is 5.0625558185577395 and perplexity is 157.9938042353447
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.052222900390625 and perplexity of 156.3696726452528
Finished 40 epochs...
Completing Train Step...
At time: 1191.5486209392548 and batch: 50, loss is 5.167610702514648 and perplexity is 175.49502633180987
At time: 1192.5717425346375 and batch: 100, loss is 5.164915828704834 and perplexity is 175.022726062243
At time: 1193.5950560569763 and batch: 150, loss is 5.131968479156495 and perplexity is 169.35015239689966
At time: 1194.6198146343231 and batch: 200, loss is 5.126956872940063 and perplexity is 168.50355928797003
At time: 1195.6431200504303 and batch: 250, loss is 5.144151515960694 and perplexity is 171.42597074656982
At time: 1196.666493654251 and batch: 300, loss is 5.147646551132202 and perplexity is 172.02615877181313
At time: 1197.716501235962 and batch: 350, loss is 5.149195518493652 and perplexity is 172.29282815483327
At time: 1198.7398924827576 and batch: 400, loss is 5.1765303134918215 and perplexity is 177.06737564261337
At time: 1199.7630593776703 and batch: 450, loss is 5.139744615554809 and perplexity is 170.67217573621582
At time: 1200.7880969047546 and batch: 500, loss is 5.185233879089355 and perplexity is 178.61521926995917
At time: 1201.8120317459106 and batch: 550, loss is 5.15434196472168 and perplexity is 173.18180951567018
At time: 1202.8353900909424 and batch: 600, loss is 5.105943222045898 and perplexity is 164.9996284443957
At time: 1203.8624711036682 and batch: 650, loss is 5.115511302947998 and perplexity is 166.58593509139746
At time: 1204.9027581214905 and batch: 700, loss is 5.13815598487854 and perplexity is 170.40125593498692
At time: 1205.9330852031708 and batch: 750, loss is 5.126070575714111 and perplexity is 168.35428121295377
At time: 1206.971314907074 and batch: 800, loss is 5.0936217212677 and perplexity is 162.97905918039513
At time: 1207.9958055019379 and batch: 850, loss is 5.082090520858765 and perplexity is 161.11050900462823
At time: 1209.0196850299835 and batch: 900, loss is 5.112148342132568 and perplexity is 166.02665406646835
At time: 1210.0429334640503 and batch: 950, loss is 5.097143936157226 and perplexity is 163.5541185962243
At time: 1211.0669198036194 and batch: 1000, loss is 5.116079149246215 and perplexity is 166.68055716082756
At time: 1212.091923236847 and batch: 1050, loss is 5.065476999282837 and perplexity is 158.45600745184902
At time: 1213.115531206131 and batch: 1100, loss is 5.058443279266357 and perplexity is 157.34538275094255
At time: 1214.1388492584229 and batch: 1150, loss is 5.0673291206359865 and perplexity is 158.7497591547134
At time: 1215.1643335819244 and batch: 1200, loss is 5.046754846572876 and perplexity is 155.51696830101363
At time: 1216.1876504421234 and batch: 1250, loss is 5.069655570983887 and perplexity is 159.11951252678833
At time: 1217.211342573166 and batch: 1300, loss is 5.0690163803100585 and perplexity is 159.01783731674186
At time: 1218.2353692054749 and batch: 1350, loss is 5.062438201904297 and perplexity is 157.97522262560068
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0521927897135415 and perplexity of 156.36496431941995
Finished 41 epochs...
Completing Train Step...
At time: 1221.3182933330536 and batch: 50, loss is 5.167264623641968 and perplexity is 175.43430171929475
At time: 1222.3688774108887 and batch: 100, loss is 5.164559297561645 and perplexity is 174.9603361322734
At time: 1223.392724275589 and batch: 150, loss is 5.131646299362183 and perplexity is 169.2955999879476
At time: 1224.446760892868 and batch: 200, loss is 5.126631383895874 and perplexity is 168.44872215044276
At time: 1225.4700384140015 and batch: 250, loss is 5.143872022628784 and perplexity is 171.37806502580668
At time: 1226.4951677322388 and batch: 300, loss is 5.147369899749756 and perplexity is 171.97857407966092
At time: 1227.5192461013794 and batch: 350, loss is 5.14893856048584 and perplexity is 172.24856182048842
At time: 1228.5431306362152 and batch: 400, loss is 5.176281595230103 and perplexity is 177.02334122904486
At time: 1229.5675992965698 and batch: 450, loss is 5.139529457092285 and perplexity is 170.635458123483
At time: 1230.5914306640625 and batch: 500, loss is 5.184993772506714 and perplexity is 178.57233772832876
At time: 1231.614266872406 and batch: 550, loss is 5.154194526672363 and perplexity is 173.15627780971673
At time: 1232.639170408249 and batch: 600, loss is 5.105860176086426 and perplexity is 164.98592646089412
At time: 1233.6623573303223 and batch: 650, loss is 5.115423374176025 and perplexity is 166.57128803865504
At time: 1234.68545794487 and batch: 700, loss is 5.138053274154663 and perplexity is 170.38375479743289
At time: 1235.709621667862 and batch: 750, loss is 5.125964736938476 and perplexity is 168.33646374486338
At time: 1236.7336971759796 and batch: 800, loss is 5.093602209091187 and perplexity is 162.97587913524927
At time: 1237.7585537433624 and batch: 850, loss is 5.082030019760132 and perplexity is 161.10076193668922
At time: 1238.7819168567657 and batch: 900, loss is 5.1120912551879885 and perplexity is 166.0171763825975
At time: 1239.8056128025055 and batch: 950, loss is 5.097119474411011 and perplexity is 163.55011782581585
At time: 1240.8298695087433 and batch: 1000, loss is 5.116152677536011 and perplexity is 166.69281334772046
At time: 1241.8536183834076 and batch: 1050, loss is 5.06564881324768 and perplexity is 158.4832347456902
At time: 1242.8779809474945 and batch: 1100, loss is 5.05861873626709 and perplexity is 157.37299252197215
At time: 1243.90194773674 and batch: 1150, loss is 5.067480297088623 and perplexity is 158.77376019430957
At time: 1244.9252111911774 and batch: 1200, loss is 5.046915111541748 and perplexity is 155.54189422041992
At time: 1245.9497756958008 and batch: 1250, loss is 5.0697214221954345 and perplexity is 159.12999108447818
At time: 1246.9741299152374 and batch: 1300, loss is 5.069010944366455 and perplexity is 159.01697290709566
At time: 1247.9971542358398 and batch: 1350, loss is 5.062320051193237 and perplexity is 157.95655884330887
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.052163492838542 and perplexity of 156.36038338170985
Finished 42 epochs...
Completing Train Step...
At time: 1251.0856158733368 and batch: 50, loss is 5.166927518844605 and perplexity is 175.375171941589
At time: 1252.1353754997253 and batch: 100, loss is 5.164213705062866 and perplexity is 174.89988159944042
At time: 1253.158989906311 and batch: 150, loss is 5.131334314346313 and perplexity is 169.24279053580594
At time: 1254.1819431781769 and batch: 200, loss is 5.126315565109253 and perplexity is 168.39553127918563
At time: 1255.2067165374756 and batch: 250, loss is 5.143601312637329 and perplexity is 171.3316775503477
At time: 1256.230141401291 and batch: 300, loss is 5.147101802825928 and perplexity is 171.93247333299612
At time: 1257.254238128662 and batch: 350, loss is 5.14868992805481 and perplexity is 172.2057405654185
At time: 1258.2792196273804 and batch: 400, loss is 5.176040229797363 and perplexity is 176.98061906971768
At time: 1259.302169084549 and batch: 450, loss is 5.139320039749146 and perplexity is 170.59972784059843
At time: 1260.3266384601593 and batch: 500, loss is 5.1847594165802 and perplexity is 178.53049314612514
At time: 1261.34969997406 and batch: 550, loss is 5.154049463272095 and perplexity is 173.13116099308937
At time: 1262.37273645401 and batch: 600, loss is 5.105778160095215 and perplexity is 164.97239553148344
At time: 1263.4026112556458 and batch: 650, loss is 5.115335988998413 and perplexity is 166.55673281302944
At time: 1264.4284934997559 and batch: 700, loss is 5.137951164245606 and perplexity is 170.36635781594296
At time: 1265.451958656311 and batch: 750, loss is 5.125857906341553 and perplexity is 168.31848122051656
At time: 1266.4771130084991 and batch: 800, loss is 5.093580665588379 and perplexity is 162.9723681017597
At time: 1267.5009803771973 and batch: 850, loss is 5.0819688892364505 and perplexity is 161.09091406375248
At time: 1268.5248811244965 and batch: 900, loss is 5.112030534744263 and perplexity is 166.00709605202567
At time: 1269.5494713783264 and batch: 950, loss is 5.097092256546021 and perplexity is 163.54566640136912
At time: 1270.572865486145 and batch: 1000, loss is 5.116219596862793 and perplexity is 166.703968691819
At time: 1271.5954327583313 and batch: 1050, loss is 5.065808506011963 and perplexity is 158.50854539244892
At time: 1272.6175088882446 and batch: 1100, loss is 5.05878246307373 and perplexity is 157.3987608089113
At time: 1273.6403186321259 and batch: 1150, loss is 5.067621412277222 and perplexity is 158.7961671643687
At time: 1274.6625967025757 and batch: 1200, loss is 5.0470654392242436 and perplexity is 155.56527823049709
At time: 1275.7109160423279 and batch: 1250, loss is 5.069779758453369 and perplexity is 159.1392744034576
At time: 1276.7336540222168 and batch: 1300, loss is 5.069001274108887 and perplexity is 159.01543517944506
At time: 1277.7566068172455 and batch: 1350, loss is 5.062200994491577 and perplexity is 157.93775417584047
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.052134195963542 and perplexity of 156.35580257820493
Finished 43 epochs...
Completing Train Step...
At time: 1280.8455214500427 and batch: 50, loss is 5.16659875869751 and perplexity is 175.317525050784
At time: 1281.8684825897217 and batch: 100, loss is 5.163877649307251 and perplexity is 174.84111536249168
At time: 1282.8919887542725 and batch: 150, loss is 5.131031703948975 and perplexity is 169.19158365597312
At time: 1283.915028810501 and batch: 200, loss is 5.12600811958313 and perplexity is 168.3437667842637
At time: 1284.9386475086212 and batch: 250, loss is 5.143338203430176 and perplexity is 171.2866045383295
At time: 1285.9624421596527 and batch: 300, loss is 5.146841506958008 and perplexity is 171.88772584467216
At time: 1286.9869620800018 and batch: 350, loss is 5.148448886871338 and perplexity is 172.1642368921602
At time: 1288.0116398334503 and batch: 400, loss is 5.175805368423462 and perplexity is 176.93905803910053
At time: 1289.035238981247 and batch: 450, loss is 5.139116458892822 and perplexity is 170.56500053694307
At time: 1290.0601229667664 and batch: 500, loss is 5.184531011581421 and perplexity is 178.48972054556617
At time: 1291.0833914279938 and batch: 550, loss is 5.153906841278076 and perplexity is 173.1064704424313
At time: 1292.1066355705261 and batch: 600, loss is 5.105697164535522 and perplexity is 164.95903404109148
At time: 1293.1309695243835 and batch: 650, loss is 5.115248441696167 and perplexity is 166.54215185867167
At time: 1294.1582896709442 and batch: 700, loss is 5.137850999832153 and perplexity is 170.34929402424692
At time: 1295.1893451213837 and batch: 750, loss is 5.1257499408721925 and perplexity is 168.30030961766002
At time: 1296.213359117508 and batch: 800, loss is 5.0935571670532225 and perplexity is 162.96853853483304
At time: 1297.2392168045044 and batch: 850, loss is 5.081907596588135 and perplexity is 161.08104067759595
At time: 1298.2637028694153 and batch: 900, loss is 5.111965827941894 and perplexity is 165.99635461119553
At time: 1299.2876524925232 and batch: 950, loss is 5.097062473297119 and perplexity is 163.5407955526151
At time: 1300.3221929073334 and batch: 1000, loss is 5.116279907226563 and perplexity is 166.71402297199828
At time: 1301.3460676670074 and batch: 1050, loss is 5.0659565734863286 and perplexity is 158.53201709008522
At time: 1302.4147353172302 and batch: 1100, loss is 5.058935203552246 and perplexity is 157.42280380707783
At time: 1303.4382078647614 and batch: 1150, loss is 5.067753314971924 and perplexity is 158.81711418818008
At time: 1304.4639356136322 and batch: 1200, loss is 5.047205686569214 and perplexity is 155.58709737774146
At time: 1305.4870562553406 and batch: 1250, loss is 5.069831056594849 and perplexity is 159.1474381618619
At time: 1306.5128698349 and batch: 1300, loss is 5.068988008499145 and perplexity is 159.01332575673055
At time: 1307.5426528453827 and batch: 1350, loss is 5.062081356048584 and perplexity is 157.91885987910567
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.052105712890625 and perplexity of 156.35134914790308
Finished 44 epochs...
Completing Train Step...
At time: 1310.638926744461 and batch: 50, loss is 5.166278686523437 and perplexity is 175.26141976873683
At time: 1311.662718296051 and batch: 100, loss is 5.163550472259521 and perplexity is 174.78392071944302
At time: 1312.687971830368 and batch: 150, loss is 5.130737380981445 and perplexity is 169.14179401446742
At time: 1313.7121577262878 and batch: 200, loss is 5.125708770751953 and perplexity is 168.29338081630755
At time: 1314.7364835739136 and batch: 250, loss is 5.1430822849273685 and perplexity is 171.24277473561307
At time: 1315.7613410949707 and batch: 300, loss is 5.146587533950806 and perplexity is 171.84407654514473
At time: 1316.7864503860474 and batch: 350, loss is 5.14821494102478 and perplexity is 172.12396449497714
At time: 1317.8098917007446 and batch: 400, loss is 5.1755758571624755 and perplexity is 176.89845319258524
At time: 1318.8351593017578 and batch: 450, loss is 5.138917455673218 and perplexity is 170.53106092984194
At time: 1319.8591530323029 and batch: 500, loss is 5.184307041168213 and perplexity is 178.44974860553532
At time: 1320.8825297355652 and batch: 550, loss is 5.153765182495118 and perplexity is 173.08195012730624
At time: 1321.9083189964294 and batch: 600, loss is 5.105616464614868 and perplexity is 164.94572239726466
At time: 1322.932086467743 and batch: 650, loss is 5.115159177780152 and perplexity is 166.52728631750324
At time: 1323.9567561149597 and batch: 700, loss is 5.1377511405944825 and perplexity is 170.3322839229299
At time: 1324.9792919158936 and batch: 750, loss is 5.125639705657959 and perplexity is 168.2817580195123
At time: 1326.0024228096008 and batch: 800, loss is 5.093531494140625 and perplexity is 162.96435471149277
At time: 1327.0246078968048 and batch: 850, loss is 5.0818461894989015 and perplexity is 161.07114946345575
At time: 1328.072890996933 and batch: 900, loss is 5.111896238327026 and perplexity is 165.98480339073583
At time: 1329.0958886146545 and batch: 950, loss is 5.097030563354492 and perplexity is 163.53557705847322
At time: 1330.1188969612122 and batch: 1000, loss is 5.116334342956543 and perplexity is 166.72309841854877
At time: 1331.1418974399567 and batch: 1050, loss is 5.066092929840088 and perplexity is 158.553635411754
At time: 1332.1648442745209 and batch: 1100, loss is 5.05907772064209 and perplexity is 157.44524084574428
At time: 1333.187059879303 and batch: 1150, loss is 5.067876882553101 and perplexity is 158.83674004736486
At time: 1334.2098705768585 and batch: 1200, loss is 5.047337007522583 and perplexity is 155.60753056532454
At time: 1335.2322297096252 and batch: 1250, loss is 5.069875459671021 and perplexity is 159.15450495457378
At time: 1336.2547507286072 and batch: 1300, loss is 5.06897126197815 and perplexity is 159.01066285902937
At time: 1337.2771396636963 and batch: 1350, loss is 5.061960802078247 and perplexity is 157.89982328104807
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.052077229817709 and perplexity of 156.34689584444692
Finished 45 epochs...
Completing Train Step...
At time: 1340.4086241722107 and batch: 50, loss is 5.165966863632202 and perplexity is 175.20677776585896
At time: 1341.4571220874786 and batch: 100, loss is 5.163231325149536 and perplexity is 174.72814783662417
At time: 1342.4796719551086 and batch: 150, loss is 5.130451173782348 and perplexity is 169.09339134227935
At time: 1343.501924753189 and batch: 200, loss is 5.125416402816772 and perplexity is 168.24418442012848
At time: 1344.524031162262 and batch: 250, loss is 5.142832584381104 and perplexity is 171.20002065929796
At time: 1345.546288728714 and batch: 300, loss is 5.146339693069458 and perplexity is 171.80149183509343
At time: 1346.568597793579 and batch: 350, loss is 5.147987012863159 and perplexity is 172.0847370668665
At time: 1347.5908997058868 and batch: 400, loss is 5.175351600646973 and perplexity is 176.85878700974072
At time: 1348.612896680832 and batch: 450, loss is 5.138723125457764 and perplexity is 170.49792481180867
At time: 1349.635196685791 and batch: 500, loss is 5.184086790084839 and perplexity is 178.41044918310615
At time: 1350.6572875976562 and batch: 550, loss is 5.153623609542847 and perplexity is 173.0574481390923
At time: 1351.6799011230469 and batch: 600, loss is 5.105535202026367 and perplexity is 164.93231902550423
At time: 1352.7025864124298 and batch: 650, loss is 5.115065832138061 and perplexity is 166.51174244652393
At time: 1353.749636888504 and batch: 700, loss is 5.137650356292725 and perplexity is 170.31511796767188
At time: 1354.7715935707092 and batch: 750, loss is 5.125526084899902 and perplexity is 168.2626388047893
At time: 1355.794293165207 and batch: 800, loss is 5.093503313064575 and perplexity is 162.95976226532963
At time: 1356.8310086727142 and batch: 850, loss is 5.08178542137146 and perplexity is 161.06136176871104
At time: 1357.8571891784668 and batch: 900, loss is 5.111820402145386 and perplexity is 165.9722162143241
At time: 1358.8879215717316 and batch: 950, loss is 5.096996555328369 and perplexity is 163.53001563086366
At time: 1359.9170262813568 and batch: 1000, loss is 5.116383028030396 and perplexity is 166.73121554249798
At time: 1360.9421789646149 and batch: 1050, loss is 5.066217861175537 and perplexity is 158.57344496655762
At time: 1361.9683363437653 and batch: 1100, loss is 5.0592107009887695 and perplexity is 157.46617936062955
At time: 1362.9935688972473 and batch: 1150, loss is 5.067992172241211 and perplexity is 158.855053341232
At time: 1364.0188219547272 and batch: 1200, loss is 5.047458829879761 and perplexity is 155.62648819620085
At time: 1365.0467162132263 and batch: 1250, loss is 5.069912786483765 and perplexity is 159.16044579585318
At time: 1366.071090221405 and batch: 1300, loss is 5.068951845169067 and perplexity is 159.00757540932088
At time: 1367.0942265987396 and batch: 1350, loss is 5.061839323043824 and perplexity is 157.8806429280092
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.05204833984375 and perplexity of 156.34237905194274
Finished 46 epochs...
Completing Train Step...
At time: 1370.1612031459808 and batch: 50, loss is 5.165663022994995 and perplexity is 175.15355091350938
At time: 1371.2210865020752 and batch: 100, loss is 5.1629197311401365 and perplexity is 174.67371207385398
At time: 1372.2479412555695 and batch: 150, loss is 5.130172185897827 and perplexity is 169.04622291475803
At time: 1373.2706468105316 and batch: 200, loss is 5.125131225585937 and perplexity is 168.19621185017888
At time: 1374.2926661968231 and batch: 250, loss is 5.142589063644409 and perplexity is 171.1583349800145
At time: 1375.3162231445312 and batch: 300, loss is 5.146097459793091 and perplexity is 171.75988083682915
At time: 1376.339783668518 and batch: 350, loss is 5.147765035629273 and perplexity is 172.04654241226703
At time: 1377.3640365600586 and batch: 400, loss is 5.1751315212249756 and perplexity is 176.81986831287966
At time: 1378.3872635364532 and batch: 450, loss is 5.138532629013062 and perplexity is 170.46544865669716
At time: 1379.4121913909912 and batch: 500, loss is 5.183869152069092 and perplexity is 178.37162451197284
At time: 1380.4736859798431 and batch: 550, loss is 5.153481340408325 and perplexity is 173.03282915702508
At time: 1381.4970796108246 and batch: 600, loss is 5.105452041625977 and perplexity is 164.9186037581083
At time: 1382.5212802886963 and batch: 650, loss is 5.114964990615845 and perplexity is 166.4949519955503
At time: 1383.5459365844727 and batch: 700, loss is 5.137546863555908 and perplexity is 170.2974925020617
At time: 1384.5857264995575 and batch: 750, loss is 5.125408954620362 and perplexity is 168.2429313090647
At time: 1385.6138048171997 and batch: 800, loss is 5.093472423553467 and perplexity is 162.95472859568716
At time: 1386.6447277069092 and batch: 850, loss is 5.081725873947144 and perplexity is 161.05177126500848
At time: 1387.6671648025513 and batch: 900, loss is 5.111736030578613 and perplexity is 165.95821346912638
At time: 1388.6896181106567 and batch: 950, loss is 5.096960086822509 and perplexity is 163.52405204427262
At time: 1389.7272119522095 and batch: 1000, loss is 5.1164263820648195 and perplexity is 166.73844417005006
At time: 1390.7512595653534 and batch: 1050, loss is 5.066332387924194 and perplexity is 158.59160690762715
At time: 1391.7756671905518 and batch: 1100, loss is 5.059335069656372 and perplexity is 157.48576443740885
At time: 1392.799524307251 and batch: 1150, loss is 5.068099298477173 and perplexity is 158.87207179670526
At time: 1393.8243141174316 and batch: 1200, loss is 5.047570219039917 and perplexity is 155.64382426552623
At time: 1394.8471503257751 and batch: 1250, loss is 5.0699420833587645 and perplexity is 159.1651087678435
At time: 1395.8718848228455 and batch: 1300, loss is 5.068929309844971 and perplexity is 159.0039921624502
At time: 1396.895521402359 and batch: 1350, loss is 5.061716794967651 and perplexity is 157.86129930165924
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.0520166015625 and perplexity of 156.33741709228767
Finished 47 epochs...
Completing Train Step...
At time: 1400.0096945762634 and batch: 50, loss is 5.165366840362549 and perplexity is 175.10168115555751
At time: 1401.0347065925598 and batch: 100, loss is 5.162614984512329 and perplexity is 174.6204889593271
At time: 1402.058082818985 and batch: 150, loss is 5.129900045394898 and perplexity is 169.00022484988787
At time: 1403.0804722309113 and batch: 200, loss is 5.1248532581329345 and perplexity is 168.1494652748804
At time: 1404.1157901287079 and batch: 250, loss is 5.1423506259918215 and perplexity is 171.11752925340525
At time: 1405.1390056610107 and batch: 300, loss is 5.145859861373902 and perplexity is 171.71907580845928
At time: 1406.205687046051 and batch: 350, loss is 5.14754846572876 and perplexity is 172.00928634411036
At time: 1407.2305533885956 and batch: 400, loss is 5.174915428161621 and perplexity is 176.7816628939857
At time: 1408.2538616657257 and batch: 450, loss is 5.138345575332641 and perplexity is 170.43356544917003
At time: 1409.277030467987 and batch: 500, loss is 5.183652563095093 and perplexity is 178.3329953683035
At time: 1410.2996683120728 and batch: 550, loss is 5.153337087631225 and perplexity is 173.00787049111153
At time: 1411.3256623744965 and batch: 600, loss is 5.105364561080933 and perplexity is 164.9041772197935
At time: 1412.3513569831848 and batch: 650, loss is 5.1148530387878415 and perplexity is 166.47631362464037
At time: 1413.3862097263336 and batch: 700, loss is 5.137438726425171 and perplexity is 170.27907801551362
At time: 1414.4108543395996 and batch: 750, loss is 5.125290250778198 and perplexity is 168.2229614119766
At time: 1415.433662891388 and batch: 800, loss is 5.0934388637542725 and perplexity is 162.94925995948134
At time: 1416.456545829773 and batch: 850, loss is 5.0816678714752195 and perplexity is 161.04243013507428
At time: 1417.483149766922 and batch: 900, loss is 5.111642599105835 and perplexity is 165.94270847316093
At time: 1418.5071330070496 and batch: 950, loss is 5.096919260025024 and perplexity is 163.51737601719722
At time: 1419.5292224884033 and batch: 1000, loss is 5.116465139389038 and perplexity is 166.74490663122347
At time: 1420.5536596775055 and batch: 1050, loss is 5.066438636779785 and perplexity is 158.60845797955514
At time: 1421.5767209529877 and batch: 1100, loss is 5.0594509315490725 and perplexity is 157.50401209323348
At time: 1422.599730014801 and batch: 1150, loss is 5.068197441101074 and perplexity is 158.88766468384696
At time: 1423.624047279358 and batch: 1200, loss is 5.047671127319336 and perplexity is 155.65953080848178
At time: 1424.6542177200317 and batch: 1250, loss is 5.069960641860962 and perplexity is 159.16806266127412
At time: 1425.6793868541718 and batch: 1300, loss is 5.068902292251587 and perplexity is 158.99969631527551
At time: 1426.7038197517395 and batch: 1350, loss is 5.061593084335327 and perplexity is 157.8417713884333
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.051990152994792 and perplexity of 156.33328224620695
Finished 48 epochs...
Completing Train Step...
At time: 1429.8158884048462 and batch: 50, loss is 5.1650779247283936 and perplexity is 175.05109884966612
At time: 1430.8409152030945 and batch: 100, loss is 5.162316751480103 and perplexity is 174.56841912627397
At time: 1431.902262210846 and batch: 150, loss is 5.129635801315308 and perplexity is 168.95557344071702
At time: 1432.92893409729 and batch: 200, loss is 5.124582319259644 and perplexity is 168.10391321940435
At time: 1433.9526891708374 and batch: 250, loss is 5.1421170330047605 and perplexity is 171.07756206681742
At time: 1434.9764597415924 and batch: 300, loss is 5.14562686920166 and perplexity is 171.67907126852464
At time: 1436.001523733139 and batch: 350, loss is 5.147337484359741 and perplexity is 171.97299941746084
At time: 1437.033706188202 and batch: 400, loss is 5.174704122543335 and perplexity is 176.7443118817845
At time: 1438.063887834549 and batch: 450, loss is 5.138162136077881 and perplexity is 170.4023041103039
At time: 1439.0904021263123 and batch: 500, loss is 5.183437299728394 and perplexity is 178.29461093885598
At time: 1440.114414691925 and batch: 550, loss is 5.153191833496094 and perplexity is 172.98274220755016
At time: 1441.1384751796722 and batch: 600, loss is 5.10527271270752 and perplexity is 164.8890317349016
At time: 1442.1638054847717 and batch: 650, loss is 5.114731407165527 and perplexity is 166.45606607193355
At time: 1443.1887001991272 and batch: 700, loss is 5.137328557968139 and perplexity is 170.26031966553208
At time: 1444.213546037674 and batch: 750, loss is 5.125176973342896 and perplexity is 168.20390662560797
At time: 1445.237565279007 and batch: 800, loss is 5.093405551910401 and perplexity is 162.94383190958422
At time: 1446.2616021633148 and batch: 850, loss is 5.0816077136993405 and perplexity is 161.03274247205226
At time: 1447.286479473114 and batch: 900, loss is 5.111545667648316 and perplexity is 165.9266241841133
At time: 1448.310255765915 and batch: 950, loss is 5.096872720718384 and perplexity is 163.50976620897268
At time: 1449.3338713645935 and batch: 1000, loss is 5.11650013923645 and perplexity is 166.7507427796439
At time: 1450.3588349819183 and batch: 1050, loss is 5.0665396785736085 and perplexity is 158.6244848723443
At time: 1451.3827278614044 and batch: 1100, loss is 5.059557981491089 and perplexity is 157.52087379110122
At time: 1452.4065554141998 and batch: 1150, loss is 5.068286685943604 and perplexity is 158.90184522122203
At time: 1453.4313440322876 and batch: 1200, loss is 5.047763395309448 and perplexity is 155.67389386314622
At time: 1454.4545867443085 and batch: 1250, loss is 5.069966850280761 and perplexity is 159.16905084649335
At time: 1455.4783849716187 and batch: 1300, loss is 5.068870277404785 and perplexity is 158.99460604583896
At time: 1456.5036616325378 and batch: 1350, loss is 5.061467580795288 and perplexity is 157.82196293039974
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.051964518229167 and perplexity of 156.32927473052328
Finished 49 epochs...
Completing Train Step...
At time: 1459.5935280323029 and batch: 50, loss is 5.16479721069336 and perplexity is 175.00196644577122
At time: 1460.6443660259247 and batch: 100, loss is 5.162025527954102 and perplexity is 174.5175880976825
At time: 1461.6840977668762 and batch: 150, loss is 5.129379234313965 and perplexity is 168.91223057629128
At time: 1462.720662355423 and batch: 200, loss is 5.1243164920806885 and perplexity is 168.05923256931058
At time: 1463.7447855472565 and batch: 250, loss is 5.141889019012451 and perplexity is 171.0385584357518
At time: 1464.7679982185364 and batch: 300, loss is 5.1453972434997555 and perplexity is 171.63965386707972
At time: 1465.7931945323944 and batch: 350, loss is 5.147131652832031 and perplexity is 171.93760559497312
At time: 1466.817003250122 and batch: 400, loss is 5.1744990634918215 and perplexity is 176.70807257655545
At time: 1467.840668439865 and batch: 450, loss is 5.137980966567993 and perplexity is 170.37143520472122
At time: 1468.8666088581085 and batch: 500, loss is 5.183226327896119 and perplexity is 178.25699976568998
At time: 1469.8906877040863 and batch: 550, loss is 5.153050231933594 and perplexity is 172.9582493151248
At time: 1470.9146194458008 and batch: 600, loss is 5.105181188583374 and perplexity is 164.87394110127983
At time: 1471.9398086071014 and batch: 650, loss is 5.11461163520813 and perplexity is 166.43613049696472
At time: 1472.9636523723602 and batch: 700, loss is 5.1372216606140135 and perplexity is 170.24212026059868
At time: 1473.9869952201843 and batch: 750, loss is 5.125070447921753 and perplexity is 168.18598958794377
At time: 1475.010771036148 and batch: 800, loss is 5.093374881744385 and perplexity is 162.9388344718448
At time: 1476.0357065200806 and batch: 850, loss is 5.0815435314178465 and perplexity is 161.0224073549144
At time: 1477.059500694275 and batch: 900, loss is 5.1114520168304445 and perplexity is 165.91108574765684
At time: 1478.0853655338287 and batch: 950, loss is 5.096820487976074 and perplexity is 163.50122586853377
At time: 1479.109028339386 and batch: 1000, loss is 5.11653226852417 and perplexity is 166.7561004483048
At time: 1480.1324429512024 and batch: 1050, loss is 5.066638107299805 and perplexity is 158.64009884675303
At time: 1481.1577413082123 and batch: 1100, loss is 5.05965744972229 and perplexity is 157.53654289307048
At time: 1482.181337594986 and batch: 1150, loss is 5.068369493484497 and perplexity is 158.91500403708534
At time: 1483.2072007656097 and batch: 1200, loss is 5.047850742340088 and perplexity is 155.68749210939782
At time: 1484.2687983512878 and batch: 1250, loss is 5.069962978363037 and perplexity is 159.16843455821734
At time: 1485.2924139499664 and batch: 1300, loss is 5.068833475112915 and perplexity is 158.988754787612
At time: 1486.3176007270813 and batch: 1350, loss is 5.061340627670288 and perplexity is 157.80192821077412
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.051944580078125 and perplexity of 156.32615784490397
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fec148f35c0>
SETTINGS FOR THIS RUN
{'wordvec_dim': 200, 'dropout': 0.8802053241651955, 'num_layers': 1, 'wordvec_source': 'glove', 'tune_wordvecs': True, 'batch_size': 80, 'seq_len': 20, 'lr': 24.369477242781443, 'data': 'wikitext', 'anneal': 7.436080736383208}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.722503662109375 and batch: 50, loss is 7.506462860107422 and perplexity is 1819.7653807904517
At time: 2.745842218399048 and batch: 100, loss is 6.931406536102295 and perplexity is 1023.9331662160375
At time: 3.769038200378418 and batch: 150, loss is 6.74366810798645 and perplexity is 848.6680394176877
At time: 4.792249917984009 and batch: 200, loss is 6.6857812881469725 and perplexity is 800.936195745292
At time: 5.814962148666382 and batch: 250, loss is 6.682173948287964 and perplexity is 798.0521516729074
At time: 6.83905029296875 and batch: 300, loss is 6.676713027954102 and perplexity is 793.7059304352722
At time: 7.862932920455933 and batch: 350, loss is 6.662620162963867 and perplexity is 782.5987894655166
At time: 8.887577533721924 and batch: 400, loss is 6.707917556762696 and perplexity is 818.8636256683094
At time: 9.911821603775024 and batch: 450, loss is 6.687047605514526 and perplexity is 801.9510776059111
At time: 10.935611963272095 and batch: 500, loss is 6.673707838058472 and perplexity is 791.324273850606
At time: 11.959022998809814 and batch: 550, loss is 6.651387758255005 and perplexity is 773.8575078488228
At time: 12.98355746269226 and batch: 600, loss is 6.608636884689331 and perplexity is 741.4716182302484
At time: 14.007229089736938 and batch: 650, loss is 6.642856531143188 and perplexity is 767.2836351690926
At time: 15.031419277191162 and batch: 700, loss is 6.643374919891357 and perplexity is 767.6814894849094
At time: 16.055363178253174 and batch: 750, loss is 6.6380111026763915 and perplexity is 763.5748098813194
At time: 17.080292224884033 and batch: 800, loss is 6.61121865272522 and perplexity is 743.3883992309774
At time: 18.104855060577393 and batch: 850, loss is 6.609427862167358 and perplexity is 742.0583375911749
At time: 19.128970861434937 and batch: 900, loss is 6.64725980758667 and perplexity is 770.6696464262025
At time: 20.153019905090332 and batch: 950, loss is 6.636994333267212 and perplexity is 762.7988249387399
At time: 21.1770281791687 and batch: 1000, loss is 6.655765256881714 and perplexity is 777.25249337758
At time: 22.201319694519043 and batch: 1050, loss is 6.6582475185394285 and perplexity is 779.1842339911952
At time: 23.225274801254272 and batch: 1100, loss is 6.67531907081604 and perplexity is 792.6003091613829
At time: 24.250036239624023 and batch: 1150, loss is 6.661883878707886 and perplexity is 782.0227863751082
At time: 25.274470329284668 and batch: 1200, loss is 6.630916271209717 and perplexity is 758.1765478169691
At time: 26.303362369537354 and batch: 1250, loss is 6.63934739112854 and perplexity is 764.5958481309904
At time: 27.3330397605896 and batch: 1300, loss is 6.607106904983521 and perplexity is 740.3380490919352
At time: 28.360170602798462 and batch: 1350, loss is 6.619098176956177 and perplexity is 749.2690842095274
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 6.079014485677083 and perplexity of 436.5987083475479
Finished 1 epochs...
Completing Train Step...
At time: 31.464653491973877 and batch: 50, loss is 6.547750301361084 and perplexity is 697.6728533113054
At time: 32.50452971458435 and batch: 100, loss is 6.748160076141358 and perplexity is 852.4888041771097
At time: 33.52004361152649 and batch: 150, loss is 6.847197265625 and perplexity is 941.2391629907672
At time: 34.5374755859375 and batch: 200, loss is 7.000361862182618 and perplexity is 1097.030060304257
At time: 35.559571743011475 and batch: 250, loss is 7.087666778564453 and perplexity is 1197.1114135734745
At time: 36.57736849784851 and batch: 300, loss is 7.109444093704224 and perplexity is 1223.4672238791268
At time: 37.59342670440674 and batch: 350, loss is 7.0997420692443844 and perplexity is 1211.654511220845
At time: 38.60902380943298 and batch: 400, loss is 7.157579307556152 and perplexity is 1283.799484783529
At time: 39.62371826171875 and batch: 450, loss is 7.2393130016326905 and perplexity is 1393.136559492276
At time: 40.638392210006714 and batch: 500, loss is 7.321177043914795 and perplexity is 1511.9825927092825
At time: 41.65161466598511 and batch: 550, loss is 7.078903179168702 and perplexity is 1186.6662442024142
At time: 42.66629385948181 and batch: 600, loss is 7.131541881561279 and perplexity is 1250.8040725834037
At time: 43.683037519454956 and batch: 650, loss is 7.213825626373291 and perplexity is 1358.0778404206312
At time: 44.698864459991455 and batch: 700, loss is 7.287520208358765 and perplexity is 1461.9408896826785
At time: 45.71313786506653 and batch: 750, loss is 7.108024635314941 and perplexity is 1221.7317950400793
At time: 46.72787261009216 and batch: 800, loss is 7.044343519210815 and perplexity is 1146.356028031001
At time: 47.740519285202026 and batch: 850, loss is 6.739652490615844 and perplexity is 845.2669466106703
At time: 48.775020122528076 and batch: 900, loss is 7.056388940811157 and perplexity is 1160.247868262882
At time: 49.79880714416504 and batch: 950, loss is 6.935531206130982 and perplexity is 1028.1652746835484
At time: 50.82482409477234 and batch: 1000, loss is 6.906697216033936 and perplexity is 998.9424966030358
At time: 51.843653440475464 and batch: 1050, loss is 7.08074649810791 and perplexity is 1188.8556658461234
At time: 52.89916706085205 and batch: 1100, loss is 6.87939528465271 and perplexity is 972.0383755044185
At time: 53.91497540473938 and batch: 1150, loss is 6.991538496017456 and perplexity is 1087.393139947387
At time: 54.929808139801025 and batch: 1200, loss is 6.874337310791016 and perplexity is 967.1342437489067
At time: 55.94442057609558 and batch: 1250, loss is 6.951360330581665 and perplexity is 1044.5697222685196
At time: 56.96018624305725 and batch: 1300, loss is 6.950117959976196 and perplexity is 1043.272785355176
At time: 57.97436451911926 and batch: 1350, loss is 6.869983329772949 and perplexity is 962.9325133745822
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 6.4591902669270835 and perplexity of 638.5437971457294
Annealing...
Finished 2 epochs...
Completing Train Step...
At time: 61.05577254295349 and batch: 50, loss is 6.5187075805664065 and perplexity is 677.7019439339628
At time: 62.073691844940186 and batch: 100, loss is 6.479471416473388 and perplexity is 651.6264162336169
At time: 63.092122077941895 and batch: 150, loss is 6.39880030632019 and perplexity is 601.123441118002
At time: 64.11048150062561 and batch: 200, loss is 6.373075227737427 and perplexity is 585.856704285049
At time: 65.12922501564026 and batch: 250, loss is 6.357419891357422 and perplexity is 576.7563409994349
At time: 66.14861536026001 and batch: 300, loss is 6.3554458332061765 and perplexity is 575.6189134865997
At time: 67.16987323760986 and batch: 350, loss is 6.32231333732605 and perplexity is 556.8597079218242
At time: 68.19093298912048 and batch: 400, loss is 6.346337852478027 and perplexity is 570.3999905187775
At time: 69.21017169952393 and batch: 450, loss is 6.320462551116943 and perplexity is 555.8300328021725
At time: 70.23228406906128 and batch: 500, loss is 6.32316107749939 and perplexity is 557.3319804210453
At time: 71.25063419342041 and batch: 550, loss is 6.294453182220459 and perplexity is 541.5596309776481
At time: 72.26915049552917 and batch: 600, loss is 6.250260601043701 and perplexity is 518.1478369425067
At time: 73.29973816871643 and batch: 650, loss is 6.271921043395996 and perplexity is 529.4935816276269
At time: 74.31915473937988 and batch: 700, loss is 6.279636287689209 and perplexity is 533.594553619443
At time: 75.33799147605896 and batch: 750, loss is 6.265203008651733 and perplexity is 525.9483471870764
At time: 76.35795283317566 and batch: 800, loss is 6.22748948097229 and perplexity is 506.48235247156464
At time: 77.37789845466614 and batch: 850, loss is 6.220761890411377 and perplexity is 503.0863827333765
At time: 78.43828058242798 and batch: 900, loss is 6.273257904052734 and perplexity is 530.2019141303335
At time: 79.46064329147339 and batch: 950, loss is 6.234903059005737 and perplexity is 510.2511517966783
At time: 80.4798321723938 and batch: 1000, loss is 6.2473084926605225 and perplexity is 516.6204639638776
At time: 81.49885082244873 and batch: 1050, loss is 6.222394866943359 and perplexity is 503.90858212338696
At time: 82.53396725654602 and batch: 1100, loss is 6.2146253490448 and perplexity is 500.00862538570055
At time: 83.55962371826172 and batch: 1150, loss is 6.226155319213867 and perplexity is 505.80707365133594
At time: 84.59254336357117 and batch: 1200, loss is 6.212731161117554 and perplexity is 499.06241152033
At time: 85.61996722221375 and batch: 1250, loss is 6.227321329116822 and perplexity is 506.3971936842394
At time: 86.64756488800049 and batch: 1300, loss is 6.18484037399292 and perplexity is 485.33548525970525
At time: 87.66572904586792 and batch: 1350, loss is 6.192946138381958 and perplexity is 489.2854876197297
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.893317057291667 and perplexity of 362.60607685377505
Finished 3 epochs...
Completing Train Step...
At time: 90.75934171676636 and batch: 50, loss is 6.281639842987061 and perplexity is 534.6647115165255
At time: 91.80439448356628 and batch: 100, loss is 6.314383602142334 and perplexity is 552.4614195816853
At time: 92.82411313056946 and batch: 150, loss is 6.26293306350708 and perplexity is 524.755827279481
At time: 93.84284996986389 and batch: 200, loss is 6.250128135681153 and perplexity is 518.0792048472206
At time: 94.87032914161682 and batch: 250, loss is 6.258583726882935 and perplexity is 522.4784436851508
At time: 95.89084672927856 and batch: 300, loss is 6.270906190872193 and perplexity is 528.9564963072675
At time: 96.9113495349884 and batch: 350, loss is 6.255616979598999 and perplexity is 520.9306792296621
At time: 97.9332845211029 and batch: 400, loss is 6.287255449295044 and perplexity is 537.6756241808167
At time: 98.952632188797 and batch: 450, loss is 6.262294626235962 and perplexity is 524.4209105241549
At time: 99.98228812217712 and batch: 500, loss is 6.2693445587158205 and perplexity is 528.1311054794808
At time: 101.00660943984985 and batch: 550, loss is 6.241854248046875 and perplexity is 513.8103600445131
At time: 102.02897644042969 and batch: 600, loss is 6.1882171630859375 and perplexity is 486.9771310185982
At time: 103.05108714103699 and batch: 650, loss is 6.217708234786987 and perplexity is 501.5524733786043
At time: 104.06991362571716 and batch: 700, loss is 6.226895980834961 and perplexity is 506.1818443104564
At time: 105.11498999595642 and batch: 750, loss is 6.216240062713623 and perplexity is 500.8166483349273
At time: 106.13496327400208 and batch: 800, loss is 6.180463972091675 and perplexity is 483.2161031359418
At time: 107.15614056587219 and batch: 850, loss is 6.182564268112182 and perplexity is 484.2320665328712
At time: 108.17725038528442 and batch: 900, loss is 6.230818548202515 and perplexity is 508.17127598400725
At time: 109.19864153862 and batch: 950, loss is 6.19383544921875 and perplexity is 489.72080804505043
At time: 110.21615314483643 and batch: 1000, loss is 6.203964414596558 and perplexity is 494.7063798718627
At time: 111.23595261573792 and batch: 1050, loss is 6.178195447921753 and perplexity is 482.1211581508312
At time: 112.26005458831787 and batch: 1100, loss is 6.142581844329834 and perplexity is 465.2532329439099
At time: 113.28090119361877 and batch: 1150, loss is 6.134522104263306 and perplexity is 461.5184835929987
At time: 114.30043745040894 and batch: 1200, loss is 6.10955641746521 and perplexity is 450.13899707783594
At time: 115.32282853126526 and batch: 1250, loss is 6.120833873748779 and perplexity is 455.24415241552424
At time: 116.3425521850586 and batch: 1300, loss is 6.071780424118042 and perplexity is 433.45172288195477
At time: 117.36252188682556 and batch: 1350, loss is 6.067217025756836 and perplexity is 431.4782163730673
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.776673990885417 and perplexity of 322.68415318184185
Finished 4 epochs...
Completing Train Step...
At time: 120.44991946220398 and batch: 50, loss is 6.131832046508789 and perplexity is 460.2786405896668
At time: 121.46756792068481 and batch: 100, loss is 6.159721164703369 and perplexity is 473.2960847797532
At time: 122.492192029953 and batch: 150, loss is 6.1105745410919186 and perplexity is 450.5975276068377
At time: 123.51429152488708 and batch: 200, loss is 6.098183031082153 and perplexity is 445.04839589903446
At time: 124.53285574913025 and batch: 250, loss is 6.11402494430542 and perplexity is 452.1549560970868
At time: 125.55222654342651 and batch: 300, loss is 6.127830362319946 and perplexity is 458.44043125079
At time: 126.57371759414673 and batch: 350, loss is 6.120332860946656 and perplexity is 455.01612639382
At time: 127.59353113174438 and batch: 400, loss is 6.149055862426758 and perplexity is 468.27506192693886
At time: 128.61598539352417 and batch: 450, loss is 6.124554147720337 and perplexity is 456.9409396861959
At time: 129.65234446525574 and batch: 500, loss is 6.131031646728515 and perplexity is 459.91038106395604
At time: 130.72236585617065 and batch: 550, loss is 6.108804807662964 and perplexity is 449.80079530906255
At time: 131.74160051345825 and batch: 600, loss is 6.045932741165161 and perplexity is 422.39155579016665
At time: 132.7646541595459 and batch: 650, loss is 6.07860800743103 and perplexity is 436.4212765338789
At time: 133.78423070907593 and batch: 700, loss is 6.083166217803955 and perplexity is 438.4151172440295
At time: 134.80406522750854 and batch: 750, loss is 6.072818336486816 and perplexity is 433.9018413377485
At time: 135.82543802261353 and batch: 800, loss is 6.042521352767944 and perplexity is 420.95306915101764
At time: 136.84512209892273 and batch: 850, loss is 6.041897954940796 and perplexity is 420.6907297017948
At time: 137.86608052253723 and batch: 900, loss is 6.086470346450806 and perplexity is 439.86609297731417
At time: 138.89532089233398 and batch: 950, loss is 6.0553671169281005 and perplexity is 426.39541369886996
At time: 139.914644241333 and batch: 1000, loss is 6.06481164932251 and perplexity is 430.44159607031185
At time: 140.94088649749756 and batch: 1050, loss is 6.044111375808716 and perplexity is 421.6229266333403
At time: 141.97269558906555 and batch: 1100, loss is 6.035417528152466 and perplexity is 417.973288825872
At time: 143.0035572052002 and batch: 1150, loss is 6.039394006729126 and perplexity is 419.6386596156824
At time: 144.02410411834717 and batch: 1200, loss is 6.0282211589813235 and perplexity is 414.9761957642363
At time: 145.04652333259583 and batch: 1250, loss is 6.0480907440185545 and perplexity is 423.30406221441814
At time: 146.065123796463 and batch: 1300, loss is 6.007114553451538 and perplexity is 406.3092436161753
At time: 147.08294534683228 and batch: 1350, loss is 6.009521522521973 and perplexity is 407.28839531979764
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.722339680989584 and perplexity of 305.61913840112237
Finished 5 epochs...
Completing Train Step...
At time: 150.17042803764343 and batch: 50, loss is 6.06482011795044 and perplexity is 430.4452413354696
At time: 151.21428036689758 and batch: 100, loss is 6.093887052536011 and perplexity is 443.14057844381773
At time: 152.2363588809967 and batch: 150, loss is 6.04281777381897 and perplexity is 421.07786699764847
At time: 153.25625705718994 and batch: 200, loss is 6.035361318588257 and perplexity is 417.94979538974036
At time: 154.27708554267883 and batch: 250, loss is 6.052944402694703 and perplexity is 425.36362982446036
At time: 155.29823994636536 and batch: 300, loss is 6.068802709579468 and perplexity is 432.16294714036485
At time: 156.32051539421082 and batch: 350, loss is 6.0673244762420655 and perplexity is 431.5245814077106
At time: 157.38391590118408 and batch: 400, loss is 6.09943470954895 and perplexity is 445.6058021668009
At time: 158.4042308330536 and batch: 450, loss is 6.077297677993775 and perplexity is 435.84979538424625
At time: 159.42404413223267 and batch: 500, loss is 6.085710172653198 and perplexity is 439.53184535821345
At time: 160.44506788253784 and batch: 550, loss is 6.066009511947632 and perplexity is 430.9575149087995
At time: 161.46494889259338 and batch: 600, loss is 6.004752674102783 and perplexity is 405.3507226055504
At time: 162.48446130752563 and batch: 650, loss is 6.040155849456787 and perplexity is 419.9584800877376
At time: 163.50596404075623 and batch: 700, loss is 6.040606393814087 and perplexity is 420.1477326413749
At time: 164.52688884735107 and batch: 750, loss is 6.026693534851074 and perplexity is 414.3427520692303
At time: 165.5473189353943 and batch: 800, loss is 5.99516393661499 and perplexity is 401.4824962776673
At time: 166.56786155700684 and batch: 850, loss is 5.990208129882813 and perplexity is 399.4977486945986
At time: 167.5903651714325 and batch: 900, loss is 6.034667158126831 and perplexity is 417.6597718400063
At time: 168.61035561561584 and batch: 950, loss is 6.002917289733887 and perplexity is 404.60743054732853
At time: 169.62973165512085 and batch: 1000, loss is 6.011244878768921 and perplexity is 407.9909034822286
At time: 170.65024495124817 and batch: 1050, loss is 5.992747688293457 and perplexity is 400.51358590533766
At time: 171.67230868339539 and batch: 1100, loss is 5.986464385986328 and perplexity is 398.00492754985555
At time: 172.7000696659088 and batch: 1150, loss is 5.9886375904083256 and perplexity is 398.8708141518946
At time: 173.721914768219 and batch: 1200, loss is 5.972675170898437 and perplexity is 392.55441748978103
At time: 174.74538159370422 and batch: 1250, loss is 5.987622623443603 and perplexity is 398.46617883281596
At time: 175.7648355960846 and batch: 1300, loss is 5.9465589427948 and perplexity is 382.435091252543
At time: 176.7832362651825 and batch: 1350, loss is 5.941361379623413 and perplexity is 380.45251744631435
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.660016682942708 and perplexity of 287.15343308036677
Finished 6 epochs...
Completing Train Step...
At time: 179.87277245521545 and batch: 50, loss is 5.990333013534546 and perplexity is 399.547642547713
At time: 180.91979098320007 and batch: 100, loss is 6.015363235473632 and perplexity is 409.67462024838886
At time: 181.94144082069397 and batch: 150, loss is 5.970060348510742 and perplexity is 391.5292982470001
At time: 182.98728227615356 and batch: 200, loss is 5.960117397308349 and perplexity is 387.65563129420855
At time: 184.00808191299438 and batch: 250, loss is 5.983099164962769 and perplexity is 396.6678041200013
At time: 185.03005957603455 and batch: 300, loss is 5.996927614212036 and perplexity is 402.19120674663986
At time: 186.050683259964 and batch: 350, loss is 6.000769929885864 and perplexity is 403.73952498304385
At time: 187.07113528251648 and batch: 400, loss is 6.036705284118653 and perplexity is 418.51188313685304
At time: 188.09222960472107 and batch: 450, loss is 6.016762084960938 and perplexity is 410.24809438937586
At time: 189.11418557167053 and batch: 500, loss is 6.0232401466369625 and perplexity is 412.9143335540609
At time: 190.13300490379333 and batch: 550, loss is 5.999026432037353 and perplexity is 403.03621927403043
At time: 191.15449929237366 and batch: 600, loss is 5.944622411727905 and perplexity is 381.6952104495641
At time: 192.1755187511444 and batch: 650, loss is 5.981761283874512 and perplexity is 396.13746461125396
At time: 193.19545912742615 and batch: 700, loss is 5.983710174560547 and perplexity is 396.9102460150678
At time: 194.21748065948486 and batch: 750, loss is 5.970062084197998 and perplexity is 391.52997782000324
At time: 195.2390432357788 and batch: 800, loss is 5.9425416183471675 and perplexity is 380.90180732245557
At time: 196.25992918014526 and batch: 850, loss is 5.9431897640228275 and perplexity is 381.1487672060675
At time: 197.28063797950745 and batch: 900, loss is 5.988938093185425 and perplexity is 398.9906939504552
At time: 198.3012251853943 and batch: 950, loss is 5.956343469619751 and perplexity is 386.1954041026515
At time: 199.32169437408447 and batch: 1000, loss is 5.965269689559936 and perplexity is 389.658100623401
At time: 200.34241914749146 and batch: 1050, loss is 5.947339448928833 and perplexity is 382.7337007052307
At time: 201.36301279067993 and batch: 1100, loss is 5.942762479782105 and perplexity is 380.9859431330269
At time: 202.3852424621582 and batch: 1150, loss is 5.947079801559449 and perplexity is 382.6343378068836
At time: 203.40560102462769 and batch: 1200, loss is 5.934880647659302 and perplexity is 377.99487890570225
At time: 204.42702746391296 and batch: 1250, loss is 5.949424037933349 and perplexity is 383.53237533433287
At time: 205.4481964111328 and batch: 1300, loss is 5.911310119628906 and perplexity is 369.18952114518856
At time: 206.46875619888306 and batch: 1350, loss is 5.910429468154907 and perplexity is 368.8645369691074
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.62816650390625 and perplexity of 278.1516598330757
Finished 7 epochs...
Completing Train Step...
At time: 209.57198762893677 and batch: 50, loss is 5.958364686965942 and perplexity is 386.976778350021
At time: 210.59223747253418 and batch: 100, loss is 5.982498950958252 and perplexity is 396.4297899856814
At time: 211.612487077713 and batch: 150, loss is 5.937977914810181 and perplexity is 379.1674449651313
At time: 212.6319637298584 and batch: 200, loss is 5.93157811164856 and perplexity is 376.74859628559653
At time: 213.65367817878723 and batch: 250, loss is 5.958340225219726 and perplexity is 386.96731233805554
At time: 214.67415356636047 and batch: 300, loss is 5.971460494995117 and perplexity is 392.0778805756594
At time: 215.69500923156738 and batch: 350, loss is 5.97964563369751 and perplexity is 395.30026224007923
At time: 216.71616387367249 and batch: 400, loss is 6.015482053756714 and perplexity is 409.72329997535246
At time: 217.73797917366028 and batch: 450, loss is 5.995126266479492 and perplexity is 401.4673726624885
At time: 218.7580373287201 and batch: 500, loss is 6.003217191696167 and perplexity is 404.72879130695816
At time: 219.77903246879578 and batch: 550, loss is 5.981851453781128 and perplexity is 396.1731858999135
At time: 220.8010482788086 and batch: 600, loss is 5.925853929519653 and perplexity is 374.5981792647454
At time: 221.82079410552979 and batch: 650, loss is 5.96218523979187 and perplexity is 388.45807145156425
At time: 222.8427472114563 and batch: 700, loss is 5.961730222702027 and perplexity is 388.2813565975546
At time: 223.86511397361755 and batch: 750, loss is 5.951242370605469 and perplexity is 384.230399210704
At time: 224.88550543785095 and batch: 800, loss is 5.918648815155029 and perplexity is 371.9088566153636
At time: 225.90642619132996 and batch: 850, loss is 5.920652618408203 and perplexity is 372.65483594042666
At time: 226.9289300441742 and batch: 900, loss is 5.964424800872803 and perplexity is 389.32902193933876
At time: 227.95049667358398 and batch: 950, loss is 5.932956562042237 and perplexity is 377.2682836357906
At time: 228.97598457336426 and batch: 1000, loss is 5.9454871273040775 and perplexity is 382.0254109875894
At time: 230.00261545181274 and batch: 1050, loss is 5.927520914077759 and perplexity is 375.2231494081391
At time: 231.0250871181488 and batch: 1100, loss is 5.92108570098877 and perplexity is 372.81626121114965
At time: 232.04534578323364 and batch: 1150, loss is 5.921985330581665 and perplexity is 373.15180866402625
At time: 233.06721329689026 and batch: 1200, loss is 5.9101664829254155 and perplexity is 368.7675437986457
At time: 234.08834624290466 and batch: 1250, loss is 5.922928371429443 and perplexity is 373.50387204099985
At time: 235.108882188797 and batch: 1300, loss is 5.88650239944458 and perplexity is 360.14344104725683
At time: 236.12920427322388 and batch: 1350, loss is 5.886374340057373 and perplexity is 360.09732425179726
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.607786051432291 and perplexity of 272.54017963406665
Finished 8 epochs...
Completing Train Step...
At time: 239.21021914482117 and batch: 50, loss is 5.936837224960327 and perplexity is 378.73517909678014
At time: 240.256929397583 and batch: 100, loss is 5.96048267364502 and perplexity is 387.7972585880721
At time: 241.2778034210205 and batch: 150, loss is 5.913067493438721 and perplexity is 369.83889557018546
At time: 242.3004457950592 and batch: 200, loss is 5.903020658493042 and perplexity is 366.14178844089116
At time: 243.32152724266052 and batch: 250, loss is 5.94009147644043 and perplexity is 379.9696862227757
At time: 244.34182024002075 and batch: 300, loss is 5.950674428939819 and perplexity is 384.01224071429704
At time: 245.36253595352173 and batch: 350, loss is 5.960375108718872 and perplexity is 387.75554744795994
At time: 246.38358426094055 and batch: 400, loss is 5.9948294067382815 and perplexity is 401.3482108501831
At time: 247.41367197036743 and batch: 450, loss is 5.974730596542359 and perplexity is 393.362113701516
At time: 248.44509100914001 and batch: 500, loss is 5.985725841522217 and perplexity is 397.71109173268866
At time: 249.47182250022888 and batch: 550, loss is 5.9586265277862545 and perplexity is 387.0781179339468
At time: 250.49294090270996 and batch: 600, loss is 5.90553635597229 and perplexity is 367.0640499942563
At time: 251.51429986953735 and batch: 650, loss is 5.9428009510040285 and perplexity is 381.0006004097349
At time: 252.53592491149902 and batch: 700, loss is 5.943345184326172 and perplexity is 381.2080100667385
At time: 253.55752849578857 and batch: 750, loss is 5.9275218105316165 and perplexity is 375.2234857785297
At time: 254.57814002037048 and batch: 800, loss is 5.89697811126709 and perplexity is 363.9360303031525
At time: 255.5985758304596 and batch: 850, loss is 5.9047496795654295 and perplexity is 366.7754029171278
At time: 256.6207649707794 and batch: 900, loss is 5.946850986480713 and perplexity is 382.5467953166541
At time: 257.6407814025879 and batch: 950, loss is 5.917948160171509 and perplexity is 371.6483680885096
At time: 258.65970754623413 and batch: 1000, loss is 5.932362833023071 and perplexity is 377.04435499083087
At time: 259.68227648735046 and batch: 1050, loss is 5.9106962108612064 and perplexity is 368.96294201778727
At time: 260.70295000076294 and batch: 1100, loss is 5.905784492492676 and perplexity is 367.1551432916999
At time: 261.7488453388214 and batch: 1150, loss is 5.907099342346191 and perplexity is 367.6382146916585
At time: 262.76952481269836 and batch: 1200, loss is 5.897158727645874 and perplexity is 364.00176904762344
At time: 263.791068315506 and batch: 1250, loss is 5.912682580947876 and perplexity is 369.69656735339163
At time: 264.81183648109436 and batch: 1300, loss is 5.878120422363281 and perplexity is 357.1373431005321
At time: 265.83033418655396 and batch: 1350, loss is 5.881844053268432 and perplexity is 358.4696697555996
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.6051033528645835 and perplexity of 271.81001632645683
Finished 9 epochs...
Completing Train Step...
At time: 268.91810178756714 and batch: 50, loss is 5.9275400257110595 and perplexity is 375.23032060390295
At time: 269.93667578697205 and batch: 100, loss is 5.951366186141968 and perplexity is 384.27797584902424
At time: 270.9582939147949 and batch: 150, loss is 5.904387092590332 and perplexity is 366.6424390401854
At time: 271.97724890708923 and batch: 200, loss is 5.898458442687988 and perplexity is 364.4751752021186
At time: 272.9973373413086 and batch: 250, loss is 5.930562305450439 and perplexity is 376.3660870368807
At time: 274.0197768211365 and batch: 300, loss is 5.941196346282959 and perplexity is 380.3897352771941
At time: 275.0399069786072 and batch: 350, loss is 5.949969425201416 and perplexity is 383.741606059432
At time: 276.0620148181915 and batch: 400, loss is 5.981513900756836 and perplexity is 396.0394790107215
At time: 277.0823311805725 and batch: 450, loss is 5.961421709060669 and perplexity is 388.1615849788986
At time: 278.10203886032104 and batch: 500, loss is 5.971694087982177 and perplexity is 392.169477916775
At time: 279.12279987335205 and batch: 550, loss is 5.943676862716675 and perplexity is 381.33446949673504
At time: 280.14353251457214 and batch: 600, loss is 5.889599370956421 and perplexity is 361.26052391842074
At time: 281.16460514068604 and batch: 650, loss is 5.926750068664551 and perplexity is 374.9340218151445
At time: 282.1859974861145 and batch: 700, loss is 5.928839149475098 and perplexity is 375.7181080098886
At time: 283.20531940460205 and batch: 750, loss is 5.914293785095214 and perplexity is 370.29270411601726
At time: 284.2254989147186 and batch: 800, loss is 5.888499822616577 and perplexity is 360.86351881224635
At time: 285.24703311920166 and batch: 850, loss is 5.893914852142334 and perplexity is 362.8229057024663
At time: 286.26787185668945 and batch: 900, loss is 5.938710622787475 and perplexity is 379.4453657817537
At time: 287.3144850730896 and batch: 950, loss is 5.909159841537476 and perplexity is 368.39651390488405
At time: 288.33383107185364 and batch: 1000, loss is 5.925023765563965 and perplexity is 374.2873304040655
At time: 289.3540949821472 and batch: 1050, loss is 5.90557279586792 and perplexity is 367.07742601363645
At time: 290.3744993209839 and batch: 1100, loss is 5.899999618530273 and perplexity is 365.0373286146123
At time: 291.40330052375793 and batch: 1150, loss is 5.901622762680054 and perplexity is 365.63031794239305
At time: 292.42628169059753 and batch: 1200, loss is 5.88804027557373 and perplexity is 360.6977231476764
At time: 293.44888186454773 and batch: 1250, loss is 5.9012532138824465 and perplexity is 365.49522466134584
At time: 294.46737265586853 and batch: 1300, loss is 5.867149734497071 and perplexity is 353.24071421543084
At time: 295.4859313964844 and batch: 1350, loss is 5.86767882347107 and perplexity is 353.4276594334555
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.589122721354166 and perplexity of 267.5008439686745
Finished 10 epochs...
Completing Train Step...
At time: 298.5871479511261 and batch: 50, loss is 5.912935438156128 and perplexity is 369.7900596149111
At time: 299.60673117637634 and batch: 100, loss is 5.937436552047729 and perplexity is 378.9622333816601
At time: 300.62765073776245 and batch: 150, loss is 5.89309211730957 and perplexity is 362.5245214222219
At time: 301.6486120223999 and batch: 200, loss is 5.886729936599732 and perplexity is 360.225396384868
At time: 302.670086145401 and batch: 250, loss is 5.921245565414429 and perplexity is 372.87586603284285
At time: 303.6910331249237 and batch: 300, loss is 5.934979448318481 and perplexity is 378.03222689387707
At time: 304.7125599384308 and batch: 350, loss is 5.942169094085694 and perplexity is 380.75993858440285
At time: 305.73282837867737 and batch: 400, loss is 5.974996404647827 and perplexity is 393.4666864372468
At time: 306.75455045700073 and batch: 450, loss is 5.955110321044922 and perplexity is 385.71946130488027
At time: 307.7749722003937 and batch: 500, loss is 5.963433151245117 and perplexity is 388.94313532346723
At time: 308.804505109787 and batch: 550, loss is 5.935568561553955 and perplexity is 378.25499629393425
At time: 309.82437229156494 and batch: 600, loss is 5.883430051803589 and perplexity is 359.0386532109253
At time: 310.84472465515137 and batch: 650, loss is 5.921649551391601 and perplexity is 373.02653308558524
At time: 311.8648724555969 and batch: 700, loss is 5.921994342803955 and perplexity is 373.1551716062274
At time: 312.8852114677429 and batch: 750, loss is 5.906886987686157 and perplexity is 367.5601532922064
At time: 313.931871175766 and batch: 800, loss is 5.877684469223023 and perplexity is 356.9816818872665
At time: 314.9516124725342 and batch: 850, loss is 5.8838301849365235 and perplexity is 359.18234521812866
At time: 315.97738671302795 and batch: 900, loss is 5.926930255889893 and perplexity is 375.0015862231606
At time: 317.00318002700806 and batch: 950, loss is 5.8966165542602536 and perplexity is 363.80447046598
At time: 318.0308873653412 and batch: 1000, loss is 5.909226493835449 and perplexity is 368.4210691974254
At time: 319.051340341568 and batch: 1050, loss is 5.891352005004883 and perplexity is 361.89423658398687
At time: 320.0745847225189 and batch: 1100, loss is 5.888092584609986 and perplexity is 360.7165913914393
At time: 321.11025190353394 and batch: 1150, loss is 5.887291822433472 and perplexity is 360.4278588071068
At time: 322.13871121406555 and batch: 1200, loss is 5.877783765792847 and perplexity is 357.01713070371187
At time: 323.1702973842621 and batch: 1250, loss is 5.89144609451294 and perplexity is 361.928288636621
At time: 324.1907284259796 and batch: 1300, loss is 5.856590337753296 and perplexity is 349.53032955568216
At time: 325.21061873435974 and batch: 1350, loss is 5.858122940063477 and perplexity is 350.06643125665397
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.592024332682292 and perplexity of 268.2781546291554
Annealing...
Finished 11 epochs...
Completing Train Step...
At time: 328.2760317325592 and batch: 50, loss is 5.902355337142945 and perplexity is 365.8982675106986
At time: 329.32386660575867 and batch: 100, loss is 5.920399312973022 and perplexity is 372.5604523994731
At time: 330.3447184562683 and batch: 150, loss is 5.8758627128601075 and perplexity is 356.3319402520201
At time: 331.36627197265625 and batch: 200, loss is 5.874881267547607 and perplexity is 355.9823914991163
At time: 332.3888669013977 and batch: 250, loss is 5.894550609588623 and perplexity is 363.0536464062392
At time: 333.4107677936554 and batch: 300, loss is 5.9123500537872316 and perplexity is 369.5736536407562
At time: 334.4330806732178 and batch: 350, loss is 5.913784999847412 and perplexity is 370.10435257010107
At time: 335.4571051597595 and batch: 400, loss is 5.944902334213257 and perplexity is 381.8020704770846
At time: 336.47918820381165 and batch: 450, loss is 5.919065504074097 and perplexity is 372.0638592065068
At time: 337.5004003047943 and batch: 500, loss is 5.927961225509644 and perplexity is 375.3884008287063
At time: 338.52267694473267 and batch: 550, loss is 5.896083116531372 and perplexity is 363.6104551876331
At time: 339.5433747768402 and batch: 600, loss is 5.845474948883057 and perplexity is 345.6666768021801
At time: 340.5896542072296 and batch: 650, loss is 5.8727756786346434 and perplexity is 355.23362749359694
At time: 341.60964608192444 and batch: 700, loss is 5.868053121566772 and perplexity is 353.5599714938815
At time: 342.6322000026703 and batch: 750, loss is 5.854456806182862 and perplexity is 348.7853905208027
At time: 343.65224170684814 and batch: 800, loss is 5.828111915588379 and perplexity is 339.716659439789
At time: 344.67433166503906 and batch: 850, loss is 5.813705968856811 and perplexity is 334.8578015938592
At time: 345.6947190761566 and batch: 900, loss is 5.8499417400360105 and perplexity is 347.2141512055161
At time: 346.71614265441895 and batch: 950, loss is 5.817989292144776 and perplexity is 336.29518199844586
At time: 347.73659014701843 and batch: 1000, loss is 5.833277959823608 and perplexity is 341.47619172751496
At time: 348.75960898399353 and batch: 1050, loss is 5.808919076919556 and perplexity is 333.2587038907538
At time: 349.7804958820343 and batch: 1100, loss is 5.792940340042114 and perplexity is 327.9759688641858
At time: 350.80295634269714 and batch: 1150, loss is 5.782813568115234 and perplexity is 324.67139162076387
At time: 351.8255248069763 and batch: 1200, loss is 5.761594200134278 and perplexity is 317.85464914707956
At time: 352.8527572154999 and batch: 1250, loss is 5.76816798210144 and perplexity is 319.9510393643731
At time: 353.8751971721649 and batch: 1300, loss is 5.746244211196899 and perplexity is 313.01283972890667
At time: 354.8948218822479 and batch: 1350, loss is 5.758285055160522 and perplexity is 316.8045604385998
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.507481282552083 and perplexity of 246.52940650949466
Finished 12 epochs...
Completing Train Step...
At time: 358.00057101249695 and batch: 50, loss is 5.8507169818878175 and perplexity is 347.4834305118779
At time: 359.02216124534607 and batch: 100, loss is 5.873044548034668 and perplexity is 355.32915178709385
At time: 360.0458130836487 and batch: 150, loss is 5.832405605316162 and perplexity is 341.1784333268005
At time: 361.0659625530243 and batch: 200, loss is 5.834482583999634 and perplexity is 341.8877900644878
At time: 362.08949398994446 and batch: 250, loss is 5.854761352539063 and perplexity is 348.891628016882
At time: 363.11068987846375 and batch: 300, loss is 5.876171770095826 and perplexity is 356.4420842359933
At time: 364.13251638412476 and batch: 350, loss is 5.877755174636841 and perplexity is 357.0069233171522
At time: 365.1548752784729 and batch: 400, loss is 5.909911956787109 and perplexity is 368.6736947638129
At time: 366.21440982818604 and batch: 450, loss is 5.885731983184814 and perplexity is 359.8660875369716
At time: 367.2352271080017 and batch: 500, loss is 5.8967099857330325 and perplexity is 363.8384628414133
At time: 368.25981521606445 and batch: 550, loss is 5.8685285758972165 and perplexity is 353.72811308205564
At time: 369.2873787879944 and batch: 600, loss is 5.816765718460083 and perplexity is 335.88395170005475
At time: 370.30804657936096 and batch: 650, loss is 5.8459522151947025 and perplexity is 345.83169123685934
At time: 371.3297486305237 and batch: 700, loss is 5.8444147872924805 and perplexity is 345.3004084544147
At time: 372.35039043426514 and batch: 750, loss is 5.829093904495239 and perplexity is 340.0504212792257
At time: 373.3729703426361 and batch: 800, loss is 5.802850999832153 and perplexity is 331.242587546569
At time: 374.39348888397217 and batch: 850, loss is 5.793858480453491 and perplexity is 328.27723513636664
At time: 375.414959192276 and batch: 900, loss is 5.833525362014771 and perplexity is 341.560684136951
At time: 376.4455621242523 and batch: 950, loss is 5.804256334304809 and perplexity is 331.7084214231955
At time: 377.46843242645264 and batch: 1000, loss is 5.82189938545227 and perplexity is 337.6127016727404
At time: 378.4901645183563 and batch: 1050, loss is 5.80024941444397 and perplexity is 330.3819516651468
At time: 379.5126905441284 and batch: 1100, loss is 5.789305248260498 and perplexity is 326.78591041149224
At time: 380.53317165374756 and batch: 1150, loss is 5.782966299057007 and perplexity is 324.7209827751283
At time: 381.5546963214874 and batch: 1200, loss is 5.765710344314575 and perplexity is 319.1656810585048
At time: 382.576548576355 and batch: 1250, loss is 5.778630561828614 and perplexity is 323.31612566768064
At time: 383.59898018836975 and batch: 1300, loss is 5.755406837463379 and perplexity is 315.8940389143659
At time: 384.6195797920227 and batch: 1350, loss is 5.761227741241455 and perplexity is 317.738189824355
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.499501139322916 and perplexity of 244.56989552341057
Finished 13 epochs...
Completing Train Step...
At time: 387.69440937042236 and batch: 50, loss is 5.840817079544068 and perplexity is 344.0603505199651
At time: 388.74141669273376 and batch: 100, loss is 5.858471555709839 and perplexity is 350.18849116661715
At time: 389.7618234157562 and batch: 150, loss is 5.8164942264556885 and perplexity is 335.79277427029547
At time: 390.78468680381775 and batch: 200, loss is 5.818594932556152 and perplexity is 336.4989176398567
At time: 391.806205034256 and batch: 250, loss is 5.838539876937866 and perplexity is 343.2777468048728
At time: 392.85349702835083 and batch: 300, loss is 5.860087184906006 and perplexity is 350.7547232044462
At time: 393.8764431476593 and batch: 350, loss is 5.861883430480957 and perplexity is 351.38533101758776
At time: 394.8993628025055 and batch: 400, loss is 5.893954019546509 and perplexity is 362.83711681216226
At time: 395.9207799434662 and batch: 450, loss is 5.8711115264892575 and perplexity is 354.64295630996617
At time: 396.9429552555084 and batch: 500, loss is 5.8823244094848635 and perplexity is 358.6419042535128
At time: 397.9642024040222 and batch: 550, loss is 5.854844570159912 and perplexity is 348.9206631562007
At time: 398.9858055114746 and batch: 600, loss is 5.803885860443115 and perplexity is 331.5855548841803
At time: 400.0079834461212 and batch: 650, loss is 5.833138065338135 and perplexity is 341.4284244326404
At time: 401.0306477546692 and batch: 700, loss is 5.833877086639404 and perplexity is 341.68084057011805
At time: 402.0521502494812 and batch: 750, loss is 5.817433404922485 and perplexity is 336.10829175361715
At time: 403.07460832595825 and batch: 800, loss is 5.791128034591675 and perplexity is 327.3821145134789
At time: 404.0963981151581 and batch: 850, loss is 5.783780965805054 and perplexity is 324.9856299471771
At time: 405.12658643722534 and batch: 900, loss is 5.825128726959228 and perplexity is 338.7047307018317
At time: 406.14937138557434 and batch: 950, loss is 5.795968046188355 and perplexity is 328.97048851783865
At time: 407.1705801486969 and batch: 1000, loss is 5.8164713668823245 and perplexity is 335.7850982784722
At time: 408.1902196407318 and batch: 1050, loss is 5.797329835891723 and perplexity is 329.4187823134729
At time: 409.2119116783142 and batch: 1100, loss is 5.787987833023071 and perplexity is 326.3556811312693
At time: 410.23335695266724 and batch: 1150, loss is 5.782406301498413 and perplexity is 324.5391907238532
At time: 411.2558798789978 and batch: 1200, loss is 5.7665056705474855 and perplexity is 319.41962286720053
At time: 412.2986013889313 and batch: 1250, loss is 5.779248371124267 and perplexity is 323.51593509125706
At time: 413.32659363746643 and batch: 1300, loss is 5.754847946166993 and perplexity is 315.7175378124953
At time: 414.34668803215027 and batch: 1350, loss is 5.759204177856446 and perplexity is 317.09587655739085
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.496846516927083 and perplexity of 243.92151578385838
Finished 14 epochs...
Completing Train Step...
At time: 417.43515968322754 and batch: 50, loss is 5.833108053207398 and perplexity is 341.4181775918945
At time: 418.4825711250305 and batch: 100, loss is 5.849825277328491 and perplexity is 347.1737160600165
At time: 419.5043525695801 and batch: 150, loss is 5.807451000213623 and perplexity is 332.7698135026246
At time: 420.52573227882385 and batch: 200, loss is 5.808644876480103 and perplexity is 333.16733673472515
At time: 421.5494408607483 and batch: 250, loss is 5.829048957824707 and perplexity is 340.0351374884565
At time: 422.57164883613586 and batch: 300, loss is 5.851470279693603 and perplexity is 347.7452876334442
At time: 423.5935995578766 and batch: 350, loss is 5.8538650703430175 and perplexity is 348.5790627566044
At time: 424.61700105667114 and batch: 400, loss is 5.88525619506836 and perplexity is 359.6949082547698
At time: 425.6391134262085 and batch: 450, loss is 5.8628418922424315 and perplexity is 351.722281872371
At time: 426.6597852706909 and batch: 500, loss is 5.874820384979248 and perplexity is 355.9607190365755
At time: 427.6815764904022 and batch: 550, loss is 5.84669454574585 and perplexity is 346.08850797648194
At time: 428.7052993774414 and batch: 600, loss is 5.796449613571167 and perplexity is 329.1289481264439
At time: 429.7274296283722 and batch: 650, loss is 5.825771789550782 and perplexity is 338.92260909094074
At time: 430.7505440711975 and batch: 700, loss is 5.827651777267456 and perplexity is 339.5603787446505
At time: 431.77224946022034 and batch: 750, loss is 5.810839643478394 and perplexity is 333.8993644315662
At time: 432.79401683807373 and batch: 800, loss is 5.784968824386596 and perplexity is 325.37189628606177
At time: 433.8157937526703 and batch: 850, loss is 5.777873497009278 and perplexity is 323.0714470338929
At time: 434.8376684188843 and batch: 900, loss is 5.821180582046509 and perplexity is 337.37011171064023
At time: 435.8589656352997 and batch: 950, loss is 5.792763519287109 and perplexity is 327.9179810326249
At time: 436.8794937133789 and batch: 1000, loss is 5.813726129531861 and perplexity is 334.8645526212373
At time: 437.90417551994324 and batch: 1050, loss is 5.795581941604614 and perplexity is 328.8434960220765
At time: 438.9280068874359 and batch: 1100, loss is 5.786165838241577 and perplexity is 325.76160415026146
At time: 439.94969391822815 and batch: 1150, loss is 5.781607303619385 and perplexity is 324.2799881637408
At time: 440.9726252555847 and batch: 1200, loss is 5.765990972518921 and perplexity is 319.25526051914267
At time: 441.99453949928284 and batch: 1250, loss is 5.778976259231567 and perplexity is 323.427914534104
At time: 443.01620078086853 and batch: 1300, loss is 5.753750019073486 and perplexity is 315.37109319410393
At time: 444.0371181964874 and batch: 1350, loss is 5.755723657608033 and perplexity is 315.994136365077
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.492570393880208 and perplexity of 242.8807042735855
Finished 15 epochs...
Completing Train Step...
At time: 447.1273236274719 and batch: 50, loss is 5.8250399017333985 and perplexity is 338.6746465137747
At time: 448.14594411849976 and batch: 100, loss is 5.841933708190918 and perplexity is 344.4447527409258
At time: 449.166437625885 and batch: 150, loss is 5.800256261825561 and perplexity is 330.3842139241861
At time: 450.18691778182983 and batch: 200, loss is 5.800467510223388 and perplexity is 330.4540144324081
At time: 451.2101573944092 and batch: 250, loss is 5.822047910690308 and perplexity is 337.6628494036304
At time: 452.230961561203 and batch: 300, loss is 5.844517946243286 and perplexity is 345.33603111963043
At time: 453.2537717819214 and batch: 350, loss is 5.847823905944824 and perplexity is 346.47958735588884
At time: 454.27423119544983 and batch: 400, loss is 5.879614324569702 and perplexity is 357.6712700834351
At time: 455.29617714881897 and batch: 450, loss is 5.857363443374634 and perplexity is 349.800657901007
At time: 456.31751012802124 and batch: 500, loss is 5.8702653217315675 and perplexity is 354.34298269050737
At time: 457.33991837501526 and batch: 550, loss is 5.841656761169434 and perplexity is 344.34937300076524
At time: 458.3620409965515 and batch: 600, loss is 5.792418069839478 and perplexity is 327.8047215110547
At time: 459.38443899154663 and batch: 650, loss is 5.822173490524292 and perplexity is 337.70525571083385
At time: 460.405996799469 and batch: 700, loss is 5.824225244522094 and perplexity is 338.3988551236815
At time: 461.43998074531555 and batch: 750, loss is 5.807926998138428 and perplexity is 332.9282489477696
At time: 462.46533823013306 and batch: 800, loss is 5.781539049148559 and perplexity is 324.2578553600894
At time: 463.49513959884644 and batch: 850, loss is 5.774750356674194 and perplexity is 322.0640235478771
At time: 464.5320680141449 and batch: 900, loss is 5.818968687057495 and perplexity is 336.6247091311253
At time: 465.56328105926514 and batch: 950, loss is 5.790814437866211 and perplexity is 327.2794646505637
At time: 466.59119486808777 and batch: 1000, loss is 5.812989683151245 and perplexity is 334.61803361861814
At time: 467.617502450943 and batch: 1050, loss is 5.7957346057891845 and perplexity is 328.8937024785144
At time: 468.6436047554016 and batch: 1100, loss is 5.786505212783814 and perplexity is 325.87217810748
At time: 469.66490721702576 and batch: 1150, loss is 5.781848068237305 and perplexity is 324.358072710811
At time: 470.7290189266205 and batch: 1200, loss is 5.766807870864868 and perplexity is 319.5161661655822
At time: 471.75108528137207 and batch: 1250, loss is 5.779053659439087 and perplexity is 323.4529488906263
At time: 472.776326417923 and batch: 1300, loss is 5.752890005111694 and perplexity is 315.0999862454016
At time: 473.7966606616974 and batch: 1350, loss is 5.7546045684814455 and perplexity is 315.64070855849815
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.490585123697917 and perplexity of 242.39899876953626
Finished 16 epochs...
Completing Train Step...
At time: 476.86860847473145 and batch: 50, loss is 5.8216828346252445 and perplexity is 337.53959927845636
At time: 477.9126932621002 and batch: 100, loss is 5.83818247795105 and perplexity is 343.1550816074825
At time: 478.933554649353 and batch: 150, loss is 5.796879253387451 and perplexity is 329.27038540861895
At time: 479.9536862373352 and batch: 200, loss is 5.7961344909667964 and perplexity is 329.02524849504357
At time: 480.97458386421204 and batch: 250, loss is 5.818296375274659 and perplexity is 336.39846843344765
At time: 481.99669313430786 and batch: 300, loss is 5.840507440567016 and perplexity is 343.9538325169
At time: 483.01771211624146 and batch: 350, loss is 5.843741760253907 and perplexity is 345.06809013012054
At time: 484.03666257858276 and batch: 400, loss is 5.8749327468872075 and perplexity is 356.0007177092465
At time: 485.0590133666992 and batch: 450, loss is 5.852712917327881 and perplexity is 348.17767761139027
At time: 486.0801067352295 and batch: 500, loss is 5.866436014175415 and perplexity is 352.98868908768503
At time: 487.1009569168091 and batch: 550, loss is 5.838440351486206 and perplexity is 343.2435836321578
At time: 488.13301515579224 and batch: 600, loss is 5.789851770401001 and perplexity is 326.9645549588903
At time: 489.1540241241455 and batch: 650, loss is 5.819535169601441 and perplexity is 336.81545517475985
At time: 490.1746726036072 and batch: 700, loss is 5.822137651443481 and perplexity is 337.6931528817627
At time: 491.19725036621094 and batch: 750, loss is 5.805756950378418 and perplexity is 332.20656207759293
At time: 492.2181873321533 and batch: 800, loss is 5.779396047592163 and perplexity is 323.5637143097057
At time: 493.2392888069153 and batch: 850, loss is 5.7727752113342286 and perplexity is 321.4285280971345
At time: 494.26124119758606 and batch: 900, loss is 5.817317838668823 and perplexity is 336.0694512218851
At time: 495.2824466228485 and batch: 950, loss is 5.789580430984497 and perplexity is 326.87584862263714
At time: 496.30298924446106 and batch: 1000, loss is 5.811950073242188 and perplexity is 334.2703421581779
At time: 497.34933066368103 and batch: 1050, loss is 5.794526882171631 and perplexity is 328.49672955140824
At time: 498.3700478076935 and batch: 1100, loss is 5.785623960494995 and perplexity is 325.58512900457686
At time: 499.38952112197876 and batch: 1150, loss is 5.781320209503174 and perplexity is 324.18690264992506
At time: 500.4111297130585 and batch: 1200, loss is 5.766613187789917 and perplexity is 319.4539678305346
At time: 501.43461561203003 and batch: 1250, loss is 5.779212141036988 and perplexity is 323.50421429301645
At time: 502.4647169113159 and batch: 1300, loss is 5.75296537399292 and perplexity is 315.12373587381944
At time: 503.4864478111267 and batch: 1350, loss is 5.753298397064209 and perplexity is 315.2286968244153
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.488740641276042 and perplexity of 241.95231015851178
Finished 17 epochs...
Completing Train Step...
At time: 506.5763990879059 and batch: 50, loss is 5.818472661972046 and perplexity is 336.4577762358887
At time: 507.5955183506012 and batch: 100, loss is 5.834879684448242 and perplexity is 342.02358081879635
At time: 508.6222176551819 and batch: 150, loss is 5.793440656661987 and perplexity is 328.14010174810863
At time: 509.64251470565796 and batch: 200, loss is 5.792421188354492 and perplexity is 327.80574377659445
At time: 510.66368341445923 and batch: 250, loss is 5.813837928771973 and perplexity is 334.90199231658653
At time: 511.6856825351715 and batch: 300, loss is 5.837170581817627 and perplexity is 342.80801993203727
At time: 512.7071504592896 and batch: 350, loss is 5.840230560302734 and perplexity is 343.85861167184646
At time: 513.7281949520111 and batch: 400, loss is 5.870841054916382 and perplexity is 354.5470484425244
At time: 514.7490222454071 and batch: 450, loss is 5.848675851821899 and perplexity is 346.7748949870254
At time: 515.769805431366 and batch: 500, loss is 5.862573137283325 and perplexity is 351.6277674660663
At time: 516.791440486908 and batch: 550, loss is 5.83500491142273 and perplexity is 342.0664140789096
At time: 517.8125700950623 and batch: 600, loss is 5.786327018737793 and perplexity is 325.8141147989989
At time: 518.8346538543701 and batch: 650, loss is 5.816134939193725 and perplexity is 335.6721498745429
At time: 519.8557071685791 and batch: 700, loss is 5.819509735107422 and perplexity is 336.8068885530242
At time: 520.8773436546326 and batch: 750, loss is 5.802664070129395 and perplexity is 331.18067425503483
At time: 521.8984634876251 and batch: 800, loss is 5.7770483016967775 and perplexity is 322.80495995726307
At time: 522.954347372055 and batch: 850, loss is 5.769413814544678 and perplexity is 320.3498931503659
At time: 523.9753465652466 and batch: 900, loss is 5.814216527938843 and perplexity is 335.0288099368687
At time: 524.9988167285919 and batch: 950, loss is 5.786713333129883 and perplexity is 325.9400057958781
At time: 526.0199558734894 and batch: 1000, loss is 5.8093242359161374 and perplexity is 333.39375400936217
At time: 527.0400230884552 and batch: 1050, loss is 5.7911739158630375 and perplexity is 327.397135565704
At time: 528.0613367557526 and batch: 1100, loss is 5.782788200378418 and perplexity is 324.6631555468153
At time: 529.0817558765411 and batch: 1150, loss is 5.7787926197052 and perplexity is 323.36852583828806
At time: 530.1028988361359 and batch: 1200, loss is 5.764625225067139 and perplexity is 318.81953607312505
At time: 531.1268627643585 and batch: 1250, loss is 5.776662549972534 and perplexity is 322.6804614016753
At time: 532.1490697860718 and batch: 1300, loss is 5.7503562259674075 and perplexity is 314.30260309488887
At time: 533.1699724197388 and batch: 1350, loss is 5.749577102661132 and perplexity is 314.05781798287035
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.48427490234375 and perplexity of 240.87422332612292
Finished 18 epochs...
Completing Train Step...
At time: 536.2698814868927 and batch: 50, loss is 5.813454303741455 and perplexity is 334.77354016986845
At time: 537.2920026779175 and batch: 100, loss is 5.829733295440674 and perplexity is 340.2679159642393
At time: 538.313622713089 and batch: 150, loss is 5.788665361404419 and perplexity is 326.57687129049384
At time: 539.3350880146027 and batch: 200, loss is 5.787810516357422 and perplexity is 326.2978179602793
At time: 540.355535030365 and batch: 250, loss is 5.811191701889038 and perplexity is 334.01693720615094
At time: 541.3762891292572 and batch: 300, loss is 5.833332529067993 and perplexity is 341.4948263337067
At time: 542.4001739025116 and batch: 350, loss is 5.835891284942627 and perplexity is 342.3697471037161
At time: 543.4209325313568 and batch: 400, loss is 5.866861896514893 and perplexity is 353.13905275274493
At time: 544.443107843399 and batch: 450, loss is 5.844860048294067 and perplexity is 345.4541914943859
At time: 545.4633436203003 and batch: 500, loss is 5.858948335647583 and perplexity is 350.35549382222877
At time: 546.4859499931335 and batch: 550, loss is 5.831610612869262 and perplexity is 340.90730683529665
At time: 547.5079231262207 and batch: 600, loss is 5.783651647567749 and perplexity is 324.94360609564654
At time: 548.5298657417297 and batch: 650, loss is 5.814036903381347 and perplexity is 334.96863593966106
At time: 549.5765790939331 and batch: 700, loss is 5.817311887741089 and perplexity is 336.0674513028178
At time: 550.6061894893646 and batch: 750, loss is 5.800911149978638 and perplexity is 330.60064949465857
At time: 551.6270000934601 and batch: 800, loss is 5.774825534820557 and perplexity is 322.08823663431355
At time: 552.6492278575897 and batch: 850, loss is 5.767201910018921 and perplexity is 319.6420928537977
At time: 553.6699364185333 and batch: 900, loss is 5.8114195728302 and perplexity is 334.09305863259715
At time: 554.6924412250519 and batch: 950, loss is 5.785120830535889 and perplexity is 325.421358574295
At time: 555.7143447399139 and batch: 1000, loss is 5.808153772354126 and perplexity is 333.0037570516305
At time: 556.7358229160309 and batch: 1050, loss is 5.790182189941406 and perplexity is 327.07260828735104
At time: 557.756326675415 and batch: 1100, loss is 5.781352901458741 and perplexity is 324.1975011269833
At time: 558.7756369113922 and batch: 1150, loss is 5.775342435836792 and perplexity is 322.2547674074022
At time: 559.7986283302307 and batch: 1200, loss is 5.763312835693359 and perplexity is 318.40139514370145
At time: 560.8193237781525 and batch: 1250, loss is 5.774725999832153 and perplexity is 322.05617918086085
At time: 561.8429067134857 and batch: 1300, loss is 5.747814807891846 and perplexity is 313.5048429286221
At time: 562.8633589744568 and batch: 1350, loss is 5.745904655456543 and perplexity is 312.90657246522227
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.480128987630208 and perplexity of 239.87764662800035
Finished 19 epochs...
Completing Train Step...
At time: 565.9357616901398 and batch: 50, loss is 5.808952045440674 and perplexity is 333.26969111848626
At time: 566.990784406662 and batch: 100, loss is 5.825561437606812 and perplexity is 338.851323559051
At time: 568.0143594741821 and batch: 150, loss is 5.785094413757324 and perplexity is 325.4127621038714
At time: 569.0356903076172 and batch: 200, loss is 5.784836187362671 and perplexity is 325.32874278800836
At time: 570.0583329200745 and batch: 250, loss is 5.807867155075074 and perplexity is 332.9083260976035
At time: 571.080112695694 and batch: 300, loss is 5.8295986938476565 and perplexity is 340.2221184429767
At time: 572.1029059886932 and batch: 350, loss is 5.832108039855957 and perplexity is 341.0769255126341
At time: 573.1251034736633 and batch: 400, loss is 5.86465015411377 and perplexity is 352.35886324343323
At time: 574.1478946208954 and batch: 450, loss is 5.842535648345947 and perplexity is 344.65215028298167
At time: 575.2062058448792 and batch: 500, loss is 5.856616382598877 and perplexity is 349.5394331376914
At time: 576.2278203964233 and batch: 550, loss is 5.829084148406983 and perplexity is 340.04710373348723
At time: 577.2501268386841 and batch: 600, loss is 5.78096905708313 and perplexity is 324.07308361959656
At time: 578.2725882530212 and batch: 650, loss is 5.810850038528442 and perplexity is 333.9028353502107
At time: 579.3046708106995 and batch: 700, loss is 5.814673118591308 and perplexity is 335.18181588767777
At time: 580.3379948139191 and batch: 750, loss is 5.799192171096802 and perplexity is 330.0328421241129
At time: 581.3634378910065 and batch: 800, loss is 5.77152834892273 and perplexity is 321.02800070063506
At time: 582.3841228485107 and batch: 850, loss is 5.765328893661499 and perplexity is 319.04395831811075
At time: 583.4063527584076 and batch: 900, loss is 5.808717088699341 and perplexity is 333.1913963561772
At time: 584.4278705120087 and batch: 950, loss is 5.782323417663574 and perplexity is 324.512292785888
At time: 585.4488408565521 and batch: 1000, loss is 5.8061982536315915 and perplexity is 332.3531982672973
At time: 586.4702951908112 and batch: 1050, loss is 5.788199405670166 and perplexity is 326.4247363714632
At time: 587.4906759262085 and batch: 1100, loss is 5.779716939926147 and perplexity is 323.6675600859487
At time: 588.5101854801178 and batch: 1150, loss is 5.773850688934326 and perplexity is 321.77440323627945
At time: 589.5334055423737 and batch: 1200, loss is 5.761567068099976 and perplexity is 317.8460252208287
At time: 590.5542507171631 and batch: 1250, loss is 5.773167219161987 and perplexity is 321.5545552964239
At time: 591.5845973491669 and batch: 1300, loss is 5.745619449615479 and perplexity is 312.81734240811943
At time: 592.6082968711853 and batch: 1350, loss is 5.7435165119171145 and perplexity is 312.16019823487153
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.4789131673177085 and perplexity of 239.58617573673524
Finished 20 epochs...
Completing Train Step...
At time: 595.7161636352539 and batch: 50, loss is 5.805825395584106 and perplexity is 332.2293008022347
At time: 596.7381272315979 and batch: 100, loss is 5.823018913269043 and perplexity is 337.9908801347138
At time: 597.760279417038 and batch: 150, loss is 5.782167997360229 and perplexity is 324.4618609060747
At time: 598.7816944122314 and batch: 200, loss is 5.782855415344239 and perplexity is 324.684978503125
At time: 599.8045010566711 and batch: 250, loss is 5.805444536209106 and perplexity is 332.10279225088755
At time: 600.8267259597778 and batch: 300, loss is 5.826655397415161 and perplexity is 339.2222161218203
At time: 601.8740797042847 and batch: 350, loss is 5.829234476089478 and perplexity is 340.09822606898547
At time: 602.896594285965 and batch: 400, loss is 5.861806316375732 and perplexity is 351.35823529694176
At time: 603.9173765182495 and batch: 450, loss is 5.839925298690796 and perplexity is 343.75366085731105
At time: 604.9379544258118 and batch: 500, loss is 5.854277772903442 and perplexity is 348.7229519179849
At time: 605.9598755836487 and batch: 550, loss is 5.82747953414917 and perplexity is 339.50189684286613
At time: 606.9831035137177 and batch: 600, loss is 5.779298791885376 and perplexity is 323.53224742217174
At time: 608.003915309906 and batch: 650, loss is 5.809348049163819 and perplexity is 333.4016932919315
At time: 609.025762796402 and batch: 700, loss is 5.813144750595093 and perplexity is 334.6699260050628
At time: 610.0478219985962 and batch: 750, loss is 5.797472848892212 and perplexity is 329.4658968508641
At time: 611.0681147575378 and batch: 800, loss is 5.769768590927124 and perplexity is 320.46356588958406
At time: 612.0901837348938 and batch: 850, loss is 5.763533306121826 and perplexity is 318.47160097458385
At time: 613.112133026123 and batch: 900, loss is 5.807702322006225 and perplexity is 332.85345631886884
At time: 614.1339910030365 and batch: 950, loss is 5.780875577926635 and perplexity is 324.0427909569855
At time: 615.1585650444031 and batch: 1000, loss is 5.805017805099487 and perplexity is 331.96110389140824
At time: 616.185289144516 and batch: 1050, loss is 5.786406307220459 and perplexity is 325.8399491299616
At time: 617.205988407135 and batch: 1100, loss is 5.778059024810791 and perplexity is 323.13139132968746
At time: 618.2262487411499 and batch: 1150, loss is 5.7724268341064455 and perplexity is 321.31656922067947
At time: 619.2488572597504 and batch: 1200, loss is 5.759920568466186 and perplexity is 317.32312245443865
At time: 620.2695055007935 and batch: 1250, loss is 5.771823673248291 and perplexity is 321.12282207926904
At time: 621.2910997867584 and batch: 1300, loss is 5.744164190292358 and perplexity is 312.36244313263353
At time: 622.3131854534149 and batch: 1350, loss is 5.741197013854981 and perplexity is 311.43698233317775
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.4775618489583335 and perplexity of 239.2626371898324
Finished 21 epochs...
Completing Train Step...
At time: 625.3783526420593 and batch: 50, loss is 5.803279781341553 and perplexity is 331.38464869765556
At time: 626.4256336688995 and batch: 100, loss is 5.820625791549682 and perplexity is 337.182993889144
At time: 627.4482514858246 and batch: 150, loss is 5.779689960479736 and perplexity is 323.65882783215255
At time: 628.4962294101715 and batch: 200, loss is 5.779905300140381 and perplexity is 323.72853191906063
At time: 629.5176453590393 and batch: 250, loss is 5.802169418334961 and perplexity is 331.0168956502624
At time: 630.5394883155823 and batch: 300, loss is 5.823566045761108 and perplexity is 338.17585652593976
At time: 631.5628206729889 and batch: 350, loss is 5.826456184387207 and perplexity is 339.1546453677082
At time: 632.5834510326385 and batch: 400, loss is 5.859218273162842 and perplexity is 350.4500806793846
At time: 633.6050832271576 and batch: 450, loss is 5.838001718521118 and perplexity is 343.0930586963349
At time: 634.6377754211426 and batch: 500, loss is 5.852218790054321 and perplexity is 348.00567602367533
At time: 635.6591820716858 and batch: 550, loss is 5.825479154586792 and perplexity is 338.8234429958751
At time: 636.681964635849 and batch: 600, loss is 5.777392091751099 and perplexity is 322.9159561705859
At time: 637.7045238018036 and batch: 650, loss is 5.807255916595459 and perplexity is 332.70490189519205
At time: 638.7249009609222 and batch: 700, loss is 5.81126953125 and perplexity is 334.04293454258885
At time: 639.7469253540039 and batch: 750, loss is 5.795869569778443 and perplexity is 328.93809428022274
At time: 640.7683055400848 and batch: 800, loss is 5.768038673400879 and perplexity is 319.9096695860234
At time: 641.7903258800507 and batch: 850, loss is 5.761957912445069 and perplexity is 317.97027782252815
At time: 642.8113694190979 and batch: 900, loss is 5.805692844390869 and perplexity is 332.1852663304603
At time: 643.8419737815857 and batch: 950, loss is 5.778631887435913 and perplexity is 323.31655425818093
At time: 644.8654267787933 and batch: 1000, loss is 5.8026575756073 and perplexity is 331.17852340181275
At time: 645.8867568969727 and batch: 1050, loss is 5.78451563835144 and perplexity is 325.2244756934326
At time: 646.9155054092407 and batch: 1100, loss is 5.775753650665283 and perplexity is 322.38731059630686
At time: 647.9434657096863 and batch: 1150, loss is 5.770096426010132 and perplexity is 320.5686423122362
At time: 648.9750425815582 and batch: 1200, loss is 5.75806529045105 and perplexity is 316.7349456261353
At time: 649.9963972568512 and batch: 1250, loss is 5.770475568771363 and perplexity is 320.69020663610695
At time: 651.0205993652344 and batch: 1300, loss is 5.7424766731262205 and perplexity is 311.8357706571964
At time: 652.0456213951111 and batch: 1350, loss is 5.739200630187988 and perplexity is 310.815854839037
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.475991617838542 and perplexity of 238.88723436284772
Finished 22 epochs...
Completing Train Step...
At time: 655.1308836936951 and batch: 50, loss is 5.800384254455566 and perplexity is 330.4265033749496
At time: 656.1778254508972 and batch: 100, loss is 5.818071031570435 and perplexity is 336.3226716969551
At time: 657.1998784542084 and batch: 150, loss is 5.776902580261231 and perplexity is 322.75792378226924
At time: 658.2222580909729 and batch: 200, loss is 5.7770692729949955 and perplexity is 322.81172966732913
At time: 659.250726222992 and batch: 250, loss is 5.7987721824645995 and perplexity is 329.8942611854137
At time: 660.2739987373352 and batch: 300, loss is 5.819860916137696 and perplexity is 336.92518951446044
At time: 661.2953531742096 and batch: 350, loss is 5.823478517532348 and perplexity is 338.1462578875857
At time: 662.3158531188965 and batch: 400, loss is 5.856049432754516 and perplexity is 349.3413179764627
At time: 663.3385493755341 and batch: 450, loss is 5.8343541622161865 and perplexity is 341.8438870438613
At time: 664.3586468696594 and batch: 500, loss is 5.848707838058472 and perplexity is 346.7859871882517
At time: 665.3800268173218 and batch: 550, loss is 5.8214984703063966 and perplexity is 337.4773747563183
At time: 666.4021668434143 and batch: 600, loss is 5.773580675125122 and perplexity is 321.68753143277837
At time: 667.4254004955292 and batch: 650, loss is 5.801928253173828 and perplexity is 330.9370755325879
At time: 668.4458975791931 and batch: 700, loss is 5.805364055633545 and perplexity is 332.07606550252814
At time: 669.4673099517822 and batch: 750, loss is 5.790645990371704 and perplexity is 327.2243398876842
At time: 670.4885404109955 and batch: 800, loss is 5.76277153968811 and perplexity is 318.22909237805095
At time: 671.5102896690369 and batch: 850, loss is 5.75642466545105 and perplexity is 316.21572839281663
At time: 672.5311524868011 and batch: 900, loss is 5.799765501022339 and perplexity is 330.2221140813666
At time: 673.5526773929596 and batch: 950, loss is 5.7722507762908934 and perplexity is 321.2600039069307
At time: 674.5766005516052 and batch: 1000, loss is 5.7954152488708495 and perplexity is 328.7886847691896
At time: 675.5970261096954 and batch: 1050, loss is 5.778372840881348 and perplexity is 323.2328110659274
At time: 676.6218845844269 and batch: 1100, loss is 5.769530563354492 and perplexity is 320.38729580243046
At time: 677.6528797149658 and batch: 1150, loss is 5.763740720748902 and perplexity is 318.53766349386365
At time: 678.6834623813629 and batch: 1200, loss is 5.752143249511719 and perplexity is 314.8647714010525
At time: 679.7422852516174 and batch: 1250, loss is 5.764100360870361 and perplexity is 318.6522430203144
At time: 680.7768182754517 and batch: 1300, loss is 5.735426826477051 and perplexity is 309.64510728779624
At time: 681.8067243099213 and batch: 1350, loss is 5.7313539505004885 and perplexity is 308.38652593176045
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.469295654296875 and perplexity of 237.292997583247
Finished 23 epochs...
Completing Train Step...
At time: 684.9333612918854 and batch: 50, loss is 5.793044185638427 and perplexity is 328.0100294927414
At time: 685.9595081806183 and batch: 100, loss is 5.810199718475342 and perplexity is 333.6857622317468
At time: 686.9872922897339 and batch: 150, loss is 5.7683659934997555 and perplexity is 320.01439958988647
At time: 688.0115978717804 and batch: 200, loss is 5.768460073471069 and perplexity is 320.04450795169464
At time: 689.0360820293427 and batch: 250, loss is 5.789978313446045 and perplexity is 327.00593266727145
At time: 690.0608801841736 and batch: 300, loss is 5.81068678855896 and perplexity is 333.8483301716352
At time: 691.0873024463654 and batch: 350, loss is 5.814752874374389 and perplexity is 335.20854964194996
At time: 692.1130790710449 and batch: 400, loss is 5.84666184425354 and perplexity is 346.07719055084925
At time: 693.1367750167847 and batch: 450, loss is 5.824169273376465 and perplexity is 338.37991508213344
At time: 694.1585912704468 and batch: 500, loss is 5.839705829620361 and perplexity is 343.6782258390337
At time: 695.1803376674652 and batch: 550, loss is 5.811501388549805 and perplexity is 334.12039381481264
At time: 696.2031350135803 and batch: 600, loss is 5.763567419052124 and perplexity is 318.48246515941315
At time: 697.2259323596954 and batch: 650, loss is 5.792322072982788 and perplexity is 327.7732547985585
At time: 698.2481610774994 and batch: 700, loss is 5.79484751701355 and perplexity is 328.6020739359964
At time: 699.2708036899567 and batch: 750, loss is 5.780601959228516 and perplexity is 323.95413891936954
At time: 700.2931799888611 and batch: 800, loss is 5.751673393249511 and perplexity is 314.7168649665644
At time: 701.31427693367 and batch: 850, loss is 5.744421052932739 and perplexity is 312.4426876800043
At time: 702.3357310295105 and batch: 900, loss is 5.787420825958252 and perplexity is 326.1706876056982
At time: 703.3567605018616 and batch: 950, loss is 5.760606756210327 and perplexity is 317.5409404154604
At time: 704.3811202049255 and batch: 1000, loss is 5.7825652122497555 and perplexity is 324.5907675884419
At time: 705.4022681713104 and batch: 1050, loss is 5.765670967102051 and perplexity is 319.15311345109154
At time: 706.4676215648651 and batch: 1100, loss is 5.755743465423584 and perplexity is 316.0003955806359
At time: 707.4946961402893 and batch: 1150, loss is 5.750214014053345 and perplexity is 314.25790869822106
At time: 708.5180497169495 and batch: 1200, loss is 5.738145618438721 and perplexity is 310.4881133762696
At time: 709.5407676696777 and batch: 1250, loss is 5.74925404548645 and perplexity is 313.9563757382105
At time: 710.5655031204224 and batch: 1300, loss is 5.721859893798828 and perplexity is 305.4725414237559
At time: 711.5904445648193 and batch: 1350, loss is 5.717415904998779 and perplexity is 304.1180368018103
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.456065266927084 and perplexity of 234.17419627341198
Finished 24 epochs...
Completing Train Step...
At time: 714.6685042381287 and batch: 50, loss is 5.777594041824341 and perplexity is 322.98117565690393
At time: 715.7167558670044 and batch: 100, loss is 5.795201072692871 and perplexity is 328.7182736057892
At time: 716.739729642868 and batch: 150, loss is 5.752954463958741 and perplexity is 315.12029788184475
At time: 717.7640421390533 and batch: 200, loss is 5.753503141403198 and perplexity is 315.2932447232599
At time: 718.7865345478058 and batch: 250, loss is 5.773915243148804 and perplexity is 321.7951758005905
At time: 719.8080990314484 and batch: 300, loss is 5.795401124954224 and perplexity is 328.78404101801254
At time: 720.8313241004944 and batch: 350, loss is 5.799596796035766 and perplexity is 330.1664086630676
At time: 721.8538913726807 and batch: 400, loss is 5.83191216468811 and perplexity is 341.01012355523665
At time: 722.8755474090576 and batch: 450, loss is 5.809380569458008 and perplexity is 333.4125357893801
At time: 723.8984880447388 and batch: 500, loss is 5.8251042079925535 and perplexity is 338.6964261136374
At time: 724.921311378479 and batch: 550, loss is 5.797043209075928 and perplexity is 329.3243755872311
At time: 725.9443521499634 and batch: 600, loss is 5.750365200042725 and perplexity is 314.3054236827776
At time: 726.967663526535 and batch: 650, loss is 5.779263687133789 and perplexity is 323.5208901023448
At time: 727.9891350269318 and batch: 700, loss is 5.781103353500367 and perplexity is 324.11660839619486
At time: 729.0143337249756 and batch: 750, loss is 5.767589769363403 and perplexity is 319.76609307216825
At time: 730.036383152008 and batch: 800, loss is 5.739114065170288 and perplexity is 310.7889502235773
At time: 731.0578784942627 and batch: 850, loss is 5.732519407272338 and perplexity is 308.74614661723075
At time: 732.079910993576 and batch: 900, loss is 5.775426330566407 and perplexity is 322.2818040180797
At time: 733.1282708644867 and batch: 950, loss is 5.750433893203735 and perplexity is 314.3270150574344
At time: 734.1509492397308 and batch: 1000, loss is 5.771262264251709 and perplexity is 320.94259143423227
At time: 735.1727962493896 and batch: 1050, loss is 5.7542323398590085 and perplexity is 315.5232399163181
At time: 736.195324420929 and batch: 1100, loss is 5.744411010742187 and perplexity is 312.4395500867522
At time: 737.2175529003143 and batch: 1150, loss is 5.739892492294311 and perplexity is 311.0309709578092
At time: 738.240814447403 and batch: 1200, loss is 5.72737982749939 and perplexity is 307.16339199798836
At time: 739.2823553085327 and batch: 1250, loss is 5.738628673553467 and perplexity is 310.6381324783339
At time: 740.3162477016449 and batch: 1300, loss is 5.7125983238220215 and perplexity is 302.65644696289576
At time: 741.3425872325897 and batch: 1350, loss is 5.707292242050171 and perplexity is 301.05478015191073
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.447339680989583 and perplexity of 232.1397778535259
Finished 25 epochs...
Completing Train Step...
At time: 744.4505047798157 and batch: 50, loss is 5.767180290222168 and perplexity is 319.63518233141883
At time: 745.4728651046753 and batch: 100, loss is 5.784776945114135 and perplexity is 325.3094701526552
At time: 746.4970710277557 and batch: 150, loss is 5.742861757278442 and perplexity is 311.9558767945732
At time: 747.5192215442657 and batch: 200, loss is 5.744618864059448 and perplexity is 312.50449843331205
At time: 748.5411660671234 and batch: 250, loss is 5.765070705413819 and perplexity is 318.9615955505865
At time: 749.5632321834564 and batch: 300, loss is 5.7864803695678715 and perplexity is 325.8640824951507
At time: 750.5865201950073 and batch: 350, loss is 5.7898349189758305 and perplexity is 326.9590451865828
At time: 751.608800649643 and batch: 400, loss is 5.822962760925293 and perplexity is 337.9719016874752
At time: 752.6300003528595 and batch: 450, loss is 5.800647220611572 and perplexity is 330.5134057880806
At time: 753.6512331962585 and batch: 500, loss is 5.816922960281372 and perplexity is 335.9367708569432
At time: 754.6813468933105 and batch: 550, loss is 5.788788871765137 and perplexity is 326.61720940870543
At time: 755.7040107250214 and batch: 600, loss is 5.742356376647949 and perplexity is 311.7982601684225
At time: 756.7265532016754 and batch: 650, loss is 5.770564298629761 and perplexity is 320.7186626951639
At time: 757.7497432231903 and batch: 700, loss is 5.772754888534546 and perplexity is 321.421995835923
At time: 758.8048624992371 and batch: 750, loss is 5.758830099105835 and perplexity is 316.9772799116901
At time: 759.8281283378601 and batch: 800, loss is 5.730993032455444 and perplexity is 308.27524375278443
At time: 760.8506398200989 and batch: 850, loss is 5.724314126968384 and perplexity is 306.22316299071457
At time: 761.8722133636475 and batch: 900, loss is 5.767429533004761 and perplexity is 319.7148590226855
At time: 762.8946471214294 and batch: 950, loss is 5.744057836532593 and perplexity is 312.3292239789192
At time: 763.9165992736816 and batch: 1000, loss is 5.7650237464904786 and perplexity is 318.94661780914464
At time: 764.938817024231 and batch: 1050, loss is 5.747830858230591 and perplexity is 313.5098748279311
At time: 765.959698677063 and batch: 1100, loss is 5.738022632598877 and perplexity is 310.4499300829348
At time: 766.9817094802856 and batch: 1150, loss is 5.733294610977173 and perplexity is 308.9855805669937
At time: 768.0056049823761 and batch: 1200, loss is 5.720646905899048 and perplexity is 305.1022315633879
At time: 769.0353713035583 and batch: 1250, loss is 5.73213638305664 and perplexity is 308.6279120113769
At time: 770.0600068569183 and batch: 1300, loss is 5.706198263168335 and perplexity is 300.7256126641176
At time: 771.0813455581665 and batch: 1350, loss is 5.701135597229004 and perplexity is 299.20698673927535
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.441654866536458 and perplexity of 230.82385023532407
Finished 26 epochs...
Completing Train Step...
At time: 774.210440158844 and batch: 50, loss is 5.7605164527893065 and perplexity is 317.5122666769145
At time: 775.2341241836548 and batch: 100, loss is 5.779037971496582 and perplexity is 323.44787461916354
At time: 776.258683681488 and batch: 150, loss is 5.736501665115356 and perplexity is 309.978104740477
At time: 777.2813582420349 and batch: 200, loss is 5.73832106590271 and perplexity is 310.54259250733315
At time: 778.3057525157928 and batch: 250, loss is 5.758793745040894 and perplexity is 316.96575670853014
At time: 779.3288564682007 and batch: 300, loss is 5.781247615814209 and perplexity is 324.16336958093405
At time: 780.3536560535431 and batch: 350, loss is 5.783837156295776 and perplexity is 325.00389156226134
At time: 781.3771131038666 and batch: 400, loss is 5.817260675430298 and perplexity is 336.0502409527495
At time: 782.3988723754883 and batch: 450, loss is 5.794873161315918 and perplexity is 328.61050081498934
At time: 783.4231820106506 and batch: 500, loss is 5.811326780319214 and perplexity is 334.0620587370849
At time: 784.4527428150177 and batch: 550, loss is 5.783506574630738 and perplexity is 324.896468991589
At time: 785.5030920505524 and batch: 600, loss is 5.737388410568237 and perplexity is 310.253098321983
At time: 786.5259156227112 and batch: 650, loss is 5.765408325195312 and perplexity is 319.0693014755835
At time: 787.5478692054749 and batch: 700, loss is 5.7673177146911625 and perplexity is 319.6791110449937
At time: 788.5728161334991 and batch: 750, loss is 5.753912401199341 and perplexity is 315.4223079807204
At time: 789.5949790477753 and batch: 800, loss is 5.7263697910308835 and perplexity is 306.85330239754484
At time: 790.6172416210175 and batch: 850, loss is 5.719515790939331 and perplexity is 304.7573209685643
At time: 791.6418590545654 and batch: 900, loss is 5.762028074264526 and perplexity is 317.99258797840497
At time: 792.6639137268066 and batch: 950, loss is 5.738755807876587 and perplexity is 310.67762775759155
At time: 793.6864049434662 and batch: 1000, loss is 5.7590327548980715 and perplexity is 317.04152370293986
At time: 794.7179222106934 and batch: 1050, loss is 5.741514463424682 and perplexity is 311.5358635632801
At time: 795.7419486045837 and batch: 1100, loss is 5.731878576278686 and perplexity is 308.5483558992876
At time: 796.7645659446716 and batch: 1150, loss is 5.726733064651489 and perplexity is 306.9647943575194
At time: 797.7882051467896 and batch: 1200, loss is 5.714409837722778 and perplexity is 303.205210219789
At time: 798.809342622757 and batch: 1250, loss is 5.725321588516235 and perplexity is 306.53182650969507
At time: 799.8340587615967 and batch: 1300, loss is 5.699103746414185 and perplexity is 298.59965998708924
At time: 800.854950428009 and batch: 1350, loss is 5.693954229354858 and perplexity is 297.0659682191791
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.435456949869792 and perplexity of 229.39764755509725
Finished 27 epochs...
Completing Train Step...
At time: 803.9254469871521 and batch: 50, loss is 5.753576765060425 and perplexity is 315.31645861957077
At time: 804.9737770557404 and batch: 100, loss is 5.772435855865479 and perplexity is 321.3194680744167
At time: 805.9992024898529 and batch: 150, loss is 5.729063291549682 and perplexity is 307.68092602872406
At time: 807.0223121643066 and batch: 200, loss is 5.731993885040283 and perplexity is 308.5839362794245
At time: 808.0458130836487 and batch: 250, loss is 5.751450996398926 and perplexity is 314.6468807093974
At time: 809.070042848587 and batch: 300, loss is 5.774566383361816 and perplexity is 322.0047778126514
At time: 810.0929107666016 and batch: 350, loss is 5.776742544174194 and perplexity is 322.7062750000318
At time: 811.1417212486267 and batch: 400, loss is 5.810901985168457 and perplexity is 333.92018093111716
At time: 812.1850168704987 and batch: 450, loss is 5.789155826568604 and perplexity is 326.7370851557384
At time: 813.2105760574341 and batch: 500, loss is 5.804896764755249 and perplexity is 331.92092563676346
At time: 814.2356648445129 and batch: 550, loss is 5.776810274124146 and perplexity is 322.728132620086
At time: 815.2764942646027 and batch: 600, loss is 5.7317486667633055 and perplexity is 308.50827513539394
At time: 816.3049793243408 and batch: 650, loss is 5.759204740524292 and perplexity is 317.0960549770951
At time: 817.3314034938812 and batch: 700, loss is 5.76127965927124 and perplexity is 317.7546865933945
At time: 818.3607087135315 and batch: 750, loss is 5.748122825622558 and perplexity is 313.60142285230927
At time: 819.38782787323 and batch: 800, loss is 5.719728393554687 and perplexity is 304.8221200600352
At time: 820.4144608974457 and batch: 850, loss is 5.713844985961914 and perplexity is 303.0339925837371
At time: 821.4370050430298 and batch: 900, loss is 5.756007537841797 and perplexity is 316.08385358824717
At time: 822.464959859848 and batch: 950, loss is 5.732345933914185 and perplexity is 308.6925920316412
At time: 823.518364906311 and batch: 1000, loss is 5.753507986068725 and perplexity is 315.2947722172737
At time: 824.5411014556885 and batch: 1050, loss is 5.736026515960694 and perplexity is 309.83085389187414
At time: 825.5672421455383 and batch: 1100, loss is 5.726622867584228 and perplexity is 306.93096960115764
At time: 826.6226723194122 and batch: 1150, loss is 5.721031665802002 and perplexity is 305.21964525498714
At time: 827.650514125824 and batch: 1200, loss is 5.709636716842652 and perplexity is 301.76142352524505
At time: 828.6759855747223 and batch: 1250, loss is 5.719230289459229 and perplexity is 304.6703247217252
At time: 829.7219734191895 and batch: 1300, loss is 5.692770080566406 and perplexity is 296.7144061048282
At time: 830.7564785480499 and batch: 1350, loss is 5.688418035507202 and perplexity is 295.4258974972319
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.4308837890625 and perplexity of 228.35097035974303
Finished 28 epochs...
Completing Train Step...
At time: 834.0286750793457 and batch: 50, loss is 5.7470306873321535 and perplexity is 313.2591136889836
At time: 835.0555291175842 and batch: 100, loss is 5.765937223434448 and perplexity is 319.2381013023268
At time: 836.0839822292328 and batch: 150, loss is 5.722717008590698 and perplexity is 305.73447869664
At time: 837.1237659454346 and batch: 200, loss is 5.726001796722412 and perplexity is 306.7404029031865
At time: 838.2265639305115 and batch: 250, loss is 5.745485792160034 and perplexity is 312.7755348321235
At time: 839.253650188446 and batch: 300, loss is 5.7682446765899655 and perplexity is 319.9755787866975
At time: 840.279212474823 and batch: 350, loss is 5.769896364212036 and perplexity is 320.50451518814975
At time: 841.3059256076813 and batch: 400, loss is 5.804342384338379 and perplexity is 331.736966172115
At time: 842.334431886673 and batch: 450, loss is 5.782838220596314 and perplexity is 324.6793956747624
At time: 843.3601005077362 and batch: 500, loss is 5.798641910552979 and perplexity is 329.8512880285348
At time: 844.386468410492 and batch: 550, loss is 5.770233497619629 and perplexity is 320.6125861836521
At time: 845.4142968654633 and batch: 600, loss is 5.725290441513062 and perplexity is 306.52227911060936
At time: 846.4413409233093 and batch: 650, loss is 5.752737836837769 and perplexity is 315.05204167229476
At time: 847.4674232006073 and batch: 700, loss is 5.754893789291382 and perplexity is 315.7320116226129
At time: 848.4953284263611 and batch: 750, loss is 5.741494979858398 and perplexity is 311.52979379276314
At time: 849.5266065597534 and batch: 800, loss is 5.713146181106567 and perplexity is 302.8223049311786
At time: 850.5528287887573 and batch: 850, loss is 5.708022689819336 and perplexity is 301.2747652785104
At time: 851.5786592960358 and batch: 900, loss is 5.749654903411865 and perplexity is 314.0822528673967
At time: 852.6037118434906 and batch: 950, loss is 5.727018461227417 and perplexity is 307.0524135612752
At time: 853.6315462589264 and batch: 1000, loss is 5.748448295593262 and perplexity is 313.7035073100291
At time: 854.656476020813 and batch: 1050, loss is 5.730723237991333 and perplexity is 308.19208401711984
At time: 855.6831731796265 and batch: 1100, loss is 5.72172254562378 and perplexity is 305.4305882088286
At time: 856.7091677188873 and batch: 1150, loss is 5.7160758113861085 and perplexity is 303.71076311657663
At time: 857.7340469360352 and batch: 1200, loss is 5.704253826141358 and perplexity is 300.141438776617
At time: 858.7598345279694 and batch: 1250, loss is 5.714860782623291 and perplexity is 303.34196989636854
At time: 859.7870166301727 and batch: 1300, loss is 5.688214797973632 and perplexity is 295.3658619674151
At time: 860.8123235702515 and batch: 1350, loss is 5.683545608520507 and perplexity is 293.98995747897806
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.427898763020833 and perplexity of 227.67035310207828
Finished 29 epochs...
Completing Train Step...
At time: 864.0598711967468 and batch: 50, loss is 5.742654609680176 and perplexity is 311.89126257650116
At time: 865.1208710670471 and batch: 100, loss is 5.761341094970703 and perplexity is 317.77420867449314
At time: 866.1489777565002 and batch: 150, loss is 5.718617839813232 and perplexity is 304.4837866176325
At time: 867.1750769615173 and batch: 200, loss is 5.72177417755127 and perplexity is 305.4463585859362
At time: 868.2010746002197 and batch: 250, loss is 5.741739511489868 and perplexity is 311.605981996324
At time: 869.2275893688202 and batch: 300, loss is 5.764215316772461 and perplexity is 318.6888760819199
At time: 870.252932548523 and batch: 350, loss is 5.765442543029785 and perplexity is 319.08021952292154
At time: 871.2791867256165 and batch: 400, loss is 5.800692682266235 and perplexity is 330.5284318159475
At time: 872.3048274517059 and batch: 450, loss is 5.77842188835144 and perplexity is 323.24866520636067
At time: 873.3317947387695 and batch: 500, loss is 5.794917030334473 and perplexity is 328.62491695135543
At time: 874.3579268455505 and batch: 550, loss is 5.766263675689697 and perplexity is 319.34233431308354
At time: 875.3843948841095 and batch: 600, loss is 5.721457872390747 and perplexity is 305.34975960463623
At time: 876.409725189209 and batch: 650, loss is 5.749101409912109 and perplexity is 313.9084584835137
At time: 877.4362938404083 and batch: 700, loss is 5.7512565612792965 and perplexity is 314.5857082527353
At time: 878.4618237018585 and batch: 750, loss is 5.737712240219116 and perplexity is 310.3535837436979
At time: 879.4880893230438 and batch: 800, loss is 5.709773082733154 and perplexity is 301.80257629633667
At time: 880.5146927833557 and batch: 850, loss is 5.704453630447388 and perplexity is 300.201414319989
At time: 881.5399601459503 and batch: 900, loss is 5.74576325416565 and perplexity is 312.8623301999771
At time: 882.5644218921661 and batch: 950, loss is 5.723447322845459 and perplexity is 305.95784249756014
At time: 883.5913181304932 and batch: 1000, loss is 5.745762481689453 and perplexity is 312.8620885213675
At time: 884.6169631481171 and batch: 1050, loss is 5.7271403884887695 and perplexity is 307.08985390360516
At time: 885.6430065631866 and batch: 1100, loss is 5.7186821174621585 and perplexity is 304.5033587485909
At time: 886.6689629554749 and batch: 1150, loss is 5.71329216003418 and perplexity is 302.8665138332152
At time: 887.6967697143555 and batch: 1200, loss is 5.701455812454224 and perplexity is 299.3028127135707
At time: 888.7225806713104 and batch: 1250, loss is 5.711977710723877 and perplexity is 302.468672681289
At time: 889.7494423389435 and batch: 1300, loss is 5.685767030715942 and perplexity is 294.64375921173655
At time: 890.7757611274719 and batch: 1350, loss is 5.679972114562989 and perplexity is 292.9412610135722
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.425441080729167 and perplexity of 227.1114987314664
Finished 30 epochs...
Completing Train Step...
At time: 893.940859079361 and batch: 50, loss is 5.738772764205932 and perplexity is 310.6828957544308
At time: 894.9956169128418 and batch: 100, loss is 5.757789001464844 and perplexity is 316.6474473370756
At time: 896.0221416950226 and batch: 150, loss is 5.715329170227051 and perplexity is 303.4840847945981
At time: 897.0581498146057 and batch: 200, loss is 5.718087873458862 and perplexity is 304.3224632070397
At time: 898.0940990447998 and batch: 250, loss is 5.738349609375 and perplexity is 310.5514565977225
At time: 899.128591299057 and batch: 300, loss is 5.761218795776367 and perplexity is 317.73534752118377
At time: 900.1512291431427 and batch: 350, loss is 5.761781768798828 and perplexity is 317.9142743108726
At time: 901.1757729053497 and batch: 400, loss is 5.797703666687012 and perplexity is 329.5419522197656
At time: 902.198760509491 and batch: 450, loss is 5.77509578704834 and perplexity is 322.1752934609275
At time: 903.2215220928192 and batch: 500, loss is 5.791793117523193 and perplexity is 327.59992319231475
At time: 904.2481532096863 and batch: 550, loss is 5.762774314880371 and perplexity is 318.2299755261908
At time: 905.2723519802094 and batch: 600, loss is 5.718185777664185 and perplexity is 304.3522591145102
At time: 906.2968695163727 and batch: 650, loss is 5.746163120269776 and perplexity is 312.987458256649
At time: 907.3192284107208 and batch: 700, loss is 5.748340225219726 and perplexity is 313.6696070866526
At time: 908.3466665744781 and batch: 750, loss is 5.734747076034546 and perplexity is 309.43469741030356
At time: 909.3769118785858 and batch: 800, loss is 5.706920986175537 and perplexity is 300.9430325409548
At time: 910.4032096862793 and batch: 850, loss is 5.7012435340881344 and perplexity is 299.239283944652
At time: 911.4290461540222 and batch: 900, loss is 5.742717905044556 and perplexity is 311.91100447239154
At time: 912.4538986682892 and batch: 950, loss is 5.720445871353149 and perplexity is 305.0409016397362
At time: 913.4838669300079 and batch: 1000, loss is 5.743278551101684 and perplexity is 312.0859251769439
At time: 914.5086877346039 and batch: 1050, loss is 5.723964586257934 and perplexity is 306.11614423356247
At time: 915.5340940952301 and batch: 1100, loss is 5.715754842758178 and perplexity is 303.6132971322499
At time: 916.6060652732849 and batch: 1150, loss is 5.7102104187011715 and perplexity is 301.93459428419453
At time: 917.6320202350616 and batch: 1200, loss is 5.698560419082642 and perplexity is 298.4374666966428
At time: 918.6570401191711 and batch: 1250, loss is 5.707870779037475 and perplexity is 301.2290018694278
At time: 919.684898853302 and batch: 1300, loss is 5.681744318008423 and perplexity is 293.4608728185704
At time: 920.711074590683 and batch: 1350, loss is 5.675465250015259 and perplexity is 291.62398505159877
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.422326253255208 and perplexity of 226.40518618748675
Finished 31 epochs...
Completing Train Step...
At time: 923.8548099994659 and batch: 50, loss is 5.734534168243409 and perplexity is 309.3688233651741
At time: 924.8801991939545 and batch: 100, loss is 5.7537642765045165 and perplexity is 315.3755896077677
At time: 925.9076220989227 and batch: 150, loss is 5.711128387451172 and perplexity is 302.21188806032984
At time: 926.9335896968842 and batch: 200, loss is 5.714027547836304 and perplexity is 303.0893200876199
At time: 927.9591312408447 and batch: 250, loss is 5.733739519119263 and perplexity is 309.12308135291795
At time: 928.9854664802551 and batch: 300, loss is 5.7574364280700685 and perplexity is 316.5358255502134
At time: 930.0122187137604 and batch: 350, loss is 5.756840238571167 and perplexity is 316.34716645886687
At time: 931.0383815765381 and batch: 400, loss is 5.792984523773193 and perplexity is 327.99046038633696
At time: 932.0636131763458 and batch: 450, loss is 5.770070352554321 and perplexity is 320.560284088871
At time: 933.0927512645721 and batch: 500, loss is 5.787632646560669 and perplexity is 326.2397845950623
At time: 934.119378566742 and batch: 550, loss is 5.758681354522705 and perplexity is 316.9301347647073
At time: 935.1461517810822 and batch: 600, loss is 5.713817367553711 and perplexity is 303.025623382803
At time: 936.174453496933 and batch: 650, loss is 5.741994247436524 and perplexity is 311.6853693521087
At time: 937.2006330490112 and batch: 700, loss is 5.744151887893676 and perplexity is 312.3586003489626
At time: 938.2277035713196 and batch: 750, loss is 5.73094988822937 and perplexity is 308.26194374288616
At time: 939.2537150382996 and batch: 800, loss is 5.70289737701416 and perplexity is 299.7345881824017
At time: 940.2792363166809 and batch: 850, loss is 5.697562065124512 and perplexity is 298.1396691489268
At time: 941.3056740760803 and batch: 900, loss is 5.739033164978028 and perplexity is 310.76380835475663
At time: 942.3316345214844 and batch: 950, loss is 5.716091451644897 and perplexity is 303.71551326865534
At time: 943.4021952152252 and batch: 1000, loss is 5.7394000434875485 and perplexity is 310.8778418345163
At time: 944.4279587268829 and batch: 1050, loss is 5.719876308441162 and perplexity is 304.8672111240563
At time: 945.4534347057343 and batch: 1100, loss is 5.711977214813232 and perplexity is 302.46852268389165
At time: 946.4789381027222 and batch: 1150, loss is 5.706668548583984 and perplexity is 300.86707279457664
At time: 947.5056784152985 and batch: 1200, loss is 5.6954990482330325 and perplexity is 297.5252359863701
At time: 948.530092716217 and batch: 1250, loss is 5.704068059921265 and perplexity is 300.08568781452533
At time: 949.5574214458466 and batch: 1300, loss is 5.678754148483276 and perplexity is 292.58468568671583
At time: 950.5829775333405 and batch: 1350, loss is 5.671265678405762 and perplexity is 290.40185724610603
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.4199210611979165 and perplexity of 225.86129257843297
Finished 32 epochs...
Completing Train Step...
At time: 953.7116181850433 and batch: 50, loss is 5.7307478618621825 and perplexity is 308.1996729926282
At time: 954.7626264095306 and batch: 100, loss is 5.750325851440429 and perplexity is 314.2930564469801
At time: 955.7892868518829 and batch: 150, loss is 5.7077099704742436 and perplexity is 301.1805655610244
At time: 956.815211057663 and batch: 200, loss is 5.710560264587403 and perplexity is 302.04024333928186
At time: 957.842511177063 and batch: 250, loss is 5.73021369934082 and perplexity is 308.035088239636
At time: 958.8682582378387 and batch: 300, loss is 5.754364852905273 and perplexity is 315.56505363237704
At time: 959.8951845169067 and batch: 350, loss is 5.7536999702453615 and perplexity is 315.3553096354428
At time: 960.9199321269989 and batch: 400, loss is 5.789694232940674 and perplexity is 326.91304985038346
At time: 961.9461362361908 and batch: 450, loss is 5.766961488723755 and perplexity is 319.56525332514394
At time: 962.9711050987244 and batch: 500, loss is 5.784835081100464 and perplexity is 325.32838288931464
At time: 963.9966259002686 and batch: 550, loss is 5.755816297531128 and perplexity is 316.0234113935657
At time: 965.0222797393799 and batch: 600, loss is 5.710852518081665 and perplexity is 302.12852855600863
At time: 966.0477244853973 and batch: 650, loss is 5.7391386985778805 and perplexity is 310.79660610875834
At time: 967.0726206302643 and batch: 700, loss is 5.7413429927825925 and perplexity is 311.4824488883761
At time: 968.0998675823212 and batch: 750, loss is 5.728206167221069 and perplexity is 307.4173182100505
At time: 969.1250677108765 and batch: 800, loss is 5.7000871181488035 and perplexity is 298.89343887594094
At time: 970.1776158809662 and batch: 850, loss is 5.695403928756714 and perplexity is 297.4969368876506
At time: 971.2035338878632 and batch: 900, loss is 5.73652006149292 and perplexity is 309.98380726718096
At time: 972.2291810512543 and batch: 950, loss is 5.7132682037353515 and perplexity is 302.85925835941225
At time: 973.2549614906311 and batch: 1000, loss is 5.736068553924561 and perplexity is 309.84387882388387
At time: 974.2805867195129 and batch: 1050, loss is 5.717113704681396 and perplexity is 304.0261461199629
At time: 975.306389093399 and batch: 1100, loss is 5.708423624038696 and perplexity is 301.3955808592723
At time: 976.3318831920624 and batch: 1150, loss is 5.703524837493896 and perplexity is 299.9227188069897
At time: 977.35560297966 and batch: 1200, loss is 5.692707681655884 and perplexity is 296.69589202678617
At time: 978.3772101402283 and batch: 1250, loss is 5.701282291412354 and perplexity is 299.25088188335013
At time: 979.4009959697723 and batch: 1300, loss is 5.676019868850708 and perplexity is 291.7857700669383
At time: 980.422577381134 and batch: 1350, loss is 5.668167304992676 and perplexity is 289.50347633097357
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.4177864583333335 and perplexity of 225.37968262216523
Finished 33 epochs...
Completing Train Step...
At time: 983.5878715515137 and batch: 50, loss is 5.7273298931121825 and perplexity is 307.1480543651772
At time: 984.6133663654327 and batch: 100, loss is 5.746885547637939 and perplexity is 313.2136506563381
At time: 985.6393513679504 and batch: 150, loss is 5.70433030128479 and perplexity is 300.1643930139005
At time: 986.6657099723816 and batch: 200, loss is 5.706770610809326 and perplexity is 300.89778152463225
At time: 987.6927242279053 and batch: 250, loss is 5.727169122695923 and perplexity is 307.09867801385815
At time: 988.7203226089478 and batch: 300, loss is 5.751885108947754 and perplexity is 314.7835025212387
At time: 989.7469568252563 and batch: 350, loss is 5.750370759963989 and perplexity is 314.30717120104407
At time: 990.7734277248383 and batch: 400, loss is 5.787080402374268 and perplexity is 326.05967030875803
At time: 991.7992405891418 and batch: 450, loss is 5.7638153457641605 and perplexity is 318.5614352588355
At time: 992.824579000473 and batch: 500, loss is 5.78153507232666 and perplexity is 324.25656584691325
At time: 993.852064371109 and batch: 550, loss is 5.753511409759522 and perplexity is 315.29585169093144
At time: 994.8782994747162 and batch: 600, loss is 5.708159093856811 and perplexity is 301.31586317577984
At time: 995.9410297870636 and batch: 650, loss is 5.736628561019898 and perplexity is 310.01744218829384
At time: 996.9671156406403 and batch: 700, loss is 5.7384134292602536 and perplexity is 310.571276588496
At time: 997.9966640472412 and batch: 750, loss is 5.725417547225952 and perplexity is 306.56124231958313
At time: 999.0274376869202 and batch: 800, loss is 5.697395906448365 and perplexity is 298.0901347715914
At time: 1000.0535459518433 and batch: 850, loss is 5.692926740646362 and perplexity is 296.76089304864166
At time: 1001.0765917301178 and batch: 900, loss is 5.733560075759888 and perplexity is 309.06761624531106
At time: 1002.1018507480621 and batch: 950, loss is 5.7103246974945066 and perplexity is 301.96910097694945
At time: 1003.125910282135 and batch: 1000, loss is 5.733215675354004 and perplexity is 308.96119156023497
At time: 1004.1497542858124 and batch: 1050, loss is 5.714367895126343 and perplexity is 303.1924932727125
At time: 1005.1759791374207 and batch: 1100, loss is 5.705249929428101 and perplexity is 300.44055960315666
At time: 1006.20232629776 and batch: 1150, loss is 5.7006903076171875 and perplexity is 299.0737826357003
At time: 1007.230263710022 and batch: 1200, loss is 5.69042179107666 and perplexity is 296.0184522538903
At time: 1008.2550837993622 and batch: 1250, loss is 5.6990142345428465 and perplexity is 298.5729329689534
At time: 1009.2831711769104 and batch: 1300, loss is 5.673109760284424 and perplexity is 290.93787612803635
At time: 1010.308429479599 and batch: 1350, loss is 5.66538070678711 and perplexity is 288.69786943599183
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.41554443359375 and perplexity of 224.874941830029
Finished 34 epochs...
Completing Train Step...
At time: 1013.4688663482666 and batch: 50, loss is 5.724011783599853 and perplexity is 306.13059244284466
At time: 1014.4940285682678 and batch: 100, loss is 5.743880834579468 and perplexity is 312.27394598855716
At time: 1015.5218698978424 and batch: 150, loss is 5.701695022583007 and perplexity is 299.37441754190377
At time: 1016.548112154007 and batch: 200, loss is 5.703272352218628 and perplexity is 299.8470022958267
At time: 1017.5732378959656 and batch: 250, loss is 5.724629383087159 and perplexity is 306.3197169353692
At time: 1018.5987703800201 and batch: 300, loss is 5.749483308792114 and perplexity is 314.02836266641197
At time: 1019.6219704151154 and batch: 350, loss is 5.747716827392578 and perplexity is 313.4741270723911
At time: 1020.6531538963318 and batch: 400, loss is 5.7847975158691405 and perplexity is 325.31616208289535
At time: 1021.6812281608582 and batch: 450, loss is 5.761620082855225 and perplexity is 317.86287619673385
At time: 1022.7335729598999 and batch: 500, loss is 5.778854675292969 and perplexity is 323.38859328486706
At time: 1023.7590608596802 and batch: 550, loss is 5.751250104904175 and perplexity is 314.5836771759516
At time: 1024.7854387760162 and batch: 600, loss is 5.705852127075195 and perplexity is 300.62153868836174
At time: 1025.8119690418243 and batch: 650, loss is 5.7343954086303714 and perplexity is 309.32589844514973
At time: 1026.8374137878418 and batch: 700, loss is 5.736287927627563 and perplexity is 309.91185787907
At time: 1027.8655045032501 and batch: 750, loss is 5.723281440734863 and perplexity is 305.90709377416226
At time: 1028.8915503025055 and batch: 800, loss is 5.695291423797608 and perplexity is 297.46346888962495
At time: 1029.920298576355 and batch: 850, loss is 5.6903744983673095 and perplexity is 296.00445307029776
At time: 1030.9498846530914 and batch: 900, loss is 5.731114683151245 and perplexity is 308.31274793184343
At time: 1031.9723272323608 and batch: 950, loss is 5.707709436416626 and perplexity is 301.18040471329203
At time: 1033.0006940364838 and batch: 1000, loss is 5.73111557006836 and perplexity is 308.3130213798176
At time: 1034.0303382873535 and batch: 1050, loss is 5.712280950546265 and perplexity is 302.56040713593757
At time: 1035.0535547733307 and batch: 1100, loss is 5.702822904586792 and perplexity is 299.7122670512183
At time: 1036.0790312290192 and batch: 1150, loss is 5.69856556892395 and perplexity is 298.43900360619404
At time: 1037.1015346050262 and batch: 1200, loss is 5.688079376220703 and perplexity is 295.3258657128745
At time: 1038.126292705536 and batch: 1250, loss is 5.696860189437866 and perplexity is 297.93048558294373
At time: 1039.1509582996368 and batch: 1300, loss is 5.670972318649292 and perplexity is 290.3166775227482
At time: 1040.1736674308777 and batch: 1350, loss is 5.663319702148438 and perplexity is 288.10347452364823
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.413818766276042 and perplexity of 224.48721713048056
Finished 35 epochs...
Completing Train Step...
At time: 1043.3093266487122 and batch: 50, loss is 5.721577157974243 and perplexity is 305.38618560138605
At time: 1044.370355129242 and batch: 100, loss is 5.741553802490234 and perplexity is 311.54811933410224
At time: 1045.3968925476074 and batch: 150, loss is 5.699400310516357 and perplexity is 298.6882270594204
At time: 1046.43404006958 and batch: 200, loss is 5.700541229248047 and perplexity is 299.02920052712875
At time: 1047.4608347415924 and batch: 250, loss is 5.722596368789673 and perplexity is 305.6975971746979
At time: 1048.5281066894531 and batch: 300, loss is 5.747515554428101 and perplexity is 313.4110395546672
At time: 1049.5565292835236 and batch: 350, loss is 5.74583571434021 and perplexity is 312.8850010803948
At time: 1050.582424402237 and batch: 400, loss is 5.783101739883423 and perplexity is 324.76496623190076
At time: 1051.6099240779877 and batch: 450, loss is 5.759786825180054 and perplexity is 317.28068545517095
At time: 1052.6375148296356 and batch: 500, loss is 5.776667585372925 and perplexity is 322.6820862310876
At time: 1053.6640164852142 and batch: 550, loss is 5.749420404434204 and perplexity is 314.0086095351784
At time: 1054.6909761428833 and batch: 600, loss is 5.703781232833863 and perplexity is 299.9996274535298
At time: 1055.718679189682 and batch: 650, loss is 5.7323283672332765 and perplexity is 308.68716937500744
At time: 1056.7442872524261 and batch: 700, loss is 5.734447784423828 and perplexity is 309.34210005880004
At time: 1057.7702460289001 and batch: 750, loss is 5.721208534240723 and perplexity is 305.27363375140004
At time: 1058.7969105243683 and batch: 800, loss is 5.693366365432739 and perplexity is 296.89138517453813
At time: 1059.8239438533783 and batch: 850, loss is 5.688382272720337 and perplexity is 295.41533243274444
At time: 1060.849101305008 and batch: 900, loss is 5.728924522399902 and perplexity is 307.63823237056533
At time: 1061.8768396377563 and batch: 950, loss is 5.70590950012207 and perplexity is 300.63878675677495
At time: 1062.9023373126984 and batch: 1000, loss is 5.7294094848632815 and perplexity is 307.7874615479154
At time: 1063.9263472557068 and batch: 1050, loss is 5.71053915977478 and perplexity is 302.0338689038075
At time: 1064.9531333446503 and batch: 1100, loss is 5.700634889602661 and perplexity is 299.05720901971233
At time: 1065.9804284572601 and batch: 1150, loss is 5.696657695770264 and perplexity is 297.87016265393913
At time: 1067.0061602592468 and batch: 1200, loss is 5.685749111175537 and perplexity is 294.6384793782944
At time: 1068.0334990024567 and batch: 1250, loss is 5.695001811981201 and perplexity is 297.3773324277558
At time: 1069.0603003501892 and batch: 1300, loss is 5.669557132720947 and perplexity is 289.9061160249026
At time: 1070.0858981609344 and batch: 1350, loss is 5.661477012634277 and perplexity is 287.57307810019455
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.412510172526042 and perplexity of 224.19364668530648
Finished 36 epochs...
Completing Train Step...
At time: 1073.25119805336 and batch: 50, loss is 5.719583902359009 and perplexity is 304.77807912927847
At time: 1074.2780668735504 and batch: 100, loss is 5.739566278457642 and perplexity is 310.92952489890365
At time: 1075.3313610553741 and batch: 150, loss is 5.697433547973633 and perplexity is 298.1013555501139
At time: 1076.3579552173615 and batch: 200, loss is 5.698454284667969 and perplexity is 298.40579389161553
At time: 1077.3864104747772 and batch: 250, loss is 5.720841312408448 and perplexity is 305.1615511891101
At time: 1078.412142276764 and batch: 300, loss is 5.7456104183197025 and perplexity is 312.81451727493356
At time: 1079.439349412918 and batch: 350, loss is 5.744066390991211 and perplexity is 312.3318957977688
At time: 1080.4647278785706 and batch: 400, loss is 5.7815025043487545 and perplexity is 324.2460056382043
At time: 1081.4895186424255 and batch: 450, loss is 5.758137645721436 and perplexity is 316.7578638978856
At time: 1082.5186085700989 and batch: 500, loss is 5.7745836734771725 and perplexity is 322.0103453605367
At time: 1083.5453608036041 and batch: 550, loss is 5.74760178565979 and perplexity is 313.4380665399014
At time: 1084.5711226463318 and batch: 600, loss is 5.70223482131958 and perplexity is 299.5360630983636
At time: 1085.598533630371 and batch: 650, loss is 5.730535526275634 and perplexity is 308.1342381816047
At time: 1086.6240894794464 and batch: 700, loss is 5.732950668334961 and perplexity is 308.8793255238759
At time: 1087.6504046916962 and batch: 750, loss is 5.719373264312744 and perplexity is 304.7138880309275
At time: 1088.6778135299683 and batch: 800, loss is 5.691722278594971 and perplexity is 296.40367098802153
At time: 1089.7046926021576 and batch: 850, loss is 5.686815357208252 and perplexity is 294.952804031945
At time: 1090.7304956912994 and batch: 900, loss is 5.7269439792633055 and perplexity is 307.02954454610307
At time: 1091.7574944496155 and batch: 950, loss is 5.704321928024292 and perplexity is 300.1618796697682
At time: 1092.7841501235962 and batch: 1000, loss is 5.728138618469238 and perplexity is 307.3965532552454
At time: 1093.8099491596222 and batch: 1050, loss is 5.7089058208465575 and perplexity is 301.5409478912089
At time: 1094.836262702942 and batch: 1100, loss is 5.698750009536743 and perplexity is 298.4940529554124
At time: 1095.861982345581 and batch: 1150, loss is 5.695168228149414 and perplexity is 297.4268249419949
At time: 1096.888394832611 and batch: 1200, loss is 5.684051685333252 and perplexity is 294.13877663342333
At time: 1097.9135248661041 and batch: 1250, loss is 5.69352123260498 and perplexity is 296.9373674643045
At time: 1098.940533876419 and batch: 1300, loss is 5.668152933120727 and perplexity is 289.4993156539815
At time: 1099.96635222435 and batch: 1350, loss is 5.659793720245362 and perplexity is 287.0894157133824
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.411291097005209 and perplexity of 223.92050422317823
Finished 37 epochs...
Completing Train Step...
At time: 1103.0820832252502 and batch: 50, loss is 5.717691822052002 and perplexity is 304.2019597317079
At time: 1104.1340487003326 and batch: 100, loss is 5.7377793502807615 and perplexity is 310.37441229072965
At time: 1105.1609101295471 and batch: 150, loss is 5.695921249389649 and perplexity is 297.65087800636275
At time: 1106.1892778873444 and batch: 200, loss is 5.696772203445435 and perplexity is 297.90427302667996
At time: 1107.217523574829 and batch: 250, loss is 5.719249353408814 and perplexity is 304.67613299679994
At time: 1108.244057416916 and batch: 300, loss is 5.7439963912963865 and perplexity is 312.31003342556767
At time: 1109.2724623680115 and batch: 350, loss is 5.742534198760986 and perplexity is 311.85370972381935
At time: 1110.2977221012115 and batch: 400, loss is 5.78018440246582 and perplexity is 323.8188979152233
At time: 1111.3231508731842 and batch: 450, loss is 5.756905574798584 and perplexity is 316.36783606450695
At time: 1112.3491439819336 and batch: 500, loss is 5.773039207458496 and perplexity is 321.51339518457945
At time: 1113.3771603107452 and batch: 550, loss is 5.746033554077148 and perplexity is 312.9469082903517
At time: 1114.403291463852 and batch: 600, loss is 5.700822830200195 and perplexity is 299.1134192922031
At time: 1115.4296255111694 and batch: 650, loss is 5.728880033493042 and perplexity is 307.62454618634285
At time: 1116.4569697380066 and batch: 700, loss is 5.731614446640014 and perplexity is 308.4668698954393
At time: 1117.4832899570465 and batch: 750, loss is 5.717841358184814 and perplexity is 304.24745231766803
At time: 1118.5082092285156 and batch: 800, loss is 5.690138292312622 and perplexity is 295.9345432831507
At time: 1119.5358939170837 and batch: 850, loss is 5.685291881561279 and perplexity is 294.5037927337306
At time: 1120.56187748909 and batch: 900, loss is 5.725371551513672 and perplexity is 306.5471421411616
At time: 1121.5867557525635 and batch: 950, loss is 5.702724657058716 and perplexity is 299.68282250829674
At time: 1122.6110973358154 and batch: 1000, loss is 5.726825008392334 and perplexity is 306.9930191465467
At time: 1123.6333763599396 and batch: 1050, loss is 5.707377080917358 and perplexity is 301.08032238189185
At time: 1124.6569247245789 and batch: 1100, loss is 5.696994304656982 and perplexity is 297.9704452748406
At time: 1125.6793859004974 and batch: 1150, loss is 5.693850393295288 and perplexity is 297.03512366102325
At time: 1126.7026102542877 and batch: 1200, loss is 5.682544422149658 and perplexity is 293.69576603518976
At time: 1127.7817335128784 and batch: 1250, loss is 5.6920132827758785 and perplexity is 296.4899382469732
At time: 1128.8110954761505 and batch: 1300, loss is 5.666792602539062 and perplexity is 289.1057686192478
At time: 1129.8414888381958 and batch: 1350, loss is 5.658267230987549 and perplexity is 286.6515111176274
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.410036214192709 and perplexity of 223.63968646460262
Finished 38 epochs...
Completing Train Step...
At time: 1132.9718062877655 and batch: 50, loss is 5.7158486270904545 and perplexity is 303.6417726378489
At time: 1134.1615769863129 and batch: 100, loss is 5.736281232833862 and perplexity is 309.9097830900612
At time: 1135.1962928771973 and batch: 150, loss is 5.694411964416504 and perplexity is 297.2019768540403
At time: 1136.2214601039886 and batch: 200, loss is 5.694955587387085 and perplexity is 297.3635865989652
At time: 1137.244945049286 and batch: 250, loss is 5.718095693588257 and perplexity is 304.324843057385
At time: 1138.2669517993927 and batch: 300, loss is 5.742617387771606 and perplexity is 311.87965360449726
At time: 1139.2913691997528 and batch: 350, loss is 5.740897960662842 and perplexity is 311.34386003441534
At time: 1140.3150029182434 and batch: 400, loss is 5.778933820724487 and perplexity is 323.41418902751025
At time: 1141.337223291397 and batch: 450, loss is 5.755619592666626 and perplexity is 315.9612541647632
At time: 1142.3605642318726 and batch: 500, loss is 5.771531295776367 and perplexity is 321.02894672456057
At time: 1143.3841392993927 and batch: 550, loss is 5.744656610488891 and perplexity is 312.51629458494284
At time: 1144.4057705402374 and batch: 600, loss is 5.69958345413208 and perplexity is 298.7429349108418
At time: 1145.4280414581299 and batch: 650, loss is 5.727588491439819 and perplexity is 307.2274926092288
At time: 1146.4605791568756 and batch: 700, loss is 5.730395336151123 and perplexity is 308.091043832169
At time: 1147.4880957603455 and batch: 750, loss is 5.716494026184082 and perplexity is 303.83780601577445
At time: 1148.5127658843994 and batch: 800, loss is 5.688590068817138 and perplexity is 295.4767249641026
At time: 1149.5349373817444 and batch: 850, loss is 5.683598985671997 and perplexity is 294.00565024428874
At time: 1150.557029724121 and batch: 900, loss is 5.723892860412597 and perplexity is 306.0941885817493
At time: 1151.5794835090637 and batch: 950, loss is 5.70123143196106 and perplexity is 299.2356625347254
At time: 1152.6033930778503 and batch: 1000, loss is 5.725446548461914 and perplexity is 306.57013310342967
At time: 1153.6689758300781 and batch: 1050, loss is 5.705947189331055 and perplexity is 300.6501178083658
At time: 1154.6923949718475 and batch: 1100, loss is 5.6953253746032715 and perplexity is 297.4735681854879
At time: 1155.714519739151 and batch: 1150, loss is 5.692512407302856 and perplexity is 296.6379605848711
At time: 1156.7368392944336 and batch: 1200, loss is 5.681208114624024 and perplexity is 293.3035602849019
At time: 1157.7695951461792 and batch: 1250, loss is 5.690391149520874 and perplexity is 296.009381926937
At time: 1158.7937443256378 and batch: 1300, loss is 5.66537844657898 and perplexity is 288.6972169194576
At time: 1159.814843416214 and batch: 1350, loss is 5.656867971420288 and perplexity is 286.2506917387997
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.408782958984375 and perplexity of 223.35958441908627
Finished 39 epochs...
Completing Train Step...
At time: 1162.96258187294 and batch: 50, loss is 5.714077472686768 and perplexity is 303.1044521543323
At time: 1163.9854810237885 and batch: 100, loss is 5.7348323154449465 and perplexity is 309.4610745656388
At time: 1165.007773399353 and batch: 150, loss is 5.692819375991821 and perplexity is 296.7290331282235
At time: 1166.0308349132538 and batch: 200, loss is 5.693114500045777 and perplexity is 296.81661792696144
At time: 1167.0547137260437 and batch: 250, loss is 5.716444978713989 and perplexity is 303.8229039055291
At time: 1168.0766763687134 and batch: 300, loss is 5.740825910568237 and perplexity is 311.32142848795235
At time: 1169.1003727912903 and batch: 350, loss is 5.7391113185882565 and perplexity is 310.78809661740337
At time: 1170.1231784820557 and batch: 400, loss is 5.777349281311035 and perplexity is 322.9021322923038
At time: 1171.143840789795 and batch: 450, loss is 5.754170589447021 and perplexity is 315.5037568278123
At time: 1172.1649022102356 and batch: 500, loss is 5.770036277770996 and perplexity is 320.54936125274554
At time: 1173.1889400482178 and batch: 550, loss is 5.742882223129272 and perplexity is 311.9622613023452
At time: 1174.2130875587463 and batch: 600, loss is 5.6981668949127195 and perplexity is 298.3200474454592
At time: 1175.2355420589447 and batch: 650, loss is 5.726373319625854 and perplexity is 306.85438516047475
At time: 1176.259066581726 and batch: 700, loss is 5.728927221298218 and perplexity is 307.6390626559929
At time: 1177.280876159668 and batch: 750, loss is 5.714868602752685 and perplexity is 303.3443420790991
At time: 1178.3024702072144 and batch: 800, loss is 5.687022151947022 and perplexity is 295.0138050271294
At time: 1179.3265883922577 and batch: 850, loss is 5.6820920467376705 and perplexity is 293.5629353389662
At time: 1180.3911259174347 and batch: 900, loss is 5.722320690155029 and perplexity is 305.61333449373893
At time: 1181.4126756191254 and batch: 950, loss is 5.699563598632812 and perplexity is 298.7370032796043
At time: 1182.4366652965546 and batch: 1000, loss is 5.723893899917602 and perplexity is 306.09450676835564
At time: 1183.4572200775146 and batch: 1050, loss is 5.704282312393189 and perplexity is 300.1499888030055
At time: 1184.4796998500824 and batch: 1100, loss is 5.693564720153809 and perplexity is 296.95028082335426
At time: 1185.503351688385 and batch: 1150, loss is 5.691284255981445 and perplexity is 296.2738679078145
At time: 1186.5341458320618 and batch: 1200, loss is 5.679944000244141 and perplexity is 292.9330252853278
At time: 1187.5650789737701 and batch: 1250, loss is 5.688939371109009 and perplexity is 295.5799536892925
At time: 1188.6043734550476 and batch: 1300, loss is 5.66396653175354 and perplexity is 288.2898886628956
At time: 1189.626454114914 and batch: 1350, loss is 5.655449113845825 and perplexity is 285.84483077417116
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.407695719401041 and perplexity of 223.11687100531339
Finished 40 epochs...
Completing Train Step...
At time: 1192.850387096405 and batch: 50, loss is 5.712767686843872 and perplexity is 302.70771011425444
At time: 1193.9055910110474 and batch: 100, loss is 5.733450174331665 and perplexity is 309.03365113930926
At time: 1194.9288153648376 and batch: 150, loss is 5.691440391540527 and perplexity is 296.3201304053381
At time: 1195.95356631279 and batch: 200, loss is 5.6917973899841305 and perplexity is 296.42593511563587
At time: 1196.9761860370636 and batch: 250, loss is 5.715133552551269 and perplexity is 303.4247237495181
At time: 1197.9992423057556 and batch: 300, loss is 5.739772357940674 and perplexity is 310.99360769750245
At time: 1199.0236322879791 and batch: 350, loss is 5.737571954727173 and perplexity is 310.31004869226564
At time: 1200.0457980632782 and batch: 400, loss is 5.776132888793946 and perplexity is 322.50959534273545
At time: 1201.0696105957031 and batch: 450, loss is 5.753003263473511 and perplexity is 315.1356759746944
At time: 1202.0935454368591 and batch: 500, loss is 5.768677406311035 and perplexity is 320.11407169249196
At time: 1203.1195514202118 and batch: 550, loss is 5.741369647979736 and perplexity is 311.4907516251131
At time: 1204.1445755958557 and batch: 600, loss is 5.697168064117432 and perplexity is 298.02222495711595
At time: 1205.168787240982 and batch: 650, loss is 5.725214166641235 and perplexity is 306.49890005468677
At time: 1206.221304655075 and batch: 700, loss is 5.7277459716796875 and perplexity is 307.27587867828385
At time: 1207.2498559951782 and batch: 750, loss is 5.713228931427002 and perplexity is 302.8473646107805
At time: 1208.2772121429443 and batch: 800, loss is 5.685672931671142 and perplexity is 294.6160348198784
At time: 1209.3029980659485 and batch: 850, loss is 5.680789365768432 and perplexity is 293.1807654665808
At time: 1210.3267590999603 and batch: 900, loss is 5.720951328277588 and perplexity is 305.1951256492202
At time: 1211.3512575626373 and batch: 950, loss is 5.698153038024902 and perplexity is 298.3159136866686
At time: 1212.3755159378052 and batch: 1000, loss is 5.722879648208618 and perplexity is 305.78420727924936
At time: 1213.39959025383 and batch: 1050, loss is 5.70309455871582 and perplexity is 299.7936961858627
At time: 1214.4240097999573 and batch: 1100, loss is 5.692080097198486 and perplexity is 296.5097487128113
At time: 1215.4479591846466 and batch: 1150, loss is 5.6901373767852785 and perplexity is 295.9342723471084
At time: 1216.4801807403564 and batch: 1200, loss is 5.678811864852905 and perplexity is 292.6015730999182
At time: 1217.5046286582947 and batch: 1250, loss is 5.687752656936645 and perplexity is 295.22939281810085
At time: 1218.5370063781738 and batch: 1300, loss is 5.662909479141235 and perplexity is 287.98531208807555
At time: 1219.5608384609222 and batch: 1350, loss is 5.654274959564209 and perplexity is 285.5094018034571
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.4070361328125 and perplexity of 222.9697546328478
Finished 41 epochs...
Completing Train Step...
At time: 1222.6964800357819 and batch: 50, loss is 5.711719417572022 and perplexity is 302.3905571832681
At time: 1223.7214827537537 and batch: 100, loss is 5.732245216369629 and perplexity is 308.6615028373891
At time: 1224.7463710308075 and batch: 150, loss is 5.690306186676025 and perplexity is 295.98423319611567
At time: 1225.7721545696259 and batch: 200, loss is 5.69069314956665 and perplexity is 296.0987902738121
At time: 1226.7975988388062 and batch: 250, loss is 5.713832511901855 and perplexity is 303.03021254309004
At time: 1227.82542014122 and batch: 300, loss is 5.738271083831787 and perplexity is 310.52707133334326
At time: 1228.8571314811707 and batch: 350, loss is 5.736291837692261 and perplexity is 309.91306965685396
At time: 1229.8826215267181 and batch: 400, loss is 5.774816331863403 and perplexity is 322.0852724837116
At time: 1230.9131548404694 and batch: 450, loss is 5.751654119491577 and perplexity is 314.7107992483459
At time: 1231.948203086853 and batch: 500, loss is 5.767439022064209 and perplexity is 319.717892830383
At time: 1233.0148298740387 and batch: 550, loss is 5.739991092681885 and perplexity is 311.06164024406996
At time: 1234.0403406620026 and batch: 600, loss is 5.695796279907227 and perplexity is 297.6136830543612
At time: 1235.065639257431 and batch: 650, loss is 5.723852033615112 and perplexity is 306.08169199140036
At time: 1236.0897481441498 and batch: 700, loss is 5.726025085449219 and perplexity is 306.7475465798138
At time: 1237.114054441452 and batch: 750, loss is 5.711537408828735 and perplexity is 302.3355244663431
At time: 1238.1364529132843 and batch: 800, loss is 5.68438982963562 and perplexity is 294.23825480288775
At time: 1239.159375667572 and batch: 850, loss is 5.679269599914551 and perplexity is 292.7355377568398
At time: 1240.1838059425354 and batch: 900, loss is 5.719478139877319 and perplexity is 304.7458467477835
At time: 1241.2093377113342 and batch: 950, loss is 5.696332969665527 and perplexity is 297.7734521393675
At time: 1242.234270811081 and batch: 1000, loss is 5.721631879806519 and perplexity is 305.4028973502583
At time: 1243.2593145370483 and batch: 1050, loss is 5.701454343795777 and perplexity is 299.3023731402893
At time: 1244.2846410274506 and batch: 1100, loss is 5.690471954345703 and perplexity is 296.0333018796023
At time: 1245.3165810108185 and batch: 1150, loss is 5.688709363937378 and perplexity is 295.5119759981316
At time: 1246.3449521064758 and batch: 1200, loss is 5.677019987106323 and perplexity is 292.0777363183638
At time: 1247.3843874931335 and batch: 1250, loss is 5.686348123550415 and perplexity is 294.81502434458815
At time: 1248.4185752868652 and batch: 1300, loss is 5.661446123123169 and perplexity is 287.5641952455984
At time: 1249.4419422149658 and batch: 1350, loss is 5.653072566986084 and perplexity is 285.1663137223598
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.406485595703125 and perplexity of 222.84703529252917
Finished 42 epochs...
Completing Train Step...
At time: 1252.6163551807404 and batch: 50, loss is 5.710495634078979 and perplexity is 302.0207229556035
At time: 1253.6393902301788 and batch: 100, loss is 5.730804109573365 and perplexity is 308.21700900637205
At time: 1254.663284778595 and batch: 150, loss is 5.6890864658355715 and perplexity is 295.6234351396254
At time: 1255.6871705055237 and batch: 200, loss is 5.689461555480957 and perplexity is 295.7343412276419
At time: 1256.7111184597015 and batch: 250, loss is 5.712038621902466 and perplexity is 302.487096965745
At time: 1257.7330176830292 and batch: 300, loss is 5.736550569534302 and perplexity is 309.9932644102596
At time: 1258.7572028636932 and batch: 350, loss is 5.734834871292114 and perplexity is 309.4618655018605
At time: 1259.8227021694183 and batch: 400, loss is 5.773166484832764 and perplexity is 321.55431916960384
At time: 1260.8461492061615 and batch: 450, loss is 5.749805860519409 and perplexity is 314.1296693946613
At time: 1261.8712503910065 and batch: 500, loss is 5.765941066741943 and perplexity is 319.2393282348721
At time: 1262.8956215381622 and batch: 550, loss is 5.738352861404419 and perplexity is 310.5524665218377
At time: 1263.9213557243347 and batch: 600, loss is 5.693975419998169 and perplexity is 297.0722633048495
At time: 1264.9467182159424 and batch: 650, loss is 5.722006711959839 and perplexity is 305.5173936330059
At time: 1265.9722816944122 and batch: 700, loss is 5.724849252700806 and perplexity is 306.38707473787997
At time: 1266.9970471858978 and batch: 750, loss is 5.7101537704467775 and perplexity is 301.9174907009358
At time: 1268.022712945938 and batch: 800, loss is 5.68330937385559 and perplexity is 293.92051506256
At time: 1269.0566494464874 and batch: 850, loss is 5.677986516952514 and perplexity is 292.3601746384691
At time: 1270.0843346118927 and batch: 900, loss is 5.718498840332031 and perplexity is 304.4475553607839
At time: 1271.1102690696716 and batch: 950, loss is 5.695343799591065 and perplexity is 297.47904918284405
At time: 1272.1435232162476 and batch: 1000, loss is 5.720627002716064 and perplexity is 305.0961591182751
At time: 1273.174246788025 and batch: 1050, loss is 5.700109786987305 and perplexity is 298.90021451983364
At time: 1274.1985895633698 and batch: 1100, loss is 5.68903154373169 and perplexity is 295.6071993244675
At time: 1275.2220335006714 and batch: 1150, loss is 5.687459592819214 and perplexity is 295.14288435353734
At time: 1276.2461287975311 and batch: 1200, loss is 5.675508108139038 and perplexity is 291.636483776281
At time: 1277.2686326503754 and batch: 1250, loss is 5.685328779220581 and perplexity is 294.5146594348145
At time: 1278.2924389839172 and batch: 1300, loss is 5.660364713668823 and perplexity is 287.253388690991
At time: 1279.3173394203186 and batch: 1350, loss is 5.651668453216553 and perplexity is 284.7661887508853
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.405605061848958 and perplexity of 222.65089729939774
Finished 43 epochs...
Completing Train Step...
At time: 1282.4058463573456 and batch: 50, loss is 5.7092191600799564 and perplexity is 301.6354473050733
At time: 1283.4539425373077 and batch: 100, loss is 5.729372138977051 and perplexity is 307.7759671670285
At time: 1284.4773170948029 and batch: 150, loss is 5.6878287220001225 and perplexity is 295.2518503147105
At time: 1285.5271582603455 and batch: 200, loss is 5.68848916053772 and perplexity is 295.44691042047066
At time: 1286.5505285263062 and batch: 250, loss is 5.710613842010498 and perplexity is 302.05642631070816
At time: 1287.5755791664124 and batch: 300, loss is 5.734823989868164 and perplexity is 309.4584981344264
At time: 1288.5985431671143 and batch: 350, loss is 5.733666925430298 and perplexity is 309.10064178259375
At time: 1289.6205275058746 and batch: 400, loss is 5.771782941818238 and perplexity is 321.10974255387856
At time: 1290.6431107521057 and batch: 450, loss is 5.748234272003174 and perplexity is 313.6363745434256
At time: 1291.6653718948364 and batch: 500, loss is 5.76416124343872 and perplexity is 318.671643977867
At time: 1292.6893537044525 and batch: 550, loss is 5.736621828079223 and perplexity is 310.0153548662745
At time: 1293.7136342525482 and batch: 600, loss is 5.692118453979492 and perplexity is 296.5211220904304
At time: 1294.7378318309784 and batch: 650, loss is 5.7203576946258545 and perplexity is 305.0140053171708
At time: 1295.7610566616058 and batch: 700, loss is 5.7232810974121096 and perplexity is 305.90698874931456
At time: 1296.7868540287018 and batch: 750, loss is 5.7063220119476314 and perplexity is 300.76282939430297
At time: 1297.8101496696472 and batch: 800, loss is 5.678860464096069 and perplexity is 292.6157936604709
At time: 1298.8331339359283 and batch: 850, loss is 5.6728376865386965 and perplexity is 290.8587303375382
At time: 1299.8569996356964 and batch: 900, loss is 5.712382011413574 and perplexity is 302.59098569821816
At time: 1300.8791954517365 and batch: 950, loss is 5.688546104431152 and perplexity is 295.4637347968708
At time: 1301.9013438224792 and batch: 1000, loss is 5.713881874084473 and perplexity is 303.04517114497196
At time: 1302.9248797893524 and batch: 1050, loss is 5.693054466247559 and perplexity is 296.7987994328743
At time: 1303.947557926178 and batch: 1100, loss is 5.681880502700806 and perplexity is 293.5008404186874
At time: 1304.9701132774353 and batch: 1150, loss is 5.680961790084839 and perplexity is 293.23132131805386
At time: 1305.9933414459229 and batch: 1200, loss is 5.667595739364624 and perplexity is 289.3380533742428
At time: 1307.0153307914734 and batch: 1250, loss is 5.679140586853027 and perplexity is 292.69777348499156
At time: 1308.0386180877686 and batch: 1300, loss is 5.653761854171753 and perplexity is 285.36294296741755
At time: 1309.0626990795135 and batch: 1350, loss is 5.644545545578003 and perplexity is 282.7450322906364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.4001708984375 and perplexity of 221.44425744818142
Finished 44 epochs...
Completing Train Step...
At time: 1312.191890001297 and batch: 50, loss is 5.70310869216919 and perplexity is 299.7979333360309
At time: 1313.216316461563 and batch: 100, loss is 5.722500143051147 and perplexity is 305.66818261288586
At time: 1314.2398409843445 and batch: 150, loss is 5.681986722946167 and perplexity is 293.532017805776
At time: 1315.2632503509521 and batch: 200, loss is 5.6821832180023195 and perplexity is 293.58970106314905
At time: 1316.286705493927 and batch: 250, loss is 5.703571386337281 and perplexity is 299.93668018759536
At time: 1317.308578491211 and batch: 300, loss is 5.728070573806763 and perplexity is 307.3756372721517
At time: 1318.3307120800018 and batch: 350, loss is 5.727407150268554 and perplexity is 307.1717846670986
At time: 1319.3552191257477 and batch: 400, loss is 5.7662607765197755 and perplexity is 319.3414084867352
At time: 1320.3777589797974 and batch: 450, loss is 5.741911382675171 and perplexity is 311.659542688435
At time: 1321.4007444381714 and batch: 500, loss is 5.758118972778321 and perplexity is 316.75194915153475
At time: 1322.4234375953674 and batch: 550, loss is 5.730025310516357 and perplexity is 307.97706333726245
At time: 1323.4459404945374 and batch: 600, loss is 5.6849987602233885 and perplexity is 294.4174800386549
At time: 1324.4691033363342 and batch: 650, loss is 5.714215669631958 and perplexity is 303.1463431582314
At time: 1325.4931585788727 and batch: 700, loss is 5.716926870346069 and perplexity is 303.96934890303083
At time: 1326.5161473751068 and batch: 750, loss is 5.702438039779663 and perplexity is 299.5969405413463
At time: 1327.5396225452423 and batch: 800, loss is 5.67597620010376 and perplexity is 291.7730284261899
At time: 1328.5623998641968 and batch: 850, loss is 5.670150270462036 and perplexity is 290.0781212900539
At time: 1329.5844051837921 and batch: 900, loss is 5.710279331207276 and perplexity is 301.95540207071633
At time: 1330.6060585975647 and batch: 950, loss is 5.686911249160767 and perplexity is 294.9810889883517
At time: 1331.629898071289 and batch: 1000, loss is 5.711803331375122 and perplexity is 302.4159329896181
At time: 1332.651179075241 and batch: 1050, loss is 5.691030149459839 and perplexity is 296.1985923502076
At time: 1333.6745400428772 and batch: 1100, loss is 5.680224418640137 and perplexity is 293.01518061280683
At time: 1334.69611287117 and batch: 1150, loss is 5.6791518115997315 and perplexity is 292.7010589617992
At time: 1335.717363357544 and batch: 1200, loss is 5.665920534133911 and perplexity is 288.8537585136846
At time: 1336.7403361797333 and batch: 1250, loss is 5.677619285583496 and perplexity is 292.25283052256
At time: 1337.7626264095306 and batch: 1300, loss is 5.652144927978515 and perplexity is 284.90190498299734
At time: 1338.7865612506866 and batch: 1350, loss is 5.6431889152526855 and perplexity is 282.3617118763372
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.398656005859375 and perplexity of 221.1090471540044
Finished 45 epochs...
Completing Train Step...
At time: 1341.8874855041504 and batch: 50, loss is 5.702130527496338 and perplexity is 299.5048249661445
At time: 1342.934340953827 and batch: 100, loss is 5.721040115356446 and perplexity is 305.2222242358926
At time: 1343.9578444957733 and batch: 150, loss is 5.6807084655761715 and perplexity is 293.1570480456723
At time: 1344.980665922165 and batch: 200, loss is 5.680675954818725 and perplexity is 293.147517442914
At time: 1346.0029034614563 and batch: 250, loss is 5.701420555114746 and perplexity is 299.29226027872255
At time: 1347.0254163742065 and batch: 300, loss is 5.725835695266723 and perplexity is 306.6894571069484
At time: 1348.0478653907776 and batch: 350, loss is 5.725144205093383 and perplexity is 306.47745766730407
At time: 1349.069536447525 and batch: 400, loss is 5.763601169586182 and perplexity is 318.49321429409395
At time: 1350.0904514789581 and batch: 450, loss is 5.739986457824707 and perplexity is 311.06019852113496
At time: 1351.11363363266 and batch: 500, loss is 5.754837770462036 and perplexity is 315.7143251803263
At time: 1352.1358194351196 and batch: 550, loss is 5.727252807617187 and perplexity is 307.1243786179097
At time: 1353.1587007045746 and batch: 600, loss is 5.6817869949340825 and perplexity is 293.4733970936704
At time: 1354.1824226379395 and batch: 650, loss is 5.711104812622071 and perplexity is 302.2047635506963
At time: 1355.2050635814667 and batch: 700, loss is 5.714631690979004 and perplexity is 303.2724847452411
At time: 1356.2275638580322 and batch: 750, loss is 5.6999582862854 and perplexity is 298.85493435760924
At time: 1357.251436471939 and batch: 800, loss is 5.673304471969605 and perplexity is 290.9945306476496
At time: 1358.2863237857819 and batch: 850, loss is 5.666698064804077 and perplexity is 289.0784385065952
At time: 1359.314049243927 and batch: 900, loss is 5.708194446563721 and perplexity is 301.3265156954745
At time: 1360.336238861084 and batch: 950, loss is 5.684911298751831 and perplexity is 294.3917309786402
At time: 1361.3587126731873 and batch: 1000, loss is 5.708828763961792 and perplexity is 301.5177129803516
At time: 1362.381144285202 and batch: 1050, loss is 5.687056407928467 and perplexity is 295.02391118765775
At time: 1363.4030702114105 and batch: 1100, loss is 5.676950635910035 and perplexity is 292.05748108031145
At time: 1364.4689583778381 and batch: 1150, loss is 5.676313362121582 and perplexity is 291.8714197951844
At time: 1365.4906194210052 and batch: 1200, loss is 5.6632076930999755 and perplexity is 288.0712061348177
At time: 1366.5114986896515 and batch: 1250, loss is 5.6749833393096925 and perplexity is 291.4834821888384
At time: 1367.5343980789185 and batch: 1300, loss is 5.6489606285095215 and perplexity is 283.9961348852231
At time: 1368.5561583042145 and batch: 1350, loss is 5.640816278457642 and perplexity is 281.6925642253056
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.3955611165364585 and perplexity of 220.42579696199607
Finished 46 epochs...
Completing Train Step...
At time: 1371.6742749214172 and batch: 50, loss is 5.699657096862793 and perplexity is 298.7649359664487
At time: 1372.724006652832 and batch: 100, loss is 5.718490915298462 and perplexity is 304.44514261324827
At time: 1373.746696472168 and batch: 150, loss is 5.678565435409546 and perplexity is 292.52947634087997
At time: 1374.768033504486 and batch: 200, loss is 5.677775678634643 and perplexity is 292.2985404086928
At time: 1375.7889995574951 and batch: 250, loss is 5.6982475280761715 and perplexity is 298.34410290442673
At time: 1376.8108875751495 and batch: 300, loss is 5.7242059326171875 and perplexity is 306.19003316653567
At time: 1377.8329255580902 and batch: 350, loss is 5.723294315338134 and perplexity is 305.91103223198553
At time: 1378.8528549671173 and batch: 400, loss is 5.761266641616821 and perplexity is 317.75055019961746
At time: 1379.8722124099731 and batch: 450, loss is 5.738081455230713 and perplexity is 310.46819210198026
At time: 1380.8951859474182 and batch: 500, loss is 5.752842655181885 and perplexity is 315.0850666363941
At time: 1381.9179730415344 and batch: 550, loss is 5.72511658668518 and perplexity is 306.468993364659
At time: 1382.9401187896729 and batch: 600, loss is 5.679351434707642 and perplexity is 292.75949468924455
At time: 1383.9631931781769 and batch: 650, loss is 5.70900668144226 and perplexity is 301.57136302466046
At time: 1384.9846732616425 and batch: 700, loss is 5.713180456161499 and perplexity is 302.83268436019154
At time: 1386.0067553520203 and batch: 750, loss is 5.697868843078613 and perplexity is 298.2311458574661
At time: 1387.0292346477509 and batch: 800, loss is 5.67154902458191 and perplexity is 290.4841531604687
At time: 1388.0519676208496 and batch: 850, loss is 5.664307975769043 and perplexity is 288.3883403270189
At time: 1389.0730941295624 and batch: 900, loss is 5.705929384231568 and perplexity is 300.6447647507634
At time: 1390.1208684444427 and batch: 950, loss is 5.682832326889038 and perplexity is 293.7803346114298
At time: 1391.1415712833405 and batch: 1000, loss is 5.707021455764771 and perplexity is 300.9732696827482
At time: 1392.1639490127563 and batch: 1050, loss is 5.686218271255493 and perplexity is 294.7767444225212
At time: 1393.1860995292664 and batch: 1100, loss is 5.675467319488526 and perplexity is 291.62458856026416
At time: 1394.2081544399261 and batch: 1150, loss is 5.675224094390869 and perplexity is 291.55366676656234
At time: 1395.229379415512 and batch: 1200, loss is 5.662054567337036 and perplexity is 287.7392152558678
At time: 1396.2522962093353 and batch: 1250, loss is 5.673729963302613 and perplexity is 291.1183726433724
At time: 1397.2764763832092 and batch: 1300, loss is 5.647688961029052 and perplexity is 283.63521576910017
At time: 1398.3010354042053 and batch: 1350, loss is 5.639914608001709 and perplexity is 281.4386848374598
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.394580078125 and perplexity of 220.20965682652272
Finished 47 epochs...
Completing Train Step...
At time: 1401.4241321086884 and batch: 50, loss is 5.698574085235595 and perplexity is 298.44154521657845
At time: 1402.4465928077698 and batch: 100, loss is 5.717080287933349 and perplexity is 304.0159867245863
At time: 1403.4718053340912 and batch: 150, loss is 5.676950721740723 and perplexity is 292.05750614780715
At time: 1404.4947617053986 and batch: 200, loss is 5.676187114715576 and perplexity is 291.83457411143297
At time: 1405.5192539691925 and batch: 250, loss is 5.696772356033325 and perplexity is 297.90431848326784
At time: 1406.5417692661285 and batch: 300, loss is 5.723135242462158 and perplexity is 305.86237395450416
At time: 1407.5629386901855 and batch: 350, loss is 5.722235040664673 and perplexity is 305.58715998832605
At time: 1408.5834295749664 and batch: 400, loss is 5.760316820144653 and perplexity is 317.4488871899257
At time: 1409.6038796901703 and batch: 450, loss is 5.736658554077149 and perplexity is 310.02674069863093
At time: 1410.6283042430878 and batch: 500, loss is 5.751056566238403 and perplexity is 314.5227989621315
At time: 1411.6508347988129 and batch: 550, loss is 5.723673496246338 and perplexity is 306.0270498494595
At time: 1412.6833636760712 and batch: 600, loss is 5.677827777862549 and perplexity is 292.31376933367034
At time: 1413.7066097259521 and batch: 650, loss is 5.707539653778076 and perplexity is 301.1292738501895
At time: 1414.7288298606873 and batch: 700, loss is 5.711865816116333 and perplexity is 302.4348299613092
At time: 1415.751550912857 and batch: 750, loss is 5.695986413955689 and perplexity is 297.67027492864867
At time: 1416.8126845359802 and batch: 800, loss is 5.6698673057556155 and perplexity is 289.9960510316648
At time: 1417.8396208286285 and batch: 850, loss is 5.662878513336182 and perplexity is 287.9763945291136
At time: 1418.864316701889 and batch: 900, loss is 5.704246110916138 and perplexity is 300.139123126752
At time: 1419.892213344574 and batch: 950, loss is 5.680864295959473 and perplexity is 293.20273438040374
At time: 1420.9202370643616 and batch: 1000, loss is 5.705064077377319 and perplexity is 300.38472729745126
At time: 1421.946444272995 and batch: 1050, loss is 5.684412155151367 and perplexity is 294.24482389700773
At time: 1422.9724488258362 and batch: 1100, loss is 5.674438714981079 and perplexity is 291.3247764144852
At time: 1424.0007600784302 and batch: 1150, loss is 5.674071998596191 and perplexity is 291.217962432066
At time: 1425.0293741226196 and batch: 1200, loss is 5.661326789855957 and perplexity is 287.5298813180839
At time: 1426.0902020931244 and batch: 1250, loss is 5.672725257873535 and perplexity is 290.8260313169238
At time: 1427.1397953033447 and batch: 1300, loss is 5.646809644699097 and perplexity is 283.38592031296963
At time: 1428.1729173660278 and batch: 1350, loss is 5.638800773620606 and perplexity is 281.1253832695353
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.3935164388020835 and perplexity of 219.9755576968262
Finished 48 epochs...
Completing Train Step...
At time: 1431.4548106193542 and batch: 50, loss is 5.697069835662842 and perplexity is 297.9929521322607
At time: 1432.536943435669 and batch: 100, loss is 5.715543670654297 and perplexity is 303.54918924266525
At time: 1433.5630807876587 and batch: 150, loss is 5.675477504730225 and perplexity is 291.6275588423105
At time: 1434.5899741649628 and batch: 200, loss is 5.674603338241577 and perplexity is 291.37273919682895
At time: 1435.617022037506 and batch: 250, loss is 5.6953768539428715 and perplexity is 297.488882322504
At time: 1436.6430785655975 and batch: 300, loss is 5.722081727981568 and perplexity is 305.5403131921015
At time: 1437.6683197021484 and batch: 350, loss is 5.721340761184693 and perplexity is 305.31400181988
At time: 1438.6934278011322 and batch: 400, loss is 5.759380311965942 and perplexity is 317.1517328761904
At time: 1439.718249797821 and batch: 450, loss is 5.735085229873658 and perplexity is 309.5393516348038
At time: 1440.7452793121338 and batch: 500, loss is 5.749464483261108 and perplexity is 314.0224509713793
At time: 1441.7732396125793 and batch: 550, loss is 5.7223532772064205 and perplexity is 305.6232936934456
At time: 1442.845504283905 and batch: 600, loss is 5.676254234313965 and perplexity is 291.85416258822124
At time: 1443.8727872371674 and batch: 650, loss is 5.706015920639038 and perplexity is 300.67078259435874
At time: 1444.9071531295776 and batch: 700, loss is 5.710812072753907 and perplexity is 302.1163091157574
At time: 1445.936633348465 and batch: 750, loss is 5.694277029037476 and perplexity is 297.161876498185
At time: 1446.9623582363129 and batch: 800, loss is 5.668544645309448 and perplexity is 289.6127382776113
At time: 1447.9888303279877 and batch: 850, loss is 5.661658277511597 and perplexity is 287.6252097235902
At time: 1449.0141327381134 and batch: 900, loss is 5.702880964279175 and perplexity is 299.72966875841064
At time: 1450.0407021045685 and batch: 950, loss is 5.679470129013062 and perplexity is 292.79424563645074
At time: 1451.0668308734894 and batch: 1000, loss is 5.703897638320923 and perplexity is 300.03455108889335
At time: 1452.0918402671814 and batch: 1050, loss is 5.683745946884155 and perplexity is 294.04886084609336
At time: 1453.1173601150513 and batch: 1100, loss is 5.6735100841522215 and perplexity is 291.0543688197434
At time: 1454.1453964710236 and batch: 1150, loss is 5.6726608562469485 and perplexity is 290.807302250551
At time: 1455.1708133220673 and batch: 1200, loss is 5.659951181411743 and perplexity is 287.13462470687335
At time: 1456.1954820156097 and batch: 1250, loss is 5.671408567428589 and perplexity is 290.4433554484633
At time: 1457.221517086029 and batch: 1300, loss is 5.645330324172973 and perplexity is 282.9670116307369
At time: 1458.2491936683655 and batch: 1350, loss is 5.637459878921509 and perplexity is 280.7486763519252
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.392211507161458 and perplexity of 219.6886918422959
Finished 49 epochs...
Completing Train Step...
At time: 1461.4328286647797 and batch: 50, loss is 5.695123643875122 and perplexity is 297.4135646784517
At time: 1462.4580538272858 and batch: 100, loss is 5.7142054557800295 and perplexity is 303.14324688218215
At time: 1463.484301328659 and batch: 150, loss is 5.673978652954101 and perplexity is 291.1907797730858
At time: 1464.5098767280579 and batch: 200, loss is 5.672994050979614 and perplexity is 290.90421385620334
At time: 1465.5381319522858 and batch: 250, loss is 5.69376784324646 and perplexity is 297.0106044091078
At time: 1466.564439535141 and batch: 300, loss is 5.721018056869507 and perplexity is 305.2154915697025
At time: 1467.591027021408 and batch: 350, loss is 5.7203744029998775 and perplexity is 305.01910164782953
At time: 1468.6167731285095 and batch: 400, loss is 5.758188877105713 and perplexity is 316.7740922574309
At time: 1469.6842024326324 and batch: 450, loss is 5.7333090877532955 and perplexity is 308.990053714447
At time: 1470.7098906040192 and batch: 500, loss is 5.747624778747559 and perplexity is 313.4452735317306
At time: 1471.7372016906738 and batch: 550, loss is 5.720455894470215 and perplexity is 305.0439591157257
At time: 1472.765640258789 and batch: 600, loss is 5.674707489013672 and perplexity is 291.40308747295444
At time: 1473.7920002937317 and batch: 650, loss is 5.704501800537109 and perplexity is 300.21587539734423
At time: 1474.819422006607 and batch: 700, loss is 5.709209814071655 and perplexity is 301.6326282308523
At time: 1475.8453323841095 and batch: 750, loss is 5.692750415802002 and perplexity is 296.7085713433066
At time: 1476.8722429275513 and batch: 800, loss is 5.667234296798706 and perplexity is 289.2334931832037
At time: 1477.8979620933533 and batch: 850, loss is 5.659757871627807 and perplexity is 287.079124139185
At time: 1478.9225780963898 and batch: 900, loss is 5.701509866714478 and perplexity is 299.31899174297257
At time: 1479.9481871128082 and batch: 950, loss is 5.677854442596436 and perplexity is 292.32156390646065
At time: 1480.9741277694702 and batch: 1000, loss is 5.702226209640503 and perplexity is 299.533483601023
At time: 1482.00088763237 and batch: 1050, loss is 5.681895799636841 and perplexity is 293.5053301166088
At time: 1483.0275721549988 and batch: 1100, loss is 5.6719628429412845 and perplexity is 290.6043857116567
At time: 1484.0548963546753 and batch: 1150, loss is 5.671383600234986 and perplexity is 290.4361039835018
At time: 1485.081211566925 and batch: 1200, loss is 5.6589373588562015 and perplexity is 286.8436686616905
At time: 1486.1062381267548 and batch: 1250, loss is 5.669910821914673 and perplexity is 290.0086708205279
At time: 1487.1333575248718 and batch: 1300, loss is 5.644190006256103 and perplexity is 282.64452318211414
At time: 1488.1593647003174 and batch: 1350, loss is 5.6363229560852055 and perplexity is 280.42966814873677
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 5.391801350911458 and perplexity of 219.59860362866732
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fec148f35c0>
SETTINGS FOR THIS RUN
{'wordvec_dim': 200, 'dropout': 0.026111274635561753, 'num_layers': 1, 'wordvec_source': 'glove', 'tune_wordvecs': True, 'batch_size': 80, 'seq_len': 20, 'lr': 5.900792486470094, 'data': 'wikitext', 'anneal': 2.717571535734867}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.train.tokens...
Got Train Dataset with 2199934 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.valid.tokens...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/wikitext-2/wikitext-2/wiki.test.tokens...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 20471 tokens
Getting Batches...
Created Iterator with 1375 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 1.5436522960662842 and batch: 50, loss is 7.410185298919678 and perplexity is 1652.7325680517554
At time: 2.570794105529785 and batch: 100, loss is 6.58124997138977 and perplexity is 721.4405459261162
At time: 3.6220555305480957 and batch: 150, loss is 6.231560802459716 and perplexity is 508.54860829792824
At time: 4.652405500411987 and batch: 200, loss is 5.995796566009521 and perplexity is 401.73656626379955
At time: 5.680808782577515 and batch: 250, loss is 5.808496255874633 and perplexity is 333.1178248827488
At time: 6.711054563522339 and batch: 300, loss is 5.664092102050781 and perplexity is 288.32609158286476
At time: 7.739603519439697 and batch: 350, loss is 5.5748934555053715 and perplexity is 263.72145607077874
At time: 8.768280982971191 and batch: 400, loss is 5.527514390945434 and perplexity is 251.51795809462752
At time: 9.798690557479858 and batch: 450, loss is 5.4341029453277585 and perplexity is 229.0872522841006
At time: 10.828122854232788 and batch: 500, loss is 5.413218011856079 and perplexity is 224.35239594383106
At time: 11.857216119766235 and batch: 550, loss is 5.355238809585571 and perplexity is 211.71452977544794
At time: 12.890629053115845 and batch: 600, loss is 5.256303195953369 and perplexity is 191.77123858275158
At time: 13.91912579536438 and batch: 650, loss is 5.250270586013794 and perplexity is 190.61784000253047
At time: 14.947602033615112 and batch: 700, loss is 5.248359832763672 and perplexity is 190.2539640944599
At time: 15.977516412734985 and batch: 750, loss is 5.186496839523316 and perplexity is 178.8409457365943
At time: 17.006367921829224 and batch: 800, loss is 5.123701162338257 and perplexity is 167.95585253468744
At time: 18.03549551963806 and batch: 850, loss is 5.091279754638672 and perplexity is 162.59781426824958
At time: 19.06609082221985 and batch: 900, loss is 5.139644575119019 and perplexity is 170.6551024714005
At time: 20.09522008895874 and batch: 950, loss is 5.0778271675109865 and perplexity is 160.42510008508305
At time: 21.125107526779175 and batch: 1000, loss is 5.081114749908448 and perplexity is 160.95337872419958
At time: 22.155899047851562 and batch: 1050, loss is 5.011729688644409 and perplexity is 150.16424904245787
At time: 23.185785055160522 and batch: 1100, loss is 4.9777896690368655 and perplexity is 145.15319022394593
At time: 24.215185165405273 and batch: 1150, loss is 4.9831469535827635 and perplexity is 145.93290387582257
At time: 25.246453523635864 and batch: 1200, loss is 4.959804286956787 and perplexity is 142.5658911620002
At time: 26.275930643081665 and batch: 1250, loss is 4.997546377182007 and perplexity is 148.04945556702498
At time: 27.309091329574585 and batch: 1300, loss is 4.9716996002197265 and perplexity is 144.27188363922193
At time: 28.34890842437744 and batch: 1350, loss is 4.921432886123657 and perplexity is 137.19906304133224
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.73225341796875 and perplexity of 113.55115247216956
Finished 1 epochs...
Completing Train Step...
At time: 31.553256273269653 and batch: 50, loss is 4.957018041610718 and perplexity is 142.16922047878265
At time: 32.57676100730896 and batch: 100, loss is 4.963679161071777 and perplexity is 143.1193877155321
At time: 33.62687826156616 and batch: 150, loss is 4.890087728500366 and perplexity is 132.96523838059218
At time: 34.65147352218628 and batch: 200, loss is 4.87236590385437 and perplexity is 130.62960867959714
At time: 35.677342891693115 and batch: 250, loss is 4.855970611572266 and perplexity is 128.5053594917174
At time: 36.70184922218323 and batch: 300, loss is 4.828581848144531 and perplexity is 125.0335183483943
At time: 37.72650456428528 and batch: 350, loss is 4.8114941120147705 and perplexity is 122.91512936107642
At time: 38.75004982948303 and batch: 400, loss is 4.8234336376190186 and perplexity is 124.39147358206921
At time: 39.775015354156494 and batch: 450, loss is 4.774821367263794 and perplexity is 118.48914668965294
At time: 40.8002655506134 and batch: 500, loss is 4.831390247344971 and perplexity is 125.38515591957209
At time: 41.82410192489624 and batch: 550, loss is 4.805080070495605 and perplexity is 122.12926958083303
At time: 42.84705972671509 and batch: 600, loss is 4.729754991531372 and perplexity is 113.26780737666695
At time: 43.870461225509644 and batch: 650, loss is 4.750073041915893 and perplexity is 115.5927273331123
At time: 44.89601802825928 and batch: 700, loss is 4.763943271636963 and perplexity is 117.2071956555873
At time: 45.919912815093994 and batch: 750, loss is 4.70725570678711 and perplexity is 110.74781800969652
At time: 46.943668842315674 and batch: 800, loss is 4.668414096832276 and perplexity is 106.52866425098719
At time: 47.968225717544556 and batch: 850, loss is 4.636346769332886 and perplexity is 103.16676631295769
At time: 48.9920437335968 and batch: 900, loss is 4.685797834396363 and perplexity is 108.39672044997555
At time: 50.016560077667236 and batch: 950, loss is 4.645120210647583 and perplexity is 104.07587606192523
At time: 51.041173696517944 and batch: 1000, loss is 4.655303592681885 and perplexity is 105.1411352332606
At time: 52.066240549087524 and batch: 1050, loss is 4.58274715423584 and perplexity is 97.78264958890246
At time: 53.09066581726074 and batch: 1100, loss is 4.563399620056153 and perplexity is 95.90898032063612
At time: 54.11500787734985 and batch: 1150, loss is 4.586380643844604 and perplexity is 98.1385880879211
At time: 55.140493869781494 and batch: 1200, loss is 4.56278883934021 and perplexity is 95.8504188508993
At time: 56.164528369903564 and batch: 1250, loss is 4.616571397781372 and perplexity is 101.14664533168498
At time: 57.1935670375824 and batch: 1300, loss is 4.599654378890992 and perplexity is 99.44993770364549
At time: 58.219192028045654 and batch: 1350, loss is 4.555095014572143 and perplexity is 95.11579219254912
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.562949625651042 and perplexity of 95.86583152517832
Finished 2 epochs...
Completing Train Step...
At time: 61.336249351501465 and batch: 50, loss is 4.6290279006958 and perplexity is 102.414458681129
At time: 62.38664793968201 and batch: 100, loss is 4.639308204650879 and perplexity is 103.4727408566512
At time: 63.410786390304565 and batch: 150, loss is 4.592621641159058 and perplexity is 98.75298598620434
At time: 64.43541312217712 and batch: 200, loss is 4.579171409606934 and perplexity is 97.43362818242532
At time: 65.4593858718872 and batch: 250, loss is 4.572868328094483 and perplexity is 96.82142748422281
At time: 66.48312473297119 and batch: 300, loss is 4.564594449996949 and perplexity is 96.02364372991038
At time: 67.51015996932983 and batch: 350, loss is 4.561845827102661 and perplexity is 95.76007333810593
At time: 68.5350604057312 and batch: 400, loss is 4.57724214553833 and perplexity is 97.2458341948439
At time: 69.55940437316895 and batch: 450, loss is 4.525892753601074 and perplexity is 92.37836014009495
At time: 70.58411049842834 and batch: 500, loss is 4.5903706741333 and perplexity is 98.53094626685117
At time: 71.60834455490112 and batch: 550, loss is 4.575967378616333 and perplexity is 97.12194740227962
At time: 72.63250064849854 and batch: 600, loss is 4.506211652755737 and perplexity is 90.57802670246886
At time: 73.6582293510437 and batch: 650, loss is 4.526578025817871 and perplexity is 92.4416861590348
At time: 74.68187952041626 and batch: 700, loss is 4.550165843963623 and perplexity is 94.64810383007348
At time: 75.70574617385864 and batch: 750, loss is 4.496166639328003 and perplexity is 89.67272371058932
At time: 76.73140096664429 and batch: 800, loss is 4.465362224578858 and perplexity is 86.9525201760682
At time: 77.75500249862671 and batch: 850, loss is 4.434394378662109 and perplexity is 84.30105490765779
At time: 78.77854657173157 and batch: 900, loss is 4.475893583297729 and perplexity is 87.87308726035859
At time: 79.80378770828247 and batch: 950, loss is 4.4439303493499756 and perplexity is 85.10879245606515
At time: 80.82847666740417 and batch: 1000, loss is 4.459170408248902 and perplexity is 86.41578952530554
At time: 81.89674544334412 and batch: 1050, loss is 4.393490343093872 and perplexity is 80.92237348268489
At time: 82.92179155349731 and batch: 1100, loss is 4.370711793899536 and perplexity is 79.09991450290713
At time: 83.94657778739929 and batch: 1150, loss is 4.399161586761474 and perplexity is 81.38260779779594
At time: 84.97149658203125 and batch: 1200, loss is 4.376854066848755 and perplexity is 79.58726294943085
At time: 85.99722480773926 and batch: 1250, loss is 4.4302231884002685 and perplexity is 83.95015151953727
At time: 87.02262139320374 and batch: 1300, loss is 4.419161148071289 and perplexity is 83.02660910721683
At time: 88.04707598686218 and batch: 1350, loss is 4.377082347869873 and perplexity is 79.60543328497742
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.511151529947917 and perplexity of 91.02657801273942
Finished 3 epochs...
Completing Train Step...
At time: 91.19749188423157 and batch: 50, loss is 4.4617360496520995 and perplexity is 86.63778611284522
At time: 92.22028255462646 and batch: 100, loss is 4.4684059524536135 and perplexity is 87.21758317068625
At time: 93.24418187141418 and batch: 150, loss is 4.4344869899749755 and perplexity is 84.30886250055894
At time: 94.26465106010437 and batch: 200, loss is 4.419903793334961 and perplexity is 83.08829132639805
At time: 95.29130935668945 and batch: 250, loss is 4.4131450271606445 and perplexity is 82.5286104999781
At time: 96.31492304801941 and batch: 300, loss is 4.411733245849609 and perplexity is 82.41218035633725
At time: 97.3390462398529 and batch: 350, loss is 4.41476803779602 and perplexity is 82.66266406829929
At time: 98.3660957813263 and batch: 400, loss is 4.430178623199463 and perplexity is 83.94641034754083
At time: 99.39054703712463 and batch: 450, loss is 4.3778766250610355 and perplexity is 79.66868718216672
At time: 100.41701817512512 and batch: 500, loss is 4.4484360408782955 and perplexity is 85.49313162788143
At time: 101.44149279594421 and batch: 550, loss is 4.43835940361023 and perplexity is 84.63597423648284
At time: 102.46552753448486 and batch: 600, loss is 4.372455787658692 and perplexity is 79.23798462186762
At time: 103.48974466323853 and batch: 650, loss is 4.392178773880005 and perplexity is 80.81630776038456
At time: 104.51514291763306 and batch: 700, loss is 4.413438835144043 and perplexity is 82.55286162701468
At time: 105.5395495891571 and batch: 750, loss is 4.36954628944397 and perplexity is 79.0077769039401
At time: 106.5646162033081 and batch: 800, loss is 4.33846586227417 and perplexity is 76.58994963080737
At time: 107.61501336097717 and batch: 850, loss is 4.3070716381073 and perplexity is 74.22281911282136
At time: 108.63962268829346 and batch: 900, loss is 4.3471220588684085 and perplexity is 77.25580502184619
At time: 109.66396951675415 and batch: 950, loss is 4.320544672012329 and perplexity is 75.22959258853936
At time: 110.68935132026672 and batch: 1000, loss is 4.338239784240723 and perplexity is 76.57263628277062
At time: 111.71379113197327 and batch: 1050, loss is 4.271860303878785 and perplexity is 71.65481143071088
At time: 112.7397837638855 and batch: 1100, loss is 4.249227104187011 and perplexity is 70.05124910098645
At time: 113.76351928710938 and batch: 1150, loss is 4.276152667999267 and perplexity is 71.9630410159172
At time: 114.78770399093628 and batch: 1200, loss is 4.254800114631653 and perplexity is 70.442735309004
At time: 115.8125102519989 and batch: 1250, loss is 4.307320413589477 and perplexity is 74.24128622742212
At time: 116.83829355239868 and batch: 1300, loss is 4.30191216468811 and perplexity is 73.84085466554717
At time: 117.86190891265869 and batch: 1350, loss is 4.261897068023682 and perplexity is 70.94444230811624
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.496874186197917 and perplexity of 89.73619381695708
Finished 4 epochs...
Completing Train Step...
At time: 121.00934076309204 and batch: 50, loss is 4.350713939666748 and perplexity is 77.53379762372955
At time: 122.03520655632019 and batch: 100, loss is 4.355006160736084 and perplexity is 77.8673050552664
At time: 123.06113648414612 and batch: 150, loss is 4.327031726837158 and perplexity is 75.7191974098134
At time: 124.08600044250488 and batch: 200, loss is 4.311508226394653 and perplexity is 74.55284675981184
At time: 125.11201095581055 and batch: 250, loss is 4.309913129806518 and perplexity is 74.43402256154019
At time: 126.13730359077454 and batch: 300, loss is 4.308014392852783 and perplexity is 74.29282602225105
At time: 127.16251158714294 and batch: 350, loss is 4.31197714805603 and perplexity is 74.58781440247665
At time: 128.1875286102295 and batch: 400, loss is 4.329905939102173 and perplexity is 75.937143517354
At time: 129.22418999671936 and batch: 450, loss is 4.276936006546021 and perplexity is 72.01943452460746
At time: 130.26347494125366 and batch: 500, loss is 4.3474667263031 and perplexity is 77.28243717133176
At time: 131.28778839111328 and batch: 550, loss is 4.340875339508057 and perplexity is 76.77471387401755
At time: 132.3098430633545 and batch: 600, loss is 4.27625048160553 and perplexity is 71.97008032474106
At time: 133.33315920829773 and batch: 650, loss is 4.294637241363525 and perplexity is 73.30561737535234
At time: 134.4107322692871 and batch: 700, loss is 4.319928102493286 and perplexity is 75.18322261144544
At time: 135.43309044837952 and batch: 750, loss is 4.279134292602539 and perplexity is 72.17792798647874
At time: 136.4562668800354 and batch: 800, loss is 4.244134483337402 and perplexity is 69.69541149133596
At time: 137.48204517364502 and batch: 850, loss is 4.2199387359619145 and perplexity is 68.0293164111189
At time: 138.5096137523651 and batch: 900, loss is 4.2583963537216185 and perplexity is 70.69652028954472
At time: 139.53438782691956 and batch: 950, loss is 4.233512763977051 and perplexity is 68.95904405701226
At time: 140.56121182441711 and batch: 1000, loss is 4.251909999847412 and perplexity is 70.23944163078289
At time: 141.5856750011444 and batch: 1050, loss is 4.185697245597839 and perplexity is 65.739321393265
At time: 142.6110246181488 and batch: 1100, loss is 4.163458480834961 and perplexity is 64.29349635765476
At time: 143.6360478401184 and batch: 1150, loss is 4.191225848197937 and perplexity is 66.10377450635725
At time: 144.6625680923462 and batch: 1200, loss is 4.164950647354126 and perplexity is 64.3895045726277
At time: 145.68792533874512 and batch: 1250, loss is 4.214848408699035 and perplexity is 67.68390480202383
At time: 146.71324563026428 and batch: 1300, loss is 4.215991287231446 and perplexity is 67.76130350404458
At time: 147.73877549171448 and batch: 1350, loss is 4.178933486938477 and perplexity is 65.29617683976564
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.486116129557292 and perplexity of 88.77598103381122
Finished 5 epochs...
Completing Train Step...
At time: 150.87342834472656 and batch: 50, loss is 4.271179256439209 and perplexity is 71.60602771874936
At time: 151.9262340068817 and batch: 100, loss is 4.2707917022705075 and perplexity is 71.57828188105763
At time: 152.95192623138428 and batch: 150, loss is 4.251158657073975 and perplexity is 70.186687554582
At time: 153.9788556098938 and batch: 200, loss is 4.228667726516724 and perplexity is 68.62574298541941
At time: 155.00473308563232 and batch: 250, loss is 4.230134429931641 and perplexity is 68.72647044760649
At time: 156.03203988075256 and batch: 300, loss is 4.231443967819214 and perplexity is 68.81652931941908
At time: 157.05848789215088 and batch: 350, loss is 4.2347926330566406 and perplexity is 69.04735910905562
At time: 158.0857880115509 and batch: 400, loss is 4.250405445098877 and perplexity is 70.133842005472
At time: 159.11176013946533 and batch: 450, loss is 4.20227765083313 and perplexity is 66.83839232389555
At time: 160.1618299484253 and batch: 500, loss is 4.271799898147583 and perplexity is 71.65048320015856
At time: 161.1911425590515 and batch: 550, loss is 4.2676614475250245 and perplexity is 71.35457393861688
At time: 162.21689200401306 and batch: 600, loss is 4.204162130355835 and perplexity is 66.964466660503
At time: 163.2422971725464 and batch: 650, loss is 4.22179901599884 and perplexity is 68.15598777593948
At time: 164.26883482933044 and batch: 700, loss is 4.246235618591308 and perplexity is 69.8420049298454
At time: 165.2951090335846 and batch: 750, loss is 4.208156614303589 and perplexity is 67.23249009892997
At time: 166.32101559638977 and batch: 800, loss is 4.177258820533752 and perplexity is 65.1869190367757
At time: 167.3470344543457 and batch: 850, loss is 4.154002518653869 and perplexity is 63.68840485747003
At time: 168.37455081939697 and batch: 900, loss is 4.186703205108643 and perplexity is 65.80548576261302
At time: 169.40060782432556 and batch: 950, loss is 4.16840030670166 and perplexity is 64.61200999225615
At time: 170.42683243751526 and batch: 1000, loss is 4.184547543525696 and perplexity is 65.66378419019782
At time: 171.45396304130554 and batch: 1050, loss is 4.120636763572693 and perplexity is 61.598453430261216
At time: 172.4811098575592 and batch: 1100, loss is 4.097989630699158 and perplexity is 60.219103189094064
At time: 173.50796556472778 and batch: 1150, loss is 4.121054081916809 and perplexity is 61.624164959420085
At time: 174.53442525863647 and batch: 1200, loss is 4.097364339828491 and perplexity is 60.18146050367046
At time: 175.5622181892395 and batch: 1250, loss is 4.148448758125305 and perplexity is 63.33567510337824
At time: 176.58893585205078 and batch: 1300, loss is 4.146533203125 and perplexity is 63.214468260485816
At time: 177.61420965194702 and batch: 1350, loss is 4.112953252792359 and perplexity is 61.1269746748571
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.4913330078125 and perplexity of 89.24032467785716
Annealing...
Finished 6 epochs...
Completing Train Step...
At time: 180.75353384017944 and batch: 50, loss is 4.196175255775452 and perplexity is 66.43176002626525
At time: 181.8151080608368 and batch: 100, loss is 4.199066753387451 and perplexity is 66.62412527955078
At time: 182.84236669540405 and batch: 150, loss is 4.17470694065094 and perplexity is 65.02078192060382
At time: 183.8685338497162 and batch: 200, loss is 4.148239727020264 and perplexity is 63.32243736082104
At time: 184.8944833278656 and batch: 250, loss is 4.137432632446289 and perplexity is 62.641790324625035
At time: 185.9470694065094 and batch: 300, loss is 4.134398846626282 and perplexity is 62.45203653112124
At time: 186.97344517707825 and batch: 350, loss is 4.133188719749451 and perplexity is 62.3765073523638
At time: 187.9992561340332 and batch: 400, loss is 4.139682812690735 and perplexity is 62.78290435014445
At time: 189.02471828460693 and batch: 450, loss is 4.083399224281311 and perplexity is 59.34686065947259
At time: 190.0515854358673 and batch: 500, loss is 4.149710807800293 and perplexity is 63.41565833234545
At time: 191.0770149230957 and batch: 550, loss is 4.13715690612793 and perplexity is 62.62452071535574
At time: 192.10483837127686 and batch: 600, loss is 4.065533475875855 and perplexity is 58.295999738126994
At time: 193.1318702697754 and batch: 650, loss is 4.078126034736633 and perplexity is 59.03473708098474
At time: 194.15774655342102 and batch: 700, loss is 4.095344343185425 and perplexity is 60.06001685465462
At time: 195.18367910385132 and batch: 750, loss is 4.049398126602173 and perplexity is 57.36292143702218
At time: 196.20937848091125 and batch: 800, loss is 4.016418504714966 and perplexity is 55.50196939486377
At time: 197.23715567588806 and batch: 850, loss is 3.9827306270599365 and perplexity is 53.66336899122652
At time: 198.26290607452393 and batch: 900, loss is 4.013155078887939 and perplexity is 55.32113805980133
At time: 199.28870391845703 and batch: 950, loss is 3.989211015701294 and perplexity is 54.01225772440901
At time: 200.31518507003784 and batch: 1000, loss is 4.00057421207428 and perplexity is 54.629509952887254
At time: 201.34058141708374 and batch: 1050, loss is 3.9342062044143677 and perplexity is 51.1215537825339
At time: 202.36604928970337 and batch: 1100, loss is 3.896094198226929 and perplexity is 49.20986926638001
At time: 203.39239597320557 and batch: 1150, loss is 3.914615273475647 and perplexity is 50.12978154397377
At time: 204.41927576065063 and batch: 1200, loss is 3.8838520526885985 and perplexity is 48.61110742770876
At time: 205.4443802833557 and batch: 1250, loss is 3.929767413139343 and perplexity is 50.8951387519215
At time: 206.46972274780273 and batch: 1300, loss is 3.92239839553833 and perplexity is 50.52147005517889
At time: 207.4967384338379 and batch: 1350, loss is 3.8868167638778686 and perplexity is 48.7554391670667
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.409197998046875 and perplexity of 82.2035096848699
Finished 7 epochs...
Completing Train Step...
At time: 210.64272165298462 and batch: 50, loss is 4.09806643486023 and perplexity is 60.22372844441216
At time: 211.6682562828064 and batch: 100, loss is 4.100800013542175 and perplexity is 60.388579959274665
At time: 212.72150349617004 and batch: 150, loss is 4.079291753768921 and perplexity is 59.10359512433435
At time: 213.746431350708 and batch: 200, loss is 4.0603819179534915 and perplexity is 57.996456737844824
At time: 214.7764928340912 and batch: 250, loss is 4.052963151931762 and perplexity is 57.56778666280771
At time: 215.80357098579407 and batch: 300, loss is 4.055103054046631 and perplexity is 57.69110799196308
At time: 216.82904624938965 and batch: 350, loss is 4.05778242111206 and perplexity is 57.84589091421798
At time: 217.8529829978943 and batch: 400, loss is 4.066685180664063 and perplexity is 58.36317819760992
At time: 218.87949299812317 and batch: 450, loss is 4.011487941741944 and perplexity is 55.228986971177854
At time: 219.90346145629883 and batch: 500, loss is 4.081543426513672 and perplexity is 59.23682701961551
At time: 220.92778515815735 and batch: 550, loss is 4.07554630279541 and perplexity is 58.88263955387061
At time: 221.96100902557373 and batch: 600, loss is 4.006628389358521 and perplexity is 54.96124988399772
At time: 222.98654866218567 and batch: 650, loss is 4.021190075874329 and perplexity is 55.76743382886279
At time: 224.01185488700867 and batch: 700, loss is 4.04480393409729 and perplexity is 57.09998957555804
At time: 225.03850102424622 and batch: 750, loss is 4.000548305511475 and perplexity is 54.62809470838878
At time: 226.0630066394806 and batch: 800, loss is 3.9728784799575805 and perplexity is 53.13726546608169
At time: 227.0883605480194 and batch: 850, loss is 3.942073702812195 and perplexity is 51.52533883135209
At time: 228.11465096473694 and batch: 900, loss is 3.976650424003601 and perplexity is 53.33807474076683
At time: 229.13992047309875 and batch: 950, loss is 3.9554575300216674 and perplexity is 52.21958050540571
At time: 230.17303109169006 and batch: 1000, loss is 3.969434323310852 and perplexity is 52.95456720135957
At time: 231.19707036018372 and batch: 1050, loss is 3.9062355279922487 and perplexity is 49.711461887491936
At time: 232.22280526161194 and batch: 1100, loss is 3.871040048599243 and perplexity is 47.9922744309643
At time: 233.24765014648438 and batch: 1150, loss is 3.892021126747131 and perplexity is 49.00984159139234
At time: 234.27327609062195 and batch: 1200, loss is 3.865095229148865 and perplexity is 47.70781539102814
At time: 235.29677319526672 and batch: 1250, loss is 3.914537396430969 and perplexity is 50.125877736747235
At time: 236.322279214859 and batch: 1300, loss is 3.9091626596450806 and perplexity is 49.857187055418215
At time: 237.34642624855042 and batch: 1350, loss is 3.877062969207764 and perplexity is 48.28220031353579
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.407128092447917 and perplexity of 82.03353215932427
Finished 8 epochs...
Completing Train Step...
At time: 240.52098321914673 and batch: 50, loss is 4.055363168716431 and perplexity is 57.706116247317865
At time: 241.5458471775055 and batch: 100, loss is 4.056295490264892 and perplexity is 57.759941990524496
At time: 242.57233500480652 and batch: 150, loss is 4.037001667022705 and perplexity is 56.65621368718423
At time: 243.597496509552 and batch: 200, loss is 4.018177609443665 and perplexity is 55.59968909607359
At time: 244.62254238128662 and batch: 250, loss is 4.011710181236267 and perplexity is 55.24126239730602
At time: 245.64819884300232 and batch: 300, loss is 4.01577130317688 and perplexity is 55.46606005644761
At time: 246.67386722564697 and batch: 350, loss is 4.020043950080872 and perplexity is 55.70355394869855
At time: 247.6984989643097 and batch: 400, loss is 4.028155508041382 and perplexity is 56.15723409397941
At time: 248.72330164909363 and batch: 450, loss is 3.974719467163086 and perplexity is 53.235180594534874
At time: 249.74839520454407 and batch: 500, loss is 4.0456532382965085 and perplexity is 57.14850543592558
At time: 250.77211952209473 and batch: 550, loss is 4.0418084192276 and perplexity is 56.929201634342256
At time: 251.79829716682434 and batch: 600, loss is 3.972901477813721 and perplexity is 53.13848752332087
At time: 252.82345032691956 and batch: 650, loss is 3.9883390426635743 and perplexity is 53.965181019758376
At time: 253.84772276878357 and batch: 700, loss is 4.014500999450684 and perplexity is 55.3956460467387
At time: 254.87452483177185 and batch: 750, loss is 3.970480079650879 and perplexity is 53.00997374156472
At time: 255.89984107017517 and batch: 800, loss is 3.9452201318740845 and perplexity is 51.687714973420434
At time: 256.9270439147949 and batch: 850, loss is 3.9154987001419066 and perplexity is 50.1740870972356
At time: 257.95332527160645 and batch: 900, loss is 3.9511577701568603 and perplexity is 51.99553087398244
At time: 258.9787564277649 and batch: 950, loss is 3.9313552713394166 and perplexity is 50.976017210100935
At time: 260.0045282840729 and batch: 1000, loss is 3.9459950065612794 and perplexity is 51.72778199684862
At time: 261.03431606292725 and batch: 1050, loss is 3.884664649963379 and perplexity is 48.650624734782106
At time: 262.0652310848236 and batch: 1100, loss is 3.850485739707947 and perplexity is 47.0158951731303
At time: 263.086706161499 and batch: 1150, loss is 3.8713847398757935 and perplexity is 48.008819800660945
At time: 264.1492922306061 and batch: 1200, loss is 3.845199255943298 and perplexity is 46.768002224959965
At time: 265.1705343723297 and batch: 1250, loss is 3.896530270576477 and perplexity is 49.23133300922422
At time: 266.1917772293091 and batch: 1300, loss is 3.8918153429031372 and perplexity is 48.9997571954346
At time: 267.21493268013 and batch: 1350, loss is 3.8630617570877077 and perplexity is 47.61090145062171
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.408373209635417 and perplexity of 82.13573713554925
Annealing...
Finished 9 epochs...
Completing Train Step...
At time: 270.3561689853668 and batch: 50, loss is 4.032721033096314 and perplexity is 56.414207516186806
At time: 271.4247522354126 and batch: 100, loss is 4.0396503782272335 and perplexity is 56.80647855144773
At time: 272.4453704357147 and batch: 150, loss is 4.02221390247345 and perplexity is 55.82455924925392
At time: 273.46669363975525 and batch: 200, loss is 4.00420154094696 and perplexity is 54.82802898087267
At time: 274.49033761024475 and batch: 250, loss is 3.9939809370040895 and perplexity is 54.27050736873635
At time: 275.5166184902191 and batch: 300, loss is 3.995094690322876 and perplexity is 54.33098499875948
At time: 276.53704476356506 and batch: 350, loss is 3.996422915458679 and perplexity is 54.40319672478635
At time: 277.5609133243561 and batch: 400, loss is 4.001038446426391 and perplexity is 54.654876735656785
At time: 278.5817792415619 and batch: 450, loss is 3.9440992307662963 and perplexity is 51.6298106150401
At time: 279.6026828289032 and batch: 500, loss is 4.011613178253174 and perplexity is 55.235904089953756
At time: 280.6240134239197 and batch: 550, loss is 4.003834815025329 and perplexity is 54.8079258078161
At time: 281.6468369960785 and batch: 600, loss is 3.934859118461609 and perplexity is 51.154942661963375
At time: 282.6680886745453 and batch: 650, loss is 3.9472693395614624 and perplexity is 51.79374243532897
At time: 283.6890287399292 and batch: 700, loss is 3.9675468397140503 and perplexity is 52.854710592892246
At time: 284.7121777534485 and batch: 750, loss is 3.9228513193130494 and perplexity is 50.54435761286891
At time: 285.7338538169861 and batch: 800, loss is 3.8929422950744628 and perplexity is 49.05500870525734
At time: 286.75528836250305 and batch: 850, loss is 3.85738685131073 and perplexity is 47.34147926673776
At time: 287.7765839099884 and batch: 900, loss is 3.8910440587997437 and perplexity is 48.961979032360716
At time: 288.7998597621918 and batch: 950, loss is 3.8670669651031493 and perplexity is 47.80197540477144
At time: 289.8591105937958 and batch: 1000, loss is 3.8767483282089232 and perplexity is 48.26701114349604
At time: 290.8969120979309 and batch: 1050, loss is 3.8181828689575195 and perplexity is 45.52141474441189
At time: 291.926477432251 and batch: 1100, loss is 3.777388963699341 and perplexity is 43.701785688306494
At time: 292.9508373737335 and batch: 1150, loss is 3.79449107170105 and perplexity is 44.45560593146736
At time: 293.97481656074524 and batch: 1200, loss is 3.763694338798523 and perplexity is 43.10738545948867
At time: 295.0005576610565 and batch: 1250, loss is 3.815261082649231 and perplexity is 45.388605013385835
At time: 296.0247757434845 and batch: 1300, loss is 3.8076517295837404 and perplexity is 45.044537817262906
At time: 297.049996137619 and batch: 1350, loss is 3.777171030044556 and perplexity is 43.692262636165275
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.378710123697917 and perplexity of 79.73511860573974
Finished 10 epochs...
Completing Train Step...
At time: 300.2041747570038 and batch: 50, loss is 4.002548999786377 and perplexity is 54.7374982297269
At time: 301.2558419704437 and batch: 100, loss is 4.002647404670715 and perplexity is 54.742884931943706
At time: 302.27952432632446 and batch: 150, loss is 3.9837086534500123 and perplexity is 53.71587885611149
At time: 303.304217338562 and batch: 200, loss is 3.9675333976745604 and perplexity is 52.85400012256033
At time: 304.32921290397644 and batch: 250, loss is 3.957353644371033 and perplexity is 52.31868873189181
At time: 305.35375905036926 and batch: 300, loss is 3.961147246360779 and perplexity is 52.51754196008552
At time: 306.3797082901001 and batch: 350, loss is 3.9632883787155153 and perplexity is 52.630109436295214
At time: 307.4045240879059 and batch: 400, loss is 3.969201126098633 and perplexity is 52.9422197836616
At time: 308.4284722805023 and batch: 450, loss is 3.913992886543274 and perplexity is 50.098591130277875
At time: 309.45292019844055 and batch: 500, loss is 3.9841817903518675 and perplexity is 53.741299833941014
At time: 310.47854566574097 and batch: 550, loss is 3.9777776622772216 and perplexity is 53.39823336023491
At time: 311.50248074531555 and batch: 600, loss is 3.909812512397766 and perplexity is 49.889597415507595
At time: 312.5264186859131 and batch: 650, loss is 3.924955668449402 and perplexity is 50.65083257911888
At time: 313.55202531814575 and batch: 700, loss is 3.947787628173828 and perplexity is 51.82059349992444
At time: 314.5765812397003 and batch: 750, loss is 3.904606194496155 and perplexity is 49.63053128687214
At time: 315.60166454315186 and batch: 800, loss is 3.8763543653488157 and perplexity is 48.24799947892788
At time: 316.6512453556061 and batch: 850, loss is 3.843622632026672 and perplexity is 46.69432477019986
At time: 317.6771216392517 and batch: 900, loss is 3.879101777076721 and perplexity is 48.38073885991424
At time: 318.7040944099426 and batch: 950, loss is 3.8568842077255248 and perplexity is 47.31768935529428
At time: 319.7285680770874 and batch: 1000, loss is 3.86724262714386 and perplexity is 47.810373134880656
At time: 320.7528738975525 and batch: 1050, loss is 3.8113313579559325 and perplexity is 45.21059029497385
At time: 321.77821254730225 and batch: 1100, loss is 3.771913013458252 and perplexity is 43.463130911630365
At time: 322.80225920677185 and batch: 1150, loss is 3.790647406578064 and perplexity is 44.2850614373546
At time: 323.8262257575989 and batch: 1200, loss is 3.762236542701721 and perplexity is 43.04458946422189
At time: 324.85119438171387 and batch: 1250, loss is 3.815187907218933 and perplexity is 45.3852838042003
At time: 325.8754529953003 and batch: 1300, loss is 3.8079886436462402 and perplexity is 45.05971651230667
At time: 326.8998336791992 and batch: 1350, loss is 3.778314108848572 and perplexity is 43.74223489115565
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.377814534505208 and perplexity of 79.6637406626652
Finished 11 epochs...
Completing Train Step...
At time: 330.0483138561249 and batch: 50, loss is 3.985014810562134 and perplexity is 53.78608607416045
At time: 331.07518792152405 and batch: 100, loss is 3.9830901050567626 and perplexity is 53.68266325933908
At time: 332.10047578811646 and batch: 150, loss is 3.964541211128235 and perplexity is 52.696087464358165
At time: 333.1257588863373 and batch: 200, loss is 3.9491128158569335 and perplexity is 51.88931103392022
At time: 334.15065145492554 and batch: 250, loss is 3.938947820663452 and perplexity is 51.364528163031885
At time: 335.1787738800049 and batch: 300, loss is 3.943560185432434 and perplexity is 51.60198730622598
At time: 336.2026216983795 and batch: 350, loss is 3.946014947891235 and perplexity is 51.72881352790232
At time: 337.2279098033905 and batch: 400, loss is 3.9524032354354857 and perplexity is 52.06032984638853
At time: 338.25459027290344 and batch: 450, loss is 3.8979349279403688 and perplexity is 49.300534754662216
At time: 339.2797384262085 and batch: 500, loss is 3.9690197944641112 and perplexity is 52.93262055476126
At time: 340.30577421188354 and batch: 550, loss is 3.9630689096450804 and perplexity is 52.61856002251625
At time: 341.331716299057 and batch: 600, loss is 3.895365662574768 and perplexity is 49.1740311784288
At time: 342.38320779800415 and batch: 650, loss is 3.9116876697540284 and perplexity is 49.98323602723026
At time: 343.40848994255066 and batch: 700, loss is 3.93557861328125 and perplexity is 51.1917616221449
At time: 344.4338264465332 and batch: 750, loss is 3.893395576477051 and perplexity is 49.077249468688656
At time: 345.4597487449646 and batch: 800, loss is 3.865299468040466 and perplexity is 47.71756017746264
At time: 346.48504400253296 and batch: 850, loss is 3.833879909515381 and perplexity is 46.24160386920927
At time: 347.50934624671936 and batch: 900, loss is 3.8700020265579225 and perplexity is 47.942483238940035
At time: 348.53468108177185 and batch: 950, loss is 3.848651075363159 and perplexity is 46.929715865842304
At time: 349.5748085975647 and batch: 1000, loss is 3.8589238834381105 and perplexity is 47.4143005913497
At time: 350.5965497493744 and batch: 1050, loss is 3.8043704557418825 and perplexity is 44.89697658041413
At time: 351.62040615081787 and batch: 1100, loss is 3.765521364212036 and perplexity is 43.18621573876696
At time: 352.6582419872284 and batch: 1150, loss is 3.784618411064148 and perplexity is 44.018870239693676
At time: 353.6795103549957 and batch: 1200, loss is 3.757346429824829 and perplexity is 42.83461039212374
At time: 354.7018196582794 and batch: 1250, loss is 3.81102942943573 and perplexity is 45.196941988858725
At time: 355.72305941581726 and batch: 1300, loss is 3.80403715133667 and perplexity is 44.88201471390568
At time: 356.74504041671753 and batch: 1350, loss is 3.774847106933594 and perplexity is 43.59084306853746
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.378253987630209 and perplexity of 79.6987568358685
Annealing...
Finished 12 epochs...
Completing Train Step...
At time: 359.8510890007019 and batch: 50, loss is 3.980440545082092 and perplexity is 53.54061608778313
At time: 360.8749351501465 and batch: 100, loss is 3.9833413553237915 and perplexity is 53.69615273736433
At time: 361.89779710769653 and batch: 150, loss is 3.9668320417404175 and perplexity is 52.816943652337834
At time: 362.92057514190674 and batch: 200, loss is 3.9539482736587526 and perplexity is 52.140827215660046
At time: 363.94549775123596 and batch: 250, loss is 3.9427758407592775 and perplexity is 51.561529430891675
At time: 364.9665467739105 and batch: 300, loss is 3.945135293006897 and perplexity is 51.68333003224394
At time: 365.98757815361023 and batch: 350, loss is 3.9438496255874633 and perplexity is 51.616925155134076
At time: 367.00917863845825 and batch: 400, loss is 3.9502325868606567 and perplexity is 51.94744772363414
At time: 368.03265357017517 and batch: 450, loss is 3.893011436462402 and perplexity is 49.05840055390182
At time: 369.07923126220703 and batch: 500, loss is 3.9646975708007814 and perplexity is 52.704327651538264
At time: 370.1024954319 and batch: 550, loss is 3.95383584022522 and perplexity is 52.134965172979925
At time: 371.12429022789 and batch: 600, loss is 3.8864826107025148 and perplexity is 48.73915010392591
At time: 372.14567732810974 and batch: 650, loss is 3.900529565811157 and perplexity is 49.428617881997
At time: 373.1683633327484 and batch: 700, loss is 3.9226954698562624 and perplexity is 50.5364809159967
At time: 374.19179606437683 and batch: 750, loss is 3.879649529457092 and perplexity is 48.40724678401535
At time: 375.2145416736603 and batch: 800, loss is 3.848591809272766 and perplexity is 46.92693460747764
At time: 376.23816680908203 and batch: 850, loss is 3.8146748828887937 and perplexity is 45.362006020923594
At time: 377.26071977615356 and batch: 900, loss is 3.8472942161560058 and perplexity is 46.86608202962177
At time: 378.28262209892273 and batch: 950, loss is 3.824063377380371 and perplexity is 45.78989242619986
At time: 379.3066563606262 and batch: 1000, loss is 3.8336190032958983 and perplexity is 46.22954072090459
At time: 380.3287580013275 and batch: 1050, loss is 3.778864793777466 and perplexity is 43.766329714385456
At time: 381.3504548072815 and batch: 1100, loss is 3.737808594703674 and perplexity is 42.00583741527499
At time: 382.37396478652954 and batch: 1150, loss is 3.753076071739197 and perplexity is 42.65208127701481
At time: 383.39649534225464 and batch: 1200, loss is 3.7220222425460814 and perplexity is 41.34792515356557
At time: 384.419189453125 and batch: 1250, loss is 3.777964224815369 and perplexity is 43.72693285871514
At time: 385.4425575733185 and batch: 1300, loss is 3.7718278121948243 and perplexity is 43.45942795571467
At time: 386.46468591690063 and batch: 1350, loss is 3.74219030380249 and perplexity is 42.19029860779551
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.36207275390625 and perplexity of 78.41951042876687
Finished 13 epochs...
Completing Train Step...
At time: 389.5288555622101 and batch: 50, loss is 3.9687218379974367 and perplexity is 52.91685128756317
At time: 390.5762515068054 and batch: 100, loss is 3.966965160369873 and perplexity is 52.82397503948279
At time: 391.59934520721436 and batch: 150, loss is 3.949847159385681 and perplexity is 51.927429608040285
At time: 392.6214427947998 and batch: 200, loss is 3.936924729347229 and perplexity is 51.26071807619299
At time: 393.643940448761 and batch: 250, loss is 3.9263883781433107 and perplexity is 50.72345252718934
At time: 394.69212341308594 and batch: 300, loss is 3.929573154449463 and perplexity is 50.885252889184734
At time: 395.717928647995 and batch: 350, loss is 3.928592157363892 and perplexity is 50.83535908124328
At time: 396.740033864975 and batch: 400, loss is 3.935642275810242 and perplexity is 51.19502072289352
At time: 397.7630543708801 and batch: 450, loss is 3.880135345458984 and perplexity is 48.43076951250688
At time: 398.7848892211914 and batch: 500, loss is 3.9524784183502195 and perplexity is 52.06424404086681
At time: 399.8074722290039 and batch: 550, loss is 3.9423308801651 and perplexity is 51.53859168569423
At time: 400.8289842605591 and batch: 600, loss is 3.8754582691192625 and perplexity is 48.204783994019664
At time: 401.8510355949402 and batch: 650, loss is 3.8908212661743162 and perplexity is 48.95107187956769
At time: 402.8737909793854 and batch: 700, loss is 3.9143604850769043 and perplexity is 50.1170106842074
At time: 403.89510464668274 and batch: 750, loss is 3.8721407413482667 and perplexity is 48.04512826201777
At time: 404.91668677330017 and batch: 800, loss is 3.8419080448150633 and perplexity is 46.61433187508864
At time: 405.94003987312317 and batch: 850, loss is 3.809270100593567 and perplexity is 45.117495611883484
At time: 406.96241641044617 and batch: 900, loss is 3.8433252954483033 and perplexity is 46.68044290333911
At time: 407.9837644100189 and batch: 950, loss is 3.8207760763168337 and perplexity is 45.63961440400873
At time: 409.0069992542267 and batch: 1000, loss is 3.831165118217468 and perplexity is 46.11623781375842
At time: 410.0288071632385 and batch: 1050, loss is 3.777701301574707 and perplexity is 43.71543754308276
At time: 411.0520091056824 and batch: 1100, loss is 3.7373670721054078 and perplexity is 41.987294982549805
At time: 412.0745806694031 and batch: 1150, loss is 3.753583998680115 and perplexity is 42.67375092101374
At time: 413.09761357307434 and batch: 1200, loss is 3.723570761680603 and perplexity is 41.4120028067703
At time: 414.11961603164673 and batch: 1250, loss is 3.780560040473938 and perplexity is 43.840587364985055
At time: 415.14279294013977 and batch: 1300, loss is 3.7741646814346312 and perplexity is 43.56110571362491
At time: 416.16417360305786 and batch: 1350, loss is 3.7444874238967896 and perplexity is 42.28732618985025
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.361264241536459 and perplexity of 78.35613290875914
Finished 14 epochs...
Completing Train Step...
At time: 419.2518744468689 and batch: 50, loss is 3.9611406660079957 and perplexity is 52.517196377269144
At time: 420.29829239845276 and batch: 100, loss is 3.958286929130554 and perplexity is 52.367539759137166
At time: 421.320627450943 and batch: 150, loss is 3.941188569068909 and perplexity is 51.47975219343023
At time: 422.3427360057831 and batch: 200, loss is 3.928247694969177 and perplexity is 50.817851227289744
At time: 423.3636291027069 and batch: 250, loss is 3.9177607250213624 and perplexity is 50.28771059169056
At time: 424.3860008716583 and batch: 300, loss is 3.921219143867493 and perplexity is 50.46192764184852
At time: 425.4071719646454 and batch: 350, loss is 3.920484480857849 and perplexity is 50.42486874478198
At time: 426.42837858200073 and batch: 400, loss is 3.927815775871277 and perplexity is 50.79590676628747
At time: 427.4501328468323 and batch: 450, loss is 3.872896409034729 and perplexity is 48.08144813408584
At time: 428.4728126525879 and batch: 500, loss is 3.945631399154663 and perplexity is 51.70897681124631
At time: 429.4952943325043 and batch: 550, loss is 3.935742053985596 and perplexity is 51.20012912349767
At time: 430.51631927490234 and batch: 600, loss is 3.869219660758972 and perplexity is 47.90498934861836
At time: 431.53872418403625 and batch: 650, loss is 3.884956569671631 and perplexity is 48.664828884095655
At time: 432.55985832214355 and batch: 700, loss is 3.9092572832107546 and perplexity is 49.86190494344005
At time: 433.5818462371826 and batch: 750, loss is 3.8674332237243654 and perplexity is 47.81948649697309
At time: 434.6028473377228 and batch: 800, loss is 3.837531552314758 and perplexity is 46.41077036884596
At time: 435.6250023841858 and batch: 850, loss is 3.805520715713501 and perplexity is 44.94864948836273
At time: 436.64592003822327 and batch: 900, loss is 3.840109848976135 and perplexity is 46.53058549623764
At time: 437.6686432361603 and batch: 950, loss is 3.8179493618011473 and perplexity is 45.51078640924534
At time: 438.6893684864044 and batch: 1000, loss is 3.828554835319519 and perplexity is 45.99601835852976
At time: 439.71041464805603 and batch: 1050, loss is 3.7757182502746582 and perplexity is 43.628833486355205
At time: 440.7328209877014 and batch: 1100, loss is 3.7356729173660277 and perplexity is 41.916222228881786
At time: 441.7535066604614 and batch: 1150, loss is 3.752258529663086 and perplexity is 42.61722565584699
At time: 442.77493500709534 and batch: 1200, loss is 3.7228017377853395 and perplexity is 41.38016822940543
At time: 443.7979927062988 and batch: 1250, loss is 3.78040696144104 and perplexity is 43.833876803905746
At time: 444.81860971450806 and batch: 1300, loss is 3.773868269920349 and perplexity is 43.548195613762175
At time: 445.84061312675476 and batch: 1350, loss is 3.7442396974563597 and perplexity is 42.276851798503344
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.361172281901042 and perplexity of 78.34892763864626
Finished 15 epochs...
Completing Train Step...
At time: 448.9315609931946 and batch: 50, loss is 3.954412789344788 and perplexity is 52.165053073994564
At time: 449.9542324542999 and batch: 100, loss is 3.9511441707611086 and perplexity is 51.99482377098886
At time: 450.9803509712219 and batch: 150, loss is 3.9342354345321655 and perplexity is 51.1230480934123
At time: 452.0037360191345 and batch: 200, loss is 3.9214151525497436 and perplexity is 50.47181958721135
At time: 453.0254783630371 and batch: 250, loss is 3.9109748125076296 and perplexity is 49.947617812089504
At time: 454.0443572998047 and batch: 300, loss is 3.914724669456482 and perplexity is 50.135265840569346
At time: 455.0630660057068 and batch: 350, loss is 3.9141402864456176 and perplexity is 50.10597620198409
At time: 456.0860319137573 and batch: 400, loss is 3.9217021083831787 and perplexity is 50.486304848481694
At time: 457.1062355041504 and batch: 450, loss is 3.8671269702911375 and perplexity is 47.80484385735197
At time: 458.12581181526184 and batch: 500, loss is 3.940138649940491 and perplexity is 51.42573098079081
At time: 459.1490168571472 and batch: 550, loss is 3.930417914390564 and perplexity is 50.92825687388273
At time: 460.1729862689972 and batch: 600, loss is 3.8642051649093627 and perplexity is 47.66537126240641
At time: 461.1965301036835 and batch: 650, loss is 3.8801170206069946 and perplexity is 48.429882033955295
At time: 462.2216246128082 and batch: 700, loss is 3.9049339962005614 and perplexity is 49.646802926408455
At time: 463.2467429637909 and batch: 750, loss is 3.863436846733093 and perplexity is 47.62876315642433
At time: 464.2696485519409 and batch: 800, loss is 3.833696527481079 and perplexity is 46.23312476730359
At time: 465.29412937164307 and batch: 850, loss is 3.8020808267593384 and perplexity is 44.79429675581557
At time: 466.3178069591522 and batch: 900, loss is 3.836984601020813 and perplexity is 46.38539287869791
At time: 467.34233713150024 and batch: 950, loss is 3.8151337623596193 and perplexity is 45.38282649091984
At time: 468.36695671081543 and batch: 1000, loss is 3.825788769721985 and perplexity is 45.86896615289985
At time: 469.3900673389435 and batch: 1050, loss is 3.7733852243423462 and perplexity is 43.527164930239216
At time: 470.41463327407837 and batch: 1100, loss is 3.7335225343704224 and perplexity is 41.82618314131836
At time: 471.439501285553 and batch: 1150, loss is 3.75028329372406 and perplexity is 42.53312966216661
At time: 472.4974801540375 and batch: 1200, loss is 3.721255578994751 and perplexity is 41.31623735491942
At time: 473.52194476127625 and batch: 1250, loss is 3.7792879438400266 and perplexity is 43.784853358406316
At time: 474.54677057266235 and batch: 1300, loss is 3.772710771560669 and perplexity is 43.49781781050923
At time: 475.5725371837616 and batch: 1350, loss is 3.7431247663497924 and perplexity is 42.22974228815475
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.361306559244792 and perplexity of 78.35944883089829
Annealing...
Finished 16 epochs...
Completing Train Step...
At time: 478.7195875644684 and batch: 50, loss is 3.953654856681824 and perplexity is 52.1255304560381
At time: 479.7444050312042 and batch: 100, loss is 3.954877142906189 and perplexity is 52.18928172706546
At time: 480.7676465511322 and batch: 150, loss is 3.939665846824646 and perplexity is 51.401422481968325
At time: 481.791791677475 and batch: 200, loss is 3.9289633989334107 and perplexity is 50.85423478324149
At time: 482.8169765472412 and batch: 250, loss is 3.918629274368286 and perplexity is 50.33140692334646
At time: 483.8400366306305 and batch: 300, loss is 3.9221474933624267 and perplexity is 50.508795698490545
At time: 484.8655025959015 and batch: 350, loss is 3.9197204446792604 and perplexity is 50.38635703480368
At time: 485.8905236721039 and batch: 400, loss is 3.9249886322021483 and perplexity is 50.65250224815955
At time: 486.91359543800354 and batch: 450, loss is 3.8691026306152345 and perplexity is 47.89938334887101
At time: 487.93862771987915 and batch: 500, loss is 3.942703585624695 and perplexity is 51.55780398023645
At time: 488.96215295791626 and batch: 550, loss is 3.932009482383728 and perplexity is 51.00937719460011
At time: 489.98853182792664 and batch: 600, loss is 3.8659849309921266 and perplexity is 47.750280009943246
At time: 491.01262378692627 and batch: 650, loss is 3.8791604232788086 and perplexity is 48.38357628970398
At time: 492.0373191833496 and batch: 700, loss is 3.902085041999817 and perplexity is 49.5055627475899
At time: 493.06297516822815 and batch: 750, loss is 3.859486880302429 and perplexity is 47.44100220966489
At time: 494.08707785606384 and batch: 800, loss is 3.828637571334839 and perplexity is 45.99982404324076
At time: 495.1115119457245 and batch: 850, loss is 3.79567907333374 and perplexity is 44.508450647485446
At time: 496.1354007720947 and batch: 900, loss is 3.8284305906295777 and perplexity is 45.990303952489924
At time: 497.16104888916016 and batch: 950, loss is 3.8064975357055664 and perplexity is 44.992577679273914
At time: 498.2112979888916 and batch: 1000, loss is 3.8176621437072753 and perplexity is 45.497716764931276
At time: 499.23621892929077 and batch: 1050, loss is 3.763274669647217 and perplexity is 43.08929841517058
At time: 500.2595009803772 and batch: 1100, loss is 3.7231703662872313 and perplexity is 41.395424950686255
At time: 501.28407406806946 and batch: 1150, loss is 3.738467984199524 and perplexity is 42.033544757192196
At time: 502.30353808403015 and batch: 1200, loss is 3.707229733467102 and perplexity is 40.74078721311784
At time: 503.3237476348877 and batch: 1250, loss is 3.7644547700881956 and perplexity is 43.140178130914535
At time: 504.3450667858124 and batch: 1300, loss is 3.7593379068374633 and perplexity is 42.919999531097524
At time: 505.3647530078888 and batch: 1350, loss is 3.7310780334472655 and perplexity is 41.72406386420273
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.353739827473959 and perplexity of 77.76876150449958
Finished 17 epochs...
Completing Train Step...
At time: 508.4379448890686 and batch: 50, loss is 3.950027871131897 and perplexity is 51.93681435246248
At time: 509.4825692176819 and batch: 100, loss is 3.9480187606811525 and perplexity is 51.83257230792376
At time: 510.5030062198639 and batch: 150, loss is 3.931360430717468 and perplexity is 50.97628021532375
At time: 511.52207469940186 and batch: 200, loss is 3.920436797142029 and perplexity is 50.42246435699601
At time: 512.5411694049835 and batch: 250, loss is 3.9101480054855347 and perplexity is 49.906337838583156
At time: 513.5635957717896 and batch: 300, loss is 3.914197950363159 and perplexity is 50.10886559217011
At time: 514.5859887599945 and batch: 350, loss is 3.912075066566467 and perplexity is 50.002603124676284
At time: 515.613543510437 and batch: 400, loss is 3.9178469371795654 and perplexity is 50.292046190639745
At time: 516.6342866420746 and batch: 450, loss is 3.863008394241333 and perplexity is 47.60836086518888
At time: 517.6545526981354 and batch: 500, loss is 3.937029256820679 and perplexity is 51.266076509587585
At time: 518.6733059883118 and batch: 550, loss is 3.927050623893738 and perplexity is 50.75705504340616
At time: 519.6923847198486 and batch: 600, loss is 3.8611838483810423 and perplexity is 47.52157642262999
At time: 520.7128536701202 and batch: 650, loss is 3.875060362815857 and perplexity is 48.18560682222593
At time: 521.7322461605072 and batch: 700, loss is 3.8984118700027466 and perplexity is 49.32405386156428
At time: 522.7522110939026 and batch: 750, loss is 3.8563995218276976 and perplexity is 47.29476069559388
At time: 523.7964322566986 and batch: 800, loss is 3.8258486223220824 and perplexity is 45.87171161194849
At time: 524.8154203891754 and batch: 850, loss is 3.7936292362213133 and perplexity is 44.4173090181922
At time: 525.8346970081329 and batch: 900, loss is 3.827029881477356 and perplexity is 45.92593000794193
At time: 526.855354309082 and batch: 950, loss is 3.8054876041412355 and perplexity is 44.94716119254701
At time: 527.8737785816193 and batch: 1000, loss is 3.8171309185028077 and perplexity is 45.47355364963619
At time: 528.8940756320953 and batch: 1050, loss is 3.763255000114441 and perplexity is 43.08845087713848
At time: 529.91286277771 and batch: 1100, loss is 3.7236877393722536 and perplexity is 41.416847370612686
At time: 530.9315071105957 and batch: 1150, loss is 3.7393356370925903 and perplexity is 42.07003111036257
At time: 531.951474905014 and batch: 1200, loss is 3.7085940504074095 and perplexity is 40.79640849317387
At time: 532.9723658561707 and batch: 1250, loss is 3.7661505222320555 and perplexity is 43.21339524195793
At time: 533.9911484718323 and batch: 1300, loss is 3.761014013290405 and perplexity is 42.99199834125129
At time: 535.0118680000305 and batch: 1350, loss is 3.732646074295044 and perplexity is 41.78954022206312
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.353255615234375 and perplexity of 77.73111403374051
Finished 18 epochs...
Completing Train Step...
At time: 538.113091468811 and batch: 50, loss is 3.947042670249939 and perplexity is 51.78200371384415
At time: 539.1660475730896 and batch: 100, loss is 3.9445325565338134 and perplexity is 51.65218799034813
At time: 540.1864032745361 and batch: 150, loss is 3.927604570388794 and perplexity is 50.78517952515669
At time: 541.2088630199432 and batch: 200, loss is 3.916667733192444 and perplexity is 50.232776561610656
At time: 542.2285442352295 and batch: 250, loss is 3.906281547546387 and perplexity is 49.71374963944381
At time: 543.2490632534027 and batch: 300, loss is 3.910471019744873 and perplexity is 49.92246090118575
At time: 544.2684338092804 and batch: 350, loss is 3.9084641408920286 and perplexity is 49.82237303582393
At time: 545.2898390293121 and batch: 400, loss is 3.9143428564071656 and perplexity is 50.11612719576515
At time: 546.3098301887512 and batch: 450, loss is 3.8598342084884645 and perplexity is 47.45748266880438
At time: 547.3301260471344 and batch: 500, loss is 3.9340419244766234 and perplexity is 51.11315622665497
At time: 548.3525145053864 and batch: 550, loss is 3.924283013343811 and perplexity is 50.61677349427497
At time: 549.3732011318207 and batch: 600, loss is 3.8585580348968507 and perplexity is 47.39695731134378
At time: 550.4182088375092 and batch: 650, loss is 3.872690267562866 and perplexity is 48.07153757512188
At time: 551.4396810531616 and batch: 700, loss is 3.8962719297409056 and perplexity is 49.218616188226136
At time: 552.4670257568359 and batch: 750, loss is 3.854552035331726 and perplexity is 47.2074649275847
At time: 553.48885846138 and batch: 800, loss is 3.824156894683838 and perplexity is 45.79417477369927
At time: 554.5092341899872 and batch: 850, loss is 3.792284617424011 and perplexity is 44.35762480481078
At time: 555.5294120311737 and batch: 900, loss is 3.825920810699463 and perplexity is 45.875023135902765
At time: 556.5499050617218 and batch: 950, loss is 3.8046608448028563 and perplexity is 44.91001606445401
At time: 557.5707709789276 and batch: 1000, loss is 3.8164838457107546 and perplexity is 45.44413846821968
At time: 558.5913836956024 and batch: 1050, loss is 3.7628244972229004 and perplexity is 43.06990516672128
At time: 559.6110184192657 and batch: 1100, loss is 3.723509783744812 and perplexity is 41.40947766531192
At time: 560.6336362361908 and batch: 1150, loss is 3.739295845031738 and perplexity is 42.06835709043114
At time: 561.6582734584808 and batch: 1200, loss is 3.7088607931137085 and perplexity is 40.807292089078
At time: 562.6805195808411 and batch: 1250, loss is 3.766578531265259 and perplexity is 43.23189492421002
At time: 563.700706243515 and batch: 1300, loss is 3.7613847351074217 and perplexity is 43.007939367654096
At time: 564.7210419178009 and batch: 1350, loss is 3.7329810857772827 and perplexity is 41.80354254321321
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.353107503255209 and perplexity of 77.71960197715593
Finished 19 epochs...
Completing Train Step...
At time: 567.8074717521667 and batch: 50, loss is 3.9443002700805665 and perplexity is 51.640191280187985
At time: 568.8300609588623 and batch: 100, loss is 3.9415557384490967 and perplexity is 51.49865745263908
At time: 569.85076212883 and batch: 150, loss is 3.924558787345886 and perplexity is 50.63073420938628
At time: 570.871150970459 and batch: 200, loss is 3.913655872344971 and perplexity is 50.08171003849557
At time: 571.8919498920441 and batch: 250, loss is 3.9032257270812987 and perplexity is 49.562065224105865
At time: 572.9138412475586 and batch: 300, loss is 3.9075444316864014 and perplexity is 49.776572005739645
At time: 573.934287071228 and batch: 350, loss is 3.905644612312317 and perplexity is 49.68209528263844
At time: 574.9640161991119 and batch: 400, loss is 3.9115974378585814 and perplexity is 49.978726148573465
At time: 576.009272813797 and batch: 450, loss is 3.8572884893417356 and perplexity is 47.3368228946307
At time: 577.029299736023 and batch: 500, loss is 3.931626391410828 and perplexity is 50.989839705220454
At time: 578.0504899024963 and batch: 550, loss is 3.922027850151062 and perplexity is 50.50275302546061
At time: 579.0724301338196 and batch: 600, loss is 3.8564319944381715 and perplexity is 47.29629650487114
At time: 580.0932371616364 and batch: 650, loss is 3.8706958293914795 and perplexity is 47.97575741118172
At time: 581.1150605678558 and batch: 700, loss is 3.8944660568237306 and perplexity is 49.12981382925186
At time: 582.1352939605713 and batch: 750, loss is 3.8529321193695067 and perplexity is 47.13105470738947
At time: 583.156167268753 and batch: 800, loss is 3.8226530170440673 and perplexity is 45.725357697426475
At time: 584.1775975227356 and batch: 850, loss is 3.7910257148742676 and perplexity is 44.301818012870164
At time: 585.205474615097 and batch: 900, loss is 3.824841775894165 and perplexity is 45.82554908615638
At time: 586.2303166389465 and batch: 950, loss is 3.8037463188171388 and perplexity is 44.868963462440966
At time: 587.2503156661987 and batch: 1000, loss is 3.8156625699996947 and perplexity is 45.406831622785624
At time: 588.2724068164825 and batch: 1050, loss is 3.7621563625335694 and perplexity is 43.04113828016074
At time: 589.293265581131 and batch: 1100, loss is 3.7230068826675415 and perplexity is 41.38865802993214
At time: 590.3138778209686 and batch: 1150, loss is 3.738887920379639 and perplexity is 42.05119987016511
At time: 591.345948934555 and batch: 1200, loss is 3.7086742401123045 and perplexity is 40.7996800763036
At time: 592.3691194057465 and batch: 1250, loss is 3.766522650718689 and perplexity is 43.22947916978986
At time: 593.3915281295776 and batch: 1300, loss is 3.761310257911682 and perplexity is 43.00473637621185
At time: 594.4156792163849 and batch: 1350, loss is 3.732892370223999 and perplexity is 41.799834083308745
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.353082682291666 and perplexity of 77.71767292568929
Finished 20 epochs...
Completing Train Step...
At time: 597.5303332805634 and batch: 50, loss is 3.9417558479309083 and perplexity is 51.508963853465794
At time: 598.551840543747 and batch: 100, loss is 3.93886944770813 and perplexity is 51.360502730905594
At time: 599.5732657909393 and batch: 150, loss is 3.9218603706359865 and perplexity is 50.494295557120054
At time: 600.5953075885773 and batch: 200, loss is 3.911008358001709 and perplexity is 49.949293357710445
At time: 601.6409800052643 and batch: 250, loss is 3.9005593395233156 and perplexity is 49.43008957734701
At time: 602.6635899543762 and batch: 300, loss is 3.904987459182739 and perplexity is 49.64945726350225
At time: 603.6850621700287 and batch: 350, loss is 3.9031675958633425 and perplexity is 49.55918420462936
At time: 604.7063829898834 and batch: 400, loss is 3.9091971158981322 and perplexity is 49.85890497686824
At time: 605.7290904521942 and batch: 450, loss is 3.8550419664382933 and perplexity is 47.23059899970295
At time: 606.7508647441864 and batch: 500, loss is 3.9294838905334473 and perplexity is 50.880710874966404
At time: 607.7722432613373 and batch: 550, loss is 3.9200127506256104 and perplexity is 50.40108741936448
At time: 608.795163154602 and batch: 600, loss is 3.8545338344573974 and perplexity is 47.20660571826739
At time: 609.8167088031769 and batch: 650, loss is 3.8688757705688475 and perplexity is 47.888518125031766
At time: 610.8393361568451 and batch: 700, loss is 3.892808003425598 and perplexity is 49.04842146956852
At time: 611.8625328540802 and batch: 750, loss is 3.851415982246399 and perplexity is 47.059651707743285
At time: 612.8840119838715 and batch: 800, loss is 3.821227822303772 and perplexity is 45.66023657430179
At time: 613.9068398475647 and batch: 850, loss is 3.7897931003570555 and perplexity is 44.24724458975503
At time: 614.9280450344086 and batch: 900, loss is 3.823731245994568 and perplexity is 45.77468669106328
At time: 615.9488558769226 and batch: 950, loss is 3.8027796506881715 and perplexity is 44.82561102256887
At time: 616.9718255996704 and batch: 1000, loss is 3.8147631311416625 and perplexity is 45.36600931534083
At time: 618.002209186554 and batch: 1050, loss is 3.7613743257522585 and perplexity is 43.00749168506843
At time: 619.0240638256073 and batch: 1100, loss is 3.722367625236511 and perplexity is 41.362208477663266
At time: 620.0460550785065 and batch: 1150, loss is 3.7382981634140013 and perplexity is 42.0264071936737
At time: 621.0681338310242 and batch: 1200, loss is 3.7082684421539307 and perplexity is 40.78312700825409
At time: 622.0895648002625 and batch: 1250, loss is 3.7662259483337404 and perplexity is 43.216654782827284
At time: 623.1135272979736 and batch: 1300, loss is 3.7610151815414428 and perplexity is 42.9920485667273
At time: 624.134316444397 and batch: 1350, loss is 3.732599415779114 and perplexity is 41.78759042962252
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.353117268880208 and perplexity of 77.7203609613499
Annealing...
Finished 21 epochs...
Completing Train Step...
At time: 627.2195851802826 and batch: 50, loss is 3.94208634853363 and perplexity is 51.525990410553646
At time: 628.2676775455475 and batch: 100, loss is 3.941912474632263 and perplexity is 51.517032164404334
At time: 629.2913391590118 and batch: 150, loss is 3.925609049797058 and perplexity is 50.68393770232662
At time: 630.3119444847107 and batch: 200, loss is 3.916660590171814 and perplexity is 50.23241774913287
At time: 631.3339142799377 and batch: 250, loss is 3.906559181213379 and perplexity is 49.727553766212644
At time: 632.3551943302155 and batch: 300, loss is 3.911553363800049 and perplexity is 49.9765234318135
At time: 633.3772025108337 and batch: 350, loss is 3.9085130739212035 and perplexity is 49.8248110551066
At time: 634.4002630710602 and batch: 400, loss is 3.9126787853240965 and perplexity is 50.03279974832984
At time: 635.4252302646637 and batch: 450, loss is 3.8573181009292603 and perplexity is 47.338224633858744
At time: 636.4480094909668 and batch: 500, loss is 3.931589751243591 and perplexity is 50.98797146319284
At time: 637.4692888259888 and batch: 550, loss is 3.9237016820907593 and perplexity is 50.587356933125726
At time: 638.490907907486 and batch: 600, loss is 3.8583342361450197 and perplexity is 47.38635111832757
At time: 639.5128397941589 and batch: 650, loss is 3.8718913698196413 and perplexity is 48.0331486686869
At time: 640.5349445343018 and batch: 700, loss is 3.89293851852417 and perplexity is 49.05482344689967
At time: 641.555065870285 and batch: 750, loss is 3.8504409646987914 and perplexity is 47.01379008312154
At time: 642.5775480270386 and batch: 800, loss is 3.820132164955139 and perplexity is 45.61023599731063
At time: 643.5980722904205 and batch: 850, loss is 3.7873263549804688 and perplexity is 44.13823241165644
At time: 644.6197938919067 and batch: 900, loss is 3.8193999624252317 and perplexity is 45.57685229043253
At time: 645.6409921646118 and batch: 950, loss is 3.7986264514923094 and perplexity is 44.63982739616919
At time: 646.6624958515167 and batch: 1000, loss is 3.8101432275772096 and perplexity is 45.15690611742079
At time: 647.6831138134003 and batch: 1050, loss is 3.755977258682251 and perplexity is 42.77600261086833
At time: 648.7038908004761 and batch: 1100, loss is 3.7170569276809693 and perplexity is 41.14312854673759
At time: 649.7264339923859 and batch: 1150, loss is 3.732751522064209 and perplexity is 41.79394706819594
At time: 650.7479958534241 and batch: 1200, loss is 3.702537331581116 and perplexity is 40.55006289389736
At time: 651.7693364620209 and batch: 1250, loss is 3.758848648071289 and perplexity is 42.89900568121407
At time: 652.7903604507446 and batch: 1300, loss is 3.754316782951355 and perplexity is 42.705033034604085
At time: 653.8104693889618 and batch: 1350, loss is 3.727710933685303 and perplexity is 41.58381103384138
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348964029947917 and perplexity of 77.39823911989366
Finished 22 epochs...
Completing Train Step...
At time: 656.9022510051727 and batch: 50, loss is 3.9419495820999146 and perplexity is 51.51894386647787
At time: 657.956220626831 and batch: 100, loss is 3.9394865798950196 and perplexity is 51.3922087326665
At time: 658.976886510849 and batch: 150, loss is 3.922409725189209 and perplexity is 50.52204244903903
At time: 659.9967098236084 and batch: 200, loss is 3.9134003019332884 and perplexity is 50.06891227067833
At time: 661.0160088539124 and batch: 250, loss is 3.9023854732513428 and perplexity is 49.52043800014713
At time: 662.0370063781738 and batch: 300, loss is 3.9072262334823606 and perplexity is 49.76073570959823
At time: 663.0565519332886 and batch: 350, loss is 3.9045854234695434 and perplexity is 49.62950042049215
At time: 664.0780766010284 and batch: 400, loss is 3.9091070652008058 and perplexity is 49.85441534985719
At time: 665.0978894233704 and batch: 450, loss is 3.853992199897766 and perplexity is 47.18104391237115
At time: 666.1172008514404 and batch: 500, loss is 3.928340449333191 and perplexity is 50.82256502337008
At time: 667.1363365650177 and batch: 550, loss is 3.920711727142334 and perplexity is 50.43632891094065
At time: 668.1577939987183 and batch: 600, loss is 3.8555119371414186 and perplexity is 47.252801214310416
At time: 669.1781022548676 and batch: 650, loss is 3.869353404045105 and perplexity is 47.91139674777977
At time: 670.1990702152252 and batch: 700, loss is 3.891105680465698 and perplexity is 48.964996244038964
At time: 671.2180786132812 and batch: 750, loss is 3.8489422607421875 and perplexity is 46.943383102697595
At time: 672.2390730381012 and batch: 800, loss is 3.8186766147613525 and perplexity is 45.54389630155702
At time: 673.2598249912262 and batch: 850, loss is 3.786426205635071 and perplexity is 44.09851928719708
At time: 674.278970003128 and batch: 900, loss is 3.8189637756347654 and perplexity is 45.55697660458334
At time: 675.2996425628662 and batch: 950, loss is 3.798362150192261 and perplexity is 44.628030590778614
At time: 676.3191156387329 and batch: 1000, loss is 3.810349507331848 and perplexity is 45.166222033744354
At time: 677.3390727043152 and batch: 1050, loss is 3.7563617753982546 and perplexity is 42.79245386160379
At time: 678.3604776859283 and batch: 1100, loss is 3.7178374195098876 and perplexity is 41.17525295717362
At time: 679.4059791564941 and batch: 1150, loss is 3.7336207532882693 and perplexity is 41.83029146551844
At time: 680.4251239299774 and batch: 1200, loss is 3.703577003479004 and perplexity is 40.59224357798219
At time: 681.4463315010071 and batch: 1250, loss is 3.760042896270752 and perplexity is 42.95026834558724
At time: 682.4656956195831 and batch: 1300, loss is 3.7554807758331297 and perplexity is 42.75477033038577
At time: 683.4873135089874 and batch: 1350, loss is 3.728912901878357 and perplexity is 41.63382350272727
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348621419270834 and perplexity of 77.37172619884802
Finished 23 epochs...
Completing Train Step...
At time: 686.5822923183441 and batch: 50, loss is 3.940862078666687 and perplexity is 51.46294729189913
At time: 687.6016438007355 and batch: 100, loss is 3.938037576675415 and perplexity is 51.317795182507105
At time: 688.6220362186432 and batch: 150, loss is 3.9207451152801513 and perplexity is 50.43801291415403
At time: 689.6422281265259 and batch: 200, loss is 3.911696949005127 and perplexity is 49.98369983637998
At time: 690.6619801521301 and batch: 250, loss is 3.9005034732818604 and perplexity is 49.427328181162665
At time: 691.6810269355774 and batch: 300, loss is 3.905446448326111 and perplexity is 49.67225105601198
At time: 692.7019941806793 and batch: 350, loss is 3.902862958908081 and perplexity is 49.54408894505173
At time: 693.7215738296509 and batch: 400, loss is 3.907486038208008 and perplexity is 49.77366546342011
At time: 694.7431466579437 and batch: 450, loss is 3.8525101375579833 and perplexity is 47.111170455236476
At time: 695.7685089111328 and batch: 500, loss is 3.926940231323242 and perplexity is 50.75145215089366
At time: 696.788801908493 and batch: 550, loss is 3.9194551420211794 and perplexity is 50.372991173429
At time: 697.8080766201019 and batch: 600, loss is 3.854316816329956 and perplexity is 47.19636214065276
At time: 698.8293089866638 and batch: 650, loss is 3.868272428512573 and perplexity is 47.859633682509966
At time: 699.8484544754028 and batch: 700, loss is 3.8901915979385375 and perplexity is 48.92025864657291
At time: 700.8676373958588 and batch: 750, loss is 3.8481607913970945 and perplexity is 46.906712618143864
At time: 701.8884844779968 and batch: 800, loss is 3.8179515171051026 and perplexity is 45.51088449892901
At time: 702.90895652771 and batch: 850, loss is 3.785932059288025 and perplexity is 44.076733548096186
At time: 703.9293270111084 and batch: 900, loss is 3.8186441898345946 and perplexity is 45.542419567996795
At time: 704.9911165237427 and batch: 950, loss is 3.798118243217468 and perplexity is 44.61714683021277
At time: 706.0105791091919 and batch: 1000, loss is 3.810231189727783 and perplexity is 45.160878390698414
At time: 707.029584646225 and batch: 1050, loss is 3.756339821815491 and perplexity is 42.79151442423832
At time: 708.050279378891 and batch: 1100, loss is 3.7179799699783325 and perplexity is 41.18112292714455
At time: 709.0692596435547 and batch: 1150, loss is 3.7338328075408938 and perplexity is 41.8391626972702
At time: 710.0903062820435 and batch: 1200, loss is 3.7038769578933715 and perplexity is 40.604421226910965
At time: 711.1102838516235 and batch: 1250, loss is 3.7604124450683596 and perplexity is 42.96614349875248
At time: 712.1306436061859 and batch: 1300, loss is 3.755824580192566 and perplexity is 42.76947213393932
At time: 713.154402256012 and batch: 1350, loss is 3.72922966003418 and perplexity is 41.64701344478041
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348521321614584 and perplexity of 77.36398185799716
Finished 24 epochs...
Completing Train Step...
At time: 716.270830154419 and batch: 50, loss is 3.939789319038391 and perplexity is 51.40776952122524
At time: 717.2892670631409 and batch: 100, loss is 3.93681640625 and perplexity is 51.255165657177834
At time: 718.3085532188416 and batch: 150, loss is 3.9194226598739625 and perplexity is 50.37135497708768
At time: 719.3280611038208 and batch: 200, loss is 3.910387625694275 and perplexity is 49.91829783854512
At time: 720.3482356071472 and batch: 250, loss is 3.899126048088074 and perplexity is 49.359292601781924
At time: 721.366767168045 and batch: 300, loss is 3.9041422319412233 and perplexity is 49.6075099197128
At time: 722.3875367641449 and batch: 350, loss is 3.9015974855422972 and perplexity is 49.481431873848834
At time: 723.4070069789886 and batch: 400, loss is 3.9062799835205078 and perplexity is 49.713671885913634
At time: 724.4257943630219 and batch: 450, loss is 3.851394271850586 and perplexity is 47.05863003516838
At time: 725.4451019763947 and batch: 500, loss is 3.9258850955963136 and perplexity is 50.697930721687314
At time: 726.4723033905029 and batch: 550, loss is 3.9185035705566404 and perplexity is 50.32508047128861
At time: 727.4918687343597 and batch: 600, loss is 3.8534019422531127 and perplexity is 47.15320315793653
At time: 728.5134115219116 and batch: 650, loss is 3.8674444007873534 and perplexity is 47.8200209813727
At time: 729.5330114364624 and batch: 700, loss is 3.8894520092010496 and perplexity is 48.88409115042793
At time: 730.5522496700287 and batch: 750, loss is 3.8475178480148315 and perplexity is 46.87656395066399
At time: 731.5982315540314 and batch: 800, loss is 3.817360963821411 and perplexity is 45.484015831115336
At time: 732.6172370910645 and batch: 850, loss is 3.785487775802612 and perplexity is 44.057155332750746
At time: 733.6365349292755 and batch: 900, loss is 3.81829749584198 and perplexity is 45.526633021432
At time: 734.6602444648743 and batch: 950, loss is 3.7978337574005128 and perplexity is 44.60445569005684
At time: 735.6802461147308 and batch: 1000, loss is 3.8100108528137206 and perplexity is 45.15092887828014
At time: 736.7010350227356 and batch: 1050, loss is 3.756178035736084 and perplexity is 42.78459191288583
At time: 737.722909450531 and batch: 1100, loss is 3.717923893928528 and perplexity is 41.17881371719057
At time: 738.7424719333649 and batch: 1150, loss is 3.7338288831710815 and perplexity is 41.838998505245314
At time: 739.7624995708466 and batch: 1200, loss is 3.7039486360549927 and perplexity is 40.607331781488554
At time: 740.7904016971588 and batch: 1250, loss is 3.7605393362045287 and perplexity is 42.971595867439156
At time: 741.8107113838196 and batch: 1300, loss is 3.75593156337738 and perplexity is 42.77404799304665
At time: 742.8315043449402 and batch: 1350, loss is 3.7293147230148316 and perplexity is 41.65055621455641
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348486328125 and perplexity of 77.36127466967115
Finished 25 epochs...
Completing Train Step...
At time: 745.8955907821655 and batch: 50, loss is 3.9387725257873534 and perplexity is 51.355525013557724
At time: 746.9436128139496 and batch: 100, loss is 3.9357101202011107 and perplexity is 51.19849413571444
At time: 747.9651997089386 and batch: 150, loss is 3.9182577753067016 and perplexity is 50.31271232563397
At time: 748.9861361980438 and batch: 200, loss is 3.9092495965957643 and perplexity is 49.86152167564709
At time: 750.0083563327789 and batch: 250, loss is 3.897951455116272 and perplexity is 49.301349560005434
At time: 751.0288605690002 and batch: 300, loss is 3.9030227565765383 and perplexity is 49.55200660754614
At time: 752.0509223937988 and batch: 350, loss is 3.9005172491073608 and perplexity is 49.42800908810065
At time: 753.0733306407928 and batch: 400, loss is 3.905241723060608 and perplexity is 49.66208293209786
At time: 754.0952286720276 and batch: 450, loss is 3.8504241132736206 and perplexity is 47.01299784043118
At time: 755.1165025234222 and batch: 500, loss is 3.9249621438980102 and perplexity is 50.65116056704415
At time: 756.1412291526794 and batch: 550, loss is 3.9176646423339845 and perplexity is 50.282879045432516
At time: 757.2046930789948 and batch: 600, loss is 3.8525933599472046 and perplexity is 47.11509132255048
At time: 758.2256572246552 and batch: 650, loss is 3.866713409423828 and perplexity is 47.78507773219438
At time: 759.2472715377808 and batch: 700, loss is 3.888778247833252 and perplexity is 48.85116603139303
At time: 760.2699427604675 and batch: 750, loss is 3.8469201850891115 and perplexity is 46.848555936814996
At time: 761.2910702228546 and batch: 800, loss is 3.816810212135315 and perplexity is 45.45897232971427
At time: 762.3116879463196 and batch: 850, loss is 3.785050325393677 and perplexity is 44.03788672697092
At time: 763.3343760967255 and batch: 900, loss is 3.8179289579391478 and perplexity is 45.50985782291337
At time: 764.3552613258362 and batch: 950, loss is 3.797517476081848 and perplexity is 44.590350364735905
At time: 765.3765652179718 and batch: 1000, loss is 3.8097399473190308 and perplexity is 45.13869890021559
At time: 766.3985764980316 and batch: 1050, loss is 3.7559499502182008 and perplexity is 42.77483447988883
At time: 767.4193964004517 and batch: 1100, loss is 3.7177793550491334 and perplexity is 41.1728622077237
At time: 768.4404532909393 and batch: 1150, loss is 3.733722224235535 and perplexity is 41.834536240174856
At time: 769.4635002613068 and batch: 1200, loss is 3.7039123821258544 and perplexity is 40.6058596328454
At time: 770.4850718975067 and batch: 1250, loss is 3.7605538320541383 and perplexity is 42.97221878174516
At time: 771.5060112476349 and batch: 1300, loss is 3.7559285593032836 and perplexity is 42.773919496830075
At time: 772.5296366214752 and batch: 1350, loss is 3.7293002557754518 and perplexity is 41.64995365034808
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348480224609375 and perplexity of 77.36080249536336
Finished 26 epochs...
Completing Train Step...
At time: 775.6165671348572 and batch: 50, loss is 3.937799544334412 and perplexity is 51.30558134128697
At time: 776.6656119823456 and batch: 100, loss is 3.934673171043396 and perplexity is 51.14543141676971
At time: 777.6869864463806 and batch: 150, loss is 3.91718400478363 and perplexity is 50.25871701267862
At time: 778.7089312076569 and batch: 200, loss is 3.9082080793380736 and perplexity is 49.80961707478795
At time: 779.7313845157623 and batch: 250, loss is 3.896885576248169 and perplexity is 49.24882828896936
At time: 780.7530062198639 and batch: 300, loss is 3.9020023250579836 and perplexity is 49.501467968191825
At time: 781.7753567695618 and batch: 350, loss is 3.8995370721817015 and perplexity is 49.3795846302563
At time: 782.7983641624451 and batch: 400, loss is 3.9042957735061647 and perplexity is 49.61512731919747
At time: 783.8452591896057 and batch: 450, loss is 3.849532837867737 and perplexity is 46.97111497905384
At time: 784.8668866157532 and batch: 500, loss is 3.92410982131958 and perplexity is 50.608007831906775
At time: 785.8899209499359 and batch: 550, loss is 3.9168851232528685 and perplexity is 50.24369785498998
At time: 786.911502122879 and batch: 600, loss is 3.851841254234314 and perplexity is 47.079669115495314
At time: 787.9333710670471 and batch: 650, loss is 3.866020050048828 and perplexity is 47.75195698418112
At time: 788.9561557769775 and batch: 700, loss is 3.888138704299927 and perplexity is 48.8199335723854
At time: 789.9779925346375 and batch: 750, loss is 3.846343264579773 and perplexity is 46.821535839035874
At time: 791.0005118846893 and batch: 800, loss is 3.8162756395339965 and perplexity is 45.43467770282221
At time: 792.0257098674774 and batch: 850, loss is 3.7846099376678466 and perplexity is 44.01849725194163
At time: 793.0498027801514 and batch: 900, loss is 3.817543725967407 and perplexity is 45.49232934713203
At time: 794.0718464851379 and batch: 950, loss is 3.797177963256836 and perplexity is 44.575213938566094
At time: 795.0936033725739 and batch: 1000, loss is 3.809436631202698 and perplexity is 45.125009681554126
At time: 796.1169261932373 and batch: 1050, loss is 3.7556824922561645 and perplexity is 42.763395539618415
At time: 797.1383492946625 and batch: 1100, loss is 3.7175846910476684 and perplexity is 41.1648481136677
At time: 798.1602244377136 and batch: 1150, loss is 3.7335556507110597 and perplexity is 41.8275682943823
At time: 799.1830370426178 and batch: 1200, loss is 3.7038136863708497 and perplexity is 40.60185220463266
At time: 800.2049987316132 and batch: 1250, loss is 3.760502047538757 and perplexity is 42.969993543837624
At time: 801.2264752388 and batch: 1300, loss is 3.755861620903015 and perplexity is 42.771056374913215
At time: 802.2481188774109 and batch: 1350, loss is 3.7292297744750975 and perplexity is 41.64701821090312
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.348487548828125 and perplexity of 77.36136910487848
Annealing...
Finished 27 epochs...
Completing Train Step...
At time: 805.3525106906891 and batch: 50, loss is 3.9381084871292114 and perplexity is 51.32143427967482
At time: 806.375189781189 and batch: 100, loss is 3.9363821077346803 and perplexity is 51.23291044788244
At time: 807.3959028720856 and batch: 150, loss is 3.9193219423294066 and perplexity is 50.366281953373964
At time: 808.4167399406433 and batch: 200, loss is 3.911571950912476 and perplexity is 49.97745235970625
At time: 809.4636046886444 and batch: 250, loss is 3.9003075695037843 and perplexity is 49.41764612923801
At time: 810.4964108467102 and batch: 300, loss is 3.905624303817749 and perplexity is 49.68108632432153
At time: 811.517814874649 and batch: 350, loss is 3.9029131746292114 and perplexity is 49.54657689967254
At time: 812.5394690036774 and batch: 400, loss is 3.9070379972457885 and perplexity is 49.75136981750698
At time: 813.5689182281494 and batch: 450, loss is 3.8508171796798707 and perplexity is 47.031480702797545
At time: 814.5987002849579 and batch: 500, loss is 3.924877572059631 and perplexity is 50.64687708641243
At time: 815.6208522319794 and batch: 550, loss is 3.9183839178085327 and perplexity is 50.319059297343664
At time: 816.6439220905304 and batch: 600, loss is 3.8536610078811644 and perplexity is 47.16542051460755
At time: 817.6657502651215 and batch: 650, loss is 3.8673801183700562 and perplexity is 47.81694709362834
At time: 818.6877210140228 and batch: 700, loss is 3.8880787897109985 and perplexity is 48.81700863375803
At time: 819.7093317508698 and batch: 750, loss is 3.8459358263015746 and perplexity is 46.802462838890044
At time: 820.7324249744415 and batch: 800, loss is 3.8159590768814087 and perplexity is 45.42029705703692
At time: 821.7545521259308 and batch: 850, loss is 3.783375916481018 and perplexity is 43.96421099580446
At time: 822.7761673927307 and batch: 900, loss is 3.8150826787948606 and perplexity is 45.38050823357678
At time: 823.8024904727936 and batch: 950, loss is 3.7946745920181275 and perplexity is 44.46376518703547
At time: 824.834920167923 and batch: 1000, loss is 3.806071553230286 and perplexity is 44.97341571128588
At time: 825.8575866222382 and batch: 1050, loss is 3.7522271347045897 and perplexity is 42.61588771081876
At time: 826.8809366226196 and batch: 1100, loss is 3.713953175544739 and perplexity is 41.0156284403369
At time: 827.9034607410431 and batch: 1150, loss is 3.7299469041824342 and perplexity is 41.67689523645503
At time: 828.9263527393341 and batch: 1200, loss is 3.7000559759140015 and perplexity is 40.449568498265855
At time: 829.9484541416168 and batch: 1250, loss is 3.7557690238952635 and perplexity is 42.76709608643278
At time: 830.9703323841095 and batch: 1300, loss is 3.751331663131714 and perplexity is 42.57774347590876
At time: 831.9975566864014 and batch: 1350, loss is 3.7257737827301027 and perplexity is 41.50333488696463
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.347157389322916 and perplexity of 77.25853455276847
Finished 28 epochs...
Completing Train Step...
At time: 835.1090898513794 and batch: 50, loss is 3.9377157211303713 and perplexity is 51.301280923313705
At time: 836.1297254562378 and batch: 100, loss is 3.9352233171463014 and perplexity is 51.173576617821524
At time: 837.1503391265869 and batch: 150, loss is 3.9178617572784424 and perplexity is 50.29279152926
At time: 838.1728982925415 and batch: 200, loss is 3.910090265274048 and perplexity is 49.903456319272394
At time: 839.1942427158356 and batch: 250, loss is 3.898438515663147 and perplexity is 49.32536815106302
At time: 840.2149493694305 and batch: 300, loss is 3.903535342216492 and perplexity is 49.57741276542362
At time: 841.2373945713043 and batch: 350, loss is 3.9010872411727906 and perplexity is 49.45619069197317
At time: 842.2587895393372 and batch: 400, loss is 3.905456290245056 and perplexity is 49.67273992868641
At time: 843.2820754051208 and batch: 450, loss is 3.8494615650177 and perplexity is 46.96776733311941
At time: 844.3032782077789 and batch: 500, loss is 3.9235416746139524 and perplexity is 50.57926322532868
At time: 845.3250007629395 and batch: 550, loss is 3.917016248703003 and perplexity is 50.25028651444866
At time: 846.3463578224182 and batch: 600, loss is 3.852203812599182 and perplexity is 47.09674133799989
At time: 847.3691313266754 and batch: 650, loss is 3.866193766593933 and perplexity is 47.76025300972802
At time: 848.3903098106384 and batch: 700, loss is 3.8873140239715576 and perplexity is 48.779689330134254
At time: 849.4114916324615 and batch: 750, loss is 3.845362024307251 and perplexity is 46.77561519572606
At time: 850.4348428249359 and batch: 800, loss is 3.815446367263794 and perplexity is 45.397015602723634
At time: 851.4556450843811 and batch: 850, loss is 3.7831281137466433 and perplexity is 43.953317893831034
At time: 852.4765446186066 and batch: 900, loss is 3.815113415718079 and perplexity is 45.38190311221099
At time: 853.4996485710144 and batch: 950, loss is 3.7947565937042236 and perplexity is 44.4674114402484
At time: 854.5211315155029 and batch: 1000, loss is 3.806438708305359 and perplexity is 44.989930960750954
At time: 855.5421380996704 and batch: 1050, loss is 3.7526646280288696 and perplexity is 42.63453595614448
At time: 856.5637037754059 and batch: 1100, loss is 3.714581360816956 and perplexity is 41.0414019484754
At time: 857.586745262146 and batch: 1150, loss is 3.73061710357666 and perplexity is 41.70483642843484
At time: 858.6078519821167 and batch: 1200, loss is 3.7008599138259886 and perplexity is 40.48210051501377
At time: 859.6288392543793 and batch: 1250, loss is 3.7565578031539917 and perplexity is 42.80084319254075
At time: 860.6518273353577 and batch: 1300, loss is 3.7520599222183226 and perplexity is 42.60876239801739
At time: 861.6794214248657 and batch: 1350, loss is 3.7265146923065187 and perplexity is 41.53409649961507
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.34683349609375 and perplexity of 77.23351508856778
Finished 29 epochs...
Completing Train Step...
At time: 864.7513401508331 and batch: 50, loss is 3.937327017784119 and perplexity is 51.28134381881242
At time: 865.8070278167725 and batch: 100, loss is 3.934548273086548 and perplexity is 51.13904385578861
At time: 866.829772233963 and batch: 150, loss is 3.9170806932449342 and perplexity is 50.25352497549445
At time: 867.8513896465302 and batch: 200, loss is 3.9092845821380617 and perplexity is 49.863266138537995
At time: 868.8725287914276 and batch: 250, loss is 3.8974668407440185 and perplexity is 49.27746320573992
At time: 869.8952932357788 and batch: 300, loss is 3.902547402381897 and perplexity is 49.528457450890976
At time: 870.9166703224182 and batch: 350, loss is 3.9001808977127075 and perplexity is 49.4113867039467
At time: 871.9379391670227 and batch: 400, loss is 3.904632682800293 and perplexity is 49.6318459328907
At time: 872.9594914913177 and batch: 450, loss is 3.8487405347824097 and perplexity is 46.93391435876383
At time: 873.9830827713013 and batch: 500, loss is 3.9228463315963746 and perplexity is 50.544105512562325
At time: 875.0096888542175 and batch: 550, loss is 3.916351652145386 and perplexity is 50.216901442042804
At time: 876.0307581424713 and batch: 600, loss is 3.85155921459198 and perplexity is 47.06639265478891
At time: 877.0537858009338 and batch: 650, loss is 3.865622391700745 and perplexity is 47.73297179490874
At time: 878.0757207870483 and batch: 700, loss is 3.886917653083801 and perplexity is 48.76035831274934
At time: 879.0975232124329 and batch: 750, loss is 3.8450353050231936 and perplexity is 46.760335196489095
At time: 880.1209287643433 and batch: 800, loss is 3.815134434700012 and perplexity is 45.38285700363748
At time: 881.1418261528015 and batch: 850, loss is 3.782956390380859 and perplexity is 43.945770730175646
At time: 882.1627397537231 and batch: 900, loss is 3.81508216381073 and perplexity is 45.38048486334123
At time: 883.1884317398071 and batch: 950, loss is 3.794762206077576 and perplexity is 44.46766100866375
At time: 884.2156052589417 and batch: 1000, loss is 3.8065673828125 and perplexity is 44.99572039041167
At time: 885.2442090511322 and batch: 1050, loss is 3.752826910018921 and perplexity is 42.641455334914454
At time: 886.2721514701843 and batch: 1100, loss is 3.7148514366149903 and perplexity is 41.052487734793
At time: 887.3250215053558 and batch: 1150, loss is 3.7309059858322144 and perplexity is 41.71688595601336
At time: 888.3518860340118 and batch: 1200, loss is 3.70120201587677 and perplexity is 40.495951893777345
At time: 889.3779304027557 and batch: 1250, loss is 3.7569063663482667 and perplexity is 42.81576459153578
At time: 890.4078211784363 and batch: 1300, loss is 3.7523574161529543 and perplexity is 42.62144013207396
At time: 891.4348485469818 and batch: 1350, loss is 3.7268168830871584 and perplexity is 41.54664961728214
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.346725667317708 and perplexity of 77.22518754214897
Finished 30 epochs...
Completing Train Step...
At time: 894.51926612854 and batch: 50, loss is 3.9369220209121703 and perplexity is 51.26057924005502
At time: 895.5650868415833 and batch: 100, loss is 3.934003348350525 and perplexity is 51.11118451712579
At time: 896.5876290798187 and batch: 150, loss is 3.9164818334579468 and perplexity is 50.223439169721026
At time: 897.6083045005798 and batch: 200, loss is 3.9086820316314697 and perplexity is 49.83323005230413
At time: 898.628359079361 and batch: 250, loss is 3.896780209541321 and perplexity is 49.24363937549059
At time: 899.6500351428986 and batch: 300, loss is 3.901884579658508 and perplexity is 49.49563974120149
At time: 900.670774936676 and batch: 350, loss is 3.899560055732727 and perplexity is 49.38071956150159
At time: 901.6922116279602 and batch: 400, loss is 3.904056177139282 and perplexity is 49.60324113894904
At time: 902.7243015766144 and batch: 450, loss is 3.848220610618591 and perplexity is 46.909518625101384
At time: 903.7454197406769 and batch: 500, loss is 3.9223509645462036 and perplexity is 50.51907382855864
At time: 904.7664906978607 and batch: 550, loss is 3.915897259712219 and perplexity is 50.19408844542949
At time: 905.789541721344 and batch: 600, loss is 3.8511300468444825 and perplexity is 47.04619761091113
At time: 906.8103947639465 and batch: 650, loss is 3.8652271747589113 and perplexity is 47.714110643140195
At time: 907.8313634395599 and batch: 700, loss is 3.8866156339645386 and perplexity is 48.74563397590434
At time: 908.8532249927521 and batch: 750, loss is 3.844774770736694 and perplexity is 46.74815411278608
At time: 909.8751263618469 and batch: 800, loss is 3.814888105392456 and perplexity is 45.37167925265721
At time: 910.8956615924835 and batch: 850, loss is 3.7828008222579954 and perplexity is 43.938934700863264
At time: 911.9179120063782 and batch: 900, loss is 3.8150076627731324 and perplexity is 45.377104096069125
At time: 912.9643869400024 and batch: 950, loss is 3.7947125577926637 and perplexity is 44.46545332036503
At time: 913.9857792854309 and batch: 1000, loss is 3.8065833330154417 and perplexity is 44.996438087007085
At time: 915.0083644390106 and batch: 1050, loss is 3.7528661775588987 and perplexity is 42.64312979284224
At time: 916.0305750370026 and batch: 1100, loss is 3.7149589395523073 and perplexity is 41.05690123503653
At time: 917.0510964393616 and batch: 1150, loss is 3.7310319423675535 and perplexity is 41.72214080136762
At time: 918.0734376907349 and batch: 1200, loss is 3.701360750198364 and perplexity is 40.502380501435354
At time: 919.0951924324036 and batch: 1250, loss is 3.7570788955688474 and perplexity is 42.82315219930011
At time: 920.1162800788879 and batch: 1300, loss is 3.7524935817718506 and perplexity is 42.6272441019894
At time: 921.1383383274078 and batch: 1350, loss is 3.7269526624679568 and perplexity is 41.55229117863661
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.3466805013020835 and perplexity of 77.22169966688915
Finished 31 epochs...
Completing Train Step...
At time: 924.2729909420013 and batch: 50, loss is 3.9365246057510377 and perplexity is 51.24021155617784
At time: 925.2940196990967 and batch: 100, loss is 3.933524112701416 and perplexity is 51.0866960837708
At time: 926.3142294883728 and batch: 150, loss is 3.915966024398804 and perplexity is 50.19754014486602
At time: 927.333093881607 and batch: 200, loss is 3.9081747150421142 and perplexity is 49.80795523970538
At time: 928.3541190624237 and batch: 250, loss is 3.896222863197327 and perplexity is 49.21620126009662
At time: 929.3741211891174 and batch: 300, loss is 3.901354284286499 and perplexity is 49.469399390695244
At time: 930.3943543434143 and batch: 350, loss is 3.8990580797195435 and perplexity is 49.35593784520193
At time: 931.415219783783 and batch: 400, loss is 3.9035857009887693 and perplexity is 49.57990948592854
At time: 932.4354960918427 and batch: 450, loss is 3.847788381576538 and perplexity is 46.88924735003537
At time: 933.455643415451 and batch: 500, loss is 3.921939740180969 and perplexity is 50.49830342543188
At time: 934.4757146835327 and batch: 550, loss is 3.915525879859924 and perplexity is 50.175450833307586
At time: 935.5043568611145 and batch: 600, loss is 3.8507801294326782 and perplexity is 47.029738207091825
At time: 936.5256733894348 and batch: 650, loss is 3.8649002075195313 and perplexity is 47.69851224232573
At time: 937.5468096733093 and batch: 700, loss is 3.886347246170044 and perplexity is 48.73255299817622
At time: 938.5921564102173 and batch: 750, loss is 3.8445400953292848 and perplexity is 46.73718475784329
At time: 939.6120140552521 and batch: 800, loss is 3.8146688556671142 and perplexity is 45.36173261488142
At time: 940.632515668869 and batch: 850, loss is 3.7826485681533812 and perplexity is 43.932245326957926
At time: 941.654928445816 and batch: 900, loss is 3.8149085235595703 and perplexity is 45.372605668644276
At time: 942.6746780872345 and batch: 950, loss is 3.7946322774887085 and perplexity is 44.46188376354144
At time: 943.6958408355713 and batch: 1000, loss is 3.806543803215027 and perplexity is 44.9946594219455
At time: 944.7157499790192 and batch: 1050, loss is 3.7528452634811402 and perplexity is 42.64223796043584
At time: 945.7358791828156 and batch: 1100, loss is 3.714987177848816 and perplexity is 41.0580606283569
At time: 946.7576971054077 and batch: 1150, loss is 3.7310782146453856 and perplexity is 41.724071424525356
At time: 947.7782099246979 and batch: 1200, loss is 3.7014342975616454 and perplexity is 40.505359454273574
At time: 948.7994062900543 and batch: 1250, loss is 3.757168827056885 and perplexity is 42.82700352227485
At time: 949.8198382854462 and batch: 1300, loss is 3.7525568056106566 and perplexity is 42.629939245197
At time: 950.8394029140472 and batch: 1350, loss is 3.727012801170349 and perplexity is 41.55479015465135
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.346659749348959 and perplexity of 77.22009718242485
Finished 32 epochs...
Completing Train Step...
At time: 953.9257440567017 and batch: 50, loss is 3.936138653755188 and perplexity is 51.22043911011292
At time: 954.9472687244415 and batch: 100, loss is 3.933083996772766 and perplexity is 51.06421696215483
At time: 955.9683349132538 and batch: 150, loss is 3.9154979944229127 and perplexity is 50.17405168844183
At time: 956.9886391162872 and batch: 200, loss is 3.9077204513549804 and perplexity is 49.7853344326042
At time: 958.0112626552582 and batch: 250, loss is 3.8957347202301027 and perplexity is 49.19218258032976
At time: 959.032318353653 and batch: 300, loss is 3.90089120388031 and perplexity is 49.446496384507455
At time: 960.0544726848602 and batch: 350, loss is 3.8986171674728394 and perplexity is 49.33418100453962
At time: 961.0764675140381 and batch: 400, loss is 3.903169522285461 and perplexity is 49.55927967662996
At time: 962.0975267887115 and batch: 450, loss is 3.8474022483825685 and perplexity is 46.87114535030968
At time: 963.1210527420044 and batch: 500, loss is 3.9215711307525636 and perplexity is 50.47969270492503
At time: 964.1429493427277 and batch: 550, loss is 3.9151944732666015 and perplexity is 50.158825113167296
At time: 965.1897115707397 and batch: 600, loss is 3.8504665184020994 and perplexity is 47.01499147491465
At time: 966.2121894359589 and batch: 650, loss is 3.8646053647994996 and perplexity is 47.684450756299995
At time: 967.2336184978485 and batch: 700, loss is 3.8860947132110595 and perplexity is 48.72024797614591
At time: 968.2548413276672 and batch: 750, loss is 3.8443176555633545 and perplexity is 46.72678970558487
At time: 969.2782995700836 and batch: 800, loss is 3.81446240901947 and perplexity is 45.3523688038487
At time: 970.2992606163025 and batch: 850, loss is 3.7824958610534667 and perplexity is 43.92553707339332
At time: 971.3200314044952 and batch: 900, loss is 3.814794588088989 and perplexity is 45.36743641395225
At time: 972.3418443202972 and batch: 950, loss is 3.7945344495773314 and perplexity is 44.45753436306681
At time: 973.3634231090546 and batch: 1000, loss is 3.806474642753601 and perplexity is 44.99154767814424
At time: 974.3859665393829 and batch: 1050, loss is 3.7527918720245363 and perplexity is 42.6399612900162
At time: 975.4070320129395 and batch: 1100, loss is 3.714972677230835 and perplexity is 41.05746526542126
At time: 976.4289002418518 and batch: 1150, loss is 3.731080560684204 and perplexity is 41.724169310931394
At time: 977.4518103599548 and batch: 1200, loss is 3.7014622831344606 and perplexity is 40.506493035821876
At time: 978.4729201793671 and batch: 1250, loss is 3.757214274406433 and perplexity is 42.82894994030347
At time: 979.4940481185913 and batch: 1300, loss is 3.752580637931824 and perplexity is 42.630955227707
At time: 980.5162942409515 and batch: 1350, loss is 3.727033314704895 and perplexity is 41.555642599018036
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.346650390625 and perplexity of 77.21937450423296
Finished 33 epochs...
Completing Train Step...
At time: 983.6233713626862 and batch: 50, loss is 3.935763330459595 and perplexity is 51.20121849330265
At time: 984.6690089702606 and batch: 100, loss is 3.932668948173523 and perplexity is 51.04302722812214
At time: 985.6899290084839 and batch: 150, loss is 3.9150602197647095 and perplexity is 50.15209156725624
At time: 986.7119841575623 and batch: 200, loss is 3.907299394607544 and perplexity is 49.76437639418936
At time: 987.7363409996033 and batch: 250, loss is 3.895288848876953 and perplexity is 49.170254084325656
At time: 988.7577579021454 and batch: 300, loss is 3.9004674768447876 and perplexity is 49.4255490054763
At time: 989.778879404068 and batch: 350, loss is 3.898212819099426 and perplexity is 49.314236841163506
At time: 990.8271155357361 and batch: 400, loss is 3.902785577774048 and perplexity is 49.54025531559173
At time: 991.8489856719971 and batch: 450, loss is 3.8470439815521242 and perplexity is 46.85435598134232
At time: 992.8710112571716 and batch: 500, loss is 3.921227607727051 and perplexity is 50.462354746324586
At time: 993.8950736522675 and batch: 550, loss is 3.914885654449463 and perplexity is 50.14333751568065
At time: 994.9167332649231 and batch: 600, loss is 3.850172801017761 and perplexity is 47.001184382384764
At time: 995.9433701038361 and batch: 650, loss is 3.8643285846710205 and perplexity is 47.67125447421178
At time: 996.9653539657593 and batch: 700, loss is 3.885851035118103 and perplexity is 48.708377365393346
At time: 997.988189458847 and batch: 750, loss is 3.844101948738098 and perplexity is 46.71671150513044
At time: 999.0104706287384 and batch: 800, loss is 3.814262547492981 and perplexity is 45.34330551592112
At time: 1000.0318295955658 and batch: 850, loss is 3.7823419094085695 and perplexity is 43.91877518522313
At time: 1001.0546922683716 and batch: 900, loss is 3.814671506881714 and perplexity is 45.36185287872862
At time: 1002.0760974884033 and batch: 950, loss is 3.7944256114959716 and perplexity is 44.45269595363112
At time: 1003.097754240036 and batch: 1000, loss is 3.8063878202438355 and perplexity is 44.98764156862815
At time: 1004.1200618743896 and batch: 1050, loss is 3.7527191638946533 and perplexity is 42.63686113087727
At time: 1005.1435146331787 and batch: 1100, loss is 3.7149328851699828 and perplexity is 41.055831536769915
At time: 1006.165699005127 and batch: 1150, loss is 3.731056056022644 and perplexity is 41.723146886810696
At time: 1007.1877167224884 and batch: 1200, loss is 3.70146333694458 and perplexity is 40.506535721996634
At time: 1008.2116804122925 and batch: 1250, loss is 3.757233166694641 and perplexity is 42.82975908481266
At time: 1009.2334752082825 and batch: 1300, loss is 3.75258095741272 and perplexity is 42.630968847484944
At time: 1010.2558889389038 and batch: 1350, loss is 3.7270309209823607 and perplexity is 41.55554312645897
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.346649169921875 and perplexity of 77.21928024235869
Finished 34 epochs...
Completing Train Step...
At time: 1013.3333840370178 and batch: 50, loss is 3.9353971338272093 and perplexity is 51.182472212138364
At time: 1014.3816401958466 and batch: 100, loss is 3.9322717142105104 and perplexity is 51.02275523076165
At time: 1015.4028487205505 and batch: 150, loss is 3.9146438217163086 and perplexity is 50.13121268146974
At time: 1016.4498991966248 and batch: 200, loss is 3.906901059150696 and perplexity is 49.74455742614452
At time: 1017.4715495109558 and batch: 250, loss is 3.8948706436157225 and perplexity is 49.14969512460375
At time: 1018.4921164512634 and batch: 300, loss is 3.900069785118103 and perplexity is 49.40589678157243
At time: 1019.5135169029236 and batch: 350, loss is 3.897832818031311 and perplexity is 49.29550093854754
At time: 1020.5361921787262 and batch: 400, loss is 3.90242317199707 and perplexity is 49.52230489373716
At time: 1021.5585203170776 and batch: 450, loss is 3.8467040252685547 and perplexity is 46.838430255792474
At time: 1022.5805048942566 and batch: 500, loss is 3.9209006929397585 and perplexity is 50.44586055260123
At time: 1023.6039552688599 and batch: 550, loss is 3.9145910263061525 and perplexity is 50.12856605340012
At time: 1024.6254200935364 and batch: 600, loss is 3.84989182472229 and perplexity is 46.98798001885769
At time: 1025.647379875183 and batch: 650, loss is 3.864062857627869 and perplexity is 47.65858861562212
At time: 1026.6713774204254 and batch: 700, loss is 3.8856132936477663 and perplexity is 48.696798740554975
At time: 1027.6937539577484 and batch: 750, loss is 3.8438903999328615 and perplexity is 46.70682968590733
At time: 1028.7154614925385 and batch: 800, loss is 3.8140662479400635 and perplexity is 45.33440551888184
At time: 1029.7386496067047 and batch: 850, loss is 3.7821863889694214 and perplexity is 43.91194544911503
At time: 1030.7594156265259 and batch: 900, loss is 3.814541835784912 and perplexity is 45.35597113886694
At time: 1031.7807641029358 and batch: 950, loss is 3.794309287071228 and perplexity is 44.44752532008732
At time: 1032.8022365570068 and batch: 1000, loss is 3.8062899017333987 and perplexity is 44.98323666144218
At time: 1033.824667930603 and batch: 1050, loss is 3.752634267807007 and perplexity is 42.63324158182269
At time: 1034.8460965156555 and batch: 1100, loss is 3.71487690448761 and perplexity is 41.05353326763504
At time: 1035.8688049316406 and batch: 1150, loss is 3.7310140466690065 and perplexity is 41.72139416119395
At time: 1036.8903534412384 and batch: 1200, loss is 3.70144615650177 and perplexity is 40.5058398077543
At time: 1037.9183831214905 and batch: 1250, loss is 3.757234296798706 and perplexity is 42.82980748692485
At time: 1038.9406275749207 and batch: 1300, loss is 3.7525653409957886 and perplexity is 42.630303109699476
At time: 1039.9643242359161 and batch: 1350, loss is 3.7270136880874634 and perplexity is 41.55482701032226
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.34665283203125 and perplexity of 77.21956302832659
Annealing...
Finished 35 epochs...
Completing Train Step...
At time: 1043.1207921504974 and batch: 50, loss is 3.9355287885665895 and perplexity is 51.18921107076989
At time: 1044.142140865326 and batch: 100, loss is 3.9329829454421996 and perplexity is 51.05905711579554
At time: 1045.164845943451 and batch: 150, loss is 3.9155194854736326 and perplexity is 50.1751299931184
At time: 1046.1851444244385 and batch: 200, loss is 3.9083468437194826 and perplexity is 49.81652935506761
At time: 1047.205769777298 and batch: 250, loss is 3.8963179063796995 and perplexity is 49.22087914678577
At time: 1048.2270278930664 and batch: 300, loss is 3.901515398025513 and perplexity is 49.477370232686674
At time: 1049.2476522922516 and batch: 350, loss is 3.899341468811035 and perplexity is 49.369926761647136
At time: 1050.268411397934 and batch: 400, loss is 3.9038069152832033 and perplexity is 49.590878483828405
At time: 1051.2902071475983 and batch: 450, loss is 3.8473360204696654 and perplexity is 46.868041274967105
At time: 1052.3106372356415 and batch: 500, loss is 3.9212223386764524 and perplexity is 50.4620888583246
At time: 1053.3327097892761 and batch: 550, loss is 3.9150597763061525 and perplexity is 50.152069326887016
At time: 1054.3534665107727 and batch: 600, loss is 3.8503604888916017 and perplexity is 47.01000676265048
At time: 1055.3794045448303 and batch: 650, loss is 3.864336886405945 and perplexity is 47.67165022997266
At time: 1056.4050331115723 and batch: 700, loss is 3.8852564191818235 and perplexity is 48.67942319713961
At time: 1057.4260082244873 and batch: 750, loss is 3.8435391283035276 and perplexity is 46.69042578302406
At time: 1058.4481999874115 and batch: 800, loss is 3.8137150382995606 and perplexity is 45.31848643424877
At time: 1059.468421459198 and batch: 850, loss is 3.7813157510757445 and perplexity is 43.873730683447434
At time: 1060.4887318611145 and batch: 900, loss is 3.8131359386444093 and perplexity is 45.292250111838555
At time: 1061.5101206302643 and batch: 950, loss is 3.7929627561569212 and perplexity is 44.3877156300147
At time: 1062.5318970680237 and batch: 1000, loss is 3.8046406078338624 and perplexity is 44.90910723104745
At time: 1063.5521771907806 and batch: 1050, loss is 3.750816888809204 and perplexity is 42.5558311872826
At time: 1064.57368350029 and batch: 1100, loss is 3.7129753494262694 and perplexity is 40.97554188961469
At time: 1065.5982248783112 and batch: 1150, loss is 3.7291379308700563 and perplexity is 41.6431933742575
At time: 1066.6214272975922 and batch: 1200, loss is 3.6994770860671995 and perplexity is 40.426159430044365
At time: 1067.644790172577 and batch: 1250, loss is 3.754964580535889 and perplexity is 42.73270621419305
At time: 1068.6698622703552 and batch: 1300, loss is 3.7503390550613402 and perplexity is 42.535501432481205
At time: 1069.6924984455109 and batch: 1350, loss is 3.7251733636856077 and perplexity is 41.478422973830384
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.346507161458334 and perplexity of 77.20831522959645
Finished 36 epochs...
Completing Train Step...
At time: 1072.7935364246368 and batch: 50, loss is 3.935236086845398 and perplexity is 51.17423009316897
At time: 1073.8146810531616 and batch: 100, loss is 3.9324961709976196 and perplexity is 51.03420891985125
At time: 1074.8368318080902 and batch: 150, loss is 3.9149751329421996 and perplexity is 50.147824466682145
At time: 1075.8573641777039 and batch: 200, loss is 3.907784357070923 and perplexity is 49.7885161017069
At time: 1076.8780930042267 and batch: 250, loss is 3.895674719810486 and perplexity is 49.189231117278474
At time: 1077.8984417915344 and batch: 300, loss is 3.9008584594726563 and perplexity is 49.444877314780676
At time: 1078.9210841655731 and batch: 350, loss is 3.8987483406066894 and perplexity is 49.34065274811808
At time: 1079.941554069519 and batch: 400, loss is 3.903288345336914 and perplexity is 49.56516881134449
At time: 1080.963722705841 and batch: 450, loss is 3.8469300842285157 and perplexity is 46.84901969949652
At time: 1081.9841661453247 and batch: 500, loss is 3.9208223676681517 and perplexity is 50.44190952160682
At time: 1083.0050292015076 and batch: 550, loss is 3.91465407371521 and perplexity is 50.13172662924156
At time: 1084.0259249210358 and batch: 600, loss is 3.849953932762146 and perplexity is 46.99089844082125
At time: 1085.0494048595428 and batch: 650, loss is 3.864025182723999 and perplexity is 47.656793116700285
At time: 1086.0707612037659 and batch: 700, loss is 3.885080223083496 and perplexity is 48.670846828287
At time: 1087.0930740833282 and batch: 750, loss is 3.843408432006836 and perplexity is 46.684323916037656
At time: 1088.1140937805176 and batch: 800, loss is 3.8136107873916627 and perplexity is 45.31376218715124
At time: 1089.1345763206482 and batch: 850, loss is 3.7813094091415405 and perplexity is 43.87345244001645
At time: 1090.15678024292 and batch: 900, loss is 3.8132126569747924 and perplexity is 45.29572499093818
At time: 1091.1772696971893 and batch: 950, loss is 3.793047695159912 and perplexity is 44.391486038450445
At time: 1092.1979882717133 and batch: 1000, loss is 3.804773178100586 and perplexity is 44.91506123802481
At time: 1093.2192132472992 and batch: 1050, loss is 3.7510153245925903 and perplexity is 42.564276624892706
At time: 1094.2725303173065 and batch: 1100, loss is 3.7132042503356932 and perplexity is 40.98492230196886
At time: 1095.2926003932953 and batch: 1150, loss is 3.729392032623291 and perplexity is 41.6537763272207
At time: 1096.3150386810303 and batch: 1200, loss is 3.6997694110870363 and perplexity is 40.43797873535684
At time: 1097.3390827178955 and batch: 1250, loss is 3.7551814794540403 and perplexity is 42.741975897196355
At time: 1098.3601138591766 and batch: 1300, loss is 3.750533952713013 and perplexity is 42.54379230973312
At time: 1099.3826305866241 and batch: 1350, loss is 3.7253674030303956 and perplexity is 41.486472200755166
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.346356201171875 and perplexity of 77.19666071991858
Finished 37 epochs...
Completing Train Step...
At time: 1102.4518280029297 and batch: 50, loss is 3.935025315284729 and perplexity is 51.16344515744499
At time: 1103.4978396892548 and batch: 100, loss is 3.9321715593338014 and perplexity is 51.01764530889823
At time: 1104.5187582969666 and batch: 150, loss is 3.9146071529388426 and perplexity is 50.1293744648906
At time: 1105.5393850803375 and batch: 200, loss is 3.907401542663574 and perplexity is 49.76945998813278
At time: 1106.5611340999603 and batch: 250, loss is 3.895245213508606 and perplexity is 49.168108568987485
At time: 1107.5826494693756 and batch: 300, loss is 3.900423216819763 and perplexity is 49.42336147785083
At time: 1108.6035170555115 and batch: 350, loss is 3.8983491706848143 and perplexity is 49.32096137397895
At time: 1109.626413345337 and batch: 400, loss is 3.90293035030365 and perplexity is 49.547427902855176
At time: 1110.647140264511 and batch: 450, loss is 3.8466440868377685 and perplexity is 46.83562291791701
At time: 1111.6680946350098 and batch: 500, loss is 3.920550866127014 and perplexity is 50.42821632437997
At time: 1112.6902883052826 and batch: 550, loss is 3.914386510848999 and perplexity is 50.11831503507884
At time: 1113.7143239974976 and batch: 600, loss is 3.8496920251846314 and perplexity is 46.97859277998863
At time: 1114.7386870384216 and batch: 650, loss is 3.863814754486084 and perplexity is 47.646765836748486
At time: 1115.76047873497 and batch: 700, loss is 3.884951014518738 and perplexity is 48.664558544281576
At time: 1116.782511472702 and batch: 750, loss is 3.84330988407135 and perplexity is 46.6797234989807
At time: 1117.8027110099792 and batch: 800, loss is 3.8135211753845213 and perplexity is 45.30970171190691
At time: 1118.8235776424408 and batch: 850, loss is 3.7812837839126585 and perplexity is 43.87232818716052
At time: 1119.870352268219 and batch: 900, loss is 3.813245024681091 and perplexity is 45.29719113338899
At time: 1120.8900227546692 and batch: 950, loss is 3.793087296485901 and perplexity is 44.39324403496946
At time: 1121.9105746746063 and batch: 1000, loss is 3.8048536729812623 and perplexity is 44.91867681603555
At time: 1122.9325473308563 and batch: 1050, loss is 3.7511283206939696 and perplexity is 42.569086493952454
At time: 1123.9534797668457 and batch: 1100, loss is 3.7133501625061034 and perplexity is 40.99090293724915
At time: 1124.9751255512238 and batch: 1150, loss is 3.7295508050918578 and perplexity is 41.660390325159796
At time: 1125.9975299835205 and batch: 1200, loss is 3.6999560499191286 and perplexity is 40.445526736833365
At time: 1127.018432855606 and batch: 1250, loss is 3.75532826423645 and perplexity is 42.74825022930516
At time: 1128.0386974811554 and batch: 1300, loss is 3.7506579256057737 and perplexity is 42.549066913681976
At time: 1129.0596053600311 and batch: 1350, loss is 3.7254883670806884 and perplexity is 41.49149087599845
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.346271565755209 and perplexity of 77.19012742485128
Finished 38 epochs...
Completing Train Step...
At time: 1132.1221029758453 and batch: 50, loss is 3.9348431539535524 and perplexity is 51.15412600498791
At time: 1133.168791294098 and batch: 100, loss is 3.9319151782989503 and perplexity is 51.00456702878141
At time: 1134.1884951591492 and batch: 150, loss is 3.914322566986084 and perplexity is 50.11511037887285
At time: 1135.2083158493042 and batch: 200, loss is 3.9071098375320434 and perplexity is 49.7549440985434
At time: 1136.2296965122223 and batch: 250, loss is 3.8949173736572265 and perplexity is 49.15199194556168
At time: 1137.2495646476746 and batch: 300, loss is 3.9000952005386353 and perplexity is 49.40715246917275
At time: 1138.2688527107239 and batch: 350, loss is 3.89804669380188 and perplexity is 49.30604517933497
At time: 1139.29012966156 and batch: 400, loss is 3.9026535511016847 and perplexity is 49.533715112284526
At time: 1140.3104856014252 and batch: 450, loss is 3.8464165258407594 and perplexity is 46.824966169446405
At time: 1141.3310339450836 and batch: 500, loss is 3.9203376531600953 and perplexity is 50.4174655209071
At time: 1142.353315114975 and batch: 550, loss is 3.9141820955276487 and perplexity is 50.108071130646586
At time: 1143.3739159107208 and batch: 600, loss is 3.8494956588745115 and perplexity is 46.96936867275139
At time: 1144.394461631775 and batch: 650, loss is 3.8636493492126465 and perplexity is 47.63888546216258
At time: 1145.4161298274994 and batch: 700, loss is 3.8848413038253784 and perplexity is 48.65921981468487
At time: 1146.4620249271393 and batch: 750, loss is 3.8432216310501097 and perplexity is 46.67560405413066
At time: 1147.4820568561554 and batch: 800, loss is 3.813437647819519 and perplexity is 45.305917260907115
At time: 1148.503136396408 and batch: 850, loss is 3.781245970726013 and perplexity is 43.870669265990955
At time: 1149.5265047550201 and batch: 900, loss is 3.8132504272460936 and perplexity is 45.29743585506958
At time: 1150.5461831092834 and batch: 950, loss is 3.793100428581238 and perplexity is 44.39382701511031
At time: 1151.5659277439117 and batch: 1000, loss is 3.8048996114730835 and perplexity is 44.920740359700766
At time: 1152.5887076854706 and batch: 1050, loss is 3.751192922592163 and perplexity is 42.57183662657527
At time: 1153.608383178711 and batch: 1100, loss is 3.7134439373016357 and perplexity is 40.994747031027515
At time: 1154.6287949085236 and batch: 1150, loss is 3.729652614593506 and perplexity is 41.66463196465321
At time: 1155.6500978469849 and batch: 1200, loss is 3.7000792360305788 and perplexity is 40.450509370886984
At time: 1156.6702392101288 and batch: 1250, loss is 3.755430669784546 and perplexity is 42.75262811145593
At time: 1157.6903505325317 and batch: 1300, loss is 3.7507391357421875 and perplexity is 42.5525224695215
At time: 1158.7129578590393 and batch: 1350, loss is 3.7255671930313112 and perplexity is 41.49476161111722
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.346219075520834 and perplexity of 77.18607580330753
Finished 39 epochs...
Completing Train Step...
At time: 1161.8133671283722 and batch: 50, loss is 3.934676752090454 and perplexity is 51.14561457129435
At time: 1162.8346228599548 and batch: 100, loss is 3.9316958713531496 and perplexity is 50.993382599420784
At time: 1163.856873512268 and batch: 150, loss is 3.9140835189819336 and perplexity is 50.10313189353254
At time: 1164.8817553520203 and batch: 200, loss is 3.906868314743042 and perplexity is 49.74292859674527
At time: 1165.9083144664764 and batch: 250, loss is 3.8946473455429076 and perplexity is 49.13872131766355
At time: 1166.92844748497 and batch: 300, loss is 3.8998289012908938 and perplexity is 49.393997133342914
At time: 1167.95117020607 and batch: 350, loss is 3.897800087928772 and perplexity is 49.29388751815097
At time: 1168.971551656723 and batch: 400, loss is 3.9024249267578126 and perplexity is 49.522391793609906
At time: 1169.9927151203156 and batch: 450, loss is 3.8462229681015017 and perplexity is 46.815903711936514
At time: 1171.0145463943481 and batch: 500, loss is 3.92015700340271 and perplexity is 50.40835844061345
At time: 1172.060043334961 and batch: 550, loss is 3.914012279510498 and perplexity is 50.09956270003441
At time: 1173.0807285308838 and batch: 600, loss is 3.849334673881531 and perplexity is 46.96180791786567
At time: 1174.1035380363464 and batch: 650, loss is 3.863508605957031 and perplexity is 47.63218108213795
At time: 1175.1306509971619 and batch: 700, loss is 3.884741535186768 and perplexity is 48.65436539273166
At time: 1176.151132106781 and batch: 750, loss is 3.843138165473938 and perplexity is 46.671708410523436
At time: 1177.1825325489044 and batch: 800, loss is 3.8133577871322633 and perplexity is 45.30229924368851
At time: 1178.2027215957642 and batch: 850, loss is 3.781201515197754 and perplexity is 43.868719015563684
At time: 1179.2225909233093 and batch: 900, loss is 3.813239212036133 and perplexity is 45.29692783766455
At time: 1180.243225812912 and batch: 950, loss is 3.793096899986267 and perplexity is 44.39367036755194
At time: 1181.2663657665253 and batch: 1000, loss is 3.804922161102295 and perplexity is 44.92175331716064
At time: 1182.286788702011 and batch: 1050, loss is 3.7512277269363405 and perplexity is 42.57331833721432
At time: 1183.3095259666443 and batch: 1100, loss is 3.7135036516189577 and perplexity is 40.997195077451245
At time: 1184.3302166461945 and batch: 1150, loss is 3.7297186756134035 and perplexity is 41.66738446364989
At time: 1185.350986480713 and batch: 1200, loss is 3.7001621389389037 and perplexity is 40.45386297476689
At time: 1186.3733749389648 and batch: 1250, loss is 3.7555037117004395 and perplexity is 42.75575095937067
At time: 1187.3943836688995 and batch: 1300, loss is 3.7507935333251954 and perplexity is 42.55483728685439
At time: 1188.4147775173187 and batch: 1350, loss is 3.725619897842407 and perplexity is 41.49694864232243
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.34619140625 and perplexity of 77.18394015041765
Finished 40 epochs...
Completing Train Step...
At time: 1191.5064811706543 and batch: 50, loss is 3.934520196914673 and perplexity is 51.137608087359325
At time: 1192.5353288650513 and batch: 100, loss is 3.9314995908737185 and perplexity is 50.9833745760583
At time: 1193.5572080612183 and batch: 150, loss is 3.9138718461990356 and perplexity is 50.09252754653815
At time: 1194.5797650814056 and batch: 200, loss is 3.906657614707947 and perplexity is 49.73244886402299
At time: 1195.6013133525848 and batch: 250, loss is 3.894413471221924 and perplexity is 49.127230376351804
At time: 1196.6224071979523 and batch: 300, loss is 3.8996012830734252 and perplexity is 49.382755439217505
At time: 1197.6693155765533 and batch: 350, loss is 3.89758816242218 and perplexity is 49.2834419929425
At time: 1198.6924121379852 and batch: 400, loss is 3.902227005958557 and perplexity is 49.51259125214256
At time: 1199.7136580944061 and batch: 450, loss is 3.846050796508789 and perplexity is 46.807844037073586
At time: 1200.7371463775635 and batch: 500, loss is 3.9199960708618162 and perplexity is 50.40024674814247
At time: 1201.7585439682007 and batch: 550, loss is 3.913863558769226 and perplexity is 50.092112409952335
At time: 1202.7805676460266 and batch: 600, loss is 3.849194507598877 and perplexity is 46.95522591712118
At time: 1203.8035199642181 and batch: 650, loss is 3.8633826923370362 and perplexity is 47.626183919359804
At time: 1204.8269171714783 and batch: 700, loss is 3.8846472978591917 and perplexity is 48.649780551397136
At time: 1205.8484110832214 and batch: 750, loss is 3.8430575037002566 and perplexity is 46.6679439395688
At time: 1206.8713376522064 and batch: 800, loss is 3.8132803726196287 and perplexity is 45.298792324016325
At time: 1207.8932700157166 and batch: 850, loss is 3.7811527824401856 and perplexity is 43.86658122400572
At time: 1208.9144122600555 and batch: 900, loss is 3.8132169151306154 and perplexity is 45.29591786760396
At time: 1209.9374063014984 and batch: 950, loss is 3.7930822134017945 and perplexity is 44.39301838094978
At time: 1210.9592535495758 and batch: 1000, loss is 3.8049286365509034 and perplexity is 44.92204420660747
At time: 1211.9852950572968 and batch: 1050, loss is 3.751242923736572 and perplexity is 42.57396532034431
At time: 1213.0117213726044 and batch: 1100, loss is 3.7135403680801393 and perplexity is 40.99870037700733
At time: 1214.033209323883 and batch: 1150, loss is 3.72976101398468 and perplexity is 41.669148630189135
At time: 1215.0558381080627 and batch: 1200, loss is 3.70021842956543 and perplexity is 40.45614021215211
At time: 1216.081706047058 and batch: 1250, loss is 3.7555563688278197 and perplexity is 42.758002413672216
At time: 1217.109784603119 and batch: 1300, loss is 3.750830025672913 and perplexity is 42.55639024110902
At time: 1218.1339468955994 and batch: 1350, loss is 3.725655164718628 and perplexity is 41.49841213588
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.346173095703125 and perplexity of 77.18252688320241
Finished 41 epochs...
Completing Train Step...
At time: 1221.2134764194489 and batch: 50, loss is 3.9343702030181884 and perplexity is 51.129938333487914
At time: 1222.2611756324768 and batch: 100, loss is 3.9313180160522463 and perplexity is 50.97411811931678
At time: 1223.2839558124542 and batch: 150, loss is 3.913678011894226 and perplexity is 50.082818837255864
At time: 1224.3308284282684 and batch: 200, loss is 3.90646710395813 and perplexity is 49.72297520034571
At time: 1225.352209329605 and batch: 250, loss is 3.8942037200927735 and perplexity is 49.1169269649222
At time: 1226.3749251365662 and batch: 300, loss is 3.89939893245697 and perplexity is 49.37276381915145
At time: 1227.3978161811829 and batch: 350, loss is 3.8973993062973022 and perplexity is 49.274135391899044
At time: 1228.4208221435547 and batch: 400, loss is 3.9020496082305907 and perplexity is 49.503808609982116
At time: 1229.4424726963043 and batch: 450, loss is 3.8458932399749757 and perplexity is 46.80046973636171
At time: 1230.464201927185 and batch: 500, loss is 3.9198482275009154 and perplexity is 50.392795957061566
At time: 1231.4858481884003 and batch: 550, loss is 3.913728127479553 and perplexity is 50.08532882993107
At time: 1232.5088920593262 and batch: 600, loss is 3.8490673542022704 and perplexity is 46.94925578022703
At time: 1233.531047821045 and batch: 650, loss is 3.8632665395736696 and perplexity is 47.62065232775001
At time: 1234.5548164844513 and batch: 700, loss is 3.884556436538696 and perplexity is 48.645360368909266
At time: 1235.5858631134033 and batch: 750, loss is 3.842978472709656 and perplexity is 46.66425587146772
At time: 1236.6074483394623 and batch: 800, loss is 3.813204779624939 and perplexity is 45.29536818207093
At time: 1237.6287302970886 and batch: 850, loss is 3.7811015605926515 and perplexity is 43.86433435421532
At time: 1238.6514346599579 and batch: 900, loss is 3.813187417984009 and perplexity is 45.29458178697932
At time: 1239.672583580017 and batch: 950, loss is 3.793059983253479 and perplexity is 44.39203152853598
At time: 1240.6952664852142 and batch: 1000, loss is 3.80492356300354 and perplexity is 44.921816293066684
At time: 1241.7171375751495 and batch: 1050, loss is 3.751244902610779 and perplexity is 42.57404956894951
At time: 1242.7382020950317 and batch: 1100, loss is 3.713561086654663 and perplexity is 40.99954982043606
At time: 1243.7605452537537 and batch: 1150, loss is 3.729786982536316 and perplexity is 41.670230731677215
At time: 1244.7831161022186 and batch: 1200, loss is 3.700256447792053 and perplexity is 40.457678312096725
At time: 1245.8041410446167 and batch: 1250, loss is 3.755594449043274 and perplexity is 42.75963067861866
At time: 1246.8258435726166 and batch: 1300, loss is 3.7508542680740358 and perplexity is 42.55742192269676
At time: 1247.8492724895477 and batch: 1350, loss is 3.7256781339645384 and perplexity is 41.49936533406033
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.346162923177084 and perplexity of 77.18174174593119
Finished 42 epochs...
Completing Train Step...
At time: 1250.9129102230072 and batch: 50, loss is 3.9342246723175047 and perplexity is 51.12249789915527
At time: 1251.9601147174835 and batch: 100, loss is 3.931147270202637 and perplexity is 50.965415243221535
At time: 1252.9805302619934 and batch: 150, loss is 3.913496527671814 and perplexity is 50.073730420550056
At time: 1254.002379655838 and batch: 200, loss is 3.90629035949707 and perplexity is 49.71418771648407
At time: 1255.0250360965729 and batch: 250, loss is 3.8940107011795044 and perplexity is 49.107447383954955
At time: 1256.045414686203 and batch: 300, loss is 3.8992139005661013 and perplexity is 49.36362912843519
At time: 1257.0678312778473 and batch: 350, loss is 3.897225923538208 and perplexity is 49.265592846939214
At time: 1258.088297367096 and batch: 400, loss is 3.9018862438201904 and perplexity is 49.49572211001711
At time: 1259.1087267398834 and batch: 450, loss is 3.845745782852173 and perplexity is 46.79356918252898
At time: 1260.1304895877838 and batch: 500, loss is 3.919709358215332 and perplexity is 50.38579843137041
At time: 1261.15251994133 and batch: 550, loss is 3.913602018356323 and perplexity is 50.079013011275194
At time: 1262.1733498573303 and batch: 600, loss is 3.8489488315582276 and perplexity is 46.94369156004567
At time: 1263.1959674358368 and batch: 650, loss is 3.863157005310059 and perplexity is 47.61543652032465
At time: 1264.216400384903 and batch: 700, loss is 3.8844677305221555 and perplexity is 48.641045424151365
At time: 1265.237389087677 and batch: 750, loss is 3.842900719642639 and perplexity is 46.6606277235053
At time: 1266.2598073482513 and batch: 800, loss is 3.813130440711975 and perplexity is 45.29200109879218
At time: 1267.28023147583 and batch: 850, loss is 3.7810486650466917 and perplexity is 43.862014187665274
At time: 1268.3006789684296 and batch: 900, loss is 3.813152761459351 and perplexity is 45.29301206138952
At time: 1269.323647260666 and batch: 950, loss is 3.793031959533691 and perplexity is 44.39078751611462
At time: 1270.344199180603 and batch: 1000, loss is 3.804909973144531 and perplexity is 44.921205816065
At time: 1271.3651525974274 and batch: 1050, loss is 3.751237277984619 and perplexity is 42.57372495897496
At time: 1272.3868927955627 and batch: 1100, loss is 3.7135700035095214 and perplexity is 40.99991540910102
At time: 1273.4077892303467 and batch: 1150, loss is 3.7298012351989747 and perplexity is 41.67082464765117
At time: 1274.428966999054 and batch: 1200, loss is 3.700281858444214 and perplexity is 40.45870638114944
At time: 1275.4933466911316 and batch: 1250, loss is 3.755621953010559 and perplexity is 42.760806754275265
At time: 1276.5141417980194 and batch: 1300, loss is 3.750869393348694 and perplexity is 42.558065620260116
At time: 1277.5359497070312 and batch: 1350, loss is 3.7256922817230222 and perplexity is 41.49995246121157
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.346157633463542 and perplexity of 77.18133347770652
Finished 43 epochs...
Completing Train Step...
At time: 1280.6264550685883 and batch: 50, loss is 3.934082760810852 and perplexity is 51.115243543205025
At time: 1281.6473107337952 and batch: 100, loss is 3.9309840965270997 and perplexity is 50.95709970754773
At time: 1282.6694688796997 and batch: 150, loss is 3.9133239793777466 and perplexity is 50.06509102916595
At time: 1283.6908295154572 and batch: 200, loss is 3.906123661994934 and perplexity is 49.70590117626297
At time: 1284.7114672660828 and batch: 250, loss is 3.8938300943374635 and perplexity is 49.098579043827804
At time: 1285.733838558197 and batch: 300, loss is 3.8990414190292357 and perplexity is 49.35511554805668
At time: 1286.754863023758 and batch: 350, loss is 3.8970640802383425 and perplexity is 49.25762018600132
At time: 1287.7748885154724 and batch: 400, loss is 3.90173282623291 and perplexity is 49.48812917820983
At time: 1288.7958319187164 and batch: 450, loss is 3.8456057691574097 and perplexity is 46.78701790066187
At time: 1289.8174414634705 and batch: 500, loss is 3.9195768642425537 and perplexity is 50.37912305899769
At time: 1290.8378944396973 and batch: 550, loss is 3.9134820985794065 and perplexity is 50.07300790727924
At time: 1291.8580286502838 and batch: 600, loss is 3.8488365411758423 and perplexity is 46.93842053091829
At time: 1292.879329442978 and batch: 650, loss is 3.8630518198013304 and perplexity is 47.610428329810084
At time: 1293.9025139808655 and batch: 700, loss is 3.8843804597854614 and perplexity is 48.63680066950776
At time: 1294.9228904247284 and batch: 750, loss is 3.842823781967163 and perplexity is 46.65703790137006
At time: 1295.9455780982971 and batch: 800, loss is 3.813057293891907 and perplexity is 45.288688254100784
At time: 1296.967389345169 and batch: 850, loss is 3.7809945344924927 and perplexity is 43.859639976788266
At time: 1297.9884536266327 and batch: 900, loss is 3.813114256858826 and perplexity is 45.2912681056289
At time: 1299.0090646743774 and batch: 950, loss is 3.7929995346069334 and perplexity is 44.38934817141614
At time: 1300.0309553146362 and batch: 1000, loss is 3.8048902702331544 and perplexity is 44.92032074624713
At time: 1301.059336900711 and batch: 1050, loss is 3.7512225246429445 and perplexity is 42.57309685889758
At time: 1302.1059756278992 and batch: 1100, loss is 3.7135703134536744 and perplexity is 40.999928116787046
At time: 1303.1270241737366 and batch: 1150, loss is 3.729806866645813 and perplexity is 41.67105931534564
At time: 1304.148166179657 and batch: 1200, loss is 3.7002978515625 and perplexity is 40.459353447200584
At time: 1305.1689848899841 and batch: 1250, loss is 3.755641431808472 and perplexity is 42.7616396915009
At time: 1306.1914627552032 and batch: 1300, loss is 3.750878005027771 and perplexity is 42.558432118241456
At time: 1307.2120373249054 and batch: 1350, loss is 3.725699954032898 and perplexity is 41.50027086292812
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.3461531575520835 and perplexity of 77.18098802166475
Finished 44 epochs...
Completing Train Step...
At time: 1310.3243839740753 and batch: 50, loss is 3.9339433813095095 and perplexity is 51.10811962252475
At time: 1311.3468191623688 and batch: 100, loss is 3.930826678276062 and perplexity is 50.94907876137204
At time: 1312.3681621551514 and batch: 150, loss is 3.9131582736968995 and perplexity is 50.05679564648529
At time: 1313.3886439800262 and batch: 200, loss is 3.9059645652771 and perplexity is 49.69799375956754
At time: 1314.4110879898071 and batch: 250, loss is 3.893658661842346 and perplexity is 49.09016267335591
At time: 1315.431207895279 and batch: 300, loss is 3.898878226280212 and perplexity is 49.34706180824586
At time: 1316.4524703025818 and batch: 350, loss is 3.89691029548645 and perplexity is 49.250045697537544
At time: 1317.4744193553925 and batch: 400, loss is 3.9015868377685545 and perplexity is 49.48090500956275
At time: 1318.4947192668915 and batch: 450, loss is 3.8454711771011354 and perplexity is 46.78072116347059
At time: 1319.5166952610016 and batch: 500, loss is 3.9194493532180785 and perplexity is 50.3726995749455
At time: 1320.5373113155365 and batch: 550, loss is 3.913366980552673 and perplexity is 50.06724393319138
At time: 1321.557790517807 and batch: 600, loss is 3.848728394508362 and perplexity is 46.93334457164006
At time: 1322.5799701213837 and batch: 650, loss is 3.8629501485824584 and perplexity is 47.60558796559781
At time: 1323.6008512973785 and batch: 700, loss is 3.8842944049835206 and perplexity is 48.63261541934212
At time: 1324.620744228363 and batch: 750, loss is 3.842747378349304 and perplexity is 46.65347327105287
At time: 1325.6414704322815 and batch: 800, loss is 3.812984809875488 and perplexity is 45.28540566704677
At time: 1326.6626691818237 and batch: 850, loss is 3.7809395360946656 and perplexity is 43.857227833192894
At time: 1327.7155084609985 and batch: 900, loss is 3.8130728101730345 and perplexity is 45.28939097157139
At time: 1328.7352285385132 and batch: 950, loss is 3.7929641342163087 and perplexity is 44.387776798965064
At time: 1329.75581741333 and batch: 1000, loss is 3.8048657608032226 and perplexity is 44.91921978828526
At time: 1330.7775242328644 and batch: 1050, loss is 3.75120267868042 and perplexity is 42.57225196319668
At time: 1331.7975902557373 and batch: 1100, loss is 3.7135642671585085 and perplexity is 40.9996802198693
At time: 1332.817217350006 and batch: 1150, loss is 3.729805965423584 and perplexity is 41.6710217604776
At time: 1333.83997631073 and batch: 1200, loss is 3.700306730270386 and perplexity is 40.45971267557583
At time: 1334.8606297969818 and batch: 1250, loss is 3.755654802322388 and perplexity is 42.76221144042175
At time: 1335.8816146850586 and batch: 1300, loss is 3.750881543159485 and perplexity is 42.558582695846226
At time: 1336.9023990631104 and batch: 1350, loss is 3.7257024908065794 and perplexity is 41.50037613985655
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.346150309244791 and perplexity of 77.18076818680682
Finished 45 epochs...
Completing Train Step...
At time: 1340.0188314914703 and batch: 50, loss is 3.933806366920471 and perplexity is 51.10111755444276
At time: 1341.064528465271 and batch: 100, loss is 3.9306739664077757 and perplexity is 50.94129882642624
At time: 1342.0857994556427 and batch: 150, loss is 3.9129978370666505 and perplexity is 50.048765347065014
At time: 1343.1053915023804 and batch: 200, loss is 3.9058112859725953 and perplexity is 49.690376669434855
At time: 1344.1254444122314 and batch: 250, loss is 3.8934944009780885 and perplexity is 49.08209974303872
At time: 1345.1475768089294 and batch: 300, loss is 3.8987220191955565 and perplexity is 49.33935404960339
At time: 1346.1676788330078 and batch: 350, loss is 3.8967629146575926 and perplexity is 49.2427877198379
At time: 1347.1876826286316 and batch: 400, loss is 3.9014463901519774 and perplexity is 49.47395602238384
At time: 1348.209047794342 and batch: 450, loss is 3.8453409767150877 and perplexity is 46.77463069201498
At time: 1349.2292699813843 and batch: 500, loss is 3.9193255043029787 and perplexity is 50.36646135705872
At time: 1350.249219417572 and batch: 550, loss is 3.9132553243637087 and perplexity is 50.06165392762701
At time: 1351.2693405151367 and batch: 600, loss is 3.8486233377456665 and perplexity is 46.92841416538769
At time: 1352.2905802726746 and batch: 650, loss is 3.862850937843323 and perplexity is 47.60086521430646
At time: 1353.3363420963287 and batch: 700, loss is 3.8842090559005737 and perplexity is 48.62846484734106
At time: 1354.3590154647827 and batch: 750, loss is 3.842671666145325 and perplexity is 46.64994116748159
At time: 1355.386395931244 and batch: 800, loss is 3.812912998199463 and perplexity is 45.28215376293008
At time: 1356.407227754593 and batch: 850, loss is 3.7808838081359863 and perplexity is 43.854783827512776
At time: 1357.4296388626099 and batch: 900, loss is 3.8130291366577147 and perplexity is 45.28741306785229
At time: 1358.4506645202637 and batch: 950, loss is 3.792926173210144 and perplexity is 44.38609182627819
At time: 1359.4703826904297 and batch: 1000, loss is 3.8048375177383424 and perplexity is 44.91795114976162
At time: 1360.4905378818512 and batch: 1050, loss is 3.751178894042969 and perplexity is 42.57123940965992
At time: 1361.5160155296326 and batch: 1100, loss is 3.7135530376434325 and perplexity is 40.99921981592722
At time: 1362.5368242263794 and batch: 1150, loss is 3.729799847602844 and perplexity is 41.67076682541625
At time: 1363.5579476356506 and batch: 1200, loss is 3.7003103256225587 and perplexity is 40.45985814275322
At time: 1364.5784630775452 and batch: 1250, loss is 3.7556634092330934 and perplexity is 42.762579492541086
At time: 1365.5980179309845 and batch: 1300, loss is 3.750881004333496 and perplexity is 42.558559764181986
At time: 1366.6178874969482 and batch: 1350, loss is 3.725701107978821 and perplexity is 41.50031875202411
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.346149495442709 and perplexity of 77.18070537696248
Finished 46 epochs...
Completing Train Step...
At time: 1369.705008983612 and batch: 50, loss is 3.9336709928512574 and perplexity is 51.094200256440004
At time: 1370.7572357654572 and batch: 100, loss is 3.9305250310897826 and perplexity is 50.93371243284154
At time: 1371.7788808345795 and batch: 150, loss is 3.9128416109085085 and perplexity is 50.0409470314637
At time: 1372.8002500534058 and batch: 200, loss is 3.9056625890731813 and perplexity is 49.68298841381236
At time: 1373.8220038414001 and batch: 250, loss is 3.8933356332778932 and perplexity is 49.07430770951975
At time: 1374.8438096046448 and batch: 300, loss is 3.898571171760559 and perplexity is 49.33191189592959
At time: 1375.8643898963928 and batch: 350, loss is 3.896620593070984 and perplexity is 49.23577990685393
At time: 1376.8851556777954 and batch: 400, loss is 3.9013105058670043 and perplexity is 49.467233745981154
At time: 1377.9080066680908 and batch: 450, loss is 3.845214343070984 and perplexity is 46.768707825103874
At time: 1378.928825378418 and batch: 500, loss is 3.919204568862915 and perplexity is 50.36037063518955
At time: 1379.9751062393188 and batch: 550, loss is 3.913146481513977 and perplexity is 50.05620537107483
At time: 1380.997360944748 and batch: 600, loss is 3.848520727157593 and perplexity is 46.92359906025744
At time: 1382.0228157043457 and batch: 650, loss is 3.8627536916732788 and perplexity is 47.596236437542636
At time: 1383.0477170944214 and batch: 700, loss is 3.884124364852905 and perplexity is 48.624346626097314
At time: 1384.0732834339142 and batch: 750, loss is 3.8425963640213014 and perplexity is 46.64642846008494
At time: 1385.1057476997375 and batch: 800, loss is 3.8128415155410766 and perplexity is 45.278916989889595
At time: 1386.126554965973 and batch: 850, loss is 3.780827350616455 and perplexity is 43.85230796508947
At time: 1387.147010564804 and batch: 900, loss is 3.8129838371276854 and perplexity is 45.285361615789334
At time: 1388.1699340343475 and batch: 950, loss is 3.792886209487915 and perplexity is 44.38431802827764
At time: 1389.1973695755005 and batch: 1000, loss is 3.804806323051453 and perplexity is 44.91654997019457
At time: 1390.227331161499 and batch: 1050, loss is 3.7511517238616943 and perplexity is 42.57008275708137
At time: 1391.2533466815948 and batch: 1100, loss is 3.713537950515747 and perplexity is 40.998601260128986
At time: 1392.2746160030365 and batch: 1150, loss is 3.729789719581604 and perplexity is 41.670344785141964
At time: 1393.2953503131866 and batch: 1200, loss is 3.700309648513794 and perplexity is 40.45983074703793
At time: 1394.3187170028687 and batch: 1250, loss is 3.7556680488586425 and perplexity is 42.7627778953577
At time: 1395.350014448166 and batch: 1300, loss is 3.750877232551575 and perplexity is 42.55839924287841
At time: 1396.3717370033264 and batch: 1350, loss is 3.725696544647217 and perplexity is 41.50012937274007
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.346150716145833 and perplexity of 77.18079959174818
Annealing...
Finished 47 epochs...
Completing Train Step...
At time: 1399.485873222351 and batch: 50, loss is 3.9337173891067505 and perplexity is 51.096570891003175
At time: 1400.5070509910583 and batch: 100, loss is 3.9307812881469726 and perplexity is 50.946766228593546
At time: 1401.530932188034 and batch: 150, loss is 3.913153429031372 and perplexity is 50.05655313864044
At time: 1402.5529198646545 and batch: 200, loss is 3.9061981773376466 and perplexity is 49.7096051665243
At time: 1403.5763914585114 and batch: 250, loss is 3.8938620901107788 and perplexity is 49.10015001596509
At time: 1404.6070837974548 and batch: 300, loss is 3.8990819025039674 and perplexity is 49.35711365507473
At time: 1405.6535449028015 and batch: 350, loss is 3.897201852798462 and perplexity is 49.264407001947504
At time: 1406.6839089393616 and batch: 400, loss is 3.901855425834656 and perplexity is 49.4941967750731
At time: 1407.706554889679 and batch: 450, loss is 3.8454572486877443 and perplexity is 46.78006958678521
At time: 1408.7287192344666 and batch: 500, loss is 3.9193189668655397 and perplexity is 50.36613209054486
At time: 1409.7519192695618 and batch: 550, loss is 3.9132878398895263 and perplexity is 50.06328173509213
At time: 1410.773952960968 and batch: 600, loss is 3.8486013221740722 and perplexity is 46.92738102089851
At time: 1411.79612159729 and batch: 650, loss is 3.862784972190857 and perplexity is 47.59772529573919
At time: 1412.81906747818 and batch: 700, loss is 3.8839263248443605 and perplexity is 48.61471801353273
At time: 1413.8430581092834 and batch: 750, loss is 3.8424287700653075 and perplexity is 46.638611455665966
At time: 1414.8711321353912 and batch: 800, loss is 3.812645616531372 and perplexity is 45.27004776365546
At time: 1415.8961172103882 and batch: 850, loss is 3.780402326583862 and perplexity is 43.83367364061803
At time: 1416.9217228889465 and batch: 900, loss is 3.8123201179504393 and perplexity is 45.255314825254985
At time: 1417.9446375370026 and batch: 950, loss is 3.792252016067505 and perplexity is 44.356178709643224
At time: 1418.9684798717499 and batch: 1000, loss is 3.804099607467651 and perplexity is 44.88481795843435
At time: 1419.9902772903442 and batch: 1050, loss is 3.750344657897949 and perplexity is 42.53573975261344
At time: 1421.0139713287354 and batch: 1100, loss is 3.7127132654190063 and perplexity is 40.96480426253811
At time: 1422.0360820293427 and batch: 1150, loss is 3.728971982002258 and perplexity is 41.63628330684033
At time: 1423.0578274726868 and batch: 1200, loss is 3.6994713497161866 and perplexity is 40.4259275320689
At time: 1424.0802547931671 and batch: 1250, loss is 3.754742827415466 and perplexity is 42.72323115384687
At time: 1425.1028068065643 and batch: 1300, loss is 3.749973359107971 and perplexity is 42.51994921559753
At time: 1426.1243438720703 and batch: 1350, loss is 3.724934072494507 and perplexity is 41.46849874003021
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.346137288411458 and perplexity of 77.17976323543039
Finished 48 epochs...
Completing Train Step...
At time: 1429.259658575058 and batch: 50, loss is 3.933627362251282 and perplexity is 51.09197103445904
At time: 1430.282583475113 and batch: 100, loss is 3.9306485414505006 and perplexity is 50.940003662544854
At time: 1431.3294870853424 and batch: 150, loss is 3.913017921447754 and perplexity is 50.04977055563647
At time: 1432.3520534038544 and batch: 200, loss is 3.906055226325989 and perplexity is 49.70249963606012
At time: 1433.3751821517944 and batch: 250, loss is 3.8937084531784056 and perplexity is 49.09260699899541
At time: 1434.396835565567 and batch: 300, loss is 3.8989276361465453 and perplexity is 49.349500100211074
At time: 1435.4190821647644 and batch: 350, loss is 3.8970570373535156 and perplexity is 49.257273271477146
At time: 1436.4419906139374 and batch: 400, loss is 3.901722798347473 and perplexity is 49.48763291940815
At time: 1437.4638044834137 and batch: 450, loss is 3.845357503890991 and perplexity is 46.77540375095247
At time: 1438.4944112300873 and batch: 500, loss is 3.9192181253433227 and perplexity is 50.361053349194975
At time: 1439.5154173374176 and batch: 550, loss is 3.913189005851746 and perplexity is 50.0583340233189
At time: 1440.536339044571 and batch: 600, loss is 3.848507561683655 and perplexity is 46.922981292903536
At time: 1441.5589101314545 and batch: 650, loss is 3.862713623046875 and perplexity is 47.59432935993383
At time: 1442.5811069011688 and batch: 700, loss is 3.8838803005218505 and perplexity is 48.61248060556013
At time: 1443.6024098396301 and batch: 750, loss is 3.842391152381897 and perplexity is 46.63685705214403
At time: 1444.6261413097382 and batch: 800, loss is 3.8126215076446535 and perplexity is 45.268956366358424
At time: 1445.647786140442 and batch: 850, loss is 3.780401797294617 and perplexity is 43.833650439932136
At time: 1446.669438123703 and batch: 900, loss is 3.812338104248047 and perplexity is 45.25612880813601
At time: 1447.6917316913605 and batch: 950, loss is 3.792276301383972 and perplexity is 44.35725592656068
At time: 1448.713371038437 and batch: 1000, loss is 3.8041272068023684 and perplexity is 44.88605676664396
At time: 1449.7370495796204 and batch: 1050, loss is 3.750392813682556 and perplexity is 42.537788143855614
At time: 1450.758292913437 and batch: 1100, loss is 3.712763066291809 and perplexity is 40.966844396344385
At time: 1451.7800250053406 and batch: 1150, loss is 3.7290300273895265 and perplexity is 41.63870017117252
At time: 1452.8031656742096 and batch: 1200, loss is 3.6995372915267946 and perplexity is 40.42859337882028
At time: 1453.825210571289 and batch: 1250, loss is 3.754786195755005 and perplexity is 42.725084029619524
At time: 1454.84858751297 and batch: 1300, loss is 3.750007996559143 and perplexity is 42.521422023769325
At time: 1455.8702547550201 and batch: 1350, loss is 3.7249684000015257 and perplexity is 41.46992227464483
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.346116129557291 and perplexity of 77.17813021735194
Finished 49 epochs...
Completing Train Step...
At time: 1458.9769551753998 and batch: 50, loss is 3.9335493659973144 and perplexity is 51.08798620751335
At time: 1460.0225422382355 and batch: 100, loss is 3.9305393409729006 and perplexity is 50.93444129352816
At time: 1461.043880224228 and batch: 150, loss is 3.912900800704956 and perplexity is 50.0439090325918
At time: 1462.0705444812775 and batch: 200, loss is 3.905932831764221 and perplexity is 49.696416692665586
At time: 1463.0935354232788 and batch: 250, loss is 3.893576879501343 and perplexity is 49.0861481290939
At time: 1464.1250731945038 and batch: 300, loss is 3.8987987756729128 and perplexity is 49.3431413099618
At time: 1465.1448543071747 and batch: 350, loss is 3.896936159133911 and perplexity is 49.25131949982942
At time: 1466.1666893959045 and batch: 400, loss is 3.901612515449524 and perplexity is 49.482175580768256
At time: 1467.1869111061096 and batch: 450, loss is 3.8452700567245484 and perplexity is 46.77131355327594
At time: 1468.2077369689941 and batch: 500, loss is 3.9191326332092284 and perplexity is 50.35674805930575
At time: 1469.2286624908447 and batch: 550, loss is 3.9131064558029176 and perplexity is 50.05420187595785
At time: 1470.2504029273987 and batch: 600, loss is 3.848430051803589 and perplexity is 46.91934443919906
At time: 1471.2712800502777 and batch: 650, loss is 3.862651381492615 and perplexity is 47.59136710708908
At time: 1472.2936236858368 and batch: 700, loss is 3.8838405323028566 and perplexity is 48.61054741222566
At time: 1473.3145344257355 and batch: 750, loss is 3.8423598289489744 and perplexity is 46.635396248559246
At time: 1474.3365976810455 and batch: 800, loss is 3.812596173286438 and perplexity is 45.26780952092916
At time: 1475.3633115291595 and batch: 850, loss is 3.7803947067260744 and perplexity is 43.83333963553111
At time: 1476.3933610916138 and batch: 900, loss is 3.812347369194031 and perplexity is 45.256548105667235
At time: 1477.415733575821 and batch: 950, loss is 3.792290000915527 and perplexity is 44.357863604350385
At time: 1478.4358475208282 and batch: 1000, loss is 3.804146547317505 and perplexity is 44.88692489449927
At time: 1479.4562361240387 and batch: 1050, loss is 3.7504268503189087 and perplexity is 42.539236011722046
At time: 1480.4802951812744 and batch: 1100, loss is 3.712802224159241 and perplexity is 40.96844860201478
At time: 1481.507076740265 and batch: 1150, loss is 3.729075198173523 and perplexity is 41.64058106638428
At time: 1482.5351037979126 and batch: 1200, loss is 3.6995891523361206 and perplexity is 40.430690092761
At time: 1483.592899799347 and batch: 1250, loss is 3.754819655418396 and perplexity is 42.72651362046619
At time: 1484.6135380268097 and batch: 1300, loss is 3.750035343170166 and perplexity is 42.52258485645726
At time: 1485.6340279579163 and batch: 1350, loss is 3.7249947500228884 and perplexity is 41.47101502237957
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 151 batches
Done Evaluating: Achieved loss of 4.346095784505208 and perplexity of 77.17656004024572
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fec148f35c0>
Saving Model Parameters and Results...
/home-nfs/siddsach/Interpreting-Attention/interpreting_language/trained_models/langmodel/



RESULTS:
[{'best_accuracy': -158.40628669403355, 'params': {'wordvec_dim': 200, 'dropout': 0.8424821444842271, 'num_layers': 1, 'wordvec_source': 'glove', 'tune_wordvecs': True, 'batch_size': 80, 'seq_len': 20, 'lr': 14.231441702412651, 'data': 'wikitext', 'anneal': 5.252339304104469}}, {'best_accuracy': -115.47348473869167, 'params': {'wordvec_dim': 200, 'dropout': 0.0652534720959691, 'num_layers': 1, 'wordvec_source': 'glove', 'tune_wordvecs': True, 'batch_size': 80, 'seq_len': 20, 'lr': 13.283216954066178, 'data': 'wikitext', 'anneal': 4.474904618324195}}, {'best_accuracy': -76.98185485413308, 'params': {'wordvec_dim': 200, 'dropout': 0.11823445326580329, 'num_layers': 1, 'wordvec_source': 'glove', 'tune_wordvecs': True, 'batch_size': 80, 'seq_len': 20, 'lr': 4.326240833377234, 'data': 'wikitext', 'anneal': 2.4098571973066725}}, {'best_accuracy': -156.32615784490397, 'params': {'wordvec_dim': 200, 'dropout': 0.3924415681187886, 'num_layers': 1, 'wordvec_source': 'glove', 'tune_wordvecs': True, 'batch_size': 80, 'seq_len': 20, 'lr': 15.23571641651625, 'data': 'wikitext', 'anneal': 7.807467530615339}}, {'best_accuracy': -219.59860362866732, 'params': {'wordvec_dim': 200, 'dropout': 0.8802053241651955, 'num_layers': 1, 'wordvec_source': 'glove', 'tune_wordvecs': True, 'batch_size': 80, 'seq_len': 20, 'lr': 24.369477242781443, 'data': 'wikitext', 'anneal': 7.436080736383208}}, {'best_accuracy': -77.17656004024572, 'params': {'wordvec_dim': 200, 'dropout': 0.026111274635561753, 'num_layers': 1, 'wordvec_source': 'glove', 'tune_wordvecs': True, 'batch_size': 80, 'seq_len': 20, 'lr': 5.900792486470094, 'data': 'wikitext', 'anneal': 2.717571535734867}}]
