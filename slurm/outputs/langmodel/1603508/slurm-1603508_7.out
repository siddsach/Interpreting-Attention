Building Bayesian Optimizer for 
 data:ptb 
 choices:[{'domain': [0, 30], 'type': 'continuous', 'name': 'lr'}, {'domain': [0, 1], 'type': 'continuous', 'name': 'dropout'}, {'domain': [2, 8], 'type': 'continuous', 'name': 'anneal'}]
SETTINGS FOR THIS RUN
{'batch_size': 20, 'lr': 14.518175663874873, 'num_layers': 1, 'wordvec_source': '', 'seq_len': 35, 'anneal': 2.0074897365311104, 'wordvec_dim': 200, 'dropout': 0.4746396332197276, 'tune_wordvecs': True, 'data': 'ptb'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.9163773059844971 and batch: 50, loss is 6.445343608856201 and perplexity is 629.7630319442262
At time: 1.3230311870574951 and batch: 100, loss is 5.867642955780029 and perplexity is 353.41498302669993
At time: 1.7151968479156494 and batch: 150, loss is 5.73369029045105 and perplexity is 309.1078640098769
At time: 2.106417655944824 and batch: 200, loss is 5.652283849716187 and perplexity is 284.9414868000273
At time: 2.496929407119751 and batch: 250, loss is 5.616180410385132 and perplexity is 274.8376089634858
At time: 2.8878705501556396 and batch: 300, loss is 5.65548267364502 and perplexity is 285.8544238302624
At time: 3.2910313606262207 and batch: 350, loss is 5.667809762954712 and perplexity is 289.3999851703712
At time: 3.6947343349456787 and batch: 400, loss is 5.558509435653686 and perplexity is 259.4358421582732
At time: 4.100440502166748 and batch: 450, loss is 5.581359949111938 and perplexity is 265.4323349121469
At time: 4.513404369354248 and batch: 500, loss is 5.555355749130249 and perplexity is 258.6189516245439
At time: 4.9131178855896 and batch: 550, loss is 5.615008955001831 and perplexity is 274.5158374742011
At time: 5.304527997970581 and batch: 600, loss is 5.435862426757812 and perplexity is 229.4906818597026
At time: 5.6955273151397705 and batch: 650, loss is 5.6076203727722165 and perplexity is 272.4950292826165
At time: 6.085852861404419 and batch: 700, loss is 5.596101427078247 and perplexity is 269.3741827768155
At time: 6.476529598236084 and batch: 750, loss is 5.534242715835571 and perplexity is 253.2159585760911
At time: 6.867165803909302 and batch: 800, loss is 5.467201023101807 and perplexity is 236.79647646399025
At time: 7.257471799850464 and batch: 850, loss is 5.416907529830933 and perplexity is 225.1816770243753
At time: 7.648131370544434 and batch: 900, loss is 5.393125524520874 and perplexity is 219.88958291528533
At time: 8.05389142036438 and batch: 950, loss is 5.419095458984375 and perplexity is 225.67489794982345
At time: 8.455268144607544 and batch: 1000, loss is 5.469347763061523 and perplexity is 237.3053629503799
At time: 8.847873449325562 and batch: 1050, loss is 5.364821300506592 and perplexity is 213.7530337089564
At time: 9.238292932510376 and batch: 1100, loss is 5.453097896575928 and perplexity is 233.48034467284842
At time: 9.628603458404541 and batch: 1150, loss is 5.436767673492431 and perplexity is 229.6985216090155
At time: 10.020846366882324 and batch: 1200, loss is 5.39052713394165 and perplexity is 219.31896555900013
At time: 10.413536548614502 and batch: 1250, loss is 5.399519777297973 and perplexity is 221.30011734235762
At time: 10.806596994400024 and batch: 1300, loss is 5.480988645553589 and perplexity is 240.0839480091696
At time: 11.22561764717102 and batch: 1350, loss is 5.411603832244873 and perplexity is 223.9905430069594
At time: 11.639365196228027 and batch: 1400, loss is 5.292873287200928 and perplexity is 198.91414255949672
At time: 12.040010213851929 and batch: 1450, loss is 5.368700428009033 and perplexity is 214.5838193005863
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.209221733940972 and perplexity of 182.95161773809204
Finished 1 epochs...
Completing Train Step...
At time: 13.303678512573242 and batch: 50, loss is 5.19255859375 and perplexity is 179.92832798765482
At time: 13.703258752822876 and batch: 100, loss is 5.164516878128052 and perplexity is 174.9529145713237
At time: 14.088052034378052 and batch: 150, loss is 5.041835689544678 and perplexity is 154.7538344399054
At time: 14.489895820617676 and batch: 200, loss is 5.075478219985962 and perplexity is 160.04871217407415
At time: 14.873655080795288 and batch: 250, loss is 5.090142908096314 and perplexity is 162.41307053783657
At time: 15.25790286064148 and batch: 300, loss is 5.102439861297608 and perplexity is 164.42258660568032
At time: 15.642290592193604 and batch: 350, loss is 5.1342840576171875 and perplexity is 169.74275033234383
At time: 16.025784254074097 and batch: 400, loss is 4.996786212921142 and perplexity is 147.93695642639275
At time: 16.409799814224243 and batch: 450, loss is 5.052125577926636 and perplexity is 156.3544551039341
At time: 16.793628692626953 and batch: 500, loss is 5.015186767578125 and perplexity is 150.68427707547727
At time: 17.177562952041626 and batch: 550, loss is 5.088198223114014 and perplexity is 162.0975351865029
At time: 17.56130313873291 and batch: 600, loss is 4.961376495361328 and perplexity is 142.79021074664732
At time: 17.960590839385986 and batch: 650, loss is 5.086211490631103 and perplexity is 161.7758104442696
At time: 18.353208541870117 and batch: 700, loss is 5.099428405761719 and perplexity is 163.92818011224935
At time: 18.737224578857422 and batch: 750, loss is 5.043211088180542 and perplexity is 154.9668290953909
At time: 19.125800371170044 and batch: 800, loss is 4.964050207138062 and perplexity is 143.17250145456558
At time: 19.537551641464233 and batch: 850, loss is 4.932067813873291 and perplexity is 138.66595146469018
At time: 19.940866708755493 and batch: 900, loss is 4.892605247497559 and perplexity is 133.30040260831703
At time: 20.33438777923584 and batch: 950, loss is 4.955872735977173 and perplexity is 142.00648647752428
At time: 20.721775770187378 and batch: 1000, loss is 4.992645473480224 and perplexity is 147.3256545305181
At time: 21.105786561965942 and batch: 1050, loss is 4.9032603454589845 and perplexity is 134.72832527490786
At time: 21.490523099899292 and batch: 1100, loss is 5.029245615005493 and perplexity is 152.81768583156963
At time: 21.87464737892151 and batch: 1150, loss is 4.982369375228882 and perplexity is 145.8194737147839
At time: 22.258924961090088 and batch: 1200, loss is 4.932057752609253 and perplexity is 138.6645563169578
At time: 22.643173217773438 and batch: 1250, loss is 4.907852630615235 and perplexity is 135.3484589887816
At time: 23.02812385559082 and batch: 1300, loss is 5.007539253234864 and perplexity is 149.53631203961615
At time: 23.413159370422363 and batch: 1350, loss is 4.9657200336456295 and perplexity is 143.41177440921285
At time: 23.798450231552124 and batch: 1400, loss is 4.812742166519165 and perplexity is 123.06862991053492
At time: 24.18931269645691 and batch: 1450, loss is 4.91889651298523 and perplexity is 136.85151596407192
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.07955332698985 and perplexity of 160.70225853326474
Finished 2 epochs...
Completing Train Step...
At time: 25.53278160095215 and batch: 50, loss is 4.953599128723145 and perplexity is 141.68398625809382
At time: 25.919840097427368 and batch: 100, loss is 4.967520990371704 and perplexity is 143.67028552272552
At time: 26.30784583091736 and batch: 150, loss is 4.843864583969117 and perplexity is 126.95904878762562
At time: 26.696758031845093 and batch: 200, loss is 4.93687141418457 and perplexity is 139.33364966604978
At time: 27.084848642349243 and batch: 250, loss is 4.964233655929565 and perplexity is 143.19876868620622
At time: 27.47288155555725 and batch: 300, loss is 4.9620061874389645 and perplexity is 142.88015292608546
At time: 27.860524892807007 and batch: 350, loss is 4.985458326339722 and perplexity is 146.2705993338827
At time: 28.248880624771118 and batch: 400, loss is 4.855041227340698 and perplexity is 128.3859841183213
At time: 28.636136531829834 and batch: 450, loss is 4.902293472290039 and perplexity is 134.598123026776
At time: 29.024802207946777 and batch: 500, loss is 4.882091131210327 and perplexity is 131.9062088752723
At time: 29.41205072402954 and batch: 550, loss is 4.941238775253296 and perplexity is 139.94350077380753
At time: 29.80020570755005 and batch: 600, loss is 4.8372593688964844 and perplexity is 126.12322041689427
At time: 30.191251277923584 and batch: 650, loss is 4.9547910976409915 and perplexity is 141.85296985746163
At time: 30.579638481140137 and batch: 700, loss is 4.9777845191955565 and perplexity is 145.1524427099756
At time: 30.967411756515503 and batch: 750, loss is 4.941006965637207 and perplexity is 139.91106428430945
At time: 31.356099367141724 and batch: 800, loss is 4.860771627426147 and perplexity is 129.12379914132075
At time: 31.744791746139526 and batch: 850, loss is 4.823844947814941 and perplexity is 124.44264758691291
At time: 32.13290333747864 and batch: 900, loss is 4.771319551467895 and perplexity is 118.07494517610348
At time: 32.51978826522827 and batch: 950, loss is 4.858872327804566 and perplexity is 128.87878710775922
At time: 32.908123254776 and batch: 1000, loss is 4.894693250656128 and perplexity is 133.5790250510448
At time: 33.294684410095215 and batch: 1050, loss is 4.783031301498413 and perplexity is 119.4659390052707
At time: 33.75806403160095 and batch: 1100, loss is 4.943432302474975 and perplexity is 140.2508075719468
At time: 34.14567756652832 and batch: 1150, loss is 4.898045463562012 and perplexity is 134.02756175801562
At time: 34.53333592414856 and batch: 1200, loss is 4.8504870510101314 and perplexity is 127.8026210856018
At time: 34.92077302932739 and batch: 1250, loss is 4.814165487289428 and perplexity is 123.2439207656193
At time: 35.30960822105408 and batch: 1300, loss is 4.916862812042236 and perplexity is 136.5734837200512
At time: 35.697107791900635 and batch: 1350, loss is 4.884027080535889 and perplexity is 132.16181995659832
At time: 36.08525800704956 and batch: 1400, loss is 4.732205095291138 and perplexity is 113.5456655090096
At time: 36.47291851043701 and batch: 1450, loss is 4.824107265472412 and perplexity is 124.47529537257543
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.061028374565972 and perplexity of 157.75266176102457
Finished 3 epochs...
Completing Train Step...
At time: 37.76919460296631 and batch: 50, loss is 4.87974365234375 and perplexity is 131.5969249982796
At time: 38.170217752456665 and batch: 100, loss is 4.917676248550415 and perplexity is 136.684622773912
At time: 38.55725169181824 and batch: 150, loss is 4.794453229904175 and perplexity is 120.83829295198584
At time: 38.94519805908203 and batch: 200, loss is 4.866711950302124 and perplexity is 129.89311894091958
At time: 39.332783460617065 and batch: 250, loss is 4.909491701126099 and perplexity is 135.57048656632105
At time: 39.725513219833374 and batch: 300, loss is 4.9056297969818115 and perplexity is 135.04793601193967
At time: 40.12223815917969 and batch: 350, loss is 4.915209980010986 and perplexity is 136.3479371381935
At time: 40.52770018577576 and batch: 400, loss is 4.793799924850464 and perplexity is 120.75937446624819
At time: 40.93252086639404 and batch: 450, loss is 4.846260061264038 and perplexity is 127.26354086270155
At time: 41.33621692657471 and batch: 500, loss is 4.828773078918457 and perplexity is 125.05743089120882
At time: 41.72968292236328 and batch: 550, loss is 4.887288570404053 and perplexity is 132.59356808169264
At time: 42.13078761100769 and batch: 600, loss is 4.795443019866943 and perplexity is 120.95795669268314
At time: 42.52230620384216 and batch: 650, loss is 4.9091409397125245 and perplexity is 135.52294200969953
At time: 42.909111738204956 and batch: 700, loss is 4.906867408752442 and perplexity is 135.21517639513414
At time: 43.296653509140015 and batch: 750, loss is 4.91239291191101 and perplexity is 135.9643762262462
At time: 43.7054877281189 and batch: 800, loss is 4.815664768218994 and perplexity is 123.42883661147023
At time: 44.11031532287598 and batch: 850, loss is 4.783819360733032 and perplexity is 119.56012234787839
At time: 44.5151252746582 and batch: 900, loss is 4.722370491027832 and perplexity is 112.43446190301015
At time: 44.90970420837402 and batch: 950, loss is 4.815563917160034 and perplexity is 123.41638931026408
At time: 45.3093159198761 and batch: 1000, loss is 4.866222133636475 and perplexity is 129.82951070596775
At time: 45.70004916191101 and batch: 1050, loss is 4.76022045135498 and perplexity is 116.7716655336072
At time: 46.087918281555176 and batch: 1100, loss is 4.908801393508911 and perplexity is 135.47693352068356
At time: 46.47510766983032 and batch: 1150, loss is 4.850385723114013 and perplexity is 127.7896717709633
At time: 46.86244297027588 and batch: 1200, loss is 4.806313095092773 and perplexity is 122.27995085202652
At time: 47.2628059387207 and batch: 1250, loss is 4.778154315948487 and perplexity is 118.88472378815719
At time: 47.658223390579224 and batch: 1300, loss is 4.873425397872925 and perplexity is 130.76808331220832
At time: 48.04631471633911 and batch: 1350, loss is 4.857601060867309 and perplexity is 128.7150518644474
At time: 48.43391561508179 and batch: 1400, loss is 4.713472900390625 and perplexity is 111.43850347327016
At time: 48.8224732875824 and batch: 1450, loss is 4.803793363571167 and perplexity is 121.97222606014647
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.072999090211004 and perplexity of 159.6524220765392
Annealing...
Finished 4 epochs...
Completing Train Step...
At time: 50.13200616836548 and batch: 50, loss is 4.823282070159912 and perplexity is 124.37262131121538
At time: 50.539072036743164 and batch: 100, loss is 4.8124715614318845 and perplexity is 123.03533141877035
At time: 50.92773222923279 and batch: 150, loss is 4.684540662765503 and perplexity is 108.26053279171467
At time: 51.31627583503723 and batch: 200, loss is 4.754654016494751 and perplexity is 116.123469408354
At time: 51.70558190345764 and batch: 250, loss is 4.788261108398437 and perplexity is 120.09235939848391
At time: 52.09405970573425 and batch: 300, loss is 4.7936869239807125 and perplexity is 120.74572932287396
At time: 52.48266077041626 and batch: 350, loss is 4.793399877548218 and perplexity is 120.71107466601865
At time: 52.87195301055908 and batch: 400, loss is 4.665712051391601 and perplexity is 106.24120749494983
At time: 53.271546602249146 and batch: 450, loss is 4.715581331253052 and perplexity is 111.67371172629132
At time: 53.66773843765259 and batch: 500, loss is 4.709972448348999 and perplexity is 111.04910027749568
At time: 54.09248208999634 and batch: 550, loss is 4.74302119255066 and perplexity is 114.7804522192203
At time: 54.49776768684387 and batch: 600, loss is 4.637623434066772 and perplexity is 103.29855979536357
At time: 54.898640632629395 and batch: 650, loss is 4.746102514266968 and perplexity is 115.13467317334646
At time: 55.29227566719055 and batch: 700, loss is 4.762715330123902 and perplexity is 117.06336040312445
At time: 55.69821548461914 and batch: 750, loss is 4.734551725387573 and perplexity is 113.81242805911259
At time: 56.091795682907104 and batch: 800, loss is 4.649991655349732 and perplexity is 104.58411285562752
At time: 56.48016166687012 and batch: 850, loss is 4.614034290313721 and perplexity is 100.89035068349791
At time: 56.86811709403992 and batch: 900, loss is 4.552407922744751 and perplexity is 94.86055040733046
At time: 57.26575970649719 and batch: 950, loss is 4.633032035827637 and perplexity is 102.82536212058655
At time: 57.65586709976196 and batch: 1000, loss is 4.680027666091919 and perplexity is 107.77305418937907
At time: 58.05057692527771 and batch: 1050, loss is 4.569452772140503 and perplexity is 96.49129259913909
At time: 58.44693613052368 and batch: 1100, loss is 4.710521049499512 and perplexity is 111.11003865557512
At time: 58.83560919761658 and batch: 1150, loss is 4.666179847717285 and perplexity is 106.29091836782752
At time: 59.22344899177551 and batch: 1200, loss is 4.59849292755127 and perplexity is 99.334498491755
At time: 59.61184215545654 and batch: 1250, loss is 4.561868124008178 and perplexity is 95.76220851521732
At time: 60.00063109397888 and batch: 1300, loss is 4.6491805362701415 and perplexity is 104.49931708065282
At time: 60.39962649345398 and batch: 1350, loss is 4.622628879547119 and perplexity is 101.76119873531258
At time: 60.795727014541626 and batch: 1400, loss is 4.484086399078369 and perplexity is 88.59597246554937
At time: 61.18928027153015 and batch: 1450, loss is 4.5539272689819335 and perplexity is 95.00478597178365
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.939663357204861 and perplexity of 139.72320483159248
Finished 5 epochs...
Completing Train Step...
At time: 62.55706810951233 and batch: 50, loss is 4.675323057174682 and perplexity is 107.26721493851954
At time: 62.9491810798645 and batch: 100, loss is 4.697193078994751 and perplexity is 109.63899214552889
At time: 63.33932876586914 and batch: 150, loss is 4.572442941665649 and perplexity is 96.7802497218023
At time: 63.7292742729187 and batch: 200, loss is 4.6516460514068605 and perplexity is 104.75727960326962
At time: 64.15259146690369 and batch: 250, loss is 4.692967901229858 and perplexity is 109.17672518150314
At time: 64.5642819404602 and batch: 300, loss is 4.697658863067627 and perplexity is 109.69007213703621
At time: 64.96329188346863 and batch: 350, loss is 4.695007925033569 and perplexity is 109.39967563447918
At time: 65.35606789588928 and batch: 400, loss is 4.5617216777801515 and perplexity is 95.7481855278246
At time: 65.75388956069946 and batch: 450, loss is 4.616372594833374 and perplexity is 101.1265390790703
At time: 66.15264534950256 and batch: 500, loss is 4.615457363128662 and perplexity is 101.0340272056749
At time: 66.54505181312561 and batch: 550, loss is 4.65110556602478 and perplexity is 104.7006751233025
At time: 66.9340569972992 and batch: 600, loss is 4.556942043304443 and perplexity is 95.2916361380429
At time: 67.3235969543457 and batch: 650, loss is 4.661593503952027 and perplexity is 105.8045478607873
At time: 67.71276187896729 and batch: 700, loss is 4.687674570083618 and perplexity is 108.60034345714193
At time: 68.11577558517456 and batch: 750, loss is 4.6506562995910645 and perplexity is 104.65364718920937
At time: 68.51402568817139 and batch: 800, loss is 4.573544454574585 and perplexity is 96.88691315098816
At time: 68.91346573829651 and batch: 850, loss is 4.542630062103272 and perplexity is 93.93753706681282
At time: 69.30878376960754 and batch: 900, loss is 4.48183759689331 and perplexity is 88.39696150109567
At time: 69.69855427742004 and batch: 950, loss is 4.570055694580078 and perplexity is 96.54948690623465
At time: 70.0888090133667 and batch: 1000, loss is 4.619976921081543 and perplexity is 101.49168978408372
At time: 70.47878670692444 and batch: 1050, loss is 4.50532395362854 and perplexity is 90.49765634484775
At time: 70.86881351470947 and batch: 1100, loss is 4.652410688400269 and perplexity is 104.83741152659535
At time: 71.25842261314392 and batch: 1150, loss is 4.602413578033447 and perplexity is 99.7247188000276
At time: 71.6489405632019 and batch: 1200, loss is 4.530537672042847 and perplexity is 92.8084481773867
At time: 72.03787875175476 and batch: 1250, loss is 4.503832025527954 and perplexity is 90.36274101532044
At time: 72.42712140083313 and batch: 1300, loss is 4.5963897609710695 and perplexity is 99.12580103395328
At time: 72.8172619342804 and batch: 1350, loss is 4.572751808166504 and perplexity is 96.8101465157071
At time: 73.20697259902954 and batch: 1400, loss is 4.443032073974609 and perplexity is 85.03237565038049
At time: 73.5966546535492 and batch: 1450, loss is 4.50027419090271 and perplexity is 90.04181656309501
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.9303813184428416 and perplexity of 138.43228906185652
Finished 6 epochs...
Completing Train Step...
At time: 74.92820119857788 and batch: 50, loss is 4.6090732765197755 and perplexity is 100.3910717509233
At time: 75.33607077598572 and batch: 100, loss is 4.636565313339234 and perplexity is 103.18931525526803
At time: 75.73866367340088 and batch: 150, loss is 4.519060115814209 and perplexity is 91.7493237021894
At time: 76.14349389076233 and batch: 200, loss is 4.600235061645508 and perplexity is 99.50770333753825
At time: 76.54064750671387 and batch: 250, loss is 4.63541615486145 and perplexity is 103.07080248684402
At time: 76.93255615234375 and batch: 300, loss is 4.641150007247925 and perplexity is 103.66349282930072
At time: 77.32165622711182 and batch: 350, loss is 4.650420999526977 and perplexity is 104.62902507622475
At time: 77.71148586273193 and batch: 400, loss is 4.510809307098389 and perplexity is 90.99543196757725
At time: 78.10596203804016 and batch: 450, loss is 4.5668421459198 and perplexity is 96.23971842655688
At time: 78.51310896873474 and batch: 500, loss is 4.562898502349854 and perplexity is 95.86093067267458
At time: 78.91135382652283 and batch: 550, loss is 4.607173051834106 and perplexity is 100.20048729215576
At time: 79.30129790306091 and batch: 600, loss is 4.506399259567261 and perplexity is 90.59502135135875
At time: 79.69126319885254 and batch: 650, loss is 4.614520998001098 and perplexity is 100.93946674437042
At time: 80.07901549339294 and batch: 700, loss is 4.649970588684082 and perplexity is 104.58190964029697
At time: 80.46666216850281 and batch: 750, loss is 4.614311094284058 and perplexity is 100.91828139862388
At time: 80.86594724655151 and batch: 800, loss is 4.533562793731689 and perplexity is 93.08963011723517
At time: 81.26040124893188 and batch: 850, loss is 4.50793342590332 and perplexity is 90.73411585309978
At time: 81.6595299243927 and batch: 900, loss is 4.444055538177491 and perplexity is 85.11944779295459
At time: 82.05721831321716 and batch: 950, loss is 4.536552772521973 and perplexity is 93.36838266130833
At time: 82.4463038444519 and batch: 1000, loss is 4.575459604263306 and perplexity is 97.0726438868623
At time: 82.84071803092957 and batch: 1050, loss is 4.468942775726318 and perplexity is 87.26441616851821
At time: 83.23889350891113 and batch: 1100, loss is 4.611257057189942 and perplexity is 100.61054338460607
At time: 83.62904238700867 and batch: 1150, loss is 4.566491432189942 and perplexity is 96.20597175400358
At time: 84.0448956489563 and batch: 1200, loss is 4.497334537506103 and perplexity is 89.77751350122803
At time: 84.44135808944702 and batch: 1250, loss is 4.462214460372925 and perplexity is 86.67924447482187
At time: 84.82903170585632 and batch: 1300, loss is 4.558071327209473 and perplexity is 95.39930823375722
At time: 85.22972655296326 and batch: 1350, loss is 4.5284615421295165 and perplexity is 92.61596566040984
At time: 85.63953685760498 and batch: 1400, loss is 4.407385940551758 and perplexity is 82.05468707730346
At time: 86.04300260543823 and batch: 1450, loss is 4.472566003799439 and perplexity is 87.58116853748093
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.939983661358173 and perplexity of 139.76796592261317
Annealing...
Finished 7 epochs...
Completing Train Step...
At time: 87.32097744941711 and batch: 50, loss is 4.558324375152588 and perplexity is 95.42345188710244
At time: 87.72227096557617 and batch: 100, loss is 4.5455375671386715 and perplexity is 94.21105836844222
At time: 88.11074542999268 and batch: 150, loss is 4.429723892211914 and perplexity is 83.90824599137761
At time: 88.51124501228333 and batch: 200, loss is 4.501845998764038 and perplexity is 90.18345628426974
At time: 88.91620421409607 and batch: 250, loss is 4.544591875076294 and perplexity is 94.12200583312976
At time: 89.32133555412292 and batch: 300, loss is 4.542251224517822 and perplexity is 93.901956737096
At time: 89.71781277656555 and batch: 350, loss is 4.546067113876343 and perplexity is 94.26096073870636
At time: 90.10707807540894 and batch: 400, loss is 4.3936303520202635 and perplexity is 80.93370413049463
At time: 90.50552749633789 and batch: 450, loss is 4.449083156585694 and perplexity is 85.54847348059232
At time: 90.91895771026611 and batch: 500, loss is 4.457038698196411 and perplexity is 86.23177232342411
At time: 91.31444764137268 and batch: 550, loss is 4.488673191070557 and perplexity is 89.00327715945346
At time: 91.7159514427185 and batch: 600, loss is 4.389879350662231 and perplexity is 80.63069035421758
At time: 92.11005020141602 and batch: 650, loss is 4.482909727096557 and perplexity is 88.4917853760834
At time: 92.49719166755676 and batch: 700, loss is 4.533933525085449 and perplexity is 93.12414775982039
At time: 92.89422655105591 and batch: 750, loss is 4.48630241394043 and perplexity is 88.79252015311755
At time: 93.29479694366455 and batch: 800, loss is 4.413317666053772 and perplexity is 82.54285937786605
At time: 93.68494844436646 and batch: 850, loss is 4.367427735328675 and perplexity is 78.84057183207494
At time: 94.09552574157715 and batch: 900, loss is 4.30335874080658 and perplexity is 73.94774837877982
At time: 94.49200224876404 and batch: 950, loss is 4.406517658233643 and perplexity is 81.98347136554162
At time: 94.89057445526123 and batch: 1000, loss is 4.448445434570313 and perplexity is 85.49393472780154
At time: 95.2856297492981 and batch: 1050, loss is 4.340876531600952 and perplexity is 76.77480539666307
At time: 95.67516350746155 and batch: 1100, loss is 4.486175785064697 and perplexity is 88.78127716797539
At time: 96.06293559074402 and batch: 1150, loss is 4.428544330596924 and perplexity is 83.80932939580372
At time: 96.44903898239136 and batch: 1200, loss is 4.3629329919815065 and perplexity is 78.48699890139574
At time: 96.83547353744507 and batch: 1250, loss is 4.3262230491638185 and perplexity is 75.65798973739955
At time: 97.2218599319458 and batch: 1300, loss is 4.421301946640015 and perplexity is 83.2045427452424
At time: 97.6089551448822 and batch: 1350, loss is 4.386318778991699 and perplexity is 80.34410950096533
At time: 97.99600505828857 and batch: 1400, loss is 4.261321082115173 and perplexity is 70.90359107505643
At time: 98.38277125358582 and batch: 1450, loss is 4.3300572204589844 and perplexity is 75.9486322604521
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8578840728498935 and perplexity of 128.7514849217167
Finished 8 epochs...
Completing Train Step...
At time: 99.64231872558594 and batch: 50, loss is 4.484820137023926 and perplexity is 88.66100254697247
At time: 100.0429298877716 and batch: 100, loss is 4.4883531475067135 and perplexity is 88.97479679115997
At time: 100.4310233592987 and batch: 150, loss is 4.37977442741394 and perplexity is 79.82002616446967
At time: 100.81885504722595 and batch: 200, loss is 4.456323146820068 and perplexity is 86.1700911307166
At time: 101.20632123947144 and batch: 250, loss is 4.497350015640259 and perplexity is 89.77890310038035
At time: 101.60556054115295 and batch: 300, loss is 4.497119073867798 and perplexity is 89.75817179532304
At time: 102.0022783279419 and batch: 350, loss is 4.505220794677735 and perplexity is 90.48832118307989
At time: 102.39099955558777 and batch: 400, loss is 4.353711614608764 and perplexity is 77.76656745586527
At time: 102.77962327003479 and batch: 450, loss is 4.40755524635315 and perplexity is 82.06858058794982
At time: 103.16839265823364 and batch: 500, loss is 4.421229829788208 and perplexity is 83.19854251192517
At time: 103.55715584754944 and batch: 550, loss is 4.455467414855957 and perplexity is 86.09638417058439
At time: 103.95963454246521 and batch: 600, loss is 4.357090787887573 and perplexity is 78.02979866404698
At time: 104.36993455886841 and batch: 650, loss is 4.448096466064453 and perplexity is 85.46410524221778
At time: 104.75800681114197 and batch: 700, loss is 4.4995488262176515 and perplexity is 89.97652709138288
At time: 105.14703488349915 and batch: 750, loss is 4.4553056240081785 and perplexity is 86.08245569037945
At time: 105.53535890579224 and batch: 800, loss is 4.388464517593384 and perplexity is 80.5166920504418
At time: 105.92374539375305 and batch: 850, loss is 4.345606226921081 and perplexity is 77.1387869167751
At time: 106.31107974052429 and batch: 900, loss is 4.2890658283233645 and perplexity is 72.89833711957382
At time: 106.70067834854126 and batch: 950, loss is 4.384399118423462 and perplexity is 80.19002402529046
At time: 107.08853840827942 and batch: 1000, loss is 4.422215051651001 and perplexity is 83.2805519270612
At time: 107.48332190513611 and batch: 1050, loss is 4.314389424324036 and perplexity is 74.7679580077583
At time: 107.88355350494385 and batch: 1100, loss is 4.461322536468506 and perplexity is 86.60196765230343
At time: 108.27701044082642 and batch: 1150, loss is 4.40354811668396 and perplexity is 81.7403791557789
At time: 108.66481137275696 and batch: 1200, loss is 4.337488932609558 and perplexity is 76.5151631735042
At time: 109.05402183532715 and batch: 1250, loss is 4.306645956039429 and perplexity is 74.1912305135253
At time: 109.44287157058716 and batch: 1300, loss is 4.399490661621094 and perplexity is 81.40939317498788
At time: 109.83190131187439 and batch: 1350, loss is 4.367379636764526 and perplexity is 78.83677980496944
At time: 110.22095799446106 and batch: 1400, loss is 4.241663269996643 and perplexity is 69.5233918967695
At time: 110.60960054397583 and batch: 1450, loss is 4.314396963119507 and perplexity is 74.76852167022619
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8612321380876065 and perplexity of 129.18327572122192
Annealing...
Finished 9 epochs...
Completing Train Step...
At time: 111.9055724143982 and batch: 50, loss is 4.447956981658936 and perplexity is 85.45218516365685
At time: 112.30207061767578 and batch: 100, loss is 4.439820184707641 and perplexity is 84.75969921336105
At time: 112.70556044578552 and batch: 150, loss is 4.326813220977783 and perplexity is 75.70265412897989
At time: 113.1105329990387 and batch: 200, loss is 4.391738376617432 and perplexity is 80.78072431567655
At time: 113.50787878036499 and batch: 250, loss is 4.435957412719727 and perplexity is 84.43292335816416
At time: 113.91208028793335 and batch: 300, loss is 4.428311796188354 and perplexity is 83.78984310866399
At time: 114.34624528884888 and batch: 350, loss is 4.435268688201904 and perplexity is 84.37479235415762
At time: 114.75280499458313 and batch: 400, loss is 4.284559164047241 and perplexity is 72.57054796051845
At time: 115.1499171257019 and batch: 450, loss is 4.33980128288269 and perplexity is 76.6922977516346
At time: 115.55784296989441 and batch: 500, loss is 4.346727356910706 and perplexity is 77.22531802139534
At time: 115.95640873908997 and batch: 550, loss is 4.378037052154541 and perplexity is 79.68146922336021
At time: 116.35830974578857 and batch: 600, loss is 4.28544548034668 and perplexity is 72.63489693259397
At time: 116.75716042518616 and batch: 650, loss is 4.375478916168213 and perplexity is 79.47789368746609
At time: 117.14672040939331 and batch: 700, loss is 4.424300279617309 and perplexity is 83.45439204813954
At time: 117.56079769134521 and batch: 750, loss is 4.377173361778259 and perplexity is 79.6126788163065
At time: 117.95955276489258 and batch: 800, loss is 4.31407365322113 and perplexity is 74.74435217441234
At time: 118.35879349708557 and batch: 850, loss is 4.261594443321228 and perplexity is 70.922976015651
At time: 118.75246524810791 and batch: 900, loss is 4.202970137596131 and perplexity is 66.88469305531164
At time: 119.14195728302002 and batch: 950, loss is 4.304726366996765 and perplexity is 74.04895044369106
At time: 119.5313470363617 and batch: 1000, loss is 4.342060790061951 and perplexity is 76.86578046791206
At time: 119.93621325492859 and batch: 1050, loss is 4.235108828544616 and perplexity is 69.06919502448959
At time: 120.33998513221741 and batch: 1100, loss is 4.372528352737427 and perplexity is 79.24373474108693
At time: 120.7359688282013 and batch: 1150, loss is 4.314016814231873 and perplexity is 74.74010390171695
At time: 121.13817620277405 and batch: 1200, loss is 4.245441446304321 and perplexity is 69.78656036424533
At time: 121.54528427124023 and batch: 1250, loss is 4.218416013717651 and perplexity is 67.92580548695182
At time: 121.9491593837738 and batch: 1300, loss is 4.310512180328369 and perplexity is 74.47862566001999
At time: 122.34398460388184 and batch: 1350, loss is 4.268808631896973 and perplexity is 71.43647776111655
At time: 122.73445653915405 and batch: 1400, loss is 4.147178249359131 and perplexity is 63.255257669292774
At time: 123.12591171264648 and batch: 1450, loss is 4.2223569202423095 and perplexity is 68.19402289972943
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.81645998180422 and perplexity of 123.52702793551535
Finished 10 epochs...
Completing Train Step...
At time: 124.4130334854126 and batch: 50, loss is 4.401405634880066 and perplexity is 81.56543935038697
At time: 124.800363779068 and batch: 100, loss is 4.402782926559448 and perplexity is 81.6778561489194
At time: 125.18840956687927 and batch: 150, loss is 4.294099521636963 and perplexity is 73.26621009480736
At time: 125.57677555084229 and batch: 200, loss is 4.360524215698242 and perplexity is 78.2981687959398
At time: 125.96481204032898 and batch: 250, loss is 4.406018009185791 and perplexity is 81.94251863398291
At time: 126.35259318351746 and batch: 300, loss is 4.402692289352417 and perplexity is 81.67045343164764
At time: 126.7402515411377 and batch: 350, loss is 4.406830215454102 and perplexity is 82.00909989645778
At time: 127.12791204452515 and batch: 400, loss is 4.260057501792907 and perplexity is 70.81405527234823
At time: 127.51430368423462 and batch: 450, loss is 4.317200498580933 and perplexity is 74.97843198013788
At time: 127.91458058357239 and batch: 500, loss is 4.323684067726135 and perplexity is 75.46613916143198
At time: 128.30700135231018 and batch: 550, loss is 4.356509637832642 and perplexity is 77.98446481642699
At time: 128.69580626487732 and batch: 600, loss is 4.26419828414917 and perplexity is 71.10788879348446
At time: 129.08327865600586 and batch: 650, loss is 4.355479307174683 and perplexity is 77.90415641069286
At time: 129.48321151733398 and batch: 700, loss is 4.4068949508666995 and perplexity is 82.01440896121673
At time: 129.87949180603027 and batch: 750, loss is 4.361234464645386 and perplexity is 78.35379974146203
At time: 130.26765513420105 and batch: 800, loss is 4.298091588020324 and perplexity is 73.55927825372683
At time: 130.65480017662048 and batch: 850, loss is 4.246145696640014 and perplexity is 69.83572488284109
At time: 131.057781457901 and batch: 900, loss is 4.189503793716431 and perplexity is 65.99003816342045
At time: 131.45273542404175 and batch: 950, loss is 4.293010931015015 and perplexity is 73.18649658115609
At time: 131.84095001220703 and batch: 1000, loss is 4.332102379798889 and perplexity is 76.10411825769665
At time: 132.22902488708496 and batch: 1050, loss is 4.2262411260604855 and perplexity is 68.45941761041244
At time: 132.6425859928131 and batch: 1100, loss is 4.362464590072632 and perplexity is 78.45024404998175
At time: 133.0472013950348 and batch: 1150, loss is 4.3055542993545535 and perplexity is 74.11028335206989
At time: 133.44352293014526 and batch: 1200, loss is 4.238162078857422 and perplexity is 69.28040283688378
At time: 133.83329463005066 and batch: 1250, loss is 4.2114722490310665 and perplexity is 67.45577844465467
At time: 134.24305844306946 and batch: 1300, loss is 4.303463745117187 and perplexity is 73.955513618804
At time: 134.63880968093872 and batch: 1350, loss is 4.26071346282959 and perplexity is 70.86052177189681
At time: 135.04354882240295 and batch: 1400, loss is 4.143268928527832 and perplexity is 63.00845530193398
At time: 135.446533203125 and batch: 1450, loss is 4.218545393943787 and perplexity is 67.93459431156393
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.81529040214343 and perplexity of 123.38263769049045
Finished 11 epochs...
Completing Train Step...
At time: 136.7870090007782 and batch: 50, loss is 4.382523765563965 and perplexity is 80.0397803584099
At time: 137.20420098304749 and batch: 100, loss is 4.382593002319336 and perplexity is 80.04532224495141
At time: 137.6168646812439 and batch: 150, loss is 4.275978708267212 and perplexity is 71.95052343339343
At time: 138.02031087875366 and batch: 200, loss is 4.3431924533843995 and perplexity is 76.95281589052816
At time: 138.41544485092163 and batch: 250, loss is 4.387381677627563 and perplexity is 80.4295525459575
At time: 138.81548738479614 and batch: 300, loss is 4.385822620391846 and perplexity is 80.30425596774306
At time: 139.21050691604614 and batch: 350, loss is 4.389884777069092 and perplexity is 80.63112789033603
At time: 139.60202288627625 and batch: 400, loss is 4.244120469093323 and perplexity is 69.69443476967217
At time: 139.98980736732483 and batch: 450, loss is 4.301784200668335 and perplexity is 73.83140629749902
At time: 140.3782365322113 and batch: 500, loss is 4.308608908653259 and perplexity is 74.33700741314944
At time: 140.7660002708435 and batch: 550, loss is 4.340601959228516 and perplexity is 76.7537280499629
At time: 141.16101574897766 and batch: 600, loss is 4.2491393613815305 and perplexity is 70.04510287751029
At time: 141.5601761341095 and batch: 650, loss is 4.341892108917237 and perplexity is 76.85281575355555
At time: 141.95456719398499 and batch: 700, loss is 4.394297437667847 and perplexity is 80.9877118548119
At time: 142.3426742553711 and batch: 750, loss is 4.349523229598999 and perplexity is 77.44153229183905
At time: 142.7314257621765 and batch: 800, loss is 4.285933017730713 and perplexity is 72.67031779402944
At time: 143.11974596977234 and batch: 850, loss is 4.234610800743103 and perplexity is 69.03480520939206
At time: 143.50853204727173 and batch: 900, loss is 4.178219852447509 and perplexity is 65.24959585871868
At time: 143.90095257759094 and batch: 950, loss is 4.281578335762024 and perplexity is 72.35454970527317
At time: 144.29179167747498 and batch: 1000, loss is 4.32201732635498 and perplexity is 75.34046139043515
At time: 144.6942846775055 and batch: 1050, loss is 4.217235517501831 and perplexity is 67.8456666417263
At time: 145.08308601379395 and batch: 1100, loss is 4.352785358428955 and perplexity is 77.69456904181227
At time: 145.4720540046692 and batch: 1150, loss is 4.295536971092224 and perplexity is 73.37160229843269
At time: 145.86032271385193 and batch: 1200, loss is 4.229040470123291 and perplexity is 68.65132756031026
At time: 146.2483627796173 and batch: 1250, loss is 4.202726855278015 and perplexity is 66.86842317130647
At time: 146.63621878623962 and batch: 1300, loss is 4.294554147720337 and perplexity is 73.29952639760272
At time: 147.02408742904663 and batch: 1350, loss is 4.2502596950531 and perplexity is 70.1236207396823
At time: 147.41080045700073 and batch: 1400, loss is 4.137502145767212 and perplexity is 62.64614491484835
At time: 147.79841804504395 and batch: 1450, loss is 4.2107061004638675 and perplexity is 67.40411708931373
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.815755208333333 and perplexity of 123.4400000343691
Annealing...
Finished 12 epochs...
Completing Train Step...
At time: 149.06323194503784 and batch: 50, loss is 4.366432104110718 and perplexity is 78.762114761153
At time: 149.4661636352539 and batch: 100, loss is 4.361994066238403 and perplexity is 78.41334002314817
At time: 149.8551778793335 and batch: 150, loss is 4.252653203010559 and perplexity is 70.29166320919795
At time: 150.2443883419037 and batch: 200, loss is 4.313823471069336 and perplexity is 74.72565481052176
At time: 150.6363549232483 and batch: 250, loss is 4.362266983985901 and perplexity is 78.43474333582012
At time: 151.0253357887268 and batch: 300, loss is 4.352253675460815 and perplexity is 77.65327114240354
At time: 151.41549515724182 and batch: 350, loss is 4.356297426223755 and perplexity is 77.967917363523
At time: 151.8055112361908 and batch: 400, loss is 4.210548000335693 and perplexity is 67.39346133212293
At time: 152.19602704048157 and batch: 450, loss is 4.2699998140335085 and perplexity is 71.52162231859282
At time: 152.58657813072205 and batch: 500, loss is 4.2699197578430175 and perplexity is 71.51589679915695
At time: 152.97715210914612 and batch: 550, loss is 4.303238973617554 and perplexity is 73.93889239516042
At time: 153.3677523136139 and batch: 600, loss is 4.213596596717834 and perplexity is 67.5992302884008
At time: 153.75944304466248 and batch: 650, loss is 4.3066268110275265 and perplexity is 74.18981013513071
At time: 154.1616039276123 and batch: 700, loss is 4.355459413528442 and perplexity is 77.90260662838003
At time: 154.57557106018066 and batch: 750, loss is 4.308301873207093 and perplexity is 74.31418682045637
At time: 154.9663188457489 and batch: 800, loss is 4.246122069358826 and perplexity is 69.83407487402498
At time: 155.3606309890747 and batch: 850, loss is 4.191058626174927 and perplexity is 66.09272142364088
At time: 155.76894092559814 and batch: 900, loss is 4.133116555213928 and perplexity is 62.37200614309901
At time: 156.1643829345703 and batch: 950, loss is 4.237579674720764 and perplexity is 69.24006539117006
At time: 156.5542175769806 and batch: 1000, loss is 4.280099000930786 and perplexity is 72.24759223215909
At time: 156.95589566230774 and batch: 1050, loss is 4.173980383872986 and perplexity is 64.97355778837564
At time: 157.35548949241638 and batch: 1100, loss is 4.3060177183151245 and perplexity is 74.14463542163394
At time: 157.74876928329468 and batch: 1150, loss is 4.246617569923401 and perplexity is 69.86868627182703
At time: 158.13853430747986 and batch: 1200, loss is 4.1831160926818844 and perplexity is 65.56985695306082
At time: 158.52894735336304 and batch: 1250, loss is 4.153839149475098 and perplexity is 63.678000984930385
At time: 158.91884589195251 and batch: 1300, loss is 4.244404373168945 and perplexity is 69.7142241127561
At time: 159.30892491340637 and batch: 1350, loss is 4.194374084472656 and perplexity is 66.31221274140094
At time: 159.6987624168396 and batch: 1400, loss is 4.083375682830811 and perplexity is 59.34546356473493
At time: 160.08977627754211 and batch: 1450, loss is 4.15793312549591 and perplexity is 63.9392315650155
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.792630187466613 and perplexity of 120.61820029593412
Finished 13 epochs...
Completing Train Step...
At time: 161.37458395957947 and batch: 50, loss is 4.341387829780579 and perplexity is 76.81407025207268
At time: 161.76308488845825 and batch: 100, loss is 4.342698221206665 and perplexity is 76.91479272965655
At time: 162.15274286270142 and batch: 150, loss is 4.2344117355346675 and perplexity is 69.02106414923263
At time: 162.54154229164124 and batch: 200, loss is 4.297937803268432 and perplexity is 73.54796682815591
At time: 162.94184494018555 and batch: 250, loss is 4.34599277973175 and perplexity is 77.16861089556943
At time: 163.35050463676453 and batch: 300, loss is 4.336808986663819 and perplexity is 76.46315468200201
At time: 163.74677085876465 and batch: 350, loss is 4.342045679092407 and perplexity is 76.8646189602202
At time: 164.13514113426208 and batch: 400, loss is 4.199195117950439 and perplexity is 66.63267800519844
At time: 164.5536708831787 and batch: 450, loss is 4.25794864654541 and perplexity is 70.66487603428676
At time: 164.9491627216339 and batch: 500, loss is 4.25737859249115 and perplexity is 70.62460471471466
At time: 165.33791255950928 and batch: 550, loss is 4.292412548065186 and perplexity is 73.14271612948843
At time: 165.72657775878906 and batch: 600, loss is 4.203208498954773 and perplexity is 66.9006376818366
At time: 166.12752079963684 and batch: 650, loss is 4.296282229423523 and perplexity is 73.42630347704909
At time: 166.52391409873962 and batch: 700, loss is 4.345897760391235 and perplexity is 77.1612787334078
At time: 166.92359447479248 and batch: 750, loss is 4.300000114440918 and perplexity is 73.69980213386832
At time: 167.32013082504272 and batch: 800, loss is 4.239660754203796 and perplexity is 69.38430951033911
At time: 167.71432185173035 and batch: 850, loss is 4.183944001197815 and perplexity is 65.62416527407926
At time: 168.1119508743286 and batch: 900, loss is 4.1258848285675045 and perplexity is 61.922575881368196
At time: 168.5021312236786 and batch: 950, loss is 4.230712642669678 and perplexity is 68.76622045913365
At time: 168.89662647247314 and batch: 1000, loss is 4.274680962562561 and perplexity is 71.85721051197785
At time: 169.30101895332336 and batch: 1050, loss is 4.169006314277649 and perplexity is 64.65117722643299
At time: 169.69465017318726 and batch: 1100, loss is 4.302634229660034 and perplexity is 73.89419181432415
At time: 170.0806279182434 and batch: 1150, loss is 4.243550391197204 and perplexity is 69.6547148357314
At time: 170.4663746356964 and batch: 1200, loss is 4.180324592590332 and perplexity is 65.3870739294811
At time: 170.85258531570435 and batch: 1250, loss is 4.151687846183777 and perplexity is 63.54115754048017
At time: 171.23900032043457 and batch: 1300, loss is 4.242410502433777 and perplexity is 69.57536144458214
At time: 171.62537097930908 and batch: 1350, loss is 4.192124934196472 and perplexity is 66.16323421015443
At time: 172.01206135749817 and batch: 1400, loss is 4.081804399490356 and perplexity is 59.2522882480858
At time: 172.39828419685364 and batch: 1450, loss is 4.1559310102462765 and perplexity is 63.81134591807005
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.791998969184028 and perplexity of 120.54208790698769
Finished 14 epochs...
Completing Train Step...
At time: 173.67976999282837 and batch: 50, loss is 4.330939249992371 and perplexity is 76.01565074892427
At time: 174.07520246505737 and batch: 100, loss is 4.332849774360657 and perplexity is 76.16101932293522
At time: 174.47597098350525 and batch: 150, loss is 4.224908175468445 and perplexity is 68.36822538004884
At time: 174.86297154426575 and batch: 200, loss is 4.288625864982605 and perplexity is 72.86627157798753
At time: 175.25064969062805 and batch: 250, loss is 4.335707397460937 and perplexity is 76.37897007332721
At time: 175.63663363456726 and batch: 300, loss is 4.327231011390686 and perplexity is 75.73428857993129
At time: 176.02277994155884 and batch: 350, loss is 4.333241147994995 and perplexity is 76.1908325715417
At time: 176.40940618515015 and batch: 400, loss is 4.190823059082032 and perplexity is 66.07715398705346
At time: 176.79557633399963 and batch: 450, loss is 4.249098477363586 and perplexity is 70.04223921080681
At time: 177.1822783946991 and batch: 500, loss is 4.24860677242279 and perplexity is 70.00780756152223
At time: 177.56991314888 and batch: 550, loss is 4.284397130012512 and perplexity is 72.55879001444934
At time: 177.96504592895508 and batch: 600, loss is 4.19577802658081 and perplexity is 66.4053766322055
At time: 178.3533263206482 and batch: 650, loss is 4.288658137321472 and perplexity is 72.86862318094154
At time: 178.74301052093506 and batch: 700, loss is 4.339329776763916 and perplexity is 76.656145387682
At time: 179.13141179084778 and batch: 750, loss is 4.293680777549744 and perplexity is 73.2355367251315
At time: 179.5198745727539 and batch: 800, loss is 4.233119373321533 and perplexity is 68.93192154868726
At time: 179.90740847587585 and batch: 850, loss is 4.178509073257446 and perplexity is 65.2684701289653
At time: 180.29583621025085 and batch: 900, loss is 4.120764970779419 and perplexity is 61.60635130218537
At time: 180.68407726287842 and batch: 950, loss is 4.225794878005981 and perplexity is 68.42887454389016
At time: 181.071448802948 and batch: 1000, loss is 4.269805212020874 and perplexity is 71.50770542111475
At time: 181.4581708908081 and batch: 1050, loss is 4.164113006591797 and perplexity is 64.33559188181749
At time: 181.86178731918335 and batch: 1100, loss is 4.298508882522583 and perplexity is 73.58998054163467
At time: 182.2567000389099 and batch: 1150, loss is 4.239670815467835 and perplexity is 69.3850076077091
At time: 182.64490580558777 and batch: 1200, loss is 4.176575412750244 and perplexity is 65.14238500810727
At time: 183.03282833099365 and batch: 1250, loss is 4.1479717016220095 and perplexity is 63.30546761359219
At time: 183.43267250061035 and batch: 1300, loss is 4.238978743553162 and perplexity is 69.33700480525609
At time: 183.8249111175537 and batch: 1350, loss is 4.18759208202362 and perplexity is 65.86400474401913
At time: 184.21104645729065 and batch: 1400, loss is 4.079020771980286 and perplexity is 59.08758129623869
At time: 184.59756112098694 and batch: 1450, loss is 4.152303647994995 and perplexity is 63.5802983506345
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.7921163444845085 and perplexity of 120.55623740116067
Annealing...
Finished 15 epochs...
Completing Train Step...
At time: 185.84815216064453 and batch: 50, loss is 4.32472309589386 and perplexity is 75.544591355692
At time: 186.24849915504456 and batch: 100, loss is 4.323020234107971 and perplexity is 75.41605882556794
At time: 186.6474404335022 and batch: 150, loss is 4.212556796073914 and perplexity is 67.52897709620537
At time: 187.04160165786743 and batch: 200, loss is 4.276394019126892 and perplexity is 71.98041147311909
At time: 187.42875051498413 and batch: 250, loss is 4.323285698890686 and perplexity is 75.43608179081578
At time: 187.81629014015198 and batch: 300, loss is 4.313751497268677 and perplexity is 74.72027671468165
At time: 188.20359325408936 and batch: 350, loss is 4.317435064315796 and perplexity is 74.99602141399279
At time: 188.59163784980774 and batch: 400, loss is 4.174161381721497 and perplexity is 64.9853189268837
At time: 188.97931957244873 and batch: 450, loss is 4.232693099975586 and perplexity is 68.90254396973044
At time: 189.36799359321594 and batch: 500, loss is 4.229042325019837 and perplexity is 68.65145490153871
At time: 189.75573635101318 and batch: 550, loss is 4.266294484138489 and perplexity is 71.25710148439698
At time: 190.1433882713318 and batch: 600, loss is 4.177141442298889 and perplexity is 65.17926796032668
At time: 190.53125166893005 and batch: 650, loss is 4.271340026855468 and perplexity is 71.61754077508704
At time: 190.91850471496582 and batch: 700, loss is 4.319024429321289 and perplexity is 75.11531223919943
At time: 191.32114434242249 and batch: 750, loss is 4.271892476081848 and perplexity is 71.65711676093828
At time: 191.72038078308105 and batch: 800, loss is 4.212205595970154 and perplexity is 67.50526507651801
At time: 192.11137866973877 and batch: 850, loss is 4.155103225708007 and perplexity is 63.75854572915794
At time: 192.4995949268341 and batch: 900, loss is 4.09678427696228 and perplexity is 60.14656159595668
At time: 192.887268781662 and batch: 950, loss is 4.200924201011658 and perplexity is 66.74799110429447
At time: 193.27559995651245 and batch: 1000, loss is 4.247960557937622 and perplexity is 69.96258211644378
At time: 193.66399025917053 and batch: 1050, loss is 4.138388051986694 and perplexity is 62.701668114797705
At time: 194.05194282531738 and batch: 1100, loss is 4.275208787918091 and perplexity is 71.89514858112034
At time: 194.47259831428528 and batch: 1150, loss is 4.212501606941223 and perplexity is 67.5252503333673
At time: 194.86855816841125 and batch: 1200, loss is 4.150660991668701 and perplexity is 63.47594350436059
At time: 195.27605414390564 and batch: 1250, loss is 4.121504702568054 and perplexity is 61.65194033837619
At time: 195.67150211334229 and batch: 1300, loss is 4.209930629730224 and perplexity is 67.35186743084277
At time: 196.06116223335266 and batch: 1350, loss is 4.156900954246521 and perplexity is 63.87326937647954
At time: 196.4499855041504 and batch: 1400, loss is 4.047787594795227 and perplexity is 57.27061098192352
At time: 196.83785557746887 and batch: 1450, loss is 4.121340351104736 and perplexity is 61.641808584372306
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.7810444628071584 and perplexity of 119.22881509685033
Finished 16 epochs...
Completing Train Step...
At time: 198.1083652973175 and batch: 50, loss is 4.31054717540741 and perplexity is 74.48123209101767
At time: 198.51146388053894 and batch: 100, loss is 4.311409039497375 and perplexity is 74.54545246097337
At time: 198.9026918411255 and batch: 150, loss is 4.201468467712402 and perplexity is 66.78432970124125
At time: 199.29223823547363 and batch: 200, loss is 4.266733303070068 and perplexity is 71.2883773112484
At time: 199.6941921710968 and batch: 250, loss is 4.313143243789673 and perplexity is 74.67484166583189
At time: 200.0921802520752 and batch: 300, loss is 4.30513258934021 and perplexity is 74.07903689235003
At time: 200.48089265823364 and batch: 350, loss is 4.308961172103881 and perplexity is 74.36319823665384
At time: 200.8703248500824 and batch: 400, loss is 4.167756485939026 and perplexity is 64.57042482684051
At time: 201.25920510292053 and batch: 450, loss is 4.224598083496094 and perplexity is 68.34702822889764
At time: 201.66494035720825 and batch: 500, loss is 4.221434149742127 and perplexity is 68.13112449196956
At time: 202.06104373931885 and batch: 550, loss is 4.2597806978225705 and perplexity is 70.79445637334486
At time: 202.45077276229858 and batch: 600, loss is 4.17110842704773 and perplexity is 64.78722423466019
At time: 202.85772061347961 and batch: 650, loss is 4.266214780807495 and perplexity is 71.25142228238037
At time: 203.25601434707642 and batch: 700, loss is 4.313627815246582 and perplexity is 74.7110357312496
At time: 203.64778208732605 and batch: 750, loss is 4.266659035682678 and perplexity is 71.28308310631002
At time: 204.04845142364502 and batch: 800, loss is 4.207729802131653 and perplexity is 67.20380057676036
At time: 204.4595148563385 and batch: 850, loss is 4.1512035417556765 and perplexity is 63.51039172712784
At time: 204.84918403625488 and batch: 900, loss is 4.09359531879425 and perplexity is 59.95506223109519
At time: 205.2509319782257 and batch: 950, loss is 4.198223624229431 and perplexity is 66.56797621068479
At time: 205.64591479301453 and batch: 1000, loss is 4.245354323387146 and perplexity is 69.78048062037317
At time: 206.03513288497925 and batch: 1050, loss is 4.135841369628906 and perplexity is 62.54219003899939
At time: 206.42357850074768 and batch: 1100, loss is 4.273663549423218 and perplexity is 71.7841392199959
At time: 206.81334233283997 and batch: 1150, loss is 4.210804619789124 and perplexity is 67.4107580245737
At time: 207.2025318145752 and batch: 1200, loss is 4.149086637496948 and perplexity is 63.376088512085346
At time: 207.59238624572754 and batch: 1250, loss is 4.1213909530639645 and perplexity is 61.644927859577095
At time: 207.9930338859558 and batch: 1300, loss is 4.209191827774048 and perplexity is 67.30212611618555
At time: 208.41313672065735 and batch: 1350, loss is 4.1558049869537355 and perplexity is 63.80330470885645
At time: 208.810608625412 and batch: 1400, loss is 4.047670726776123 and perplexity is 57.26391827015479
At time: 209.20358610153198 and batch: 1450, loss is 4.120571131706238 and perplexity is 61.594410741457885
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.780838925614316 and perplexity of 119.20431165915954
Finished 17 epochs...
Completing Train Step...
At time: 210.5686707496643 and batch: 50, loss is 4.30469708442688 and perplexity is 74.04678213187178
At time: 210.96161794662476 and batch: 100, loss is 4.305301990509033 and perplexity is 74.09158703075894
At time: 211.34905219078064 and batch: 150, loss is 4.196150870323181 and perplexity is 66.43014007750354
At time: 211.73780822753906 and batch: 200, loss is 4.260770864486695 and perplexity is 70.86458940001302
At time: 212.14179348945618 and batch: 250, loss is 4.3074931621551515 and perplexity is 74.25411241095223
At time: 212.53301095962524 and batch: 300, loss is 4.299542827606201 and perplexity is 73.66610788918567
At time: 212.9221429824829 and batch: 350, loss is 4.303893775939941 and perplexity is 73.98732360832047
At time: 213.31302428245544 and batch: 400, loss is 4.1638385820388795 and perplexity is 64.3179390380763
At time: 213.71127080917358 and batch: 450, loss is 4.219131994247436 and perplexity is 67.97445645564528
At time: 214.09924125671387 and batch: 500, loss is 4.216464686393738 and perplexity is 67.79338924244082
At time: 214.5006582736969 and batch: 550, loss is 4.2554114627838135 and perplexity is 70.48581351161637
At time: 214.88813018798828 and batch: 600, loss is 4.166827502250672 and perplexity is 64.51046780928391
At time: 215.28476738929749 and batch: 650, loss is 4.262503399848938 and perplexity is 70.98747122489522
At time: 215.68355226516724 and batch: 700, loss is 4.309904708862304 and perplexity is 74.43339575942771
At time: 216.0890326499939 and batch: 750, loss is 4.262904863357544 and perplexity is 71.01597582555594
At time: 216.48513317108154 and batch: 800, loss is 4.204775438308716 and perplexity is 67.0055490972712
At time: 216.87294840812683 and batch: 850, loss is 4.148535575866699 and perplexity is 63.34117400233794
At time: 217.26024770736694 and batch: 900, loss is 4.09085527420044 and perplexity is 59.79100754817222
At time: 217.6637623310089 and batch: 950, loss is 4.195089855194092 and perplexity is 66.35969407260102
At time: 218.0670235157013 and batch: 1000, loss is 4.2427682781219485 and perplexity is 69.60025827087678
At time: 218.4612684249878 and batch: 1050, loss is 4.1332620334625245 and perplexity is 62.38108057336424
At time: 218.84976410865784 and batch: 1100, loss is 4.2717069816589355 and perplexity is 71.64382599813644
At time: 219.23762440681458 and batch: 1150, loss is 4.20876383304596 and perplexity is 67.27332732432383
At time: 219.63584804534912 and batch: 1200, loss is 4.147191214561462 and perplexity is 63.256077791823486
At time: 220.03808546066284 and batch: 1250, loss is 4.120408535003662 and perplexity is 61.584396507536994
At time: 220.43446397781372 and batch: 1300, loss is 4.207829856872559 and perplexity is 67.21052497201315
At time: 220.82389545440674 and batch: 1350, loss is 4.154067854881287 and perplexity is 63.69256615351388
At time: 221.21196341514587 and batch: 1400, loss is 4.046089444160462 and perplexity is 57.173439386885335
At time: 221.59994316101074 and batch: 1450, loss is 4.119097466468811 and perplexity is 61.50370804864592
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.7808937007545405 and perplexity of 119.2108412708746
Annealing...
Finished 18 epochs...
Completing Train Step...
At time: 222.87950325012207 and batch: 50, loss is 4.300622162818908 and perplexity is 73.74566123805585
At time: 223.26787042617798 and batch: 100, loss is 4.300026149749756 and perplexity is 73.7017209559566
At time: 223.656405210495 and batch: 150, loss is 4.190825548171997 and perplexity is 66.07731845923907
At time: 224.0535614490509 and batch: 200, loss is 4.254383878707886 and perplexity is 70.4134206133379
At time: 224.45495796203613 and batch: 250, loss is 4.3012039709091185 and perplexity is 73.7885795442803
At time: 224.8425714969635 and batch: 300, loss is 4.2930954074859615 and perplexity is 73.19267937925501
At time: 225.2309832572937 and batch: 350, loss is 4.295564270019531 and perplexity is 73.37360529180991
At time: 225.63176083564758 and batch: 400, loss is 4.1558242559432985 and perplexity is 63.80453414591394
At time: 226.02725887298584 and batch: 450, loss is 4.2115654945373535 and perplexity is 67.46206868613154
At time: 226.41882824897766 and batch: 500, loss is 4.2065392684936525 and perplexity is 67.12383979901455
At time: 226.81953382492065 and batch: 550, loss is 4.245312190055847 and perplexity is 69.77754059820185
At time: 227.20980644226074 and batch: 600, loss is 4.157287621498108 and perplexity is 63.8979718535109
At time: 227.59766697883606 and batch: 650, loss is 4.252721295356751 and perplexity is 70.29644969642331
At time: 227.98637104034424 and batch: 700, loss is 4.299158020019531 and perplexity is 73.6377660654136
At time: 228.37473106384277 and batch: 750, loss is 4.252216577529907 and perplexity is 70.26097877725333
At time: 228.76298069953918 and batch: 800, loss is 4.193153676986694 and perplexity is 66.23133418299801
At time: 229.15098667144775 and batch: 850, loss is 4.135944714546204 and perplexity is 62.54865379044875
At time: 229.53932523727417 and batch: 900, loss is 4.077714347839356 and perplexity is 59.01043825534154
At time: 229.9268400669098 and batch: 950, loss is 4.181359229087829 and perplexity is 65.45476079224431
At time: 230.314058303833 and batch: 1000, loss is 4.228611707687378 and perplexity is 68.6218987593099
At time: 230.7008922100067 and batch: 1050, loss is 4.1193381023406985 and perplexity is 61.518509827904616
At time: 231.0893108844757 and batch: 1100, loss is 4.258655400276184 and perplexity is 70.71483635179946
At time: 231.4779074192047 and batch: 1150, loss is 4.193473982810974 and perplexity is 66.25255186297849
At time: 231.86616349220276 and batch: 1200, loss is 4.1330895376205445 and perplexity is 62.370321024362525
At time: 232.2549307346344 and batch: 1250, loss is 4.105043692588806 and perplexity is 60.64539424399322
At time: 232.6438262462616 and batch: 1300, loss is 4.191050071716308 and perplexity is 66.09215603860875
At time: 233.0316960811615 and batch: 1350, loss is 4.136439204216003 and perplexity is 62.57959110206811
At time: 233.42004323005676 and batch: 1400, loss is 4.028165626525879 and perplexity is 56.15780232295676
At time: 233.80854153633118 and batch: 1450, loss is 4.101336936950684 and perplexity is 60.42101270763316
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.776080791766827 and perplexity of 118.63846883458416
Finished 19 epochs...
Completing Train Step...
At time: 235.09289622306824 and batch: 50, loss is 4.293414340019226 and perplexity is 73.2160266288067
At time: 235.5078785419464 and batch: 100, loss is 4.293570775985717 and perplexity is 73.22748114462077
At time: 235.89984464645386 and batch: 150, loss is 4.184149770736695 and perplexity is 65.63767011770216
At time: 236.34399247169495 and batch: 200, loss is 4.248650236129761 and perplexity is 70.01085042648234
At time: 236.73978638648987 and batch: 250, loss is 4.29554970741272 and perplexity is 73.37253678862584
At time: 237.12997221946716 and batch: 300, loss is 4.288375487327576 and perplexity is 72.84802977554426
At time: 237.52740454673767 and batch: 350, loss is 4.291181325912476 and perplexity is 73.05271661314879
At time: 237.93692803382874 and batch: 400, loss is 4.152494339942932 and perplexity is 63.5924237576494
At time: 238.33394074440002 and batch: 450, loss is 4.207190146446228 and perplexity is 67.16754344775977
At time: 238.72515892982483 and batch: 500, loss is 4.201963181495667 and perplexity is 66.81737700345445
At time: 239.11804819107056 and batch: 550, loss is 4.241909117698669 and perplexity is 69.54048616411147
At time: 239.508239030838 and batch: 600, loss is 4.153984990119934 and perplexity is 63.68728850288825
At time: 239.89777398109436 and batch: 650, loss is 4.249458937644959 and perplexity is 70.06749120695812
At time: 240.3045048713684 and batch: 700, loss is 4.296187000274658 and perplexity is 73.4193114855907
At time: 240.70378589630127 and batch: 750, loss is 4.249552350044251 and perplexity is 70.07403668513379
At time: 241.09928560256958 and batch: 800, loss is 4.190434489250183 and perplexity is 66.05148338617322
At time: 241.49076557159424 and batch: 850, loss is 4.133943777084351 and perplexity is 62.42362297702623
At time: 241.8820595741272 and batch: 900, loss is 4.075535960197449 and perplexity is 58.88203055755212
At time: 242.27249145507812 and batch: 950, loss is 4.179951009750366 and perplexity is 65.36265100298262
At time: 242.6630620956421 and batch: 1000, loss is 4.22672860622406 and perplexity is 68.49279835407151
At time: 243.07164907455444 and batch: 1050, loss is 4.118538570404053 and perplexity is 61.46934347225727
At time: 243.4803183078766 and batch: 1100, loss is 4.257772736549377 and perplexity is 70.65244646949832
At time: 243.880113363266 and batch: 1150, loss is 4.192896242141724 and perplexity is 66.21428612422677
At time: 244.2715404033661 and batch: 1200, loss is 4.132803654670715 and perplexity is 62.35249296149728
At time: 244.68358397483826 and batch: 1250, loss is 4.105239329338073 and perplexity is 60.65725987241979
At time: 245.07485127449036 and batch: 1300, loss is 4.1907227516174315 and perplexity is 66.07052628767843
At time: 245.46851468086243 and batch: 1350, loss is 4.13643581867218 and perplexity is 62.579379236478644
At time: 245.8609368801117 and batch: 1400, loss is 4.028396635055542 and perplexity is 56.17077675284481
At time: 246.25281238555908 and batch: 1450, loss is 4.1017106962203975 and perplexity is 60.4435998420306
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.775593553852831 and perplexity of 118.58067775465547
Finished 20 epochs...
Completing Train Step...
At time: 247.5555489063263 and batch: 50, loss is 4.290237393379211 and perplexity is 72.98379231235691
At time: 247.9599461555481 and batch: 100, loss is 4.290187511444092 and perplexity is 72.98015183036192
At time: 248.35004925727844 and batch: 150, loss is 4.180491156578064 and perplexity is 65.39796596834647
At time: 248.74030947685242 and batch: 200, loss is 4.245280346870422 and perplexity is 69.77531869441455
At time: 249.13011860847473 and batch: 250, loss is 4.292254385948181 and perplexity is 73.13114863745552
At time: 249.52010250091553 and batch: 300, loss is 4.285603609085083 and perplexity is 72.64638350536464
At time: 249.922865152359 and batch: 350, loss is 4.288497190475464 and perplexity is 72.8568961496073
At time: 250.32483911514282 and batch: 400, loss is 4.15078462600708 and perplexity is 63.48379179578787
At time: 250.72558283805847 and batch: 450, loss is 4.204670739173889 and perplexity is 66.99853404149367
At time: 251.11700582504272 and batch: 500, loss is 4.199082641601563 and perplexity is 66.62518382632739
At time: 251.50595092773438 and batch: 550, loss is 4.239672603607178 and perplexity is 69.38513167788197
At time: 251.8949797153473 and batch: 600, loss is 4.151952018737793 and perplexity is 63.5579455877258
At time: 252.28526163101196 and batch: 650, loss is 4.247343330383301 and perplexity is 69.91941260706592
At time: 252.6751537322998 and batch: 700, loss is 4.2942976379394535 and perplexity is 73.2807267633957
At time: 253.06588912010193 and batch: 750, loss is 4.247620015144348 and perplexity is 69.93876091960387
At time: 253.46760630607605 and batch: 800, loss is 4.188636374473572 and perplexity is 65.9328219532889
At time: 253.86621356010437 and batch: 850, loss is 4.132546753883362 and perplexity is 62.33647661435621
At time: 254.25580620765686 and batch: 900, loss is 4.07392294883728 and perplexity is 58.78712973198398
At time: 254.65887546539307 and batch: 950, loss is 4.178651690483093 and perplexity is 65.27777920089854
At time: 255.04881286621094 and batch: 1000, loss is 4.22511824131012 and perplexity is 68.38258871742754
At time: 255.45156574249268 and batch: 1050, loss is 4.117575402259827 and perplexity is 61.4101666619624
At time: 255.86105132102966 and batch: 1100, loss is 4.2570404624938964 and perplexity is 70.60072845418391
At time: 256.2599468231201 and batch: 1150, loss is 4.192134304046631 and perplexity is 66.16385415264938
At time: 256.6531312465668 and batch: 1200, loss is 4.13210422039032 and perplexity is 62.30889673857565
At time: 257.05245304107666 and batch: 1250, loss is 4.1045753765106205 and perplexity is 60.61699968013521
At time: 257.4448664188385 and batch: 1300, loss is 4.190471625328064 and perplexity is 66.05393632475032
At time: 257.8353760242462 and batch: 1350, loss is 4.136067757606506 and perplexity is 62.55635044172897
At time: 258.24645590782166 and batch: 1400, loss is 4.028121151924133 and perplexity is 56.15530478260252
At time: 258.64827060699463 and batch: 1450, loss is 4.101288132667541 and perplexity is 60.41806397537717
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.775563297108707 and perplexity of 118.57708994370866
Finished 21 epochs...
Completing Train Step...
At time: 260.00086736679077 and batch: 50, loss is 4.287751078605652 and perplexity is 72.80255702864476
At time: 260.4006898403168 and batch: 100, loss is 4.287580375671387 and perplexity is 72.79013047919236
At time: 260.7943637371063 and batch: 150, loss is 4.1776842021942135 and perplexity is 65.21465425524434
At time: 261.18536257743835 and batch: 200, loss is 4.242656016349793 and perplexity is 69.59244526110017
At time: 261.5865731239319 and batch: 250, loss is 4.289552326202393 and perplexity is 72.93381063416233
At time: 261.9845838546753 and batch: 300, loss is 4.283341670036316 and perplexity is 72.48224751654507
At time: 262.3756721019745 and batch: 350, loss is 4.286173334121704 and perplexity is 72.68778376112894
At time: 262.76803493499756 and batch: 400, loss is 4.149412360191345 and perplexity is 63.396734904712616
At time: 263.16694045066833 and batch: 450, loss is 4.202553701400757 and perplexity is 66.8568456469438
At time: 263.570693731308 and batch: 500, loss is 4.196772246360779 and perplexity is 66.47143100198895
At time: 263.97457671165466 and batch: 550, loss is 4.237662415504456 and perplexity is 69.24579460545999
At time: 264.37075686454773 and batch: 600, loss is 4.150200839042664 and perplexity is 63.44674160144828
At time: 264.7750151157379 and batch: 650, loss is 4.2455460596084595 and perplexity is 69.7938613487929
At time: 265.1660358905792 and batch: 700, loss is 4.29256118774414 and perplexity is 73.15358884737041
At time: 265.560081243515 and batch: 750, loss is 4.246190056800843 and perplexity is 69.83882287554168
At time: 265.9500324726105 and batch: 800, loss is 4.187075600624085 and perplexity is 65.82999599386936
At time: 266.3406105041504 and batch: 850, loss is 4.131266884803772 and perplexity is 62.25674511922834
At time: 266.73010873794556 and batch: 900, loss is 4.072360029220581 and perplexity is 58.695321936507064
At time: 267.12090706825256 and batch: 950, loss is 4.1774172735214234 and perplexity is 65.19724891723276
At time: 267.52551913261414 and batch: 1000, loss is 4.223721013069153 and perplexity is 68.2871093520473
At time: 267.92177391052246 and batch: 1050, loss is 4.116618957519531 and perplexity is 61.35145931070194
At time: 268.31164598464966 and batch: 1100, loss is 4.256386942863465 and perplexity is 70.55460456529131
At time: 268.70057559013367 and batch: 1150, loss is 4.191235332489014 and perplexity is 66.10440145676904
At time: 269.089341878891 and batch: 1200, loss is 4.131328859329224 and perplexity is 62.260603571024916
At time: 269.47869348526 and batch: 1250, loss is 4.1040263795852665 and perplexity is 60.58373026692502
At time: 269.868843793869 and batch: 1300, loss is 4.189765639305115 and perplexity is 66.00731962624933
At time: 270.25803780555725 and batch: 1350, loss is 4.135656008720398 and perplexity is 62.53059823620038
At time: 270.646737575531 and batch: 1400, loss is 4.0275682878494266 and perplexity is 56.124267112580945
At time: 271.0452606678009 and batch: 1450, loss is 4.100725698471069 and perplexity is 60.38409234441179
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.7753807133079595 and perplexity of 118.55544166431783
Finished 22 epochs...
Completing Train Step...
At time: 272.3250894546509 and batch: 50, loss is 4.285501799583435 and perplexity is 72.63898778974689
At time: 272.7129189968109 and batch: 100, loss is 4.285350513458252 and perplexity is 72.62799934996717
At time: 273.1028571128845 and batch: 150, loss is 4.175181083679199 and perplexity is 65.05161838091207
At time: 273.493079662323 and batch: 200, loss is 4.240378909111023 and perplexity is 69.4341560893388
At time: 273.89254236221313 and batch: 250, loss is 4.287262425422669 and perplexity is 72.76699051797544
At time: 274.28504514694214 and batch: 300, loss is 4.281455521583557 and perplexity is 72.34566408634393
At time: 274.68052673339844 and batch: 350, loss is 4.283938035964966 and perplexity is 72.5254863511983
At time: 275.09657979011536 and batch: 400, loss is 4.148093738555908 and perplexity is 63.313193690182544
At time: 275.48781728744507 and batch: 450, loss is 4.200610961914062 and perplexity is 66.72708629806692
At time: 275.87729239463806 and batch: 500, loss is 4.194621381759643 and perplexity is 66.32861359956627
At time: 276.26714754104614 and batch: 550, loss is 4.235848789215088 and perplexity is 69.12032242614917
At time: 276.6571755409241 and batch: 600, loss is 4.1486798620224 and perplexity is 63.350313916197955
At time: 277.0546247959137 and batch: 650, loss is 4.243664665222168 and perplexity is 69.66267501516558
At time: 277.44450402259827 and batch: 700, loss is 4.290824470520019 and perplexity is 73.0266520082158
At time: 277.8455514907837 and batch: 750, loss is 4.2447520446777345 and perplexity is 69.7384659760959
At time: 278.24081087112427 and batch: 800, loss is 4.185522799491882 and perplexity is 65.72785442485277
At time: 278.6411919593811 and batch: 850, loss is 4.130039920806885 and perplexity is 62.18040517716102
At time: 279.0335931777954 and batch: 900, loss is 4.071010084152221 and perplexity is 58.61613993382488
At time: 279.43736505508423 and batch: 950, loss is 4.176085019111634 and perplexity is 65.11044742852835
At time: 279.83316946029663 and batch: 1000, loss is 4.222419290542603 and perplexity is 68.19827631405789
At time: 280.22135305404663 and batch: 1050, loss is 4.115718874931336 and perplexity is 61.29626277486286
At time: 280.6111800670624 and batch: 1100, loss is 4.25563458442688 and perplexity is 70.5015421767775
At time: 280.99993348121643 and batch: 1150, loss is 4.190347495079041 and perplexity is 66.04573754205441
At time: 281.3894245624542 and batch: 1200, loss is 4.13051591873169 and perplexity is 62.210009966339
At time: 281.77685737609863 and batch: 1250, loss is 4.103357186317444 and perplexity is 60.54320160475722
At time: 282.1653428077698 and batch: 1300, loss is 4.189203124046326 and perplexity is 65.97019994294072
At time: 282.5550935268402 and batch: 1350, loss is 4.134961271286011 and perplexity is 62.48717097582955
At time: 282.94330883026123 and batch: 1400, loss is 4.026874809265137 and perplexity is 56.08535962759248
At time: 283.34805941581726 and batch: 1450, loss is 4.100119318962097 and perplexity is 60.34748776740059
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.775349934895833 and perplexity of 118.55179277222828
Finished 23 epochs...
Completing Train Step...
At time: 284.62356328964233 and batch: 50, loss is 4.283330826759339 and perplexity is 72.48146157572039
At time: 285.0267791748047 and batch: 100, loss is 4.283235449790954 and perplexity is 72.47454884331418
At time: 285.4168601036072 and batch: 150, loss is 4.172768278121948 and perplexity is 64.89485067562335
At time: 285.80702781677246 and batch: 200, loss is 4.238281736373901 and perplexity is 69.28869325382338
At time: 286.2016534805298 and batch: 250, loss is 4.285112075805664 and perplexity is 72.61068416466809
At time: 286.5919768810272 and batch: 300, loss is 4.27958553314209 and perplexity is 72.21050494311599
At time: 286.98161602020264 and batch: 350, loss is 4.281909971237183 and perplexity is 72.3785490200367
At time: 287.3712866306305 and batch: 400, loss is 4.146857371330261 and perplexity is 63.234963703014294
At time: 287.7606315612793 and batch: 450, loss is 4.198696346282959 and perplexity is 66.59945180011476
At time: 288.15084981918335 and batch: 500, loss is 4.192312130928039 and perplexity is 66.17562091068726
At time: 288.54825735092163 and batch: 550, loss is 4.23401786327362 and perplexity is 68.9938840197372
At time: 288.9550063610077 and batch: 600, loss is 4.147183089256287 and perplexity is 63.255563818975325
At time: 289.3760688304901 and batch: 650, loss is 4.24188862323761 and perplexity is 69.53906098392996
At time: 289.7967805862427 and batch: 700, loss is 4.2890456104278565 and perplexity is 72.89686328351021
At time: 290.2023401260376 and batch: 750, loss is 4.2433579158782955 and perplexity is 69.64130931243746
At time: 290.63086318969727 and batch: 800, loss is 4.18399115562439 and perplexity is 65.62725981692235
At time: 291.0392334461212 and batch: 850, loss is 4.128790755271911 and perplexity is 62.102780051472784
At time: 291.4462080001831 and batch: 900, loss is 4.069729981422424 and perplexity is 58.54115325864902
At time: 291.84660816192627 and batch: 950, loss is 4.1746739435195925 and perplexity is 65.01863645671976
At time: 292.24020862579346 and batch: 1000, loss is 4.221257472038269 and perplexity is 68.11908830462738
At time: 292.6320688724518 and batch: 1050, loss is 4.114632458686828 and perplexity is 61.22970568015755
At time: 293.0377538204193 and batch: 1100, loss is 4.254841623306274 and perplexity is 70.44565935426955
At time: 293.4592354297638 and batch: 1150, loss is 4.189308166503906 and perplexity is 65.97712997883741
At time: 293.87420868873596 and batch: 1200, loss is 4.129850440025329 and perplexity is 62.16862430155061
At time: 294.28738498687744 and batch: 1250, loss is 4.102557415962219 and perplexity is 60.49480030444584
At time: 294.6852078437805 and batch: 1300, loss is 4.188589315414429 and perplexity is 65.92971928972592
At time: 295.0755681991577 and batch: 1350, loss is 4.134402365684509 and perplexity is 62.452256303860885
At time: 295.4650731086731 and batch: 1400, loss is 4.026407828330994 and perplexity is 56.05917494831068
At time: 295.86556696891785 and batch: 1450, loss is 4.099370985031128 and perplexity is 60.302344587848715
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.775198129507212 and perplexity of 118.5337973371913
Finished 24 epochs...
Completing Train Step...
At time: 297.17926478385925 and batch: 50, loss is 4.281381034851075 and perplexity is 72.34027549490864
At time: 297.5826926231384 and batch: 100, loss is 4.281255559921265 and perplexity is 72.3311991733558
At time: 297.9729251861572 and batch: 150, loss is 4.170525288581848 and perplexity is 64.7494553254334
At time: 298.3849763870239 and batch: 200, loss is 4.236246552467346 and perplexity is 69.14782141907641
At time: 298.7815911769867 and batch: 250, loss is 4.283030967712403 and perplexity is 72.45973061200763
At time: 299.17538809776306 and batch: 300, loss is 4.277645740509033 and perplexity is 72.07056730647611
At time: 299.5660858154297 and batch: 350, loss is 4.280095405578614 and perplexity is 72.24733247708836
At time: 299.9568762779236 and batch: 400, loss is 4.14536862373352 and perplexity is 63.140892844028684
At time: 300.34584522247314 and batch: 450, loss is 4.196906752586365 and perplexity is 66.48037242460734
At time: 300.7466745376587 and batch: 500, loss is 4.190313901901245 and perplexity is 66.04351889311644
At time: 301.14003133773804 and batch: 550, loss is 4.232491374015808 and perplexity is 68.88864593976085
At time: 301.53097224235535 and batch: 600, loss is 4.145638861656189 and perplexity is 63.157958213497444
At time: 301.9276509284973 and batch: 650, loss is 4.24021324634552 and perplexity is 69.42265438774882
At time: 302.3327724933624 and batch: 700, loss is 4.287350225448608 and perplexity is 72.77337974211338
At time: 302.7275903224945 and batch: 750, loss is 4.241884341239929 and perplexity is 69.53876321846961
At time: 303.12967801094055 and batch: 800, loss is 4.182652397155762 and perplexity is 65.5394595518573
At time: 303.5248565673828 and batch: 850, loss is 4.127576766014099 and perplexity is 62.027433687701716
At time: 303.9152801036835 and batch: 900, loss is 4.06849937915802 and perplexity is 58.469156691543205
At time: 304.315869808197 and batch: 950, loss is 4.173291330337524 and perplexity is 64.92880294968073
At time: 304.7116005420685 and batch: 1000, loss is 4.219980340003968 and perplexity is 68.03214676453639
At time: 305.118780374527 and batch: 1050, loss is 4.113545961380005 and perplexity is 61.16321589686452
At time: 305.51216173171997 and batch: 1100, loss is 4.253713765144348 and perplexity is 70.3662514312493
At time: 305.9147992134094 and batch: 1150, loss is 4.188175106048584 and perplexity is 65.90241623748894
At time: 306.30630445480347 and batch: 1200, loss is 4.1290725994110105 and perplexity is 62.12028582288571
At time: 306.694931268692 and batch: 1250, loss is 4.101643495559692 and perplexity is 60.43953812866224
At time: 307.09776854515076 and batch: 1300, loss is 4.187669258117676 and perplexity is 65.86908806679713
At time: 307.49500703811646 and batch: 1350, loss is 4.133867583274841 and perplexity is 62.41886686458368
At time: 307.90306758880615 and batch: 1400, loss is 4.0255810832977295 and perplexity is 56.012847457003694
At time: 308.3096809387207 and batch: 1450, loss is 4.098554654121399 and perplexity is 60.253138007191474
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.775016589042468 and perplexity of 118.51228060967233
Finished 25 epochs...
Completing Train Step...
At time: 309.63531398773193 and batch: 50, loss is 4.279689440727234 and perplexity is 72.21800855214086
At time: 310.02781438827515 and batch: 100, loss is 4.279094099998474 and perplexity is 72.17502702589594
At time: 310.4255611896515 and batch: 150, loss is 4.168466100692749 and perplexity is 64.61626121411672
At time: 310.81521558761597 and batch: 200, loss is 4.2342149448394775 and perplexity is 69.00748278242308
At time: 311.21959805488586 and batch: 250, loss is 4.280780277252197 and perplexity is 72.29682957623976
At time: 311.6184649467468 and batch: 300, loss is 4.276105976104736 and perplexity is 71.95968100363922
At time: 312.00914216041565 and batch: 350, loss is 4.278240919113159 and perplexity is 72.11347493370835
At time: 312.3983461856842 and batch: 400, loss is 4.143990573883056 and perplexity is 63.05394147150996
At time: 312.8031928539276 and batch: 450, loss is 4.195115423202514 and perplexity is 66.3613907795086
At time: 313.1970372200012 and batch: 500, loss is 4.188342218399048 and perplexity is 65.91343026543203
At time: 313.5859491825104 and batch: 550, loss is 4.231055941581726 and perplexity is 68.78983188045866
At time: 313.9932954311371 and batch: 600, loss is 4.144236030578614 and perplexity is 63.069420383248975
At time: 314.3940041065216 and batch: 650, loss is 4.238776912689209 and perplexity is 69.32301186982299
At time: 314.80129837989807 and batch: 700, loss is 4.285963220596313 and perplexity is 72.67251267901666
At time: 315.2225651741028 and batch: 750, loss is 4.240369963645935 and perplexity is 69.43353497129769
At time: 315.6195924282074 and batch: 800, loss is 4.181425852775574 and perplexity is 65.45912177505949
At time: 316.0123248100281 and batch: 850, loss is 4.126411685943603 and perplexity is 61.95520884292173
At time: 316.4231843948364 and batch: 900, loss is 4.067277231216431 and perplexity is 58.39774238036187
At time: 316.8327555656433 and batch: 950, loss is 4.171920585632324 and perplexity is 64.8398631076573
At time: 317.226407289505 and batch: 1000, loss is 4.218767504692078 and perplexity is 67.94968499098036
At time: 317.6146502494812 and batch: 1050, loss is 4.112565054893493 and perplexity is 61.10324991697285
At time: 318.00289583206177 and batch: 1100, loss is 4.25287805557251 and perplexity is 70.30747024681419
At time: 318.392671585083 and batch: 1150, loss is 4.1869413900375365 and perplexity is 65.82116150434882
At time: 318.7904415130615 and batch: 1200, loss is 4.128302431106567 and perplexity is 62.072461166563166
At time: 319.1857786178589 and batch: 1250, loss is 4.100780272483826 and perplexity is 60.387387836561004
At time: 319.5750870704651 and batch: 1300, loss is 4.186868181228638 and perplexity is 65.8163429918957
At time: 319.9646167755127 and batch: 1350, loss is 4.1329810380935665 and perplexity is 62.36355424113694
At time: 320.3539159297943 and batch: 1400, loss is 4.0249131345748905 and perplexity is 55.97544623952051
At time: 320.7559471130371 and batch: 1450, loss is 4.0976762866973875 and perplexity is 60.20023685029918
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.774980072282318 and perplexity of 118.50795300416203
Finished 26 epochs...
Completing Train Step...
At time: 322.0766885280609 and batch: 50, loss is 4.27791476726532 and perplexity is 72.0899588257241
At time: 322.46801137924194 and batch: 100, loss is 4.277257256507873 and perplexity is 72.04257448185732
At time: 322.85957169532776 and batch: 150, loss is 4.166454839706421 and perplexity is 64.486431653185
At time: 323.2629563808441 and batch: 200, loss is 4.232301535606385 and perplexity is 68.87556947003569
At time: 323.6578862667084 and batch: 250, loss is 4.278991484642029 and perplexity is 72.16762113975658
At time: 324.0568997859955 and batch: 300, loss is 4.274452080726624 and perplexity is 71.840765583755
At time: 324.44758653640747 and batch: 350, loss is 4.276423301696777 and perplexity is 71.9825192754092
At time: 324.87346720695496 and batch: 400, loss is 4.142680897712707 and perplexity is 62.971415280007456
At time: 325.2754747867584 and batch: 450, loss is 4.193569173812866 and perplexity is 66.2588588099458
At time: 325.68624544143677 and batch: 500, loss is 4.186456141471862 and perplexity is 65.78922962821295
At time: 326.09827733039856 and batch: 550, loss is 4.229627223014831 and perplexity is 68.69162074517972
At time: 326.4959456920624 and batch: 600, loss is 4.142351365089416 and perplexity is 62.95066756305044
At time: 326.8900682926178 and batch: 650, loss is 4.237075414657593 and perplexity is 69.20515919306241
At time: 327.28764486312866 and batch: 700, loss is 4.28441752910614 and perplexity is 72.56027016309714
At time: 327.6903941631317 and batch: 750, loss is 4.238760786056519 and perplexity is 69.32189393208787
At time: 328.0940363407135 and batch: 800, loss is 4.179978713989258 and perplexity is 65.3644618505646
At time: 328.5037033557892 and batch: 850, loss is 4.125131802558899 and perplexity is 61.87596412334532
At time: 328.90155959129333 and batch: 900, loss is 4.065839719772339 and perplexity is 58.313855266169945
At time: 329.2921268939972 and batch: 950, loss is 4.170483727455139 and perplexity is 64.74676432103725
At time: 329.69230914115906 and batch: 1000, loss is 4.217504920959473 and perplexity is 67.86394696118566
At time: 330.09318685531616 and batch: 1050, loss is 4.111569838523865 and perplexity is 61.04246921241076
At time: 330.5026259422302 and batch: 1100, loss is 4.251790437698364 and perplexity is 70.23104415421376
At time: 330.90251302719116 and batch: 1150, loss is 4.1857963514328 and perplexity is 65.74583686645681
At time: 331.29638504981995 and batch: 1200, loss is 4.127477965354919 and perplexity is 62.02130563909878
At time: 331.69994497299194 and batch: 1250, loss is 4.099884099960327 and perplexity is 60.33329456089001
At time: 332.1109824180603 and batch: 1300, loss is 4.186107587814331 and perplexity is 65.76630254749091
At time: 332.5188412666321 and batch: 1350, loss is 4.132287201881408 and perplexity is 62.32029915659284
At time: 332.91720390319824 and batch: 1400, loss is 4.024131865501404 and perplexity is 55.9317314332356
At time: 333.3200786113739 and batch: 1450, loss is 4.09685546875 and perplexity is 60.15084368962506
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.774877303685898 and perplexity of 118.49577473394973
Finished 27 epochs...
Completing Train Step...
At time: 334.60444831848145 and batch: 50, loss is 4.276350407600403 and perplexity is 71.97727236594858
At time: 335.0087397098541 and batch: 100, loss is 4.275471954345703 and perplexity is 71.91407146035915
At time: 335.3980059623718 and batch: 150, loss is 4.16461341381073 and perplexity is 64.3677939328269
At time: 335.80140137672424 and batch: 200, loss is 4.230442199707031 and perplexity is 68.74762563327592
At time: 336.1961979866028 and batch: 250, loss is 4.277169470787048 and perplexity is 72.03625045011024
At time: 336.5953392982483 and batch: 300, loss is 4.273017716407776 and perplexity is 71.73779362027264
At time: 336.9942629337311 and batch: 350, loss is 4.274813594818116 and perplexity is 71.86674172794527
At time: 337.40245389938354 and batch: 400, loss is 4.141597285270691 and perplexity is 62.90321562858748
At time: 337.8071343898773 and batch: 450, loss is 4.1920446681976316 and perplexity is 66.15792376520098
At time: 338.20537996292114 and batch: 500, loss is 4.18477723121643 and perplexity is 65.67886808537958
At time: 338.5953698158264 and batch: 550, loss is 4.2281722688674925 and perplexity is 68.59175025779693
At time: 338.98444986343384 and batch: 600, loss is 4.140954751968383 and perplexity is 62.86281119970954
At time: 339.37986040115356 and batch: 650, loss is 4.235585751533509 and perplexity is 69.10214356775539
At time: 339.77192187309265 and batch: 700, loss is 4.28302909374237 and perplexity is 72.45959482477113
At time: 340.17606830596924 and batch: 750, loss is 4.237434620857239 and perplexity is 69.2300225805662
At time: 340.58179473876953 and batch: 800, loss is 4.178608417510986 and perplexity is 65.27495449849705
At time: 340.99089884757996 and batch: 850, loss is 4.12402804851532 and perplexity is 61.80770595478835
At time: 341.39016127586365 and batch: 900, loss is 4.064721126556396 and perplexity is 58.248662252302985
At time: 341.7799572944641 and batch: 950, loss is 4.169194827079773 and perplexity is 64.66336594984166
At time: 342.1706647872925 and batch: 1000, loss is 4.216397514343262 and perplexity is 67.78883557441803
At time: 342.5602629184723 and batch: 1050, loss is 4.110613436698913 and perplexity is 60.98411599246749
At time: 342.9498748779297 and batch: 1100, loss is 4.251049203872681 and perplexity is 70.17900581734393
At time: 343.3510675430298 and batch: 1150, loss is 4.184677519798279 and perplexity is 65.67231947879104
At time: 343.74888801574707 and batch: 1200, loss is 4.126671452522277 and perplexity is 61.97130482606262
At time: 344.13793540000916 and batch: 1250, loss is 4.099033365249634 and perplexity is 60.281988759903804
At time: 344.5278046131134 and batch: 1300, loss is 4.1853115320205685 and perplexity is 65.71396973399696
At time: 344.91708111763 and batch: 1350, loss is 4.131566281318665 and perplexity is 62.275387362317666
At time: 345.3170027732849 and batch: 1400, loss is 4.023355960845947 and perplexity is 55.888350574310394
At time: 345.74725914001465 and batch: 1450, loss is 4.095993824005127 and perplexity is 60.099037353793946
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.7748152251936435 and perplexity of 118.48841892323694
Finished 28 epochs...
Completing Train Step...
At time: 347.0961124897003 and batch: 50, loss is 4.274866724014283 and perplexity is 71.87056005159575
At time: 347.50232911109924 and batch: 100, loss is 4.273804202079773 and perplexity is 71.79423655996787
At time: 347.90060353279114 and batch: 150, loss is 4.162906031608582 and perplexity is 64.25798727471661
At time: 348.30002880096436 and batch: 200, loss is 4.228670878410339 and perplexity is 68.62595928680145
At time: 348.70630502700806 and batch: 250, loss is 4.275401544570923 and perplexity is 71.90900818503822
At time: 349.11555075645447 and batch: 300, loss is 4.271440935134888 and perplexity is 71.62476794253729
At time: 349.52549743652344 and batch: 350, loss is 4.273243970870972 and perplexity is 71.75402645256518
At time: 349.9454622268677 and batch: 400, loss is 4.140402116775513 and perplexity is 62.82808059547879
At time: 350.35623002052307 and batch: 450, loss is 4.190454716682434 and perplexity is 66.05281945159102
At time: 350.75338768959045 and batch: 500, loss is 4.183163104057312 and perplexity is 65.57293955468086
At time: 351.1467549800873 and batch: 550, loss is 4.226678342819214 and perplexity is 68.48935575933778
At time: 351.5356605052948 and batch: 600, loss is 4.139480895996094 and perplexity is 62.77022871337253
At time: 351.9244222640991 and batch: 650, loss is 4.234155564308167 and perplexity is 69.00338520309047
At time: 352.3138265609741 and batch: 700, loss is 4.281600427627564 and perplexity is 72.35614816991291
At time: 352.70290446281433 and batch: 750, loss is 4.236197271347046 and perplexity is 69.14441382093638
At time: 353.1024417877197 and batch: 800, loss is 4.177292385101318 and perplexity is 65.1891070442437
At time: 353.50899028778076 and batch: 850, loss is 4.122806358337402 and perplexity is 61.732242193557674
At time: 353.906672000885 and batch: 900, loss is 4.063611888885498 and perplexity is 58.18408646342338
At time: 354.2968852519989 and batch: 950, loss is 4.167841634750366 and perplexity is 64.57592315584702
At time: 354.686546087265 and batch: 1000, loss is 4.215392241477966 and perplexity is 67.72072353877171
At time: 355.07614183425903 and batch: 1050, loss is 4.10974395275116 and perplexity is 60.93111432793146
At time: 355.4881784915924 and batch: 1100, loss is 4.250224933624268 and perplexity is 70.12118318479719
At time: 355.9101197719574 and batch: 1150, loss is 4.183490805625915 and perplexity is 65.59443143109935
At time: 356.3065571784973 and batch: 1200, loss is 4.1258004903793335 and perplexity is 61.91735366373076
At time: 356.69680309295654 and batch: 1250, loss is 4.098231897354126 and perplexity is 60.233694037155495
At time: 357.1023018360138 and batch: 1300, loss is 4.18440242767334 and perplexity is 65.65425602554673
At time: 357.5035972595215 and batch: 1350, loss is 4.1309579706192014 and perplexity is 62.23751609778749
At time: 357.9142220020294 and batch: 1400, loss is 4.0224578046798705 and perplexity is 55.83817664301598
At time: 358.32580828666687 and batch: 1450, loss is 4.095091638565063 and perplexity is 60.04484132843999
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.774793836805555 and perplexity of 118.4858846740509
Finished 29 epochs...
Completing Train Step...
At time: 359.65105724334717 and batch: 50, loss is 4.273336896896362 and perplexity is 71.76069457886561
At time: 360.0489299297333 and batch: 100, loss is 4.272144412994384 and perplexity is 71.67517210800499
At time: 360.4393434524536 and batch: 150, loss is 4.161208696365357 and perplexity is 64.14901243783471
At time: 360.829354763031 and batch: 200, loss is 4.226955714225769 and perplexity is 68.50835538313324
At time: 361.2204236984253 and batch: 250, loss is 4.273782720565796 and perplexity is 71.79269432763658
At time: 361.6094660758972 and batch: 300, loss is 4.270006799697876 and perplexity is 71.52212194638649
At time: 362.0030767917633 and batch: 350, loss is 4.271651124954223 and perplexity is 71.63982432186447
At time: 362.39456486701965 and batch: 400, loss is 4.1391513586044315 and perplexity is 62.749546983817034
At time: 362.78290462493896 and batch: 450, loss is 4.188927206993103 and perplexity is 65.95200015070392
At time: 363.17199969291687 and batch: 500, loss is 4.181643652915954 and perplexity is 65.47338033367296
At time: 363.58423495292664 and batch: 550, loss is 4.225420417785645 and perplexity is 68.40325544941633
At time: 363.9965982437134 and batch: 600, loss is 4.1381165361404415 and perplexity is 62.684645929319196
At time: 364.4033143520355 and batch: 650, loss is 4.23264527797699 and perplexity is 68.89924899115628
At time: 364.7913272380829 and batch: 700, loss is 4.280147652626038 and perplexity is 72.25110728550503
At time: 365.19021916389465 and batch: 750, loss is 4.2350119829177855 and perplexity is 69.06250629889487
At time: 365.5828733444214 and batch: 800, loss is 4.176146326065063 and perplexity is 65.11443927405931
At time: 365.9989333152771 and batch: 850, loss is 4.121581130027771 and perplexity is 61.65665241962676
At time: 366.39291429519653 and batch: 900, loss is 4.062451362609863 and perplexity is 58.116601468887616
At time: 366.78188157081604 and batch: 950, loss is 4.1666837453842165 and perplexity is 64.50119465313398
At time: 367.18480372428894 and batch: 1000, loss is 4.214168572425843 and perplexity is 67.63790646586841
At time: 367.5808219909668 and batch: 1050, loss is 4.1086370420455935 and perplexity is 60.86370633937453
At time: 367.98024892807007 and batch: 1100, loss is 4.249327373504639 and perplexity is 70.05827344408992
At time: 368.37629103660583 and batch: 1150, loss is 4.182439641952515 and perplexity is 65.52551717402896
At time: 368.77925205230713 and batch: 1200, loss is 4.124924283027649 and perplexity is 61.86312498450693
At time: 369.1738512516022 and batch: 1250, loss is 4.097313504219056 and perplexity is 60.17840122020995
At time: 369.56361198425293 and batch: 1300, loss is 4.183302750587464 and perplexity is 65.58209722756527
At time: 369.9690730571747 and batch: 1350, loss is 4.130272464752197 and perplexity is 62.1948665352875
At time: 370.3708498477936 and batch: 1400, loss is 4.021474885940552 and perplexity is 55.78331921743657
At time: 370.77103900909424 and batch: 1450, loss is 4.094236102104187 and perplexity is 59.993492745820326
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.774812616853633 and perplexity of 118.48810986555611
Annealing...
Finished 30 epochs...
Completing Train Step...
At time: 372.0583484172821 and batch: 50, loss is 4.272200875282287 and perplexity is 71.67921916646006
At time: 372.4484746456146 and batch: 100, loss is 4.270580735206604 and perplexity is 71.56318281384887
At time: 372.83782625198364 and batch: 150, loss is 4.15908251285553 and perplexity is 64.0127647605275
At time: 373.2440276145935 and batch: 200, loss is 4.224783344268799 and perplexity is 68.35969142511995
At time: 373.6409728527069 and batch: 250, loss is 4.271626749038696 and perplexity is 71.63807805684192
At time: 374.03000569343567 and batch: 300, loss is 4.267483768463134 and perplexity is 71.34189685111775
At time: 374.4220163822174 and batch: 350, loss is 4.2678611469268795 and perplexity is 71.36882482725164
At time: 374.8127920627594 and batch: 400, loss is 4.135470490455628 and perplexity is 62.51899874411267
At time: 375.20308351516724 and batch: 450, loss is 4.185378651618958 and perplexity is 65.71838057727943
At time: 375.59276509284973 and batch: 500, loss is 4.176878733634949 and perplexity is 65.16214705092831
At time: 375.98181438446045 and batch: 550, loss is 4.220245127677917 and perplexity is 68.05016322359485
At time: 376.3850622177124 and batch: 600, loss is 4.133630418777466 and perplexity is 62.40406508069521
At time: 376.7872438430786 and batch: 650, loss is 4.22765971660614 and perplexity is 68.55660240941621
At time: 377.18060755729675 and batch: 700, loss is 4.274938640594482 and perplexity is 71.8757289223532
At time: 377.57008504867554 and batch: 750, loss is 4.229281821250916 and perplexity is 68.66789863527326
At time: 377.97085547447205 and batch: 800, loss is 4.169904298782349 and perplexity is 64.70925905618152
At time: 378.36938285827637 and batch: 850, loss is 4.115219898223877 and perplexity is 61.26568499691787
At time: 378.76385617256165 and batch: 900, loss is 4.0556290292739865 and perplexity is 57.72146006712561
At time: 379.15482807159424 and batch: 950, loss is 4.158966851234436 and perplexity is 64.00536136853701
At time: 379.5455513000488 and batch: 1000, loss is 4.206585807800293 and perplexity is 67.12696376867096
At time: 379.9370639324188 and batch: 1050, loss is 4.101059918403625 and perplexity is 60.40427728459939
At time: 380.3438973426819 and batch: 1100, loss is 4.242401852607727 and perplexity is 69.57475963241107
At time: 380.75221490859985 and batch: 1150, loss is 4.173573818206787 and perplexity is 64.94714713976336
At time: 381.1524267196655 and batch: 1200, loss is 4.117568445205689 and perplexity is 61.409739429594445
At time: 381.5530676841736 and batch: 1250, loss is 4.088670611381531 and perplexity is 59.66052693704245
At time: 381.9719817638397 and batch: 1300, loss is 4.173687710762024 and perplexity is 64.95454455755385
At time: 382.3720512390137 and batch: 1350, loss is 4.121435623168946 and perplexity is 61.64768160648076
At time: 382.7656228542328 and batch: 1400, loss is 4.0111179494857785 and perplexity is 55.2085564534824
At time: 383.1562864780426 and batch: 1450, loss is 4.084320616722107 and perplexity is 59.401567607683134
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.771920489449786 and perplexity of 118.14592221963414
Finished 31 epochs...
Completing Train Step...
At time: 384.45797324180603 and batch: 50, loss is 4.268519592285156 and perplexity is 71.41583277306833
At time: 384.86787700653076 and batch: 100, loss is 4.267724099159241 and perplexity is 71.35904455932734
At time: 385.2608845233917 and batch: 150, loss is 4.1564115619659425 and perplexity is 63.84201793924118
At time: 385.66918182373047 and batch: 200, loss is 4.2223239469528195 and perplexity is 68.19177435554204
At time: 386.08357095718384 and batch: 250, loss is 4.269098515510559 and perplexity is 71.45718902721511
At time: 386.49589252471924 and batch: 300, loss is 4.265657410621643 and perplexity is 71.21171992938243
At time: 386.894731760025 and batch: 350, loss is 4.266003761291504 and perplexity is 71.23638842801081
At time: 387.2926959991455 and batch: 400, loss is 4.133866539001465 and perplexity is 62.41880168225687
At time: 387.70342683792114 and batch: 450, loss is 4.183234181404114 and perplexity is 65.57760047088722
At time: 388.10959005355835 and batch: 500, loss is 4.175114598274231 and perplexity is 65.04729354149113
At time: 388.5120949745178 and batch: 550, loss is 4.218896698951721 and perplexity is 67.9584642673296
At time: 388.9242134094238 and batch: 600, loss is 4.132382020950318 and perplexity is 62.326208589492055
At time: 389.3268060684204 and batch: 650, loss is 4.2266183185577395 and perplexity is 68.48524485971758
At time: 389.7264106273651 and batch: 700, loss is 4.273744468688965 and perplexity is 71.78994817485885
At time: 390.1229147911072 and batch: 750, loss is 4.228140444755554 and perplexity is 68.58956742099227
At time: 390.5253789424896 and batch: 800, loss is 4.169008994102478 and perplexity is 64.65135048049513
At time: 390.93066334724426 and batch: 850, loss is 4.114390592575074 and perplexity is 61.214898080121316
At time: 391.3266530036926 and batch: 900, loss is 4.054681825637817 and perplexity is 57.666811975786274
At time: 391.72990107536316 and batch: 950, loss is 4.158349785804749 and perplexity is 63.96587805586831
At time: 392.14017486572266 and batch: 1000, loss is 4.2060160779953 and perplexity is 67.08873042906401
At time: 392.5465953350067 and batch: 1050, loss is 4.100883054733276 and perplexity is 60.39359490710414
At time: 392.9479639530182 and batch: 1100, loss is 4.242160010337829 and perplexity is 69.55793554908325
At time: 393.33790349960327 and batch: 1150, loss is 4.173217821121216 and perplexity is 64.92403025968055
At time: 393.73718333244324 and batch: 1200, loss is 4.117495889663696 and perplexity is 61.40528397430246
At time: 394.1305694580078 and batch: 1250, loss is 4.088544898033142 and perplexity is 59.65302728384768
At time: 394.5206093788147 and batch: 1300, loss is 4.17377140045166 and perplexity is 64.95998081070432
At time: 394.91156220436096 and batch: 1350, loss is 4.121527686119079 and perplexity is 61.6533573351765
At time: 395.3042666912079 and batch: 1400, loss is 4.011299839019776 and perplexity is 55.21859922539824
At time: 395.7325623035431 and batch: 1450, loss is 4.084682016372681 and perplexity is 59.42303919313813
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.771720168936966 and perplexity of 118.12225753824718
Finished 32 epochs...
Completing Train Step...
At time: 397.0844507217407 and batch: 50, loss is 4.2668461561203 and perplexity is 71.29642287604877
At time: 397.5038278102875 and batch: 100, loss is 4.266189217567444 and perplexity is 71.24960088844907
At time: 397.8965313434601 and batch: 150, loss is 4.1549496698379516 and perplexity is 63.74875598185082
At time: 398.2860972881317 and batch: 200, loss is 4.221041369438171 and perplexity is 68.10436918300594
At time: 398.67600560188293 and batch: 250, loss is 4.267725133895874 and perplexity is 71.35911839718307
At time: 399.07864904403687 and batch: 300, loss is 4.264493508338928 and perplexity is 71.12888466143046
At time: 399.4737765789032 and batch: 350, loss is 4.264820251464844 and perplexity is 71.15212933285915
At time: 399.8729965686798 and batch: 400, loss is 4.132799777984619 and perplexity is 62.35225124092333
At time: 400.277152299881 and batch: 450, loss is 4.181830458641052 and perplexity is 65.48561227842387
At time: 400.6760106086731 and batch: 500, loss is 4.173932452201843 and perplexity is 64.97044357180613
At time: 401.0694682598114 and batch: 550, loss is 4.217959189414978 and perplexity is 67.8947824148129
At time: 401.459614276886 and batch: 600, loss is 4.131472845077514 and perplexity is 62.26956885604026
At time: 401.8638377189636 and batch: 650, loss is 4.225814137458801 and perplexity is 68.4301924592621
At time: 402.2690620422363 and batch: 700, loss is 4.272947106361389 and perplexity is 71.73272839016761
At time: 402.66668128967285 and batch: 750, loss is 4.227224526405334 and perplexity is 68.52677373889043
At time: 403.05529618263245 and batch: 800, loss is 4.168400340080261 and perplexity is 64.61201214891469
At time: 403.4540042877197 and batch: 850, loss is 4.113794875144959 and perplexity is 61.17844215814447
At time: 403.86111521720886 and batch: 900, loss is 4.053821997642517 and perplexity is 57.617249746999164
At time: 404.27265644073486 and batch: 950, loss is 4.157605099678039 and perplexity is 63.91826128587186
At time: 404.6683111190796 and batch: 1000, loss is 4.205436210632325 and perplexity is 67.04983914084887
At time: 405.05811524391174 and batch: 1050, loss is 4.100594544410706 and perplexity is 60.37617324484186
At time: 405.448091506958 and batch: 1100, loss is 4.241840801239014 and perplexity is 69.53573556656785
At time: 405.8377695083618 and batch: 1150, loss is 4.172831897735596 and perplexity is 64.89897939228332
At time: 406.22722578048706 and batch: 1200, loss is 4.117324795722961 and perplexity is 61.39477880099672
At time: 406.6315598487854 and batch: 1250, loss is 4.088314547538757 and perplexity is 59.63928776203487
At time: 407.0213825702667 and batch: 1300, loss is 4.173615803718567 and perplexity is 64.94987403621936
At time: 407.40956449508667 and batch: 1350, loss is 4.121542944908142 and perplexity is 61.6542980979285
At time: 407.8160698413849 and batch: 1400, loss is 4.0112489891052245 and perplexity is 55.21579143573454
At time: 408.21582794189453 and batch: 1450, loss is 4.084703574180603 and perplexity is 59.42432023741139
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.771707648904915 and perplexity of 118.12077865305471
Finished 33 epochs...
Completing Train Step...
At time: 409.5616464614868 and batch: 50, loss is 4.2655558681488035 and perplexity is 71.20448928236073
At time: 409.9559302330017 and batch: 100, loss is 4.2650484848022465 and perplexity is 71.16837047411452
At time: 410.3472764492035 and batch: 150, loss is 4.153796911239624 and perplexity is 63.67531139533245
At time: 410.7384750843048 and batch: 200, loss is 4.220111155509949 and perplexity is 68.04104700637052
At time: 411.1365432739258 and batch: 250, loss is 4.266656785011292 and perplexity is 71.2829226716951
At time: 411.5272798538208 and batch: 300, loss is 4.263642644882202 and perplexity is 71.06838943299367
At time: 411.9343945980072 and batch: 350, loss is 4.263835105895996 and perplexity is 71.08206864358782
At time: 412.34264278411865 and batch: 400, loss is 4.131958522796631 and perplexity is 62.29981914356333
At time: 412.75932240486145 and batch: 450, loss is 4.180715317726135 and perplexity is 65.41262729466793
At time: 413.1517927646637 and batch: 500, loss is 4.17303493976593 and perplexity is 64.91215795068113
At time: 413.54248571395874 and batch: 550, loss is 4.217266874313355 and perplexity is 67.8477940988628
At time: 413.94307589530945 and batch: 600, loss is 4.130822916030883 and perplexity is 62.22911120324552
At time: 414.3387768268585 and batch: 650, loss is 4.225197005271911 and perplexity is 68.38797501315271
At time: 414.72923946380615 and batch: 700, loss is 4.272240738868714 and perplexity is 71.68207661416196
At time: 415.1353340148926 and batch: 750, loss is 4.226534767150879 and perplexity is 68.47952306019589
At time: 415.5364010334015 and batch: 800, loss is 4.167837557792663 and perplexity is 64.57565988307637
At time: 415.929475069046 and batch: 850, loss is 4.113211436271667 and perplexity is 61.14275868735623
At time: 416.32089352607727 and batch: 900, loss is 4.05317723274231 and perplexity is 57.580112140514956
At time: 416.7259979248047 and batch: 950, loss is 4.15708143234253 and perplexity is 63.88479814283605
At time: 417.1323220729828 and batch: 1000, loss is 4.204947986602783 and perplexity is 67.01711178799356
At time: 417.53491497039795 and batch: 1050, loss is 4.100268168449402 and perplexity is 60.35647112858266
At time: 417.9265925884247 and batch: 1100, loss is 4.241542959213257 and perplexity is 69.51502798617118
At time: 418.3287003040314 and batch: 1150, loss is 4.172419219017029 and perplexity is 64.8722024901403
At time: 418.7436845302582 and batch: 1200, loss is 4.117084550857544 and perplexity is 61.38003079226396
At time: 419.1522259712219 and batch: 1250, loss is 4.088034138679505 and perplexity is 59.62256672186036
At time: 419.55225110054016 and batch: 1300, loss is 4.173401455879212 and perplexity is 64.93595366300755
At time: 419.9461667537689 and batch: 1350, loss is 4.121420397758484 and perplexity is 61.6467430023696
At time: 420.33664631843567 and batch: 1400, loss is 4.011042008399963 and perplexity is 55.20436401495021
At time: 420.72749638557434 and batch: 1450, loss is 4.08452702999115 and perplexity is 59.41383014497095
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.772893400273771 and perplexity of 118.260923600144
Annealing...
Finished 34 epochs...
Completing Train Step...
At time: 422.03069376945496 and batch: 50, loss is 4.26460036277771 and perplexity is 71.1364855045668
At time: 422.4288156032562 and batch: 100, loss is 4.264160304069519 and perplexity is 71.1051881614897
At time: 422.8268508911133 and batch: 150, loss is 4.1526975917816165 and perplexity is 63.60535034833668
At time: 423.23636269569397 and batch: 200, loss is 4.219179725646972 and perplexity is 67.97770104901848
At time: 423.63790249824524 and batch: 250, loss is 4.265646677017212 and perplexity is 71.210955575052
At time: 424.0290789604187 and batch: 300, loss is 4.262606506347656 and perplexity is 70.9947908718512
At time: 424.41901659965515 and batch: 350, loss is 4.261916913986206 and perplexity is 70.94585028283083
At time: 424.8083276748657 and batch: 400, loss is 4.129953384399414 and perplexity is 62.175024541095716
At time: 425.1978290081024 and batch: 450, loss is 4.17864052772522 and perplexity is 65.27705052492182
At time: 425.6108100414276 and batch: 500, loss is 4.17061399936676 and perplexity is 64.75519955522178
At time: 426.0093882083893 and batch: 550, loss is 4.214430303573608 and perplexity is 67.65561172966862
At time: 426.4116418361664 and batch: 600, loss is 4.128491101264953 and perplexity is 62.08417349249133
At time: 426.80621242523193 and batch: 650, loss is 4.222859354019165 and perplexity is 68.22829448909499
At time: 427.2093086242676 and batch: 700, loss is 4.269548840522766 and perplexity is 71.48937523331898
At time: 427.5990192890167 and batch: 750, loss is 4.2236422920227055 and perplexity is 68.28173393092239
At time: 427.99968910217285 and batch: 800, loss is 4.164432249069214 and perplexity is 64.35613381431017
At time: 428.39783096313477 and batch: 850, loss is 4.10992398262024 and perplexity is 60.94208473593774
At time: 428.7923548221588 and batch: 900, loss is 4.0496872663497925 and perplexity is 57.379509735701866
At time: 429.1813495159149 and batch: 950, loss is 4.152902684211731 and perplexity is 63.61839666201226
At time: 429.56967306137085 and batch: 1000, loss is 4.201340589523316 and perplexity is 66.77578998813284
At time: 429.95767879486084 and batch: 1050, loss is 4.096093578338623 and perplexity is 60.10503279223942
At time: 430.34911251068115 and batch: 1100, loss is 4.238209204673767 and perplexity is 69.28366780935585
At time: 430.7561101913452 and batch: 1150, loss is 4.1677826976776124 and perplexity is 64.57211735211843
At time: 431.16133856773376 and batch: 1200, loss is 4.113252425193787 and perplexity is 61.145264914493666
At time: 431.56859612464905 and batch: 1250, loss is 4.083497819900512 and perplexity is 59.35271228841472
At time: 431.9716250896454 and batch: 1300, loss is 4.168393692970276 and perplexity is 64.61158266719099
At time: 432.37363743782043 and batch: 1350, loss is 4.116981019973755 and perplexity is 61.373676392373056
At time: 432.77012634277344 and batch: 1400, loss is 4.005732760429383 and perplexity is 54.91204703565623
At time: 433.16647481918335 and batch: 1450, loss is 4.079216976165771 and perplexity is 59.0991756643938
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.772142720018697 and perplexity of 118.17218077276202
Annealing...
Finished 35 epochs...
Completing Train Step...
At time: 434.45322155952454 and batch: 50, loss is 4.2631017780303955 and perplexity is 71.02996129012922
At time: 434.8576023578644 and batch: 100, loss is 4.263057556152344 and perplexity is 71.02682028129419
At time: 435.26889419555664 and batch: 150, loss is 4.151663994789123 and perplexity is 63.53964201332869
At time: 435.6740515232086 and batch: 200, loss is 4.218171534538269 and perplexity is 67.90920107156708
At time: 436.0780143737793 and batch: 250, loss is 4.264922456741333 and perplexity is 71.15940182754774
At time: 436.4749913215637 and batch: 300, loss is 4.261723046302795 and perplexity is 70.93209750834123
At time: 436.8762876987457 and batch: 350, loss is 4.260733852386474 and perplexity is 70.86196660126602
At time: 437.2856476306915 and batch: 400, loss is 4.1284575939178465 and perplexity is 62.08209325139216
At time: 437.67558312416077 and batch: 450, loss is 4.177337589263916 and perplexity is 65.1920539298434
At time: 438.07481145858765 and batch: 500, loss is 4.169138579368592 and perplexity is 64.65972888579893
At time: 438.47183775901794 and batch: 550, loss is 4.2125015592575075 and perplexity is 67.52524711351253
At time: 438.8625774383545 and batch: 600, loss is 4.126916289329529 and perplexity is 61.98647954006589
At time: 439.25094199180603 and batch: 650, loss is 4.221509156227111 and perplexity is 68.13623495979249
At time: 439.65509843826294 and batch: 700, loss is 4.267883591651916 and perplexity is 71.37042669887781
At time: 440.07081842422485 and batch: 750, loss is 4.2221051120758055 and perplexity is 68.1768532496763
At time: 440.4680655002594 and batch: 800, loss is 4.162509570121765 and perplexity is 64.23251650696466
At time: 440.8543231487274 and batch: 850, loss is 4.108121800422668 and perplexity is 60.8323549020193
At time: 441.2600486278534 and batch: 900, loss is 4.047972135543823 and perplexity is 57.28118071859024
At time: 441.6712121963501 and batch: 950, loss is 4.150754375457764 and perplexity is 63.48187140525996
At time: 442.08118438720703 and batch: 1000, loss is 4.19955421924591 and perplexity is 66.65661018297166
At time: 442.4774115085602 and batch: 1050, loss is 4.093993539810181 and perplexity is 59.978942351354334
At time: 442.87923407554626 and batch: 1100, loss is 4.2365510416030885 and perplexity is 69.16887938525703
At time: 443.2755117416382 and batch: 1150, loss is 4.165428094863891 and perplexity is 64.42025452140003
At time: 443.6657626628876 and batch: 1200, loss is 4.111391458511353 and perplexity is 61.03158142709939
At time: 444.0548644065857 and batch: 1250, loss is 4.0814507818222046 and perplexity is 59.23133929626089
At time: 444.45480823516846 and batch: 1300, loss is 4.165778479576111 and perplexity is 64.442830348623
At time: 444.8599622249603 and batch: 1350, loss is 4.1146671581268315 and perplexity is 61.23183035351848
At time: 445.26562118530273 and batch: 1400, loss is 4.003144383430481 and perplexity is 54.770097744538006
At time: 445.6734776496887 and batch: 1450, loss is 4.0765221977233885 and perplexity is 58.94013087133702
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.771634093716613 and perplexity of 118.11209057646899
Finished 36 epochs...
Completing Train Step...
At time: 447.00779724121094 and batch: 50, loss is 4.262215685844422 and perplexity is 70.96705007314519
At time: 447.4256637096405 and batch: 100, loss is 4.262309217453003 and perplexity is 70.97368804592011
At time: 447.82368063926697 and batch: 150, loss is 4.151065349578857 and perplexity is 63.501615694247945
At time: 448.2149565219879 and batch: 200, loss is 4.217611031532288 and perplexity is 67.87114842554017
At time: 448.60546803474426 and batch: 250, loss is 4.26431257724762 and perplexity is 71.11601639887463
At time: 448.9966449737549 and batch: 300, loss is 4.261149873733521 and perplexity is 70.89145282508984
At time: 449.3989725112915 and batch: 350, loss is 4.260203943252564 and perplexity is 70.82442614531085
At time: 449.7953350543976 and batch: 400, loss is 4.127971911430359 and perplexity is 62.051948386922355
At time: 450.1845667362213 and batch: 450, loss is 4.176712918281555 and perplexity is 65.15134306224553
At time: 450.5800004005432 and batch: 500, loss is 4.168650360107422 and perplexity is 64.62816846556427
At time: 450.96956729888916 and batch: 550, loss is 4.212065463066101 and perplexity is 67.49580603046124
At time: 451.35922956466675 and batch: 600, loss is 4.126511144638061 and perplexity is 61.96137113354973
At time: 451.74389362335205 and batch: 650, loss is 4.221234683990478 and perplexity is 68.11753602127445
At time: 452.1313750743866 and batch: 700, loss is 4.2675052785873415 and perplexity is 71.34343144068474
At time: 452.5193099975586 and batch: 750, loss is 4.22178026676178 and perplexity is 68.15470991514707
At time: 452.90860629081726 and batch: 800, loss is 4.162247629165649 and perplexity is 64.21569358357962
At time: 453.2980635166168 and batch: 850, loss is 4.107878046035767 and perplexity is 60.81752855571327
At time: 453.6869111061096 and batch: 900, loss is 4.0477852487564085 and perplexity is 57.27047662300461
At time: 454.0768280029297 and batch: 950, loss is 4.150649857521057 and perplexity is 63.4752367577683
At time: 454.4639992713928 and batch: 1000, loss is 4.199497904777527 and perplexity is 66.65285655709766
At time: 454.8649208545685 and batch: 1050, loss is 4.09408742427826 and perplexity is 59.98457370679719
At time: 455.26003527641296 and batch: 1100, loss is 4.236601881980896 and perplexity is 69.17239604661093
At time: 455.6460602283478 and batch: 1150, loss is 4.16538378238678 and perplexity is 64.41739996359274
At time: 456.03221440315247 and batch: 1200, loss is 4.111436305046081 and perplexity is 61.03431854341002
At time: 456.4184248447418 and batch: 1250, loss is 4.081650462150574 and perplexity is 59.24316781046281
At time: 456.804327249527 and batch: 1300, loss is 4.165828351974487 and perplexity is 64.44604434727489
At time: 457.1904766559601 and batch: 1350, loss is 4.114813671112061 and perplexity is 61.24080226900965
At time: 457.5765709877014 and batch: 1400, loss is 4.00337767124176 and perplexity is 54.782876431262366
At time: 457.9632716178894 and batch: 1450, loss is 4.076764960289001 and perplexity is 58.95444106564434
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.771520370092148 and perplexity of 118.09865920518207
Finished 37 epochs...
Completing Train Step...
At time: 459.2307698726654 and batch: 50, loss is 4.261615338325501 and perplexity is 70.92445796702052
At time: 459.6188704967499 and batch: 100, loss is 4.261808967590332 and perplexity is 70.93819234732126
At time: 460.0074944496155 and batch: 150, loss is 4.15062686920166 and perplexity is 63.47377758552391
At time: 460.3963222503662 and batch: 200, loss is 4.217214560508728 and perplexity is 67.84424481545703
At time: 460.7952013015747 and batch: 250, loss is 4.263859014511109 and perplexity is 71.08376813772462
At time: 461.183176279068 and batch: 300, loss is 4.2607156991958615 and perplexity is 70.8606802421549
At time: 461.5724399089813 and batch: 350, loss is 4.259808416366577 and perplexity is 70.79641871979584
At time: 461.96245074272156 and batch: 400, loss is 4.127603983879089 and perplexity is 62.029121964993074
At time: 462.35489892959595 and batch: 450, loss is 4.176265177726745 and perplexity is 65.12217869327883
At time: 462.74400901794434 and batch: 500, loss is 4.1682486867904665 and perplexity is 64.60221426767131
At time: 463.13400435447693 and batch: 550, loss is 4.211760268211365 and perplexity is 67.47520980083601
At time: 463.52722811698914 and batch: 600, loss is 4.126270928382874 and perplexity is 61.9464887925714
At time: 463.9166865348816 and batch: 650, loss is 4.22100980758667 and perplexity is 68.10221971693996
At time: 464.3055784702301 and batch: 700, loss is 4.267180614471435 and perplexity is 71.32027254822444
At time: 464.70064091682434 and batch: 750, loss is 4.22152425289154 and perplexity is 68.13726359743158
At time: 465.10055589675903 and batch: 800, loss is 4.161974678039551 and perplexity is 64.19816822959413
At time: 465.49793910980225 and batch: 850, loss is 4.10765814781189 and perplexity is 60.80415635951825
At time: 465.9134929180145 and batch: 900, loss is 4.047630453109742 and perplexity is 57.26161208865419
At time: 466.3111569881439 and batch: 950, loss is 4.150583848953247 and perplexity is 63.47104698658045
At time: 466.7042109966278 and batch: 1000, loss is 4.199465532302856 and perplexity is 66.650698874112
At time: 467.0933265686035 and batch: 1050, loss is 4.094116344451904 and perplexity is 59.98630849616986
At time: 467.5059986114502 and batch: 1100, loss is 4.236603388786316 and perplexity is 69.17250027603073
At time: 467.895090341568 and batch: 1150, loss is 4.165326833724976 and perplexity is 64.41373158332358
At time: 468.2840406894684 and batch: 1200, loss is 4.111396737098694 and perplexity is 61.03190358848282
At time: 468.68246841430664 and batch: 1250, loss is 4.081772384643554 and perplexity is 59.250391325519864
At time: 469.0751326084137 and batch: 1300, loss is 4.165861511230469 and perplexity is 64.4481813655872
At time: 469.47176909446716 and batch: 1350, loss is 4.114878187179565 and perplexity is 61.244753412197596
At time: 469.8604485988617 and batch: 1400, loss is 4.003485045433044 and perplexity is 54.78875901412852
At time: 470.24918246269226 and batch: 1450, loss is 4.076852107048035 and perplexity is 58.95957897798682
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.771464029947917 and perplexity of 118.09200569712054
Finished 38 epochs...
Completing Train Step...
At time: 471.5367798805237 and batch: 50, loss is 4.261114015579223 and perplexity is 70.8889108340119
At time: 471.9239938259125 and batch: 100, loss is 4.261431427001953 and perplexity is 70.91141535546261
At time: 472.3124876022339 and batch: 150, loss is 4.150249924659729 and perplexity is 63.44985600034603
At time: 472.7180459499359 and batch: 200, loss is 4.216906790733337 and perplexity is 67.82336762031827
At time: 473.1235010623932 and batch: 250, loss is 4.263484492301941 and perplexity is 71.05715067257273
At time: 473.5272092819214 and batch: 300, loss is 4.260347785949707 and perplexity is 70.83461445453062
At time: 473.9284496307373 and batch: 350, loss is 4.259477291107178 and perplexity is 70.77298011805341
At time: 474.324467420578 and batch: 400, loss is 4.127298607826233 and perplexity is 62.01018264851929
At time: 474.7148699760437 and batch: 450, loss is 4.1759104347229 and perplexity is 65.09908115307988
At time: 475.10260701179504 and batch: 500, loss is 4.1679212188720705 and perplexity is 64.58106257848013
At time: 475.50864601135254 and batch: 550, loss is 4.2115318393707275 and perplexity is 67.45979827717468
At time: 475.90551686286926 and batch: 600, loss is 4.126043844223022 and perplexity is 61.93242332329129
At time: 476.29688000679016 and batch: 650, loss is 4.220835461616516 and perplexity is 68.09034740434875
At time: 476.6844174861908 and batch: 700, loss is 4.266932649612427 and perplexity is 71.30258981933585
At time: 477.07200717926025 and batch: 750, loss is 4.221337194442749 and perplexity is 68.1245191386147
At time: 477.4743800163269 and batch: 800, loss is 4.1617770004272465 and perplexity is 64.18547894321945
At time: 477.86708331108093 and batch: 850, loss is 4.107465682029724 and perplexity is 60.79245476611987
At time: 478.2555651664734 and batch: 900, loss is 4.047479782104492 and perplexity is 57.25298507393541
At time: 478.6441390514374 and batch: 950, loss is 4.150507378578186 and perplexity is 63.4661935173875
At time: 479.0324068069458 and batch: 1000, loss is 4.19942461013794 and perplexity is 66.64797143902754
At time: 479.4208309650421 and batch: 1050, loss is 4.094135355949402 and perplexity is 59.987448936564455
At time: 479.80881690979004 and batch: 1100, loss is 4.236586046218872 and perplexity is 69.17130065768171
At time: 480.1965184211731 and batch: 1150, loss is 4.165246024131775 and perplexity is 64.40852654618908
At time: 480.5842933654785 and batch: 1200, loss is 4.111389670372009 and perplexity is 61.03147229422503
At time: 480.9726257324219 and batch: 1250, loss is 4.081849513053894 and perplexity is 59.254961390253435
At time: 481.36114144325256 and batch: 1300, loss is 4.165856094360351 and perplexity is 64.44783225910494
At time: 481.7491874694824 and batch: 1350, loss is 4.114925584793091 and perplexity is 61.24765633614559
At time: 482.1371648311615 and batch: 1400, loss is 4.003566823005676 and perplexity is 54.79323968905507
At time: 482.52546429634094 and batch: 1450, loss is 4.07691342830658 and perplexity is 58.96319456442804
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.771445249899839 and perplexity of 118.0897879444008
Finished 39 epochs...
Completing Train Step...
At time: 483.79587984085083 and batch: 50, loss is 4.260656795501709 and perplexity is 70.85650640924678
At time: 484.1976270675659 and batch: 100, loss is 4.261106953620911 and perplexity is 70.88841022124643
At time: 484.59446811676025 and batch: 150, loss is 4.149925107955933 and perplexity is 63.42924977406808
At time: 484.99265813827515 and batch: 200, loss is 4.216643671989441 and perplexity is 67.80552436857316
At time: 485.3841280937195 and batch: 250, loss is 4.263178176879883 and perplexity is 71.0353881047495
At time: 485.77238297462463 and batch: 300, loss is 4.260046639442444 and perplexity is 70.8132860694398
At time: 486.17671489715576 and batch: 350, loss is 4.259197807312011 and perplexity is 70.75320298079819
At time: 486.57883620262146 and batch: 400, loss is 4.127035503387451 and perplexity is 61.99386964032135
At time: 486.96871066093445 and batch: 450, loss is 4.175598907470703 and perplexity is 65.07880417378749
At time: 487.37439918518066 and batch: 500, loss is 4.167654991149902 and perplexity is 64.56387159775403
At time: 487.76100873947144 and batch: 550, loss is 4.211324419975281 and perplexity is 67.44580725765363
At time: 488.14729022979736 and batch: 600, loss is 4.125825934410095 and perplexity is 61.91892911082483
At time: 488.5333878993988 and batch: 650, loss is 4.220687532424927 and perplexity is 68.0802755992776
At time: 488.91897320747375 and batch: 700, loss is 4.266705813407898 and perplexity is 71.28641764477489
At time: 489.30453419685364 and batch: 750, loss is 4.221156749725342 and perplexity is 68.11222753802078
At time: 489.68997979164124 and batch: 800, loss is 4.16159921169281 and perplexity is 64.17406850250288
At time: 490.07655000686646 and batch: 850, loss is 4.107270812988281 and perplexity is 60.780609352922276
At time: 490.4620633125305 and batch: 900, loss is 4.047326679229736 and perplexity is 57.24422014831701
At time: 490.8472726345062 and batch: 950, loss is 4.150407123565674 and perplexity is 63.45983103230316
At time: 491.23254656791687 and batch: 1000, loss is 4.199375548362732 and perplexity is 66.6447016514462
At time: 491.6173269748688 and batch: 1050, loss is 4.0941413354873655 and perplexity is 59.98780763486513
At time: 492.00243616104126 and batch: 1100, loss is 4.236558508872986 and perplexity is 69.16939588987636
At time: 492.38850450515747 and batch: 1150, loss is 4.165151867866516 and perplexity is 64.40246236537348
At time: 492.774044752121 and batch: 1200, loss is 4.111378707885742 and perplexity is 61.03080324121539
At time: 493.1593191623688 and batch: 1250, loss is 4.081894874572754 and perplexity is 59.257649346266525
At time: 493.5500547885895 and batch: 1300, loss is 4.16582308292389 and perplexity is 64.44570477870101
At time: 493.93792176246643 and batch: 1350, loss is 4.114954309463501 and perplexity is 61.24941568015541
At time: 494.32510137557983 and batch: 1400, loss is 4.003616371154785 and perplexity is 54.795954659925684
At time: 494.7130000591278 and batch: 1450, loss is 4.076941604614258 and perplexity is 58.96485595294557
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.771436903211805 and perplexity of 118.0888022898943
Finished 40 epochs...
Completing Train Step...
At time: 495.98634815216064 and batch: 50, loss is 4.2602394628524785 and perplexity is 70.82694184526979
At time: 496.38930654525757 and batch: 100, loss is 4.260810222625732 and perplexity is 70.86737855326305
At time: 496.7778351306915 and batch: 150, loss is 4.149623117446899 and perplexity is 63.41009763466892
At time: 497.18040800094604 and batch: 200, loss is 4.216404480934143 and perplexity is 67.78930783314681
At time: 497.5701377391815 and batch: 250, loss is 4.262901315689087 and perplexity is 71.01572388486541
At time: 497.95942211151123 and batch: 300, loss is 4.259775586128235 and perplexity is 70.79409449464815
At time: 498.34857988357544 and batch: 350, loss is 4.258941621780395 and perplexity is 70.73507935548342
At time: 498.7379581928253 and batch: 400, loss is 4.126792011260986 and perplexity is 61.97877645878483
At time: 499.12830209732056 and batch: 450, loss is 4.175312151908875 and perplexity is 65.06014514015222
At time: 499.5176079273224 and batch: 500, loss is 4.167408623695374 and perplexity is 64.54796712030722
At time: 499.90668272972107 and batch: 550, loss is 4.211125278472901 and perplexity is 67.43237733553893
At time: 500.29595589637756 and batch: 600, loss is 4.125622129440307 and perplexity is 61.90631101120749
At time: 500.68574929237366 and batch: 650, loss is 4.220542101860047 and perplexity is 68.07037536625566
At time: 501.07742285728455 and batch: 700, loss is 4.266484775543213 and perplexity is 71.27066238855585
At time: 501.470011472702 and batch: 750, loss is 4.220982837677002 and perplexity is 68.10038303099373
At time: 501.86095094680786 and batch: 800, loss is 4.161425466537476 and perplexity is 64.16291953756986
At time: 502.25240540504456 and batch: 850, loss is 4.107078504562378 and perplexity is 60.768921853450536
At time: 502.64477467536926 and batch: 900, loss is 4.047173933982849 and perplexity is 57.2354770335292
At time: 503.03485441207886 and batch: 950, loss is 4.15029625415802 and perplexity is 63.45279566843732
At time: 503.42549085617065 and batch: 1000, loss is 4.19932234287262 and perplexity is 66.64115588175949
At time: 503.81663036346436 and batch: 1050, loss is 4.0941356801986695 and perplexity is 59.98746838745399
At time: 504.2072730064392 and batch: 1100, loss is 4.236519365310669 and perplexity is 69.16668840630854
At time: 504.5988504886627 and batch: 1150, loss is 4.165050716400146 and perplexity is 64.39594829132702
At time: 504.9899778366089 and batch: 1200, loss is 4.111352820396423 and perplexity is 61.02922332739842
At time: 505.3901569843292 and batch: 1250, loss is 4.081916036605835 and perplexity is 59.25890337187114
At time: 505.8088011741638 and batch: 1300, loss is 4.165772123336792 and perplexity is 64.44242073587272
At time: 506.2082054615021 and batch: 1350, loss is 4.1149663066864015 and perplexity is 61.250150507455785
At time: 506.604608297348 and batch: 1400, loss is 4.00363778591156 and perplexity is 54.79712811453155
At time: 507.01049733161926 and batch: 1450, loss is 4.076944918632507 and perplexity is 58.965051363878054
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.771432208199786 and perplexity of 118.08824786284974
Finished 41 epochs...
Completing Train Step...
At time: 508.382363319397 and batch: 50, loss is 4.259849429130554 and perplexity is 70.79932233614947
At time: 508.78082752227783 and batch: 100, loss is 4.26053147315979 and perplexity is 70.84762706232526
At time: 509.1926190853119 and batch: 150, loss is 4.149333658218384 and perplexity is 63.391745652930894
At time: 509.5911753177643 and batch: 200, loss is 4.216182808876038 and perplexity is 67.77428250317135
At time: 509.9884223937988 and batch: 250, loss is 4.262645983695984 and perplexity is 70.99759361326197
At time: 510.38286662101746 and batch: 300, loss is 4.259526529312134 and perplexity is 70.77646493834624
At time: 510.79341650009155 and batch: 350, loss is 4.258703546524048 and perplexity is 70.7182410878001
At time: 511.18764567375183 and batch: 400, loss is 4.126562533378601 and perplexity is 61.964555332189654
At time: 511.59400963783264 and batch: 450, loss is 4.175043044090271 and perplexity is 65.0426393020001
At time: 512.0000367164612 and batch: 500, loss is 4.167173376083374 and perplexity is 64.53278415113141
At time: 512.404632806778 and batch: 550, loss is 4.2109274625778195 and perplexity is 67.41903945872437
At time: 512.8063325881958 and batch: 600, loss is 4.125427331924438 and perplexity is 61.894252990080304
At time: 513.1998345851898 and batch: 650, loss is 4.2203901720046995 and perplexity is 68.06003422955644
At time: 513.593001127243 and batch: 700, loss is 4.266267013549805 and perplexity is 71.25514403675754
At time: 514.0008854866028 and batch: 750, loss is 4.220812644958496 and perplexity is 68.08879382790136
At time: 514.3968191146851 and batch: 800, loss is 4.161251292228699 and perplexity is 64.15174497859911
At time: 514.7860522270203 and batch: 850, loss is 4.106892566680909 and perplexity is 60.757623659275616
At time: 515.1846179962158 and batch: 900, loss is 4.047022466659546 and perplexity is 57.226808385549965
At time: 515.5822875499725 and batch: 950, loss is 4.150166282653808 and perplexity is 63.44454914905573
At time: 515.9858131408691 and batch: 1000, loss is 4.199270210266113 and perplexity is 66.63768179516015
At time: 516.3766746520996 and batch: 1050, loss is 4.094122734069824 and perplexity is 59.98669178698613
At time: 516.7655010223389 and batch: 1100, loss is 4.236470160484314 and perplexity is 69.16328515514479
At time: 517.1550459861755 and batch: 1150, loss is 4.164948353767395 and perplexity is 64.38935688988374
At time: 517.584070444107 and batch: 1200, loss is 4.111306500434876 and perplexity is 61.02639652158991
At time: 517.9817795753479 and batch: 1250, loss is 4.081913161277771 and perplexity is 59.258732983328166
At time: 518.3712968826294 and batch: 1300, loss is 4.165703887939453 and perplexity is 64.43802363170911
At time: 518.7628586292267 and batch: 1350, loss is 4.114965591430664 and perplexity is 61.25010669794989
At time: 519.1549623012543 and batch: 1400, loss is 4.00362756729126 and perplexity is 54.796568166346766
At time: 519.5458724498749 and batch: 1450, loss is 4.076936101913452 and perplexity is 58.9645314878779
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.771422818175748 and perplexity of 118.08713901656972
Finished 42 epochs...
Completing Train Step...
At time: 520.9166104793549 and batch: 50, loss is 4.25947072505951 and perplexity is 70.77251542081794
At time: 521.3136644363403 and batch: 100, loss is 4.260257630348206 and perplexity is 70.82822860512171
At time: 521.7066490650177 and batch: 150, loss is 4.1490577125549315 and perplexity is 63.374255388911514
At time: 522.0953722000122 and batch: 200, loss is 4.215972471237182 and perplexity is 67.76002851974167
At time: 522.4836230278015 and batch: 250, loss is 4.262410416603088 and perplexity is 70.98087088627129
At time: 522.8785190582275 and batch: 300, loss is 4.259297242164612 and perplexity is 70.76023866489791
At time: 523.2776997089386 and batch: 350, loss is 4.258490409851074 and perplexity is 70.70317004332928
At time: 523.6710081100464 and batch: 400, loss is 4.1263471651077275 and perplexity is 61.9512115700154
At time: 524.0769240856171 and batch: 450, loss is 4.174789795875549 and perplexity is 65.02616945528375
At time: 524.4874680042267 and batch: 500, loss is 4.166942405700683 and perplexity is 64.51788071047287
At time: 524.87628698349 and batch: 550, loss is 4.210727367401123 and perplexity is 67.4055505836856
At time: 525.2730813026428 and batch: 600, loss is 4.125233840942383 and perplexity is 61.882278168833
At time: 525.6683235168457 and batch: 650, loss is 4.22022650718689 and perplexity is 68.04889610793833
At time: 526.084802865982 and batch: 700, loss is 4.266044363975525 and perplexity is 71.23928087530113
At time: 526.497786283493 and batch: 750, loss is 4.220652050971985 and perplexity is 68.0778600550364
At time: 526.8992774486542 and batch: 800, loss is 4.161077299118042 and perplexity is 64.1405839879321
At time: 527.2957592010498 and batch: 850, loss is 4.106717443466186 and perplexity is 60.74698452050879
At time: 527.7088665962219 and batch: 900, loss is 4.046875104904175 and perplexity is 57.21837596393549
At time: 528.1110305786133 and batch: 950, loss is 4.15001211643219 and perplexity is 63.43476889654283
At time: 528.5243077278137 and batch: 1000, loss is 4.1992282915115355 and perplexity is 66.6348884850778
At time: 528.9252145290375 and batch: 1050, loss is 4.094106211662292 and perplexity is 59.985700670605766
At time: 529.3168387413025 and batch: 1100, loss is 4.236411423683166 and perplexity is 69.15922284432268
At time: 529.710230588913 and batch: 1150, loss is 4.164844961166382 and perplexity is 64.38269985094755
At time: 530.1228477954865 and batch: 1200, loss is 4.1112512636184695 and perplexity is 61.0230257108266
At time: 530.5365669727325 and batch: 1250, loss is 4.081895699501038 and perplexity is 59.25769822959767
At time: 530.9301171302795 and batch: 1300, loss is 4.165625171661377 and perplexity is 64.43295150995414
At time: 531.3283128738403 and batch: 1350, loss is 4.114957933425903 and perplexity is 61.24963764613719
At time: 531.7339777946472 and batch: 1400, loss is 4.003599648475647 and perplexity is 54.79503833241957
At time: 532.1340310573578 and batch: 1450, loss is 4.076916198730469 and perplexity is 58.963357917697145
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.771417601495727 and perplexity of 118.08652299535764
Finished 43 epochs...
Completing Train Step...
At time: 533.4555184841156 and batch: 50, loss is 4.259113101959229 and perplexity is 70.74721005959904
At time: 533.8590750694275 and batch: 100, loss is 4.260007672309875 and perplexity is 70.81052673249599
At time: 534.2525720596313 and batch: 150, loss is 4.148796310424805 and perplexity is 63.35769138858447
At time: 534.648398399353 and batch: 200, loss is 4.215778532028199 and perplexity is 67.74688846763667
At time: 535.0527245998383 and batch: 250, loss is 4.2621852397918705 and perplexity is 70.96488943950081
At time: 535.4480035305023 and batch: 300, loss is 4.259080591201783 and perplexity is 70.7449100516005
At time: 535.849415063858 and batch: 350, loss is 4.25827431678772 and perplexity is 70.68789322939196
At time: 536.2373168468475 and batch: 400, loss is 4.126135802268982 and perplexity is 61.93811876978867
At time: 536.626503944397 and batch: 450, loss is 4.174546413421631 and perplexity is 65.01034515234976
At time: 537.0158228874207 and batch: 500, loss is 4.166728572845459 and perplexity is 64.50408614274598
At time: 537.4061028957367 and batch: 550, loss is 4.210541315078736 and perplexity is 67.39301079102263
At time: 537.8260090351105 and batch: 600, loss is 4.12505331993103 and perplexity is 61.871108125637235
At time: 538.220826625824 and batch: 650, loss is 4.220083122253418 and perplexity is 68.03913962098038
At time: 538.6105244159698 and batch: 700, loss is 4.265842051506042 and perplexity is 71.22486973828858
At time: 538.9998841285706 and batch: 750, loss is 4.220492205619812 and perplexity is 68.0669789951873
At time: 539.3886158466339 and batch: 800, loss is 4.160908493995667 and perplexity is 64.12975764259977
At time: 539.7767791748047 and batch: 850, loss is 4.106532797813416 and perplexity is 60.7357688893888
At time: 540.1639323234558 and batch: 900, loss is 4.046728076934815 and perplexity is 57.20996388072834
At time: 540.5512838363647 and batch: 950, loss is 4.149885077476501 and perplexity is 63.426710721609716
At time: 540.9394733905792 and batch: 1000, loss is 4.1991725301742555 and perplexity is 66.63117293817926
At time: 541.3280317783356 and batch: 1050, loss is 4.094076075553894 and perplexity is 59.98389296226681
At time: 541.723840713501 and batch: 1100, loss is 4.2363354587554936 and perplexity is 69.1539693685039
At time: 542.1215884685516 and batch: 1150, loss is 4.164727354049683 and perplexity is 64.37512843248788
At time: 542.516836643219 and batch: 1200, loss is 4.111210436820984 and perplexity is 61.02053438697067
At time: 542.9056622982025 and batch: 1250, loss is 4.081881828308106 and perplexity is 59.256876260333684
At time: 543.2943286895752 and batch: 1300, loss is 4.165548052787781 and perplexity is 64.42798270490799
At time: 543.6839263439178 and batch: 1350, loss is 4.114943919181823 and perplexity is 61.24877928478007
At time: 544.0738017559052 and batch: 1400, loss is 4.003569183349609 and perplexity is 54.79336902009856
At time: 544.4673550128937 and batch: 1450, loss is 4.076878380775452 and perplexity is 58.96112808624384
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.771425948183761 and perplexity of 118.0875086308395
Annealing...
Finished 44 epochs...
Completing Train Step...
At time: 545.837081193924 and batch: 50, loss is 4.258836622238159 and perplexity is 70.72765259444115
At time: 546.2417643070221 and batch: 100, loss is 4.259964499473572 and perplexity is 70.80746970720752
At time: 546.631894826889 and batch: 150, loss is 4.148803935050965 and perplexity is 63.3581744691373
At time: 547.035031080246 and batch: 200, loss is 4.215452547073364 and perplexity is 67.72480760047017
At time: 547.4364960193634 and batch: 250, loss is 4.2620028877258305 and perplexity is 70.95195002509554
At time: 547.843976020813 and batch: 300, loss is 4.25879864692688 and perplexity is 70.7249667408162
At time: 548.2489647865295 and batch: 350, loss is 4.257892293930054 and perplexity is 70.6608939959086
At time: 548.6525762081146 and batch: 400, loss is 4.125529947280884 and perplexity is 61.90060461679448
At time: 549.0514919757843 and batch: 450, loss is 4.174187660217285 and perplexity is 64.98702666575174
At time: 549.443666934967 and batch: 500, loss is 4.166150588989257 and perplexity is 64.46681459451061
At time: 549.8422541618347 and batch: 550, loss is 4.209635744094848 and perplexity is 67.33200926071014
At time: 550.2408020496368 and batch: 600, loss is 4.12436502456665 and perplexity is 61.82853718109785
At time: 550.632404088974 and batch: 650, loss is 4.219382405281067 and perplexity is 67.99148014091716
At time: 551.0244688987732 and batch: 700, loss is 4.265029420852661 and perplexity is 71.16701373682017
At time: 551.4259316921234 and batch: 750, loss is 4.219734573364258 and perplexity is 68.01542878687859
At time: 551.8306500911713 and batch: 800, loss is 4.159932250976563 and perplexity is 64.06718196388893
At time: 552.2336809635162 and batch: 850, loss is 4.105610098838806 and perplexity is 60.67975390417127
At time: 552.6408052444458 and batch: 900, loss is 4.045908646583557 and perplexity is 57.16310350196053
At time: 553.0390474796295 and batch: 950, loss is 4.14870934009552 and perplexity is 63.352181388908384
At time: 553.4441659450531 and batch: 1000, loss is 4.1981409597396855 and perplexity is 66.56247363033506
At time: 553.8445000648499 and batch: 1050, loss is 4.092950239181518 and perplexity is 59.9163989145692
At time: 554.2446200847626 and batch: 1100, loss is 4.235325846672058 and perplexity is 69.08418591844675
At time: 554.6500911712646 and batch: 1150, loss is 4.163426141738892 and perplexity is 64.29141719771873
At time: 555.0589640140533 and batch: 1200, loss is 4.1102067613601685 and perplexity is 60.95932029867851
At time: 555.4581916332245 and batch: 1250, loss is 4.080725431442261 and perplexity is 59.1883913998173
At time: 555.8608574867249 and batch: 1300, loss is 4.16413950920105 and perplexity is 64.33729696546467
At time: 556.2720711231232 and batch: 1350, loss is 4.113580355644226 and perplexity is 61.16531959685007
At time: 556.6734509468079 and batch: 1400, loss is 4.00205689907074 and perplexity is 54.710568494290364
At time: 557.0669598579407 and batch: 1450, loss is 4.075330972671509 and perplexity is 58.86996171280936
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.771255362747062 and perplexity of 118.06736633965063
Finished 45 epochs...
Completing Train Step...
At time: 558.3722221851349 and batch: 50, loss is 4.2584623432159425 and perplexity is 70.70118567110049
At time: 558.7785677909851 and batch: 100, loss is 4.259724640846253 and perplexity is 70.79048796141014
At time: 559.1910560131073 and batch: 150, loss is 4.1485791635513305 and perplexity is 63.34393495762592
At time: 559.5996165275574 and batch: 200, loss is 4.215204267501831 and perplexity is 67.70799500145577
At time: 559.9998042583466 and batch: 250, loss is 4.261792211532593 and perplexity is 70.93700371283285
At time: 560.3982653617859 and batch: 300, loss is 4.258542847633362 and perplexity is 70.70687765797577
At time: 560.8114817142487 and batch: 350, loss is 4.2576962661743165 and perplexity is 70.64704385699038
At time: 561.2121744155884 and batch: 400, loss is 4.125351748466492 and perplexity is 61.88957498520441
At time: 561.6151165962219 and batch: 450, loss is 4.17398247718811 and perplexity is 64.97369379864918
At time: 562.0124819278717 and batch: 500, loss is 4.166001176834106 and perplexity is 64.45718318834881
At time: 562.4168856143951 and batch: 550, loss is 4.209488973617554 and perplexity is 67.32212763475697
At time: 562.8196866512299 and batch: 600, loss is 4.124208464622497 and perplexity is 61.81885806647031
At time: 563.2212455272675 and batch: 650, loss is 4.2192674732208255 and perplexity is 67.9836661890711
At time: 563.6250336170197 and batch: 700, loss is 4.264882864952088 and perplexity is 71.15658455527856
At time: 564.0270898342133 and batch: 750, loss is 4.219593758583069 and perplexity is 68.00585188345708
At time: 564.4218075275421 and batch: 800, loss is 4.159826884269714 and perplexity is 64.06043177153734
At time: 564.8168065547943 and batch: 850, loss is 4.105512795448303 and perplexity is 60.67384984562861
At time: 565.2223765850067 and batch: 900, loss is 4.045834536552429 and perplexity is 57.15886729955511
At time: 565.615020275116 and batch: 950, loss is 4.148660116195678 and perplexity is 63.349063024226616
At time: 566.0046012401581 and batch: 1000, loss is 4.1981096887588505 and perplexity is 66.56039218904236
At time: 566.3948655128479 and batch: 1050, loss is 4.0929869413375854 and perplexity is 59.91859801594878
At time: 566.807719707489 and batch: 1100, loss is 4.235330605506897 and perplexity is 69.08451467945979
At time: 567.2198424339294 and batch: 1150, loss is 4.163395118713379 and perplexity is 64.28942271438035
At time: 567.6168539524078 and batch: 1200, loss is 4.110223908424377 and perplexity is 60.960365581019516
At time: 568.0228769779205 and batch: 1250, loss is 4.080805401802063 and perplexity is 59.193124906041255
At time: 568.4288980960846 and batch: 1300, loss is 4.164145717620849 and perplexity is 64.33769639965293
At time: 568.8245785236359 and batch: 1350, loss is 4.113616881370544 and perplexity is 61.16755374537553
At time: 569.2223958969116 and batch: 1400, loss is 4.002116804122925 and perplexity is 54.71384603192061
At time: 569.618082523346 and batch: 1450, loss is 4.075391144752502 and perplexity is 58.873504147490394
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.771219367654915 and perplexity of 118.06311657040557
Finished 46 epochs...
Completing Train Step...
At time: 570.9405615329742 and batch: 50, loss is 4.258224396705628 and perplexity is 70.6843645720352
At time: 571.3463242053986 and batch: 100, loss is 4.259556560516358 and perplexity is 70.77859047273506
At time: 571.748122215271 and batch: 150, loss is 4.148434243202209 and perplexity is 63.33475579759676
At time: 572.1539051532745 and batch: 200, loss is 4.215035171508789 and perplexity is 67.69654681875227
At time: 572.5554642677307 and batch: 250, loss is 4.261615862846375 and perplexity is 70.92449516838894
At time: 572.9495301246643 and batch: 300, loss is 4.2583699131011965 and perplexity is 70.69465105439856
At time: 573.3483505249023 and batch: 350, loss is 4.2575522136688235 and perplexity is 70.6368677062847
At time: 573.7423825263977 and batch: 400, loss is 4.125206375122071 and perplexity is 61.88057854464119
At time: 574.1408531665802 and batch: 450, loss is 4.173835129737854 and perplexity is 64.96412079583031
At time: 574.531364440918 and batch: 500, loss is 4.165872240066529 and perplexity is 64.44887282326867
At time: 574.9211022853851 and batch: 550, loss is 4.209386267662048 and perplexity is 67.31521360637359
At time: 575.3107895851135 and batch: 600, loss is 4.1241049432754515 and perplexity is 61.81245882624515
At time: 575.7146513462067 and batch: 650, loss is 4.219179863929749 and perplexity is 67.97771044916435
At time: 576.1259939670563 and batch: 700, loss is 4.264760503768921 and perplexity is 71.14787828406793
At time: 576.5264604091644 and batch: 750, loss is 4.219487104415894 and perplexity is 67.99859916273472
At time: 576.9188647270203 and batch: 800, loss is 4.159741539955139 and perplexity is 64.05496481118671
At time: 577.3221123218536 and batch: 850, loss is 4.105414276123047 and perplexity is 60.6678725933234
At time: 577.7173652648926 and batch: 900, loss is 4.045773158073425 and perplexity is 57.15535908288427
At time: 578.1061527729034 and batch: 950, loss is 4.148602709770203 and perplexity is 63.34542648534253
At time: 578.5193910598755 and batch: 1000, loss is 4.19807737827301 and perplexity is 66.55824162517607
At time: 578.9076075553894 and batch: 1050, loss is 4.093013377189636 and perplexity is 59.92018203607837
At time: 579.2970144748688 and batch: 1100, loss is 4.235315742492676 and perplexity is 69.08348788296631
At time: 579.6978809833527 and batch: 1150, loss is 4.163348550796509 and perplexity is 64.28642895959476
At time: 580.0898087024689 and batch: 1200, loss is 4.110235476493836 and perplexity is 60.96107077884167
At time: 580.4908449649811 and batch: 1250, loss is 4.080853271484375 and perplexity is 59.195958529947326
At time: 580.8908953666687 and batch: 1300, loss is 4.164132571220398 and perplexity is 64.33685059609157
At time: 581.2949695587158 and batch: 1350, loss is 4.113629279136657 and perplexity is 61.16831209110147
At time: 581.6930277347565 and batch: 1400, loss is 4.002141556739807 and perplexity is 54.715200359551105
At time: 582.0852792263031 and batch: 1450, loss is 4.075419826507568 and perplexity is 58.875192767132404
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.771200587606837 and perplexity of 118.06089936021992
Finished 47 epochs...
Completing Train Step...
At time: 583.4724471569061 and batch: 50, loss is 4.258011026382446 and perplexity is 70.66928423522798
At time: 583.8877725601196 and batch: 100, loss is 4.2594144153594975 and perplexity is 70.7685303539055
At time: 584.2777855396271 and batch: 150, loss is 4.148303093910218 and perplexity is 63.326450033874856
At time: 584.6690907478333 and batch: 200, loss is 4.214890561103821 and perplexity is 67.68675790150857
At time: 585.068609714508 and batch: 250, loss is 4.261463327407837 and perplexity is 70.91367749447564
At time: 585.4670372009277 and batch: 300, loss is 4.258220624923706 and perplexity is 70.68409796652956
At time: 585.859667301178 and batch: 350, loss is 4.2574246215820315 and perplexity is 70.62785557588009
At time: 586.2507996559143 and batch: 400, loss is 4.125071768760681 and perplexity is 61.872249585700615
At time: 586.6583604812622 and batch: 450, loss is 4.1737084341049195 and perplexity is 64.95589064680105
At time: 587.0552377700806 and batch: 500, loss is 4.1657564115524295 and perplexity is 64.44140823840841
At time: 587.4465584754944 and batch: 550, loss is 4.2092950773239135 and perplexity is 67.30907538916051
At time: 587.8388652801514 and batch: 600, loss is 4.124008073806762 and perplexity is 61.806471376205515
At time: 588.2295808792114 and batch: 650, loss is 4.219098844528198 and perplexity is 67.9722031588467
At time: 588.6474688053131 and batch: 700, loss is 4.2646473693847655 and perplexity is 71.13982946798183
At time: 589.0463206768036 and batch: 750, loss is 4.219389839172363 and perplexity is 67.99198558406832
At time: 589.4410898685455 and batch: 800, loss is 4.159660863876343 and perplexity is 64.04979731624773
At time: 589.8326873779297 and batch: 850, loss is 4.105317902565003 and perplexity is 60.662026096310996
At time: 590.223934173584 and batch: 900, loss is 4.0457105493545535 and perplexity is 57.15178077109337
At time: 590.6149435043335 and batch: 950, loss is 4.148541622161865 and perplexity is 63.341556982929916
At time: 591.0066637992859 and batch: 1000, loss is 4.198042607307434 and perplexity is 66.55592737108236
At time: 591.3977642059326 and batch: 1050, loss is 4.093029217720032 and perplexity is 59.92113121106094
At time: 591.7887740135193 and batch: 1100, loss is 4.2352910900115965 and perplexity is 69.08178482458075
At time: 592.1799805164337 and batch: 1150, loss is 4.163295316696167 and perplexity is 64.28300682047295
At time: 592.5711286067963 and batch: 1200, loss is 4.110240268707275 and perplexity is 60.96136291800434
At time: 592.962112903595 and batch: 1250, loss is 4.0808847761154174 and perplexity is 59.19782350615757
At time: 593.3529045581818 and batch: 1300, loss is 4.164111914634705 and perplexity is 64.33552163015003
At time: 593.7583475112915 and batch: 1350, loss is 4.113630766868591 and perplexity is 61.16840309322042
At time: 594.1686007976532 and batch: 1400, loss is 4.002151012420654 and perplexity is 54.71571773146925
At time: 594.5697195529938 and batch: 1450, loss is 4.075433177947998 and perplexity is 58.875978841009015
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.771189632578793 and perplexity of 118.05960600684081
Finished 48 epochs...
Completing Train Step...
At time: 595.8890290260315 and batch: 50, loss is 4.257813577651977 and perplexity is 70.65533205223832
At time: 596.2978053092957 and batch: 100, loss is 4.259288039207458 and perplexity is 70.7595874644498
At time: 596.6937947273254 and batch: 150, loss is 4.14818106174469 and perplexity is 63.31872264154687
At time: 597.0918183326721 and batch: 200, loss is 4.214759612083435 and perplexity is 67.67789496717725
At time: 597.4817979335785 and batch: 250, loss is 4.261323122978211 and perplexity is 70.90373577972234
At time: 597.8720426559448 and batch: 300, loss is 4.258083753585815 and perplexity is 70.67442400153263
At time: 598.2780523300171 and batch: 350, loss is 4.257305746078491 and perplexity is 70.61946015299948
At time: 598.6787481307983 and batch: 400, loss is 4.124944124221802 and perplexity is 61.86435243495764
At time: 599.0949039459229 and batch: 450, loss is 4.173590936660767 and perplexity is 64.94825894402894
At time: 599.4851729869843 and batch: 500, loss is 4.165648250579834 and perplexity is 64.4344385699478
At time: 599.8876614570618 and batch: 550, loss is 4.209208827018738 and perplexity is 67.30327021121991
At time: 600.2880835533142 and batch: 600, loss is 4.12391450881958 and perplexity is 61.80068872503449
At time: 600.6948642730713 and batch: 650, loss is 4.219020671844483 and perplexity is 67.96688979699029
At time: 601.0898640155792 and batch: 700, loss is 4.264539160728455 and perplexity is 71.13213193910204
At time: 601.4921660423279 and batch: 750, loss is 4.219297299385071 and perplexity is 67.98569391130428
At time: 601.9058306217194 and batch: 800, loss is 4.159580845832824 and perplexity is 64.0446723818251
At time: 602.3121185302734 and batch: 850, loss is 4.105223774909973 and perplexity is 60.65631639077003
At time: 602.7093381881714 and batch: 900, loss is 4.0456463766098025 and perplexity is 57.148113302130916
At time: 603.111921787262 and batch: 950, loss is 4.148478937149048 and perplexity is 63.337586541063494
At time: 603.5161962509155 and batch: 1000, loss is 4.198005499839783 and perplexity is 66.55345769498248
At time: 603.9221460819244 and batch: 1050, loss is 4.093036484718323 and perplexity is 59.92156665940125
At time: 604.3304028511047 and batch: 1100, loss is 4.235260949134827 and perplexity is 69.07970267039647
At time: 604.725234746933 and batch: 1150, loss is 4.163238258361816 and perplexity is 64.27933904381632
At time: 605.1148710250854 and batch: 1200, loss is 4.1102404260635375 and perplexity is 60.961372510657306
At time: 605.5185708999634 and batch: 1250, loss is 4.080905971527099 and perplexity is 59.199078241694714
At time: 605.915283203125 and batch: 1300, loss is 4.164086589813232 and perplexity is 64.3338923651809
At time: 606.3072302341461 and batch: 1350, loss is 4.11362557888031 and perplexity is 61.168085753085144
At time: 606.7093183994293 and batch: 1400, loss is 4.0021516752243045 and perplexity is 54.7157539972587
At time: 607.1062829494476 and batch: 1450, loss is 4.075436997413635 and perplexity is 58.8762037162165
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.771187024238782 and perplexity of 118.05929806764843
Finished 49 epochs...
Completing Train Step...
At time: 608.42174077034 and batch: 50, loss is 4.257627258300781 and perplexity is 70.64216882293204
At time: 608.8097515106201 and batch: 100, loss is 4.259171552658081 and perplexity is 70.75134540432461
At time: 609.2140347957611 and batch: 150, loss is 4.1480649995803835 and perplexity is 63.31137416000453
At time: 609.6263957023621 and batch: 200, loss is 4.214637989997864 and perplexity is 67.66966434096737
At time: 610.0241775512695 and batch: 250, loss is 4.2611902236938475 and perplexity is 70.89431335010948
At time: 610.4265794754028 and batch: 300, loss is 4.2579551029205325 and perplexity is 70.66533227470725
At time: 610.8246605396271 and batch: 350, loss is 4.257192029953003 and perplexity is 70.61143003819221
At time: 611.217693567276 and batch: 400, loss is 4.124821166992188 and perplexity is 61.8567462331987
At time: 611.6063494682312 and batch: 450, loss is 4.173478293418884 and perplexity is 64.94094337361938
At time: 612.0172250270844 and batch: 500, loss is 4.165544142723084 and perplexity is 64.42773078781983
At time: 612.4132254123688 and batch: 550, loss is 4.2091250371932984 and perplexity is 67.29763111821
At time: 612.8035047054291 and batch: 600, loss is 4.123823189735413 and perplexity is 61.79504540041474
At time: 613.1920392513275 and batch: 650, loss is 4.218944010734558 and perplexity is 67.96167957949339
At time: 613.5818457603455 and batch: 700, loss is 4.264433813095093 and perplexity is 71.12463873204904
At time: 613.9695935249329 and batch: 750, loss is 4.21920768737793 and perplexity is 67.97960184978102
At time: 614.3581647872925 and batch: 800, loss is 4.1595006275177 and perplexity is 64.03953503217149
At time: 614.7484591007233 and batch: 850, loss is 4.105131406784057 and perplexity is 60.65071393924801
At time: 615.136515378952 and batch: 900, loss is 4.045581002235412 and perplexity is 57.144377402093596
At time: 615.5367197990417 and batch: 950, loss is 4.148415675163269 and perplexity is 63.33357980630281
At time: 615.9371917247772 and batch: 1000, loss is 4.197966070175171 and perplexity is 66.55083356620136
At time: 616.329363822937 and batch: 1050, loss is 4.093037390708924 and perplexity is 59.92162094780202
At time: 616.7166259288788 and batch: 1100, loss is 4.2352272891998295 and perplexity is 69.07737749122785
At time: 617.1033234596252 and batch: 1150, loss is 4.163178176879883 and perplexity is 64.27547716188381
At time: 617.4988923072815 and batch: 1200, loss is 4.110236978530883 and perplexity is 60.961162344697215
At time: 617.8903794288635 and batch: 1250, loss is 4.080920224189758 and perplexity is 59.19992199219945
At time: 618.2786283493042 and batch: 1300, loss is 4.164058017730713 and perplexity is 64.33205423815912
At time: 618.6663074493408 and batch: 1350, loss is 4.1136158132553104 and perplexity is 61.16748841141446
At time: 619.0537598133087 and batch: 1400, loss is 4.002146201133728 and perplexity is 54.71545447908516
At time: 619.4421305656433 and batch: 1450, loss is 4.075434007644653 and perplexity is 58.87602769023201
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.771184415898771 and perplexity of 118.05899012925926
Finished Training.
Improved accuracyfrom -10000000 to -118.05899012925926
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc1f716f898>
SETTINGS FOR THIS RUN
{'batch_size': 20, 'lr': 14.711765920568743, 'num_layers': 1, 'wordvec_source': '', 'seq_len': 35, 'anneal': 2.1350035374060834, 'wordvec_dim': 200, 'dropout': 0.7670515392427568, 'tune_wordvecs': True, 'data': 'ptb'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.6491985321044922 and batch: 50, loss is 6.89861270904541 and perplexity is 990.8990962803452
At time: 1.0668609142303467 and batch: 100, loss is 6.348514003753662 and perplexity is 571.6426187689069
At time: 1.4606919288635254 and batch: 150, loss is 6.252520942687989 and perplexity is 519.3203527201532
At time: 1.852161169052124 and batch: 200, loss is 6.108633317947388 and perplexity is 449.7236657122643
At time: 2.2436883449554443 and batch: 250, loss is 6.068498516082764 and perplexity is 432.03150597511575
At time: 2.6429145336151123 and batch: 300, loss is 6.13209566116333 and perplexity is 460.39999277890337
At time: 3.0451300144195557 and batch: 350, loss is 6.154667139053345 and perplexity is 470.9100687990705
At time: 3.441322088241577 and batch: 400, loss is 6.034410514831543 and perplexity is 417.5525960134188
At time: 3.84714937210083 and batch: 450, loss is 6.0616100025177 and perplexity is 429.065677886949
At time: 4.241896629333496 and batch: 500, loss is 6.02757550239563 and perplexity is 414.70835012798926
At time: 4.634212493896484 and batch: 550, loss is 6.095983600616455 and perplexity is 444.07061856917375
At time: 5.050389051437378 and batch: 600, loss is 5.9054343795776365 and perplexity is 367.02662003434943
At time: 5.456912517547607 and batch: 650, loss is 6.1046096706390385 and perplexity is 447.91777187157743
At time: 5.856214284896851 and batch: 700, loss is 6.051405086517334 and perplexity is 424.7093643976749
At time: 6.252886533737183 and batch: 750, loss is 6.000586624145508 and perplexity is 403.66552399311604
At time: 6.64815092086792 and batch: 800, loss is 5.95017526626587 and perplexity is 383.8206039703266
At time: 7.040333986282349 and batch: 850, loss is 5.907055597305298 and perplexity is 367.6221326946794
At time: 7.432993650436401 and batch: 900, loss is 5.873672266006469 and perplexity is 355.55226830137235
At time: 7.82641077041626 and batch: 950, loss is 5.8945174980163575 and perplexity is 363.0416253282095
At time: 8.229642868041992 and batch: 1000, loss is 5.9551092052459715 and perplexity is 385.7190309197504
At time: 8.635722160339355 and batch: 1050, loss is 5.804587297439575 and perplexity is 331.818222851288
At time: 9.034636974334717 and batch: 1100, loss is 5.911896142959595 and perplexity is 369.4059382245607
At time: 9.435563325881958 and batch: 1150, loss is 5.916631002426147 and perplexity is 371.1591708076503
At time: 9.837721824645996 and batch: 1200, loss is 5.883054618835449 and perplexity is 358.9038835637408
At time: 10.269376516342163 and batch: 1250, loss is 5.903871269226074 and perplexity is 366.4533650723775
At time: 10.69142770767212 and batch: 1300, loss is 5.948248014450074 and perplexity is 383.081597369033
At time: 11.103391170501709 and batch: 1350, loss is 5.877052001953125 and perplexity is 356.7559740414561
At time: 11.515654563903809 and batch: 1400, loss is 5.798400077819824 and perplexity is 329.771528834597
At time: 11.926523923873901 and batch: 1450, loss is 5.835179347991943 and perplexity is 342.1260881751456
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.612350594284188 and perplexity of 273.78704448201086
Finished 1 epochs...
Completing Train Step...
At time: 13.201200723648071 and batch: 50, loss is 5.553824758529663 and perplexity is 258.2233113785017
At time: 13.615569591522217 and batch: 100, loss is 5.45068775177002 and perplexity is 232.91830080847035
At time: 14.005189895629883 and batch: 150, loss is 5.302360115051269 and perplexity is 200.81018628688486
At time: 14.401569366455078 and batch: 200, loss is 5.290043830871582 and perplexity is 198.35211916511548
At time: 14.805252075195312 and batch: 250, loss is 5.2591313552856445 and perplexity is 192.31436586403973
At time: 15.214804887771606 and batch: 300, loss is 5.2722746276855466 and perplexity is 194.85868970503756
At time: 15.615918159484863 and batch: 350, loss is 5.289627351760864 and perplexity is 198.2695268510972
At time: 16.03412914276123 and batch: 400, loss is 5.184087419509888 and perplexity is 178.4105614791472
At time: 16.434568643569946 and batch: 450, loss is 5.1984733295440675 and perplexity is 180.9957100392017
At time: 16.830605268478394 and batch: 500, loss is 5.156193218231201 and perplexity is 173.50270989064646
At time: 17.22461462020874 and batch: 550, loss is 5.2286435413360595 and perplexity is 186.5395985733177
At time: 17.624303817749023 and batch: 600, loss is 5.090852088928223 and perplexity is 162.5282916257779
At time: 18.037772178649902 and batch: 650, loss is 5.214655313491821 and perplexity is 183.9484055174645
At time: 18.434972047805786 and batch: 700, loss is 5.214096450805664 and perplexity is 183.84563233816513
At time: 18.841841220855713 and batch: 750, loss is 5.177003192901611 and perplexity is 177.15112695927618
At time: 19.243943214416504 and batch: 800, loss is 5.098790998458862 and perplexity is 163.82372438705943
At time: 19.648159742355347 and batch: 850, loss is 5.055711259841919 and perplexity is 156.9160987820043
At time: 20.048842191696167 and batch: 900, loss is 5.020082054138183 and perplexity is 151.42372822782792
At time: 20.460565090179443 and batch: 950, loss is 5.076713132858276 and perplexity is 160.24648047711355
At time: 20.85236430168152 and batch: 1000, loss is 5.11941240310669 and perplexity is 167.23707276006715
At time: 21.241705894470215 and batch: 1050, loss is 5.025592164993286 and perplexity is 152.26039269658975
At time: 21.636037826538086 and batch: 1100, loss is 5.138102350234985 and perplexity is 170.39211676945368
At time: 22.042357921600342 and batch: 1150, loss is 5.108373212814331 and perplexity is 165.40106356259145
At time: 22.454119205474854 and batch: 1200, loss is 5.057141542434692 and perplexity is 157.14069372544913
At time: 22.855584621429443 and batch: 1250, loss is 5.04650297164917 and perplexity is 155.47780240914796
At time: 23.260358095169067 and batch: 1300, loss is 5.136993885040283 and perplexity is 170.2033476798743
At time: 23.6571786403656 and batch: 1350, loss is 5.075085830688477 and perplexity is 159.98592309202823
At time: 24.06894063949585 and batch: 1400, loss is 4.952607469558716 and perplexity is 141.5435536768046
At time: 24.466704607009888 and batch: 1450, loss is 5.036204795837403 and perplexity is 153.88488083605975
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.173478607438568 and perplexity of 176.5278417287058
Finished 2 epochs...
Completing Train Step...
At time: 25.75233769416809 and batch: 50, loss is 5.073458166122436 and perplexity is 159.7257314837203
At time: 26.140995979309082 and batch: 100, loss is 5.097995948791504 and perplexity is 163.6935281525747
At time: 26.540863037109375 and batch: 150, loss is 4.9786701679229735 and perplexity is 145.28105372982958
At time: 26.946533679962158 and batch: 200, loss is 5.043667039871216 and perplexity is 155.0375025937414
At time: 27.350773096084595 and batch: 250, loss is 5.0661796283721925 and perplexity is 158.5673823751162
At time: 27.74854016304016 and batch: 300, loss is 5.087080373764038 and perplexity is 161.9164358019349
At time: 28.144027709960938 and batch: 350, loss is 5.10214732170105 and perplexity is 164.37449352343816
At time: 28.53666615486145 and batch: 400, loss is 4.987990474700927 and perplexity is 146.64144751543654
At time: 28.94883942604065 and batch: 450, loss is 5.048279571533203 and perplexity is 155.75426976809865
At time: 29.339396715164185 and batch: 500, loss is 5.011171140670776 and perplexity is 150.08039852489142
At time: 29.73331356048584 and batch: 550, loss is 5.075036458969116 and perplexity is 159.97802450691663
At time: 30.122003316879272 and batch: 600, loss is 4.946169672012329 and perplexity is 140.63525180308753
At time: 30.534821033477783 and batch: 650, loss is 5.075258150100708 and perplexity is 160.0134941477065
At time: 30.933671712875366 and batch: 700, loss is 5.088024215698242 and perplexity is 162.0693314672015
At time: 31.346518754959106 and batch: 750, loss is 5.058626794815064 and perplexity is 157.3742607248921
At time: 31.755756616592407 and batch: 800, loss is 4.9813230609893795 and perplexity is 145.6669805148547
At time: 32.16589069366455 and batch: 850, loss is 4.936939258575439 and perplexity is 139.3431029933129
At time: 32.563631772994995 and batch: 900, loss is 4.908415517807007 and perplexity is 135.42466634883377
At time: 32.95998239517212 and batch: 950, loss is 4.972327613830567 and perplexity is 144.3625168022601
At time: 33.35250973701477 and batch: 1000, loss is 5.010134944915771 and perplexity is 149.92496639599386
At time: 33.74140977859497 and batch: 1050, loss is 4.901508760452271 and perplexity is 134.49254371638054
At time: 34.130006313323975 and batch: 1100, loss is 5.039745540618896 and perplexity is 154.43071368197815
At time: 34.51757264137268 and batch: 1150, loss is 4.990969076156616 and perplexity is 147.07888509716457
At time: 34.91315841674805 and batch: 1200, loss is 4.963620290756226 and perplexity is 143.11096248001635
At time: 35.30888509750366 and batch: 1250, loss is 4.9353017997741695 and perplexity is 139.11512110933162
At time: 35.71194911003113 and batch: 1300, loss is 5.04188949584961 and perplexity is 154.76216139592995
At time: 36.10806894302368 and batch: 1350, loss is 4.9908755493164065 and perplexity is 147.06512991702922
At time: 36.51202607154846 and batch: 1400, loss is 4.851803913116455 and perplexity is 127.97103037596773
At time: 36.91245174407959 and batch: 1450, loss is 4.956316461563111 and perplexity is 142.06951237101012
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.1595156416933765 and perplexity of 174.08011803077105
Finished 3 epochs...
Completing Train Step...
At time: 38.23811101913452 and batch: 50, loss is 5.015313806533814 and perplexity is 150.70342106466606
At time: 38.626283407211304 and batch: 100, loss is 5.0325119972229 and perplexity is 153.31766291667336
At time: 39.015010595321655 and batch: 150, loss is 4.91707859992981 and perplexity is 136.60295780356245
At time: 39.40360069274902 and batch: 200, loss is 4.96177900314331 and perplexity is 142.84769648611632
At time: 39.806607484817505 and batch: 250, loss is 4.996742391586304 and perplexity is 147.93047377353054
At time: 40.20246124267578 and batch: 300, loss is 5.008415117263794 and perplexity is 149.66734289057845
At time: 40.60668635368347 and batch: 350, loss is 5.031035709381103 and perplexity is 153.09148890502598
At time: 40.99563455581665 and batch: 400, loss is 4.908668079376221 and perplexity is 135.4588737346308
At time: 41.39398550987244 and batch: 450, loss is 4.968458223342895 and perplexity is 143.80500117141048
At time: 41.7912392616272 and batch: 500, loss is 4.948809986114502 and perplexity is 141.00706367575157
At time: 42.18053150177002 and batch: 550, loss is 5.005620241165161 and perplexity is 149.24962521766867
At time: 42.57009410858154 and batch: 600, loss is 4.90552472114563 and perplexity is 135.03374648264003
At time: 42.96811556816101 and batch: 650, loss is 5.009087944030762 and perplexity is 149.76807696950846
At time: 43.356584548950195 and batch: 700, loss is 5.0276758575439455 and perplexity is 152.57798731246936
At time: 43.74509572982788 and batch: 750, loss is 4.9861565113067625 and perplexity is 146.37275892645363
At time: 44.13507342338562 and batch: 800, loss is 4.920140752792358 and perplexity is 137.02189804400228
At time: 44.53776240348816 and batch: 850, loss is 4.863727970123291 and perplexity is 129.50609816696607
At time: 44.932225704193115 and batch: 900, loss is 4.824100694656372 and perplexity is 124.4744774709952
At time: 45.320611238479614 and batch: 950, loss is 4.940412139892578 and perplexity is 139.8278663279109
At time: 45.708993911743164 and batch: 1000, loss is 4.963967304229737 and perplexity is 143.16063252979384
At time: 46.098440647125244 and batch: 1050, loss is 4.855084600448609 and perplexity is 128.39155273822797
At time: 46.48785471916199 and batch: 1100, loss is 4.999017610549926 and perplexity is 148.2674311733323
At time: 46.877344608306885 and batch: 1150, loss is 4.936738395690918 and perplexity is 139.3151169464807
At time: 47.266615867614746 and batch: 1200, loss is 4.907603902816772 and perplexity is 135.3147982509062
At time: 47.656036615371704 and batch: 1250, loss is 4.883633232116699 and perplexity is 132.1097784816302
At time: 48.045631885528564 and batch: 1300, loss is 4.990723609924316 and perplexity is 147.04278662804782
At time: 48.4343101978302 and batch: 1350, loss is 4.948118734359741 and perplexity is 140.90962597642223
At time: 48.82265377044678 and batch: 1400, loss is 4.818916683197021 and perplexity is 123.83087002892324
At time: 49.212059020996094 and batch: 1450, loss is 4.907145709991455 and perplexity is 135.25281218305858
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.139559753939637 and perplexity of 170.64062791822442
Finished 4 epochs...
Completing Train Step...
At time: 50.559016942977905 and batch: 50, loss is 4.956378574371338 and perplexity is 142.0783369814448
At time: 50.94956064224243 and batch: 100, loss is 4.990596399307251 and perplexity is 147.02408241413843
At time: 51.34061789512634 and batch: 150, loss is 4.8818764400482175 and perplexity is 131.87789281771182
At time: 51.73231315612793 and batch: 200, loss is 4.956977052688599 and perplexity is 142.16339323510365
At time: 52.13766694068909 and batch: 250, loss is 4.955955276489258 and perplexity is 142.01820824939136
At time: 52.54652690887451 and batch: 300, loss is 4.969022808074951 and perplexity is 143.88621420312668
At time: 52.9462685585022 and batch: 350, loss is 4.995993251800537 and perplexity is 147.81969466979734
At time: 53.336992263793945 and batch: 400, loss is 4.86612566947937 and perplexity is 129.8169874156842
At time: 53.72776126861572 and batch: 450, loss is 4.914591121673584 and perplexity is 136.26358318477378
At time: 54.11841654777527 and batch: 500, loss is 4.929279117584229 and perplexity is 138.27979293011475
At time: 54.509320974349976 and batch: 550, loss is 4.971863813400269 and perplexity is 144.29557692941918
At time: 54.89993715286255 and batch: 600, loss is 4.8817822456359865 and perplexity is 131.8654712421423
At time: 55.29042911529541 and batch: 650, loss is 4.976579704284668 and perplexity is 144.97766619046692
At time: 55.68132448196411 and batch: 700, loss is 4.973378000259399 and perplexity is 144.5142328970556
At time: 56.07980251312256 and batch: 750, loss is 4.966920747756958 and perplexity is 143.5840743712739
At time: 56.47878670692444 and batch: 800, loss is 4.903811016082764 and perplexity is 134.80253663696092
At time: 56.87254238128662 and batch: 850, loss is 4.855150671005249 and perplexity is 128.40003591982645
At time: 57.26322674751282 and batch: 900, loss is 4.819018077850342 and perplexity is 123.84342645362662
At time: 57.65460181236267 and batch: 950, loss is 4.896257696151733 and perplexity is 133.788165707016
At time: 58.045711278915405 and batch: 1000, loss is 4.944704866409301 and perplexity is 140.42939930201908
At time: 58.44828128814697 and batch: 1050, loss is 4.833797349929809 and perplexity is 125.68733439387431
At time: 58.85406255722046 and batch: 1100, loss is 4.9552154636383055 and perplexity is 141.91318020919653
At time: 59.25355505943298 and batch: 1150, loss is 4.907913675308228 and perplexity is 135.35672154609773
At time: 59.64468169212341 and batch: 1200, loss is 4.870016098022461 and perplexity is 130.32301482239234
At time: 60.03669571876526 and batch: 1250, loss is 4.847894306182861 and perplexity is 127.47169069528454
At time: 60.427327156066895 and batch: 1300, loss is 4.9322833156585695 and perplexity is 138.69583744491348
At time: 60.8188362121582 and batch: 1350, loss is 4.923638706207275 and perplexity is 137.50203351637617
At time: 61.21027612686157 and batch: 1400, loss is 4.789071741104126 and perplexity is 120.18974966124867
At time: 61.60187792778015 and batch: 1450, loss is 4.884995527267456 and perplexity is 132.2898736357485
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.158417530548879 and perplexity of 173.88906363180686
Annealing...
Finished 5 epochs...
Completing Train Step...
At time: 62.877904653549194 and batch: 50, loss is 4.9109495162963865 and perplexity is 135.7682674072085
At time: 63.279895067214966 and batch: 100, loss is 4.901204690933228 and perplexity is 134.45165485014184
At time: 63.66921830177307 and batch: 150, loss is 4.791691293716431 and perplexity is 120.50500576865046
At time: 64.05958127975464 and batch: 200, loss is 4.862709255218506 and perplexity is 129.37423555111258
At time: 64.45009708404541 and batch: 250, loss is 4.884246854782105 and perplexity is 132.19086891294714
At time: 64.84010410308838 and batch: 300, loss is 4.889440336227417 and perplexity is 132.87918557066138
At time: 65.23000073432922 and batch: 350, loss is 4.9025302982330325 and perplexity is 134.63000312905555
At time: 65.62011814117432 and batch: 400, loss is 4.780677480697632 and perplexity is 119.1850682824098
At time: 66.01133823394775 and batch: 450, loss is 4.821165342330932 and perplexity is 124.10963675408071
At time: 66.40159773826599 and batch: 500, loss is 4.799778814315796 and perplexity is 121.48354412601253
At time: 66.79152274131775 and batch: 550, loss is 4.8545997428894045 and perplexity is 128.32931621248912
At time: 67.18060660362244 and batch: 600, loss is 4.766726732254028 and perplexity is 117.53389173063333
At time: 67.56858229637146 and batch: 650, loss is 4.860253868103027 and perplexity is 129.05696139490493
At time: 67.97005033493042 and batch: 700, loss is 4.880861835479736 and perplexity is 131.74415676125682
At time: 68.37247610092163 and batch: 750, loss is 4.841209001541138 and perplexity is 126.62234583768337
At time: 68.76983094215393 and batch: 800, loss is 4.7719082736969 and perplexity is 118.14447898705886
At time: 69.15952634811401 and batch: 850, loss is 4.717605409622192 and perplexity is 111.89997698265493
At time: 69.54931306838989 and batch: 900, loss is 4.676736545562744 and perplexity is 107.41894310899634
At time: 69.93885636329651 and batch: 950, loss is 4.7527815532684325 and perplexity is 115.90623592649804
At time: 70.32839012145996 and batch: 1000, loss is 4.792282056808472 and perplexity is 120.5762167107919
At time: 70.73427128791809 and batch: 1050, loss is 4.699260730743408 and perplexity is 109.86592192438943
At time: 71.12413096427917 and batch: 1100, loss is 4.829172878265381 and perplexity is 125.10743876629898
At time: 71.51328611373901 and batch: 1150, loss is 4.782172508239746 and perplexity is 119.36338650421389
At time: 71.91371583938599 and batch: 1200, loss is 4.717080059051514 and perplexity is 111.84120570500208
At time: 72.3065721988678 and batch: 1250, loss is 4.703615531921387 and perplexity is 110.34540944926302
At time: 72.69639897346497 and batch: 1300, loss is 4.791584615707397 and perplexity is 120.4921512202175
At time: 73.08681964874268 and batch: 1350, loss is 4.753108377456665 and perplexity is 115.94412307884747
At time: 73.4764051437378 and batch: 1400, loss is 4.617936592102051 and perplexity is 101.2848244566649
At time: 73.86732792854309 and batch: 1450, loss is 4.697692193984985 and perplexity is 109.69372826869643
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.043660481770833 and perplexity of 155.03648584557027
Finished 6 epochs...
Completing Train Step...
At time: 75.14398264884949 and batch: 50, loss is 4.807252082824707 and perplexity is 122.39482414960635
At time: 75.54591274261475 and batch: 100, loss is 4.826767301559448 and perplexity is 124.80684492159553
At time: 75.93484163284302 and batch: 150, loss is 4.715199089050293 and perplexity is 111.63103347796422
At time: 76.32457375526428 and batch: 200, loss is 4.792966327667236 and perplexity is 120.65875173708339
At time: 76.71346378326416 and batch: 250, loss is 4.809498815536499 and perplexity is 122.67012174903427
At time: 77.10271906852722 and batch: 300, loss is 4.818705167770386 and perplexity is 123.80468065944387
At time: 77.49138832092285 and batch: 350, loss is 4.847340993881225 and perplexity is 127.4011785501301
At time: 77.87960410118103 and batch: 400, loss is 4.710808067321778 and perplexity is 111.1419337939195
At time: 78.26656007766724 and batch: 450, loss is 4.758130445480346 and perplexity is 116.5278669256578
At time: 78.65400075912476 and batch: 500, loss is 4.73494026184082 and perplexity is 113.85665692795365
At time: 79.04315066337585 and batch: 550, loss is 4.78704137802124 and perplexity is 119.94596839658166
At time: 79.44448590278625 and batch: 600, loss is 4.704087133407593 and perplexity is 110.39746078113329
At time: 79.84052777290344 and batch: 650, loss is 4.8012345600128175 and perplexity is 121.66052205881071
At time: 80.23040866851807 and batch: 700, loss is 4.820562000274658 and perplexity is 124.03477877539233
At time: 80.6525571346283 and batch: 750, loss is 4.788263025283814 and perplexity is 120.09258960199213
At time: 81.05291318893433 and batch: 800, loss is 4.7087040042877195 and perplexity is 110.90833000422116
At time: 81.44684505462646 and batch: 850, loss is 4.66474760055542 and perplexity is 106.13879246861187
At time: 81.8376111984253 and batch: 900, loss is 4.632245988845825 and perplexity is 102.74456831306222
At time: 82.22653365135193 and batch: 950, loss is 4.715203523635864 and perplexity is 111.63152851643228
At time: 82.6164698600769 and batch: 1000, loss is 4.742284936904907 and perplexity is 114.69597556527462
At time: 83.00639200210571 and batch: 1050, loss is 4.652430067062378 and perplexity is 104.83944315505474
At time: 83.39738440513611 and batch: 1100, loss is 4.789517297744751 and perplexity is 120.24331293419507
At time: 83.78742337226868 and batch: 1150, loss is 4.730840358734131 and perplexity is 113.39081128004813
At time: 84.17661547660828 and batch: 1200, loss is 4.6661844730377195 and perplexity is 106.29140999852119
At time: 84.56639218330383 and batch: 1250, loss is 4.647276983261109 and perplexity is 104.3005862984799
At time: 84.95840883255005 and batch: 1300, loss is 4.7330998611450195 and perplexity is 113.64730775958958
At time: 85.36136674880981 and batch: 1350, loss is 4.702253465652466 and perplexity is 110.1952140004197
At time: 85.75793981552124 and batch: 1400, loss is 4.578826417922974 and perplexity is 97.40002018853687
At time: 86.15635561943054 and batch: 1450, loss is 4.658222570419311 and perplexity is 105.44848822633473
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0113587990785255 and perplexity of 150.10856501626978
Finished 7 epochs...
Completing Train Step...
At time: 87.5288016796112 and batch: 50, loss is 4.75062686920166 and perplexity is 115.65676347038887
At time: 87.93535876274109 and batch: 100, loss is 4.7783004188537594 and perplexity is 118.90209446061714
At time: 88.3335611820221 and batch: 150, loss is 4.655748910903931 and perplexity is 105.18796692339514
At time: 88.72371053695679 and batch: 200, loss is 4.745998573303223 and perplexity is 115.12270658637637
At time: 89.11227297782898 and batch: 250, loss is 4.766057348251342 and perplexity is 117.45524274985692
At time: 89.50143504142761 and batch: 300, loss is 4.75847843170166 and perplexity is 116.56842407400218
At time: 89.89202070236206 and batch: 350, loss is 4.776877269744873 and perplexity is 118.73299940312079
At time: 90.28154802322388 and batch: 400, loss is 4.652634010314942 and perplexity is 104.86082663252263
At time: 90.68494033813477 and batch: 450, loss is 4.704678506851196 and perplexity is 110.46276621572711
At time: 91.08537197113037 and batch: 500, loss is 4.689061269760132 and perplexity is 108.75104398231908
At time: 91.49045443534851 and batch: 550, loss is 4.734751091003418 and perplexity is 113.83512060590509
At time: 91.88998532295227 and batch: 600, loss is 4.657258224487305 and perplexity is 105.34684842152038
At time: 92.284592628479 and batch: 650, loss is 4.748067083358765 and perplexity is 115.36108552218775
At time: 92.67489862442017 and batch: 700, loss is 4.774887638092041 and perplexity is 118.49699932373979
At time: 93.06462907791138 and batch: 750, loss is 4.746078853607178 and perplexity is 115.13194904324189
At time: 93.46083378791809 and batch: 800, loss is 4.673207082748413 and perplexity is 107.0404802219609
At time: 93.84834814071655 and batch: 850, loss is 4.61959566116333 and perplexity is 101.4530024461716
At time: 94.2353367805481 and batch: 900, loss is 4.584038181304932 and perplexity is 97.90897116114832
At time: 94.6228289604187 and batch: 950, loss is 4.6730420207977295 and perplexity is 107.02281336959602
At time: 95.01034259796143 and batch: 1000, loss is 4.7032857131958 and perplexity is 110.30902146799278
At time: 95.39690256118774 and batch: 1050, loss is 4.616493635177612 and perplexity is 101.13878021099252
At time: 95.78403162956238 and batch: 1100, loss is 4.744563703536987 and perplexity is 114.95763894889038
At time: 96.1707136631012 and batch: 1150, loss is 4.701558418273926 and perplexity is 110.1186497167857
At time: 96.55740666389465 and batch: 1200, loss is 4.634306116104126 and perplexity is 102.95645337904749
At time: 96.9463963508606 and batch: 1250, loss is 4.6225621795654295 and perplexity is 101.75441149157723
At time: 97.3354377746582 and batch: 1300, loss is 4.704129018783569 and perplexity is 110.40208491712612
At time: 97.72321510314941 and batch: 1350, loss is 4.661269598007202 and perplexity is 105.77028268839177
At time: 98.11086869239807 and batch: 1400, loss is 4.540828828811645 and perplexity is 93.76848594367654
At time: 98.49968242645264 and batch: 1450, loss is 4.6187080383300785 and perplexity is 101.3629903989825
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.025425055088141 and perplexity of 152.23495060268107
Annealing...
Finished 8 epochs...
Completing Train Step...
At time: 99.77348351478577 and batch: 50, loss is 4.706127443313599 and perplexity is 110.62293575515598
At time: 100.16683268547058 and batch: 100, loss is 4.691823301315307 and perplexity is 109.05183300061442
At time: 100.57144618034363 and batch: 150, loss is 4.57150050163269 and perplexity is 96.68908310634657
At time: 100.9620885848999 and batch: 200, loss is 4.642425889968872 and perplexity is 103.79583970018386
At time: 101.3521876335144 and batch: 250, loss is 4.671936902999878 and perplexity is 106.90460588239455
At time: 101.74219155311584 and batch: 300, loss is 4.679328107833863 and perplexity is 107.69768702425988
At time: 102.13209557533264 and batch: 350, loss is 4.681673603057861 and perplexity is 107.9505879077769
At time: 102.5225305557251 and batch: 400, loss is 4.550933437347412 and perplexity is 94.72078297880994
At time: 102.91252708435059 and batch: 450, loss is 4.599560279846191 and perplexity is 99.4405799997845
At time: 103.31647253036499 and batch: 500, loss is 4.586799812316895 and perplexity is 98.17973331275071
At time: 103.71502089500427 and batch: 550, loss is 4.627109308242797 and perplexity is 102.21815544679292
At time: 104.1132025718689 and batch: 600, loss is 4.545814065933228 and perplexity is 94.2371112141392
At time: 104.52070116996765 and batch: 650, loss is 4.633638572692871 and perplexity is 102.88774841127376
At time: 104.91810750961304 and batch: 700, loss is 4.6654451465606686 and perplexity is 106.21285498730425
At time: 105.30799651145935 and batch: 750, loss is 4.635768613815308 and perplexity is 103.10713711691848
At time: 105.71350240707397 and batch: 800, loss is 4.570936851501465 and perplexity is 96.63459964821219
At time: 106.10954070091248 and batch: 850, loss is 4.508246154785156 and perplexity is 90.76249546902636
At time: 106.50019383430481 and batch: 900, loss is 4.471191654205322 and perplexity is 87.46088406943726
At time: 106.89097476005554 and batch: 950, loss is 4.56225432395935 and perplexity is 95.79919901787541
At time: 107.28249216079712 and batch: 1000, loss is 4.585910863876343 and perplexity is 98.09249537268879
At time: 107.67260646820068 and batch: 1050, loss is 4.499881105422974 and perplexity is 90.006429387983
At time: 108.0740396976471 and batch: 1100, loss is 4.624427289962768 and perplexity is 101.94437179582764
At time: 108.48108625411987 and batch: 1150, loss is 4.575423631668091 and perplexity is 97.06915199474393
At time: 108.87982511520386 and batch: 1200, loss is 4.511645927429199 and perplexity is 91.07159245023402
At time: 109.26950454711914 and batch: 1250, loss is 4.500019636154175 and perplexity is 90.01889890814485
At time: 109.65981912612915 and batch: 1300, loss is 4.572754278182983 and perplexity is 96.81038563865968
At time: 110.04970455169678 and batch: 1350, loss is 4.527472639083863 and perplexity is 92.52442272089814
At time: 110.45182728767395 and batch: 1400, loss is 4.4076731300354 and perplexity is 82.0782557046846
At time: 110.85029697418213 and batch: 1450, loss is 4.494793195724487 and perplexity is 89.54964782004348
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.952317979600695 and perplexity of 141.50258416980907
Finished 9 epochs...
Completing Train Step...
At time: 112.15711426734924 and batch: 50, loss is 4.641942281723022 and perplexity is 103.74565531198996
At time: 112.56479549407959 and batch: 100, loss is 4.642690773010254 and perplexity is 103.82333709952303
At time: 112.96466088294983 and batch: 150, loss is 4.532727003097534 and perplexity is 93.01185918088356
At time: 113.36026930809021 and batch: 200, loss is 4.605850372314453 and perplexity is 100.06804177055385
At time: 113.76138639450073 and batch: 250, loss is 4.634668827056885 and perplexity is 102.99380358560029
At time: 114.16769409179688 and batch: 300, loss is 4.641652479171753 and perplexity is 103.71559391254296
At time: 114.56527161598206 and batch: 350, loss is 4.650665254592895 and perplexity is 104.65458436700774
At time: 114.95515704154968 and batch: 400, loss is 4.520136566162109 and perplexity is 91.84814046973813
At time: 115.36047220230103 and batch: 450, loss is 4.567343626022339 and perplexity is 96.28799283373739
At time: 115.7633945941925 and batch: 500, loss is 4.559436273574829 and perplexity is 95.52961208143952
At time: 116.16892600059509 and batch: 550, loss is 4.597891798019409 and perplexity is 99.27480353517731
At time: 116.56581950187683 and batch: 600, loss is 4.517744722366333 and perplexity is 91.62871658324163
At time: 116.95845055580139 and batch: 650, loss is 4.607985954284668 and perplexity is 100.28197362955748
At time: 117.36176085472107 and batch: 700, loss is 4.642152595520019 and perplexity is 103.76747674927483
At time: 117.75864672660828 and batch: 750, loss is 4.6081613922119145 and perplexity is 100.29956843450412
At time: 118.15950918197632 and batch: 800, loss is 4.547123413085938 and perplexity is 94.36058112223374
At time: 118.55603361129761 and batch: 850, loss is 4.489328002929687 and perplexity is 89.06157664635349
At time: 118.94554781913757 and batch: 900, loss is 4.450008115768433 and perplexity is 85.62763893346963
At time: 119.33430027961731 and batch: 950, loss is 4.538841686248779 and perplexity is 93.58233960511204
At time: 119.72330689430237 and batch: 1000, loss is 4.571178560256958 and perplexity is 96.65795990010574
At time: 120.127037525177 and batch: 1050, loss is 4.482850837707519 and perplexity is 88.4865743023477
At time: 120.53011703491211 and batch: 1100, loss is 4.603248615264892 and perplexity is 99.80802743118453
At time: 120.95278191566467 and batch: 1150, loss is 4.547672348022461 and perplexity is 94.4123931612605
At time: 121.34782218933105 and batch: 1200, loss is 4.49075098991394 and perplexity is 89.18840032353893
At time: 121.73732614517212 and batch: 1250, loss is 4.485459175109863 and perplexity is 88.71767841142663
At time: 122.12650108337402 and batch: 1300, loss is 4.560598316192627 and perplexity is 95.64068608580428
At time: 122.5287537574768 and batch: 1350, loss is 4.515415849685669 and perplexity is 91.41557325659637
At time: 122.93403244018555 and batch: 1400, loss is 4.39380030632019 and perplexity is 80.94746033045017
At time: 123.33044815063477 and batch: 1450, loss is 4.480026531219482 and perplexity is 88.2370136801729
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.948819152310363 and perplexity of 141.00835618003867
Finished 10 epochs...
Completing Train Step...
At time: 124.62543392181396 and batch: 50, loss is 4.614374380111695 and perplexity is 100.92466829768385
At time: 125.049973487854 and batch: 100, loss is 4.615660753250122 and perplexity is 101.05457861864616
At time: 125.45058178901672 and batch: 150, loss is 4.507954921722412 and perplexity is 90.73606627820253
At time: 125.85115051269531 and batch: 200, loss is 4.57712290763855 and perplexity is 97.23423949708962
At time: 126.2425446510315 and batch: 250, loss is 4.611810274124146 and perplexity is 100.66621823968228
At time: 126.63018560409546 and batch: 300, loss is 4.617761907577514 and perplexity is 101.26713311050906
At time: 127.01829981803894 and batch: 350, loss is 4.623133354187011 and perplexity is 101.81254763041825
At time: 127.40719079971313 and batch: 400, loss is 4.493489875793457 and perplexity is 89.43301200262586
At time: 127.79536604881287 and batch: 450, loss is 4.542681007385254 and perplexity is 93.94232286303324
At time: 128.18431329727173 and batch: 500, loss is 4.536339330673218 and perplexity is 93.34845606775794
At time: 128.5729923248291 and batch: 550, loss is 4.573413333892822 and perplexity is 96.87421010571609
At time: 128.96573305130005 and batch: 600, loss is 4.496611423492432 and perplexity is 89.71261758950214
At time: 129.36437559127808 and batch: 650, loss is 4.588303565979004 and perplexity is 98.3274825076193
At time: 129.7529866695404 and batch: 700, loss is 4.622291116714478 and perplexity is 101.72683338856989
At time: 130.14215397834778 and batch: 750, loss is 4.5858726978302 and perplexity is 98.08875164142627
At time: 130.53856682777405 and batch: 800, loss is 4.526789655685425 and perplexity is 92.46125165108131
At time: 130.95709037780762 and batch: 850, loss is 4.4710695171356205 and perplexity is 87.45020250566424
At time: 131.361083984375 and batch: 900, loss is 4.426342515945435 and perplexity is 83.62499979069017
At time: 131.75559735298157 and batch: 950, loss is 4.515213203430176 and perplexity is 91.3970501098687
At time: 132.14436769485474 and batch: 1000, loss is 4.553525810241699 and perplexity is 94.96665312498565
At time: 132.5487847328186 and batch: 1050, loss is 4.470444459915161 and perplexity is 87.39555820484391
At time: 132.9431493282318 and batch: 1100, loss is 4.594401073455811 and perplexity is 98.92886667635045
At time: 133.33182644844055 and batch: 1150, loss is 4.533240947723389 and perplexity is 93.05967441218841
At time: 133.71938800811768 and batch: 1200, loss is 4.475546398162842 and perplexity is 87.84258432609418
At time: 134.10776233673096 and batch: 1250, loss is 4.471366500854492 and perplexity is 87.47617764892684
At time: 134.49640202522278 and batch: 1300, loss is 4.543239765167236 and perplexity is 93.99482853460064
At time: 134.8843069076538 and batch: 1350, loss is 4.498927507400513 and perplexity is 89.92064034554149
At time: 135.2729308605194 and batch: 1400, loss is 4.3791338109970095 and perplexity is 79.76890852045803
At time: 135.66144704818726 and batch: 1450, loss is 4.46409951210022 and perplexity is 86.84279343503489
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.950543786725428 and perplexity of 141.25175386960504
Annealing...
Finished 11 epochs...
Completing Train Step...
At time: 136.94335007667542 and batch: 50, loss is 4.5847780132293705 and perplexity is 97.9814341456117
At time: 137.33450174331665 and batch: 100, loss is 4.572482862472534 and perplexity is 96.7841133445807
At time: 137.7248673439026 and batch: 150, loss is 4.46112244606018 and perplexity is 86.58464116272407
At time: 138.1156895160675 and batch: 200, loss is 4.521684026718139 and perplexity is 91.99038187235509
At time: 138.519433259964 and batch: 250, loss is 4.558465824127198 and perplexity is 95.43695039117787
At time: 138.91325569152832 and batch: 300, loss is 4.561381607055664 and perplexity is 95.71562990892403
At time: 139.3057403564453 and batch: 350, loss is 4.562819223403931 and perplexity is 95.85333122037794
At time: 139.71970987319946 and batch: 400, loss is 4.431410417556763 and perplexity is 84.04987877495215
At time: 140.11897253990173 and batch: 450, loss is 4.481418304443359 and perplexity is 88.35990509181885
At time: 140.51180410385132 and batch: 500, loss is 4.469473495483398 and perplexity is 87.31074141004203
At time: 140.91630458831787 and batch: 550, loss is 4.50528037071228 and perplexity is 90.49371227901713
At time: 141.30641674995422 and batch: 600, loss is 4.437258024215698 and perplexity is 84.54280923284799
At time: 141.6973946094513 and batch: 650, loss is 4.525989151000976 and perplexity is 92.38726560304455
At time: 142.08808875083923 and batch: 700, loss is 4.5573771286010745 and perplexity is 95.3331051484427
At time: 142.4903907775879 and batch: 750, loss is 4.516023464202881 and perplexity is 91.47113556452933
At time: 142.8915491104126 and batch: 800, loss is 4.455990839004516 and perplexity is 86.14146089325635
At time: 143.30229377746582 and batch: 850, loss is 4.40682701587677 and perplexity is 82.00883750242052
At time: 143.7070279121399 and batch: 900, loss is 4.362938871383667 and perplexity is 78.4874603593832
At time: 144.10589790344238 and batch: 950, loss is 4.449087762832642 and perplexity is 85.5488675388948
At time: 144.49618673324585 and batch: 1000, loss is 4.481533298492431 and perplexity is 88.3700665393228
At time: 144.90815424919128 and batch: 1050, loss is 4.3972133350372316 and perplexity is 81.2242083429389
At time: 145.31408405303955 and batch: 1100, loss is 4.518177070617676 and perplexity is 91.66834066371287
At time: 145.71685981750488 and batch: 1150, loss is 4.45365195274353 and perplexity is 85.94022124393555
At time: 146.11647605895996 and batch: 1200, loss is 4.398464035987854 and perplexity is 81.32585909162036
At time: 146.5073962211609 and batch: 1250, loss is 4.393583207130432 and perplexity is 80.92988860987163
At time: 146.89855647087097 and batch: 1300, loss is 4.459150533676148 and perplexity is 86.41407206547649
At time: 147.289537191391 and batch: 1350, loss is 4.412780065536499 and perplexity is 82.49849621986407
At time: 147.68108463287354 and batch: 1400, loss is 4.2940287733078 and perplexity is 73.26102681621535
At time: 148.0851128101349 and batch: 1450, loss is 4.384741382598877 and perplexity is 80.21747489519666
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.90467038928953 and perplexity of 134.91843211675328
Finished 12 epochs...
Completing Train Step...
At time: 149.4405665397644 and batch: 50, loss is 4.544437265396118 and perplexity is 94.10745478480584
At time: 149.83688163757324 and batch: 100, loss is 4.54493932723999 and perplexity is 94.15471440971172
At time: 150.22838854789734 and batch: 150, loss is 4.436491947174073 and perplexity is 84.47806772931622
At time: 150.6175844669342 and batch: 200, loss is 4.498563585281372 and perplexity is 89.88792218934388
At time: 151.0189986228943 and batch: 250, loss is 4.537919578552246 and perplexity is 93.49608638299416
At time: 151.4085991382599 and batch: 300, loss is 4.5418346118927 and perplexity is 93.86284414436129
At time: 151.81588006019592 and batch: 350, loss is 4.5457008361816404 and perplexity is 94.22644137352923
At time: 152.20328211784363 and batch: 400, loss is 4.417179269790649 and perplexity is 82.86222342392647
At time: 152.5921287536621 and batch: 450, loss is 4.469116907119751 and perplexity is 87.27961296598414
At time: 152.97899103164673 and batch: 500, loss is 4.45725040435791 and perplexity is 86.25003005351076
At time: 153.36817455291748 and batch: 550, loss is 4.49330304145813 and perplexity is 89.41630440609705
At time: 153.7555947303772 and batch: 600, loss is 4.424163732528687 and perplexity is 83.44299737184522
At time: 154.1427707672119 and batch: 650, loss is 4.5142834186553955 and perplexity is 91.31211001833786
At time: 154.53045654296875 and batch: 700, loss is 4.545865058898926 and perplexity is 94.24191676644247
At time: 154.91840386390686 and batch: 750, loss is 4.5059534740448 and perplexity is 90.55464440283146
At time: 155.30635738372803 and batch: 800, loss is 4.445273375511169 and perplexity is 85.2231725814391
At time: 155.6944718360901 and batch: 850, loss is 4.397717275619507 and perplexity is 81.26515083321081
At time: 156.0821943283081 and batch: 900, loss is 4.353927450180054 and perplexity is 77.78335405888718
At time: 156.4696171283722 and batch: 950, loss is 4.441746263504029 and perplexity is 84.92311039369054
At time: 156.85735821723938 and batch: 1000, loss is 4.474852495193481 and perplexity is 87.78165123926388
At time: 157.2446825504303 and batch: 1050, loss is 4.392614240646362 and perplexity is 80.85150824035726
At time: 157.632226228714 and batch: 1100, loss is 4.511986408233643 and perplexity is 91.10260585872898
At time: 158.01983261108398 and batch: 1150, loss is 4.449828300476074 and perplexity is 85.61224315878022
At time: 158.40780925750732 and batch: 1200, loss is 4.39584222316742 and perplexity is 81.11291718051585
At time: 158.79654169082642 and batch: 1250, loss is 4.394115405082703 and perplexity is 80.97297079397549
At time: 159.18584418296814 and batch: 1300, loss is 4.457227869033813 and perplexity is 86.24808640303064
At time: 159.5885510444641 and batch: 1350, loss is 4.410795965194702 and perplexity is 82.33497320199882
At time: 159.9854793548584 and batch: 1400, loss is 4.294586906433105 and perplexity is 73.30192763506453
At time: 160.38127732276917 and batch: 1450, loss is 4.3838525485992434 and perplexity is 80.14620655369956
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.904084556123131 and perplexity of 134.83941557197693
Finished 13 epochs...
Completing Train Step...
At time: 161.68517971038818 and batch: 50, loss is 4.531896924972534 and perplexity is 92.93468410631381
At time: 162.09663438796997 and batch: 100, loss is 4.534473886489868 and perplexity is 93.1744820532192
At time: 162.48619079589844 and batch: 150, loss is 4.4261363697052 and perplexity is 83.607762588147
At time: 162.87487053871155 and batch: 200, loss is 4.486214351654053 and perplexity is 88.7847012250611
At time: 163.26338267326355 and batch: 250, loss is 4.525838623046875 and perplexity is 92.37335978360183
At time: 163.65229058265686 and batch: 300, loss is 4.530054025650024 and perplexity is 92.76357255904243
At time: 164.0418665409088 and batch: 350, loss is 4.534643478393555 and perplexity is 93.19028503099628
At time: 164.4312081336975 and batch: 400, loss is 4.4064748573303225 and perplexity is 81.97996247400225
At time: 164.82772016525269 and batch: 450, loss is 4.4584810829162596 and perplexity is 86.3562414587988
At time: 165.21693539619446 and batch: 500, loss is 4.447451658248902 and perplexity is 85.40901508240005
At time: 165.60615706443787 and batch: 550, loss is 4.485888147354126 and perplexity is 88.75574399699671
At time: 165.99553036689758 and batch: 600, loss is 4.414969081878662 and perplexity is 82.67928457843728
At time: 166.38474369049072 and batch: 650, loss is 4.507223272323609 and perplexity is 90.6697035699385
At time: 166.78906393051147 and batch: 700, loss is 4.5380464363098145 and perplexity is 93.50794783919713
At time: 167.17989563941956 and batch: 750, loss is 4.498661279678345 and perplexity is 89.89670416466524
At time: 167.56875681877136 and batch: 800, loss is 4.437611556053161 and perplexity is 84.57270309144442
At time: 167.9578835964203 and batch: 850, loss is 4.390261316299439 and perplexity is 80.66149438990425
At time: 168.34711074829102 and batch: 900, loss is 4.346750755310058 and perplexity is 77.22712499136654
At time: 168.7428891658783 and batch: 950, loss is 4.435053806304932 and perplexity is 84.35666368655093
At time: 169.13605976104736 and batch: 1000, loss is 4.469527292251587 and perplexity is 87.31543857210298
At time: 169.52774167060852 and batch: 1050, loss is 4.388556680679321 and perplexity is 80.52411305921692
At time: 169.92971014976501 and batch: 1100, loss is 4.506120471954346 and perplexity is 90.56976810192434
At time: 170.33522248268127 and batch: 1150, loss is 4.444903793334961 and perplexity is 85.1916814354947
At time: 170.74587512016296 and batch: 1200, loss is 4.391446604728698 and perplexity is 80.7571582093006
At time: 171.15760707855225 and batch: 1250, loss is 4.390027928352356 and perplexity is 80.64267116596218
At time: 171.54871344566345 and batch: 1300, loss is 4.452457866668701 and perplexity is 85.8376624666704
At time: 171.9386920928955 and batch: 1350, loss is 4.406004152297974 and perplexity is 81.9413831735617
At time: 172.3279058933258 and batch: 1400, loss is 4.291637616157532 and perplexity is 73.0860574610876
At time: 172.71791076660156 and batch: 1450, loss is 4.379461450576782 and perplexity is 79.79504825409643
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.905039730235043 and perplexity of 134.96827222146752
Annealing...
Finished 14 epochs...
Completing Train Step...
At time: 173.979416847229 and batch: 50, loss is 4.521368427276611 and perplexity is 91.96135433998765
At time: 174.39829349517822 and batch: 100, loss is 4.519117774963379 and perplexity is 91.75461404264777
At time: 174.79138827323914 and batch: 150, loss is 4.405945320129394 and perplexity is 81.93656252609917
At time: 175.19069933891296 and batch: 200, loss is 4.462985038757324 and perplexity is 86.74606336828134
At time: 175.5871386528015 and batch: 250, loss is 4.505517206192017 and perplexity is 90.51514693892163
At time: 175.97694563865662 and batch: 300, loss is 4.505046367645264 and perplexity is 90.47253895020667
At time: 176.37478804588318 and batch: 350, loss is 4.508608274459839 and perplexity is 90.79536830595028
At time: 176.77672028541565 and batch: 400, loss is 4.381214594841003 and perplexity is 79.93506318257923
At time: 177.17289280891418 and batch: 450, loss is 4.433897695541382 and perplexity is 84.25919439319169
At time: 177.5637936592102 and batch: 500, loss is 4.414882555007934 and perplexity is 82.6721309081655
At time: 177.95257592201233 and batch: 550, loss is 4.454717693328857 and perplexity is 86.03186004855019
At time: 178.3415071964264 and batch: 600, loss is 4.385630836486817 and perplexity is 80.2888563806868
At time: 178.73005986213684 and batch: 650, loss is 4.477836227416992 and perplexity is 88.0439593146247
At time: 179.11829733848572 and batch: 700, loss is 4.505767526626587 and perplexity is 90.53780756592928
At time: 179.51789712905884 and batch: 750, loss is 4.464322805404663 and perplexity is 86.86218701449572
At time: 179.92033123970032 and batch: 800, loss is 4.403964648246765 and perplexity is 81.77443369555589
At time: 180.33530044555664 and batch: 850, loss is 4.353526058197022 and perplexity is 77.75213870936925
At time: 180.7312307357788 and batch: 900, loss is 4.308606023788452 and perplexity is 74.33679296124225
At time: 181.13659048080444 and batch: 950, loss is 4.396894760131836 and perplexity is 81.19833646973382
At time: 181.52729725837708 and batch: 1000, loss is 4.435572729110718 and perplexity is 84.40044964294103
At time: 181.91680574417114 and batch: 1050, loss is 4.349815549850464 and perplexity is 77.46417332908808
At time: 182.30664205551147 and batch: 1100, loss is 4.46822566986084 and perplexity is 87.20186077593644
At time: 182.7091670036316 and batch: 1150, loss is 4.4033026599884035 and perplexity is 81.72031789460394
At time: 183.10192036628723 and batch: 1200, loss is 4.353378367424011 and perplexity is 77.74065628384507
At time: 183.50159573554993 and batch: 1250, loss is 4.348667707443237 and perplexity is 77.37530767753888
At time: 183.8942129611969 and batch: 1300, loss is 4.408742933273316 and perplexity is 82.16611027357207
At time: 184.28264832496643 and batch: 1350, loss is 4.361498193740845 and perplexity is 78.3744666433055
At time: 184.67084074020386 and batch: 1400, loss is 4.245494470596314 and perplexity is 69.7902608453061
At time: 185.06015539169312 and batch: 1450, loss is 4.33366961479187 and perplexity is 76.223484808225
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.88399668636485 and perplexity of 132.15780306868308
Finished 15 epochs...
Completing Train Step...
At time: 186.33960485458374 and batch: 50, loss is 4.502021532058716 and perplexity is 90.1992878729216
At time: 186.72992587089539 and batch: 100, loss is 4.5034535694122315 and perplexity is 90.32854915381739
At time: 187.11990189552307 and batch: 150, loss is 4.390741500854492 and perplexity is 80.7002360945375
At time: 187.50997281074524 and batch: 200, loss is 4.451018600463867 and perplexity is 85.71420808315239
At time: 187.91174244880676 and batch: 250, loss is 4.492814464569092 and perplexity is 89.37262833668888
At time: 188.309739112854 and batch: 300, loss is 4.493723134994507 and perplexity is 89.45387550876092
At time: 188.69966197013855 and batch: 350, loss is 4.49904839515686 and perplexity is 89.93151130707203
At time: 189.09511613845825 and batch: 400, loss is 4.37427312374115 and perplexity is 79.38211759978384
At time: 189.48978734016418 and batch: 450, loss is 4.424762773513794 and perplexity is 83.4929981219452
At time: 189.89517855644226 and batch: 500, loss is 4.406324281692505 and perplexity is 81.96761921818457
At time: 190.29441809654236 and batch: 550, loss is 4.447037773132324 and perplexity is 85.3736728765469
At time: 190.6840295791626 and batch: 600, loss is 4.37815902709961 and perplexity is 79.69118895896179
At time: 191.09868335723877 and batch: 650, loss is 4.47133243560791 and perplexity is 87.47319780212008
At time: 191.5038866996765 and batch: 700, loss is 4.498447456359863 and perplexity is 89.8774842079709
At time: 192.07860708236694 and batch: 750, loss is 4.457737722396851 and perplexity is 86.29207149195868
At time: 192.4684500694275 and batch: 800, loss is 4.399348230361938 and perplexity is 81.39779875833415
At time: 192.85927772521973 and batch: 850, loss is 4.350099358558655 and perplexity is 77.48616145611504
At time: 193.24945950508118 and batch: 900, loss is 4.306479082107544 and perplexity is 74.17885096411894
At time: 193.64021015167236 and batch: 950, loss is 4.394791584014893 and perplexity is 81.027741526224
At time: 194.03068161010742 and batch: 1000, loss is 4.4341653537750245 and perplexity is 84.28175007880397
At time: 194.42040061950684 and batch: 1050, loss is 4.3482547378540035 and perplexity is 77.34336062554496
At time: 194.8103153705597 and batch: 1100, loss is 4.467790508270264 and perplexity is 87.16392213081926
At time: 195.19930505752563 and batch: 1150, loss is 4.401911039352417 and perplexity is 81.60667330725927
At time: 195.59805703163147 and batch: 1200, loss is 4.353114051818848 and perplexity is 77.72011093058192
At time: 195.9947111606598 and batch: 1250, loss is 4.3500680112838745 and perplexity is 77.48373251419076
At time: 196.38598012924194 and batch: 1300, loss is 4.4093526840209964 and perplexity is 82.21622639836494
At time: 196.77576398849487 and batch: 1350, loss is 4.362338714599609 and perplexity is 78.44036970988488
At time: 197.16556596755981 and batch: 1400, loss is 4.245776224136352 and perplexity is 69.80992726877157
At time: 197.55504846572876 and batch: 1450, loss is 4.33372124671936 and perplexity is 76.2274204752678
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.883167234241453 and perplexity of 132.04822994741545
Finished 16 epochs...
Completing Train Step...
At time: 198.83689093589783 and batch: 50, loss is 4.4954563236236575 and perplexity is 89.60905038344559
At time: 199.2253131866455 and batch: 100, loss is 4.496820945739746 and perplexity is 89.7314163480622
At time: 199.61433863639832 and batch: 150, loss is 4.38440089225769 and perplexity is 80.19016626922597
At time: 200.00362944602966 and batch: 200, loss is 4.444683027267456 and perplexity is 85.17287607886874
At time: 200.39320731163025 and batch: 250, loss is 4.485792655944824 and perplexity is 88.74726899057033
At time: 200.78153443336487 and batch: 300, loss is 4.487623643875122 and perplexity is 88.9099130231304
At time: 201.1840364933014 and batch: 350, loss is 4.493968744277954 and perplexity is 89.47584890935126
At time: 201.57271432876587 and batch: 400, loss is 4.370512194633484 and perplexity is 79.08412779358777
At time: 201.98590278625488 and batch: 450, loss is 4.418961210250854 and perplexity is 83.01001060734306
At time: 202.38905906677246 and batch: 500, loss is 4.40152286529541 and perplexity is 81.57500186121734
At time: 202.78401064872742 and batch: 550, loss is 4.442751569747925 and perplexity is 85.00852705457787
At time: 203.17545199394226 and batch: 600, loss is 4.374175748825073 and perplexity is 79.37438814907796
At time: 203.56420516967773 and batch: 650, loss is 4.467504568099976 and perplexity is 87.13900202708133
At time: 203.95311951637268 and batch: 700, loss is 4.493611879348755 and perplexity is 89.44392381367756
At time: 204.34150099754333 and batch: 750, loss is 4.453421487808227 and perplexity is 85.9204173185495
At time: 204.72986316680908 and batch: 800, loss is 4.395687093734741 and perplexity is 81.10033515563718
At time: 205.1197543144226 and batch: 850, loss is 4.346786880493164 and perplexity is 77.22991488579004
At time: 205.50876712799072 and batch: 900, loss is 4.3036590051651 and perplexity is 73.96995558586033
At time: 205.89709782600403 and batch: 950, loss is 4.392558526992798 and perplexity is 80.84700383291667
At time: 206.2850661277771 and batch: 1000, loss is 4.432407217025757 and perplexity is 84.13370141972734
At time: 206.67265129089355 and batch: 1050, loss is 4.346798896789551 and perplexity is 77.23084290891289
At time: 207.0597789287567 and batch: 1100, loss is 4.466429986953735 and perplexity is 87.04541439116103
At time: 207.44780826568604 and batch: 1150, loss is 4.399645652770996 and perplexity is 81.42201188831808
At time: 207.83486819267273 and batch: 1200, loss is 4.35128333568573 and perplexity is 77.57795763050603
At time: 208.2229561805725 and batch: 1250, loss is 4.3492281627655025 and perplexity is 77.41868523499471
At time: 208.62602829933167 and batch: 1300, loss is 4.408497581481933 and perplexity is 82.14595314412057
At time: 209.0185239315033 and batch: 1350, loss is 4.360747194290161 and perplexity is 78.31562955798344
At time: 209.40714859962463 and batch: 1400, loss is 4.244622731208802 and perplexity is 69.72944843619972
At time: 209.7933750152588 and batch: 1450, loss is 4.3314316368103025 and perplexity is 76.05308906962095
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.883024818876869 and perplexity of 132.02942558965134
Finished 17 epochs...
Completing Train Step...
At time: 211.04100108146667 and batch: 50, loss is 4.49048186302185 and perplexity is 89.16440055618563
At time: 211.44193959236145 and batch: 100, loss is 4.491252355575561 and perplexity is 89.23312753628343
At time: 211.84017729759216 and batch: 150, loss is 4.379130840301514 and perplexity is 79.76867155167277
At time: 212.23284816741943 and batch: 200, loss is 4.439616394042969 and perplexity is 84.74242773786344
At time: 212.61934185028076 and batch: 250, loss is 4.479954605102539 and perplexity is 88.23066736264393
At time: 213.00678133964539 and batch: 300, loss is 4.482217254638672 and perplexity is 88.43052846377151
At time: 213.39402222633362 and batch: 350, loss is 4.489271659851074 and perplexity is 89.05655878430129
At time: 213.7817358970642 and batch: 400, loss is 4.367259383201599 and perplexity is 78.82729997131152
At time: 214.16853427886963 and batch: 450, loss is 4.414067697525025 and perplexity is 82.60479234305976
At time: 214.55598855018616 and batch: 500, loss is 4.3967702293396 and perplexity is 81.18822540614741
At time: 214.94318556785583 and batch: 550, loss is 4.438440866470337 and perplexity is 84.64286920585026
At time: 215.33042335510254 and batch: 600, loss is 4.3701407337188725 and perplexity is 79.05475658661172
At time: 215.71874260902405 and batch: 650, loss is 4.46385666847229 and perplexity is 86.82170677650149
At time: 216.1063277721405 and batch: 700, loss is 4.489966840744018 and perplexity is 89.11849072681689
At time: 216.49309635162354 and batch: 750, loss is 4.4499992084503175 and perplexity is 85.62687622424706
At time: 216.88001608848572 and batch: 800, loss is 4.392361006736755 and perplexity is 80.83103648900816
At time: 217.2670738697052 and batch: 850, loss is 4.34400059223175 and perplexity is 77.01502958572836
At time: 217.65356349945068 and batch: 900, loss is 4.30099515914917 and perplexity is 73.77317322968734
At time: 218.04065918922424 and batch: 950, loss is 4.390229697227478 and perplexity is 80.65894398862956
At time: 218.42738723754883 and batch: 1000, loss is 4.430246753692627 and perplexity is 83.95212985271127
At time: 218.82702469825745 and batch: 1050, loss is 4.344836549758911 and perplexity is 77.07943779692873
At time: 219.2133331298828 and batch: 1100, loss is 4.464556188583374 and perplexity is 86.88246155358708
At time: 219.60081124305725 and batch: 1150, loss is 4.39709062576294 and perplexity is 81.21424199077262
At time: 219.98782992362976 and batch: 1200, loss is 4.349432573318482 and perplexity is 77.43451204878329
At time: 220.37514638900757 and batch: 1250, loss is 4.347756805419922 and perplexity is 77.3048584442666
At time: 220.76177191734314 and batch: 1300, loss is 4.407072439193725 and perplexity is 82.02896685334501
At time: 221.1485300064087 and batch: 1350, loss is 4.358593626022339 and perplexity is 78.14715298131173
At time: 221.5354688167572 and batch: 1400, loss is 4.242662134170533 and perplexity is 69.59287101650746
At time: 221.92243266105652 and batch: 1450, loss is 4.329523324966431 and perplexity is 75.90809445046256
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8832094893496265 and perplexity of 132.0538097775433
Annealing...
Finished 18 epochs...
Completing Train Step...
At time: 223.29347276687622 and batch: 50, loss is 4.486820945739746 and perplexity is 88.83857383747637
At time: 223.7032811641693 and batch: 100, loss is 4.485309782028199 and perplexity is 88.7044255940149
At time: 224.09226036071777 and batch: 150, loss is 4.370930471420288 and perplexity is 79.1172137675135
At time: 224.4817488193512 and batch: 200, loss is 4.430443029403687 and perplexity is 83.96860923389134
At time: 224.87027049064636 and batch: 250, loss is 4.471618728637695 and perplexity is 87.49824435409941
At time: 225.26014733314514 and batch: 300, loss is 4.471866350173951 and perplexity is 87.51991348654722
At time: 225.64981722831726 and batch: 350, loss is 4.478619813919067 and perplexity is 88.11297640963353
At time: 226.05011105537415 and batch: 400, loss is 4.355416421890259 and perplexity is 77.89925753969422
At time: 226.4489724636078 and batch: 450, loss is 4.40258786201477 and perplexity is 81.66192524892685
At time: 226.8403947353363 and batch: 500, loss is 4.381812839508057 and perplexity is 79.98289821493864
At time: 227.22858238220215 and batch: 550, loss is 4.425539112091064 and perplexity is 83.55784212451279
At time: 227.61682868003845 and batch: 600, loss is 4.3558612728118895 and perplexity is 77.93391880518145
At time: 228.0057077407837 and batch: 650, loss is 4.449252996444702 and perplexity is 85.5630042551841
At time: 228.39466667175293 and batch: 700, loss is 4.474472160339356 and perplexity is 87.74827116594993
At time: 228.79973602294922 and batch: 750, loss is 4.433777980804443 and perplexity is 84.24910792966146
At time: 229.18828177452087 and batch: 800, loss is 4.375925674438476 and perplexity is 79.51340902656912
At time: 229.57739233970642 and batch: 850, loss is 4.326653871536255 and perplexity is 75.69059191440134
At time: 229.9662961959839 and batch: 900, loss is 4.281039028167725 and perplexity is 72.31553886750109
At time: 230.35427951812744 and batch: 950, loss is 4.3707257270812985 and perplexity is 79.10101662407126
At time: 230.7428822517395 and batch: 1000, loss is 4.413034687042236 and perplexity is 82.51950478569547
At time: 231.1311981678009 and batch: 1050, loss is 4.323616962432862 and perplexity is 75.46107515394411
At time: 231.52100086212158 and batch: 1100, loss is 4.446455736160278 and perplexity is 85.32399670058128
At time: 231.91145777702332 and batch: 1150, loss is 4.375487470626831 and perplexity is 79.4785735807268
At time: 232.30166220664978 and batch: 1200, loss is 4.329283170700073 and perplexity is 75.88986698651841
At time: 232.6927092075348 and batch: 1250, loss is 4.326899485588074 and perplexity is 75.70918487061819
At time: 233.0832977294922 and batch: 1300, loss is 4.384286680221558 and perplexity is 80.1810081100545
At time: 233.4729745388031 and batch: 1350, loss is 4.334368715286255 and perplexity is 76.27679131526975
At time: 233.86282753944397 and batch: 1400, loss is 4.218383560180664 and perplexity is 67.92360109008146
At time: 234.26242804527283 and batch: 1450, loss is 4.305693445205688 and perplexity is 74.12059620800366
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.875331780849359 and perplexity of 131.0176151361335
Finished 19 epochs...
Completing Train Step...
At time: 235.55330848693848 and batch: 50, loss is 4.476960964202881 and perplexity is 87.96693139058362
At time: 235.94136714935303 and batch: 100, loss is 4.478234920501709 and perplexity is 88.07906883085016
At time: 236.3472626209259 and batch: 150, loss is 4.363333978652954 and perplexity is 78.51847745265508
At time: 236.75182342529297 and batch: 200, loss is 4.424162635803222 and perplexity is 83.44290585783538
At time: 237.14912152290344 and batch: 250, loss is 4.464393253326416 and perplexity is 86.86830649059947
At time: 237.54668283462524 and batch: 300, loss is 4.466233520507813 and perplexity is 87.0283145677875
At time: 237.94512915611267 and batch: 350, loss is 4.473691177368164 and perplexity is 87.67976801379737
At time: 238.34929823875427 and batch: 400, loss is 4.352425866127014 and perplexity is 77.66664346215532
At time: 238.78003525733948 and batch: 450, loss is 4.39799843788147 and perplexity is 81.28800273923412
At time: 239.178649187088 and batch: 500, loss is 4.377104358673096 and perplexity is 79.6071854837885
At time: 239.5829803943634 and batch: 550, loss is 4.421949806213379 and perplexity is 83.25846506996844
At time: 239.9908585548401 and batch: 600, loss is 4.352131633758545 and perplexity is 77.64379478327372
At time: 240.39517498016357 and batch: 650, loss is 4.445501298904419 and perplexity is 85.24259914991796
At time: 240.7884533405304 and batch: 700, loss is 4.471152210235596 and perplexity is 87.45743433300991
At time: 241.1772758960724 and batch: 750, loss is 4.430872287750244 and perplexity is 84.00466119750334
At time: 241.56944870948792 and batch: 800, loss is 4.373116335868835 and perplexity is 79.2903424213066
At time: 241.97469663619995 and batch: 850, loss is 4.324398107528687 and perplexity is 75.52004423143062
At time: 242.39217853546143 and batch: 900, loss is 4.279261951446533 and perplexity is 72.18714272548635
At time: 242.79356622695923 and batch: 950, loss is 4.369228992462158 and perplexity is 78.98271195151601
At time: 243.1875286102295 and batch: 1000, loss is 4.411358003616333 and perplexity is 82.38126162710049
At time: 243.5885214805603 and batch: 1050, loss is 4.322626705169678 and perplexity is 75.38638626289705
At time: 243.99975991249084 and batch: 1100, loss is 4.445947933197021 and perplexity is 85.28067992134507
At time: 244.38678741455078 and batch: 1150, loss is 4.375433359146118 and perplexity is 79.474272993782
At time: 244.7751603126526 and batch: 1200, loss is 4.3290425968170165 and perplexity is 75.87161206244986
At time: 245.16410613059998 and batch: 1250, loss is 4.327553653717041 and perplexity is 75.75872760930423
At time: 245.55298781394958 and batch: 1300, loss is 4.383769598007202 and perplexity is 80.13955865414346
At time: 245.94077610969543 and batch: 1350, loss is 4.334887065887451 and perplexity is 76.31633968498045
At time: 246.3296594619751 and batch: 1400, loss is 4.219498043060303 and perplexity is 67.99934297929943
At time: 246.72485184669495 and batch: 1450, loss is 4.305809564590454 and perplexity is 74.12920354576354
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.874793419471154 and perplexity of 130.94709929548546
Finished 20 epochs...
Completing Train Step...
At time: 248.05001950263977 and batch: 50, loss is 4.4738247776031494 and perplexity is 87.6914828339414
At time: 248.44756197929382 and batch: 100, loss is 4.4748166561126705 and perplexity is 87.77850528194588
At time: 248.86292576789856 and batch: 150, loss is 4.359553508758545 and perplexity is 78.2222010972753
At time: 249.25393295288086 and batch: 200, loss is 4.4200247859954835 and perplexity is 83.09834500802249
At time: 249.64234375953674 and batch: 250, loss is 4.46061749458313 and perplexity is 86.54093115692382
At time: 250.02991795539856 and batch: 300, loss is 4.462825241088868 and perplexity is 86.73220265709145
At time: 250.41741633415222 and batch: 350, loss is 4.4712771129608155 and perplexity is 87.46835868712542
At time: 250.80571293830872 and batch: 400, loss is 4.350796217918396 and perplexity is 77.54017723148958
At time: 251.19386410713196 and batch: 450, loss is 4.395369997024536 and perplexity is 81.07462258306434
At time: 251.5946273803711 and batch: 500, loss is 4.374003429412841 and perplexity is 79.3607115795689
At time: 251.99447774887085 and batch: 550, loss is 4.419849157333374 and perplexity is 83.08375183839216
At time: 252.38384008407593 and batch: 600, loss is 4.34947416305542 and perplexity is 77.43773259673972
At time: 252.772296667099 and batch: 650, loss is 4.442791051864624 and perplexity is 85.0118834374216
At time: 253.1614408493042 and batch: 700, loss is 4.468850479125977 and perplexity is 87.25636233125172
At time: 253.54997777938843 and batch: 750, loss is 4.4288269138336185 and perplexity is 83.83301585390998
At time: 253.9388463497162 and batch: 800, loss is 4.371267137527465 and perplexity is 79.14385433611996
At time: 254.32714247703552 and batch: 850, loss is 4.322937197685242 and perplexity is 75.40979680581822
At time: 254.72401928901672 and batch: 900, loss is 4.277576823234558 and perplexity is 72.06560057055634
At time: 255.11206102371216 and batch: 950, loss is 4.367843847274781 and perplexity is 78.87338516238802
At time: 255.5008716583252 and batch: 1000, loss is 4.409646081924438 and perplexity is 82.24035200584738
At time: 255.88911747932434 and batch: 1050, loss is 4.321526899337768 and perplexity is 75.30352145159247
At time: 256.27729058265686 and batch: 1100, loss is 4.44546968460083 and perplexity is 85.2399043071078
At time: 256.6655156612396 and batch: 1150, loss is 4.374602689743042 and perplexity is 79.40828355837122
At time: 257.054719209671 and batch: 1200, loss is 4.328375086784363 and perplexity is 75.8209838994878
At time: 257.4431025981903 and batch: 1250, loss is 4.327608995437622 and perplexity is 75.76292034365461
At time: 257.8539996147156 and batch: 1300, loss is 4.382999505996704 and perplexity is 80.07786757725056
At time: 258.25625467300415 and batch: 1350, loss is 4.334582567214966 and perplexity is 76.29310499850256
At time: 258.65475273132324 and batch: 1400, loss is 4.219476995468139 and perplexity is 67.99791177192282
At time: 259.061110496521 and batch: 1450, loss is 4.30544264793396 and perplexity is 74.10200929556672
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8745951856303416 and perplexity of 130.92114372177036
Finished 21 epochs...
Completing Train Step...
At time: 260.3566048145294 and batch: 50, loss is 4.471812229156495 and perplexity is 87.51517694795596
At time: 260.76814222335815 and batch: 100, loss is 4.47219687461853 and perplexity is 87.54884573848685
At time: 261.16655349731445 and batch: 150, loss is 4.356858024597168 and perplexity is 78.01163830497471
At time: 261.5662155151367 and batch: 200, loss is 4.4169981575012205 and perplexity is 82.84721741586225
At time: 261.9728560447693 and batch: 250, loss is 4.457769498825074 and perplexity is 86.29481358934146
At time: 262.3730936050415 and batch: 300, loss is 4.460101957321167 and perplexity is 86.49632758061814
At time: 262.7671103477478 and batch: 350, loss is 4.469409875869751 and perplexity is 87.30518691109566
At time: 263.15644812583923 and batch: 400, loss is 4.349498286247253 and perplexity is 77.43960066455008
At time: 263.55208945274353 and batch: 450, loss is 4.392941780090332 and perplexity is 80.87799463584328
At time: 263.94668340682983 and batch: 500, loss is 4.371416292190552 and perplexity is 79.15565989145375
At time: 264.3354070186615 and batch: 550, loss is 4.417967777252198 and perplexity is 82.9275866716944
At time: 264.73631381988525 and batch: 600, loss is 4.347303228378296 and perplexity is 77.26980268611464
At time: 265.1331899166107 and batch: 650, loss is 4.440784683227539 and perplexity is 84.84148925464572
At time: 265.5438950061798 and batch: 700, loss is 4.466810350418091 and perplexity is 87.0785295840406
At time: 265.938414812088 and batch: 750, loss is 4.427023916244507 and perplexity is 83.68200130877769
At time: 266.3269965648651 and batch: 800, loss is 4.369573450088501 and perplexity is 79.00992283522606
At time: 266.7155523300171 and batch: 850, loss is 4.321688294410706 and perplexity is 75.31567604974934
At time: 267.11493372917175 and batch: 900, loss is 4.276066741943359 and perplexity is 71.95685778128585
At time: 267.51125383377075 and batch: 950, loss is 4.366644620895386 and perplexity is 78.77885481124349
At time: 267.90052342414856 and batch: 1000, loss is 4.408293828964234 and perplexity is 82.12921740438107
At time: 268.30009961128235 and batch: 1050, loss is 4.320329971313477 and perplexity is 75.21344247621846
At time: 268.71256947517395 and batch: 1100, loss is 4.444704179763794 and perplexity is 85.17467771687257
At time: 269.1388490200043 and batch: 1150, loss is 4.373774795532227 and perplexity is 79.3425691061832
At time: 269.5370132923126 and batch: 1200, loss is 4.327581253051758 and perplexity is 75.76081852863906
At time: 269.93648648262024 and batch: 1250, loss is 4.3273022174835205 and perplexity is 75.7396815147173
At time: 270.3375024795532 and batch: 1300, loss is 4.382051944732666 and perplexity is 80.00202483032693
At time: 270.7296941280365 and batch: 1350, loss is 4.333898811340332 and perplexity is 76.2409569700579
At time: 271.1185688972473 and batch: 1400, loss is 4.219293885231018 and perplexity is 67.98546179806812
At time: 271.5078887939453 and batch: 1450, loss is 4.3044415473937985 and perplexity is 74.02786285424757
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.874525282118055 and perplexity of 130.9119921938574
Finished 22 epochs...
Completing Train Step...
At time: 272.8555929660797 and batch: 50, loss is 4.469704303741455 and perplexity is 87.33089577598413
At time: 273.2704744338989 and batch: 100, loss is 4.469984226226806 and perplexity is 87.35534507917289
At time: 273.66815876960754 and batch: 150, loss is 4.354739112854004 and perplexity is 77.84651353265767
At time: 274.061137676239 and batch: 200, loss is 4.414235954284668 and perplexity is 82.61869232710075
At time: 274.4501738548279 and batch: 250, loss is 4.455324029922485 and perplexity is 86.08404013126366
At time: 274.83982515335083 and batch: 300, loss is 4.457901420593262 and perplexity is 86.30619850467824
At time: 275.22902727127075 and batch: 350, loss is 4.467562217712402 and perplexity is 87.14402570158045
At time: 275.61963295936584 and batch: 400, loss is 4.348363327980041 and perplexity is 77.3517598068493
At time: 276.023268699646 and batch: 450, loss is 4.390729246139526 and perplexity is 80.69924714220613
At time: 276.42044496536255 and batch: 500, loss is 4.369313726425171 and perplexity is 78.98940475325892
At time: 276.8103802204132 and batch: 550, loss is 4.416417627334595 and perplexity is 82.79913606461913
At time: 277.19990825653076 and batch: 600, loss is 4.345380449295044 and perplexity is 77.12137267053724
At time: 277.5896465778351 and batch: 650, loss is 4.438714141845703 and perplexity is 84.66600317853312
At time: 277.97943687438965 and batch: 700, loss is 4.4649888706207275 and perplexity is 86.92006216803101
At time: 278.3695616722107 and batch: 750, loss is 4.4254407787323 and perplexity is 83.54962600521152
At time: 278.75881576538086 and batch: 800, loss is 4.368117446899414 and perplexity is 78.89496784333409
At time: 279.1745955944061 and batch: 850, loss is 4.3203865337371825 and perplexity is 75.2176968511379
At time: 279.58136343955994 and batch: 900, loss is 4.274571714401245 and perplexity is 71.84936067265015
At time: 279.98902463912964 and batch: 950, loss is 4.365632328987122 and perplexity is 78.69914796408051
At time: 280.384681224823 and batch: 1000, loss is 4.407586908340454 and perplexity is 82.07117908344301
At time: 280.7749469280243 and batch: 1050, loss is 4.319534082412719 and perplexity is 75.15360474741459
At time: 281.16445899009705 and batch: 1100, loss is 4.443838233947754 and perplexity is 85.10095298648895
At time: 281.55398440361023 and batch: 1150, loss is 4.372806167602539 and perplexity is 79.26575288690748
At time: 281.94501423835754 and batch: 1200, loss is 4.326738538742066 and perplexity is 75.69700069662791
At time: 282.3350591659546 and batch: 1250, loss is 4.326977219581604 and perplexity is 75.71507027665018
At time: 282.7247140407562 and batch: 1300, loss is 4.380865602493286 and perplexity is 79.90717132451987
At time: 283.11430835723877 and batch: 1350, loss is 4.3329792499542235 and perplexity is 76.1708809545252
At time: 283.5035629272461 and batch: 1400, loss is 4.218646540641784 and perplexity is 67.94146601897775
At time: 283.8930649757385 and batch: 1450, loss is 4.303739547729492 and perplexity is 73.97591355570306
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.874662480802617 and perplexity of 130.92995437914567
Annealing...
Finished 23 epochs...
Completing Train Step...
At time: 285.19643115997314 and batch: 50, loss is 4.467780351638794 and perplexity is 87.16303684348047
At time: 285.58939957618713 and batch: 100, loss is 4.468170070648194 and perplexity is 87.19701255591586
At time: 285.97794246673584 and batch: 150, loss is 4.35136305809021 and perplexity is 77.58414257835915
At time: 286.3663306236267 and batch: 200, loss is 4.410142974853516 and perplexity is 82.2812268096034
At time: 286.7556474208832 and batch: 250, loss is 4.451858534812927 and perplexity is 85.78623263443677
At time: 287.1441824436188 and batch: 300, loss is 4.453706693649292 and perplexity is 85.944925818253
At time: 287.53364539146423 and batch: 350, loss is 4.463178176879882 and perplexity is 86.7628189581191
At time: 287.9292583465576 and batch: 400, loss is 4.343292155265808 and perplexity is 76.96048861353825
At time: 288.32114934921265 and batch: 450, loss is 4.386376943588257 and perplexity is 80.34878281958977
At time: 288.7182331085205 and batch: 500, loss is 4.362224407196045 and perplexity is 78.43140390732731
At time: 289.1298086643219 and batch: 550, loss is 4.40918872833252 and perplexity is 82.20274768534789
At time: 289.5184874534607 and batch: 600, loss is 4.339038553237915 and perplexity is 76.63382456506471
At time: 289.90744185447693 and batch: 650, loss is 4.433087520599365 and perplexity is 84.19095735096315
At time: 290.3040382862091 and batch: 700, loss is 4.457608041763305 and perplexity is 86.28088180701606
At time: 290.70379757881165 and batch: 750, loss is 4.418144063949585 and perplexity is 82.94220699071707
At time: 291.10477781295776 and batch: 800, loss is 4.359233746528625 and perplexity is 78.19719259042428
At time: 291.50193881988525 and batch: 850, loss is 4.311472434997558 and perplexity is 74.55017845702034
At time: 291.9003999233246 and batch: 900, loss is 4.26528507232666 and perplexity is 71.18521001463557
At time: 292.30678272247314 and batch: 950, loss is 4.354650144577026 and perplexity is 77.83958797056219
At time: 292.7121286392212 and batch: 1000, loss is 4.395927143096924 and perplexity is 81.11980557620161
At time: 293.1118657588959 and batch: 1050, loss is 4.3096808815002445 and perplexity is 74.41673739317436
At time: 293.5013976097107 and batch: 1100, loss is 4.434630641937256 and perplexity is 84.32097450403046
At time: 293.90965247154236 and batch: 1150, loss is 4.360958280563355 and perplexity is 78.33216265725345
At time: 294.30760765075684 and batch: 1200, loss is 4.316987562179565 and perplexity is 74.96246804236391
At time: 294.6972699165344 and batch: 1250, loss is 4.315352115631104 and perplexity is 74.83997112862065
At time: 295.0874762535095 and batch: 1300, loss is 4.36719048500061 and perplexity is 78.82186909924549
At time: 295.47728967666626 and batch: 1350, loss is 4.320617532730102 and perplexity is 75.23507407034305
At time: 295.8674783706665 and batch: 1400, loss is 4.20516990184784 and perplexity is 67.03198555707597
At time: 296.2733585834503 and batch: 1450, loss is 4.290328254699707 and perplexity is 72.99042401737938
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.869832878438835 and perplexity of 130.2991392811799
Finished 24 epochs...
Completing Train Step...
At time: 297.5627541542053 and batch: 50, loss is 4.4631473827362065 and perplexity is 86.76014721254364
At time: 297.96275901794434 and batch: 100, loss is 4.464211521148681 and perplexity is 86.85252115847962
At time: 298.355815410614 and batch: 150, loss is 4.348025436401367 and perplexity is 77.32562771377067
At time: 298.74448800086975 and batch: 200, loss is 4.406963701248169 and perplexity is 82.02004767694852
At time: 299.16278553009033 and batch: 250, loss is 4.448505644798279 and perplexity is 85.4990824920737
At time: 299.55461859703064 and batch: 300, loss is 4.451659336090088 and perplexity is 85.76914582835028
At time: 299.9425892829895 and batch: 350, loss is 4.461006517410278 and perplexity is 86.57460410397441
At time: 300.3315095901489 and batch: 400, loss is 4.341294302940368 and perplexity is 76.80688641074455
At time: 300.7198987007141 and batch: 450, loss is 4.384119176864624 and perplexity is 80.16757864680527
At time: 301.10744881629944 and batch: 500, loss is 4.359430103302002 and perplexity is 78.21254864643194
At time: 301.49762535095215 and batch: 550, loss is 4.4067267894744875 and perplexity is 82.00061846357151
At time: 301.8878753185272 and batch: 600, loss is 4.3371080303192135 and perplexity is 76.48602392256136
At time: 302.29960346221924 and batch: 650, loss is 4.4313838672637935 and perplexity is 84.0476472556705
At time: 302.70530581474304 and batch: 700, loss is 4.456136960983276 and perplexity is 86.15404897365052
At time: 303.1069984436035 and batch: 750, loss is 4.416431798934936 and perplexity is 82.80030946919852
At time: 303.50742387771606 and batch: 800, loss is 4.358348670005799 and perplexity is 78.12801271037146
At time: 303.9129419326782 and batch: 850, loss is 4.310797700881958 and perplexity is 74.49989387456067
At time: 304.308456659317 and batch: 900, loss is 4.264497437477112 and perplexity is 71.1291641371962
At time: 304.69741582870483 and batch: 950, loss is 4.353551163673401 and perplexity is 77.75409073835421
At time: 305.0860722064972 and batch: 1000, loss is 4.395044193267823 and perplexity is 81.04821246894343
At time: 305.47649908065796 and batch: 1050, loss is 4.309506759643555 and perplexity is 74.40378094072419
At time: 305.8766129016876 and batch: 1100, loss is 4.434696407318115 and perplexity is 84.32652008738485
At time: 306.27310585975647 and batch: 1150, loss is 4.361080560684204 and perplexity is 78.34174170922145
At time: 306.6618936061859 and batch: 1200, loss is 4.317488708496094 and perplexity is 75.00004462199702
At time: 307.05145812034607 and batch: 1250, loss is 4.315611963272095 and perplexity is 74.85942064541634
At time: 307.44831895828247 and batch: 1300, loss is 4.367168445587158 and perplexity is 78.82013193062647
At time: 307.8449945449829 and batch: 1350, loss is 4.320981092453003 and perplexity is 75.26243148575035
At time: 308.2509570121765 and batch: 1400, loss is 4.2055014753341675 and perplexity is 67.0542152714109
At time: 308.6414542198181 and batch: 1450, loss is 4.290753889083862 and perplexity is 73.02149786413491
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.869606996193911 and perplexity of 130.26971034294976
Finished 25 epochs...
Completing Train Step...
At time: 309.9655840396881 and batch: 50, loss is 4.460959620475769 and perplexity is 86.57054411563684
At time: 310.38523840904236 and batch: 100, loss is 4.46238522529602 and perplexity is 86.69404751322246
At time: 310.80074405670166 and batch: 150, loss is 4.3461584377288816 and perplexity is 77.18139555200285
At time: 311.2003638744354 and batch: 200, loss is 4.405145940780639 and perplexity is 81.87109030216614
At time: 311.6084325313568 and batch: 250, loss is 4.446296143531799 and perplexity is 85.31038070621058
At time: 312.0053279399872 and batch: 300, loss is 4.45029733657837 and perplexity is 85.6524078102196
At time: 312.40854477882385 and batch: 350, loss is 4.459785957336425 and perplexity is 86.46899906055583
At time: 312.8125705718994 and batch: 400, loss is 4.34039674282074 and perplexity is 76.73797854169315
At time: 313.20911741256714 and batch: 450, loss is 4.382483310699463 and perplexity is 80.03654242543625
At time: 313.601313829422 and batch: 500, loss is 4.357609720230102 and perplexity is 78.0703013584249
At time: 314.00782203674316 and batch: 550, loss is 4.405270280838013 and perplexity is 81.88127079113974
At time: 314.4096894264221 and batch: 600, loss is 4.336116313934326 and perplexity is 76.4102090790474
At time: 314.82734751701355 and batch: 650, loss is 4.430308780670166 and perplexity is 83.95733731108378
At time: 315.2300012111664 and batch: 700, loss is 4.455046424865722 and perplexity is 86.06014608312442
At time: 315.63047552108765 and batch: 750, loss is 4.415355644226074 and perplexity is 82.71125145496362
At time: 316.02139711380005 and batch: 800, loss is 4.357493181228637 and perplexity is 78.06120365358953
At time: 316.41711688041687 and batch: 850, loss is 4.310258855819702 and perplexity is 74.45976078833654
At time: 316.8442075252533 and batch: 900, loss is 4.263884282112121 and perplexity is 71.08556427670835
At time: 317.25756454467773 and batch: 950, loss is 4.352479753494262 and perplexity is 77.67082882586261
At time: 317.6735668182373 and batch: 1000, loss is 4.394172325134277 and perplexity is 80.97757991082355
At time: 318.08873748779297 and batch: 1050, loss is 4.309277601242066 and perplexity is 74.38673264267403
At time: 318.4971809387207 and batch: 1100, loss is 4.434539289474487 and perplexity is 84.31327192717652
At time: 318.8985571861267 and batch: 1150, loss is 4.361025876998902 and perplexity is 78.3374578112025
At time: 319.29694843292236 and batch: 1200, loss is 4.317655801773071 and perplexity is 75.01257767229143
At time: 319.71662068367004 and batch: 1250, loss is 4.315519156455994 and perplexity is 74.85247350330717
At time: 320.1126012802124 and batch: 1300, loss is 4.366960239410401 and perplexity is 78.80372280060608
At time: 320.5118386745453 and batch: 1350, loss is 4.3211056518554685 and perplexity is 75.27180671311854
At time: 320.9171886444092 and batch: 1400, loss is 4.2054335880279545 and perplexity is 67.04966329587832
At time: 321.3241581916809 and batch: 1450, loss is 4.29077449798584 and perplexity is 73.02300277253387
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.869501619257479 and perplexity of 130.25598364321542
Finished 26 epochs...
Completing Train Step...
At time: 322.65203285217285 and batch: 50, loss is 4.459337553977966 and perplexity is 86.43023476264467
At time: 323.06202507019043 and batch: 100, loss is 4.461003818511963 and perplexity is 86.57437044823652
At time: 323.4666497707367 and batch: 150, loss is 4.3447285079956055 and perplexity is 77.07111044841334
At time: 323.86186504364014 and batch: 200, loss is 4.403758363723755 and perplexity is 81.75756663527314
At time: 324.279319524765 and batch: 250, loss is 4.444746837615967 and perplexity is 85.17831116318047
At time: 324.678679227829 and batch: 300, loss is 4.449255619049072 and perplexity is 85.56322865338723
At time: 325.07209944725037 and batch: 350, loss is 4.458786125183106 and perplexity is 86.38258778061628
At time: 325.4725914001465 and batch: 400, loss is 4.33963267326355 and perplexity is 76.6793677826089
At time: 325.8717806339264 and batch: 450, loss is 4.3813782787323 and perplexity is 79.9481483356572
At time: 326.2656636238098 and batch: 500, loss is 4.356185331344604 and perplexity is 77.95917804907387
At time: 326.66991925239563 and batch: 550, loss is 4.4041359233856205 and perplexity is 81.78844082254399
At time: 327.0683968067169 and batch: 600, loss is 4.3352843761444095 and perplexity is 76.34666697378331
At time: 327.48429322242737 and batch: 650, loss is 4.429361591339111 and perplexity is 83.87785146693341
At time: 327.8731589317322 and batch: 700, loss is 4.454207916259765 and perplexity is 85.98801415585099
At time: 328.26653480529785 and batch: 750, loss is 4.414457483291626 and perplexity is 82.63699679137818
At time: 328.66725158691406 and batch: 800, loss is 4.356537456512451 and perplexity is 77.9866342714594
At time: 329.0602374076843 and batch: 850, loss is 4.309785037040711 and perplexity is 74.42448871234168
At time: 329.45020842552185 and batch: 900, loss is 4.263371329307557 and perplexity is 71.04911008758715
At time: 329.86673283576965 and batch: 950, loss is 4.351436610221863 and perplexity is 77.58984926729524
At time: 330.2654547691345 and batch: 1000, loss is 4.393530950546265 and perplexity is 80.92565960083357
At time: 330.65660095214844 and batch: 1050, loss is 4.3090964031219485 and perplexity is 74.37325512764458
At time: 331.06429743766785 and batch: 1100, loss is 4.434319562911988 and perplexity is 84.29474809692617
At time: 331.4752941131592 and batch: 1150, loss is 4.360870351791382 and perplexity is 78.32527530918749
At time: 331.89140272140503 and batch: 1200, loss is 4.317611541748047 and perplexity is 75.00925768719836
At time: 332.2898471355438 and batch: 1250, loss is 4.315241708755493 and perplexity is 74.83170873735833
At time: 332.689325094223 and batch: 1300, loss is 4.3666670036315915 and perplexity is 78.78061811730306
At time: 333.0844609737396 and batch: 1350, loss is 4.321057586669922 and perplexity is 75.26818884670986
At time: 333.4820716381073 and batch: 1400, loss is 4.205037407875061 and perplexity is 67.0231048113419
At time: 333.88094902038574 and batch: 1450, loss is 4.290654201507568 and perplexity is 73.0142188908131
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8695579594017095 and perplexity of 130.26332249085473
Annealing...
Finished 27 epochs...
Completing Train Step...
At time: 335.19976687431335 and batch: 50, loss is 4.457544946670533 and perplexity is 86.27543807851202
At time: 335.59421610832214 and batch: 100, loss is 4.459702138900757 and perplexity is 86.46175166805753
At time: 335.9969382286072 and batch: 150, loss is 4.343310985565186 and perplexity is 76.9619378162235
At time: 336.38962745666504 and batch: 200, loss is 4.402704381942749 and perplexity is 81.67144104495466
At time: 336.8037886619568 and batch: 250, loss is 4.443118705749511 and perplexity is 85.03974247510317
At time: 337.20194387435913 and batch: 300, loss is 4.447550115585327 and perplexity is 85.4174246405163
At time: 337.6127038002014 and batch: 350, loss is 4.456369705200196 and perplexity is 86.17410316397122
At time: 338.01277780532837 and batch: 400, loss is 4.337058038711548 and perplexity is 76.48220035883534
At time: 338.4036157131195 and batch: 450, loss is 4.378729724884034 and perplexity is 79.73668152395706
At time: 338.7976357936859 and batch: 500, loss is 4.35232271194458 and perplexity is 77.65863223624942
At time: 339.1905541419983 and batch: 550, loss is 4.400609569549561 and perplexity is 81.50053376992152
At time: 339.5934913158417 and batch: 600, loss is 4.332359104156494 and perplexity is 76.12365854669423
At time: 340.0033049583435 and batch: 650, loss is 4.426587400436401 and perplexity is 83.64548076382994
At time: 340.40476059913635 and batch: 700, loss is 4.450743799209595 and perplexity is 85.69065694735117
At time: 340.7985768318176 and batch: 750, loss is 4.410396871566772 and perplexity is 82.30212039494714
At time: 341.18740725517273 and batch: 800, loss is 4.35206175327301 and perplexity is 77.63836918676935
At time: 341.5934066772461 and batch: 850, loss is 4.305751895904541 and perplexity is 74.12492873526978
At time: 342.0045394897461 and batch: 900, loss is 4.258788633346557 and perplexity is 70.72425853422679
At time: 342.40272307395935 and batch: 950, loss is 4.3455967569351195 and perplexity is 77.13805641700482
At time: 342.801456451416 and batch: 1000, loss is 4.388179960250855 and perplexity is 80.49378369404778
At time: 343.1999819278717 and batch: 1050, loss is 4.304096317291259 and perplexity is 74.00231061851792
At time: 343.5941860675812 and batch: 1100, loss is 4.43007269859314 and perplexity is 83.93751882799617
At time: 343.98461532592773 and batch: 1150, loss is 4.3545676040649415 and perplexity is 77.8331633162614
At time: 344.3743407726288 and batch: 1200, loss is 4.312590813636779 and perplexity is 74.63360042413468
At time: 344.76290106773376 and batch: 1250, loss is 4.3093677377700805 and perplexity is 74.39343790667488
At time: 345.1531431674957 and batch: 1300, loss is 4.35984471321106 and perplexity is 78.24498306746494
At time: 345.5439999103546 and batch: 1350, loss is 4.315185461044312 and perplexity is 74.82749974339232
At time: 345.93436098098755 and batch: 1400, loss is 4.197610049247742 and perplexity is 66.52714429390254
At time: 346.32380533218384 and batch: 1450, loss is 4.283598580360413 and perplexity is 72.50087134647043
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.867609007745727 and perplexity of 130.00969280904903
Finished 28 epochs...
Completing Train Step...
At time: 347.6152677536011 and batch: 50, loss is 4.455119833946228 and perplexity is 86.06646391120672
At time: 348.00604367256165 and batch: 100, loss is 4.457938709259033 and perplexity is 86.30941680767098
At time: 348.39730978012085 and batch: 150, loss is 4.341808319091797 and perplexity is 76.84637653931308
At time: 348.7883734703064 and batch: 200, loss is 4.401448106765747 and perplexity is 81.56890366196994
At time: 349.1779019832611 and batch: 250, loss is 4.441644377708435 and perplexity is 84.91445837579018
At time: 349.5679244995117 and batch: 300, loss is 4.4463658618927 and perplexity is 85.31632861345804
At time: 349.9582185745239 and batch: 350, loss is 4.455192699432373 and perplexity is 86.07273541442564
At time: 350.3612928390503 and batch: 400, loss is 4.335886363983154 and perplexity is 76.39264057521635
At time: 350.7623145580292 and batch: 450, loss is 4.377159996032715 and perplexity is 79.61161474061045
At time: 351.15932965278625 and batch: 500, loss is 4.350939741134644 and perplexity is 77.55130684577418
At time: 351.5637774467468 and batch: 550, loss is 4.399555206298828 and perplexity is 81.41464788761493
At time: 351.96153020858765 and batch: 600, loss is 4.331701173782348 and perplexity is 76.07359095184701
At time: 352.3512680530548 and batch: 650, loss is 4.426242408752441 and perplexity is 83.6166287457049
At time: 352.74155592918396 and batch: 700, loss is 4.45003662109375 and perplexity is 85.63007981196242
At time: 353.1317400932312 and batch: 750, loss is 4.409670610427856 and perplexity is 82.24236926334268
At time: 353.5455605983734 and batch: 800, loss is 4.351462397575379 and perplexity is 77.59185012996589
At time: 353.9430022239685 and batch: 850, loss is 4.305343899726868 and perplexity is 74.09469221628703
At time: 354.33436608314514 and batch: 900, loss is 4.258380165100098 and perplexity is 70.69537581959864
At time: 354.72420048713684 and batch: 950, loss is 4.345428609848023 and perplexity is 77.1250869679321
At time: 355.11534118652344 and batch: 1000, loss is 4.3879823398590085 and perplexity is 80.47787805266427
At time: 355.5045874118805 and batch: 1050, loss is 4.304063014984131 and perplexity is 73.9998462118769
At time: 355.8942177295685 and batch: 1100, loss is 4.430075559616089 and perplexity is 83.93775897550736
At time: 356.28403997421265 and batch: 1150, loss is 4.354406070709229 and perplexity is 77.82059167960186
At time: 356.6735625267029 and batch: 1200, loss is 4.312793612480164 and perplexity is 74.64873756682393
At time: 357.0631501674652 and batch: 1250, loss is 4.309407696723938 and perplexity is 74.39641065002097
At time: 357.4527099132538 and batch: 1300, loss is 4.359913539886475 and perplexity is 78.25036859484923
At time: 357.8427538871765 and batch: 1350, loss is 4.315484848022461 and perplexity is 74.84990547624791
At time: 358.2331681251526 and batch: 1400, loss is 4.197874946594238 and perplexity is 66.54476949222703
At time: 358.6231005191803 and batch: 1450, loss is 4.2837062311172485 and perplexity is 72.50867654025211
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.867518237513354 and perplexity of 129.99789233459612
Finished 29 epochs...
Completing Train Step...
At time: 359.9062159061432 and batch: 50, loss is 4.453788452148437 and perplexity is 85.95195283365223
At time: 360.3105437755585 and batch: 100, loss is 4.456859722137451 and perplexity is 86.21634028168073
At time: 360.70110750198364 and batch: 150, loss is 4.34085488319397 and perplexity is 76.7731433624201
At time: 361.1078429222107 and batch: 200, loss is 4.40085991859436 and perplexity is 81.5209399049231
At time: 361.5084059238434 and batch: 250, loss is 4.440734510421753 and perplexity is 84.83723262586712
At time: 361.90031719207764 and batch: 300, loss is 4.4456673526763915 and perplexity is 85.25675518033817
At time: 362.29530692100525 and batch: 350, loss is 4.454387655258179 and perplexity is 86.00347094444318
At time: 362.6908929347992 and batch: 400, loss is 4.3351826667785645 and perplexity is 76.33890219758295
At time: 363.08238458633423 and batch: 450, loss is 4.375992498397827 and perplexity is 79.51872260491695
At time: 363.47388195991516 and batch: 500, loss is 4.350147762298584 and perplexity is 77.48991216689575
At time: 363.8652641773224 and batch: 550, loss is 4.3988933086395265 and perplexity is 81.3607775530362
At time: 364.2565610408783 and batch: 600, loss is 4.331251888275147 and perplexity is 76.039419866813
At time: 364.64806604385376 and batch: 650, loss is 4.425957069396973 and perplexity is 83.5927730344007
At time: 365.03940868377686 and batch: 700, loss is 4.449587507247925 and perplexity is 85.59163079213963
At time: 365.43040466308594 and batch: 750, loss is 4.408961963653565 and perplexity is 82.1841091190239
At time: 365.8224103450775 and batch: 800, loss is 4.3509306144714355 and perplexity is 77.55059906434508
At time: 366.2129487991333 and batch: 850, loss is 4.304983696937561 and perplexity is 74.06800790764761
At time: 366.60636925697327 and batch: 900, loss is 4.258049764633179 and perplexity is 70.67202189270544
At time: 367.0070562362671 and batch: 950, loss is 4.345140953063964 and perplexity is 77.10290460405137
At time: 367.4056627750397 and batch: 1000, loss is 4.3877408409118654 and perplexity is 80.45844507646234
At time: 367.8135030269623 and batch: 1050, loss is 4.304096202850342 and perplexity is 74.0023021496261
At time: 368.21632051467896 and batch: 1100, loss is 4.430163555145263 and perplexity is 83.94514544800964
At time: 368.6254229545593 and batch: 1150, loss is 4.354253768920898 and perplexity is 77.8087403668311
At time: 369.02304434776306 and batch: 1200, loss is 4.312951464653015 and perplexity is 74.6605219623212
At time: 369.41490936279297 and batch: 1250, loss is 4.309393658638 and perplexity is 74.39536627414532
At time: 369.8165726661682 and batch: 1300, loss is 4.359912786483765 and perplexity is 78.25030964083167
At time: 370.23927760124207 and batch: 1350, loss is 4.315791625976562 and perplexity is 74.87287129963863
At time: 370.6416964530945 and batch: 1400, loss is 4.197856602668762 and perplexity is 66.5435488111307
At time: 371.0429141521454 and batch: 1450, loss is 4.2836876344680785 and perplexity is 72.50732813437067
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8674577240251065 and perplexity of 129.99002594667976
Finished 30 epochs...
Completing Train Step...
At time: 372.3375325202942 and batch: 50, loss is 4.452671866416932 and perplexity is 85.85603367047332
At time: 372.7414240837097 and batch: 100, loss is 4.455986032485962 and perplexity is 86.14104685372128
At time: 373.1308970451355 and batch: 150, loss is 4.340059089660644 and perplexity is 76.71207209468216
At time: 373.5228772163391 and batch: 200, loss is 4.400370702743531 and perplexity is 81.48106832264732
At time: 373.9229235649109 and batch: 250, loss is 4.440046606063842 and perplexity is 84.7788927922442
At time: 374.32353925704956 and batch: 300, loss is 4.44511344909668 and perplexity is 85.20954423481213
At time: 374.71602296829224 and batch: 350, loss is 4.453683605194092 and perplexity is 85.94294150559101
At time: 375.106924533844 and batch: 400, loss is 4.334611577987671 and perplexity is 76.29531835253603
At time: 375.5146441459656 and batch: 450, loss is 4.37520097732544 and perplexity is 79.45580676321784
At time: 375.913122177124 and batch: 500, loss is 4.349391222000122 and perplexity is 77.43131009582648
At time: 376.3036048412323 and batch: 550, loss is 4.398342351913453 and perplexity is 81.31596363180402
At time: 376.71764039993286 and batch: 600, loss is 4.3309260272979735 and perplexity is 76.01464562385026
At time: 377.1291124820709 and batch: 650, loss is 4.425672130584717 and perplexity is 83.56895760207071
At time: 377.52471804618835 and batch: 700, loss is 4.449242210388183 and perplexity is 85.5620813727614
At time: 377.91358256340027 and batch: 750, loss is 4.408549575805664 and perplexity is 82.15022437844054
At time: 378.32256627082825 and batch: 800, loss is 4.350474681854248 and perplexity is 77.51524927592234
At time: 378.719895362854 and batch: 850, loss is 4.3047676229476926 and perplexity is 74.0520054665753
At time: 379.11155128479004 and batch: 900, loss is 4.25778856754303 and perplexity is 70.65356497678346
At time: 379.50157022476196 and batch: 950, loss is 4.344907755851746 and perplexity is 77.084926517945
At time: 379.89106965065 and batch: 1000, loss is 4.387594232559204 and perplexity is 80.44665006101698
At time: 380.2951829433441 and batch: 1050, loss is 4.304060001373291 and perplexity is 73.99962320547424
At time: 380.685599565506 and batch: 1100, loss is 4.43020206451416 and perplexity is 83.94837818482769
At time: 381.0745232105255 and batch: 1150, loss is 4.354088907241821 and perplexity is 77.79591374458563
At time: 381.46536922454834 and batch: 1200, loss is 4.312950615882873 and perplexity is 74.66045859272631
At time: 381.8695423603058 and batch: 1250, loss is 4.309302616119385 and perplexity is 74.38859344093896
At time: 382.264187335968 and batch: 1300, loss is 4.3599138259887695 and perplexity is 78.25039098246245
At time: 382.6546542644501 and batch: 1350, loss is 4.31600546836853 and perplexity is 74.88888400556753
At time: 383.0434527397156 and batch: 1400, loss is 4.1977703332901 and perplexity is 66.53780838813572
At time: 383.43348264694214 and batch: 1450, loss is 4.283677768707276 and perplexity is 72.5066127979435
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.867442073985043 and perplexity of 129.98799161348455
Finished 31 epochs...
Completing Train Step...
At time: 384.8016245365143 and batch: 50, loss is 4.45173189163208 and perplexity is 85.77536908097507
At time: 385.2043945789337 and batch: 100, loss is 4.455242118835449 and perplexity is 86.07698918273945
At time: 385.6041171550751 and batch: 150, loss is 4.339455966949463 and perplexity is 76.66581925125229
At time: 386.0028851032257 and batch: 200, loss is 4.399995393753052 and perplexity is 81.45049348301701
At time: 386.39026832580566 and batch: 250, loss is 4.439448504447937 and perplexity is 84.72820156023553
At time: 386.7795784473419 and batch: 300, loss is 4.444627914428711 and perplexity is 85.16818208923468
At time: 387.168913602829 and batch: 350, loss is 4.453110046386719 and perplexity is 85.89366230816873
At time: 387.5573163032532 and batch: 400, loss is 4.334072690010071 and perplexity is 76.25421479882888
At time: 387.9463629722595 and batch: 450, loss is 4.374511432647705 and perplexity is 79.40103731970841
At time: 388.3531336784363 and batch: 500, loss is 4.3487342357635494 and perplexity is 77.38045549802834
At time: 388.7620642185211 and batch: 550, loss is 4.397894458770752 and perplexity is 81.27955092441096
At time: 389.16354870796204 and batch: 600, loss is 4.3306099224090575 and perplexity is 75.99062082011835
At time: 389.5650942325592 and batch: 650, loss is 4.425447721481323 and perplexity is 83.55020607130946
At time: 389.9659481048584 and batch: 700, loss is 4.4489162826538085 and perplexity is 85.53419886151987
At time: 390.38877058029175 and batch: 750, loss is 4.40814024925232 and perplexity is 82.11660499136254
At time: 390.7871720790863 and batch: 800, loss is 4.350087695121765 and perplexity is 77.48525770643147
At time: 391.1954653263092 and batch: 850, loss is 4.304536924362183 and perplexity is 74.03492374410038
At time: 391.5956666469574 and batch: 900, loss is 4.257528176307678 and perplexity is 70.63516980279213
At time: 392.00715684890747 and batch: 950, loss is 4.344681496620178 and perplexity is 77.06748731467037
At time: 392.4114248752594 and batch: 1000, loss is 4.387412796020508 and perplexity is 80.43205542332052
At time: 392.80222511291504 and batch: 1050, loss is 4.304006481170655 and perplexity is 73.99566283662611
At time: 393.1930890083313 and batch: 1100, loss is 4.4302076148986815 and perplexity is 83.94884413189968
At time: 393.5843553543091 and batch: 1150, loss is 4.353916997909546 and perplexity is 77.78254105047846
At time: 393.9767076969147 and batch: 1200, loss is 4.312901339530945 and perplexity is 74.65677968833579
At time: 394.36793088912964 and batch: 1250, loss is 4.309170341491699 and perplexity is 74.37875436818169
At time: 394.7666177749634 and batch: 1300, loss is 4.3598733901977536 and perplexity is 78.24722692997668
At time: 395.16539883613586 and batch: 1350, loss is 4.316160802841186 and perplexity is 74.90051773440851
At time: 395.5610044002533 and batch: 1400, loss is 4.197642931938171 and perplexity is 66.52933192136084
At time: 395.9637007713318 and batch: 1450, loss is 4.283592271804809 and perplexity is 72.50041397213495
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.867420685596955 and perplexity of 129.98521140960537
Finished 32 epochs...
Completing Train Step...
At time: 397.35277581214905 and batch: 50, loss is 4.450873641967774 and perplexity is 85.70178398096613
At time: 397.74910140037537 and batch: 100, loss is 4.454561214447022 and perplexity is 86.01839893250526
At time: 398.1395831108093 and batch: 150, loss is 4.338861789703369 and perplexity is 76.62027969652347
At time: 398.544552564621 and batch: 200, loss is 4.399578094482422 and perplexity is 81.41651134234847
At time: 398.9428701400757 and batch: 250, loss is 4.438904929161072 and perplexity is 84.6821579189933
At time: 399.3439738750458 and batch: 300, loss is 4.444101142883301 and perplexity is 85.1233297288465
At time: 399.74797105789185 and batch: 350, loss is 4.452605199813843 and perplexity is 85.85031013114043
At time: 400.1460385322571 and batch: 400, loss is 4.333607349395752 and perplexity is 76.21873887050528
At time: 400.5412633419037 and batch: 450, loss is 4.373879184722901 and perplexity is 79.3508520450753
At time: 400.9588694572449 and batch: 500, loss is 4.348077917098999 and perplexity is 77.32968592314583
At time: 401.3524453639984 and batch: 550, loss is 4.397464847564697 and perplexity is 81.24463981814888
At time: 401.7426996231079 and batch: 600, loss is 4.330222663879394 and perplexity is 75.96119850142098
At time: 402.13319301605225 and batch: 650, loss is 4.425229158401489 and perplexity is 83.53194707639354
At time: 402.53854417800903 and batch: 700, loss is 4.448525495529175 and perplexity is 85.50077972819777
At time: 402.9379360675812 and batch: 750, loss is 4.407718667984009 and perplexity is 82.08199346517907
At time: 403.3285171985626 and batch: 800, loss is 4.349722456932068 and perplexity is 77.45696229877487
At time: 403.7191300392151 and batch: 850, loss is 4.304289140701294 and perplexity is 74.0165813722253
At time: 404.10918855667114 and batch: 900, loss is 4.257265543937683 and perplexity is 70.61662115658585
At time: 404.49839973449707 and batch: 950, loss is 4.3444321870803835 and perplexity is 77.04827604975013
At time: 404.889279127121 and batch: 1000, loss is 4.387232284545899 and perplexity is 80.41753782472622
At time: 405.2791967391968 and batch: 1050, loss is 4.303934469223022 and perplexity is 73.99033445668469
At time: 405.66905093193054 and batch: 1100, loss is 4.430163679122924 and perplexity is 83.94515585533307
At time: 406.05906200408936 and batch: 1150, loss is 4.353724451065063 and perplexity is 77.76756570941694
At time: 406.44897842407227 and batch: 1200, loss is 4.31279598236084 and perplexity is 74.64891447563424
At time: 406.84319138526917 and batch: 1250, loss is 4.308969888687134 and perplexity is 74.36384643248722
At time: 407.240478515625 and batch: 1300, loss is 4.359811496734619 and perplexity is 78.24238408799302
At time: 407.64159536361694 and batch: 1350, loss is 4.316277742385864 and perplexity is 74.90927707899542
At time: 408.04166078567505 and batch: 1400, loss is 4.197514328956604 and perplexity is 66.52077660104572
At time: 408.4315576553345 and batch: 1450, loss is 4.28346164226532 and perplexity is 72.49094389499436
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.867400340544871 and perplexity of 129.98256688061073
Finished 33 epochs...
Completing Train Step...
At time: 409.7064251899719 and batch: 50, loss is 4.450075349807739 and perplexity is 85.63339621905203
At time: 410.1083610057831 and batch: 100, loss is 4.453951349258423 and perplexity is 85.96595529881606
At time: 410.49657583236694 and batch: 150, loss is 4.338312845230103 and perplexity is 76.57823095971071
At time: 410.89866065979004 and batch: 200, loss is 4.399198217391968 and perplexity is 81.38558894863115
At time: 411.2873818874359 and batch: 250, loss is 4.438377895355225 and perplexity is 84.6375393178063
At time: 411.6761529445648 and batch: 300, loss is 4.443621883392334 and perplexity is 85.082543339584
At time: 412.06416845321655 and batch: 350, loss is 4.452106275558472 and perplexity is 85.80748801247
At time: 412.45260643959045 and batch: 400, loss is 4.333200712203979 and perplexity is 76.18775179724571
At time: 412.84093403816223 and batch: 450, loss is 4.373253059387207 and perplexity is 79.30118401702902
At time: 413.23881936073303 and batch: 500, loss is 4.3474813652038575 and perplexity is 77.28356850954056
At time: 413.64343786239624 and batch: 550, loss is 4.397062530517578 and perplexity is 81.2119602887697
At time: 414.0472810268402 and batch: 600, loss is 4.329916381835938 and perplexity is 75.93793651286713
At time: 414.44277477264404 and batch: 650, loss is 4.425036745071411 and perplexity is 83.51587596248653
At time: 414.8322985172272 and batch: 700, loss is 4.448216514587402 and perplexity is 85.47436569768121
At time: 415.2350208759308 and batch: 750, loss is 4.407396106719971 and perplexity is 82.05552126329519
At time: 415.63011050224304 and batch: 800, loss is 4.349342622756958 and perplexity is 77.42754708419912
At time: 416.0185492038727 and batch: 850, loss is 4.304052138328553 and perplexity is 73.99904134541397
At time: 416.40718388557434 and batch: 900, loss is 4.257009477615356 and perplexity is 70.59854093307811
At time: 416.7953917980194 and batch: 950, loss is 4.344140434265137 and perplexity is 77.02580027714713
At time: 417.1839876174927 and batch: 1000, loss is 4.387030811309814 and perplexity is 80.40133747516595
At time: 417.57240080833435 and batch: 1050, loss is 4.30386794090271 and perplexity is 73.98541216775156
At time: 417.960476398468 and batch: 1100, loss is 4.430071535110474 and perplexity is 83.93742116820482
At time: 418.35871934890747 and batch: 1150, loss is 4.35353717803955 and perplexity is 77.75300330571503
At time: 418.7582461833954 and batch: 1200, loss is 4.312683763504029 and perplexity is 74.64053792980157
At time: 419.16162967681885 and batch: 1250, loss is 4.3087879133224485 and perplexity is 74.3503152756192
At time: 419.55976033210754 and batch: 1300, loss is 4.359720783233643 and perplexity is 78.2352867693238
At time: 419.96437764167786 and batch: 1350, loss is 4.31632025718689 and perplexity is 74.91246189970592
At time: 420.35833525657654 and batch: 1400, loss is 4.197401695251465 and perplexity is 66.51328454144553
At time: 420.74720215797424 and batch: 1450, loss is 4.283287920951843 and perplexity is 72.47835176679794
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.86737060546875 and perplexity of 129.97870189655316
Finished 34 epochs...
Completing Train Step...
At time: 422.01322746276855 and batch: 50, loss is 4.449329347610473 and perplexity is 85.569537339707
At time: 422.43800473213196 and batch: 100, loss is 4.453392353057861 and perplexity is 85.9179140851053
At time: 422.83359122276306 and batch: 150, loss is 4.337786979675293 and perplexity is 76.53797169220952
At time: 423.2262933254242 and batch: 200, loss is 4.398843736648559 and perplexity is 81.35674443727187
At time: 423.6137933731079 and batch: 250, loss is 4.437886500358582 and perplexity is 84.59595907145658
At time: 424.00192952156067 and batch: 300, loss is 4.443206701278687 and perplexity is 85.04722592149328
At time: 424.38985538482666 and batch: 350, loss is 4.4516074657440186 and perplexity is 85.76469706845447
At time: 424.777046918869 and batch: 400, loss is 4.332830023765564 and perplexity is 76.15951511233528
At time: 425.1653995513916 and batch: 450, loss is 4.37262375831604 and perplexity is 79.25129539610998
At time: 425.5660207271576 and batch: 500, loss is 4.34690185546875 and perplexity is 77.23879490384866
At time: 425.96359753608704 and batch: 550, loss is 4.396680498123169 and perplexity is 81.18094061476337
At time: 426.3570637702942 and batch: 600, loss is 4.329594440460205 and perplexity is 75.91349288403475
At time: 426.745019197464 and batch: 650, loss is 4.42480242729187 and perplexity is 83.49630900040765
At time: 427.1332850456238 and batch: 700, loss is 4.447890338897705 and perplexity is 85.44649058383767
At time: 427.52147030830383 and batch: 750, loss is 4.407071199417114 and perplexity is 82.0288651558135
At time: 427.92253613471985 and batch: 800, loss is 4.348965926170349 and perplexity is 77.39838588431006
At time: 428.3204526901245 and batch: 850, loss is 4.303829030990601 and perplexity is 73.9825334578723
At time: 428.7091929912567 and batch: 900, loss is 4.256748871803284 and perplexity is 70.58014494014257
At time: 429.11478090286255 and batch: 950, loss is 4.343816609382629 and perplexity is 77.0008614445475
At time: 429.511510848999 and batch: 1000, loss is 4.386819715499878 and perplexity is 80.38436688098535
At time: 429.90214824676514 and batch: 1050, loss is 4.303745365142822 and perplexity is 73.9763439054204
At time: 430.3048870563507 and batch: 1100, loss is 4.4299850749969485 and perplexity is 83.93016424296339
At time: 430.72004222869873 and batch: 1150, loss is 4.353347549438476 and perplexity is 77.73826051034087
At time: 431.1213185787201 and batch: 1200, loss is 4.312556276321411 and perplexity is 74.63102282445169
At time: 431.5134394168854 and batch: 1250, loss is 4.3085420703887936 and perplexity is 74.33203902262954
At time: 431.90148639678955 and batch: 1300, loss is 4.359606580734253 and perplexity is 78.22635261419542
At time: 432.2898564338684 and batch: 1350, loss is 4.316281709671021 and perplexity is 74.90957426604795
At time: 432.6782879829407 and batch: 1400, loss is 4.19723000049591 and perplexity is 66.50186553963448
At time: 433.07572889328003 and batch: 1450, loss is 4.283121767044068 and perplexity is 72.46631020582667
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.867382082164797 and perplexity of 129.98019363116748
Annealing...
Finished 35 epochs...
Completing Train Step...
At time: 434.3545868396759 and batch: 50, loss is 4.448535594940186 and perplexity is 85.50164324007444
At time: 434.7424621582031 and batch: 100, loss is 4.453011522293091 and perplexity is 85.88520012981246
At time: 435.148398399353 and batch: 150, loss is 4.337132358551026 and perplexity is 76.48788471491655
At time: 435.5476849079132 and batch: 200, loss is 4.398577547073364 and perplexity is 81.33509100211803
At time: 435.94427847862244 and batch: 250, loss is 4.437712807655334 and perplexity is 84.58126664666204
At time: 436.33181715011597 and batch: 300, loss is 4.442633590698242 and perplexity is 84.99849842093701
At time: 436.73258924484253 and batch: 350, loss is 4.450478229522705 and perplexity is 85.6679031279124
At time: 437.12940192222595 and batch: 400, loss is 4.33154716014862 and perplexity is 76.06187548386782
At time: 437.5185503959656 and batch: 450, loss is 4.371209802627564 and perplexity is 79.13931676123572
At time: 437.90635681152344 and batch: 500, loss is 4.34502046585083 and perplexity is 77.09361524958649
At time: 438.29556107521057 and batch: 550, loss is 4.394855508804321 and perplexity is 81.03292137309745
At time: 438.68325996398926 and batch: 600, loss is 4.327865161895752 and perplexity is 75.78233074865786
At time: 439.0716383457184 and batch: 650, loss is 4.423374786376953 and perplexity is 83.37719130231557
At time: 439.4598000049591 and batch: 700, loss is 4.445982980728149 and perplexity is 85.28366885100623
At time: 439.84982895851135 and batch: 750, loss is 4.405307130813599 and perplexity is 81.88428816956413
At time: 440.23852038383484 and batch: 800, loss is 4.346641707420349 and perplexity is 77.21870399551217
At time: 440.6488666534424 and batch: 850, loss is 4.301651139259338 and perplexity is 73.82158284012488
At time: 441.03602838516235 and batch: 900, loss is 4.254541110992432 and perplexity is 70.42449274674925
At time: 441.4225435256958 and batch: 950, loss is 4.340847334861755 and perplexity is 76.77256385541601
At time: 441.8086531162262 and batch: 1000, loss is 4.384586086273194 and perplexity is 80.20501838334013
At time: 442.20881700515747 and batch: 1050, loss is 4.300859460830688 and perplexity is 73.76316301333115
At time: 442.60513186454773 and batch: 1100, loss is 4.427932586669922 and perplexity is 83.75807522633158
At time: 442.9927546977997 and batch: 1150, loss is 4.350198402404785 and perplexity is 77.49383636363741
At time: 443.3800780773163 and batch: 1200, loss is 4.309790935516357 and perplexity is 74.42492770467055
At time: 443.7674911022186 and batch: 1250, loss is 4.305587272644043 and perplexity is 74.11272705218522
At time: 444.15508222579956 and batch: 1300, loss is 4.3563244438171385 and perplexity is 77.97002389746793
At time: 444.5420923233032 and batch: 1350, loss is 4.313294219970703 and perplexity is 74.68611663935042
At time: 444.92860221862793 and batch: 1400, loss is 4.193318219184875 and perplexity is 66.24223292894018
At time: 445.31526803970337 and batch: 1450, loss is 4.27947687625885 and perplexity is 72.2026592009664
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.866653311965812 and perplexity of 129.88550244783795
Finished 36 epochs...
Completing Train Step...
At time: 446.57916164398193 and batch: 50, loss is 4.4476150798797605 and perplexity is 85.42297390349044
At time: 446.9673800468445 and batch: 100, loss is 4.4523343658447265 and perplexity is 85.82706209921824
At time: 447.35579776763916 and batch: 150, loss is 4.336582746505737 and perplexity is 76.44585760252012
At time: 447.76009345054626 and batch: 200, loss is 4.398367033004761 and perplexity is 81.31797062329453
At time: 448.1555292606354 and batch: 250, loss is 4.437344698905945 and perplexity is 84.55013727222406
At time: 448.54359245300293 and batch: 300, loss is 4.442180166244507 and perplexity is 84.95996675948109
At time: 448.93203568458557 and batch: 350, loss is 4.450047960281372 and perplexity is 85.6310507930086
At time: 449.3201699256897 and batch: 400, loss is 4.331126503944397 and perplexity is 76.02988631273402
At time: 449.70787239074707 and batch: 450, loss is 4.3706339168548585 and perplexity is 79.09375467518906
At time: 450.09660959243774 and batch: 500, loss is 4.344516725540161 and perplexity is 77.05478986766607
At time: 450.48521542549133 and batch: 550, loss is 4.3944313526153564 and perplexity is 80.99855804621124
At time: 450.8870348930359 and batch: 600, loss is 4.327477989196777 and perplexity is 75.75299557838225
At time: 451.2751498222351 and batch: 650, loss is 4.423245677947998 and perplexity is 83.36642729901257
At time: 451.67362809181213 and batch: 700, loss is 4.445559768676758 and perplexity is 85.24758341099677
At time: 452.06162333488464 and batch: 750, loss is 4.404982061386108 and perplexity is 81.85767441678144
At time: 452.4500079154968 and batch: 800, loss is 4.346374306678772 and perplexity is 77.19805841724467
At time: 452.84342312812805 and batch: 850, loss is 4.301461691856384 and perplexity is 73.8075988576303
At time: 453.2354905605316 and batch: 900, loss is 4.254417295455933 and perplexity is 70.4157736401887
At time: 453.6244602203369 and batch: 950, loss is 4.34075165271759 and perplexity is 76.76521844331127
At time: 454.0130043029785 and batch: 1000, loss is 4.3845768070220945 and perplexity is 80.20427414428814
At time: 454.4009771347046 and batch: 1050, loss is 4.3009256172180175 and perplexity is 73.76804307913606
At time: 454.7891275882721 and batch: 1100, loss is 4.427966909408569 and perplexity is 83.76095008219339
At time: 455.1770226955414 and batch: 1150, loss is 4.35011251449585 and perplexity is 77.48718086589426
At time: 455.56578302383423 and batch: 1200, loss is 4.309848785400391 and perplexity is 74.42923330264543
At time: 455.95618724823 and batch: 1250, loss is 4.305719914436341 and perplexity is 74.12255814912622
At time: 456.344313621521 and batch: 1300, loss is 4.356352653503418 and perplexity is 77.9722234384053
At time: 456.73185324668884 and batch: 1350, loss is 4.313451433181763 and perplexity is 74.69785920658806
At time: 457.11970615386963 and batch: 1400, loss is 4.193451285362244 and perplexity is 66.25104811614501
At time: 457.5080988407135 and batch: 1450, loss is 4.2795825815200805 and perplexity is 72.21029180531487
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8665954068175745 and perplexity of 129.8779816263141
Finished 37 epochs...
Completing Train Step...
At time: 458.76250672340393 and batch: 50, loss is 4.447047433853149 and perplexity is 85.37449765175033
At time: 459.16245698928833 and batch: 100, loss is 4.451952857971191 and perplexity is 85.79432464446043
At time: 459.5492889881134 and batch: 150, loss is 4.336211290359497 and perplexity is 76.41746659219315
At time: 459.9368953704834 and batch: 200, loss is 4.398226995468139 and perplexity is 81.30658385231165
At time: 460.3234295845032 and batch: 250, loss is 4.437078943252564 and perplexity is 84.52767058070717
At time: 460.7235858440399 and batch: 300, loss is 4.441891984939575 and perplexity is 84.93548641295195
At time: 461.10959672927856 and batch: 350, loss is 4.449759292602539 and perplexity is 85.60633544377299
At time: 461.4964442253113 and batch: 400, loss is 4.330866198539734 and perplexity is 76.01009789803834
At time: 461.8947784900665 and batch: 450, loss is 4.370229997634888 and perplexity is 79.06181363872965
At time: 462.2917833328247 and batch: 500, loss is 4.344173154830933 and perplexity is 77.02832064614677
At time: 462.68133544921875 and batch: 550, loss is 4.394163818359375 and perplexity is 80.97689105570909
At time: 463.069375038147 and batch: 600, loss is 4.327208766937256 and perplexity is 75.73260393081301
At time: 463.4565408229828 and batch: 650, loss is 4.423160762786865 and perplexity is 83.35934852595724
At time: 463.8439302444458 and batch: 700, loss is 4.445264835357666 and perplexity is 85.22244476557104
At time: 464.2312681674957 and batch: 750, loss is 4.404795255661011 and perplexity is 81.84238436273648
At time: 464.6183798313141 and batch: 800, loss is 4.346158528327942 and perplexity is 77.18140254456512
At time: 465.00569128990173 and batch: 850, loss is 4.301283693313598 and perplexity is 73.79446238175856
At time: 465.39294147491455 and batch: 900, loss is 4.254302248954773 and perplexity is 70.40767301778803
At time: 465.78040838241577 and batch: 950, loss is 4.340659742355347 and perplexity is 76.75816324850415
At time: 466.1675298213959 and batch: 1000, loss is 4.38456208229065 and perplexity is 80.20309316658545
At time: 466.5548572540283 and batch: 1050, loss is 4.300945549011231 and perplexity is 73.76951342316971
At time: 466.94311451911926 and batch: 1100, loss is 4.427977867126465 and perplexity is 83.76186791608374
At time: 467.3411865234375 and batch: 1150, loss is 4.350002002716065 and perplexity is 77.4786180927786
At time: 467.7366108894348 and batch: 1200, loss is 4.309869794845581 and perplexity is 74.43079703596962
At time: 468.1258018016815 and batch: 1250, loss is 4.305781726837158 and perplexity is 74.1271399840058
At time: 468.5126941204071 and batch: 1300, loss is 4.356354150772095 and perplexity is 77.97234018386054
At time: 468.89931201934814 and batch: 1350, loss is 4.313571882247925 and perplexity is 74.70685703585298
At time: 469.28680086135864 and batch: 1400, loss is 4.193507847785949 and perplexity is 66.25479554198024
At time: 469.6745402812958 and batch: 1450, loss is 4.279591579437255 and perplexity is 72.21094155046288
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8665708884214745 and perplexity of 129.87479726555375
Finished 38 epochs...
Completing Train Step...
At time: 470.97567558288574 and batch: 50, loss is 4.446582770347595 and perplexity is 85.3348364536558
At time: 471.3894567489624 and batch: 100, loss is 4.451649265289307 and perplexity is 85.76828206871888
At time: 471.7911856174469 and batch: 150, loss is 4.33589729309082 and perplexity is 76.39347548317247
At time: 472.2055125236511 and batch: 200, loss is 4.398112401962281 and perplexity is 81.2972671796439
At time: 472.61429357528687 and batch: 250, loss is 4.436877799034119 and perplexity is 84.51067003830897
At time: 473.0235502719879 and batch: 300, loss is 4.441662969589234 and perplexity is 84.91603710995413
At time: 473.4163248538971 and batch: 350, loss is 4.4495118141174315 and perplexity is 85.58515233885124
At time: 473.8288588523865 and batch: 400, loss is 4.330648307800293 and perplexity is 75.9935378058132
At time: 474.23810625076294 and batch: 450, loss is 4.369888954162597 and perplexity is 79.03485472062353
At time: 474.6413209438324 and batch: 500, loss is 4.343875255584717 and perplexity is 77.00537738504877
At time: 475.03812313079834 and batch: 550, loss is 4.393932876586914 and perplexity is 80.95819226820896
At time: 475.4266788959503 and batch: 600, loss is 4.32697340965271 and perplexity is 75.71478180816572
At time: 475.83074426651 and batch: 650, loss is 4.423088827133179 and perplexity is 83.3533522324064
At time: 476.22363352775574 and batch: 700, loss is 4.445006856918335 and perplexity is 85.20046204792997
At time: 476.61156463623047 and batch: 750, loss is 4.40463791847229 and perplexity is 81.82950852501331
At time: 477.0006821155548 and batch: 800, loss is 4.345962424278259 and perplexity is 77.16626844294369
At time: 477.3901541233063 and batch: 850, loss is 4.301114468574524 and perplexity is 73.78197558968375
At time: 477.7785837650299 and batch: 900, loss is 4.254196972846985 and perplexity is 70.40026116216676
At time: 478.1682755947113 and batch: 950, loss is 4.340558681488037 and perplexity is 76.75040639391702
At time: 478.5572073459625 and batch: 1000, loss is 4.384531154632568 and perplexity is 80.20061271110043
At time: 478.94559359550476 and batch: 1050, loss is 4.300945596694946 and perplexity is 73.7695169407743
At time: 479.33642530441284 and batch: 1100, loss is 4.427971878051758 and perplexity is 83.7613662615014
At time: 479.74185037612915 and batch: 1150, loss is 4.349885778427124 and perplexity is 77.46961371875629
At time: 480.13579297065735 and batch: 1200, loss is 4.309868659973144 and perplexity is 74.43071256655753
At time: 480.5455632209778 and batch: 1250, loss is 4.305804643630982 and perplexity is 74.1288387598547
At time: 480.9507791996002 and batch: 1300, loss is 4.3563299560546875 and perplexity is 77.9704536879459
At time: 481.34428191185 and batch: 1350, loss is 4.313666353225708 and perplexity is 74.71391499906532
At time: 481.7495496273041 and batch: 1400, loss is 4.193521385192871 and perplexity is 66.25569246617901
At time: 482.1488709449768 and batch: 1450, loss is 4.279560194015503 and perplexity is 72.20867521517232
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8665588900574255 and perplexity of 129.87323898980378
Finished 39 epochs...
Completing Train Step...
At time: 483.4593343734741 and batch: 50, loss is 4.446170244216919 and perplexity is 85.29964086381109
At time: 483.8575484752655 and batch: 100, loss is 4.451383724212646 and perplexity is 85.74551009033665
At time: 484.24917817115784 and batch: 150, loss is 4.335615196228027 and perplexity is 76.37192816275947
At time: 484.6420707702637 and batch: 200, loss is 4.398013725280761 and perplexity is 81.28924543088831
At time: 485.04532837867737 and batch: 250, loss is 4.4367069196701046 and perplexity is 84.49623014253565
At time: 485.4385437965393 and batch: 300, loss is 4.441457185745239 and perplexity is 84.89856455926686
At time: 485.8343243598938 and batch: 350, loss is 4.449289226531983 and perplexity is 85.56610426645274
At time: 486.2353165149689 and batch: 400, loss is 4.330450272560119 and perplexity is 75.97848989735945
At time: 486.6357822418213 and batch: 450, loss is 4.3695823764801025 and perplexity is 79.01062811188551
At time: 487.0422067642212 and batch: 500, loss is 4.343591833114624 and perplexity is 76.98355542334313
At time: 487.4425961971283 and batch: 550, loss is 4.39371768951416 and perplexity is 80.94077298606872
At time: 487.8368287086487 and batch: 600, loss is 4.326754350662231 and perplexity is 75.69819762102249
At time: 488.2439286708832 and batch: 650, loss is 4.4230140209197994 and perplexity is 83.34711711696902
At time: 488.6389362812042 and batch: 700, loss is 4.44476879119873 and perplexity is 85.18018115281063
At time: 489.0285322666168 and batch: 750, loss is 4.404494514465332 and perplexity is 81.81777468696322
At time: 489.418270111084 and batch: 800, loss is 4.345767431259155 and perplexity is 77.1512230262103
At time: 489.8081889152527 and batch: 850, loss is 4.300949301719665 and perplexity is 73.76979025916441
At time: 490.19779109954834 and batch: 900, loss is 4.254096999168396 and perplexity is 70.39322334088907
At time: 490.6246130466461 and batch: 950, loss is 4.340449953079224 and perplexity is 76.74206189800414
At time: 491.0183424949646 and batch: 1000, loss is 4.384487829208374 and perplexity is 80.197138060805
At time: 491.42044258117676 and batch: 1050, loss is 4.30093391418457 and perplexity is 73.76865513266127
At time: 491.816335439682 and batch: 1100, loss is 4.427955827713013 and perplexity is 83.76002187398811
At time: 492.20610094070435 and batch: 1150, loss is 4.3497670555114745 and perplexity is 77.46041684629192
At time: 492.60679030418396 and batch: 1200, loss is 4.309855103492737 and perplexity is 74.42970355490024
At time: 493.007999420166 and batch: 1250, loss is 4.305790581703186 and perplexity is 74.12779637280549
At time: 493.4047076702118 and batch: 1300, loss is 4.356285810470581 and perplexity is 77.96701171269937
At time: 493.79465508461 and batch: 1350, loss is 4.313744029998779 and perplexity is 74.7197187602918
At time: 494.18539023399353 and batch: 1400, loss is 4.193506817817688 and perplexity is 66.25472730167884
At time: 494.5888407230377 and batch: 1450, loss is 4.279504866600036 and perplexity is 72.20468020631616
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8665510650373935 and perplexity of 129.8722227330832
Finished 40 epochs...
Completing Train Step...
At time: 495.8934497833252 and batch: 50, loss is 4.445788993835449 and perplexity is 85.2671265416352
At time: 496.2818751335144 and batch: 100, loss is 4.45113468170166 and perplexity is 85.72415847203865
At time: 496.6894643306732 and batch: 150, loss is 4.3353532028198245 and perplexity is 76.35192184188561
At time: 497.0948576927185 and batch: 200, loss is 4.397921934127807 and perplexity is 81.28178413977294
At time: 497.49158573150635 and batch: 250, loss is 4.436552262306213 and perplexity is 84.48316318879938
At time: 497.88002157211304 and batch: 300, loss is 4.441258087158203 and perplexity is 84.88166305761006
At time: 498.26862144470215 and batch: 350, loss is 4.449084520339966 and perplexity is 85.54859014776807
At time: 498.65934681892395 and batch: 400, loss is 4.330263338088989 and perplexity is 75.96428822596555
At time: 499.0525212287903 and batch: 450, loss is 4.369290018081665 and perplexity is 78.98753206751698
At time: 499.4455978870392 and batch: 500, loss is 4.343309736251831 and perplexity is 76.96184166670682
At time: 499.8335790634155 and batch: 550, loss is 4.39349931716919 and perplexity is 80.92309968941791
At time: 500.2228157520294 and batch: 600, loss is 4.326544008255005 and perplexity is 75.6822767543876
At time: 500.61137080192566 and batch: 650, loss is 4.422921667098999 and perplexity is 83.33942004768289
At time: 501.0142993927002 and batch: 700, loss is 4.444550228118897 and perplexity is 85.16156594444982
At time: 501.4048569202423 and batch: 750, loss is 4.4043390083312985 and perplexity is 81.80505251034029
At time: 501.79387640953064 and batch: 800, loss is 4.345561928749085 and perplexity is 77.13536988520936
At time: 502.1972939968109 and batch: 850, loss is 4.300772857666016 and perplexity is 73.75677516658581
At time: 502.6062984466553 and batch: 900, loss is 4.253970847129822 and perplexity is 70.38434365237002
At time: 503.0126521587372 and batch: 950, loss is 4.340335416793823 and perplexity is 76.7332726506538
At time: 503.4088590145111 and batch: 1000, loss is 4.38444296836853 and perplexity is 80.19354043053548
At time: 503.7979187965393 and batch: 1050, loss is 4.300898551940918 and perplexity is 73.76604655362742
At time: 504.1886513233185 and batch: 1100, loss is 4.427930965423584 and perplexity is 83.75793943396891
At time: 504.5769884586334 and batch: 1150, loss is 4.349645137786865 and perplexity is 77.45097362418251
At time: 504.96548223495483 and batch: 1200, loss is 4.309854812622071 and perplexity is 74.42968190548594
At time: 505.3541784286499 and batch: 1250, loss is 4.305764007568359 and perplexity is 74.125826516924
At time: 505.7429301738739 and batch: 1300, loss is 4.3562234592437745 and perplexity is 77.96215052542071
At time: 506.13149213790894 and batch: 1350, loss is 4.313821811676025 and perplexity is 74.7255308113729
At time: 506.52153635025024 and batch: 1400, loss is 4.193389229774475 and perplexity is 66.24693699597417
At time: 506.9093337059021 and batch: 1450, loss is 4.279429388046265 and perplexity is 72.19923050714894
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.866489508213141 and perplexity of 129.8642284575468
Finished 41 epochs...
Completing Train Step...
At time: 508.1926267147064 and batch: 50, loss is 4.445526781082154 and perplexity is 85.24477134465612
At time: 508.6047158241272 and batch: 100, loss is 4.450872859954834 and perplexity is 85.7017169610883
At time: 508.9929220676422 and batch: 150, loss is 4.335101900100708 and perplexity is 76.33273680704363
At time: 509.3815166950226 and batch: 200, loss is 4.3978289604187015 and perplexity is 81.27422742211222
At time: 509.7701163291931 and batch: 250, loss is 4.436398582458496 and perplexity is 84.47018082673516
At time: 510.1598377227783 and batch: 300, loss is 4.441045465469361 and perplexity is 84.86361729358742
At time: 510.54850149154663 and batch: 350, loss is 4.448873491287231 and perplexity is 85.53053881457126
At time: 510.95205760002136 and batch: 400, loss is 4.330040860176086 and perplexity is 75.9473897295067
At time: 511.3392765522003 and batch: 450, loss is 4.369035959243774 and perplexity is 78.96746713585657
At time: 511.7412865161896 and batch: 500, loss is 4.3430141353607175 and perplexity is 76.93909503985563
At time: 512.1333975791931 and batch: 550, loss is 4.393252992630005 and perplexity is 80.903168799012
At time: 512.521605014801 and batch: 600, loss is 4.326331357955933 and perplexity is 75.666184606662
At time: 512.9134199619293 and batch: 650, loss is 4.422793054580689 and perplexity is 83.32870224423269
At time: 513.3112120628357 and batch: 700, loss is 4.444190425872803 and perplexity is 85.13093013348943
At time: 513.7136831283569 and batch: 750, loss is 4.404242649078369 and perplexity is 81.7971702163666
At time: 514.107574224472 and batch: 800, loss is 4.345290627479553 and perplexity is 77.1144457999275
At time: 514.5101583003998 and batch: 850, loss is 4.300623812675476 and perplexity is 73.74578290791976
At time: 514.9031686782837 and batch: 900, loss is 4.25368456363678 and perplexity is 70.36419666062692
At time: 515.2985548973083 and batch: 950, loss is 4.340178928375244 and perplexity is 76.72126572166148
At time: 515.7017874717712 and batch: 1000, loss is 4.384185810089111 and perplexity is 80.17292064904522
At time: 516.105094909668 and batch: 1050, loss is 4.30068193435669 and perplexity is 73.75006926136861
At time: 516.4974644184113 and batch: 1100, loss is 4.427883977890015 and perplexity is 83.75400394743822
At time: 516.8857474327087 and batch: 1150, loss is 4.349347066879273 and perplexity is 77.4278911824535
At time: 517.2748758792877 and batch: 1200, loss is 4.309841737747193 and perplexity is 74.42870875306976
At time: 517.6638827323914 and batch: 1250, loss is 4.305708217620849 and perplexity is 74.12169115631035
At time: 518.0527377128601 and batch: 1300, loss is 4.356115427017212 and perplexity is 77.9537285556421
At time: 518.4627690315247 and batch: 1350, loss is 4.313888139724732 and perplexity is 74.73048737439797
At time: 518.865406036377 and batch: 1400, loss is 4.193282942771912 and perplexity is 66.23989618179205
At time: 519.2612884044647 and batch: 1450, loss is 4.279346971511841 and perplexity is 72.19328034198185
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.866495768229167 and perplexity of 129.86504141224265
Annealing...
Finished 42 epochs...
Completing Train Step...
At time: 520.5544831752777 and batch: 50, loss is 4.44526168346405 and perplexity is 85.22217615391482
At time: 520.9633545875549 and batch: 100, loss is 4.450751571655274 and perplexity is 85.69132297591582
At time: 521.3524231910706 and batch: 150, loss is 4.335189247131348 and perplexity is 76.3394045361433
At time: 521.7415008544922 and batch: 200, loss is 4.397426557540894 and perplexity is 81.24152901851303
At time: 522.1305034160614 and batch: 250, loss is 4.436380076408386 and perplexity is 84.4686176318003
At time: 522.5336792469025 and batch: 300, loss is 4.440672388076782 and perplexity is 84.83196250173353
At time: 522.9394955635071 and batch: 350, loss is 4.448348264694214 and perplexity is 85.48562769636003
At time: 523.3354568481445 and batch: 400, loss is 4.329002203941346 and perplexity is 75.86854745175151
At time: 523.7333469390869 and batch: 450, loss is 4.368660497665405 and perplexity is 78.93782345138644
At time: 524.1293532848358 and batch: 500, loss is 4.342172842025757 and perplexity is 76.87439391213064
At time: 524.5373702049255 and batch: 550, loss is 4.392217454910278 and perplexity is 80.81943387889196
At time: 524.932507276535 and batch: 600, loss is 4.325343141555786 and perplexity is 75.59144697665519
At time: 525.3221254348755 and batch: 650, loss is 4.42205171585083 and perplexity is 83.26695034231658
At time: 525.7105379104614 and batch: 700, loss is 4.443251981735229 and perplexity is 85.051076985899
At time: 526.098949432373 and batch: 750, loss is 4.403387508392334 and perplexity is 81.72725202731687
At time: 526.4873893260956 and batch: 800, loss is 4.344067749977111 and perplexity is 77.02020191515332
At time: 526.8760976791382 and batch: 850, loss is 4.29946916103363 and perplexity is 73.66068135938221
At time: 527.2646839618683 and batch: 900, loss is 4.25268295288086 and perplexity is 70.29375440816793
At time: 527.6533203125 and batch: 950, loss is 4.3386740350723265 and perplexity is 76.6058952345956
At time: 528.0535933971405 and batch: 1000, loss is 4.383078889846802 and perplexity is 80.08422471901032
At time: 528.4517991542816 and batch: 1050, loss is 4.299083347320557 and perplexity is 73.63226753997247
At time: 528.8439011573792 and batch: 1100, loss is 4.426802740097046 and perplexity is 83.66349489278073
At time: 529.2317972183228 and batch: 1150, loss is 4.347764120101929 and perplexity is 77.30542390679177
At time: 529.6194219589233 and batch: 1200, loss is 4.308483276367188 and perplexity is 74.32766887159187
At time: 530.0063097476959 and batch: 1250, loss is 4.304415125846862 and perplexity is 74.02590694943372
At time: 530.3938438892365 and batch: 1300, loss is 4.35451904296875 and perplexity is 77.82938374430155
At time: 530.7931571006775 and batch: 1350, loss is 4.312126407623291 and perplexity is 74.59894817826789
At time: 531.1893155574799 and batch: 1400, loss is 4.1913429594039915 and perplexity is 66.11151645243991
At time: 531.5996968746185 and batch: 1450, loss is 4.277437891960144 and perplexity is 72.05558910029694
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.866207285823985 and perplexity of 129.82758303604803
Finished 43 epochs...
Completing Train Step...
At time: 532.9173150062561 and batch: 50, loss is 4.444890146255493 and perplexity is 85.19051882578125
At time: 533.3123028278351 and batch: 100, loss is 4.450523357391358 and perplexity is 85.67176922502621
At time: 533.7031145095825 and batch: 150, loss is 4.335047721862793 and perplexity is 76.32860134589522
At time: 534.0920391082764 and batch: 200, loss is 4.397221431732178 and perplexity is 81.22486599323851
At time: 534.4839301109314 and batch: 250, loss is 4.436224083900452 and perplexity is 84.45544218795618
At time: 534.8881325721741 and batch: 300, loss is 4.440412826538086 and perplexity is 84.80994624442637
At time: 535.2833802700043 and batch: 350, loss is 4.448156871795654 and perplexity is 85.46926791991247
At time: 535.6821193695068 and batch: 400, loss is 4.328862094879151 and perplexity is 75.85791832535381
At time: 536.0814025402069 and batch: 450, loss is 4.368482093811036 and perplexity is 78.92374189556644
At time: 536.4874243736267 and batch: 500, loss is 4.341953029632569 and perplexity is 76.85749782468264
At time: 536.885769367218 and batch: 550, loss is 4.392006950378418 and perplexity is 80.80242281231422
At time: 537.2913978099823 and batch: 600, loss is 4.325200576782226 and perplexity is 75.58067106728471
At time: 537.6873450279236 and batch: 650, loss is 4.422022914886474 and perplexity is 83.26455220838221
At time: 538.0767576694489 and batch: 700, loss is 4.443052825927734 and perplexity is 85.03414025656352
At time: 538.482474565506 and batch: 750, loss is 4.403202295303345 and perplexity is 81.71211647220902
At time: 538.8763854503632 and batch: 800, loss is 4.343943762779236 and perplexity is 77.01065298812262
At time: 539.2656097412109 and batch: 850, loss is 4.299391989707947 and perplexity is 73.65499708628523
At time: 539.6549451351166 and batch: 900, loss is 4.2526414012908935 and perplexity is 70.29083365158905
At time: 540.0592985153198 and batch: 950, loss is 4.338602027893066 and perplexity is 76.60037925876237
At time: 540.4574859142303 and batch: 1000, loss is 4.383014268875122 and perplexity is 80.07904976579984
At time: 540.8465855121613 and batch: 1050, loss is 4.299129657745361 and perplexity is 73.63567756052069
At time: 541.2496931552887 and batch: 1100, loss is 4.426790580749512 and perplexity is 83.6624776054552
At time: 541.6433389186859 and batch: 1150, loss is 4.347714824676514 and perplexity is 77.30161319695942
At time: 542.0459370613098 and batch: 1200, loss is 4.308545002937317 and perplexity is 74.33225700526042
At time: 542.4410161972046 and batch: 1250, loss is 4.304508514404297 and perplexity is 74.03282044491219
At time: 542.8426127433777 and batch: 1300, loss is 4.35453278541565 and perplexity is 77.83045331782415
At time: 543.2403819561005 and batch: 1350, loss is 4.312144918441772 and perplexity is 74.60032907863729
At time: 543.6298334598541 and batch: 1400, loss is 4.191406893730163 and perplexity is 66.11574338281804
At time: 544.0184345245361 and batch: 1450, loss is 4.2774742269515995 and perplexity is 72.05820728707684
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.866178594083867 and perplexity of 129.82385811021297
Finished 44 epochs...
Completing Train Step...
At time: 545.2951984405518 and batch: 50, loss is 4.44466552734375 and perplexity is 85.17138557307739
At time: 545.6833066940308 and batch: 100, loss is 4.450419979095459 and perplexity is 85.6629130812915
At time: 546.0724890232086 and batch: 150, loss is 4.334964618682862 and perplexity is 76.32225845996432
At time: 546.4612147808075 and batch: 200, loss is 4.397087697982788 and perplexity is 81.21400421367497
At time: 546.8500363826752 and batch: 250, loss is 4.436118960380554 and perplexity is 84.44656440123912
At time: 547.254369020462 and batch: 300, loss is 4.440238389968872 and perplexity is 84.79515357859673
At time: 547.6486828327179 and batch: 350, loss is 4.448015909194947 and perplexity is 85.45722079874261
At time: 548.0514698028564 and batch: 400, loss is 4.328738036155701 and perplexity is 75.84850807256686
At time: 548.4508969783783 and batch: 450, loss is 4.368362598419189 and perplexity is 78.91431143556211
At time: 548.8528571128845 and batch: 500, loss is 4.3417889022827145 and perplexity is 76.84488444237708
At time: 549.2470970153809 and batch: 550, loss is 4.39185869216919 and perplexity is 80.79044407780154
At time: 549.6358819007874 and batch: 600, loss is 4.325088357925415 and perplexity is 75.5721899666591
At time: 550.0242865085602 and batch: 650, loss is 4.422010669708252 and perplexity is 83.2635326253433
At time: 550.4131019115448 and batch: 700, loss is 4.442907104492187 and perplexity is 85.02174986236979
At time: 550.8000319004059 and batch: 750, loss is 4.403096475601196 and perplexity is 81.70347017786422
At time: 551.209144115448 and batch: 800, loss is 4.343839106559753 and perplexity is 77.0025937660522
At time: 551.5960910320282 and batch: 850, loss is 4.299309644699097 and perplexity is 73.64893221460771
At time: 551.9846262931824 and batch: 900, loss is 4.252604446411133 and perplexity is 70.28823611027939
At time: 552.3741910457611 and batch: 950, loss is 4.33853208065033 and perplexity is 76.59502146082443
At time: 552.7623267173767 and batch: 1000, loss is 4.382962322235107 and perplexity is 80.07489003627181
At time: 553.1513533592224 and batch: 1050, loss is 4.299140930175781 and perplexity is 73.63650761825082
At time: 553.5386044979095 and batch: 1100, loss is 4.426769971847534 and perplexity is 83.66075343142172
At time: 553.9258470535278 and batch: 1150, loss is 4.347655868530273 and perplexity is 77.29705592608805
At time: 554.3153676986694 and batch: 1200, loss is 4.308589072227478 and perplexity is 74.3355328472442
At time: 554.7027564048767 and batch: 1250, loss is 4.30456422328949 and perplexity is 74.03694484568868
At time: 555.0900859832764 and batch: 1300, loss is 4.354528217315674 and perplexity is 77.8300977813443
At time: 555.4772174358368 and batch: 1350, loss is 4.312150106430054 and perplexity is 74.6007161052743
At time: 555.8641154766083 and batch: 1400, loss is 4.191426076889038 and perplexity is 66.11701170379264
At time: 556.2511188983917 and batch: 1450, loss is 4.2774742603302 and perplexity is 72.058209692279
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.866170247395833 and perplexity of 129.82277451549214
Finished 45 epochs...
Completing Train Step...
At time: 557.5015640258789 and batch: 50, loss is 4.444474511146545 and perplexity is 85.15511801262781
At time: 557.9014077186584 and batch: 100, loss is 4.450350017547607 and perplexity is 85.65692018093756
At time: 558.2888405323029 and batch: 150, loss is 4.334888591766357 and perplexity is 76.3164561345622
At time: 558.6766557693481 and batch: 200, loss is 4.396974782943726 and perplexity is 81.20483444892872
At time: 559.0646126270294 and batch: 250, loss is 4.436036653518677 and perplexity is 84.43961415555732
At time: 559.4530074596405 and batch: 300, loss is 4.440088701248169 and perplexity is 84.78246165047867
At time: 559.8408854007721 and batch: 350, loss is 4.447894201278687 and perplexity is 85.44682061137524
At time: 560.2335312366486 and batch: 400, loss is 4.328626689910888 and perplexity is 75.84006309618525
At time: 560.6345615386963 and batch: 450, loss is 4.368264122009277 and perplexity is 78.90654062010856
At time: 561.0412790775299 and batch: 500, loss is 4.341644010543823 and perplexity is 76.83375106003236
At time: 561.4300529956818 and batch: 550, loss is 4.3917303562164305 and perplexity is 80.78007642447255
At time: 561.8183128833771 and batch: 600, loss is 4.324986705780029 and perplexity is 75.56450828185399
At time: 562.2073276042938 and batch: 650, loss is 4.421998195648193 and perplexity is 83.26249399751461
At time: 562.5958020687103 and batch: 700, loss is 4.44277645111084 and perplexity is 85.01064220890422
At time: 562.984121799469 and batch: 750, loss is 4.403011665344239 and perplexity is 81.69654117939332
At time: 563.3731248378754 and batch: 800, loss is 4.34374098777771 and perplexity is 76.99503873598894
At time: 563.7710349559784 and batch: 850, loss is 4.299229249954224 and perplexity is 73.6430114654939
At time: 564.1689412593842 and batch: 900, loss is 4.2525706338882445 and perplexity is 70.28585952786648
At time: 564.5613355636597 and batch: 950, loss is 4.3384595251083375 and perplexity is 76.58946426913339
At time: 564.9495453834534 and batch: 1000, loss is 4.382911195755005 and perplexity is 80.07079619365248
At time: 565.3384380340576 and batch: 1050, loss is 4.299138355255127 and perplexity is 73.63631801033054
At time: 565.7264440059662 and batch: 1100, loss is 4.426741142272949 and perplexity is 83.65834156225755
At time: 566.115576505661 and batch: 1150, loss is 4.347593851089478 and perplexity is 77.29226230914396
At time: 566.5152423381805 and batch: 1200, loss is 4.308617911338806 and perplexity is 74.33767664886415
At time: 566.9114918708801 and batch: 1250, loss is 4.304599866867066 and perplexity is 74.03958383430698
At time: 567.3024315834045 and batch: 1300, loss is 4.354516572952271 and perplexity is 77.82919150467855
At time: 567.6913864612579 and batch: 1350, loss is 4.31214940071106 and perplexity is 74.60066345815054
At time: 568.0799765586853 and batch: 1400, loss is 4.191427044868469 and perplexity is 66.11707570373098
At time: 568.4693489074707 and batch: 1450, loss is 4.277458081245422 and perplexity is 72.05704386582647
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.86616711738782 and perplexity of 129.8223681698036
Finished 46 epochs...
Completing Train Step...
At time: 569.7679197788239 and batch: 50, loss is 4.444302353858948 and perplexity is 85.14045920033263
At time: 570.199476480484 and batch: 100, loss is 4.450294761657715 and perplexity is 85.65218726234957
At time: 570.5999314785004 and batch: 150, loss is 4.334816808700562 and perplexity is 76.31097810198754
At time: 571.0306839942932 and batch: 200, loss is 4.396874904632568 and perplexity is 81.19672425222925
At time: 571.4337117671967 and batch: 250, loss is 4.435965852737427 and perplexity is 84.43363597653901
At time: 571.8435776233673 and batch: 300, loss is 4.439951848983765 and perplexity is 84.77085977250977
At time: 572.2412254810333 and batch: 350, loss is 4.447781791687012 and perplexity is 85.4372161089896
At time: 572.632150888443 and batch: 400, loss is 4.328522329330444 and perplexity is 75.83214879615727
At time: 573.0214722156525 and batch: 450, loss is 4.36817403793335 and perplexity is 78.89943271747137
At time: 573.4113800525665 and batch: 500, loss is 4.341509618759155 and perplexity is 76.82342592892661
At time: 573.8014335632324 and batch: 550, loss is 4.391610889434815 and perplexity is 80.77042646515972
At time: 574.190994977951 and batch: 600, loss is 4.324891595840454 and perplexity is 75.557321687801
At time: 574.5805304050446 and batch: 650, loss is 4.421984481811523 and perplexity is 83.26135215710073
At time: 574.9697365760803 and batch: 700, loss is 4.44265305519104 and perplexity is 85.00015288969901
At time: 575.3600933551788 and batch: 750, loss is 4.40293511390686 and perplexity is 81.69028743110697
At time: 575.7544872760773 and batch: 800, loss is 4.343645687103272 and perplexity is 76.98770140650079
At time: 576.1613731384277 and batch: 850, loss is 4.299150156974792 and perplexity is 73.63718705064097
At time: 576.5578081607819 and batch: 900, loss is 4.252538905143738 and perplexity is 70.28362948116558
At time: 576.947986125946 and batch: 950, loss is 4.338384470939636 and perplexity is 76.58371612627514
At time: 577.3385264873505 and batch: 1000, loss is 4.382860260009766 and perplexity is 80.06671783184453
At time: 577.7288856506348 and batch: 1050, loss is 4.299129428863526 and perplexity is 73.6356607066536
At time: 578.119286775589 and batch: 1100, loss is 4.426707792282104 and perplexity is 83.65555160385519
At time: 578.5235242843628 and batch: 1150, loss is 4.347530403137207 and perplexity is 77.28735842894629
At time: 578.9203834533691 and batch: 1200, loss is 4.308637151718139 and perplexity is 74.33910694772133
At time: 579.3340640068054 and batch: 1250, loss is 4.304623293876648 and perplexity is 74.04131838066445
At time: 579.7332127094269 and batch: 1300, loss is 4.354500942230224 and perplexity is 77.82797498772658
At time: 580.1239099502563 and batch: 1350, loss is 4.312145261764527 and perplexity is 74.60035469063213
At time: 580.5139772891998 and batch: 1400, loss is 4.191417069435119 and perplexity is 66.11641616053863
At time: 580.90394282341 and batch: 1450, loss is 4.277431998252869 and perplexity is 72.0551644269987
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.866167639055822 and perplexity of 129.8224358939967
Annealing...
Finished 47 epochs...
Completing Train Step...
At time: 582.1825850009918 and batch: 50, loss is 4.444144177436828 and perplexity is 85.12699305216036
At time: 582.5706272125244 and batch: 100, loss is 4.450255546569824 and perplexity is 85.64882847015615
At time: 582.9594972133636 and batch: 150, loss is 4.3350119876861575 and perplexity is 76.32587385490501
At time: 583.3480753898621 and batch: 200, loss is 4.396654510498047 and perplexity is 81.17883094232442
At time: 583.736385345459 and batch: 250, loss is 4.435845375061035 and perplexity is 84.4234642210143
At time: 584.13427901268 and batch: 300, loss is 4.439802770614624 and perplexity is 84.75822321292645
At time: 584.5326206684113 and batch: 350, loss is 4.447664203643799 and perplexity is 85.42717030457463
At time: 584.9335472583771 and batch: 400, loss is 4.3279381322860715 and perplexity is 75.78786081667506
At time: 585.3309781551361 and batch: 450, loss is 4.36796007156372 and perplexity is 78.88255269822962
At time: 585.7285134792328 and batch: 500, loss is 4.341151599884033 and perplexity is 76.7959266153229
At time: 586.1341776847839 and batch: 550, loss is 4.391083793640137 and perplexity is 80.72786393128732
At time: 586.5283479690552 and batch: 600, loss is 4.324475116729737 and perplexity is 75.52586019363855
At time: 586.9173965454102 and batch: 650, loss is 4.421507015228271 and perplexity is 83.22160713298483
At time: 587.3190891742706 and batch: 700, loss is 4.442241897583008 and perplexity is 84.96521161383247
At time: 587.7231426239014 and batch: 750, loss is 4.402474126815796 and perplexity is 81.65263794176691
At time: 588.1239094734192 and batch: 800, loss is 4.343052306175232 and perplexity is 76.94203192383259
At time: 588.5158214569092 and batch: 850, loss is 4.29863317489624 and perplexity is 73.59912778344801
At time: 588.9039251804352 and batch: 900, loss is 4.252113571166992 and perplexity is 70.25374182210726
At time: 589.292946100235 and batch: 950, loss is 4.337655811309815 and perplexity is 76.52793298996008
At time: 589.6819083690643 and batch: 1000, loss is 4.38222825050354 and perplexity is 80.01613089243968
At time: 590.0701923370361 and batch: 1050, loss is 4.298395223617554 and perplexity is 73.58161686033765
At time: 590.4585981369019 and batch: 1100, loss is 4.426136770248413 and perplexity is 83.60779607667554
At time: 590.8461537361145 and batch: 1150, loss is 4.346732406616211 and perplexity is 77.22570798749351
At time: 591.2470846176147 and batch: 1200, loss is 4.307994394302368 and perplexity is 74.2913402882807
At time: 591.635853767395 and batch: 1250, loss is 4.303945913314819 and perplexity is 73.99118121370947
At time: 592.0245695114136 and batch: 1300, loss is 4.353819389343261 and perplexity is 77.77494917868643
At time: 592.4139006137848 and batch: 1350, loss is 4.3112297534942625 and perplexity is 74.53208870275459
At time: 592.806421995163 and batch: 1400, loss is 4.190422835350037 and perplexity is 66.05071363326664
At time: 593.2126071453094 and batch: 1450, loss is 4.276479663848877 and perplexity is 71.98657647944447
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.86610347389156 and perplexity of 129.81410608331728
Finished 48 epochs...
Completing Train Step...
At time: 594.5062739849091 and batch: 50, loss is 4.4440038824081425 and perplexity is 85.1150509959533
At time: 594.8956592082977 and batch: 100, loss is 4.450104417800904 and perplexity is 85.63588544620623
At time: 595.284432888031 and batch: 150, loss is 4.334939432144165 and perplexity is 76.32033619065598
At time: 595.6733596324921 and batch: 200, loss is 4.396509037017823 and perplexity is 81.16702243419988
At time: 596.0617136955261 and batch: 250, loss is 4.4357595205307 and perplexity is 84.41621639527816
At time: 596.4501206874847 and batch: 300, loss is 4.439663686752319 and perplexity is 84.74643553163706
At time: 596.8387198448181 and batch: 350, loss is 4.447567834854126 and perplexity is 85.41893818823306
At time: 597.2277069091797 and batch: 400, loss is 4.327881636619568 and perplexity is 75.78357925191143
At time: 597.6154398918152 and batch: 450, loss is 4.367892026901245 and perplexity is 78.87718534416805
At time: 598.0266389846802 and batch: 500, loss is 4.3410921478271485 and perplexity is 76.79136107524197
At time: 598.4235360622406 and batch: 550, loss is 4.391012678146362 and perplexity is 80.72212313351473
At time: 598.8260335922241 and batch: 600, loss is 4.324433784484864 and perplexity is 75.52273860480237
At time: 599.2223386764526 and batch: 650, loss is 4.421482133865356 and perplexity is 83.2195364917357
At time: 599.6309816837311 and batch: 700, loss is 4.442161197662354 and perplexity is 84.9583552046564
At time: 600.024885892868 and batch: 750, loss is 4.402408180236816 and perplexity is 81.64725340717774
At time: 600.4135558605194 and batch: 800, loss is 4.342996740341187 and perplexity is 76.93775669443507
At time: 600.8077881336212 and batch: 850, loss is 4.298605599403381 and perplexity is 73.59709827920781
At time: 601.222315788269 and batch: 900, loss is 4.252109584808349 and perplexity is 70.25346176605453
At time: 601.6106641292572 and batch: 950, loss is 4.337627158164978 and perplexity is 76.52574025542661
At time: 601.9993216991425 and batch: 1000, loss is 4.3821886539459225 and perplexity is 80.01296259182976
At time: 602.4042925834656 and batch: 1050, loss is 4.298433570861817 and perplexity is 73.58443856667462
At time: 602.8013651371002 and batch: 1100, loss is 4.426139688491821 and perplexity is 83.60804006493129
At time: 603.1900935173035 and batch: 1150, loss is 4.346720485687256 and perplexity is 77.22478739080228
At time: 603.5792815685272 and batch: 1200, loss is 4.308025398254395 and perplexity is 74.29364364913742
At time: 603.9673192501068 and batch: 1250, loss is 4.303999428749084 and perplexity is 73.99514098985756
At time: 604.3697073459625 and batch: 1300, loss is 4.3538477325439455 and perplexity is 77.77715360091925
At time: 604.765656709671 and batch: 1350, loss is 4.311231555938721 and perplexity is 74.53222304282593
At time: 605.154408454895 and batch: 1400, loss is 4.190456681251526 and perplexity is 66.05294921704598
At time: 605.5430603027344 and batch: 1450, loss is 4.276487545967102 and perplexity is 71.98714388838705
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.866090432191506 and perplexity of 129.81241309772278
Finished 49 epochs...
Completing Train Step...
At time: 606.8132984638214 and batch: 50, loss is 4.443878231048584 and perplexity is 85.10435684595805
At time: 607.2157373428345 and batch: 100, loss is 4.450035552978516 and perplexity is 85.62998834921856
At time: 607.6043033599854 and batch: 150, loss is 4.33491322517395 and perplexity is 76.31833609208698
At time: 608.0043232440948 and batch: 200, loss is 4.396411457061768 and perplexity is 81.15910254613509
At time: 608.3918929100037 and batch: 250, loss is 4.435682735443115 and perplexity is 84.40973473755915
At time: 608.785174369812 and batch: 300, loss is 4.4395615673065185 and perplexity is 84.737781714476
At time: 609.1874542236328 and batch: 350, loss is 4.447497549057007 and perplexity is 85.4129346610573
At time: 609.5922763347626 and batch: 400, loss is 4.327814769744873 and perplexity is 75.77851201023086
At time: 609.9864418506622 and batch: 450, loss is 4.36783501625061 and perplexity is 78.87268863269277
At time: 610.3816621303558 and batch: 500, loss is 4.3410405349731445 and perplexity is 76.787397756214
At time: 610.7733771800995 and batch: 550, loss is 4.390954952239991 and perplexity is 80.7174635102844
At time: 611.1877956390381 and batch: 600, loss is 4.324392013549804 and perplexity is 75.51958401527816
At time: 611.5845732688904 and batch: 650, loss is 4.421466627120972 and perplexity is 83.2182460376609
At time: 612.0087893009186 and batch: 700, loss is 4.4420993041992185 and perplexity is 84.95309700055643
At time: 612.4051706790924 and batch: 750, loss is 4.402363862991333 and perplexity is 81.64363510598263
At time: 612.7940950393677 and batch: 800, loss is 4.342952342033386 and perplexity is 76.93434086406093
At time: 613.1831951141357 and batch: 850, loss is 4.2985723161697384 and perplexity is 73.59464877055436
At time: 613.5730736255646 and batch: 900, loss is 4.252106895446778 and perplexity is 70.25327282934823
At time: 613.9620373249054 and batch: 950, loss is 4.33759521484375 and perplexity is 76.5232958081655
At time: 614.3521752357483 and batch: 1000, loss is 4.382158393859863 and perplexity is 80.01054142932837
At time: 614.7413184642792 and batch: 1050, loss is 4.298457946777344 and perplexity is 73.58623227659479
At time: 615.1302056312561 and batch: 1100, loss is 4.42613639831543 and perplexity is 83.60776498018431
At time: 615.5189824104309 and batch: 1150, loss is 4.346699228286743 and perplexity is 77.22314581001514
At time: 615.9072070121765 and batch: 1200, loss is 4.308055334091186 and perplexity is 74.29586772481797
At time: 616.3010821342468 and batch: 1250, loss is 4.304035930633545 and perplexity is 73.99784200124033
At time: 616.7030258178711 and batch: 1300, loss is 4.353865003585815 and perplexity is 77.77849690499568
At time: 617.1096024513245 and batch: 1350, loss is 4.31122579574585 and perplexity is 74.53179372408256
At time: 617.5068292617798 and batch: 1400, loss is 4.190468244552612 and perplexity is 66.0537130116014
At time: 617.9033970832825 and batch: 1450, loss is 4.276483359336853 and perplexity is 71.98684250546383
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.866082085503472 and perplexity of 129.81132959852954
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc1f716f898>
SETTINGS FOR THIS RUN
{'batch_size': 20, 'lr': 23.81289885111111, 'num_layers': 1, 'wordvec_source': '', 'seq_len': 35, 'anneal': 3.846529973176787, 'wordvec_dim': 200, 'dropout': 0.9642517586214361, 'tune_wordvecs': True, 'data': 'ptb'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.637197732925415 and batch: 50, loss is 9.43766653060913 and perplexity is 12552.392082859033
At time: 1.0535531044006348 and batch: 100, loss is 8.614352874755859 and perplexity is 5510.1816820702825
At time: 1.444760799407959 and batch: 150, loss is 8.246400575637818 and perplexity is 3813.8733371702883
At time: 1.8358025550842285 and batch: 200, loss is 7.958574085235596 and perplexity is 2859.991938877416
At time: 2.226116895675659 and batch: 250, loss is 7.810443696975708 and perplexity is 2466.2244488917536
At time: 2.61833119392395 and batch: 300, loss is 7.792054519653321 and perplexity is 2421.287057350463
At time: 3.010101079940796 and batch: 350, loss is 7.741032962799072 and perplexity is 2300.847846260097
At time: 3.402052879333496 and batch: 400, loss is 7.60504602432251 and perplexity is 2008.3043224283297
At time: 3.7959868907928467 and batch: 450, loss is 7.5627406978607175 and perplexity is 1925.1144468442171
At time: 4.223350763320923 and batch: 500, loss is 7.517603092193603 and perplexity is 1840.1513307494079
At time: 4.6222357749938965 and batch: 550, loss is 7.513789043426514 and perplexity is 1833.1462711464392
At time: 5.017260789871216 and batch: 600, loss is 7.3344968318939205 and perplexity is 1532.2566032886282
At time: 5.409566640853882 and batch: 650, loss is 7.472778310775757 and perplexity is 1759.488306426697
At time: 5.802295207977295 and batch: 700, loss is 7.396865348815918 and perplexity is 1630.8642186961229
At time: 6.19460391998291 and batch: 750, loss is 7.288900165557862 and perplexity is 1463.959698152326
At time: 6.586918354034424 and batch: 800, loss is 7.29794641494751 and perplexity is 1477.2631250134752
At time: 6.979525566101074 and batch: 850, loss is 7.20033224105835 and perplexity is 1339.875852223298
At time: 7.372348785400391 and batch: 900, loss is 7.136239547729492 and perplexity is 1256.6937556094313
At time: 7.771482944488525 and batch: 950, loss is 7.170621042251587 and perplexity is 1300.6521119455588
At time: 8.182486772537231 and batch: 1000, loss is 7.209045991897583 and perplexity is 1351.6022126486585
At time: 8.58342695236206 and batch: 1050, loss is 7.051017370223999 and perplexity is 1154.0322237718635
At time: 8.976410150527954 and batch: 1100, loss is 7.14099193572998 and perplexity is 1262.6802657762166
At time: 9.37095832824707 and batch: 1150, loss is 7.124333457946777 and perplexity is 1241.820165773786
At time: 9.763000249862671 and batch: 1200, loss is 7.0581920337677 and perplexity is 1162.3417902226558
At time: 10.155051708221436 and batch: 1250, loss is 7.064996261596679 and perplexity is 1170.277596478039
At time: 10.547137260437012 and batch: 1300, loss is 7.143098764419555 and perplexity is 1265.343321101547
At time: 10.93973684310913 and batch: 1350, loss is 7.0541032123565675 and perplexity is 1157.5988852772227
At time: 11.340084075927734 and batch: 1400, loss is 7.003891201019287 and perplexity is 1100.9086915769806
At time: 11.754764556884766 and batch: 1450, loss is 7.001392889022827 and perplexity is 1098.161711021832
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 6.455956613915598 and perplexity of 636.4823029479203
Finished 1 epochs...
Completing Train Step...
At time: 13.041327476501465 and batch: 50, loss is 6.384557132720947 and perplexity is 592.6222214834097
At time: 13.459543704986572 and batch: 100, loss is 5.880180740356446 and perplexity is 357.87391812338166
At time: 13.851216316223145 and batch: 150, loss is 5.58127721786499 and perplexity is 265.41037627244464
At time: 14.26190710067749 and batch: 200, loss is 5.496861305236816 and perplexity is 243.9251229974566
At time: 14.659146785736084 and batch: 250, loss is 5.465991649627686 and perplexity is 236.51027418419497
At time: 15.050079584121704 and batch: 300, loss is 5.4690876483917235 and perplexity is 237.2436443715562
At time: 15.438838005065918 and batch: 350, loss is 5.49262243270874 and perplexity is 242.89334382977984
At time: 15.847230911254883 and batch: 400, loss is 5.375407075881958 and perplexity is 216.02779411879445
At time: 16.243473768234253 and batch: 450, loss is 5.391490888595581 and perplexity is 219.53043711973507
At time: 16.635035276412964 and batch: 500, loss is 5.359723930358887 and perplexity is 212.6662276555357
At time: 17.02272939682007 and batch: 550, loss is 5.419057931900024 and perplexity is 225.66642918779712
At time: 17.420349836349487 and batch: 600, loss is 5.270199956893921 and perplexity is 194.4548411442745
At time: 17.818270206451416 and batch: 650, loss is 5.4199826049804685 and perplexity is 225.87519336445942
At time: 18.216712713241577 and batch: 700, loss is 5.4318014430999755 and perplexity is 228.56061372498374
At time: 18.614776849746704 and batch: 750, loss is 5.3818142795562744 and perplexity is 217.41637189499053
At time: 19.00952386856079 and batch: 800, loss is 5.324278030395508 and perplexity is 205.26011539267634
At time: 19.408745765686035 and batch: 850, loss is 5.268344593048096 and perplexity is 194.09439114871503
At time: 19.79916214942932 and batch: 900, loss is 5.2350656700134275 and perplexity is 187.74143492193778
At time: 20.187556743621826 and batch: 950, loss is 5.295654020309448 and perplexity is 199.46803946427954
At time: 20.575765371322632 and batch: 1000, loss is 5.350383014678955 and perplexity is 210.68897938638392
At time: 20.964741468429565 and batch: 1050, loss is 5.244972152709961 and perplexity is 189.61053501643715
At time: 21.369301080703735 and batch: 1100, loss is 5.324376182556152 and perplexity is 205.28026310525084
At time: 21.76501202583313 and batch: 1150, loss is 5.3710758495330815 and perplexity is 215.09415221158784
At time: 22.15314817428589 and batch: 1200, loss is 5.297292280197143 and perplexity is 199.79508777412778
At time: 22.541695833206177 and batch: 1250, loss is 5.284909992218018 and perplexity is 197.33642083523884
At time: 22.930028676986694 and batch: 1300, loss is 5.347390623092651 and perplexity is 210.05945781441818
At time: 23.318681955337524 and batch: 1350, loss is 5.330441913604736 and perplexity is 206.52922206598348
At time: 23.707934379577637 and batch: 1400, loss is 5.233166131973267 and perplexity is 187.38515141875274
At time: 24.097269296646118 and batch: 1450, loss is 5.27980257987976 and perplexity is 196.331111813872
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.459117922008547 and perplexity of 234.89014153461002
Finished 2 epochs...
Completing Train Step...
At time: 25.414875030517578 and batch: 50, loss is 5.381052694320679 and perplexity is 217.25085383223512
At time: 25.80426859855652 and batch: 100, loss is 5.364947872161865 and perplexity is 213.78009049652766
At time: 26.19351315498352 and batch: 150, loss is 5.276522760391235 and perplexity is 195.68823604168026
At time: 26.582697868347168 and batch: 200, loss is 5.315430011749267 and perplexity is 203.45198106364919
At time: 26.97212553024292 and batch: 250, loss is 5.323087844848633 and perplexity is 205.01596309207676
At time: 27.361027002334595 and batch: 300, loss is 5.325129404067993 and perplexity is 205.4349428621251
At time: 27.757413864135742 and batch: 350, loss is 5.384774160385132 and perplexity is 218.06085176733336
At time: 28.155097723007202 and batch: 400, loss is 5.235509080886841 and perplexity is 187.82469997452299
At time: 28.547122716903687 and batch: 450, loss is 5.267643280029297 and perplexity is 193.95831794585814
At time: 28.95089602470398 and batch: 500, loss is 5.265261688232422 and perplexity is 193.49693803428698
At time: 29.354222774505615 and batch: 550, loss is 5.322162618637085 and perplexity is 204.82636467347692
At time: 29.74940824508667 and batch: 600, loss is 5.216184015274048 and perplexity is 184.22982281957806
At time: 30.141366720199585 and batch: 650, loss is 5.3358726310729985 and perplexity is 207.65387499202387
At time: 30.544296503067017 and batch: 700, loss is 5.3511194896698 and perplexity is 210.84420370294606
At time: 30.936964988708496 and batch: 750, loss is 5.289663944244385 and perplexity is 198.2767821582352
At time: 31.325927257537842 and batch: 800, loss is 5.258185863494873 and perplexity is 192.1326201429509
At time: 31.71432590484619 and batch: 850, loss is 5.176103210449218 and perplexity is 176.99176577548218
At time: 32.116655349731445 and batch: 900, loss is 5.164183206558228 and perplexity is 174.89454749593176
At time: 32.513766050338745 and batch: 950, loss is 5.209754390716553 and perplexity is 183.04909411530534
At time: 32.903430223464966 and batch: 1000, loss is 5.277636651992798 and perplexity is 195.90633296994963
At time: 33.29304122924805 and batch: 1050, loss is 5.1555408763885495 and perplexity is 173.38956372217382
At time: 33.68315410614014 and batch: 1100, loss is 5.264585514068603 and perplexity is 193.36614462855437
At time: 34.071840047836304 and batch: 1150, loss is 5.252212219238281 and perplexity is 190.98830947539054
At time: 34.48084473609924 and batch: 1200, loss is 5.19123010635376 and perplexity is 179.68945417725172
At time: 34.869462966918945 and batch: 1250, loss is 5.204794673919678 and perplexity is 182.14347012426612
At time: 35.2584969997406 and batch: 1300, loss is 5.302498025894165 and perplexity is 200.83788209867024
At time: 35.6490261554718 and batch: 1350, loss is 5.2354019737243656 and perplexity is 187.80458368118474
At time: 36.038355112075806 and batch: 1400, loss is 5.104575958251953 and perplexity is 164.77418458214512
At time: 36.440210819244385 and batch: 1450, loss is 5.202633495330811 and perplexity is 181.75025061837061
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.390617174979968 and perplexity of 219.33871415546056
Finished 3 epochs...
Completing Train Step...
At time: 37.75723338127136 and batch: 50, loss is 5.274721708297729 and perplexity is 195.33610852966487
At time: 38.171791076660156 and batch: 100, loss is 5.29669153213501 and perplexity is 199.6750973079524
At time: 38.569427728652954 and batch: 150, loss is 5.210724077224731 and perplexity is 183.2266804398195
At time: 38.959526777267456 and batch: 200, loss is 5.247264976501465 and perplexity is 190.04577733854438
At time: 39.34950923919678 and batch: 250, loss is 5.29703914642334 and perplexity is 199.74451929013776
At time: 39.739341735839844 and batch: 300, loss is 5.285316276550293 and perplexity is 197.41661182027875
At time: 40.13012433052063 and batch: 350, loss is 5.320219440460205 and perplexity is 204.42873700741356
At time: 40.52025580406189 and batch: 400, loss is 5.219932622909546 and perplexity is 184.92172416319616
At time: 40.910773515701294 and batch: 450, loss is 5.235289173126221 and perplexity is 187.78340040657665
At time: 41.30109357833862 and batch: 500, loss is 5.21776554107666 and perplexity is 184.52141755950177
At time: 41.693053007125854 and batch: 550, loss is 5.285280065536499 and perplexity is 197.4094632940535
At time: 42.08422303199768 and batch: 600, loss is 5.153792905807495 and perplexity is 173.08674859879096
At time: 42.47483825683594 and batch: 650, loss is 5.3036431884765625 and perplexity is 201.06800586579266
At time: 42.86571717262268 and batch: 700, loss is 5.2825110721588135 and perplexity is 196.8635939006473
At time: 43.25536131858826 and batch: 750, loss is 5.27656044960022 and perplexity is 195.69561151549132
At time: 43.65226721763611 and batch: 800, loss is 5.200947322845459 and perplexity is 181.44404657553747
At time: 44.056748390197754 and batch: 850, loss is 5.141652050018311 and perplexity is 170.99803240249642
At time: 44.472089767456055 and batch: 900, loss is 5.143921327590943 and perplexity is 171.38651502312922
At time: 44.86276340484619 and batch: 950, loss is 5.175508260726929 and perplexity is 176.8864958918357
At time: 45.25312304496765 and batch: 1000, loss is 5.24211724281311 and perplexity is 189.06998599998582
At time: 45.64413928985596 and batch: 1050, loss is 5.139259958267212 and perplexity is 170.58947826404025
At time: 46.03572082519531 and batch: 1100, loss is 5.249057340621948 and perplexity is 190.3867140211604
At time: 46.42546510696411 and batch: 1150, loss is 5.232655839920044 and perplexity is 187.28955465829983
At time: 46.81646966934204 and batch: 1200, loss is 5.197745866775513 and perplexity is 180.86409027892213
At time: 47.20670509338379 and batch: 1250, loss is 5.186889400482178 and perplexity is 178.9111654916019
At time: 47.59852623939514 and batch: 1300, loss is 5.3001110553741455 and perplexity is 200.3590596896309
At time: 47.98922276496887 and batch: 1350, loss is 5.247317514419556 and perplexity is 190.05576221031754
At time: 48.391125440597534 and batch: 1400, loss is 5.1481404304504395 and perplexity is 172.1111399173141
At time: 48.80462694168091 and batch: 1450, loss is 5.168361654281616 and perplexity is 175.62686412764518
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.381436339810363 and perplexity of 217.33421713239247
Finished 4 epochs...
Completing Train Step...
At time: 50.0952684879303 and batch: 50, loss is 5.284168138504028 and perplexity is 197.19008036685824
At time: 50.48428273200989 and batch: 100, loss is 5.2843563270568845 and perplexity is 197.22719277467579
At time: 50.87399435043335 and batch: 150, loss is 5.182899961471557 and perplexity is 178.19883215851675
At time: 51.26320838928223 and batch: 200, loss is 5.22726357460022 and perplexity is 186.28235766513995
At time: 51.666505336761475 and batch: 250, loss is 5.274144077301026 and perplexity is 195.22330892001452
At time: 52.079073667526245 and batch: 300, loss is 5.254156427383423 and perplexity is 191.3599916990246
At time: 52.49008250236511 and batch: 350, loss is 5.294348115921021 and perplexity is 199.20772328720605
At time: 52.88620114326477 and batch: 400, loss is 5.187968797683716 and perplexity is 179.10438596501655
At time: 53.274110555648804 and batch: 450, loss is 5.223873176574707 and perplexity is 185.65185575769289
At time: 53.663285970687866 and batch: 500, loss is 5.206396732330322 and perplexity is 182.43550847130578
At time: 54.05305314064026 and batch: 550, loss is 5.284881658554077 and perplexity is 197.33082965061743
At time: 54.45565223693848 and batch: 600, loss is 5.156093111038208 and perplexity is 173.48534189072802
At time: 54.84467363357544 and batch: 650, loss is 5.271734170913696 and perplexity is 194.7534054599869
At time: 55.234559535980225 and batch: 700, loss is 5.294162864685059 and perplexity is 199.17082322825024
At time: 55.624401807785034 and batch: 750, loss is 5.230587339401245 and perplexity is 186.90254651858314
At time: 56.01471209526062 and batch: 800, loss is 5.200719375610351 and perplexity is 181.4026916203467
At time: 56.404240131378174 and batch: 850, loss is 5.14854061126709 and perplexity is 172.1800292770216
At time: 56.81462097167969 and batch: 900, loss is 5.122045774459838 and perplexity is 167.6780504508318
At time: 57.21827960014343 and batch: 950, loss is 5.170076313018799 and perplexity is 175.9282625886139
At time: 57.63076162338257 and batch: 1000, loss is 5.2272147369384765 and perplexity is 186.27326029251662
At time: 58.04327368736267 and batch: 1050, loss is 5.133907766342163 and perplexity is 169.67888963226073
At time: 58.4458794593811 and batch: 1100, loss is 5.223813791275024 and perplexity is 185.64083109395673
At time: 58.84202241897583 and batch: 1150, loss is 5.228681316375733 and perplexity is 186.54664524714778
At time: 59.232260942459106 and batch: 1200, loss is 5.196091260910034 and perplexity is 180.56507893547092
At time: 59.62208795547485 and batch: 1250, loss is 5.158779420852661 and perplexity is 173.95200378589786
At time: 60.01179552078247 and batch: 1300, loss is 5.285682487487793 and perplexity is 197.48892118220303
At time: 60.40127158164978 and batch: 1350, loss is 5.2081138610839846 and perplexity is 182.74904284099276
At time: 60.79097080230713 and batch: 1400, loss is 5.0908363342285154 and perplexity is 162.5257310615199
At time: 61.18133878707886 and batch: 1450, loss is 5.167801237106323 and perplexity is 175.52846739073104
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.3394425873063565 and perplexity of 208.39651504495572
Finished 5 epochs...
Completing Train Step...
At time: 62.46686029434204 and batch: 50, loss is 5.222074031829834 and perplexity is 185.31814148718578
At time: 62.87533402442932 and batch: 100, loss is 5.280454549789429 and perplexity is 196.45915552689485
At time: 63.265034914016724 and batch: 150, loss is 5.165085544586182 and perplexity is 175.05243271922697
At time: 63.668065309524536 and batch: 200, loss is 5.247458295822144 and perplexity is 190.08252041057574
At time: 64.07431507110596 and batch: 250, loss is 5.282923240661621 and perplexity is 196.9447515975768
At time: 64.48700213432312 and batch: 300, loss is 5.267975482940674 and perplexity is 194.02276216745184
At time: 64.87784004211426 and batch: 350, loss is 5.314647779464722 and perplexity is 203.29289658432614
At time: 65.26630973815918 and batch: 400, loss is 5.213709154129028 and perplexity is 183.774443322271
At time: 65.66579556465149 and batch: 450, loss is 5.2134971427917485 and perplexity is 183.7354851867135
At time: 66.06893658638 and batch: 500, loss is 5.207965030670166 and perplexity is 182.72184624921192
At time: 66.46562099456787 and batch: 550, loss is 5.26710355758667 and perplexity is 193.85366253370637
At time: 66.85701894760132 and batch: 600, loss is 5.153849267959595 and perplexity is 173.09650441536883
At time: 67.24652600288391 and batch: 650, loss is 5.294058046340942 and perplexity is 199.14994756645842
At time: 67.63616681098938 and batch: 700, loss is 5.3206491374969485 and perplexity is 204.51659830544867
At time: 68.02729630470276 and batch: 750, loss is 5.245537796020508 and perplexity is 189.71781728606706
At time: 68.42835402488708 and batch: 800, loss is 5.175642366409302 and perplexity is 176.91021896673388
At time: 68.82524371147156 and batch: 850, loss is 5.153613805770874 and perplexity is 173.0557515316491
At time: 69.21392846107483 and batch: 900, loss is 5.113220386505127 and perplexity is 166.204737446242
At time: 69.60210371017456 and batch: 950, loss is 5.175741834640503 and perplexity is 176.92781678849346
At time: 69.99008083343506 and batch: 1000, loss is 5.257294206619263 and perplexity is 191.96138012618601
At time: 70.37821817398071 and batch: 1050, loss is 5.11504319190979 and perplexity is 166.50797262534013
At time: 70.76605439186096 and batch: 1100, loss is 5.212143354415893 and perplexity is 183.48691451664132
At time: 71.15379977226257 and batch: 1150, loss is 5.198012828826904 and perplexity is 180.9123805730372
At time: 71.54187512397766 and batch: 1200, loss is 5.183590669631958 and perplexity is 178.32195806320095
At time: 71.94006752967834 and batch: 1250, loss is 5.17172022819519 and perplexity is 176.21771157904826
At time: 72.33754634857178 and batch: 1300, loss is 5.271860761642456 and perplexity is 194.7780609960608
At time: 72.74828505516052 and batch: 1350, loss is 5.1875638580322265 and perplexity is 179.03187417982298
At time: 73.14476490020752 and batch: 1400, loss is 5.078457098007203 and perplexity is 160.52618858400652
At time: 73.54098224639893 and batch: 1450, loss is 5.1554771995544435 and perplexity is 173.37852317520623
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.41993648170406 and perplexity of 225.8647755007368
Annealing...
Finished 6 epochs...
Completing Train Step...
At time: 74.82724809646606 and batch: 50, loss is 5.195830411911011 and perplexity is 180.51798485786065
At time: 75.23496222496033 and batch: 100, loss is 5.166413049697876 and perplexity is 175.28497003156224
At time: 75.62406420707703 and batch: 150, loss is 5.056855487823486 and perplexity is 157.0957493339825
At time: 76.01404309272766 and batch: 200, loss is 5.079222726821899 and perplexity is 160.64913912073072
At time: 76.40281414985657 and batch: 250, loss is 5.095617723464966 and perplexity is 163.30469061304473
At time: 76.79251146316528 and batch: 300, loss is 5.115671758651733 and perplexity is 166.61266689942312
At time: 77.18131637573242 and batch: 350, loss is 5.141102428436279 and perplexity is 170.90407401654673
At time: 77.57074332237244 and batch: 400, loss is 5.019328899383545 and perplexity is 151.30972566312386
At time: 77.95956540107727 and batch: 450, loss is 5.034441547393799 and perplexity is 153.61378263640873
At time: 78.34887528419495 and batch: 500, loss is 5.027194395065307 and perplexity is 152.50454441793002
At time: 78.74271702766418 and batch: 550, loss is 5.078270711898804 and perplexity is 160.4962715205694
At time: 79.1434679031372 and batch: 600, loss is 4.965249185562134 and perplexity is 143.3442651446327
At time: 79.53522849082947 and batch: 650, loss is 5.099636173248291 and perplexity is 163.9622425966254
At time: 79.92329144477844 and batch: 700, loss is 5.11989182472229 and perplexity is 167.31726905005948
At time: 80.31254601478577 and batch: 750, loss is 5.074378242492676 and perplexity is 159.87275898286953
At time: 80.7014811038971 and batch: 800, loss is 4.973500499725342 and perplexity is 144.53193689774974
At time: 81.09101700782776 and batch: 850, loss is 4.951201610565185 and perplexity is 141.34470320950203
At time: 81.48009657859802 and batch: 900, loss is 4.910405292510986 and perplexity is 135.6943991890267
At time: 81.88325214385986 and batch: 950, loss is 4.974078102111816 and perplexity is 144.61544300376514
At time: 82.27692103385925 and batch: 1000, loss is 5.008481111526489 and perplexity is 149.67722040244809
At time: 82.66604471206665 and batch: 1050, loss is 4.908301639556885 and perplexity is 135.40924530288413
At time: 83.05576848983765 and batch: 1100, loss is 5.025675239562989 and perplexity is 152.27304218861403
At time: 83.44554996490479 and batch: 1150, loss is 4.993674459457398 and perplexity is 147.4773285849626
At time: 83.83425974845886 and batch: 1200, loss is 4.919069480895996 and perplexity is 136.8751889321464
At time: 84.23786163330078 and batch: 1250, loss is 4.907381439208985 and perplexity is 135.28469898082048
At time: 84.63424777984619 and batch: 1300, loss is 5.000063171386719 and perplexity is 148.42253486378127
At time: 85.02970385551453 and batch: 1350, loss is 4.9602052688598635 and perplexity is 142.62306896721856
At time: 85.41984534263611 and batch: 1400, loss is 4.838533277511597 and perplexity is 126.28399225652255
At time: 85.80834126472473 and batch: 1450, loss is 4.9178728675842285 and perplexity is 136.7115002146006
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.197754427918002 and perplexity of 180.86563868879824
Finished 7 epochs...
Completing Train Step...
At time: 87.1115243434906 and batch: 50, loss is 5.037475185394287 and perplexity is 154.0804988108436
At time: 87.50123023986816 and batch: 100, loss is 5.056531352996826 and perplexity is 157.04483738211718
At time: 87.89986729621887 and batch: 150, loss is 4.962591619491577 and perplexity is 142.96382403677586
At time: 88.29655528068542 and batch: 200, loss is 5.004398679733276 and perplexity is 149.06741894251618
At time: 88.68734097480774 and batch: 250, loss is 5.0134352684021 and perplexity is 150.42058468425438
At time: 89.07668352127075 and batch: 300, loss is 5.03847445487976 and perplexity is 154.23454370497453
At time: 89.47748637199402 and batch: 350, loss is 5.061994876861572 and perplexity is 157.90520377498245
At time: 89.87303614616394 and batch: 400, loss is 4.964013404846192 and perplexity is 143.16723247533514
At time: 90.26164865493774 and batch: 450, loss is 4.969109554290771 and perplexity is 143.89869632909827
At time: 90.65024280548096 and batch: 500, loss is 4.971014709472656 and perplexity is 144.17310699052248
At time: 91.0386712551117 and batch: 550, loss is 5.019818010330201 and perplexity is 151.38375100810865
At time: 91.42665219306946 and batch: 600, loss is 4.901535673141479 and perplexity is 134.49616332111688
At time: 91.81534838676453 and batch: 650, loss is 5.02582857131958 and perplexity is 152.29639227176318
At time: 92.20397543907166 and batch: 700, loss is 5.051042470932007 and perplexity is 156.18519817819632
At time: 92.59337902069092 and batch: 750, loss is 5.008327560424805 and perplexity is 149.65423906480825
At time: 92.98246622085571 and batch: 800, loss is 4.9260085010528565 and perplexity is 137.8282715325674
At time: 93.37267756462097 and batch: 850, loss is 4.897057542800903 and perplexity is 133.89521853026903
At time: 93.7626416683197 and batch: 900, loss is 4.862206382751465 and perplexity is 129.3091931654926
At time: 94.16617345809937 and batch: 950, loss is 4.922042798995972 and perplexity is 137.2827680397338
At time: 94.5565390586853 and batch: 1000, loss is 4.9664789485931395 and perplexity is 143.52065305805223
At time: 94.94633388519287 and batch: 1050, loss is 4.860064191818237 and perplexity is 129.03248467134168
At time: 95.35033440589905 and batch: 1100, loss is 4.9877175617218015 and perplexity is 146.60143262167207
At time: 95.75326800346375 and batch: 1150, loss is 4.95663743019104 and perplexity is 142.11511954631112
At time: 96.15867733955383 and batch: 1200, loss is 4.902636737823486 and perplexity is 134.6443338541161
At time: 96.5645318031311 and batch: 1250, loss is 4.867177686691284 and perplexity is 129.95362898288238
At time: 96.96247172355652 and batch: 1300, loss is 4.963104772567749 and perplexity is 143.0372051891334
At time: 97.35228157043457 and batch: 1350, loss is 4.9188182926177975 and perplexity is 136.8408118068566
At time: 97.74233937263489 and batch: 1400, loss is 4.804052648544311 and perplexity is 122.00385572587615
At time: 98.13285493850708 and batch: 1450, loss is 4.887346506118774 and perplexity is 132.60125020735953
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.20775636852297 and perplexity of 182.6837230940021
Annealing...
Finished 8 epochs...
Completing Train Step...
At time: 99.47609162330627 and batch: 50, loss is 4.993662338256836 and perplexity is 147.47554099351845
At time: 99.87175750732422 and batch: 100, loss is 4.974747638702393 and perplexity is 144.71230075570483
At time: 100.26048636436462 and batch: 150, loss is 4.858707008361816 and perplexity is 128.8574826995573
At time: 100.64911150932312 and batch: 200, loss is 4.886982946395874 and perplexity is 132.5530504958457
At time: 101.04658317565918 and batch: 250, loss is 4.905536890029907 and perplexity is 135.03538970267252
At time: 101.45225119590759 and batch: 300, loss is 4.918850545883179 and perplexity is 136.84522544105144
At time: 101.84989166259766 and batch: 350, loss is 4.938986320495605 and perplexity is 139.62863910863183
At time: 102.23943519592285 and batch: 400, loss is 4.824624633789062 and perplexity is 124.53971160862984
At time: 102.62859153747559 and batch: 450, loss is 4.846295614242553 and perplexity is 127.268065541068
At time: 103.01871538162231 and batch: 500, loss is 4.84083044052124 and perplexity is 126.57442062518223
At time: 103.40786862373352 and batch: 550, loss is 4.8807456588745115 and perplexity is 131.72885206140734
At time: 103.80037140846252 and batch: 600, loss is 4.778114404678345 and perplexity is 118.87997904251534
At time: 104.18874502182007 and batch: 650, loss is 4.895385026931763 and perplexity is 133.6714638212852
At time: 104.59699130058289 and batch: 700, loss is 4.919680004119873 and perplexity is 136.95877992828773
At time: 104.99454951286316 and batch: 750, loss is 4.873814239501953 and perplexity is 130.81894127395384
At time: 105.39104199409485 and batch: 800, loss is 4.7994112873077395 and perplexity is 121.4389038462685
At time: 105.79582834243774 and batch: 850, loss is 4.751553535461426 and perplexity is 115.76398836398316
At time: 106.19167613983154 and batch: 900, loss is 4.721668472290039 and perplexity is 112.35555850305367
At time: 106.6004626750946 and batch: 950, loss is 4.789399967193604 and perplexity is 120.22920554764669
At time: 106.99620985984802 and batch: 1000, loss is 4.837915315628051 and perplexity is 126.20597767030908
At time: 107.38498830795288 and batch: 1050, loss is 4.729670133590698 and perplexity is 113.25819611159012
At time: 107.77701950073242 and batch: 1100, loss is 4.839085912704467 and perplexity is 126.3538005224153
At time: 108.16651749610901 and batch: 1150, loss is 4.789805183410644 and perplexity is 120.27793424365865
At time: 108.55692958831787 and batch: 1200, loss is 4.7412786865234375 and perplexity is 114.58062074375906
At time: 108.94602155685425 and batch: 1250, loss is 4.712368679046631 and perplexity is 111.31551861294248
At time: 109.33552885055542 and batch: 1300, loss is 4.798454399108887 and perplexity is 121.3227559714242
At time: 109.72370266914368 and batch: 1350, loss is 4.744829969406128 and perplexity is 114.98825232000655
At time: 110.11741709709167 and batch: 1400, loss is 4.638723468780517 and perplexity is 103.41225431951507
At time: 110.52419686317444 and batch: 1450, loss is 4.711356735229492 and perplexity is 111.20293053814136
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.093363965678419 and perplexity of 162.93705583048722
Finished 9 epochs...
Completing Train Step...
At time: 111.84781908988953 and batch: 50, loss is 4.906884622573853 and perplexity is 135.21750398506597
At time: 112.25712871551514 and batch: 100, loss is 4.910331420898437 and perplexity is 135.68437559517886
At time: 112.64656019210815 and batch: 150, loss is 4.810372047424316 and perplexity is 122.77728799470958
At time: 113.04548048973083 and batch: 200, loss is 4.843521614074707 and perplexity is 126.91551312220658
At time: 113.43413591384888 and batch: 250, loss is 4.864618158340454 and perplexity is 129.62143429742085
At time: 113.82401466369629 and batch: 300, loss is 4.883909406661988 and perplexity is 132.14626887825798
At time: 114.21635246276855 and batch: 350, loss is 4.904062080383301 and perplexity is 134.8363849904111
At time: 114.63596820831299 and batch: 400, loss is 4.792515926361084 and perplexity is 120.60441911436288
At time: 115.05051016807556 and batch: 450, loss is 4.819208354949951 and perplexity is 123.86699326365888
At time: 115.44776129722595 and batch: 500, loss is 4.81556004524231 and perplexity is 123.41591145308396
At time: 115.84270286560059 and batch: 550, loss is 4.854556159973145 and perplexity is 128.32372336852404
At time: 116.23724699020386 and batch: 600, loss is 4.753980531692505 and perplexity is 116.04528834635703
At time: 116.6262629032135 and batch: 650, loss is 4.871841402053833 and perplexity is 130.56111117974248
At time: 117.02938032150269 and batch: 700, loss is 4.8976333045959475 and perplexity is 133.97233247914042
At time: 117.4314866065979 and batch: 750, loss is 4.854424886703491 and perplexity is 128.3068789994152
At time: 117.82484006881714 and batch: 800, loss is 4.779488105773925 and perplexity is 119.04339681785899
At time: 118.21308279037476 and batch: 850, loss is 4.736012830734253 and perplexity is 113.978841550484
At time: 118.60236310958862 and batch: 900, loss is 4.705910863876343 and perplexity is 110.59897969627109
At time: 119.00370979309082 and batch: 950, loss is 4.774112138748169 and perplexity is 118.40514060130657
At time: 119.40555953979492 and batch: 1000, loss is 4.821710863113403 and perplexity is 124.17735961066839
At time: 119.80200934410095 and batch: 1050, loss is 4.719696073532105 and perplexity is 112.13416694700464
At time: 120.19104409217834 and batch: 1100, loss is 4.8296420192718506 and perplexity is 125.16614556584538
At time: 120.57999062538147 and batch: 1150, loss is 4.780332412719726 and perplexity is 119.1439484268818
At time: 120.96925044059753 and batch: 1200, loss is 4.731441669464111 and perplexity is 113.45901489527974
At time: 121.37068319320679 and batch: 1250, loss is 4.70679126739502 and perplexity is 110.69639430294673
At time: 121.7683641910553 and batch: 1300, loss is 4.79326545715332 and perplexity is 120.69484972619935
At time: 122.16127753257751 and batch: 1350, loss is 4.7413272953033445 and perplexity is 114.5861905033029
At time: 122.55815744400024 and batch: 1400, loss is 4.638421211242676 and perplexity is 103.38100190951802
At time: 122.94750022888184 and batch: 1450, loss is 4.715282802581787 and perplexity is 111.6403788971646
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.089371118790064 and perplexity of 162.2877702257404
Finished 10 epochs...
Completing Train Step...
At time: 124.24486017227173 and batch: 50, loss is 4.8865674781799315 and perplexity is 132.49799035509966
At time: 124.64898252487183 and batch: 100, loss is 4.889495878219605 and perplexity is 132.8865661503124
At time: 125.04163408279419 and batch: 150, loss is 4.789433002471924 and perplexity is 120.23317741851972
At time: 125.44295716285706 and batch: 200, loss is 4.820378694534302 and perplexity is 124.01204457215759
At time: 125.83398485183716 and batch: 250, loss is 4.84306923866272 and perplexity is 126.85811264893064
At time: 126.22387218475342 and batch: 300, loss is 4.864908647537232 and perplexity is 129.65909339327052
At time: 126.61396718025208 and batch: 350, loss is 4.883679027557373 and perplexity is 132.11582864568706
At time: 127.00386929512024 and batch: 400, loss is 4.771709012985229 and perplexity is 118.1209397793935
At time: 127.39431381225586 and batch: 450, loss is 4.8020133113861085 and perplexity is 121.75530225775438
At time: 127.78413343429565 and batch: 500, loss is 4.798891458511353 and perplexity is 121.37579281193524
At time: 128.18592524528503 and batch: 550, loss is 4.838240013122559 and perplexity is 126.24696308862173
At time: 128.5876567363739 and batch: 600, loss is 4.738852138519287 and perplexity is 114.30292242758684
At time: 128.97726702690125 and batch: 650, loss is 4.857079982757568 and perplexity is 128.64799874000153
At time: 129.36756324768066 and batch: 700, loss is 4.882218856811523 and perplexity is 131.92305775109588
At time: 129.7573356628418 and batch: 750, loss is 4.84092080116272 and perplexity is 126.58585848778333
At time: 130.14711141586304 and batch: 800, loss is 4.7659336280822755 and perplexity is 117.44071206625397
At time: 130.53704071044922 and batch: 850, loss is 4.725259494781494 and perplexity is 112.75975514593813
At time: 130.92632365226746 and batch: 900, loss is 4.693323411941528 and perplexity is 109.21554557689457
At time: 131.3290982246399 and batch: 950, loss is 4.763243789672852 and perplexity is 117.12524000275424
At time: 131.73716974258423 and batch: 1000, loss is 4.810942583084106 and perplexity is 122.84735680219885
At time: 132.12723970413208 and batch: 1050, loss is 4.713021259307862 and perplexity is 111.3881846307836
At time: 132.51795482635498 and batch: 1100, loss is 4.820840253829956 and perplexity is 124.06929669571142
At time: 132.90865302085876 and batch: 1150, loss is 4.772256870269775 and perplexity is 118.18567092680527
At time: 133.29966020584106 and batch: 1200, loss is 4.725891046524048 and perplexity is 112.83099125806804
At time: 133.6897587776184 and batch: 1250, loss is 4.7031343555450436 and perplexity is 110.29232661712469
At time: 134.08062767982483 and batch: 1300, loss is 4.788349142074585 and perplexity is 120.10293203572627
At time: 134.47146034240723 and batch: 1350, loss is 4.734791603088379 and perplexity is 113.83973239739856
At time: 134.86643433570862 and batch: 1400, loss is 4.633776397705078 and perplexity is 102.9019298937135
At time: 135.2682499885559 and batch: 1450, loss is 4.710897912979126 and perplexity is 111.15191986261596
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0854878221821584 and perplexity of 161.65878074490644
Finished 11 epochs...
Completing Train Step...
At time: 136.5853521823883 and batch: 50, loss is 4.87083402633667 and perplexity is 130.42965331158337
At time: 136.98172402381897 and batch: 100, loss is 4.873595066070557 and perplexity is 130.790272379548
At time: 137.37078881263733 and batch: 150, loss is 4.773288478851319 and perplexity is 118.30765518833621
At time: 137.75926113128662 and batch: 200, loss is 4.803977613449097 and perplexity is 121.99470149839368
At time: 138.148255109787 and batch: 250, loss is 4.827764053344726 and perplexity is 124.93130838637175
At time: 138.53807473182678 and batch: 300, loss is 4.84994589805603 and perplexity is 127.73347902956074
At time: 138.9285306930542 and batch: 350, loss is 4.870564260482788 and perplexity is 130.39447259027824
At time: 139.33779311180115 and batch: 400, loss is 4.758031702041626 and perplexity is 116.51636113144097
At time: 139.74746966362 and batch: 450, loss is 4.7891929149627686 and perplexity is 120.20431439939931
At time: 140.15231466293335 and batch: 500, loss is 4.786291189193726 and perplexity is 119.85602001453923
At time: 140.55074000358582 and batch: 550, loss is 4.8244082736969 and perplexity is 124.51276909989528
At time: 140.94251370429993 and batch: 600, loss is 4.726624536514282 and perplexity is 112.91378202012986
At time: 141.34273648262024 and batch: 650, loss is 4.844874086380005 and perplexity is 127.08727896690854
At time: 141.73982691764832 and batch: 700, loss is 4.869648380279541 and perplexity is 130.27510154735188
At time: 142.14360356330872 and batch: 750, loss is 4.828732948303223 and perplexity is 125.05241236026669
At time: 142.53833436965942 and batch: 800, loss is 4.754422006607055 and perplexity is 116.09653074039726
At time: 142.92709136009216 and batch: 850, loss is 4.716213150024414 and perplexity is 111.74429156811422
At time: 143.32732152938843 and batch: 900, loss is 4.682735271453858 and perplexity is 108.06525649452448
At time: 143.7230339050293 and batch: 950, loss is 4.753435697555542 and perplexity is 115.98208013239218
At time: 144.12660384178162 and batch: 1000, loss is 4.80178071975708 and perplexity is 121.72698628681592
At time: 144.52005290985107 and batch: 1050, loss is 4.707659730911255 and perplexity is 110.79257184007363
At time: 144.92297554016113 and batch: 1100, loss is 4.813391160964966 and perplexity is 123.14852669127836
At time: 145.3117754459381 and batch: 1150, loss is 4.763751831054687 and perplexity is 117.1847595894594
At time: 145.7010109424591 and batch: 1200, loss is 4.718255424499512 and perplexity is 111.97273727754062
At time: 146.090017080307 and batch: 1250, loss is 4.698351802825928 and perplexity is 109.76610708988937
At time: 146.4799816608429 and batch: 1300, loss is 4.782424097061157 and perplexity is 119.39342077592916
At time: 146.87049984931946 and batch: 1350, loss is 4.727445335388183 and perplexity is 113.0064995712853
At time: 147.260596036911 and batch: 1400, loss is 4.628630151748657 and perplexity is 102.37373153814244
At time: 147.65002059936523 and batch: 1450, loss is 4.706210746765136 and perplexity is 110.63215141136628
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.084814870459402 and perplexity of 161.55002878641852
Finished 12 epochs...
Completing Train Step...
At time: 148.98919701576233 and batch: 50, loss is 4.858219938278198 and perplexity is 128.79473535710122
At time: 149.38354635238647 and batch: 100, loss is 4.860661916732788 and perplexity is 129.10963365685453
At time: 149.78203797340393 and batch: 150, loss is 4.760712890625 and perplexity is 116.8291826480222
At time: 150.17827320098877 and batch: 200, loss is 4.789383840560913 and perplexity is 120.22726667104395
At time: 150.5693016052246 and batch: 250, loss is 4.814996891021728 and perplexity is 123.34642882821527
At time: 150.96498727798462 and batch: 300, loss is 4.836808452606201 and perplexity is 126.06636222233175
At time: 151.36899161338806 and batch: 350, loss is 4.857539806365967 and perplexity is 128.70716772960202
At time: 151.76347827911377 and batch: 400, loss is 4.745500364303589 and perplexity is 115.06536570295097
At time: 152.15249752998352 and batch: 450, loss is 4.778018913269043 and perplexity is 118.86862756777161
At time: 152.54184246063232 and batch: 500, loss is 4.7754549884796145 and perplexity is 118.56424771712956
At time: 152.93083786964417 and batch: 550, loss is 4.812029790878296 and perplexity is 122.98099003639362
At time: 153.3196930885315 and batch: 600, loss is 4.715978660583496 and perplexity is 111.71809178356511
At time: 153.70821499824524 and batch: 650, loss is 4.834196882247925 and perplexity is 125.73756057876638
At time: 154.09803104400635 and batch: 700, loss is 4.8591977405548095 and perplexity is 128.92073273277052
At time: 154.48720169067383 and batch: 750, loss is 4.818053236007691 and perplexity is 123.7239947594599
At time: 154.8901391029358 and batch: 800, loss is 4.744832334518432 and perplexity is 114.98852428045856
At time: 155.2801456451416 and batch: 850, loss is 4.7079365444183345 and perplexity is 110.82324496561495
At time: 155.67039704322815 and batch: 900, loss is 4.673103094100952 and perplexity is 107.02934980592754
At time: 156.05993938446045 and batch: 950, loss is 4.744567918777466 and perplexity is 114.95812352400469
At time: 156.4597406387329 and batch: 1000, loss is 4.792613372802735 and perplexity is 120.61617215848983
At time: 156.85294699668884 and batch: 1050, loss is 4.700939712524414 and perplexity is 110.05053974726493
At time: 157.24053525924683 and batch: 1100, loss is 4.8065589427947994 and perplexity is 122.31001679261715
At time: 157.628732919693 and batch: 1150, loss is 4.756176195144653 and perplexity is 116.30036467318176
At time: 158.01931738853455 and batch: 1200, loss is 4.711194705963135 and perplexity is 111.18491386854284
At time: 158.4070484638214 and batch: 1250, loss is 4.692941160202026 and perplexity is 109.1738057226913
At time: 158.79401111602783 and batch: 1300, loss is 4.775866403579712 and perplexity is 118.61303687458191
At time: 159.18249893188477 and batch: 1350, loss is 4.71974534034729 and perplexity is 112.13969157637295
At time: 159.58353471755981 and batch: 1400, loss is 4.622656593322754 and perplexity is 101.764018961422
At time: 159.97735786437988 and batch: 1450, loss is 4.699987163543701 and perplexity is 109.94576112910737
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.083617642394498 and perplexity of 161.35673229115238
Finished 13 epochs...
Completing Train Step...
At time: 161.233136177063 and batch: 50, loss is 4.848423557281494 and perplexity is 127.53917308361848
At time: 161.6436767578125 and batch: 100, loss is 4.8491958904266355 and perplexity is 127.63771386255144
At time: 162.03832030296326 and batch: 150, loss is 4.748820381164551 and perplexity is 115.44801951426648
At time: 162.4249405860901 and batch: 200, loss is 4.775773391723633 and perplexity is 118.60200496892406
At time: 162.8112599849701 and batch: 250, loss is 4.803650817871094 and perplexity is 121.95484068292808
At time: 163.19855666160583 and batch: 300, loss is 4.826486196517944 and perplexity is 124.77176601893309
At time: 163.58686661720276 and batch: 350, loss is 4.846782188415528 and perplexity is 127.33000596288741
At time: 163.97586822509766 and batch: 400, loss is 4.734413108825684 and perplexity is 113.79665286501161
At time: 164.36304593086243 and batch: 450, loss is 4.7686847305297855 and perplexity is 117.76424833330609
At time: 164.76324772834778 and batch: 500, loss is 4.7652702903747555 and perplexity is 117.36283504578013
At time: 165.15178990364075 and batch: 550, loss is 4.8016476058959965 and perplexity is 121.7107838160839
At time: 165.55261731147766 and batch: 600, loss is 4.706696577072144 and perplexity is 110.68591292187948
At time: 165.9545476436615 and batch: 650, loss is 4.824601364135742 and perplexity is 124.53681364643359
At time: 166.3510754108429 and batch: 700, loss is 4.849751691818238 and perplexity is 127.70867479980427
At time: 166.73969912528992 and batch: 750, loss is 4.808224744796753 and perplexity is 122.51393085652387
At time: 167.1295726299286 and batch: 800, loss is 4.7360950946807865 and perplexity is 113.98821828548964
At time: 167.5185317993164 and batch: 850, loss is 4.700084962844849 and perplexity is 109.95651427352634
At time: 167.90695238113403 and batch: 900, loss is 4.664264402389526 and perplexity is 106.08751878743286
At time: 168.31025385856628 and batch: 950, loss is 4.736250371932983 and perplexity is 114.00591943706533
At time: 168.70921111106873 and batch: 1000, loss is 4.784464502334595 and perplexity is 119.63728044296533
At time: 169.11008834838867 and batch: 1050, loss is 4.6947200489044185 and perplexity is 109.36818661201359
At time: 169.51421523094177 and batch: 1100, loss is 4.799661655426025 and perplexity is 121.46931208257875
At time: 169.91119694709778 and batch: 1150, loss is 4.748475008010864 and perplexity is 115.40815375235816
At time: 170.29918599128723 and batch: 1200, loss is 4.704075584411621 and perplexity is 110.39618580866575
At time: 170.6876323223114 and batch: 1250, loss is 4.687394008636475 and perplexity is 108.56987866144478
At time: 171.07637095451355 and batch: 1300, loss is 4.769806299209595 and perplexity is 117.89640312232083
At time: 171.4659550189972 and batch: 1350, loss is 4.7125439453125 and perplexity is 111.33503017803272
At time: 171.85474848747253 and batch: 1400, loss is 4.617209587097168 and perplexity is 101.21121664223297
At time: 172.2441701889038 and batch: 1450, loss is 4.694232378005982 and perplexity is 109.31486393320421
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.083145532852564 and perplexity of 161.28057221754577
Finished 14 epochs...
Completing Train Step...
At time: 173.5183346271515 and batch: 50, loss is 4.839776344299317 and perplexity is 126.4410693015197
At time: 173.9227638244629 and batch: 100, loss is 4.840772218704224 and perplexity is 126.56705144695118
At time: 174.3131501674652 and batch: 150, loss is 4.73953800201416 and perplexity is 114.38134552013112
At time: 174.72268104553223 and batch: 200, loss is 4.764606513977051 and perplexity is 117.28495821516945
At time: 175.11304712295532 and batch: 250, loss is 4.793580379486084 and perplexity is 120.73286521547676
At time: 175.5106382369995 and batch: 300, loss is 4.816115131378174 and perplexity is 123.4844369314886
At time: 175.91225910186768 and batch: 350, loss is 4.836347398757934 and perplexity is 126.00825223783751
At time: 176.30600023269653 and batch: 400, loss is 4.723935594558716 and perplexity is 112.61057125506288
At time: 176.69606375694275 and batch: 450, loss is 4.759871044158936 and perplexity is 116.73087180060259
At time: 177.09376668930054 and batch: 500, loss is 4.757144117355347 and perplexity is 116.41298887620161
At time: 177.5059690475464 and batch: 550, loss is 4.792719936370849 and perplexity is 120.6290261330379
At time: 177.90665292739868 and batch: 600, loss is 4.698231163024903 and perplexity is 109.75286572730445
At time: 178.30118036270142 and batch: 650, loss is 4.816041336059571 and perplexity is 123.47532469434704
At time: 178.69114112854004 and batch: 700, loss is 4.841012945175171 and perplexity is 126.59752315411032
At time: 179.09575295448303 and batch: 750, loss is 4.7997174644470215 and perplexity is 121.47609135513773
At time: 179.49202632904053 and batch: 800, loss is 4.728157825469971 and perplexity is 113.08704427165014
At time: 179.88226199150085 and batch: 850, loss is 4.6932559585571285 and perplexity is 109.20817886717387
At time: 180.27183485031128 and batch: 900, loss is 4.655891056060791 and perplexity is 105.20291994617799
At time: 180.6718566417694 and batch: 950, loss is 4.727845211029052 and perplexity is 113.05169715382762
At time: 181.07766389846802 and batch: 1000, loss is 4.776610355377198 and perplexity is 118.70131208875074
At time: 181.4757342338562 and batch: 1050, loss is 4.688906784057617 and perplexity is 108.73424479854052
At time: 181.88937950134277 and batch: 1100, loss is 4.79293378829956 and perplexity is 120.65482564147398
At time: 182.28736639022827 and batch: 1150, loss is 4.7412575912475585 and perplexity is 114.57820365944869
At time: 182.67916798591614 and batch: 1200, loss is 4.69616732597351 and perplexity is 109.52658727776198
At time: 183.0697214603424 and batch: 1250, loss is 4.679059514999389 and perplexity is 107.66876408165727
At time: 183.45996236801147 and batch: 1300, loss is 4.762668285369873 and perplexity is 117.05785331566935
At time: 183.86071252822876 and batch: 1350, loss is 4.7051411151885985 and perplexity is 110.51387903404746
At time: 184.26158714294434 and batch: 1400, loss is 4.611002082824707 and perplexity is 100.58489354533538
At time: 184.65223002433777 and batch: 1450, loss is 4.687469568252563 and perplexity is 108.57808246972961
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.082890437199519 and perplexity of 161.23943549177554
Finished 15 epochs...
Completing Train Step...
At time: 185.96129035949707 and batch: 50, loss is 4.830529479980469 and perplexity is 125.27727490625222
At time: 186.35800647735596 and batch: 100, loss is 4.831145744323731 and perplexity is 125.35450261769626
At time: 186.74707627296448 and batch: 150, loss is 4.730002374649048 and perplexity is 113.29583138617853
At time: 187.1400501728058 and batch: 200, loss is 4.75392107963562 and perplexity is 116.03838942035277
At time: 187.54344844818115 and batch: 250, loss is 4.783900146484375 and perplexity is 119.56978149234827
At time: 187.93579363822937 and batch: 300, loss is 4.807383890151978 and perplexity is 122.4109577474891
At time: 188.3227024078369 and batch: 350, loss is 4.828703842163086 and perplexity is 125.04877262019768
At time: 188.70978045463562 and batch: 400, loss is 4.715695333480835 and perplexity is 111.68644350392466
At time: 189.09713673591614 and batch: 450, loss is 4.752180070877075 and perplexity is 115.83654132867757
At time: 189.48408913612366 and batch: 500, loss is 4.749208736419678 and perplexity is 115.49286306638976
At time: 189.87125205993652 and batch: 550, loss is 4.7837605285644536 and perplexity is 119.55308857351328
At time: 190.25925087928772 and batch: 600, loss is 4.690191307067871 and perplexity is 108.87400618212621
At time: 190.6487467288971 and batch: 650, loss is 4.807811489105225 and perplexity is 122.46331173734583
At time: 191.03849458694458 and batch: 700, loss is 4.83258131980896 and perplexity is 125.53458770055465
At time: 191.4287555217743 and batch: 750, loss is 4.791500482559204 and perplexity is 120.48201426263584
At time: 191.81718134880066 and batch: 800, loss is 4.721104984283447 and perplexity is 112.29226532751063
At time: 192.20650005340576 and batch: 850, loss is 4.687035331726074 and perplexity is 108.53094413567901
At time: 192.59427762031555 and batch: 900, loss is 4.650693187713623 and perplexity is 104.6575077369768
At time: 192.98365378379822 and batch: 950, loss is 4.721777477264404 and perplexity is 112.36780648536144
At time: 193.37278509140015 and batch: 1000, loss is 4.770052213668823 and perplexity is 117.92539911766072
At time: 193.76200008392334 and batch: 1050, loss is 4.683445043563843 and perplexity is 108.14198542644947
At time: 194.15705847740173 and batch: 1100, loss is 4.78724401473999 and perplexity is 119.97027631680021
At time: 194.55142521858215 and batch: 1150, loss is 4.736886510848999 and perplexity is 114.07846611151034
At time: 194.95408010482788 and batch: 1200, loss is 4.695739994049072 and perplexity is 109.47979306948504
At time: 195.34332466125488 and batch: 1250, loss is 4.676944198608399 and perplexity is 107.44125129579521
At time: 195.73319697380066 and batch: 1300, loss is 4.757203922271729 and perplexity is 116.41995115345424
At time: 196.14603185653687 and batch: 1350, loss is 4.698471021652222 and perplexity is 109.77919405643436
At time: 196.54914808273315 and batch: 1400, loss is 4.606327466964721 and perplexity is 100.11579508846584
At time: 196.94548845291138 and batch: 1450, loss is 4.681881637573242 and perplexity is 107.97304769214152
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0828633104634084 and perplexity of 161.23506165148257
Finished 16 epochs...
Completing Train Step...
At time: 198.23137545585632 and batch: 50, loss is 4.82287223815918 and perplexity is 124.32165987451413
At time: 198.63344645500183 and batch: 100, loss is 4.823175001144409 and perplexity is 124.3593055699604
At time: 199.0381064414978 and batch: 150, loss is 4.7225421524047855 and perplexity is 112.45376421424066
At time: 199.4330551624298 and batch: 200, loss is 4.744573335647583 and perplexity is 114.95874623891538
At time: 199.83531284332275 and batch: 250, loss is 4.775393104553222 and perplexity is 118.55691072297444
At time: 200.235413312912 and batch: 300, loss is 4.797658653259277 and perplexity is 121.22625229318972
At time: 200.6383728981018 and batch: 350, loss is 4.819770879745484 and perplexity is 123.93669112026615
At time: 201.03303241729736 and batch: 400, loss is 4.706913099288941 and perplexity is 110.7098814758821
At time: 201.43509483337402 and batch: 450, loss is 4.74468770980835 and perplexity is 114.97189530098134
At time: 201.84184861183167 and batch: 500, loss is 4.742045850753784 and perplexity is 114.6685566238026
At time: 202.2535960674286 and batch: 550, loss is 4.7760621929168705 and perplexity is 118.6362623160227
At time: 202.65130615234375 and batch: 600, loss is 4.682415781021118 and perplexity is 108.03073619370944
At time: 203.0417230129242 and batch: 650, loss is 4.800129451751709 and perplexity is 121.52614827329847
At time: 203.43149304389954 and batch: 700, loss is 4.8251924800872805 and perplexity is 124.6104511055279
At time: 203.83580875396729 and batch: 750, loss is 4.784049482345581 and perplexity is 119.58763888198277
At time: 204.2367925643921 and batch: 800, loss is 4.714411811828613 and perplexity is 111.54318349375774
At time: 204.6441502571106 and batch: 850, loss is 4.680656242370605 and perplexity is 107.84081907019115
At time: 205.0552053451538 and batch: 900, loss is 4.643483123779297 and perplexity is 103.90563420029834
At time: 205.45118474960327 and batch: 950, loss is 4.715341491699219 and perplexity is 111.64693116474334
At time: 205.84951949119568 and batch: 1000, loss is 4.763405513763428 and perplexity is 117.14418350744644
At time: 206.24225115776062 and batch: 1050, loss is 4.678191223144531 and perplexity is 107.57531674643361
At time: 206.6311686038971 and batch: 1100, loss is 4.781239576339722 and perplexity is 119.25208052177304
At time: 207.02122855186462 and batch: 1150, loss is 4.730363931655884 and perplexity is 113.33680169396612
At time: 207.41050744056702 and batch: 1200, loss is 4.6891912078857425 and perplexity is 108.76517580724385
At time: 207.7993700504303 and batch: 1250, loss is 4.673042831420898 and perplexity is 107.02290012480327
At time: 208.18807291984558 and batch: 1300, loss is 4.7529925346374515 and perplexity is 115.93069256268822
At time: 208.57517862319946 and batch: 1350, loss is 4.692876749038696 and perplexity is 109.16677393732469
At time: 208.96898365020752 and batch: 1400, loss is 4.60176251411438 and perplexity is 99.65981276505929
At time: 209.36942148208618 and batch: 1450, loss is 4.676176052093506 and perplexity is 107.35875236274714
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.082880003839477 and perplexity of 161.23775323146782
Annealing...
Finished 17 epochs...
Completing Train Step...
At time: 210.6688039302826 and batch: 50, loss is 4.816979646682739 and perplexity is 123.59123727570578
At time: 211.0707504749298 and batch: 100, loss is 4.807049455642701 and perplexity is 122.37002614375659
At time: 211.45969414710999 and batch: 150, loss is 4.701858997344971 and perplexity is 110.15175405320835
At time: 211.84896087646484 and batch: 200, loss is 4.722469100952148 and perplexity is 112.44554960345857
At time: 212.23754930496216 and batch: 250, loss is 4.755674905776978 and perplexity is 116.24207914709213
At time: 212.63883328437805 and batch: 300, loss is 4.76897011756897 and perplexity is 117.79786151961545
At time: 213.0383324623108 and batch: 350, loss is 4.79012315750122 and perplexity is 120.31618559156263
At time: 213.42921137809753 and batch: 400, loss is 4.6769820594787594 and perplexity is 107.44531919208848
At time: 213.81821012496948 and batch: 450, loss is 4.717136163711547 and perplexity is 111.84748069385229
At time: 214.20722770690918 and batch: 500, loss is 4.7021740055084225 and perplexity is 110.18645822071471
At time: 214.59764432907104 and batch: 550, loss is 4.739225902557373 and perplexity is 114.34565273446697
At time: 214.99994254112244 and batch: 600, loss is 4.645593729019165 and perplexity is 104.12516957104904
At time: 215.38891339302063 and batch: 650, loss is 4.762819700241089 and perplexity is 117.0755789573829
At time: 215.77830028533936 and batch: 700, loss is 4.786116685867309 and perplexity is 119.83510656514197
At time: 216.16701316833496 and batch: 750, loss is 4.740906744003296 and perplexity is 114.5380112635502
At time: 216.57021021842957 and batch: 800, loss is 4.672305459976196 and perplexity is 106.94401358223834
At time: 216.9683747291565 and batch: 850, loss is 4.6349921131134035 and perplexity is 103.02710542892811
At time: 217.35721683502197 and batch: 900, loss is 4.592259263992309 and perplexity is 98.7172066421349
At time: 217.74576663970947 and batch: 950, loss is 4.66628623008728 and perplexity is 106.302226449112
At time: 218.13495445251465 and batch: 1000, loss is 4.717766456604004 and perplexity is 111.91799958741687
At time: 218.52398347854614 and batch: 1050, loss is 4.623242998123169 and perplexity is 101.82371137089775
At time: 218.91384553909302 and batch: 1100, loss is 4.7267232131958 and perplexity is 112.92492452718106
At time: 219.30292749404907 and batch: 1150, loss is 4.672618198394775 and perplexity is 106.9774643143144
At time: 219.69248628616333 and batch: 1200, loss is 4.634292421340942 and perplexity is 102.95504342445473
At time: 220.0817482471466 and batch: 1250, loss is 4.614242286682129 and perplexity is 100.91133769258265
At time: 220.4699411392212 and batch: 1300, loss is 4.691939611434936 and perplexity is 109.06451757001408
At time: 220.85900163650513 and batch: 1350, loss is 4.627151832580567 and perplexity is 102.22250229858415
At time: 221.24783062934875 and batch: 1400, loss is 4.5327106285095216 and perplexity is 93.01033616247861
At time: 221.63639116287231 and batch: 1450, loss is 4.610103397369385 and perplexity is 100.494539970284
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.05403071998531 and perplexity of 156.65261648212154
Finished 18 epochs...
Completing Train Step...
At time: 222.89033699035645 and batch: 50, loss is 4.792625398635864 and perplexity is 120.61762267717073
At time: 223.2911353111267 and batch: 100, loss is 4.788747034072876 and perplexity is 120.15072953984617
At time: 223.692040681839 and batch: 150, loss is 4.682557888031006 and perplexity is 108.04608920946572
At time: 224.08999276161194 and batch: 200, loss is 4.708669385910034 and perplexity is 110.9044906042219
At time: 224.49467992782593 and batch: 250, loss is 4.741399612426758 and perplexity is 114.5944773466197
At time: 224.91207695007324 and batch: 300, loss is 4.757326440811157 and perplexity is 116.43421562964343
At time: 225.3159613609314 and batch: 350, loss is 4.781711187362671 and perplexity is 119.30833438138417
At time: 225.71011447906494 and batch: 400, loss is 4.670416402816772 and perplexity is 106.74218092445746
At time: 226.1001045703888 and batch: 450, loss is 4.707427520751953 and perplexity is 110.76684766614002
At time: 226.4895133972168 and batch: 500, loss is 4.692974328994751 and perplexity is 109.17742694607976
At time: 226.8790409564972 and batch: 550, loss is 4.73117811203003 and perplexity is 113.42911586866897
At time: 227.28198432922363 and batch: 600, loss is 4.637923698425293 and perplexity is 103.32958132825394
At time: 227.68736243247986 and batch: 650, loss is 4.755748634338379 and perplexity is 116.25064982430986
At time: 228.08969831466675 and batch: 700, loss is 4.779692974090576 and perplexity is 119.06778753653089
At time: 228.49516940116882 and batch: 750, loss is 4.734207706451416 and perplexity is 113.77328116271319
At time: 228.88951921463013 and batch: 800, loss is 4.667925901412964 and perplexity is 106.4766701377511
At time: 229.2785084247589 and batch: 850, loss is 4.631944599151612 and perplexity is 102.71360682500736
At time: 229.66832304000854 and batch: 900, loss is 4.5891790771484375 and perplexity is 98.41360701279879
At time: 230.07227063179016 and batch: 950, loss is 4.6652546310424805 and perplexity is 106.19262171763523
At time: 230.4685344696045 and batch: 1000, loss is 4.715636224746704 and perplexity is 111.67984205473309
At time: 230.85721254348755 and batch: 1050, loss is 4.621882810592651 and perplexity is 101.68530617822732
At time: 231.24574947357178 and batch: 1100, loss is 4.726808977127075 and perplexity is 112.93460982796624
At time: 231.63454151153564 and batch: 1150, loss is 4.67337025642395 and perplexity is 107.05794783563856
At time: 232.0240662097931 and batch: 1200, loss is 4.635092535018921 and perplexity is 103.03745212668409
At time: 232.41259360313416 and batch: 1250, loss is 4.617593994140625 and perplexity is 101.25013042567414
At time: 232.8012297153473 and batch: 1300, loss is 4.694940900802612 and perplexity is 109.39234345107252
At time: 233.19657182693481 and batch: 1350, loss is 4.630548057556152 and perplexity is 102.57026311667937
At time: 233.58576130867004 and batch: 1400, loss is 4.536604967117309 and perplexity is 93.37325611344139
At time: 233.97577452659607 and batch: 1450, loss is 4.613479557037354 and perplexity is 100.83439896928316
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.053124582665598 and perplexity of 156.51073199322013
Finished 19 epochs...
Completing Train Step...
At time: 235.25804543495178 and batch: 50, loss is 4.78726716041565 and perplexity is 119.97305314204026
At time: 235.64672565460205 and batch: 100, loss is 4.782527780532837 and perplexity is 119.40580054206838
At time: 236.0356640815735 and batch: 150, loss is 4.677117919921875 and perplexity is 107.45991775242554
At time: 236.43979501724243 and batch: 200, loss is 4.703368511199951 and perplexity is 110.31815521293285
At time: 236.83458137512207 and batch: 250, loss is 4.735911178588867 and perplexity is 113.96725594557262
At time: 237.22434496879578 and batch: 300, loss is 4.7523659324646 and perplexity is 115.8580728930257
At time: 237.6131067276001 and batch: 350, loss is 4.778432884216309 and perplexity is 118.9178459129056
At time: 238.0020399093628 and batch: 400, loss is 4.668547201156616 and perplexity is 106.5428446205785
At time: 238.40113353729248 and batch: 450, loss is 4.702883272171021 and perplexity is 110.26463752390977
At time: 238.80018877983093 and batch: 500, loss is 4.688565130233765 and perplexity is 108.69710167342804
At time: 239.19418692588806 and batch: 550, loss is 4.72732234954834 and perplexity is 112.99260222663355
At time: 239.5828619003296 and batch: 600, loss is 4.6342197513580325 and perplexity is 102.94756195505104
At time: 239.97243857383728 and batch: 650, loss is 4.75218186378479 and perplexity is 115.83674901309234
At time: 240.3611762523651 and batch: 700, loss is 4.77620680809021 and perplexity is 118.65342016027428
At time: 240.75024461746216 and batch: 750, loss is 4.7310884571075436 and perplexity is 113.41894684593639
At time: 241.13823628425598 and batch: 800, loss is 4.6657382678985595 and perplexity is 106.24399280481576
At time: 241.5264482498169 and batch: 850, loss is 4.630394124984742 and perplexity is 102.55447542747855
At time: 241.91577982902527 and batch: 900, loss is 4.587572269439697 and perplexity is 98.25560224603942
At time: 242.3045449256897 and batch: 950, loss is 4.664641456604004 and perplexity is 106.12752707566798
At time: 242.6938033103943 and batch: 1000, loss is 4.7142191410064695 and perplexity is 111.52169444711208
At time: 243.08299040794373 and batch: 1050, loss is 4.620847978591919 and perplexity is 101.58013339685533
At time: 243.47284364700317 and batch: 1100, loss is 4.7268123531341555 and perplexity is 112.9349910966522
At time: 243.8660864830017 and batch: 1150, loss is 4.673503589630127 and perplexity is 107.07222316673692
At time: 244.26895809173584 and batch: 1200, loss is 4.635098304748535 and perplexity is 103.03804662663804
At time: 244.66368770599365 and batch: 1250, loss is 4.61931116104126 and perplexity is 101.4241431600212
At time: 245.05864548683167 and batch: 1300, loss is 4.696159229278565 and perplexity is 109.52570047798643
At time: 245.44849228858948 and batch: 1350, loss is 4.6316250038146975 and perplexity is 102.68078528031414
At time: 245.8367202281952 and batch: 1400, loss is 4.537843160629272 and perplexity is 93.48894187925417
At time: 246.2250657081604 and batch: 1450, loss is 4.61400954246521 and perplexity is 100.88785389527818
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.052932608840812 and perplexity of 156.48068891321407
Finished 20 epochs...
Completing Train Step...
At time: 247.51183652877808 and batch: 50, loss is 4.783767328262329 and perplexity is 119.55390150115953
At time: 247.9002697467804 and batch: 100, loss is 4.7778708934783936 and perplexity is 118.8510339605374
At time: 248.28744673728943 and batch: 150, loss is 4.673387441635132 and perplexity is 107.05978766488971
At time: 248.67535161972046 and batch: 200, loss is 4.699391508102417 and perplexity is 109.88029083904773
At time: 249.06448101997375 and batch: 250, loss is 4.7320441627502445 and perplexity is 113.52739378684855
At time: 249.48793125152588 and batch: 300, loss is 4.74866792678833 and perplexity is 115.43042030003818
At time: 249.8709592819214 and batch: 350, loss is 4.775862293243408 and perplexity is 118.61254933611238
At time: 250.25428819656372 and batch: 400, loss is 4.667471904754638 and perplexity is 106.42834105676963
At time: 250.63731384277344 and batch: 450, loss is 4.699555854797364 and perplexity is 109.8983507856925
At time: 251.02040719985962 and batch: 500, loss is 4.685241851806641 and perplexity is 108.33647051113294
At time: 251.4040162563324 and batch: 550, loss is 4.724468231201172 and perplexity is 112.67056774838817
At time: 251.78770565986633 and batch: 600, loss is 4.631477527618408 and perplexity is 102.665643425228
At time: 252.17074251174927 and batch: 650, loss is 4.749571886062622 and perplexity is 115.53481187476133
At time: 252.55421662330627 and batch: 700, loss is 4.773560934066772 and perplexity is 118.33989311751691
At time: 252.93663883209229 and batch: 750, loss is 4.728554019927978 and perplexity is 113.1318576086747
At time: 253.31946182250977 and batch: 800, loss is 4.664105453491211 and perplexity is 106.07065763326302
At time: 253.7021882534027 and batch: 850, loss is 4.628949155807495 and perplexity is 102.40639438353462
At time: 254.08511996269226 and batch: 900, loss is 4.586320762634277 and perplexity is 98.13271160643376
At time: 254.46756410598755 and batch: 950, loss is 4.664175205230713 and perplexity is 106.07805650418209
At time: 254.86492824554443 and batch: 1000, loss is 4.713018703460693 and perplexity is 111.38789993997112
At time: 255.24707341194153 and batch: 1050, loss is 4.619666118621826 and perplexity is 101.46015081870587
At time: 255.63012146949768 and batch: 1100, loss is 4.726414823532105 and perplexity is 112.89010501694776
At time: 256.01282930374146 and batch: 1150, loss is 4.673103122711182 and perplexity is 107.02935286806186
At time: 256.39558482170105 and batch: 1200, loss is 4.634651203155517 and perplexity is 102.99198844895936
At time: 256.7785041332245 and batch: 1250, loss is 4.62020396232605 and perplexity is 101.51473519967035
At time: 257.1618068218231 and batch: 1300, loss is 4.696496648788452 and perplexity is 109.56266282171904
At time: 257.54591035842896 and batch: 1350, loss is 4.631893606185913 and perplexity is 102.70836928711765
At time: 257.92900562286377 and batch: 1400, loss is 4.5378885746002195 and perplexity is 93.49318767975318
At time: 258.3118712902069 and batch: 1450, loss is 4.613507480621338 and perplexity is 100.83721466640321
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.052845490284455 and perplexity of 156.4670571352973
Finished 21 epochs...
Completing Train Step...
At time: 259.54578471183777 and batch: 50, loss is 4.7809700012207035 and perplexity is 119.2199374606526
At time: 259.94295716285706 and batch: 100, loss is 4.774242210388183 and perplexity is 118.4205427538006
At time: 260.32674622535706 and batch: 150, loss is 4.670555219650269 and perplexity is 106.75699956452847
At time: 260.71119499206543 and batch: 200, loss is 4.696244888305664 and perplexity is 109.5350827447639
At time: 261.09666657447815 and batch: 250, loss is 4.728823699951172 and perplexity is 113.16237112491649
At time: 261.48126125335693 and batch: 300, loss is 4.745832233428955 and perplexity is 115.10355868241157
At time: 261.8659157752991 and batch: 350, loss is 4.774026165008545 and perplexity is 118.39496130616062
At time: 262.2509276866913 and batch: 400, loss is 4.666446180343628 and perplexity is 106.31923087737792
At time: 262.6354310512543 and batch: 450, loss is 4.696807250976563 and perplexity is 109.59669851003271
At time: 263.0201926231384 and batch: 500, loss is 4.682459688186645 and perplexity is 108.03547962126001
At time: 263.4047975540161 and batch: 550, loss is 4.722109069824219 and perplexity is 112.40507299226142
At time: 263.7889623641968 and batch: 600, loss is 4.629262771606445 and perplexity is 102.43851568333706
At time: 264.1736252307892 and batch: 650, loss is 4.747443647384643 and perplexity is 115.28918768563709
At time: 264.57044863700867 and batch: 700, loss is 4.771390151977539 and perplexity is 118.08328162168426
At time: 264.95483922958374 and batch: 750, loss is 4.726317586898804 and perplexity is 112.87912849687153
At time: 265.33910369873047 and batch: 800, loss is 4.662661867141724 and perplexity is 105.91764594918402
At time: 265.72391653060913 and batch: 850, loss is 4.627670307159423 and perplexity is 102.27551580930432
At time: 266.1084575653076 and batch: 900, loss is 4.584968385696411 and perplexity is 98.00008888857252
At time: 266.50176525115967 and batch: 950, loss is 4.663282012939453 and perplexity is 105.98335070338263
At time: 266.89785265922546 and batch: 1000, loss is 4.711762609481812 and perplexity is 111.24807410511536
At time: 267.28821086883545 and batch: 1050, loss is 4.618404188156128 and perplexity is 101.33219591540914
At time: 267.69107246398926 and batch: 1100, loss is 4.725738115310669 and perplexity is 112.81373719704413
At time: 268.0870397090912 and batch: 1150, loss is 4.672512445449829 and perplexity is 106.96615173060039
At time: 268.47422194480896 and batch: 1200, loss is 4.633968629837036 and perplexity is 102.92171285247885
At time: 268.865939617157 and batch: 1250, loss is 4.620559005737305 and perplexity is 101.55078373656735
At time: 269.25297117233276 and batch: 1300, loss is 4.6960729885101316 and perplexity is 109.51625530469937
At time: 269.639928817749 and batch: 1350, loss is 4.631741132736206 and perplexity is 102.69271018156793
At time: 270.0263469219208 and batch: 1400, loss is 4.537732429504395 and perplexity is 93.47859031668695
At time: 270.41310238838196 and batch: 1450, loss is 4.612637996673584 and perplexity is 100.74957643245463
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.052692641559829 and perplexity of 156.443143172824
Finished 22 epochs...
Completing Train Step...
At time: 271.6538293361664 and batch: 50, loss is 4.7785964012146 and perplexity is 118.93729259200049
At time: 272.05190539360046 and batch: 100, loss is 4.77102144241333 and perplexity is 118.03975121190952
At time: 272.4371905326843 and batch: 150, loss is 4.6679244709014895 and perplexity is 106.47651782176163
At time: 272.8226888179779 and batch: 200, loss is 4.693368768692016 and perplexity is 109.2204993514874
At time: 273.2089340686798 and batch: 250, loss is 4.725894050598145 and perplexity is 112.83133021123534
At time: 273.59462428092957 and batch: 300, loss is 4.743042583465576 and perplexity is 114.78290750436813
At time: 273.97978806495667 and batch: 350, loss is 4.772331981658936 and perplexity is 118.19454835012111
At time: 274.365514755249 and batch: 400, loss is 4.665660438537597 and perplexity is 106.23572422452303
At time: 274.7642695903778 and batch: 450, loss is 4.6943160247802735 and perplexity is 109.32400815139124
At time: 275.1487865447998 and batch: 500, loss is 4.680072841644287 and perplexity is 107.77792300660732
At time: 275.5339341163635 and batch: 550, loss is 4.719871006011963 and perplexity is 112.15378457073525
At time: 275.91932916641235 and batch: 600, loss is 4.62709080696106 and perplexity is 102.21626429739469
At time: 276.3058125972748 and batch: 650, loss is 4.745346012115479 and perplexity is 115.04760648260157
At time: 276.69706106185913 and batch: 700, loss is 4.769387226104737 and perplexity is 117.84700626178356
At time: 277.112642288208 and batch: 750, loss is 4.724249839782715 and perplexity is 112.6459641499844
At time: 277.498507976532 and batch: 800, loss is 4.6611497116088865 and perplexity is 105.75760303022592
At time: 277.8828327655792 and batch: 850, loss is 4.626442136764527 and perplexity is 102.14998115341824
At time: 278.2683641910553 and batch: 900, loss is 4.58355544090271 and perplexity is 97.86171795146329
At time: 278.6574833393097 and batch: 950, loss is 4.662381629943848 and perplexity is 105.88796804349842
At time: 279.04652094841003 and batch: 1000, loss is 4.710406179428101 and perplexity is 111.09727617052806
At time: 279.43549275398254 and batch: 1050, loss is 4.617148952484131 and perplexity is 101.20507992532745
At time: 279.8237042427063 and batch: 1100, loss is 4.724919118881226 and perplexity is 112.7213809739584
At time: 280.21104311943054 and batch: 1150, loss is 4.671687631607056 and perplexity is 106.87796094343564
At time: 280.5972466468811 and batch: 1200, loss is 4.633012962341309 and perplexity is 102.82340090115166
At time: 280.98522305488586 and batch: 1250, loss is 4.6207473087310795 and perplexity is 101.56990785367286
At time: 281.37993574142456 and batch: 1300, loss is 4.695699987411499 and perplexity is 109.47541323869383
At time: 281.7746739387512 and batch: 1350, loss is 4.631144199371338 and perplexity is 102.6314277691099
At time: 282.1841948032379 and batch: 1400, loss is 4.537044620513916 and perplexity is 93.41431700826338
At time: 282.58638978004456 and batch: 1450, loss is 4.611431455612182 and perplexity is 100.62809123474732
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.052730201655983 and perplexity of 156.44901930267756
Annealing...
Finished 23 epochs...
Completing Train Step...
At time: 283.8748471736908 and batch: 50, loss is 4.7770405197143555 and perplexity is 118.75238414388599
At time: 284.2630376815796 and batch: 100, loss is 4.76808650970459 and perplexity is 117.6938203753255
At time: 284.66507363319397 and batch: 150, loss is 4.664200963973999 and perplexity is 106.08078897680032
At time: 285.06739258766174 and batch: 200, loss is 4.688628263473511 and perplexity is 108.70396429023505
At time: 285.46037340164185 and batch: 250, loss is 4.722012577056884 and perplexity is 112.39422723898274
At time: 285.84953212738037 and batch: 300, loss is 4.738871793746949 and perplexity is 114.30516909962887
At time: 286.2387161254883 and batch: 350, loss is 4.766260643005371 and perplexity is 117.47912321184516
At time: 286.62704277038574 and batch: 400, loss is 4.6588303756713865 and perplexity is 105.51259985302009
At time: 287.0148298740387 and batch: 450, loss is 4.688315591812134 and perplexity is 108.66998095421205
At time: 287.40400433540344 and batch: 500, loss is 4.6700405025482175 and perplexity is 106.70206405042607
At time: 287.79555583000183 and batch: 550, loss is 4.709545907974243 and perplexity is 111.00174345316374
At time: 288.18757462501526 and batch: 600, loss is 4.6177818393707275 and perplexity is 101.26915156618116
At time: 288.57698702812195 and batch: 650, loss is 4.736307764053345 and perplexity is 114.01246266627874
At time: 288.9653351306915 and batch: 700, loss is 4.75881293296814 and perplexity is 116.6074228816981
At time: 289.35376381874084 and batch: 750, loss is 4.713886165618897 and perplexity is 111.48456664934525
At time: 289.7410509586334 and batch: 800, loss is 4.648781185150146 and perplexity is 104.45759349307315
At time: 290.1301078796387 and batch: 850, loss is 4.613845643997192 and perplexity is 100.87131988556958
At time: 290.5174403190613 and batch: 900, loss is 4.569786491394043 and perplexity is 96.52349897492338
At time: 290.9051694869995 and batch: 950, loss is 4.645558795928955 and perplexity is 104.12153222063961
At time: 291.2925624847412 and batch: 1000, loss is 4.693789710998535 and perplexity is 109.26648455828408
At time: 291.68024253845215 and batch: 1050, loss is 4.601244382858276 and perplexity is 99.6081892761147
At time: 292.0692095756531 and batch: 1100, loss is 4.710973796844482 and perplexity is 111.16035481997139
At time: 292.4610619544983 and batch: 1150, loss is 4.652604093551636 and perplexity is 104.85768958291764
At time: 292.85055136680603 and batch: 1200, loss is 4.617679824829102 and perplexity is 101.25882116703774
At time: 293.24067854881287 and batch: 1250, loss is 4.602782917022705 and perplexity is 99.76155782949944
At time: 293.65863966941833 and batch: 1300, loss is 4.6728807640075685 and perplexity is 107.00555660566062
At time: 294.05496191978455 and batch: 1350, loss is 4.610845441818237 and perplexity is 100.5691390603062
At time: 294.44278264045715 and batch: 1400, loss is 4.514051465988159 and perplexity is 91.29093238706713
At time: 294.8299288749695 and batch: 1450, loss is 4.588686819076538 and perplexity is 98.3651740421004
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.044985518496261 and perplexity of 155.24205104373914
Finished 24 epochs...
Completing Train Step...
At time: 296.11918807029724 and batch: 50, loss is 4.770033960342407 and perplexity is 117.92324660650323
At time: 296.5317895412445 and batch: 100, loss is 4.763638324737549 and perplexity is 117.17145913383082
At time: 296.93205857276917 and batch: 150, loss is 4.659445009231567 and perplexity is 105.57747137197579
At time: 297.3650221824646 and batch: 200, loss is 4.6846207332611085 and perplexity is 108.2692016132836
At time: 297.7626187801361 and batch: 250, loss is 4.717409582138061 and perplexity is 111.87806603714083
At time: 298.15903520584106 and batch: 300, loss is 4.736065273284912 and perplexity is 113.98481904839237
At time: 298.5587270259857 and batch: 350, loss is 4.763495969772339 and perplexity is 117.15478038202191
At time: 298.9643905162811 and batch: 400, loss is 4.6561307621002195 and perplexity is 105.22814074412261
At time: 299.3719959259033 and batch: 450, loss is 4.684874477386475 and perplexity is 108.29667777296072
At time: 299.7750635147095 and batch: 500, loss is 4.666582183837891 and perplexity is 106.33369164761994
At time: 300.1815104484558 and batch: 550, loss is 4.707348308563232 and perplexity is 110.75807392919678
At time: 300.59298300743103 and batch: 600, loss is 4.616229295730591 and perplexity is 101.11204877500131
At time: 300.99892473220825 and batch: 650, loss is 4.734790410995483 and perplexity is 113.83959668994324
At time: 301.41693568229675 and batch: 700, loss is 4.757255487442016 and perplexity is 116.42595452284138
At time: 301.81544160842896 and batch: 750, loss is 4.71164686203003 and perplexity is 111.23519816921475
At time: 302.22976422309875 and batch: 800, loss is 4.647450923919678 and perplexity is 104.3187299890668
At time: 302.633337020874 and batch: 850, loss is 4.613271856307984 and perplexity is 100.81345776589852
At time: 303.0333445072174 and batch: 900, loss is 4.5693286037445064 and perplexity is 96.47931217391994
At time: 303.4317741394043 and batch: 950, loss is 4.644551000595093 and perplexity is 104.01665188414675
At time: 303.83264327049255 and batch: 1000, loss is 4.693012361526489 and perplexity is 109.18157931899731
At time: 304.2242512702942 and batch: 1050, loss is 4.601608209609985 and perplexity is 99.64443599342552
At time: 304.63995885849 and batch: 1100, loss is 4.711244945526123 and perplexity is 111.19049989034491
At time: 305.0423936843872 and batch: 1150, loss is 4.653526296615601 and perplexity is 104.95443426779725
At time: 305.43731927871704 and batch: 1200, loss is 4.618896255493164 and perplexity is 101.38207044901736
At time: 305.83394479751587 and batch: 1250, loss is 4.603543300628662 and perplexity is 99.83744373011871
At time: 306.2361478805542 and batch: 1300, loss is 4.673354024887085 and perplexity is 107.0562101347144
At time: 306.6586067676544 and batch: 1350, loss is 4.612184476852417 and perplexity is 100.70389486210014
At time: 307.0693144798279 and batch: 1400, loss is 4.5154221153259275 and perplexity is 91.41614603548682
At time: 307.48352432250977 and batch: 1450, loss is 4.590627412796021 and perplexity is 98.55624621783114
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.044717381143163 and perplexity of 155.20043043135254
Finished 25 epochs...
Completing Train Step...
At time: 308.814341545105 and batch: 50, loss is 4.767551355361938 and perplexity is 117.63085286641906
At time: 309.2227416038513 and batch: 100, loss is 4.761838064193726 and perplexity is 116.96070973791986
At time: 309.6081700325012 and batch: 150, loss is 4.657453508377075 and perplexity is 105.36742297272896
At time: 309.99618792533875 and batch: 200, loss is 4.683075656890869 and perplexity is 108.10204659513415
At time: 310.3803722858429 and batch: 250, loss is 4.715383243560791 and perplexity is 111.65159272927214
At time: 310.76579666137695 and batch: 300, loss is 4.734732275009155 and perplexity is 113.83297870507988
At time: 311.1499996185303 and batch: 350, loss is 4.762164688110351 and perplexity is 116.99891814257543
At time: 311.5368504524231 and batch: 400, loss is 4.655120897293091 and perplexity is 105.12192818725369
At time: 311.94064259529114 and batch: 450, loss is 4.683156852722168 and perplexity is 108.11082438702776
At time: 312.33617067337036 and batch: 500, loss is 4.664684457778931 and perplexity is 106.13209078214597
At time: 312.73514914512634 and batch: 550, loss is 4.7061957740783695 and perplexity is 110.63049496321761
At time: 313.13103318214417 and batch: 600, loss is 4.61557827949524 and perplexity is 101.04624461177256
At time: 313.52424025535583 and batch: 650, loss is 4.73406231880188 and perplexity is 113.75674113517191
At time: 313.92321944236755 and batch: 700, loss is 4.756552877426148 and perplexity is 116.34418121182428
At time: 314.3185315132141 and batch: 750, loss is 4.710597505569458 and perplexity is 111.11853401721915
At time: 314.7397017478943 and batch: 800, loss is 4.646728992462158 and perplexity is 104.24344619441874
At time: 315.1241285800934 and batch: 850, loss is 4.613084182739258 and perplexity is 100.79453951978694
At time: 315.5432040691376 and batch: 900, loss is 4.569196319580078 and perplexity is 96.4665503328377
At time: 315.9379451274872 and batch: 950, loss is 4.643788747787475 and perplexity is 103.93739510989599
At time: 316.3672957420349 and batch: 1000, loss is 4.692548513412476 and perplexity is 109.13094739301467
At time: 316.76507806777954 and batch: 1050, loss is 4.601874971389771 and perplexity is 99.67102086627322
At time: 317.16927194595337 and batch: 1100, loss is 4.711514148712158 and perplexity is 111.22043675654135
At time: 317.57135820388794 and batch: 1150, loss is 4.654096612930298 and perplexity is 105.0143085659816
At time: 317.9830038547516 and batch: 1200, loss is 4.619750928878784 and perplexity is 101.46875604506843
At time: 318.3763065338135 and batch: 1250, loss is 4.603824167251587 and perplexity is 99.86548867404068
At time: 318.7645015716553 and batch: 1300, loss is 4.673557424545288 and perplexity is 107.07798754594828
At time: 319.15351486206055 and batch: 1350, loss is 4.612954187393188 and perplexity is 100.78143755035609
At time: 319.5495092868805 and batch: 1400, loss is 4.515947303771973 and perplexity is 91.46416934870741
At time: 319.94698452949524 and batch: 1450, loss is 4.591473007202149 and perplexity is 98.63962007358703
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.044620350894765 and perplexity of 155.1853720256086
Finished 26 epochs...
Completing Train Step...
At time: 321.2332673072815 and batch: 50, loss is 4.765681972503662 and perplexity is 117.41116117438554
At time: 321.6354398727417 and batch: 100, loss is 4.760505027770996 and perplexity is 116.80490072442844
At time: 322.0210950374603 and batch: 150, loss is 4.656006059646606 and perplexity is 105.21501935493438
At time: 322.4152801036835 and batch: 200, loss is 4.681946754455566 and perplexity is 107.98007878930139
At time: 322.8097264766693 and batch: 250, loss is 4.713989238739014 and perplexity is 111.49605830370488
At time: 323.2003450393677 and batch: 300, loss is 4.7337453651428225 and perplexity is 113.72069123320264
At time: 323.5882890224457 and batch: 350, loss is 4.761218061447144 and perplexity is 116.88821625204255
At time: 323.9728636741638 and batch: 400, loss is 4.654427328109741 and perplexity is 105.04904413535658
At time: 324.3603718280792 and batch: 450, loss is 4.681885976791381 and perplexity is 107.97351621176514
At time: 324.74624824523926 and batch: 500, loss is 4.663187999725341 and perplexity is 105.97338733629213
At time: 325.1430516242981 and batch: 550, loss is 4.705356016159057 and perplexity is 110.53763112598344
At time: 325.52952766418457 and batch: 600, loss is 4.615141363143921 and perplexity is 101.00210549851464
At time: 325.91720175743103 and batch: 650, loss is 4.733587522506713 and perplexity is 113.70274267607931
At time: 326.31204557418823 and batch: 700, loss is 4.756018133163452 and perplexity is 116.28198345985084
At time: 326.6984214782715 and batch: 750, loss is 4.709825534820556 and perplexity is 111.03278686070364
At time: 327.0874080657959 and batch: 800, loss is 4.646129455566406 and perplexity is 104.18096713340745
At time: 327.4911758899689 and batch: 850, loss is 4.612956895828247 and perplexity is 100.78171051070444
At time: 327.88733959198 and batch: 900, loss is 4.5690913581848145 and perplexity is 96.45642560048084
At time: 328.2960844039917 and batch: 950, loss is 4.6430620765686035 and perplexity is 103.86189423178503
At time: 328.68923234939575 and batch: 1000, loss is 4.692146100997925 and perplexity is 109.08704057988788
At time: 329.0894832611084 and batch: 1050, loss is 4.602005968093872 and perplexity is 99.68407829672259
At time: 329.48097348213196 and batch: 1100, loss is 4.711676692962646 and perplexity is 111.23851646840967
At time: 329.87172627449036 and batch: 1150, loss is 4.654492120742798 and perplexity is 105.05585076003342
At time: 330.27889037132263 and batch: 1200, loss is 4.620341491699219 and perplexity is 101.52869741765531
At time: 330.67532324790955 and batch: 1250, loss is 4.6039458274841305 and perplexity is 99.87763907171093
At time: 331.0858066082001 and batch: 1300, loss is 4.673597364425659 and perplexity is 107.08226431336745
At time: 331.4865822792053 and batch: 1350, loss is 4.613464317321777 and perplexity is 100.8328622934318
At time: 331.88976097106934 and batch: 1400, loss is 4.516387672424316 and perplexity is 91.50445617157712
At time: 332.28421807289124 and batch: 1450, loss is 4.5919023132324215 and perplexity is 98.68197574843121
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.044603135850695 and perplexity of 155.18270052558518
Finished 27 epochs...
Completing Train Step...
At time: 333.5749328136444 and batch: 50, loss is 4.764237031936646 and perplexity is 117.24163153420744
At time: 333.96919441223145 and batch: 100, loss is 4.759407625198365 and perplexity is 116.67678903378389
At time: 334.3549416065216 and batch: 150, loss is 4.654828624725342 and perplexity is 105.09120842086688
At time: 334.74708127975464 and batch: 200, loss is 4.6810869789123535 and perplexity is 107.88728005716082
At time: 335.1453676223755 and batch: 250, loss is 4.712937107086182 and perplexity is 111.37881146197006
At time: 335.5376205444336 and batch: 300, loss is 4.732932376861572 and perplexity is 113.62827521555423
At time: 335.93364691734314 and batch: 350, loss is 4.760413246154785 and perplexity is 116.79418067381788
At time: 336.3261206150055 and batch: 400, loss is 4.65387454032898 and perplexity is 104.99099035456652
At time: 336.72321248054504 and batch: 450, loss is 4.680851545333862 and perplexity is 107.86188275854903
At time: 337.10879945755005 and batch: 500, loss is 4.661963834762573 and perplexity is 105.84373780092932
At time: 337.4991126060486 and batch: 550, loss is 4.704637050628662 and perplexity is 110.45818694162952
At time: 337.88517928123474 and batch: 600, loss is 4.614817714691162 and perplexity is 100.9694216126745
At time: 338.2721743583679 and batch: 650, loss is 4.733192377090454 and perplexity is 113.65782243409305
At time: 338.6806480884552 and batch: 700, loss is 4.7555940723419186 and perplexity is 116.23268328029144
At time: 339.0840094089508 and batch: 750, loss is 4.709201126098633 and perplexity is 110.96347866074252
At time: 339.48883509635925 and batch: 800, loss is 4.645583381652832 and perplexity is 104.12409215534926
At time: 339.89374828338623 and batch: 850, loss is 4.612845792770385 and perplexity is 100.77051397648631
At time: 340.2887353897095 and batch: 900, loss is 4.569045352935791 and perplexity is 96.45198820067378
At time: 340.6752419471741 and batch: 950, loss is 4.642440519332886 and perplexity is 103.79735817841309
At time: 341.0631923675537 and batch: 1000, loss is 4.691745357513428 and perplexity is 109.04333341739766
At time: 341.46229457855225 and batch: 1050, loss is 4.602034950256348 and perplexity is 99.68696739874208
At time: 341.854355096817 and batch: 1100, loss is 4.7117381763458255 and perplexity is 111.24535599899858
At time: 342.2502164840698 and batch: 1150, loss is 4.654767923355102 and perplexity is 105.08482943412416
At time: 342.64675998687744 and batch: 1200, loss is 4.620782098770142 and perplexity is 101.57344153620274
At time: 343.04596638679504 and batch: 1250, loss is 4.603962831497192 and perplexity is 99.87933740682948
At time: 343.43811988830566 and batch: 1300, loss is 4.673516883850097 and perplexity is 107.07364661788621
At time: 343.83968329429626 and batch: 1350, loss is 4.613767395019531 and perplexity is 100.86342711671779
At time: 344.2451455593109 and batch: 1400, loss is 4.516358432769775 and perplexity is 91.50178065200552
At time: 344.6517369747162 and batch: 1450, loss is 4.592075796127319 and perplexity is 98.69909686832605
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.044595832498665 and perplexity of 155.18156717583292
Finished 28 epochs...
Completing Train Step...
At time: 345.99666929244995 and batch: 50, loss is 4.7629516983032225 and perplexity is 117.09103372690586
At time: 346.38825702667236 and batch: 100, loss is 4.758399257659912 and perplexity is 116.55919524607461
At time: 346.7807650566101 and batch: 150, loss is 4.65387921333313 and perplexity is 104.99148097904649
At time: 347.1796119213104 and batch: 200, loss is 4.680309495925903 and perplexity is 107.80343213185337
At time: 347.5688829421997 and batch: 250, loss is 4.712035512924194 and perplexity is 111.27843823054575
At time: 347.9695780277252 and batch: 300, loss is 4.732199659347534 and perplexity is 113.54504828285305
At time: 348.37435150146484 and batch: 350, loss is 4.759662132263184 and perplexity is 116.70648788001621
At time: 348.778701543808 and batch: 400, loss is 4.6535444259643555 and perplexity is 104.9563370405874
At time: 349.1743094921112 and batch: 450, loss is 4.679991817474365 and perplexity is 107.76919074362677
At time: 349.5687379837036 and batch: 500, loss is 4.66087664604187 and perplexity is 105.72872821292675
At time: 349.9559097290039 and batch: 550, loss is 4.704008979797363 and perplexity is 110.3888331581574
At time: 350.3447093963623 and batch: 600, loss is 4.614523544311523 and perplexity is 100.93972376791409
At time: 350.7452161312103 and batch: 650, loss is 4.732871103286743 and perplexity is 113.62131301823165
At time: 351.14652705192566 and batch: 700, loss is 4.755188674926758 and perplexity is 116.18557240089197
At time: 351.5715639591217 and batch: 750, loss is 4.708632211685181 and perplexity is 110.90036789238076
At time: 351.9746403694153 and batch: 800, loss is 4.645100421905518 and perplexity is 104.07381655163624
At time: 352.38509130477905 and batch: 850, loss is 4.6127525997161865 and perplexity is 100.76112330209526
At time: 352.78126859664917 and batch: 900, loss is 4.5689990425109865 and perplexity is 96.44752157155354
At time: 353.1715247631073 and batch: 950, loss is 4.641842670440674 and perplexity is 103.73532158891256
At time: 353.5695197582245 and batch: 1000, loss is 4.691349067687988 and perplexity is 109.00012921509065
At time: 353.96404457092285 and batch: 1050, loss is 4.602056188583374 and perplexity is 99.68908460563881
At time: 354.3585293292999 and batch: 1100, loss is 4.711763191223144 and perplexity is 111.24813882273705
At time: 354.74693870544434 and batch: 1150, loss is 4.654963731765747 and perplexity is 105.10540794221528
At time: 355.1679754257202 and batch: 1200, loss is 4.621149377822876 and perplexity is 101.6107541852509
At time: 355.56368470191956 and batch: 1250, loss is 4.603928546905518 and perplexity is 99.87591314322988
At time: 355.95334577560425 and batch: 1300, loss is 4.673429870605469 and perplexity is 107.06433019781166
At time: 356.34950947761536 and batch: 1350, loss is 4.613925294876099 and perplexity is 100.8793546948405
At time: 356.7448568344116 and batch: 1400, loss is 4.516254720687866 and perplexity is 91.49229130392423
At time: 357.156672000885 and batch: 1450, loss is 4.592118663787842 and perplexity is 98.70332795839231
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.044588007478633 and perplexity of 155.18035288171214
Finished 29 epochs...
Completing Train Step...
At time: 358.5005295276642 and batch: 50, loss is 4.761782255172729 and perplexity is 116.95418245735658
At time: 358.92201352119446 and batch: 100, loss is 4.757487964630127 and perplexity is 116.45302404777357
At time: 359.31741404533386 and batch: 150, loss is 4.652947912216186 and perplexity is 104.89374781210877
At time: 359.70869636535645 and batch: 200, loss is 4.67957275390625 and perplexity is 107.72403806360325
At time: 360.1072175502777 and batch: 250, loss is 4.711209602355957 and perplexity is 111.1865701350319
At time: 360.505184173584 and batch: 300, loss is 4.731167163848877 and perplexity is 113.42787403295837
At time: 360.90159344673157 and batch: 350, loss is 4.758982353210449 and perplexity is 116.62718021313644
At time: 361.28986620903015 and batch: 400, loss is 4.653196315765381 and perplexity is 104.9198070278205
At time: 361.6851716041565 and batch: 450, loss is 4.679090223312378 and perplexity is 107.67207045853014
At time: 362.0882787704468 and batch: 500, loss is 4.659852113723755 and perplexity is 105.62046118492435
At time: 362.48219656944275 and batch: 550, loss is 4.703511133193969 and perplexity is 110.33389013025172
At time: 362.87893629074097 and batch: 600, loss is 4.614304752349853 and perplexity is 100.91764138355268
At time: 363.27151703834534 and batch: 650, loss is 4.732524642944336 and perplexity is 113.58195455768514
At time: 363.66486644744873 and batch: 700, loss is 4.754797630310058 and perplexity is 116.1401475404189
At time: 364.06564354896545 and batch: 750, loss is 4.707849140167236 and perplexity is 110.81355896618939
At time: 364.46072459220886 and batch: 800, loss is 4.644614505767822 and perplexity is 104.02325768934055
At time: 364.85741901397705 and batch: 850, loss is 4.612639989852905 and perplexity is 100.74977724462711
At time: 365.2747974395752 and batch: 900, loss is 4.5689795875549315 and perplexity is 96.4456452075121
At time: 365.67913818359375 and batch: 950, loss is 4.641264905929566 and perplexity is 103.67540431225486
At time: 366.0761675834656 and batch: 1000, loss is 4.69096962928772 and perplexity is 108.9587782260049
At time: 366.4744863510132 and batch: 1050, loss is 4.602017993927002 and perplexity is 99.68527708802215
At time: 366.88146448135376 and batch: 1100, loss is 4.711773548126221 and perplexity is 111.24929101489484
At time: 367.28042340278625 and batch: 1150, loss is 4.655052671432495 and perplexity is 105.11475639788915
At time: 367.6865472793579 and batch: 1200, loss is 4.621434259414673 and perplexity is 101.63970534227688
At time: 368.0810754299164 and batch: 1250, loss is 4.603875646591186 and perplexity is 99.87062981577652
At time: 368.4784893989563 and batch: 1300, loss is 4.673331289291382 and perplexity is 107.05377617567214
At time: 368.88491773605347 and batch: 1350, loss is 4.614025897979737 and perplexity is 100.8895039815321
At time: 369.2881896495819 and batch: 1400, loss is 4.516037158966064 and perplexity is 91.47238824864657
At time: 369.6895442008972 and batch: 1450, loss is 4.5920742416381835 and perplexity is 98.69894344177152
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0445984408386755 and perplexity of 155.1819719426514
Annealing...
Finished 30 epochs...
Completing Train Step...
At time: 370.94700145721436 and batch: 50, loss is 4.760469913482666 and perplexity is 116.80079927547615
At time: 371.36562991142273 and batch: 100, loss is 4.756792850494385 and perplexity is 116.37210403218967
At time: 371.7720260620117 and batch: 150, loss is 4.652183618545532 and perplexity is 104.81360881333062
At time: 372.1689782142639 and batch: 200, loss is 4.678302240371704 and perplexity is 107.58726012275905
At time: 372.56391406059265 and batch: 250, loss is 4.710780668258667 and perplexity is 111.13888865077847
At time: 372.95115661621094 and batch: 300, loss is 4.730371475219727 and perplexity is 113.3376566605902
At time: 373.33803939819336 and batch: 350, loss is 4.756798372268677 and perplexity is 116.37274661445612
At time: 373.7264561653137 and batch: 400, loss is 4.6507639503479 and perplexity is 104.66491383995577
At time: 374.1313970088959 and batch: 450, loss is 4.676890211105347 and perplexity is 107.435450967487
At time: 374.53232288360596 and batch: 500, loss is 4.656401195526123 and perplexity is 105.25660179896234
At time: 374.93874979019165 and batch: 550, loss is 4.7005527973175045 and perplexity is 110.0079677563146
At time: 375.32835841178894 and batch: 600, loss is 4.611542749404907 and perplexity is 100.63929113990389
At time: 375.7460904121399 and batch: 650, loss is 4.7305696582794186 and perplexity is 113.36012049006722
At time: 376.1326518058777 and batch: 700, loss is 4.751655759811402 and perplexity is 115.7758228673212
At time: 376.51996660232544 and batch: 750, loss is 4.705055475234985 and perplexity is 110.50441503582735
At time: 376.92092990875244 and batch: 800, loss is 4.640398874282837 and perplexity is 103.58565699874914
At time: 377.316104888916 and batch: 850, loss is 4.6088059139251705 and perplexity is 100.36423452130033
At time: 377.71299839019775 and batch: 900, loss is 4.565344152450561 and perplexity is 96.09565988318984
At time: 378.10812735557556 and batch: 950, loss is 4.635270252227783 and perplexity is 103.05576528231754
At time: 378.49682998657227 and batch: 1000, loss is 4.686873779296875 and perplexity is 108.51341211421912
At time: 378.89747858047485 and batch: 1050, loss is 4.596503286361695 and perplexity is 99.13705496802822
At time: 379.2908561229706 and batch: 1100, loss is 4.708268156051636 and perplexity is 110.86000133696909
At time: 379.70473885536194 and batch: 1150, loss is 4.64940333366394 and perplexity is 104.52260184994879
At time: 380.10972023010254 and batch: 1200, loss is 4.616610145568847 and perplexity is 101.15056461633347
At time: 380.5103669166565 and batch: 1250, loss is 4.598350467681885 and perplexity is 99.3203483200142
At time: 380.9048218727112 and batch: 1300, loss is 4.666623392105103 and perplexity is 106.33807356508397
At time: 381.2901020050049 and batch: 1350, loss is 4.609097213745117 and perplexity is 100.39347486339187
At time: 381.6865828037262 and batch: 1400, loss is 4.50879207611084 and perplexity is 90.81205817831426
At time: 382.0791780948639 and batch: 1450, loss is 4.584997835159302 and perplexity is 98.00297498105033
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.043084038628472 and perplexity of 154.94714187982106
Finished 31 epochs...
Completing Train Step...
At time: 383.414635181427 and batch: 50, loss is 4.75916335105896 and perplexity is 116.64829139231426
At time: 383.810977935791 and batch: 100, loss is 4.755977697372437 and perplexity is 116.27728160093116
At time: 384.21989846229553 and batch: 150, loss is 4.651235103607178 and perplexity is 104.7142386741092
At time: 384.6341631412506 and batch: 200, loss is 4.67812481880188 and perplexity is 107.56817351541297
At time: 385.03919100761414 and batch: 250, loss is 4.710254764556884 and perplexity is 111.08045566423375
At time: 385.4427032470703 and batch: 300, loss is 4.729769639968872 and perplexity is 113.26946658521638
At time: 385.85298228263855 and batch: 350, loss is 4.756168518066406 and perplexity is 116.29947182960923
At time: 386.25737619400024 and batch: 400, loss is 4.650017004013062 and perplexity is 104.58676395669478
At time: 386.6636962890625 and batch: 450, loss is 4.676054725646972 and perplexity is 107.34572769695285
At time: 387.06947231292725 and batch: 500, loss is 4.655597734451294 and perplexity is 105.1720661816347
At time: 387.4662847518921 and batch: 550, loss is 4.6999761009216305 and perplexity is 109.94454484743136
At time: 387.8562948703766 and batch: 600, loss is 4.611132869720459 and perplexity is 100.59804959162216
At time: 388.25225043296814 and batch: 650, loss is 4.730310888290405 and perplexity is 113.33079008801101
At time: 388.6394259929657 and batch: 700, loss is 4.751092433929443 and perplexity is 115.71062171626718
At time: 389.0363085269928 and batch: 750, loss is 4.70460786819458 and perplexity is 110.45496354990375
At time: 389.4391829967499 and batch: 800, loss is 4.6401025009155275 and perplexity is 103.55496151766573
At time: 389.83676266670227 and batch: 850, loss is 4.608575601577758 and perplexity is 100.34112206049623
At time: 390.2254967689514 and batch: 900, loss is 4.565119466781616 and perplexity is 96.07407099101444
At time: 390.6139488220215 and batch: 950, loss is 4.635174827575684 and perplexity is 103.04593169095963
At time: 391.012731552124 and batch: 1000, loss is 4.686921081542969 and perplexity is 108.5185451637448
At time: 391.40049958229065 and batch: 1050, loss is 4.596685476303101 and perplexity is 99.15511838770075
At time: 391.79626631736755 and batch: 1100, loss is 4.708366775512696 and perplexity is 110.87093482967275
At time: 392.20066142082214 and batch: 1150, loss is 4.649340763092041 and perplexity is 104.5160620155773
At time: 392.60094809532166 and batch: 1200, loss is 4.616828556060791 and perplexity is 101.1726593736873
At time: 392.99084663391113 and batch: 1250, loss is 4.5987049579620365 and perplexity is 99.35556265931665
At time: 393.3795030117035 and batch: 1300, loss is 4.666716651916504 and perplexity is 106.3479910962158
At time: 393.7727906703949 and batch: 1350, loss is 4.609561738967895 and perplexity is 100.44012099798252
At time: 394.1624183654785 and batch: 1400, loss is 4.509146270751953 and perplexity is 90.84422901970291
At time: 394.55420756340027 and batch: 1450, loss is 4.585341567993164 and perplexity is 98.03666761166743
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042969271668002 and perplexity of 154.9293600877146
Finished 32 epochs...
Completing Train Step...
At time: 395.826801776886 and batch: 50, loss is 4.758525409698486 and perplexity is 116.57390035368965
At time: 396.21952295303345 and batch: 100, loss is 4.755521554946899 and perplexity is 116.22425469449706
At time: 396.6228840351105 and batch: 150, loss is 4.650805807113647 and perplexity is 104.66929486642344
At time: 397.01711106300354 and batch: 200, loss is 4.677955408096313 and perplexity is 107.54995185875661
At time: 397.41705322265625 and batch: 250, loss is 4.7099230670928955 and perplexity is 111.04361666882964
At time: 397.80624198913574 and batch: 300, loss is 4.729399709701538 and perplexity is 113.22757253057897
At time: 398.2085030078888 and batch: 350, loss is 4.755784482955932 and perplexity is 116.25481732409487
At time: 398.6031184196472 and batch: 400, loss is 4.649672327041626 and perplexity is 104.55072151949773
At time: 398.99058294296265 and batch: 450, loss is 4.67554084777832 and perplexity is 107.29057927418559
At time: 399.38628029823303 and batch: 500, loss is 4.655124702453613 and perplexity is 105.12232819382594
At time: 399.7801957130432 and batch: 550, loss is 4.699626245498657 and perplexity is 109.90608687994666
At time: 400.172114610672 and batch: 600, loss is 4.610885982513428 and perplexity is 100.5732162857646
At time: 400.5752286911011 and batch: 650, loss is 4.730189027786255 and perplexity is 113.31698038224114
At time: 400.9705843925476 and batch: 700, loss is 4.75076696395874 and perplexity is 115.67296751159596
At time: 401.3749556541443 and batch: 750, loss is 4.704337062835694 and perplexity is 110.42505580363057
At time: 401.76190185546875 and batch: 800, loss is 4.63987211227417 and perplexity is 103.53110637885787
At time: 402.1526815891266 and batch: 850, loss is 4.608394451141358 and perplexity is 100.32294686871771
At time: 402.55345273017883 and batch: 900, loss is 4.564949035644531 and perplexity is 96.05769837309263
At time: 402.95739817619324 and batch: 950, loss is 4.6350993728637695 and perplexity is 103.03815668320414
At time: 403.3447382450104 and batch: 1000, loss is 4.686993370056152 and perplexity is 108.52639009157319
At time: 403.74151515960693 and batch: 1050, loss is 4.5968101215362545 and perplexity is 99.16747837084105
At time: 404.1443452835083 and batch: 1100, loss is 4.708481178283692 and perplexity is 110.88361949740691
At time: 404.54050493240356 and batch: 1150, loss is 4.649270286560059 and perplexity is 104.50869634554654
At time: 404.9425575733185 and batch: 1200, loss is 4.617023239135742 and perplexity is 101.19235789553731
At time: 405.33756613731384 and batch: 1250, loss is 4.5989515209198 and perplexity is 99.3800630810403
At time: 405.728031873703 and batch: 1300, loss is 4.66678373336792 and perplexity is 106.35512531309783
At time: 406.14215564727783 and batch: 1350, loss is 4.609881744384766 and perplexity is 100.47226752402993
At time: 406.5475239753723 and batch: 1400, loss is 4.509336414337159 and perplexity is 90.86150410942568
At time: 406.9389657974243 and batch: 1450, loss is 4.585499992370606 and perplexity is 98.05220024004126
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042930668235844 and perplexity of 154.92337939811142
Finished 33 epochs...
Completing Train Step...
At time: 408.21617913246155 and batch: 50, loss is 4.758028736114502 and perplexity is 116.51601555291764
At time: 408.62317872047424 and batch: 100, loss is 4.7551679611206055 and perplexity is 116.1831657803928
At time: 409.0192320346832 and batch: 150, loss is 4.6504501247406 and perplexity is 104.63207246330896
At time: 409.40679121017456 and batch: 200, loss is 4.6778301334381105 and perplexity is 107.53647941919306
At time: 409.80769443511963 and batch: 250, loss is 4.709681806564331 and perplexity is 111.01682945865655
At time: 410.2014229297638 and batch: 300, loss is 4.729157361984253 and perplexity is 113.20013541163829
At time: 410.59681153297424 and batch: 350, loss is 4.7554591941833495 and perplexity is 116.21700708721684
At time: 410.99426078796387 and batch: 400, loss is 4.649421081542969 and perplexity is 104.52445692090392
At time: 411.3857319355011 and batch: 450, loss is 4.6750365829467775 and perplexity is 107.23649004709543
At time: 411.7933042049408 and batch: 500, loss is 4.6547488021850585 and perplexity is 105.08282010844192
At time: 412.1872684955597 and batch: 550, loss is 4.69936861038208 and perplexity is 109.87777485968269
At time: 412.59140372276306 and batch: 600, loss is 4.610698432922363 and perplexity is 100.55435558889143
At time: 412.98645091056824 and batch: 650, loss is 4.730104541778564 and perplexity is 113.30740708737545
At time: 413.3879323005676 and batch: 700, loss is 4.750515737533569 and perplexity is 115.64391105550676
At time: 413.7738721370697 and batch: 750, loss is 4.704126052856445 and perplexity is 110.40175747307347
At time: 414.15913581848145 and batch: 800, loss is 4.639645099639893 and perplexity is 103.50760617719142
At time: 414.5570013523102 and batch: 850, loss is 4.608241157531738 and perplexity is 100.3075691807453
At time: 414.942946434021 and batch: 900, loss is 4.564815092086792 and perplexity is 96.04483292486547
At time: 415.3444495201111 and batch: 950, loss is 4.63501953125 and perplexity is 103.0299302789038
At time: 415.7369701862335 and batch: 1000, loss is 4.6870423412323 and perplexity is 108.5317048866739
At time: 416.1437957286835 and batch: 1050, loss is 4.596913013458252 and perplexity is 99.17768242823882
At time: 416.5379784107208 and batch: 1100, loss is 4.708580751419067 and perplexity is 110.89466107677524
At time: 416.9363820552826 and batch: 1150, loss is 4.649206552505493 and perplexity is 104.50203579484528
At time: 417.33866786956787 and batch: 1200, loss is 4.617172088623047 and perplexity is 101.20742144720238
At time: 417.72957611083984 and batch: 1250, loss is 4.599121894836426 and perplexity is 99.39699629406985
At time: 418.12074542045593 and batch: 1300, loss is 4.666826658248901 and perplexity is 106.35969069217711
At time: 418.50699186325073 and batch: 1350, loss is 4.610155162811279 and perplexity is 100.49974224920145
At time: 418.89881014823914 and batch: 1400, loss is 4.509459819793701 and perplexity is 90.87271760671157
At time: 419.29501485824585 and batch: 1450, loss is 4.585577945709229 and perplexity is 98.05984403433509
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0429056281717415 and perplexity of 154.91950015532882
Finished 34 epochs...
Completing Train Step...
At time: 420.57709527015686 and batch: 50, loss is 4.7575960540771485 and perplexity is 116.46561207105084
At time: 421.00019454956055 and batch: 100, loss is 4.754872875213623 and perplexity is 116.14888682340971
At time: 421.3997611999512 and batch: 150, loss is 4.650146198272705 and perplexity is 104.60027683910728
At time: 421.7939565181732 and batch: 200, loss is 4.677741575241089 and perplexity is 107.52695660412951
At time: 422.2067656517029 and batch: 250, loss is 4.709482049942016 and perplexity is 110.99465532657243
At time: 422.608873128891 and batch: 300, loss is 4.7289440631866455 and perplexity is 113.17599253378091
At time: 423.0047416687012 and batch: 350, loss is 4.755172882080078 and perplexity is 116.18373751444977
At time: 423.3929171562195 and batch: 400, loss is 4.6491844367980955 and perplexity is 104.49972468395518
At time: 423.8034770488739 and batch: 450, loss is 4.674583787918091 and perplexity is 107.18794488884087
At time: 424.19813656806946 and batch: 500, loss is 4.654423961639404 and perplexity is 105.04869049146082
At time: 424.5951693058014 and batch: 550, loss is 4.699159965515137 and perplexity is 109.85485181743783
At time: 424.97925209999084 and batch: 600, loss is 4.610540742874146 and perplexity is 100.53850041784435
At time: 425.36336278915405 and batch: 650, loss is 4.730028676986694 and perplexity is 113.2988113705797
At time: 425.7532775402069 and batch: 700, loss is 4.7503042316436765 and perplexity is 115.61945427365616
At time: 426.15818548202515 and batch: 750, loss is 4.703947057723999 and perplexity is 110.38199786436198
At time: 426.5467517375946 and batch: 800, loss is 4.63943489074707 and perplexity is 103.4858502446236
At time: 426.93095779418945 and batch: 850, loss is 4.608090085983276 and perplexity is 100.29241670552948
At time: 427.3221139907837 and batch: 900, loss is 4.564695024490357 and perplexity is 96.03330174490057
At time: 427.7199580669403 and batch: 950, loss is 4.6349452686309816 and perplexity is 103.02227929053872
At time: 428.11398434638977 and batch: 1000, loss is 4.687085952758789 and perplexity is 108.5364382232097
At time: 428.5262997150421 and batch: 1050, loss is 4.597002658843994 and perplexity is 99.1865736483596
At time: 428.9192245006561 and batch: 1100, loss is 4.708666648864746 and perplexity is 110.90418705402388
At time: 429.3257386684418 and batch: 1150, loss is 4.6491389560699465 and perplexity is 104.49497206846222
At time: 429.70964002609253 and batch: 1200, loss is 4.617290897369385 and perplexity is 101.2194464883905
At time: 430.0994851589203 and batch: 1250, loss is 4.599260654449463 and perplexity is 99.41078953976326
At time: 430.500159740448 and batch: 1300, loss is 4.666851348876953 and perplexity is 106.3623168121599
At time: 430.89248061180115 and batch: 1350, loss is 4.610391731262207 and perplexity is 100.52352012998135
At time: 431.2910451889038 and batch: 1400, loss is 4.509551382064819 and perplexity is 90.88103850005244
At time: 431.67713236808777 and batch: 1450, loss is 4.585612478256226 and perplexity is 98.06323034897643
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042896238147703 and perplexity of 154.91804546432815
Finished 35 epochs...
Completing Train Step...
At time: 433.0555443763733 and batch: 50, loss is 4.757215061187744 and perplexity is 116.4212479527351
At time: 433.452086687088 and batch: 100, loss is 4.754610319137573 and perplexity is 116.1183952304994
At time: 433.85825181007385 and batch: 150, loss is 4.649866132736206 and perplexity is 104.57098600832397
At time: 434.266783952713 and batch: 200, loss is 4.677669706344605 and perplexity is 107.51922903810525
At time: 434.66304993629456 and batch: 250, loss is 4.709308938980103 and perplexity is 110.97544259803651
At time: 435.0689673423767 and batch: 300, loss is 4.728726758956909 and perplexity is 113.15140158385417
At time: 435.4604516029358 and batch: 350, loss is 4.75491660118103 and perplexity is 116.15396565688694
At time: 435.85808205604553 and batch: 400, loss is 4.648976268768311 and perplexity is 104.47797344618941
At time: 436.26050996780396 and batch: 450, loss is 4.674252433776855 and perplexity is 107.15243360314213
At time: 436.65220522880554 and batch: 500, loss is 4.654126663208007 and perplexity is 105.01746432253294
At time: 437.05359292030334 and batch: 550, loss is 4.698953599929809 and perplexity is 109.83218389566136
At time: 437.44522166252136 and batch: 600, loss is 4.610401153564453 and perplexity is 100.52446729743308
At time: 437.8355886936188 and batch: 650, loss is 4.729951944351196 and perplexity is 113.2901179877218
At time: 438.221289396286 and batch: 700, loss is 4.750118293762207 and perplexity is 115.59795823579766
At time: 438.620619058609 and batch: 750, loss is 4.703802690505982 and perplexity is 110.36606347264066
At time: 439.0165944099426 and batch: 800, loss is 4.639229955673218 and perplexity is 103.46464453723188
At time: 439.4069757461548 and batch: 850, loss is 4.60794771194458 and perplexity is 100.2781386855463
At time: 439.8113293647766 and batch: 900, loss is 4.56458535194397 and perplexity is 96.02277010568667
At time: 440.204247713089 and batch: 950, loss is 4.634860677719116 and perplexity is 103.01356491057494
At time: 440.61580443382263 and batch: 1000, loss is 4.687121105194092 and perplexity is 108.54025361039204
At time: 441.0119502544403 and batch: 1050, loss is 4.597078762054443 and perplexity is 99.19412235228434
At time: 441.4131033420563 and batch: 1100, loss is 4.708740100860596 and perplexity is 110.91233348709335
At time: 441.81873297691345 and batch: 1150, loss is 4.649066429138184 and perplexity is 104.48739364357677
At time: 442.22235465049744 and batch: 1200, loss is 4.617388925552368 and perplexity is 101.22936933316363
At time: 442.6281681060791 and batch: 1250, loss is 4.599367113113403 and perplexity is 99.42137324295237
At time: 443.0208623409271 and batch: 1300, loss is 4.666856269836426 and perplexity is 106.3628402180982
At time: 443.42501854896545 and batch: 1350, loss is 4.610598840713501 and perplexity is 100.5443416571707
At time: 443.82312750816345 and batch: 1400, loss is 4.50961853981018 and perplexity is 90.88714207064292
At time: 444.21428203582764 and batch: 1450, loss is 4.585616035461426 and perplexity is 98.06357918062976
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042892064803686 and perplexity of 154.91739893937907
Finished 36 epochs...
Completing Train Step...
At time: 445.4882082939148 and batch: 50, loss is 4.756867179870605 and perplexity is 116.38075421956934
At time: 445.8741645812988 and batch: 100, loss is 4.754368686676026 and perplexity is 116.09034064641456
At time: 446.30480098724365 and batch: 150, loss is 4.649613466262817 and perplexity is 104.54456776371333
At time: 446.69983983039856 and batch: 200, loss is 4.6776035785675045 and perplexity is 107.51211926557274
At time: 447.10250759124756 and batch: 250, loss is 4.7091544818878175 and perplexity is 110.95830297755981
At time: 447.4983084201813 and batch: 300, loss is 4.7285257339477536 and perplexity is 113.12865760844537
At time: 447.9070813655853 and batch: 350, loss is 4.754675235748291 and perplexity is 116.12593348783619
At time: 448.29560828208923 and batch: 400, loss is 4.648797979354859 and perplexity is 104.45934779001298
At time: 448.6785480976105 and batch: 450, loss is 4.6739439773559575 and perplexity is 107.11938684398694
At time: 449.0720019340515 and batch: 500, loss is 4.653842182159424 and perplexity is 104.98759309326363
At time: 449.4575607776642 and batch: 550, loss is 4.6987584400177 and perplexity is 109.81075114778017
At time: 449.85467863082886 and batch: 600, loss is 4.6102698707580565 and perplexity is 100.51127102949525
At time: 450.24935150146484 and batch: 650, loss is 4.729873743057251 and perplexity is 113.28125890030451
At time: 450.64905524253845 and batch: 700, loss is 4.749938888549805 and perplexity is 115.57722121976708
At time: 451.04766631126404 and batch: 750, loss is 4.703666791915894 and perplexity is 110.3510658993188
At time: 451.43898129463196 and batch: 800, loss is 4.639034233093262 and perplexity is 103.44439615166654
At time: 451.8430256843567 and batch: 850, loss is 4.607801675796509 and perplexity is 100.26349552167855
At time: 452.239629983902 and batch: 900, loss is 4.564477376937866 and perplexity is 96.01240260622386
At time: 452.64509868621826 and batch: 950, loss is 4.634771728515625 and perplexity is 103.00440234353496
At time: 453.0395681858063 and batch: 1000, loss is 4.687143039703369 and perplexity is 108.5426344137026
At time: 453.4260423183441 and batch: 1050, loss is 4.597144412994385 and perplexity is 99.2006347534237
At time: 453.8359127044678 and batch: 1100, loss is 4.708801498413086 and perplexity is 110.91914344196556
At time: 454.23763632774353 and batch: 1150, loss is 4.648992881774903 and perplexity is 104.47970915386858
At time: 454.63531851768494 and batch: 1200, loss is 4.6174701309204105 and perplexity is 101.23759003513507
At time: 455.02930331230164 and batch: 1250, loss is 4.599449205398559 and perplexity is 99.42953530569187
At time: 455.4185960292816 and batch: 1300, loss is 4.666846723556518 and perplexity is 106.36182485350015
At time: 455.8216676712036 and batch: 1350, loss is 4.610783624649048 and perplexity is 100.56292235297325
At time: 456.21761775016785 and batch: 1400, loss is 4.509673910140991 and perplexity is 90.89217466109265
At time: 456.6178252696991 and batch: 1450, loss is 4.585611019134522 and perplexity is 98.06308726289302
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042891021467682 and perplexity of 154.9172373085634
Finished 37 epochs...
Completing Train Step...
At time: 457.9028580188751 and batch: 50, loss is 4.756549310684204 and perplexity is 116.34376624289331
At time: 458.3126230239868 and batch: 100, loss is 4.754144649505616 and perplexity is 116.06433500820778
At time: 458.7153329849243 and batch: 150, loss is 4.649388475418091 and perplexity is 104.52104883897118
At time: 459.11847019195557 and batch: 200, loss is 4.677544708251953 and perplexity is 107.50579017948546
At time: 459.515545129776 and batch: 250, loss is 4.709025144577026 and perplexity is 110.94395285706574
At time: 459.90784978866577 and batch: 300, loss is 4.728342094421387 and perplexity is 113.10788462277264
At time: 460.3036458492279 and batch: 350, loss is 4.754445381164551 and perplexity is 116.09924447714619
At time: 460.69873905181885 and batch: 400, loss is 4.648631286621094 and perplexity is 104.4419366269601
At time: 461.0889563560486 and batch: 450, loss is 4.673654479980469 and perplexity is 107.08838055096842
At time: 461.47694993019104 and batch: 500, loss is 4.653563575744629 and perplexity is 104.95834695062464
At time: 461.86121249198914 and batch: 550, loss is 4.698573980331421 and perplexity is 109.79049735913453
At time: 462.2677628993988 and batch: 600, loss is 4.610153722763061 and perplexity is 100.49959752483096
At time: 462.6595549583435 and batch: 650, loss is 4.729799251556397 and perplexity is 113.27282072360053
At time: 463.0582528114319 and batch: 700, loss is 4.74976016998291 and perplexity is 115.55656727010211
At time: 463.455961227417 and batch: 750, loss is 4.703542757034302 and perplexity is 110.33737936674767
At time: 463.8545949459076 and batch: 800, loss is 4.638844633102417 and perplexity is 103.42478495430346
At time: 464.2575557231903 and batch: 850, loss is 4.6076734924316405 and perplexity is 100.25064423312743
At time: 464.65132212638855 and batch: 900, loss is 4.564384031295776 and perplexity is 96.00344068513864
At time: 465.0483891963959 and batch: 950, loss is 4.634677886962891 and perplexity is 102.99473670400694
At time: 465.4378750324249 and batch: 1000, loss is 4.687157201766968 and perplexity is 108.54417161227923
At time: 465.83034491539 and batch: 1050, loss is 4.597201671600342 and perplexity is 99.20631500609986
At time: 466.2242159843445 and batch: 1100, loss is 4.7088547039031985 and perplexity is 110.92504510635432
At time: 466.62731313705444 and batch: 1150, loss is 4.648916292190552 and perplexity is 104.47170740280066
At time: 467.0135922431946 and batch: 1200, loss is 4.617542819976807 and perplexity is 101.2449491674875
At time: 467.4169588088989 and batch: 1250, loss is 4.599515953063965 and perplexity is 99.43617221654256
At time: 467.81848645210266 and batch: 1300, loss is 4.6668322658538814 and perplexity is 106.3602871169806
At time: 468.22251319885254 and batch: 1350, loss is 4.610952453613281 and perplexity is 100.57990172025856
At time: 468.6250784397125 and batch: 1400, loss is 4.5097114372253415 and perplexity is 90.89558564339966
At time: 469.01954078674316 and batch: 1450, loss is 4.5855992412567135 and perplexity is 98.0619322946353
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042896238147703 and perplexity of 154.91804546432815
Annealing...
Finished 38 epochs...
Completing Train Step...
At time: 470.2946939468384 and batch: 50, loss is 4.756271305084229 and perplexity is 116.3114265198759
At time: 470.7201635837555 and batch: 100, loss is 4.754218597412109 and perplexity is 116.07291804014487
At time: 471.11678433418274 and batch: 150, loss is 4.649838771820068 and perplexity is 104.56812488948691
At time: 471.51254892349243 and batch: 200, loss is 4.6770103931427 and perplexity is 107.4483635547832
At time: 471.9079568386078 and batch: 250, loss is 4.7090963363647464 and perplexity is 110.95185143656003
At time: 472.30198431015015 and batch: 300, loss is 4.728053197860718 and perplexity is 113.07521286352728
At time: 472.69014024734497 and batch: 350, loss is 4.754174098968506 and perplexity is 116.06775309086461
At time: 473.08022451400757 and batch: 400, loss is 4.6473189544677735 and perplexity is 104.30496401181101
At time: 473.49023056030273 and batch: 450, loss is 4.673131828308105 and perplexity is 107.0324252536214
At time: 473.8809804916382 and batch: 500, loss is 4.652868146896362 and perplexity is 104.8853812624517
At time: 474.271950006485 and batch: 550, loss is 4.697281751632691 and perplexity is 109.64871455523298
At time: 474.6611177921295 and batch: 600, loss is 4.609105157852173 and perplexity is 100.39427240307175
At time: 475.0588800907135 and batch: 650, loss is 4.728969955444336 and perplexity is 113.17892295368145
At time: 475.46218943595886 and batch: 700, loss is 4.748748416900635 and perplexity is 115.43971168145869
At time: 475.8489336967468 and batch: 750, loss is 4.702862920761109 and perplexity is 110.26239350590727
At time: 476.24760150909424 and batch: 800, loss is 4.6376011943817135 and perplexity is 103.29626249347243
At time: 476.6472294330597 and batch: 850, loss is 4.606401882171631 and perplexity is 100.1232455032809
At time: 477.05340600013733 and batch: 900, loss is 4.563642435073852 and perplexity is 95.93227128897423
At time: 477.45045256614685 and batch: 950, loss is 4.632898569107056 and perplexity is 102.81163927250387
At time: 477.8424711227417 and batch: 1000, loss is 4.686025457382202 and perplexity is 108.42139684349023
At time: 478.2319405078888 and batch: 1050, loss is 4.595402965545654 and perplexity is 99.02803239370944
At time: 478.6177890300751 and batch: 1100, loss is 4.707872333526612 and perplexity is 110.81612913469145
At time: 479.0363984107971 and batch: 1150, loss is 4.647158679962158 and perplexity is 104.28824792488781
At time: 479.43274903297424 and batch: 1200, loss is 4.616008243560791 and perplexity is 101.08970020741737
At time: 479.83369421958923 and batch: 1250, loss is 4.598502864837647 and perplexity is 99.33548561201825
At time: 480.2304139137268 and batch: 1300, loss is 4.665019817352295 and perplexity is 106.16768916362633
At time: 480.62368273735046 and batch: 1350, loss is 4.60882381439209 and perplexity is 100.36603110404006
At time: 481.0097689628601 and batch: 1400, loss is 4.507649002075195 and perplexity is 90.70831257823434
At time: 481.4137489795685 and batch: 1450, loss is 4.5833502197265625 and perplexity is 97.84163671522337
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042635404146635 and perplexity of 154.87764284011016
Finished 39 epochs...
Completing Train Step...
At time: 482.7593264579773 and batch: 50, loss is 4.755937128067017 and perplexity is 116.27256440806777
At time: 483.16095304489136 and batch: 100, loss is 4.753969078063965 and perplexity is 116.04395921434222
At time: 483.5622978210449 and batch: 150, loss is 4.649754180908203 and perplexity is 104.55927975056491
At time: 483.95568013191223 and batch: 200, loss is 4.676830434799195 and perplexity is 107.4290290650191
At time: 484.3626387119293 and batch: 250, loss is 4.708985109329223 and perplexity is 110.9395112773313
At time: 484.7575912475586 and batch: 300, loss is 4.727826223373413 and perplexity is 113.04955058751186
At time: 485.1449520587921 and batch: 350, loss is 4.7540380573272705 and perplexity is 116.05196411724289
At time: 485.5410318374634 and batch: 400, loss is 4.647181396484375 and perplexity is 104.29061701809746
At time: 485.9424555301666 and batch: 450, loss is 4.6730087375640865 and perplexity is 107.01925136357139
At time: 486.33856320381165 and batch: 500, loss is 4.65270827293396 and perplexity is 104.8686141612984
At time: 486.7475526332855 and batch: 550, loss is 4.697139015197754 and perplexity is 109.63306480554333
At time: 487.1457943916321 and batch: 600, loss is 4.609046354293823 and perplexity is 100.38836903618771
At time: 487.54430866241455 and batch: 650, loss is 4.7289048862457275 and perplexity is 113.17155873146005
At time: 487.94036173820496 and batch: 700, loss is 4.74854001045227 and perplexity is 115.41565580793359
At time: 488.33605885505676 and batch: 750, loss is 4.702684192657471 and perplexity is 110.24268827840481
At time: 488.7279019355774 and batch: 800, loss is 4.637528924942017 and perplexity is 103.28879760020433
At time: 489.12418007850647 and batch: 850, loss is 4.6063940048217775 and perplexity is 100.12245680055408
At time: 489.5198769569397 and batch: 900, loss is 4.563584766387939 and perplexity is 95.92673916046918
At time: 489.9066436290741 and batch: 950, loss is 4.632837781906128 and perplexity is 102.80538983067464
At time: 490.3196876049042 and batch: 1000, loss is 4.685971145629883 and perplexity is 108.41550844734473
At time: 490.71745347976685 and batch: 1050, loss is 4.595495576858521 and perplexity is 99.03720393448768
At time: 491.10620284080505 and batch: 1100, loss is 4.707894430160523 and perplexity is 110.81857782518219
At time: 491.50315976142883 and batch: 1150, loss is 4.647150611877441 and perplexity is 104.28740652186286
At time: 491.9127526283264 and batch: 1200, loss is 4.616048402786255 and perplexity is 101.09375997299809
At time: 492.303701877594 and batch: 1250, loss is 4.598643188476562 and perplexity is 99.34942570687234
At time: 492.6910996437073 and batch: 1300, loss is 4.665068426132202 and perplexity is 106.17284997089138
At time: 493.07994055747986 and batch: 1350, loss is 4.608882942199707 and perplexity is 100.37196570286666
At time: 493.4644875526428 and batch: 1400, loss is 4.507815570831299 and perplexity is 90.72342300745652
At time: 493.87050223350525 and batch: 1450, loss is 4.583431301116943 and perplexity is 97.84957017278889
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042593149038462 and perplexity of 154.87109860682293
Finished 40 epochs...
Completing Train Step...
At time: 495.2243757247925 and batch: 50, loss is 4.7557931232452395 and perplexity is 116.2558218036894
At time: 495.63205766677856 and batch: 100, loss is 4.753876457214355 and perplexity is 116.033211621981
At time: 496.0268383026123 and batch: 150, loss is 4.649736022949218 and perplexity is 104.55738118468886
At time: 496.41370487213135 and batch: 200, loss is 4.676730842590332 and perplexity is 107.41833050347404
At time: 496.82892298698425 and batch: 250, loss is 4.7088955211639405 and perplexity is 110.92957285524777
At time: 497.2205629348755 and batch: 300, loss is 4.727695217132569 and perplexity is 113.03474136093193
At time: 497.6076419353485 and batch: 350, loss is 4.753941783905029 and perplexity is 116.0407919353002
At time: 497.99600744247437 and batch: 400, loss is 4.647086849212647 and perplexity is 104.28075709091351
At time: 498.38947319984436 and batch: 450, loss is 4.672908477783203 and perplexity is 107.00852217474139
At time: 498.7867503166199 and batch: 500, loss is 4.652604370117188 and perplexity is 104.85771858294643
At time: 499.1780381202698 and batch: 550, loss is 4.697046842575073 and perplexity is 109.62296010412321
At time: 499.56588888168335 and batch: 600, loss is 4.6089935398101805 and perplexity is 100.38306721632102
At time: 499.96853041648865 and batch: 650, loss is 4.728863830566406 and perplexity is 113.16691249161443
At time: 500.36957597732544 and batch: 700, loss is 4.748420495986938 and perplexity is 115.40186279178762
At time: 500.7641248703003 and batch: 750, loss is 4.702590351104736 and perplexity is 110.23234341875556
At time: 501.14846873283386 and batch: 800, loss is 4.637480659484863 and perplexity is 103.28381243947581
At time: 501.55734610557556 and batch: 850, loss is 4.606380052566529 and perplexity is 100.12105987622579
At time: 501.95200872421265 and batch: 900, loss is 4.563570585250854 and perplexity is 95.92537881987664
At time: 502.3561038970947 and batch: 950, loss is 4.632782011032105 and perplexity is 102.79965644410899
At time: 502.7620656490326 and batch: 1000, loss is 4.685948581695556 and perplexity is 108.41306219453082
At time: 503.16195797920227 and batch: 1050, loss is 4.595559730529785 and perplexity is 99.04355773851957
At time: 503.56431555747986 and batch: 1100, loss is 4.707918577194214 and perplexity is 110.82125379742277
At time: 503.96001720428467 and batch: 1150, loss is 4.647127523422241 and perplexity is 104.28499871454582
At time: 504.36064743995667 and batch: 1200, loss is 4.616099185943604 and perplexity is 101.09889396367677
At time: 504.7541778087616 and batch: 1250, loss is 4.5987575721740725 and perplexity is 99.36079031148056
At time: 505.1493878364563 and batch: 1300, loss is 4.665099935531616 and perplexity is 106.17619546633505
At time: 505.5442957878113 and batch: 1350, loss is 4.608919343948364 and perplexity is 100.37561948443602
At time: 505.94856238365173 and batch: 1400, loss is 4.507907829284668 and perplexity is 90.7317933962612
At time: 506.342467546463 and batch: 1450, loss is 4.583480815887452 and perplexity is 97.85441529175185
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042575933994391 and perplexity of 154.8684325169837
Finished 41 epochs...
Completing Train Step...
At time: 507.60483503341675 and batch: 50, loss is 4.755674505233765 and perplexity is 116.2420325871256
At time: 508.02612018585205 and batch: 100, loss is 4.753809337615967 and perplexity is 116.0254237807785
At time: 508.4221329689026 and batch: 150, loss is 4.649706468582154 and perplexity is 104.55429110312892
At time: 508.82979822158813 and batch: 200, loss is 4.676643743515014 and perplexity is 107.40897487365432
At time: 509.22750425338745 and batch: 250, loss is 4.708829574584961 and perplexity is 110.92225767061862
At time: 509.64144802093506 and batch: 300, loss is 4.727586536407471 and perplexity is 113.02245733081034
At time: 510.037602186203 and batch: 350, loss is 4.753858699798584 and perplexity is 116.03115119029293
At time: 510.42833495140076 and batch: 400, loss is 4.647004957199097 and perplexity is 104.2722176794004
At time: 510.82939553260803 and batch: 450, loss is 4.672824058532715 and perplexity is 106.99948897679685
At time: 511.22230052948 and batch: 500, loss is 4.6525201320648195 and perplexity is 104.84888594498456
At time: 511.616402387619 and batch: 550, loss is 4.696967821121216 and perplexity is 109.61429788069493
At time: 512.011855840683 and batch: 600, loss is 4.608942375183106 and perplexity is 100.3779312855124
At time: 512.4378755092621 and batch: 650, loss is 4.728831443786621 and perplexity is 113.16324743909054
At time: 512.833548784256 and batch: 700, loss is 4.748323459625244 and perplexity is 115.39066515818715
At time: 513.2235591411591 and batch: 750, loss is 4.702520189285278 and perplexity is 110.22460958829113
At time: 513.6240532398224 and batch: 800, loss is 4.637438678741455 and perplexity is 103.27947659925914
At time: 514.0250923633575 and batch: 850, loss is 4.606366844177246 and perplexity is 100.11973744702513
At time: 514.4222540855408 and batch: 900, loss is 4.563566637039185 and perplexity is 95.92500008692423
At time: 514.823867559433 and batch: 950, loss is 4.632726812362671 and perplexity is 102.79398219646195
At time: 515.2245891094208 and batch: 1000, loss is 4.6859313488006595 and perplexity is 108.41119393972234
At time: 515.6283814907074 and batch: 1050, loss is 4.5956106376647945 and perplexity is 99.04859989062487
At time: 516.0231738090515 and batch: 1100, loss is 4.7079386711120605 and perplexity is 110.82348065296533
At time: 516.4285278320312 and batch: 1150, loss is 4.647100601196289 and perplexity is 104.28219116803993
At time: 516.8205692768097 and batch: 1200, loss is 4.6161424255371095 and perplexity is 101.1032655332674
At time: 517.2209253311157 and batch: 1250, loss is 4.59885645866394 and perplexity is 99.37061623708257
At time: 517.6069793701172 and batch: 1300, loss is 4.665123863220215 and perplexity is 106.17873604767173
At time: 518.0088102817535 and batch: 1350, loss is 4.608947534561157 and perplexity is 100.37844917454387
At time: 518.4026479721069 and batch: 1400, loss is 4.507974433898926 and perplexity is 90.73783675361676
At time: 518.7976310253143 and batch: 1450, loss is 4.583513956069947 and perplexity is 97.85765825866854
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042568108974359 and perplexity of 154.86722067313815
Finished 42 epochs...
Completing Train Step...
At time: 520.1019275188446 and batch: 50, loss is 4.755566530227661 and perplexity is 116.22948203053285
At time: 520.5158545970917 and batch: 100, loss is 4.75375506401062 and perplexity is 116.01912683359858
At time: 520.9114952087402 and batch: 150, loss is 4.649675731658935 and perplexity is 104.55107747529992
At time: 521.3153882026672 and batch: 200, loss is 4.676560230255127 and perplexity is 107.4000051745711
At time: 521.7119228839874 and batch: 250, loss is 4.708774633407593 and perplexity is 110.9161636385941
At time: 522.111701965332 and batch: 300, loss is 4.727486524581909 and perplexity is 113.01115431375034
At time: 522.5044362545013 and batch: 350, loss is 4.753782939910889 and perplexity is 116.02236101628516
At time: 522.9063029289246 and batch: 400, loss is 4.646931095123291 and perplexity is 104.26451620138079
At time: 523.3019459247589 and batch: 450, loss is 4.6727501487731935 and perplexity is 106.99158096254097
At time: 523.7026584148407 and batch: 500, loss is 4.6524451732635494 and perplexity is 104.84102689273587
At time: 524.0992980003357 and batch: 550, loss is 4.696894969940185 and perplexity is 109.60631264050708
At time: 524.4888017177582 and batch: 600, loss is 4.608892669677735 and perplexity is 100.37294207370641
At time: 524.90846991539 and batch: 650, loss is 4.728803339004517 and perplexity is 113.16006705537126
At time: 525.3041839599609 and batch: 700, loss is 4.748234691619873 and perplexity is 115.38042261361456
At time: 525.7117896080017 and batch: 750, loss is 4.7024595737457275 and perplexity is 110.21792846660114
At time: 526.1080181598663 and batch: 800, loss is 4.637399263381958 and perplexity is 103.27540588178523
At time: 526.5005965232849 and batch: 850, loss is 4.606352605819702 and perplexity is 100.11831191655482
At time: 526.9009475708008 and batch: 900, loss is 4.563565483093262 and perplexity is 95.92488939472535
At time: 527.303807258606 and batch: 950, loss is 4.632670974731445 and perplexity is 102.78824258423646
At time: 527.7071659564972 and batch: 1000, loss is 4.685916767120362 and perplexity is 108.40961313387703
At time: 528.1012506484985 and batch: 1050, loss is 4.595653486251831 and perplexity is 99.05284407410613
At time: 528.4929685592651 and batch: 1100, loss is 4.707955179214477 and perplexity is 110.82531015343486
At time: 528.8800046443939 and batch: 1150, loss is 4.647072143554688 and perplexity is 104.27922358504367
At time: 529.2693517208099 and batch: 1200, loss is 4.616178188323975 and perplexity is 101.1068813324592
At time: 529.659342288971 and batch: 1250, loss is 4.598945093154907 and perplexity is 99.37942429141278
At time: 530.0489792823792 and batch: 1300, loss is 4.665143756866455 and perplexity is 106.18084835089557
At time: 530.4474451541901 and batch: 1350, loss is 4.608972787857056 and perplexity is 100.38098409323014
At time: 530.838701248169 and batch: 1400, loss is 4.5080290699005126 and perplexity is 90.74279444164252
At time: 531.2349858283997 and batch: 1450, loss is 4.583536424636841 and perplexity is 97.85985700471046
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042565500634348 and perplexity of 154.86681672729696
Finished 43 epochs...
Completing Train Step...
At time: 532.599523305893 and batch: 50, loss is 4.75546498298645 and perplexity is 116.21767984653508
At time: 532.9930033683777 and batch: 100, loss is 4.7537078857421875 and perplexity is 116.01365338120455
At time: 533.4009902477264 and batch: 150, loss is 4.649645528793335 and perplexity is 104.5479197808445
At time: 533.7961857318878 and batch: 200, loss is 4.6764796924591066 and perplexity is 107.39135576316868
At time: 534.1931290626526 and batch: 250, loss is 4.7087263584136965 and perplexity is 110.910809290713
At time: 534.5859389305115 and batch: 300, loss is 4.727391748428345 and perplexity is 113.00044405878101
At time: 534.9825954437256 and batch: 350, loss is 4.753712253570557 and perplexity is 116.01416011003766
At time: 535.3763160705566 and batch: 400, loss is 4.646862497329712 and perplexity is 104.25736413093175
At time: 535.7675361633301 and batch: 450, loss is 4.672683010101318 and perplexity is 106.9843979310256
At time: 536.159850358963 and batch: 500, loss is 4.652375841140747 and perplexity is 104.83375829376126
At time: 536.549299955368 and batch: 550, loss is 4.696826210021973 and perplexity is 109.59877637851369
At time: 536.9543266296387 and batch: 600, loss is 4.6088446998596195 and perplexity is 100.36812731741388
At time: 537.3624398708344 and batch: 650, loss is 4.728777379989624 and perplexity is 113.15712956963254
At time: 537.7713479995728 and batch: 700, loss is 4.748148488998413 and perplexity is 115.37047694739745
At time: 538.1740002632141 and batch: 750, loss is 4.702403964996338 and perplexity is 110.21179955585094
At time: 538.5746974945068 and batch: 800, loss is 4.637360877990723 and perplexity is 103.27144169100947
At time: 538.970618724823 and batch: 850, loss is 4.606336717605591 and perplexity is 100.11672122801524
At time: 539.3642675876617 and batch: 900, loss is 4.56356502532959 and perplexity is 95.92484548380577
At time: 539.7765135765076 and batch: 950, loss is 4.632614517211914 and perplexity is 102.78243957883643
At time: 540.1705513000488 and batch: 1000, loss is 4.685903625488281 and perplexity is 108.40818846398852
At time: 540.5694978237152 and batch: 1050, loss is 4.595690965652466 and perplexity is 99.05655658490409
At time: 540.9557931423187 and batch: 1100, loss is 4.707968769073486 and perplexity is 110.82681626400834
At time: 541.3413491249084 and batch: 1150, loss is 4.647043313980102 and perplexity is 104.27621730272475
At time: 541.7491722106934 and batch: 1200, loss is 4.6162084865570066 and perplexity is 101.1099447387186
At time: 542.1425321102142 and batch: 1250, loss is 4.599026155471802 and perplexity is 99.38748054432234
At time: 542.5423831939697 and batch: 1300, loss is 4.665161008834839 and perplexity is 106.18268019533569
At time: 542.9276356697083 and batch: 1350, loss is 4.608996229171753 and perplexity is 100.38333718304756
At time: 543.3325254917145 and batch: 1400, loss is 4.508076133728028 and perplexity is 90.74706524536776
At time: 543.7312326431274 and batch: 1450, loss is 4.583551721572876 and perplexity is 97.86135397213296
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042562370626335 and perplexity of 154.8663319936783
Finished 44 epochs...
Completing Train Step...
At time: 545.0088670253754 and batch: 50, loss is 4.755367412567138 and perplexity is 116.20634099195838
At time: 545.4219193458557 and batch: 100, loss is 4.753665361404419 and perplexity is 116.0087200823158
At time: 545.8247339725494 and batch: 150, loss is 4.649616231918335 and perplexity is 104.54485689837385
At time: 546.2369999885559 and batch: 200, loss is 4.676401948928833 and perplexity is 107.38300710458205
At time: 546.6329610347748 and batch: 250, loss is 4.708682231903076 and perplexity is 110.90591529168725
At time: 547.0378289222717 and batch: 300, loss is 4.727300825119019 and perplexity is 112.99017015152778
At time: 547.4398086071014 and batch: 350, loss is 4.753644971847534 and perplexity is 116.00635474003279
At time: 547.8485767841339 and batch: 400, loss is 4.6467976379394536 and perplexity is 104.25060228115134
At time: 548.2693054676056 and batch: 450, loss is 4.672620182037353 and perplexity is 106.977676519578
At time: 548.667799949646 and batch: 500, loss is 4.652310228347778 and perplexity is 104.82688008373388
At time: 549.0575687885284 and batch: 550, loss is 4.696760301589966 and perplexity is 109.59155313305169
At time: 549.442348241806 and batch: 600, loss is 4.60879807472229 and perplexity is 100.3634477487878
At time: 549.8260269165039 and batch: 650, loss is 4.728752355575562 and perplexity is 113.15429791419855
At time: 550.2297158241272 and batch: 700, loss is 4.748062219619751 and perplexity is 115.36052443733985
At time: 550.6291120052338 and batch: 750, loss is 4.70235161781311 and perplexity is 110.20603042958578
At time: 551.0273683071136 and batch: 800, loss is 4.637322568893433 and perplexity is 103.26748553108139
At time: 551.4159698486328 and batch: 850, loss is 4.606319551467895 and perplexity is 100.11500262534396
At time: 551.8077704906464 and batch: 900, loss is 4.563564777374268 and perplexity is 95.92482169873276
At time: 552.2032713890076 and batch: 950, loss is 4.632557897567749 and perplexity is 102.7766202384271
At time: 552.5935842990875 and batch: 1000, loss is 4.685891246795654 and perplexity is 108.406846520651
At time: 553.0020668506622 and batch: 1050, loss is 4.595725307464599 and perplexity is 99.05995842497326
At time: 553.390150308609 and batch: 1100, loss is 4.707980327606201 and perplexity is 110.82809726679307
At time: 553.7843778133392 and batch: 1150, loss is 4.647013635635376 and perplexity is 104.27312260312384
At time: 554.1794016361237 and batch: 1200, loss is 4.616234693527222 and perplexity is 101.11259455875056
At time: 554.5699825286865 and batch: 1250, loss is 4.599101467132568 and perplexity is 99.39496586240385
At time: 554.9558799266815 and batch: 1300, loss is 4.6651763820648195 and perplexity is 106.18431257864576
At time: 555.3387048244476 and batch: 1350, loss is 4.60901837348938 and perplexity is 100.38556012816328
At time: 555.7421627044678 and batch: 1400, loss is 4.508117694854736 and perplexity is 90.75083687402085
At time: 556.145781993866 and batch: 1450, loss is 4.583562307357788 and perplexity is 97.86238991686041
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042561327290331 and perplexity of 154.86617041614258
Finished 45 epochs...
Completing Train Step...
At time: 557.4724273681641 and batch: 50, loss is 4.75527286529541 and perplexity is 116.19535451883878
At time: 557.8864059448242 and batch: 100, loss is 4.753626174926758 and perplexity is 116.004174198267
At time: 558.2860560417175 and batch: 150, loss is 4.64958740234375 and perplexity is 104.5418429580699
At time: 558.6866192817688 and batch: 200, loss is 4.676327381134033 and perplexity is 107.37500008907979
At time: 559.0778095722198 and batch: 250, loss is 4.708641576766968 and perplexity is 110.90140648825948
At time: 559.4822480678558 and batch: 300, loss is 4.727213201522827 and perplexity is 112.98026998023538
At time: 559.8754813671112 and batch: 350, loss is 4.7535810470581055 and perplexity is 115.99893929525152
At time: 560.2687082290649 and batch: 400, loss is 4.646735754013061 and perplexity is 104.24415104416943
At time: 560.6659114360809 and batch: 450, loss is 4.672560405731201 and perplexity is 106.9712819803578
At time: 561.059534072876 and batch: 500, loss is 4.652247228622437 and perplexity is 104.82027622710297
At time: 561.44966340065 and batch: 550, loss is 4.696696510314942 and perplexity is 109.58456237112264
At time: 561.8376381397247 and batch: 600, loss is 4.608753271102906 and perplexity is 100.35895120380627
At time: 562.234879732132 and batch: 650, loss is 4.728727903366089 and perplexity is 113.15153107543095
At time: 562.6320769786835 and batch: 700, loss is 4.747976951599121 and perplexity is 115.35068829312247
At time: 563.0343918800354 and batch: 750, loss is 4.7023013401031495 and perplexity is 110.20048966204163
At time: 563.4320831298828 and batch: 800, loss is 4.637285022735596 and perplexity is 103.26360830655811
At time: 563.8255715370178 and batch: 850, loss is 4.6063018417358395 and perplexity is 100.11322963117236
At time: 564.2348442077637 and batch: 900, loss is 4.563564138412476 and perplexity is 95.92476040645639
At time: 564.6319713592529 and batch: 950, loss is 4.632501773834228 and perplexity is 102.7708521926443
At time: 565.0255284309387 and batch: 1000, loss is 4.685879325866699 and perplexity is 108.40555421803812
At time: 565.4098913669586 and batch: 1050, loss is 4.595757360458374 and perplexity is 99.06313364409135
At time: 565.8037416934967 and batch: 1100, loss is 4.707990493774414 and perplexity is 110.82922396959972
At time: 566.2010324001312 and batch: 1150, loss is 4.646983995437622 and perplexity is 104.27003197295313
At time: 566.6026484966278 and batch: 1200, loss is 4.616258335113526 and perplexity is 101.1149850491386
At time: 567.01358294487 and batch: 1250, loss is 4.59917236328125 and perplexity is 99.40201283248038
At time: 567.4099683761597 and batch: 1300, loss is 4.665190296173096 and perplexity is 106.18579004894703
At time: 567.8206486701965 and batch: 1350, loss is 4.609039993286133 and perplexity is 100.38773046703122
At time: 568.2189996242523 and batch: 1400, loss is 4.508155317306518 and perplexity is 90.75425120723274
At time: 568.6209206581116 and batch: 1450, loss is 4.583569688796997 and perplexity is 97.86311228480851
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042562370626335 and perplexity of 154.8663319936783
Annealing...
Finished 46 epochs...
Completing Train Step...
At time: 569.917227268219 and batch: 50, loss is 4.755177984237671 and perplexity is 116.18433030370049
At time: 570.328714132309 and batch: 100, loss is 4.753647394180298 and perplexity is 116.00663574636702
At time: 570.7178387641907 and batch: 150, loss is 4.649897928237915 and perplexity is 104.57431094814709
At time: 571.1034893989563 and batch: 200, loss is 4.676228456497192 and perplexity is 107.3643785815632
At time: 571.4886231422424 and batch: 250, loss is 4.708446836471557 and perplexity is 110.87981161836245
At time: 571.889764547348 and batch: 300, loss is 4.727153816223145 and perplexity is 112.97356081225936
At time: 572.2953898906708 and batch: 350, loss is 4.7536947059631345 and perplexity is 116.01212435696198
At time: 572.6975960731506 and batch: 400, loss is 4.646241283416748 and perplexity is 104.19261811844865
At time: 573.0926268100739 and batch: 450, loss is 4.672379217147827 and perplexity is 106.95190176110431
At time: 573.4895379543304 and batch: 500, loss is 4.652075786590576 and perplexity is 104.80230716633653
At time: 573.8979225158691 and batch: 550, loss is 4.696325807571411 and perplexity is 109.54394660185677
At time: 574.3149778842926 and batch: 600, loss is 4.608468494415283 and perplexity is 100.33037538316609
At time: 574.6998009681702 and batch: 650, loss is 4.728347797393798 and perplexity is 113.10852967575754
At time: 575.0866949558258 and batch: 700, loss is 4.747685337066651 and perplexity is 115.3170552602647
At time: 575.4877669811249 and batch: 750, loss is 4.702077016830445 and perplexity is 110.17577190003526
At time: 575.8808562755585 and batch: 800, loss is 4.636912040710449 and perplexity is 103.22510001870396
At time: 576.2752110958099 and batch: 850, loss is 4.605971956253052 and perplexity is 100.0802091768658
At time: 576.6667637825012 and batch: 900, loss is 4.56337158203125 and perplexity is 95.90629125995564
At time: 577.059189081192 and batch: 950, loss is 4.631977825164795 and perplexity is 102.71701964535873
At time: 577.4444725513458 and batch: 1000, loss is 4.685527229309082 and perplexity is 108.36739171440878
At time: 577.8450741767883 and batch: 1050, loss is 4.595407619476318 and perplexity is 99.02849326437843
At time: 578.2539944648743 and batch: 1100, loss is 4.707717742919922 and perplexity is 110.79899932614535
At time: 578.6519737243652 and batch: 1150, loss is 4.646494846343995 and perplexity is 104.21904085346773
At time: 579.0573470592499 and batch: 1200, loss is 4.61575758934021 and perplexity is 101.0643648227463
At time: 579.4446537494659 and batch: 1250, loss is 4.598701486587524 and perplexity is 99.35521775954741
At time: 579.837589263916 and batch: 1300, loss is 4.6647397232055665 and perplexity is 106.13795637950368
At time: 580.2342884540558 and batch: 1350, loss is 4.608352575302124 and perplexity is 100.31874584908442
At time: 580.62451004982 and batch: 1400, loss is 4.507485761642456 and perplexity is 90.69350652254238
At time: 581.0205228328705 and batch: 1450, loss is 4.582930154800415 and perplexity is 97.80054550641451
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042556632278312 and perplexity of 154.86544331931796
Finished 47 epochs...
Completing Train Step...
At time: 582.3045120239258 and batch: 50, loss is 4.755102815628052 and perplexity is 116.17559721736319
At time: 582.7004585266113 and batch: 100, loss is 4.7536428260803225 and perplexity is 116.00610581766747
At time: 583.0862464904785 and batch: 150, loss is 4.6498967552185055 and perplexity is 104.57418828052253
At time: 583.4739751815796 and batch: 200, loss is 4.6761429977416995 and perplexity is 107.35520374742592
At time: 583.8910381793976 and batch: 250, loss is 4.708429183959961 and perplexity is 110.87785432847764
At time: 584.2846789360046 and batch: 300, loss is 4.7270996952056885 and perplexity is 112.96744673365414
At time: 584.6839723587036 and batch: 350, loss is 4.753677577972412 and perplexity is 116.01013731938932
At time: 585.0860414505005 and batch: 400, loss is 4.646180696487427 and perplexity is 104.18630559888899
At time: 585.4874978065491 and batch: 450, loss is 4.672358741760254 and perplexity is 106.94971190188326
At time: 585.8911304473877 and batch: 500, loss is 4.652041177749634 and perplexity is 104.79868014272141
At time: 586.2861471176147 and batch: 550, loss is 4.696292123794556 and perplexity is 109.54025681014694
At time: 586.6822166442871 and batch: 600, loss is 4.608468685150147 and perplexity is 100.33039451966836
At time: 587.0774195194244 and batch: 650, loss is 4.728353586196899 and perplexity is 113.10918444066002
At time: 587.4695546627045 and batch: 700, loss is 4.747643489837646 and perplexity is 115.31222966201473
At time: 587.8816561698914 and batch: 750, loss is 4.702032604217529 and perplexity is 110.17087881478336
At time: 588.2807404994965 and batch: 800, loss is 4.636896057128906 and perplexity is 103.22345012508619
At time: 588.6739876270294 and batch: 850, loss is 4.6059887504577635 and perplexity is 100.08188995849991
At time: 589.0660519599915 and batch: 900, loss is 4.563338117599487 and perplexity is 95.90308186411677
At time: 589.4600877761841 and batch: 950, loss is 4.631972732543946 and perplexity is 102.71649654785486
At time: 589.8489964008331 and batch: 1000, loss is 4.685505933761597 and perplexity is 108.3650839960448
At time: 590.2463464736938 and batch: 1050, loss is 4.595435152053833 and perplexity is 99.03121981157966
At time: 590.6428208351135 and batch: 1100, loss is 4.7077363586425784 and perplexity is 110.80106194878599
At time: 591.0351135730743 and batch: 1150, loss is 4.646512250900269 and perplexity is 104.22085475541417
At time: 591.4312081336975 and batch: 1200, loss is 4.615748500823974 and perplexity is 101.06344630179976
At time: 591.8210043907166 and batch: 1250, loss is 4.598709030151367 and perplexity is 99.35596725480264
At time: 592.2243602275848 and batch: 1300, loss is 4.66474762916565 and perplexity is 106.13879550526715
At time: 592.6192727088928 and batch: 1350, loss is 4.608372411727905 and perplexity is 100.32073583417794
At time: 593.0274322032928 and batch: 1400, loss is 4.507532873153687 and perplexity is 90.69777933134192
At time: 593.4234480857849 and batch: 1450, loss is 4.582943353652954 and perplexity is 97.80183636991181
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0425555889423075 and perplexity of 154.86528174270944
Finished 48 epochs...
Completing Train Step...
At time: 594.7046344280243 and batch: 50, loss is 4.755053482055664 and perplexity is 116.16986600149998
At time: 595.1079359054565 and batch: 100, loss is 4.753630065917969 and perplexity is 116.00462557036738
At time: 595.5024199485779 and batch: 150, loss is 4.6499020385742185 and perplexity is 104.57474078461715
At time: 595.9002904891968 and batch: 200, loss is 4.676092557907104 and perplexity is 107.34978890526898
At time: 596.2844710350037 and batch: 250, loss is 4.708404865264892 and perplexity is 110.87515795653465
At time: 596.6716709136963 and batch: 300, loss is 4.727054700851441 and perplexity is 112.96236395068647
At time: 597.0605945587158 and batch: 350, loss is 4.753662042617798 and perplexity is 116.00833507476649
At time: 597.4490807056427 and batch: 400, loss is 4.646145868301391 and perplexity is 104.18267704204362
At time: 597.8459525108337 and batch: 450, loss is 4.672332963943481 and perplexity is 106.94695500733948
At time: 598.2550909519196 and batch: 500, loss is 4.652014217376709 and perplexity is 104.79585476930943
At time: 598.6488072872162 and batch: 550, loss is 4.696271362304688 and perplexity is 109.537982614823
At time: 599.035640001297 and batch: 600, loss is 4.608465194702148 and perplexity is 100.33004432225482
At time: 599.4199438095093 and batch: 650, loss is 4.7283500385284425 and perplexity is 113.108783167486
At time: 599.8111848831177 and batch: 700, loss is 4.7476068782806395 and perplexity is 115.30800797902658
At time: 600.1962292194366 and batch: 750, loss is 4.702002019882202 and perplexity is 110.16750936320886
At time: 600.5874798297882 and batch: 800, loss is 4.6368867206573485 and perplexity is 103.22248638677898
At time: 600.972268819809 and batch: 850, loss is 4.60600100517273 and perplexity is 100.08311644104974
At time: 601.3643546104431 and batch: 900, loss is 4.563326168060303 and perplexity is 95.90193587332914
At time: 601.7674899101257 and batch: 950, loss is 4.631964187622071 and perplexity is 102.71561884716654
At time: 602.162721157074 and batch: 1000, loss is 4.685492000579834 and perplexity is 108.36357413615133
At time: 602.5623433589935 and batch: 1050, loss is 4.5954594039917 and perplexity is 99.03362153969256
At time: 602.953821182251 and batch: 1100, loss is 4.707748575210571 and perplexity is 110.80241556576122
At time: 603.3403882980347 and batch: 1150, loss is 4.646519527435303 and perplexity is 104.22161312487422
At time: 603.7264277935028 and batch: 1200, loss is 4.615745038986206 and perplexity is 101.06309643714994
At time: 604.123922586441 and batch: 1250, loss is 4.598727140426636 and perplexity is 99.3577666350128
At time: 604.5335114002228 and batch: 1300, loss is 4.6647520351409915 and perplexity is 106.13926315121319
At time: 604.9340317249298 and batch: 1350, loss is 4.608382196426391 and perplexity is 100.32171744713236
At time: 605.3481466770172 and batch: 1400, loss is 4.507567176818847 and perplexity is 90.70089065095947
At time: 605.7503910064697 and batch: 1450, loss is 4.582952861785889 and perplexity is 97.80276628719412
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042554023938301 and perplexity of 154.8650393781127
Finished 49 epochs...
Completing Train Step...
At time: 607.0618615150452 and batch: 50, loss is 4.755014905929565 and perplexity is 116.16538470453632
At time: 607.4816195964813 and batch: 100, loss is 4.753617057800293 and perplexity is 116.00311657836156
At time: 607.8913955688477 and batch: 150, loss is 4.6499071788787845 and perplexity is 104.57527833201627
At time: 608.2968201637268 and batch: 200, loss is 4.676053161621094 and perplexity is 107.34555980558807
At time: 608.6843667030334 and batch: 250, loss is 4.708379926681519 and perplexity is 110.87239292164207
At time: 609.0890116691589 and batch: 300, loss is 4.7270168209075925 and perplexity is 112.95808502372631
At time: 609.4766638278961 and batch: 350, loss is 4.75364839553833 and perplexity is 116.00675191060165
At time: 609.8741836547852 and batch: 400, loss is 4.646117753982544 and perplexity is 104.1797480582163
At time: 610.2784330844879 and batch: 450, loss is 4.672306146621704 and perplexity is 106.94408701489004
At time: 610.6766593456268 and batch: 500, loss is 4.651990642547608 and perplexity is 104.79338425406381
At time: 611.0695445537567 and batch: 550, loss is 4.69625415802002 and perplexity is 109.53609810839897
At time: 611.4698541164398 and batch: 600, loss is 4.608458461761475 and perplexity is 100.32936880829274
At time: 611.8692529201508 and batch: 650, loss is 4.728343420028686 and perplexity is 113.1080345595095
At time: 612.2787044048309 and batch: 700, loss is 4.747575464248658 and perplexity is 115.30438574647091
At time: 612.6787855625153 and batch: 750, loss is 4.7019773292541505 and perplexity is 110.16478929179209
At time: 613.075989484787 and batch: 800, loss is 4.636878786087036 and perplexity is 103.22166736395218
At time: 613.4751110076904 and batch: 850, loss is 4.606009607315063 and perplexity is 100.08397737396548
At time: 613.8703982830048 and batch: 900, loss is 4.563320903778076 and perplexity is 95.90143101980152
At time: 614.2589967250824 and batch: 950, loss is 4.631952991485596 and perplexity is 102.71446883551769
At time: 614.6604382991791 and batch: 1000, loss is 4.685481567382812 and perplexity is 108.36244356353012
At time: 615.0626463890076 and batch: 1050, loss is 4.59548092842102 and perplexity is 99.03575320482112
At time: 615.4635400772095 and batch: 1100, loss is 4.707758140563965 and perplexity is 110.803475435092
At time: 615.8520927429199 and batch: 1150, loss is 4.646521701812744 and perplexity is 104.22183974224502
At time: 616.2407836914062 and batch: 1200, loss is 4.61574354171753 and perplexity is 101.06294511865461
At time: 616.6530809402466 and batch: 1250, loss is 4.598747358322144 and perplexity is 99.35977546026358
At time: 617.0404541492462 and batch: 1300, loss is 4.664755210876465 and perplexity is 106.13960022197155
At time: 617.4476878643036 and batch: 1350, loss is 4.608387937545777 and perplexity is 100.32229340774248
At time: 617.8471066951752 and batch: 1400, loss is 4.50759388923645 and perplexity is 90.70331352338769
At time: 618.2589259147644 and batch: 1450, loss is 4.582960357666016 and perplexity is 97.803499407754
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.042550893930288 and perplexity of 154.86455465005716
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc1f716f898>
SETTINGS FOR THIS RUN
{'batch_size': 20, 'lr': 24.58191061908424, 'num_layers': 1, 'wordvec_source': '', 'seq_len': 35, 'anneal': 3.5317084089400117, 'wordvec_dim': 200, 'dropout': 0.8125441635649477, 'tune_wordvecs': True, 'data': 'ptb'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.6557028293609619 and batch: 50, loss is 7.053263864517212 and perplexity is 1156.6276648069456
At time: 1.066551923751831 and batch: 100, loss is 6.597928657531738 and perplexity is 733.5741312181581
At time: 1.4796974658966064 and batch: 150, loss is 6.529693202972412 and perplexity is 685.1879656108641
At time: 1.8687803745269775 and batch: 200, loss is 6.368657779693604 and perplexity is 583.2744204841961
At time: 2.269603967666626 and batch: 250, loss is 6.3171987724304195 and perplexity is 554.0188837902888
At time: 2.6599748134613037 and batch: 300, loss is 6.397282438278198 and perplexity is 600.2117071783888
At time: 3.0550150871276855 and batch: 350, loss is 6.397377195358277 and perplexity is 600.2685841818968
At time: 3.4670886993408203 and batch: 400, loss is 6.273564395904541 and perplexity is 530.3644416022273
At time: 3.8637096881866455 and batch: 450, loss is 6.304831628799438 and perplexity is 547.2094461166602
At time: 4.263516187667847 and batch: 500, loss is 6.252931489944458 and perplexity is 519.5336020376569
At time: 4.67303729057312 and batch: 550, loss is 6.31029637336731 and perplexity is 550.2079916452735
At time: 5.072671413421631 and batch: 600, loss is 6.121236867904663 and perplexity is 455.427650120216
At time: 5.479019641876221 and batch: 650, loss is 6.330188798904419 and perplexity is 561.2625496049677
At time: 5.884402275085449 and batch: 700, loss is 6.254793567657471 and perplexity is 520.5019152365974
At time: 6.29459285736084 and batch: 750, loss is 6.185823974609375 and perplexity is 485.81309639299053
At time: 6.696443319320679 and batch: 800, loss is 6.159333353042602 and perplexity is 473.1125706258446
At time: 7.109249830245972 and batch: 850, loss is 6.103105878829956 and perplexity is 447.24470299966185
At time: 7.508739709854126 and batch: 900, loss is 6.065693140029907 and perplexity is 430.82119361860094
At time: 7.916880130767822 and batch: 950, loss is 6.087283372879028 and perplexity is 440.22386115356744
At time: 8.320135354995728 and batch: 1000, loss is 6.160723390579224 and perplexity is 473.7706721450038
At time: 8.713834047317505 and batch: 1050, loss is 5.9801725482940675 and perplexity is 395.50860660329914
At time: 9.122000694274902 and batch: 1100, loss is 6.076781072616577 and perplexity is 435.62469118632623
At time: 9.52109432220459 and batch: 1150, loss is 6.119403429031372 and perplexity is 454.5934163545113
At time: 9.937760591506958 and batch: 1200, loss is 6.070554275512695 and perplexity is 432.9205723577409
At time: 10.330720901489258 and batch: 1250, loss is 6.095457563400268 and perplexity is 443.8370823269541
At time: 10.738088846206665 and batch: 1300, loss is 6.135948781967163 and perplexity is 462.17739163640357
At time: 11.142695426940918 and batch: 1350, loss is 6.073411064147949 and perplexity is 434.15910319690425
At time: 11.546001434326172 and batch: 1400, loss is 5.99467209815979 and perplexity is 401.2850802992729
At time: 11.955536842346191 and batch: 1450, loss is 6.018386039733887 and perplexity is 410.91485999241
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.8205321222289 and perplexity of 337.15141166629274
Finished 1 epochs...
Completing Train Step...
At time: 13.25733208656311 and batch: 50, loss is 5.8719142627716066 and perplexity is 354.9277553722526
At time: 13.650618314743042 and batch: 100, loss is 5.813465414047241 and perplexity is 334.77725962693074
At time: 14.052722215652466 and batch: 150, loss is 5.663783874511719 and perplexity is 288.23723523589865
At time: 14.456019639968872 and batch: 200, loss is 5.585046615600586 and perplexity is 266.4127014380917
At time: 14.852704286575317 and batch: 250, loss is 5.563566150665284 and perplexity is 260.7510578086784
At time: 15.263710498809814 and batch: 300, loss is 5.5751250457763675 and perplexity is 263.782538467029
At time: 15.661736488342285 and batch: 350, loss is 5.589397029876709 and perplexity is 267.5742317949554
At time: 16.063713312149048 and batch: 400, loss is 5.502982778549194 and perplexity is 245.42288370213623
At time: 16.46920609474182 and batch: 450, loss is 5.49921347618103 and perplexity is 244.49955189697283
At time: 16.863805532455444 and batch: 500, loss is 5.466294441223145 and perplexity is 236.5818983505082
At time: 17.257338762283325 and batch: 550, loss is 5.529449577331543 and perplexity is 252.00516348756946
At time: 17.655078172683716 and batch: 600, loss is 5.3579937362670895 and perplexity is 212.2985919372072
At time: 18.062215328216553 and batch: 650, loss is 5.519980678558349 and perplexity is 249.63021392748513
At time: 18.486767053604126 and batch: 700, loss is 5.52905951499939 and perplexity is 251.90688493441178
At time: 18.88204336166382 and batch: 750, loss is 5.48253999710083 and perplexity is 240.45669166684985
At time: 19.28151559829712 and batch: 800, loss is 5.412287759780884 and perplexity is 224.1437887056308
At time: 19.681760549545288 and batch: 850, loss is 5.363797988891601 and perplexity is 213.5344096261821
At time: 20.095204830169678 and batch: 900, loss is 5.356973495483398 and perplexity is 212.08210670770086
At time: 20.494479417800903 and batch: 950, loss is 5.396651878356933 and perplexity is 220.66636018030584
At time: 20.8986873626709 and batch: 1000, loss is 5.470636758804321 and perplexity is 237.61144578031852
At time: 21.31719994544983 and batch: 1050, loss is 5.343242549896241 and perplexity is 209.1899205068134
At time: 21.70628023147583 and batch: 1100, loss is 5.41303713798523 and perplexity is 224.3118201272054
At time: 22.108464002609253 and batch: 1150, loss is 5.425570268630981 and perplexity is 227.14084068473733
At time: 22.50158429145813 and batch: 1200, loss is 5.384879493713379 and perplexity is 218.08382205235748
At time: 22.89640498161316 and batch: 1250, loss is 5.381992015838623 and perplexity is 217.45501810696817
At time: 23.28923749923706 and batch: 1300, loss is 5.470868129730224 and perplexity is 237.66642852099233
At time: 23.67680072784424 and batch: 1350, loss is 5.406671342849731 and perplexity is 222.88843233803686
At time: 24.074817419052124 and batch: 1400, loss is 5.275575122833252 and perplexity is 195.50288235747888
At time: 24.459571838378906 and batch: 1450, loss is 5.3373300743103025 and perplexity is 207.95673937804605
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.491945967715011 and perplexity of 242.72909054753052
Finished 2 epochs...
Completing Train Step...
At time: 25.79326605796814 and batch: 50, loss is 5.436561889648438 and perplexity is 229.65125822746614
At time: 26.216955184936523 and batch: 100, loss is 5.43331582069397 and perplexity is 228.9070030131679
At time: 26.614043951034546 and batch: 150, loss is 5.362122116088867 and perplexity is 213.17685281019794
At time: 27.017935752868652 and batch: 200, loss is 5.360896482467651 and perplexity is 212.91573614149988
At time: 27.414883613586426 and batch: 250, loss is 5.388500118255616 and perplexity is 218.8748528393556
At time: 27.820894956588745 and batch: 300, loss is 5.414989109039307 and perplexity is 224.75009792080428
At time: 28.224182844161987 and batch: 350, loss is 5.4491989803314205 and perplexity is 232.57179669141647
At time: 28.62608051300049 and batch: 400, loss is 5.305028209686279 and perplexity is 201.34668226032238
At time: 29.03638482093811 and batch: 450, loss is 5.373241949081421 and perplexity is 215.5605725315962
At time: 29.43396544456482 and batch: 500, loss is 5.359003677368164 and perplexity is 212.5131093176308
At time: 29.826673984527588 and batch: 550, loss is 5.422397232055664 and perplexity is 226.42125672634634
At time: 30.225892543792725 and batch: 600, loss is 5.288236627578735 and perplexity is 197.99398027458125
At time: 30.61410140991211 and batch: 650, loss is 5.430396394729614 and perplexity is 228.23970050923066
At time: 31.017542600631714 and batch: 700, loss is 5.453031568527222 and perplexity is 233.46485889075163
At time: 31.42353630065918 and batch: 750, loss is 5.429520130157471 and perplexity is 228.03978974586911
At time: 31.822445392608643 and batch: 800, loss is 5.350841236114502 and perplexity is 210.78554371520542
At time: 32.226019859313965 and batch: 850, loss is 5.302883958816528 and perplexity is 200.91540700817495
At time: 32.63229417800903 and batch: 900, loss is 5.280849876403809 and perplexity is 196.53683641336252
At time: 33.0372097492218 and batch: 950, loss is 5.342582387924194 and perplexity is 209.0518668502603
At time: 33.43467569351196 and batch: 1000, loss is 5.383568124771118 and perplexity is 217.79802113748755
At time: 33.833651542663574 and batch: 1050, loss is 5.259685049057007 and perplexity is 192.42087861556448
At time: 34.2305064201355 and batch: 1100, loss is 5.388225536346436 and perplexity is 218.8147620146958
At time: 34.624131202697754 and batch: 1150, loss is 5.360380430221557 and perplexity is 212.80588884354552
At time: 35.02188420295715 and batch: 1200, loss is 5.2875312805175785 and perplexity is 197.85437504332563
At time: 35.41285157203674 and batch: 1250, loss is 5.304932861328125 and perplexity is 201.32748509997253
At time: 35.81186556816101 and batch: 1300, loss is 5.395225267410279 and perplexity is 220.35177958073106
At time: 36.21214318275452 and batch: 1350, loss is 5.350168685913086 and perplexity is 210.6438275162951
At time: 36.61852478981018 and batch: 1400, loss is 5.222425842285157 and perplexity is 185.3833498167354
At time: 37.015055656433105 and batch: 1450, loss is 5.305374460220337 and perplexity is 201.41641072764867
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.492556319277511 and perplexity of 242.8772858482265
Annealing...
Finished 3 epochs...
Completing Train Step...
At time: 38.43854594230652 and batch: 50, loss is 5.330981731414795 and perplexity is 206.64074031541278
At time: 38.83656048774719 and batch: 100, loss is 5.265208444595337 and perplexity is 193.48663582780713
At time: 39.252455949783325 and batch: 150, loss is 5.169831075668335 and perplexity is 175.8851236974748
At time: 39.65450882911682 and batch: 200, loss is 5.2096875 and perplexity is 183.03685023974106
At time: 40.06841588020325 and batch: 250, loss is 5.209885883331299 and perplexity is 183.07316530187438
At time: 40.47508430480957 and batch: 300, loss is 5.225787010192871 and perplexity is 186.00750273653455
At time: 40.876893043518066 and batch: 350, loss is 5.270008478164673 and perplexity is 194.41761074292475
At time: 41.281314849853516 and batch: 400, loss is 5.144383974075318 and perplexity is 171.4658247365394
At time: 41.676926612854004 and batch: 450, loss is 5.1814772605896 and perplexity is 177.9454887814962
At time: 42.07254910469055 and batch: 500, loss is 5.154911708831787 and perplexity is 173.28050694508917
At time: 42.46143698692322 and batch: 550, loss is 5.221276597976685 and perplexity is 185.17042143387476
At time: 42.85123944282532 and batch: 600, loss is 5.08682071685791 and perplexity is 161.8743985390324
At time: 43.27167773246765 and batch: 650, loss is 5.2199524402618405 and perplexity is 184.92538885846292
At time: 43.66752338409424 and batch: 700, loss is 5.252594490051269 and perplexity is 191.06133268815714
At time: 44.0707483291626 and batch: 750, loss is 5.186702260971069 and perplexity is 178.87768727620605
At time: 44.467536211013794 and batch: 800, loss is 5.111024074554443 and perplexity is 165.84010056987074
At time: 44.86045956611633 and batch: 850, loss is 5.073593349456787 and perplexity is 159.74732520020626
At time: 45.25095510482788 and batch: 900, loss is 5.020296277999878 and perplexity is 151.45617027844776
At time: 45.64548063278198 and batch: 950, loss is 5.081308002471924 and perplexity is 160.98448638295878
At time: 46.03967046737671 and batch: 1000, loss is 5.126240196228028 and perplexity is 168.38283997466058
At time: 46.42696976661682 and batch: 1050, loss is 5.017440156936646 and perplexity is 151.02421027902548
At time: 46.83042764663696 and batch: 1100, loss is 5.139564533233642 and perplexity is 170.64144346190332
At time: 47.23014974594116 and batch: 1150, loss is 5.103159074783325 and perplexity is 164.54088408279478
At time: 47.63225984573364 and batch: 1200, loss is 5.041660394668579 and perplexity is 154.7267092631931
At time: 48.03866934776306 and batch: 1250, loss is 5.045398254394531 and perplexity is 155.3061382357586
At time: 48.43397808074951 and batch: 1300, loss is 5.113857669830322 and perplexity is 166.3106907115237
At time: 48.85283851623535 and batch: 1350, loss is 5.065385341644287 and perplexity is 158.44148441397576
At time: 49.2486846446991 and batch: 1400, loss is 4.9412314891815186 and perplexity is 139.94248113913073
At time: 49.64894342422485 and batch: 1450, loss is 5.027357692718506 and perplexity is 152.5294500855988
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.24518552600828 and perplexity of 189.65099715830644
Finished 4 epochs...
Completing Train Step...
At time: 50.95701050758362 and batch: 50, loss is 5.14710638999939 and perplexity is 171.93326201888402
At time: 51.359230041503906 and batch: 100, loss is 5.155050249099731 and perplexity is 173.30451493594916
At time: 51.76122975349426 and batch: 150, loss is 5.058000535964966 and perplexity is 157.27573455599824
At time: 52.148571491241455 and batch: 200, loss is 5.108151130676269 and perplexity is 165.36433501928548
At time: 52.548927783966064 and batch: 250, loss is 5.139402952194214 and perplexity is 170.6138732675695
At time: 52.95040225982666 and batch: 300, loss is 5.150037183761596 and perplexity is 172.43790208748808
At time: 53.34868574142456 and batch: 350, loss is 5.180727710723877 and perplexity is 177.81215973889937
At time: 53.74272966384888 and batch: 400, loss is 5.040828733444214 and perplexity is 154.59808255306277
At time: 54.132365226745605 and batch: 450, loss is 5.083304319381714 and perplexity is 161.30618343313174
At time: 54.52677321434021 and batch: 500, loss is 5.066524133682251 and perplexity is 158.62201909112557
At time: 54.91250395774841 and batch: 550, loss is 5.149726228713989 and perplexity is 172.38428998734378
At time: 55.3066885471344 and batch: 600, loss is 5.011037979125977 and perplexity is 150.06041491773323
At time: 55.70114040374756 and batch: 650, loss is 5.139273042678833 and perplexity is 170.59171034159473
At time: 56.08878207206726 and batch: 700, loss is 5.167908763885498 and perplexity is 175.54734241625022
At time: 56.47506880760193 and batch: 750, loss is 5.111577672958374 and perplexity is 165.93193480215078
At time: 56.8584418296814 and batch: 800, loss is 5.0388838481903075 and perplexity is 154.29769922226367
At time: 57.25912642478943 and batch: 850, loss is 5.017235679626465 and perplexity is 150.99333241175466
At time: 57.65992712974548 and batch: 900, loss is 4.956607007980347 and perplexity is 142.11079615596552
At time: 58.067962408065796 and batch: 950, loss is 5.012585306167603 and perplexity is 150.29278718719868
At time: 58.4582245349884 and batch: 1000, loss is 5.067461080551148 and perplexity is 158.77070914171216
At time: 58.857096433639526 and batch: 1050, loss is 4.966079788208008 and perplexity is 143.46337673088414
At time: 59.263532638549805 and batch: 1100, loss is 5.0625535583496095 and perplexity is 157.99344713686742
At time: 59.65104866027832 and batch: 1150, loss is 5.044434614181519 and perplexity is 155.15655108130127
At time: 60.06232690811157 and batch: 1200, loss is 4.9870325756073 and perplexity is 146.5010470612428
At time: 60.464009284973145 and batch: 1250, loss is 4.996410112380982 and perplexity is 147.88132771882033
At time: 60.8625111579895 and batch: 1300, loss is 5.052013473510742 and perplexity is 156.33692806152013
At time: 61.25411677360535 and batch: 1350, loss is 5.009610862731933 and perplexity is 149.84641397795255
At time: 61.652700901031494 and batch: 1400, loss is 4.903214912414551 and perplexity is 134.72220429596763
At time: 62.0566029548645 and batch: 1450, loss is 4.981537590026855 and perplexity is 145.69823366421073
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.216991457164797 and perplexity of 184.3786377676742
Finished 5 epochs...
Completing Train Step...
At time: 63.33851146697998 and batch: 50, loss is 5.06998833656311 and perplexity is 159.1724708344023
At time: 63.752697467803955 and batch: 100, loss is 5.096703252792358 and perplexity is 163.48205889582508
At time: 64.14791226387024 and batch: 150, loss is 5.00180832862854 and perplexity is 148.681781672775
At time: 64.54800868034363 and batch: 200, loss is 5.054279336929321 and perplexity is 156.69156781868324
At time: 64.93499255180359 and batch: 250, loss is 5.077004547119141 and perplexity is 160.29318539168648
At time: 65.33629870414734 and batch: 300, loss is 5.097224950790405 and perplexity is 163.56736940989492
At time: 65.7397677898407 and batch: 350, loss is 5.12848973274231 and perplexity is 168.76204968469352
At time: 66.13420224189758 and batch: 400, loss is 4.984648036956787 and perplexity is 146.15212582560204
At time: 66.53271055221558 and batch: 450, loss is 5.022150182723999 and perplexity is 151.7372160235462
At time: 66.92987847328186 and batch: 500, loss is 5.033406782150268 and perplexity is 153.45491064499265
At time: 67.32029747962952 and batch: 550, loss is 5.098228635787964 and perplexity is 163.73162193977308
At time: 67.71875 and batch: 600, loss is 4.968327751159668 and perplexity is 143.786239842891
At time: 68.11560201644897 and batch: 650, loss is 5.08965874671936 and perplexity is 162.33445543470367
At time: 68.51308512687683 and batch: 700, loss is 5.1230129051208495 and perplexity is 167.84029547802533
At time: 68.90199327468872 and batch: 750, loss is 5.050155582427979 and perplexity is 156.04674072866842
At time: 69.31662178039551 and batch: 800, loss is 4.976091794967651 and perplexity is 144.90694748993258
At time: 69.71281313896179 and batch: 850, loss is 4.960191736221313 and perplexity is 142.6211389138367
At time: 70.10477828979492 and batch: 900, loss is 4.9130573558807376 and perplexity is 136.05474695594586
At time: 70.4991397857666 and batch: 950, loss is 4.985359830856323 and perplexity is 146.2561930499829
At time: 70.88958430290222 and batch: 1000, loss is 5.033924551010132 and perplexity is 153.53438539211683
At time: 71.28248858451843 and batch: 1050, loss is 4.935150699615479 and perplexity is 139.09410238046232
At time: 71.6700439453125 and batch: 1100, loss is 5.038762502670288 and perplexity is 154.27897702366414
At time: 72.05909466743469 and batch: 1150, loss is 4.999951667785645 and perplexity is 148.40598613930172
At time: 72.44769763946533 and batch: 1200, loss is 4.938266687393188 and perplexity is 139.52819386408012
At time: 72.83795952796936 and batch: 1250, loss is 4.966188097000122 and perplexity is 143.47891591743058
At time: 73.23941898345947 and batch: 1300, loss is 5.030949869155884 and perplexity is 153.07834806115375
At time: 73.63606905937195 and batch: 1350, loss is 4.980612382888794 and perplexity is 145.56349495863927
At time: 74.03240847587585 and batch: 1400, loss is 4.862619333267212 and perplexity is 129.36260249044625
At time: 74.43249917030334 and batch: 1450, loss is 4.954981327056885 and perplexity is 141.87995703185618
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.196338099292201 and perplexity of 180.60965482872558
Finished 6 epochs...
Completing Train Step...
At time: 75.71329617500305 and batch: 50, loss is 5.013706684112549 and perplexity is 150.46141673509197
At time: 76.1138174533844 and batch: 100, loss is 5.030472631454468 and perplexity is 153.00531073165834
At time: 76.50189232826233 and batch: 150, loss is 4.9396429443359375 and perplexity is 139.72035270923683
At time: 76.9089002609253 and batch: 200, loss is 4.99165020942688 and perplexity is 147.17909954498046
At time: 77.3062915802002 and batch: 250, loss is 5.01561671257019 and perplexity is 150.74907695498237
At time: 77.70972418785095 and batch: 300, loss is 5.026870088577271 and perplexity is 152.45509422366302
At time: 78.10633039474487 and batch: 350, loss is 5.062365198135376 and perplexity is 157.96369025991112
At time: 78.49831962585449 and batch: 400, loss is 4.941835670471192 and perplexity is 140.02705731496417
At time: 78.89630150794983 and batch: 450, loss is 4.986731548309326 and perplexity is 146.45695288400407
At time: 79.28893423080444 and batch: 500, loss is 4.978483867645264 and perplexity is 145.25399035020962
At time: 79.71041536331177 and batch: 550, loss is 5.045838317871094 and perplexity is 155.37449783506045
At time: 80.10368537902832 and batch: 600, loss is 4.920565633773804 and perplexity is 137.08012841213477
At time: 80.5119776725769 and batch: 650, loss is 5.038217353820801 and perplexity is 154.19489493754824
At time: 80.90993452072144 and batch: 700, loss is 5.08404881477356 and perplexity is 161.4263198583324
At time: 81.31296420097351 and batch: 750, loss is 5.012582740783691 and perplexity is 150.29240162899495
At time: 81.7118353843689 and batch: 800, loss is 4.958396482467651 and perplexity is 142.36532747078206
At time: 82.10379767417908 and batch: 850, loss is 4.925980701446533 and perplexity is 137.82444001413614
At time: 82.51537847518921 and batch: 900, loss is 4.881091566085815 and perplexity is 131.77442590297792
At time: 82.91046404838562 and batch: 950, loss is 4.945818614959717 and perplexity is 140.5858894711006
At time: 83.30448389053345 and batch: 1000, loss is 4.98525188446045 and perplexity is 146.2404060731579
At time: 83.69385743141174 and batch: 1050, loss is 4.89565710067749 and perplexity is 133.7078372650491
At time: 84.09194469451904 and batch: 1100, loss is 4.996714029312134 and perplexity is 147.92627818837371
At time: 84.49033308029175 and batch: 1150, loss is 4.969327411651611 and perplexity is 143.93004913440458
At time: 84.88388991355896 and batch: 1200, loss is 4.921395454406738 and perplexity is 137.19392754095884
At time: 85.28277111053467 and batch: 1250, loss is 4.930824689865112 and perplexity is 138.4936795911435
At time: 85.67727041244507 and batch: 1300, loss is 4.995514516830444 and perplexity is 147.7489451491765
At time: 86.07467341423035 and batch: 1350, loss is 4.96014009475708 and perplexity is 142.6137739395633
At time: 86.4731547832489 and batch: 1400, loss is 4.843049802780151 and perplexity is 126.85564707351077
At time: 86.86576342582703 and batch: 1450, loss is 4.920503711700439 and perplexity is 137.07164038916707
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.21071057441907 and perplexity of 183.22420638226498
Annealing...
Finished 7 epochs...
Completing Train Step...
At time: 88.17183446884155 and batch: 50, loss is 4.9975149440765385 and perplexity is 148.0448019860122
At time: 88.56714200973511 and batch: 100, loss is 4.9775111198425295 and perplexity is 145.1127635504238
At time: 88.96932697296143 and batch: 150, loss is 4.877046298980713 and perplexity is 131.24243989079628
At time: 89.36235165596008 and batch: 200, loss is 4.914741058349609 and perplexity is 136.2840156252476
At time: 89.77807092666626 and batch: 250, loss is 4.926475667953492 and perplexity is 137.8926753815011
At time: 90.19076442718506 and batch: 300, loss is 4.928351669311524 and perplexity is 138.1516050280244
At time: 90.58963632583618 and batch: 350, loss is 4.961347923278809 and perplexity is 142.78613099124672
At time: 90.99558162689209 and batch: 400, loss is 4.824370222091675 and perplexity is 124.50803127930143
At time: 91.3859634399414 and batch: 450, loss is 4.876201171875 and perplexity is 131.1315702035125
At time: 91.78029441833496 and batch: 500, loss is 4.871856546401977 and perplexity is 130.56308845763658
At time: 92.1685380935669 and batch: 550, loss is 4.920748519897461 and perplexity is 137.10520075807264
At time: 92.59440088272095 and batch: 600, loss is 4.810828714370728 and perplexity is 122.83336912813219
At time: 93.01026463508606 and batch: 650, loss is 4.919354801177978 and perplexity is 136.91424777152343
At time: 93.40361428260803 and batch: 700, loss is 4.965447626113892 and perplexity is 143.372713282238
At time: 93.80276679992676 and batch: 750, loss is 4.882713718414307 and perplexity is 131.98835756275082
At time: 94.1982672214508 and batch: 800, loss is 4.828194751739502 and perplexity is 124.98512768946273
At time: 94.59553122520447 and batch: 850, loss is 4.793330612182618 and perplexity is 120.70271385886039
At time: 94.98233604431152 and batch: 900, loss is 4.741081972122192 and perplexity is 114.55808330234743
At time: 95.3794355392456 and batch: 950, loss is 4.8113964080810545 and perplexity is 122.90312065608305
At time: 95.77460360527039 and batch: 1000, loss is 4.851034002304077 and perplexity is 127.87254201450239
At time: 96.16185522079468 and batch: 1050, loss is 4.770456142425537 and perplexity is 117.97304219906893
At time: 96.56105732917786 and batch: 1100, loss is 4.876250219345093 and perplexity is 131.13800203301156
At time: 96.95428395271301 and batch: 1150, loss is 4.821226873397827 and perplexity is 124.11727358739098
At time: 97.34838724136353 and batch: 1200, loss is 4.760930013656616 and perplexity is 116.85455170834395
At time: 97.73498249053955 and batch: 1250, loss is 4.762915620803833 and perplexity is 117.08680945140915
At time: 98.13113641738892 and batch: 1300, loss is 4.8250734329223635 and perplexity is 124.59561746757353
At time: 98.53827476501465 and batch: 1350, loss is 4.779103937149048 and perplexity is 118.99767286321952
At time: 98.94212484359741 and batch: 1400, loss is 4.667604446411133 and perplexity is 106.44244818026137
At time: 99.35297322273254 and batch: 1450, loss is 4.761846971511841 and perplexity is 116.96175154880832
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.1052835578592415 and perplexity of 164.89081999116493
Finished 8 epochs...
Completing Train Step...
At time: 100.66952085494995 and batch: 50, loss is 4.912274122238159 and perplexity is 135.94822602173264
At time: 101.06654691696167 and batch: 100, loss is 4.912590227127075 and perplexity is 135.99120671346304
At time: 101.46411895751953 and batch: 150, loss is 4.822566928863526 and perplexity is 124.28370910975873
At time: 101.86201119422913 and batch: 200, loss is 4.872084665298462 and perplexity is 130.59287576269156
At time: 102.25471687316895 and batch: 250, loss is 4.887876234054565 and perplexity is 132.67151140193096
At time: 102.65193247795105 and batch: 300, loss is 4.890298042297363 and perplexity is 132.99320574560295
At time: 103.06527519226074 and batch: 350, loss is 4.923850622177124 and perplexity is 137.53117548087974
At time: 103.46938943862915 and batch: 400, loss is 4.789082107543945 and perplexity is 120.19099560751334
At time: 103.87554860115051 and batch: 450, loss is 4.844981098175049 and perplexity is 127.10087953245552
At time: 104.26215767860413 and batch: 500, loss is 4.840160970687866 and perplexity is 126.48971122725393
At time: 104.65186500549316 and batch: 550, loss is 4.889664754867554 and perplexity is 132.90900948318546
At time: 105.05692648887634 and batch: 600, loss is 4.782431859970092 and perplexity is 119.39434761977961
At time: 105.45336723327637 and batch: 650, loss is 4.892462892532349 and perplexity is 133.28142798473917
At time: 105.85613059997559 and batch: 700, loss is 4.93812931060791 and perplexity is 139.50902724590577
At time: 106.24946928024292 and batch: 750, loss is 4.8605023288726805 and perplexity is 129.08903097071303
At time: 106.64308452606201 and batch: 800, loss is 4.800737457275391 and perplexity is 121.60005930960267
At time: 107.03943276405334 and batch: 850, loss is 4.772722158432007 and perplexity is 118.24067411560696
At time: 107.45583248138428 and batch: 900, loss is 4.72278130531311 and perplexity is 112.48066107510762
At time: 107.85351967811584 and batch: 950, loss is 4.796580944061279 and perplexity is 121.09567602031794
At time: 108.24289417266846 and batch: 1000, loss is 4.836341848373413 and perplexity is 126.00755284552574
At time: 108.64844179153442 and batch: 1050, loss is 4.755908508300781 and perplexity is 116.26923676207319
At time: 109.03730297088623 and batch: 1100, loss is 4.8641273784637455 and perplexity is 129.55783431395022
At time: 109.43298530578613 and batch: 1150, loss is 4.809397029876709 and perplexity is 122.6576363251848
At time: 109.86192631721497 and batch: 1200, loss is 4.751421880722046 and perplexity is 115.7487484894884
At time: 110.25862646102905 and batch: 1250, loss is 4.755572090148926 and perplexity is 116.23012825909807
At time: 110.66479110717773 and batch: 1300, loss is 4.817170467376709 and perplexity is 123.61482329164969
At time: 111.06030631065369 and batch: 1350, loss is 4.77208179473877 and perplexity is 118.16498131888547
At time: 111.45912265777588 and batch: 1400, loss is 4.66465280532837 and perplexity is 106.12873149455467
At time: 111.85170555114746 and batch: 1450, loss is 4.757102842330933 and perplexity is 116.40818402640443
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.100809733072917 and perplexity of 164.15477504937118
Finished 9 epochs...
Completing Train Step...
At time: 113.18170928955078 and batch: 50, loss is 4.894986610412598 and perplexity is 133.61821750976728
At time: 113.59467482566833 and batch: 100, loss is 4.895493774414063 and perplexity is 133.68600104686013
At time: 113.99790120124817 and batch: 150, loss is 4.80407530784607 and perplexity is 122.00662027938006
At time: 114.39179348945618 and batch: 200, loss is 4.847684707641601 and perplexity is 127.44497561468161
At time: 114.78380250930786 and batch: 250, loss is 4.866145353317261 and perplexity is 129.81954273736918
At time: 115.18222212791443 and batch: 300, loss is 4.869558334350586 and perplexity is 130.2633713329503
At time: 115.58191514015198 and batch: 350, loss is 4.901580848693848 and perplexity is 134.50223939683033
At time: 115.97434544563293 and batch: 400, loss is 4.769582405090332 and perplexity is 117.87000976574839
At time: 116.3666021823883 and batch: 450, loss is 4.82904275894165 and perplexity is 125.0911609300265
At time: 116.75236225128174 and batch: 500, loss is 4.823048238754272 and perplexity is 124.3435424862548
At time: 117.16870665550232 and batch: 550, loss is 4.870994758605957 and perplexity is 130.45061925064883
At time: 117.56616067886353 and batch: 600, loss is 4.762862300872802 and perplexity is 117.08056655724145
At time: 117.96851539611816 and batch: 650, loss is 4.873619918823242 and perplexity is 130.79352291823332
At time: 118.36630821228027 and batch: 700, loss is 4.9200393581390385 and perplexity is 137.00800546048166
At time: 118.7682626247406 and batch: 750, loss is 4.8473790168762205 and perplexity is 127.40602281660068
At time: 119.16511130332947 and batch: 800, loss is 4.787577819824219 and perplexity is 120.01032968962893
At time: 119.55558443069458 and batch: 850, loss is 4.758014354705811 and perplexity is 116.51433990052803
At time: 119.97418808937073 and batch: 900, loss is 4.706481828689575 and perplexity is 110.66214585316746
At time: 120.36757564544678 and batch: 950, loss is 4.784922122955322 and perplexity is 119.69204145843305
At time: 120.76226329803467 and batch: 1000, loss is 4.823741436004639 and perplexity is 124.42976696984181
At time: 121.14977979660034 and batch: 1050, loss is 4.7418587779998775 and perplexity is 114.64710726748615
At time: 121.54725289344788 and batch: 1100, loss is 4.849802160263062 and perplexity is 127.71512022065579
At time: 121.9608805179596 and batch: 1150, loss is 4.796458978652954 and perplexity is 121.08090743739207
At time: 122.37456607818604 and batch: 1200, loss is 4.74295931816101 and perplexity is 114.77335046850608
At time: 122.79047656059265 and batch: 1250, loss is 4.744139728546142 and perplexity is 114.90891011560272
At time: 123.18812203407288 and batch: 1300, loss is 4.80698413848877 and perplexity is 122.36203354295225
At time: 123.60020899772644 and batch: 1350, loss is 4.761761102676392 and perplexity is 116.9517086106046
At time: 123.99873352050781 and batch: 1400, loss is 4.657214145660401 and perplexity is 105.34220495836388
At time: 124.40139245986938 and batch: 1450, loss is 4.745788803100586 and perplexity is 115.09855980561376
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.096646300747863 and perplexity of 163.4727485234575
Finished 10 epochs...
Completing Train Step...
At time: 125.6655433177948 and batch: 50, loss is 4.8771788692474365 and perplexity is 131.25983988939376
At time: 126.0632050037384 and batch: 100, loss is 4.877499160766601 and perplexity is 131.30188803639024
At time: 126.46888017654419 and batch: 150, loss is 4.785993585586548 and perplexity is 119.82035573781279
At time: 126.86639189720154 and batch: 200, loss is 4.8284126663208005 and perplexity is 125.01236673901701
At time: 127.26972818374634 and batch: 250, loss is 4.847824621200561 and perplexity is 127.46280814226854
At time: 127.67191553115845 and batch: 300, loss is 4.851078071594238 and perplexity is 127.87817739083268
At time: 128.0674488544464 and batch: 350, loss is 4.8834234237670895 and perplexity is 132.08206365454245
At time: 128.4540615081787 and batch: 400, loss is 4.7517266273498535 and perplexity is 115.78402790563203
At time: 128.83885526657104 and batch: 450, loss is 4.812280921936035 and perplexity is 123.0118782608372
At time: 129.23873662948608 and batch: 500, loss is 4.80614068031311 and perplexity is 122.25886979863795
At time: 129.63424396514893 and batch: 550, loss is 4.855008478164673 and perplexity is 128.38177965197502
At time: 130.02699375152588 and batch: 600, loss is 4.746485776901245 and perplexity is 115.1788084486442
At time: 130.4436480998993 and batch: 650, loss is 4.859625282287598 and perplexity is 128.97586351074983
At time: 130.84369564056396 and batch: 700, loss is 4.906645021438599 and perplexity is 135.18510959862576
At time: 131.24366688728333 and batch: 750, loss is 4.832975330352784 and perplexity is 125.58405939726826
At time: 131.64317965507507 and batch: 800, loss is 4.773796949386597 and perplexity is 118.36782644145559
At time: 132.03827810287476 and batch: 850, loss is 4.7451028156280515 and perplexity is 115.01963071076067
At time: 132.42709922790527 and batch: 900, loss is 4.693635625839233 and perplexity is 109.24964951165327
At time: 132.82088375091553 and batch: 950, loss is 4.774794101715088 and perplexity is 118.48591606209537
At time: 133.20765256881714 and batch: 1000, loss is 4.809372425079346 and perplexity is 122.6546183960259
At time: 133.59439992904663 and batch: 1050, loss is 4.730523633956909 and perplexity is 113.3549032873821
At time: 134.00182938575745 and batch: 1100, loss is 4.837091407775879 and perplexity is 126.10203839838624
At time: 134.3973424434662 and batch: 1150, loss is 4.783916215896607 and perplexity is 119.57170292389566
At time: 134.79248189926147 and batch: 1200, loss is 4.732484045028687 and perplexity is 113.57734346067588
At time: 135.19365859031677 and batch: 1250, loss is 4.735103302001953 and perplexity is 113.87522164900166
At time: 135.6037278175354 and batch: 1300, loss is 4.795882358551025 and perplexity is 121.01110987747589
At time: 136.0100998878479 and batch: 1350, loss is 4.750353918075562 and perplexity is 115.62519913451519
At time: 136.39897346496582 and batch: 1400, loss is 4.64897385597229 and perplexity is 104.47772136245493
At time: 136.79585528373718 and batch: 1450, loss is 4.734221725463867 and perplexity is 113.77487616293858
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.093958145532852 and perplexity of 163.03389851473918
Finished 11 epochs...
Completing Train Step...
At time: 138.0638885498047 and batch: 50, loss is 4.862918138504028 and perplexity is 129.401262489136
At time: 138.46313190460205 and batch: 100, loss is 4.86250018119812 and perplexity is 129.34718958695439
At time: 138.85890674591064 and batch: 150, loss is 4.770295972824097 and perplexity is 117.95414801709636
At time: 139.26747059822083 and batch: 200, loss is 4.812542495727539 and perplexity is 123.0440591528893
At time: 139.66496396064758 and batch: 250, loss is 4.831622362136841 and perplexity is 125.41426304690864
At time: 140.05520582199097 and batch: 300, loss is 4.835985097885132 and perplexity is 125.96260760711552
At time: 140.47089099884033 and batch: 350, loss is 4.86852650642395 and perplexity is 130.1290312684253
At time: 140.86306953430176 and batch: 400, loss is 4.737561292648316 and perplexity is 114.15547016168028
At time: 141.24907732009888 and batch: 450, loss is 4.799234294891358 and perplexity is 121.4174119832385
At time: 141.6365361213684 and batch: 500, loss is 4.793366432189941 and perplexity is 120.70703750839094
At time: 142.02629709243774 and batch: 550, loss is 4.840798397064209 and perplexity is 126.57036480815515
At time: 142.42573595046997 and batch: 600, loss is 4.731870565414429 and perplexity is 113.50768744427883
At time: 142.81809973716736 and batch: 650, loss is 4.846146163940429 and perplexity is 127.24904671144247
At time: 143.22760009765625 and batch: 700, loss is 4.893773937225342 and perplexity is 133.4562804882513
At time: 143.61451363563538 and batch: 750, loss is 4.821657772064209 and perplexity is 124.17076707936423
At time: 144.0112795829773 and batch: 800, loss is 4.762543821334839 and perplexity is 117.04328472956459
At time: 144.41490173339844 and batch: 850, loss is 4.734994850158691 and perplexity is 113.86287234097672
At time: 144.8111891746521 and batch: 900, loss is 4.683223524093628 and perplexity is 108.11803252424485
At time: 145.21159720420837 and batch: 950, loss is 4.769147253036499 and perplexity is 117.81872954706894
At time: 145.6069622039795 and batch: 1000, loss is 4.802009267807007 and perplexity is 121.75480993155402
At time: 146.00495886802673 and batch: 1050, loss is 4.722879037857056 and perplexity is 112.49165463346466
At time: 146.39971375465393 and batch: 1100, loss is 4.82750168800354 and perplexity is 124.8985350405052
At time: 146.79668807983398 and batch: 1150, loss is 4.77119631767273 and perplexity is 118.06039524903522
At time: 147.1930615901947 and batch: 1200, loss is 4.721310930252075 and perplexity is 112.31539384839402
At time: 147.58442306518555 and batch: 1250, loss is 4.725781450271606 and perplexity is 112.81862608186778
At time: 147.98114204406738 and batch: 1300, loss is 4.7842018604278564 and perplexity is 119.60586280548748
At time: 148.3692433834076 and batch: 1350, loss is 4.736283597946167 and perplexity is 114.00970746217767
At time: 148.77204418182373 and batch: 1400, loss is 4.640602817535401 and perplexity is 103.60678474891427
At time: 149.17138481140137 and batch: 1450, loss is 4.723205804824829 and perplexity is 112.52841919674431
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0929200262086 and perplexity of 162.8647376939333
Finished 12 epochs...
Completing Train Step...
At time: 150.47642540931702 and batch: 50, loss is 4.851551828384399 and perplexity is 127.93877489879198
At time: 150.8795816898346 and batch: 100, loss is 4.852442331314087 and perplexity is 128.0527554951554
At time: 151.2746500968933 and batch: 150, loss is 4.758711538314819 and perplexity is 116.59560011187335
At time: 151.6792278289795 and batch: 200, loss is 4.799086666107177 and perplexity is 121.39948860136516
At time: 152.0784091949463 and batch: 250, loss is 4.818900156021118 and perplexity is 123.82882347126397
At time: 152.47891855239868 and batch: 300, loss is 4.823237018585205 and perplexity is 124.36701825498905
At time: 152.8739993572235 and batch: 350, loss is 4.856829080581665 and perplexity is 128.61572472617152
At time: 153.26948022842407 and batch: 400, loss is 4.725250768661499 and perplexity is 112.75877119507712
At time: 153.66362404823303 and batch: 450, loss is 4.788131866455078 and perplexity is 120.07683943150964
At time: 154.05276536941528 and batch: 500, loss is 4.782109498977661 and perplexity is 119.35586574225158
At time: 154.4498872756958 and batch: 550, loss is 4.8302390766143795 and perplexity is 125.24089924598765
At time: 154.83477759361267 and batch: 600, loss is 4.7210656261444095 and perplexity is 112.28784579989178
At time: 155.22999548912048 and batch: 650, loss is 4.835529308319092 and perplexity is 125.90520824686548
At time: 155.6335461139679 and batch: 700, loss is 4.882351007461548 and perplexity is 131.94049262092025
At time: 156.02937507629395 and batch: 750, loss is 4.810757713317871 and perplexity is 122.82464813920153
At time: 156.43451261520386 and batch: 800, loss is 4.752253646850586 and perplexity is 115.84506442851783
At time: 156.83417201042175 and batch: 850, loss is 4.72439248085022 and perplexity is 112.6620332365895
At time: 157.24548172950745 and batch: 900, loss is 4.672698221206665 and perplexity is 106.98602529434996
At time: 157.63975763320923 and batch: 950, loss is 4.759540662765503 and perplexity is 116.69231246251519
At time: 158.03495860099792 and batch: 1000, loss is 4.793013610839844 and perplexity is 120.6644570005488
At time: 158.43760228157043 and batch: 1050, loss is 4.715027227401733 and perplexity is 111.61185003301675
At time: 158.83236742019653 and batch: 1100, loss is 4.822345495223999 and perplexity is 124.25619156248443
At time: 159.22849798202515 and batch: 1150, loss is 4.764828395843506 and perplexity is 117.3109845078798
At time: 159.627836227417 and batch: 1200, loss is 4.714375219345093 and perplexity is 111.53910192633171
At time: 160.028804063797 and batch: 1250, loss is 4.7197779846191406 and perplexity is 112.14335235470135
At time: 160.42438530921936 and batch: 1300, loss is 4.7812204170227055 and perplexity is 119.2497957552448
At time: 160.8198435306549 and batch: 1350, loss is 4.730386791229248 and perplexity is 113.33939255451216
At time: 161.21731638908386 and batch: 1400, loss is 4.634898157119751 and perplexity is 103.01742586959779
At time: 161.6012361049652 and batch: 1450, loss is 4.713977422714233 and perplexity is 111.49474087130042
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.09144527076656 and perplexity of 162.62472905622462
Finished 13 epochs...
Completing Train Step...
At time: 162.8749167919159 and batch: 50, loss is 4.840343980789185 and perplexity is 126.51286224049143
At time: 163.27774500846863 and batch: 100, loss is 4.841281290054321 and perplexity is 126.63149950964845
At time: 163.68640327453613 and batch: 150, loss is 4.748991966247559 and perplexity is 115.46783037185313
At time: 164.09229707717896 and batch: 200, loss is 4.786965045928955 and perplexity is 119.93681301928179
At time: 164.4912292957306 and batch: 250, loss is 4.806214294433594 and perplexity is 122.26787010908042
At time: 164.8958888053894 and batch: 300, loss is 4.811709632873535 and perplexity is 122.94162299017381
At time: 165.29305791854858 and batch: 350, loss is 4.845270347595215 and perplexity is 127.1376487056375
At time: 165.69738245010376 and batch: 400, loss is 4.713949785232544 and perplexity is 111.49165948002232
At time: 166.0930347442627 and batch: 450, loss is 4.778821868896484 and perplexity is 118.96411213100687
At time: 166.4873752593994 and batch: 500, loss is 4.7736741065979 and perplexity is 118.35328670063298
At time: 166.87791657447815 and batch: 550, loss is 4.819247026443481 and perplexity is 123.87178347790925
At time: 167.2819266319275 and batch: 600, loss is 4.710527830123901 and perplexity is 111.11079205356737
At time: 167.67112565040588 and batch: 650, loss is 4.825391006469727 and perplexity is 124.63519202338206
At time: 168.05899214744568 and batch: 700, loss is 4.872662057876587 and perplexity is 130.6683008927727
At time: 168.4607322216034 and batch: 750, loss is 4.801911478042602 and perplexity is 121.74290413951752
At time: 168.8666262626648 and batch: 800, loss is 4.743213186264038 and perplexity is 114.80249146009525
At time: 169.27238249778748 and batch: 850, loss is 4.715960483551026 and perplexity is 111.71606109863922
At time: 169.66947388648987 and batch: 900, loss is 4.664376811981201 and perplexity is 106.09944471238317
At time: 170.0602889060974 and batch: 950, loss is 4.750821809768677 and perplexity is 115.67931186316594
At time: 170.44952178001404 and batch: 1000, loss is 4.784462032318115 and perplexity is 119.63698493727594
At time: 170.85001182556152 and batch: 1050, loss is 4.706454725265503 and perplexity is 110.65914657074526
At time: 171.24715971946716 and batch: 1100, loss is 4.81294285774231 and perplexity is 123.09333118298382
At time: 171.65243530273438 and batch: 1150, loss is 4.754908285140991 and perplexity is 116.15299971987426
At time: 172.06987118721008 and batch: 1200, loss is 4.705667133331299 and perplexity is 110.5720266314444
At time: 172.46744799613953 and batch: 1250, loss is 4.71155351638794 and perplexity is 111.22481533282247
At time: 172.85749101638794 and batch: 1300, loss is 4.772672414779663 and perplexity is 118.23479253890761
At time: 173.25745820999146 and batch: 1350, loss is 4.722662286758423 and perplexity is 112.46727458603229
At time: 173.64787459373474 and batch: 1400, loss is 4.6286502456665035 and perplexity is 102.37578864816119
At time: 174.03569674491882 and batch: 1450, loss is 4.707012872695923 and perplexity is 110.72092792900555
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.092846471020299 and perplexity of 162.8527585880527
Annealing...
Finished 14 epochs...
Completing Train Step...
At time: 175.30665612220764 and batch: 50, loss is 4.827554607391358 and perplexity is 124.90514476940871
At time: 175.71263432502747 and batch: 100, loss is 4.816017713546753 and perplexity is 123.47240793135752
At time: 176.1085286140442 and batch: 150, loss is 4.721028032302857 and perplexity is 112.28362454775554
At time: 176.4983630180359 and batch: 200, loss is 4.7591750431060795 and perplexity is 116.64965525760684
At time: 176.88530206680298 and batch: 250, loss is 4.778760271072388 and perplexity is 118.95678442624168
At time: 177.2689528465271 and batch: 300, loss is 4.77527684211731 and perplexity is 118.54312780897264
At time: 177.66141486167908 and batch: 350, loss is 4.807806205749512 and perplexity is 122.46266472181736
At time: 178.05181884765625 and batch: 400, loss is 4.675658702850342 and perplexity is 107.30322475828577
At time: 178.45643305778503 and batch: 450, loss is 4.744484558105468 and perplexity is 114.94854093698719
At time: 178.8647928237915 and batch: 500, loss is 4.724950132369995 and perplexity is 112.72487691145162
At time: 179.26003623008728 and batch: 550, loss is 4.772758493423462 and perplexity is 118.24497046754404
At time: 179.66036772727966 and batch: 600, loss is 4.670654029846191 and perplexity is 106.76754876574725
At time: 180.04823780059814 and batch: 650, loss is 4.780261344909668 and perplexity is 119.13548142825451
At time: 180.4526948928833 and batch: 700, loss is 4.824317626953125 and perplexity is 124.50148293435275
At time: 180.86811590194702 and batch: 750, loss is 4.750197086334229 and perplexity is 115.60706685508856
At time: 181.25804090499878 and batch: 800, loss is 4.691210584640503 and perplexity is 108.98503559015036
At time: 181.64587306976318 and batch: 850, loss is 4.66329550743103 and perplexity is 105.98478090446595
At time: 182.04300904273987 and batch: 900, loss is 4.603451414108276 and perplexity is 99.82827043626766
At time: 182.43918442726135 and batch: 950, loss is 4.693612861633301 and perplexity is 109.24716255844058
At time: 182.82467079162598 and batch: 1000, loss is 4.730114898681641 and perplexity is 113.3085806072855
At time: 183.22007656097412 and batch: 1050, loss is 4.647301788330078 and perplexity is 104.3031735138045
At time: 183.61611819267273 and batch: 1100, loss is 4.748785018920898 and perplexity is 115.44393708545357
At time: 184.0084891319275 and batch: 1150, loss is 4.692842931747436 and perplexity is 109.16308227515593
At time: 184.40992426872253 and batch: 1200, loss is 4.643065948486328 and perplexity is 103.86229637727271
At time: 184.80220913887024 and batch: 1250, loss is 4.644648923873901 and perplexity is 104.02683803447239
At time: 185.18985891342163 and batch: 1300, loss is 4.705042152404785 and perplexity is 110.50294281407658
At time: 185.58827447891235 and batch: 1350, loss is 4.64783712387085 and perplexity is 104.35902565808674
At time: 185.98900413513184 and batch: 1400, loss is 4.553915929794312 and perplexity is 95.00370870079826
At time: 186.38558888435364 and batch: 1450, loss is 4.632336015701294 and perplexity is 102.75381849984035
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.049801035823985 and perplexity of 155.99142469331449
Finished 15 epochs...
Completing Train Step...
At time: 187.7569077014923 and batch: 50, loss is 4.796878519058228 and perplexity is 121.1317164278363
At time: 188.15161442756653 and batch: 100, loss is 4.794008779525757 and perplexity is 120.78459826015288
At time: 188.54020237922668 and batch: 150, loss is 4.700691976547241 and perplexity is 110.02327964605561
At time: 188.9330940246582 and batch: 200, loss is 4.742902297973632 and perplexity is 114.76680625713422
At time: 189.32881951332092 and batch: 250, loss is 4.763696813583374 and perplexity is 117.1783125576617
At time: 189.717547416687 and batch: 300, loss is 4.762495822906494 and perplexity is 117.03766697067213
At time: 190.10485553741455 and batch: 350, loss is 4.797296676635742 and perplexity is 121.18237916470336
At time: 190.5006148815155 and batch: 400, loss is 4.667034177780152 and perplexity is 106.38176469564772
At time: 190.92639327049255 and batch: 450, loss is 4.732006530761719 and perplexity is 113.5231216056541
At time: 191.3213758468628 and batch: 500, loss is 4.713823003768921 and perplexity is 111.47752530024657
At time: 191.7178511619568 and batch: 550, loss is 4.764179468154907 and perplexity is 117.23488285676069
At time: 192.11403512954712 and batch: 600, loss is 4.661583776473999 and perplexity is 105.80351865437856
At time: 192.50524067878723 and batch: 650, loss is 4.77146710395813 and perplexity is 118.09236871371004
At time: 192.89488625526428 and batch: 700, loss is 4.817270841598511 and perplexity is 123.6272316560703
At time: 193.28088927268982 and batch: 750, loss is 4.743391027450562 and perplexity is 114.82290988695723
At time: 193.67814540863037 and batch: 800, loss is 4.686532773971558 and perplexity is 108.47641477132377
At time: 194.07329154014587 and batch: 850, loss is 4.659493885040283 and perplexity is 105.58263168237741
At time: 194.47143483161926 and batch: 900, loss is 4.599503374099731 and perplexity is 99.43492142035558
At time: 194.8673119544983 and batch: 950, loss is 4.690822105407715 and perplexity is 108.94270538987318
At time: 195.25619649887085 and batch: 1000, loss is 4.727849025726318 and perplexity is 113.05212841265019
At time: 195.66124320030212 and batch: 1050, loss is 4.644684314727783 and perplexity is 104.03051969824531
At time: 196.05579662322998 and batch: 1100, loss is 4.748127784729004 and perplexity is 115.36808831068845
At time: 196.45022559165955 and batch: 1150, loss is 4.693044624328613 and perplexity is 109.18510187951
At time: 196.8453106880188 and batch: 1200, loss is 4.643674831390381 and perplexity is 103.92555561069108
At time: 197.23208045959473 and batch: 1250, loss is 4.648336515426636 and perplexity is 104.41115468958618
At time: 197.61893129348755 and batch: 1300, loss is 4.708376417160034 and perplexity is 110.87200381327982
At time: 198.0047905445099 and batch: 1350, loss is 4.652145147323608 and perplexity is 104.80957658328823
At time: 198.4096758365631 and batch: 1400, loss is 4.557596340179443 and perplexity is 95.35400555961543
At time: 198.80533051490784 and batch: 1450, loss is 4.635065774917603 and perplexity is 103.03469487091802
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.048685709635417 and perplexity of 155.81754035906317
Finished 16 epochs...
Completing Train Step...
At time: 200.1348102092743 and batch: 50, loss is 4.789778728485107 and perplexity is 120.27475234195312
At time: 200.53953981399536 and batch: 100, loss is 4.786633510589599 and perplexity is 119.89705631801603
At time: 200.96142601966858 and batch: 150, loss is 4.6943674659729 and perplexity is 109.32963205340212
At time: 201.36749410629272 and batch: 200, loss is 4.737067928314209 and perplexity is 114.09916381507307
At time: 201.76491165161133 and batch: 250, loss is 4.757691135406494 and perplexity is 116.47668630273762
At time: 202.1564588546753 and batch: 300, loss is 4.756708717346191 and perplexity is 116.3623136925673
At time: 202.54269576072693 and batch: 350, loss is 4.792923202514649 and perplexity is 120.65354842220137
At time: 202.94036841392517 and batch: 400, loss is 4.663419885635376 and perplexity is 105.99796392102579
At time: 203.33758640289307 and batch: 450, loss is 4.725698471069336 and perplexity is 112.80926487067256
At time: 203.73526263237 and batch: 500, loss is 4.708180847167969 and perplexity is 110.85032269653085
At time: 204.14960932731628 and batch: 550, loss is 4.759917573928833 and perplexity is 116.73630338757167
At time: 204.54121661186218 and batch: 600, loss is 4.6573667812347415 and perplexity is 105.3582851534937
At time: 204.94797158241272 and batch: 650, loss is 4.7670911598205565 and perplexity is 117.57673212641778
At time: 205.33832669258118 and batch: 700, loss is 4.813347263336182 and perplexity is 123.1431208816203
At time: 205.73750925064087 and batch: 750, loss is 4.739563112258911 and perplexity is 114.38421769977249
At time: 206.14896368980408 and batch: 800, loss is 4.683881692886352 and perplexity is 108.18921586193913
At time: 206.55025506019592 and batch: 850, loss is 4.657278985977173 and perplexity is 105.34903560175096
At time: 206.95514512062073 and batch: 900, loss is 4.596833915710449 and perplexity is 99.16983800716852
At time: 207.35244512557983 and batch: 950, loss is 4.6892025184631345 and perplexity is 108.76640601113952
At time: 207.75388646125793 and batch: 1000, loss is 4.726356554031372 and perplexity is 112.88352715853686
At time: 208.14225363731384 and batch: 1050, loss is 4.642751598358155 and perplexity is 103.829652382185
At time: 208.53700613975525 and batch: 1100, loss is 4.747588367462158 and perplexity is 115.30587355317645
At time: 208.93395042419434 and batch: 1150, loss is 4.692480239868164 and perplexity is 109.12349689078108
At time: 209.32673835754395 and batch: 1200, loss is 4.643293771743775 and perplexity is 103.88596131956906
At time: 209.7320098876953 and batch: 1250, loss is 4.649771814346313 and perplexity is 104.56112350640912
At time: 210.13477444648743 and batch: 1300, loss is 4.709151439666748 and perplexity is 110.9579654183861
At time: 210.54403066635132 and batch: 1350, loss is 4.652877578735351 and perplexity is 104.88637052914535
At time: 210.94224572181702 and batch: 1400, loss is 4.55800217628479 and perplexity is 95.39271151146615
At time: 211.34450578689575 and batch: 1450, loss is 4.634520082473755 and perplexity is 102.97848495453096
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.048383142194178 and perplexity of 155.77040217617582
Finished 17 epochs...
Completing Train Step...
At time: 212.65320253372192 and batch: 50, loss is 4.784869556427002 and perplexity is 119.685749828712
At time: 213.06587982177734 and batch: 100, loss is 4.781274166107178 and perplexity is 119.2562054948474
At time: 213.46562480926514 and batch: 150, loss is 4.68967300415039 and perplexity is 108.81759108840095
At time: 213.86360120773315 and batch: 200, loss is 4.7323797416687015 and perplexity is 113.56549757992804
At time: 214.26854181289673 and batch: 250, loss is 4.75295241355896 and perplexity is 115.92604139157795
At time: 214.66326308250427 and batch: 300, loss is 4.752378339767456 and perplexity is 115.85951038814213
At time: 215.05762648582458 and batch: 350, loss is 4.789352922439575 and perplexity is 120.22354952728875
At time: 215.4536383152008 and batch: 400, loss is 4.660755710601807 and perplexity is 105.71594263578329
At time: 215.84184098243713 and batch: 450, loss is 4.721095209121704 and perplexity is 112.29116765781951
At time: 216.2467920780182 and batch: 500, loss is 4.703700428009033 and perplexity is 110.35477774047497
At time: 216.63245034217834 and batch: 550, loss is 4.756546602249146 and perplexity is 116.34345113378471
At time: 217.03039455413818 and batch: 600, loss is 4.654472045898437 and perplexity is 105.05374180134876
At time: 217.4309093952179 and batch: 650, loss is 4.76380410194397 and perplexity is 117.19088510114511
At time: 217.82895255088806 and batch: 700, loss is 4.810494422912598 and perplexity is 122.79231384465693
At time: 218.22673845291138 and batch: 750, loss is 4.736380586624145 and perplexity is 114.02076564923196
At time: 218.6181399822235 and batch: 800, loss is 4.681720352172851 and perplexity is 107.95563462018798
At time: 219.0202877521515 and batch: 850, loss is 4.655231494903564 and perplexity is 105.13355506426011
At time: 219.4157476425171 and batch: 900, loss is 4.5943812084198 and perplexity is 98.92690147037092
At time: 219.81506204605103 and batch: 950, loss is 4.6874665355682374 and perplexity is 108.57775318718006
At time: 220.20398473739624 and batch: 1000, loss is 4.724872970581055 and perplexity is 112.71617919386117
At time: 220.61774230003357 and batch: 1050, loss is 4.640584182739258 and perplexity is 103.60485407559038
At time: 221.00421619415283 and batch: 1100, loss is 4.746370153427124 and perplexity is 115.16549184453707
At time: 221.40377116203308 and batch: 1150, loss is 4.69142240524292 and perplexity is 109.0081233111847
At time: 221.814799785614 and batch: 1200, loss is 4.642482013702392 and perplexity is 103.80166527370663
At time: 222.2111930847168 and batch: 1250, loss is 4.650120620727539 and perplexity is 104.59760145501704
At time: 222.60643029212952 and batch: 1300, loss is 4.709092855453491 and perplexity is 110.95146522368375
At time: 223.0036916732788 and batch: 1350, loss is 4.653007383346558 and perplexity is 104.89998614735863
At time: 223.4143943786621 and batch: 1400, loss is 4.558304176330567 and perplexity is 95.42152446524702
At time: 223.80997467041016 and batch: 1450, loss is 4.633651084899903 and perplexity is 102.88903577213672
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.048360710470085 and perplexity of 155.7669080166826
Finished 18 epochs...
Completing Train Step...
At time: 225.06428027153015 and batch: 50, loss is 4.7812293434143065 and perplexity is 119.25086023037102
At time: 225.47740626335144 and batch: 100, loss is 4.7769176197052 and perplexity is 118.73779037159323
At time: 225.87319207191467 and batch: 150, loss is 4.685513191223144 and perplexity is 108.36587045432881
At time: 226.27315306663513 and batch: 200, loss is 4.728389530181885 and perplexity is 113.11325010855502
At time: 226.66924166679382 and batch: 250, loss is 4.749501695632935 and perplexity is 115.52670272126782
At time: 227.06342124938965 and batch: 300, loss is 4.7488955307006835 and perplexity is 115.45669570538219
At time: 227.45544719696045 and batch: 350, loss is 4.7865522098541256 and perplexity is 119.88730899539387
At time: 227.84427332878113 and batch: 400, loss is 4.658705701828003 and perplexity is 105.49944601165807
At time: 228.2468764781952 and batch: 450, loss is 4.716871280670166 and perplexity is 111.81785811642762
At time: 228.6474997997284 and batch: 500, loss is 4.699998788833618 and perplexity is 109.94703928788506
At time: 229.05574536323547 and batch: 550, loss is 4.753770055770874 and perplexity is 116.0208661775709
At time: 229.4507930278778 and batch: 600, loss is 4.651713762283325 and perplexity is 104.76437305063669
At time: 229.84137320518494 and batch: 650, loss is 4.760971431732178 and perplexity is 116.85939169922713
At time: 230.25136637687683 and batch: 700, loss is 4.807884798049927 and perplexity is 122.47228972257334
At time: 230.64949107170105 and batch: 750, loss is 4.733533763885498 and perplexity is 113.69663033770159
At time: 231.05876398086548 and batch: 800, loss is 4.679568567276001 and perplexity is 107.72358706383106
At time: 231.48804306983948 and batch: 850, loss is 4.653672676086426 and perplexity is 104.96979856682769
At time: 231.9157702922821 and batch: 900, loss is 4.591704082489014 and perplexity is 98.66241588576477
At time: 232.32237124443054 and batch: 950, loss is 4.686000852584839 and perplexity is 108.41872918980974
At time: 232.7281141281128 and batch: 1000, loss is 4.723151903152466 and perplexity is 112.5223538902278
At time: 233.1348798274994 and batch: 1050, loss is 4.63850100517273 and perplexity is 103.38925141507912
At time: 233.53253889083862 and batch: 1100, loss is 4.74530442237854 and perplexity is 115.04282178241041
At time: 233.92817425727844 and batch: 1150, loss is 4.689927892684937 and perplexity is 108.84533097986629
At time: 234.31448650360107 and batch: 1200, loss is 4.6412587738037105 and perplexity is 103.67476856357678
At time: 234.70919132232666 and batch: 1250, loss is 4.6500106525421145 and perplexity is 104.5860996790116
At time: 235.11442470550537 and batch: 1300, loss is 4.708476104736328 and perplexity is 110.88305692553867
At time: 235.52241015434265 and batch: 1350, loss is 4.652359294891357 and perplexity is 104.83202370260256
At time: 235.92352032661438 and batch: 1400, loss is 4.556920900344848 and perplexity is 95.28962141212904
At time: 236.321959733963 and batch: 1450, loss is 4.632004175186157 and perplexity is 102.71972627668039
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0483784471821584 and perplexity of 155.76967083398222
Annealing...
Finished 19 epochs...
Completing Train Step...
At time: 237.6393039226532 and batch: 50, loss is 4.777421007156372 and perplexity is 118.79757653178507
At time: 238.04444456100464 and batch: 100, loss is 4.773751363754273 and perplexity is 118.36243069222569
At time: 238.44201517105103 and batch: 150, loss is 4.679172439575195 and perplexity is 107.68092321768844
At time: 238.8374457359314 and batch: 200, loss is 4.72175440788269 and perplexity is 112.36521425944188
At time: 239.23270869255066 and batch: 250, loss is 4.743111152648925 and perplexity is 114.79077834444358
At time: 239.63573622703552 and batch: 300, loss is 4.741421947479248 and perplexity is 114.59703684886952
At time: 240.03208541870117 and batch: 350, loss is 4.777018203735351 and perplexity is 118.74973409774402
At time: 240.43618273735046 and batch: 400, loss is 4.648353023529053 and perplexity is 104.41287833384824
At time: 240.83716440200806 and batch: 450, loss is 4.708209018707276 and perplexity is 110.85344556474166
At time: 241.23254466056824 and batch: 500, loss is 4.68695858001709 and perplexity is 108.52261451989916
At time: 241.63813400268555 and batch: 550, loss is 4.73992470741272 and perplexity is 114.42558595739493
At time: 242.03795862197876 and batch: 600, loss is 4.639207239151001 and perplexity is 103.46229420703133
At time: 242.43494033813477 and batch: 650, loss is 4.748739213943481 and perplexity is 115.43864929962679
At time: 242.82455778121948 and batch: 700, loss is 4.793845300674438 and perplexity is 120.76485414668883
At time: 243.2147023677826 and batch: 750, loss is 4.719043016433716 and perplexity is 112.06096083979372
At time: 243.6080334186554 and batch: 800, loss is 4.663508377075195 and perplexity is 106.0073442485043
At time: 244.01194834709167 and batch: 850, loss is 4.63670615196228 and perplexity is 103.20384931979649
At time: 244.4144823551178 and batch: 900, loss is 4.573267078399658 and perplexity is 96.86004275639375
At time: 244.81348061561584 and batch: 950, loss is 4.665547618865967 and perplexity is 106.22373942107407
At time: 245.19986176490784 and batch: 1000, loss is 4.702955455780029 and perplexity is 110.27259711066463
At time: 245.58323049545288 and batch: 1050, loss is 4.6167611885070805 and perplexity is 101.16584384869809
At time: 245.98564457893372 and batch: 1100, loss is 4.7269125652313235 and perplexity is 112.9463091160454
At time: 246.37995433807373 and batch: 1150, loss is 4.667324762344361 and perplexity is 106.41268208622229
At time: 246.77810645103455 and batch: 1200, loss is 4.620621500015258 and perplexity is 101.55713027778178
At time: 247.1798324584961 and batch: 1250, loss is 4.6287321186065675 and perplexity is 102.38417079810013
At time: 247.58307480812073 and batch: 1300, loss is 4.681768951416015 and perplexity is 107.96088130981735
At time: 248.00180983543396 and batch: 1350, loss is 4.626486930847168 and perplexity is 102.15455697059983
At time: 248.39700937271118 and batch: 1400, loss is 4.5296626663208 and perplexity is 92.72727577251563
At time: 248.80533123016357 and batch: 1450, loss is 4.605216856002808 and perplexity is 100.00466711037784
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.038205399472489 and perplexity of 154.193051649084
Finished 20 epochs...
Completing Train Step...
At time: 250.16338777542114 and batch: 50, loss is 4.768971090316772 and perplexity is 117.7979761072821
At time: 250.56158709526062 and batch: 100, loss is 4.76761344909668 and perplexity is 117.6381572321697
At time: 250.95138907432556 and batch: 150, loss is 4.672703857421875 and perplexity is 106.9866282923123
At time: 251.35531544685364 and batch: 200, loss is 4.716702899932861 and perplexity is 111.79903172807923
At time: 251.77053594589233 and batch: 250, loss is 4.737241878509521 and perplexity is 114.11901311324823
At time: 252.17472052574158 and batch: 300, loss is 4.737808427810669 and perplexity is 114.18368547868707
At time: 252.582989692688 and batch: 350, loss is 4.773622465133667 and perplexity is 118.34717492142296
At time: 252.98998427391052 and batch: 400, loss is 4.64541407585144 and perplexity is 104.10646483472863
At time: 253.40951800346375 and batch: 450, loss is 4.7043821907043455 and perplexity is 110.43003916348809
At time: 253.8165864944458 and batch: 500, loss is 4.6824671459198 and perplexity is 108.03628532404261
At time: 254.23302555084229 and batch: 550, loss is 4.736731901168823 and perplexity is 114.06082983975418
At time: 254.62322545051575 and batch: 600, loss is 4.63653525352478 and perplexity is 103.18621345021793
At time: 255.01180839538574 and batch: 650, loss is 4.746019344329834 and perplexity is 115.12509782801266
At time: 255.4094054698944 and batch: 700, loss is 4.791681680679321 and perplexity is 120.50384735512608
At time: 255.822585105896 and batch: 750, loss is 4.716854066848755 and perplexity is 111.81593332035403
At time: 256.23688530921936 and batch: 800, loss is 4.661606502532959 and perplexity is 105.80592317870426
At time: 256.64543080329895 and batch: 850, loss is 4.63549126625061 and perplexity is 103.07854456875626
At time: 257.05398893356323 and batch: 900, loss is 4.57245099067688 and perplexity is 96.78102871025428
At time: 257.45737862586975 and batch: 950, loss is 4.66394347190857 and perplexity is 106.05347753173537
At time: 257.85821080207825 and batch: 1000, loss is 4.701459741592407 and perplexity is 110.10778410995809
At time: 258.26132225990295 and batch: 1050, loss is 4.616943359375 and perplexity is 101.184274997034
At time: 258.657071352005 and batch: 1100, loss is 4.727098035812378 and perplexity is 112.96725927638424
At time: 259.05948185920715 and batch: 1150, loss is 4.668749265670776 and perplexity is 106.56437532393629
At time: 259.4564712047577 and batch: 1200, loss is 4.622134780883789 and perplexity is 101.7109310826512
At time: 259.85581636428833 and batch: 1250, loss is 4.6296389770507815 and perplexity is 102.47706086064504
At time: 260.2586073875427 and batch: 1300, loss is 4.682425518035888 and perplexity is 108.03178809570461
At time: 260.6540675163269 and batch: 1350, loss is 4.627687349319458 and perplexity is 102.27725881986463
At time: 261.0747127532959 and batch: 1400, loss is 4.531051073074341 and perplexity is 92.85610836375989
At time: 261.47224736213684 and batch: 1450, loss is 4.607159051895142 and perplexity is 100.19908450126896
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.037725464910523 and perplexity of 154.11906682973867
Finished 21 epochs...
Completing Train Step...
At time: 262.76884746551514 and batch: 50, loss is 4.766272039413452 and perplexity is 117.48046205950332
At time: 263.1863057613373 and batch: 100, loss is 4.76533390045166 and perplexity is 117.37030074218737
At time: 263.5811104774475 and batch: 150, loss is 4.669994068145752 and perplexity is 106.69710951887132
At time: 263.9685015678406 and batch: 200, loss is 4.714568881988526 and perplexity is 111.56070497544118
At time: 264.355539560318 and batch: 250, loss is 4.734882421493531 and perplexity is 113.85007160982609
At time: 264.7579548358917 and batch: 300, loss is 4.73616997718811 and perplexity is 113.9967543286764
At time: 265.15616631507874 and batch: 350, loss is 4.77212721824646 and perplexity is 118.1703489087296
At time: 265.5626964569092 and batch: 400, loss is 4.644388484954834 and perplexity is 103.99974892490303
At time: 265.949826002121 and batch: 450, loss is 4.702625617980957 and perplexity is 110.23623103771816
At time: 266.344970703125 and batch: 500, loss is 4.680038652420044 and perplexity is 107.77423822601948
At time: 266.7413682937622 and batch: 550, loss is 4.735133714675904 and perplexity is 113.87868495165262
At time: 267.1460783481598 and batch: 600, loss is 4.63516827583313 and perplexity is 103.04525656275561
At time: 267.5507082939148 and batch: 650, loss is 4.744533052444458 and perplexity is 114.95411542566224
At time: 267.93800377845764 and batch: 700, loss is 4.790358057022095 and perplexity is 120.34445112556176
At time: 268.3377821445465 and batch: 750, loss is 4.715854549407959 and perplexity is 111.70422718025904
At time: 268.736444234848 and batch: 800, loss is 4.660499210357666 and perplexity is 105.68882994804183
At time: 269.14074540138245 and batch: 850, loss is 4.634905328750611 and perplexity is 103.01816467519748
At time: 269.53521609306335 and batch: 900, loss is 4.572037601470948 and perplexity is 96.74102874599279
At time: 269.9226882457733 and batch: 950, loss is 4.662764768600464 and perplexity is 105.92854559024342
At time: 270.3380057811737 and batch: 1000, loss is 4.700549983978272 and perplexity is 110.00765826701836
At time: 270.73638558387756 and batch: 1050, loss is 4.616807518005371 and perplexity is 101.17053092006171
At time: 271.13818407058716 and batch: 1100, loss is 4.7273855400085445 and perplexity is 112.99974250676442
At time: 271.53706407546997 and batch: 1150, loss is 4.669545269012451 and perplexity is 106.64923469248737
At time: 271.946799993515 and batch: 1200, loss is 4.62294755935669 and perplexity is 101.79363314256808
At time: 272.3680851459503 and batch: 1250, loss is 4.6299905109405515 and perplexity is 102.5130913530601
At time: 272.7641248703003 and batch: 1300, loss is 4.682632389068604 and perplexity is 108.0541390550774
At time: 273.15796518325806 and batch: 1350, loss is 4.628228454589844 and perplexity is 102.33261655948435
At time: 273.5457396507263 and batch: 1400, loss is 4.5314349269866945 and perplexity is 92.89175838600376
At time: 273.94972586631775 and batch: 1450, loss is 4.607838087081909 and perplexity is 100.26714631089376
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.03753662109375 and perplexity of 154.0899651448441
Finished 22 epochs...
Completing Train Step...
At time: 275.2284858226776 and batch: 50, loss is 4.764266119003296 and perplexity is 117.24504179895514
At time: 275.6344668865204 and batch: 100, loss is 4.763548593521119 and perplexity is 117.1609456679719
At time: 276.0345950126648 and batch: 150, loss is 4.668081398010254 and perplexity is 106.49322818497491
At time: 276.42950224876404 and batch: 200, loss is 4.713031778335571 and perplexity is 111.3893563323468
At time: 276.839861869812 and batch: 250, loss is 4.733269462585449 and perplexity is 113.6665841412914
At time: 277.2308328151703 and batch: 300, loss is 4.73499831199646 and perplexity is 113.8632665164509
At time: 277.6302664279938 and batch: 350, loss is 4.771010026931763 and perplexity is 118.03840373899641
At time: 278.02529549598694 and batch: 400, loss is 4.64375864982605 and perplexity is 103.93426685326462
At time: 278.4198751449585 and batch: 450, loss is 4.701370458602906 and perplexity is 110.09795379667182
At time: 278.81636810302734 and batch: 500, loss is 4.6781620693206785 and perplexity is 107.57218056031441
At time: 279.2063009738922 and batch: 550, loss is 4.7339488697052 and perplexity is 113.74383626768552
At time: 279.60759973526 and batch: 600, loss is 4.6341820907592775 and perplexity is 102.94368496123285
At time: 280.00579023361206 and batch: 650, loss is 4.743510808944702 and perplexity is 114.83666437041487
At time: 280.41966009140015 and batch: 700, loss is 4.7894001388549805 and perplexity is 120.2292261863594
At time: 280.83436918258667 and batch: 750, loss is 4.715096559524536 and perplexity is 111.61958858777162
At time: 281.2357702255249 and batch: 800, loss is 4.659619235992432 and perplexity is 105.59586739532645
At time: 281.6418354511261 and batch: 850, loss is 4.634442758560181 and perplexity is 102.97052256290593
At time: 282.0373167991638 and batch: 900, loss is 4.571690349578858 and perplexity is 96.70744107274707
At time: 282.4519507884979 and batch: 950, loss is 4.6618066501617434 and perplexity is 105.82710210272482
At time: 282.8570885658264 and batch: 1000, loss is 4.699779405593872 and perplexity is 109.92292139583296
At time: 283.2593948841095 and batch: 1050, loss is 4.616482400894165 and perplexity is 101.13764399565048
At time: 283.652813911438 and batch: 1100, loss is 4.727426786422729 and perplexity is 113.00440343706927
At time: 284.0440413951874 and batch: 1150, loss is 4.670001497268677 and perplexity is 106.69790218775807
At time: 284.4477610588074 and batch: 1200, loss is 4.623400020599365 and perplexity is 101.83970123754402
At time: 284.8535780906677 and batch: 1250, loss is 4.630072202682495 and perplexity is 102.5214661681367
At time: 285.24918508529663 and batch: 1300, loss is 4.682537736892701 and perplexity is 108.04391197971559
At time: 285.6350975036621 and batch: 1350, loss is 4.628295688629151 and perplexity is 102.33949702594664
At time: 286.02801990509033 and batch: 1400, loss is 4.53140884399414 and perplexity is 92.88933552255932
At time: 286.4170265197754 and batch: 1450, loss is 4.608016052246094 and perplexity is 100.28499195795399
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.037403595753205 and perplexity of 154.0694686380638
Finished 23 epochs...
Completing Train Step...
At time: 287.6913275718689 and batch: 50, loss is 4.762486257553101 and perplexity is 117.03654746938139
At time: 288.08199095726013 and batch: 100, loss is 4.762377872467041 and perplexity is 117.02386314052022
At time: 288.4725151062012 and batch: 150, loss is 4.666522636413574 and perplexity is 106.32735993868458
At time: 288.8658993244171 and batch: 200, loss is 4.711840753555298 and perplexity is 111.25676782247021
At time: 289.2537887096405 and batch: 250, loss is 4.73174373626709 and perplexity is 113.49329227394674
At time: 289.6495258808136 and batch: 300, loss is 4.733851547241211 and perplexity is 113.73276697593049
At time: 290.0432231426239 and batch: 350, loss is 4.770306777954102 and perplexity is 117.95542253388595
At time: 290.43219566345215 and batch: 400, loss is 4.643129043579101 and perplexity is 103.86884978524009
At time: 290.8247261047363 and batch: 450, loss is 4.70030258178711 and perplexity is 109.98044549770667
At time: 291.2134618759155 and batch: 500, loss is 4.676317310333252 and perplexity is 107.37391874228997
At time: 291.61705589294434 and batch: 550, loss is 4.732924108505249 and perplexity is 113.6273357003705
At time: 292.0148618221283 and batch: 600, loss is 4.633262548446655 and perplexity is 102.8490673961881
At time: 292.432804107666 and batch: 650, loss is 4.742643804550171 and perplexity is 114.73714362644769
At time: 292.8395266532898 and batch: 700, loss is 4.788435621261597 and perplexity is 120.11331888876325
At time: 293.2434482574463 and batch: 750, loss is 4.714385290145874 and perplexity is 111.54022522006271
At time: 293.6478273868561 and batch: 800, loss is 4.658909540176392 and perplexity is 105.52095303639275
At time: 294.04367542266846 and batch: 850, loss is 4.6340229701995845 and perplexity is 102.92730580762958
At time: 294.4451630115509 and batch: 900, loss is 4.571273260116577 and perplexity is 96.66711382877037
At time: 294.85318326950073 and batch: 950, loss is 4.661013278961182 and perplexity is 105.74317522466384
At time: 295.253515958786 and batch: 1000, loss is 4.698985567092896 and perplexity is 109.83569497511542
At time: 295.6494359970093 and batch: 1050, loss is 4.615937032699585 and perplexity is 101.08250177911272
At time: 296.0381729602814 and batch: 1100, loss is 4.727224206924438 and perplexity is 112.98151338032271
At time: 296.4416255950928 and batch: 1150, loss is 4.670302085876465 and perplexity is 106.7299791823786
At time: 296.8368310928345 and batch: 1200, loss is 4.623728551864624 and perplexity is 101.87316425996876
At time: 297.238233089447 and batch: 1250, loss is 4.630085372924805 and perplexity is 102.5228164095796
At time: 297.6375160217285 and batch: 1300, loss is 4.682148370742798 and perplexity is 108.00185152667734
At time: 298.04202914237976 and batch: 1350, loss is 4.628311748504639 and perplexity is 102.34114059872415
At time: 298.43286538124084 and batch: 1400, loss is 4.5312854671478275 and perplexity is 92.87787583623098
At time: 298.82342004776 and batch: 1450, loss is 4.607937755584717 and perplexity is 100.27714028528139
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.037385859041133 and perplexity of 154.0667359764937
Finished 24 epochs...
Completing Train Step...
At time: 300.1411747932434 and batch: 50, loss is 4.761219148635864 and perplexity is 116.88834333166189
At time: 300.5367214679718 and batch: 100, loss is 4.761241025924683 and perplexity is 116.890900559681
At time: 300.93429589271545 and batch: 150, loss is 4.665115804672241 and perplexity is 106.17788040468112
At time: 301.32248616218567 and batch: 200, loss is 4.710662746429444 and perplexity is 111.12578372242469
At time: 301.7209839820862 and batch: 250, loss is 4.730533514022827 and perplexity is 113.35602324683137
At time: 302.13376116752625 and batch: 300, loss is 4.7328138256073 and perplexity is 113.6148052394637
At time: 302.52690863609314 and batch: 350, loss is 4.769302797317505 and perplexity is 117.83705700197386
At time: 302.95546197891235 and batch: 400, loss is 4.642670288085937 and perplexity is 103.82121030810389
At time: 303.34998655319214 and batch: 450, loss is 4.699292325973511 and perplexity is 109.86939321831102
At time: 303.74451994895935 and batch: 500, loss is 4.674865083694458 and perplexity is 107.21810064616031
At time: 304.1515805721283 and batch: 550, loss is 4.732091302871704 and perplexity is 113.53274560812243
At time: 304.54509711265564 and batch: 600, loss is 4.632509965896606 and perplexity is 102.77169410132456
At time: 304.93575382232666 and batch: 650, loss is 4.741869306564331 and perplexity is 114.64831434329875
At time: 305.3276891708374 and batch: 700, loss is 4.787644157409668 and perplexity is 120.01829114919855
At time: 305.72517824172974 and batch: 750, loss is 4.7137406635284425 and perplexity is 111.46834659189912
At time: 306.12314534187317 and batch: 800, loss is 4.658169736862183 and perplexity is 105.442917154779
At time: 306.5267038345337 and batch: 850, loss is 4.633512735366821 and perplexity is 102.87480210671164
At time: 306.9145812988281 and batch: 900, loss is 4.570926504135132 and perplexity is 96.63359973978244
At time: 307.30149030685425 and batch: 950, loss is 4.660238256454468 and perplexity is 105.66125363357239
At time: 307.7108588218689 and batch: 1000, loss is 4.698207702636719 and perplexity is 109.75029091267336
At time: 308.10443115234375 and batch: 1050, loss is 4.615565814971924 and perplexity is 101.0449851263501
At time: 308.51815700531006 and batch: 1100, loss is 4.7270897769927975 and perplexity is 112.96632630402402
At time: 308.9047248363495 and batch: 1150, loss is 4.670557518005371 and perplexity is 106.75724493030503
At time: 309.29378056526184 and batch: 1200, loss is 4.624038333892822 and perplexity is 101.90472762404124
At time: 309.6822600364685 and batch: 1250, loss is 4.6300632286071775 and perplexity is 102.52054613690586
At time: 310.0710632801056 and batch: 1300, loss is 4.681794319152832 and perplexity is 107.96362006777885
At time: 310.47381019592285 and batch: 1350, loss is 4.628345613479614 and perplexity is 102.34460643757443
At time: 310.86347818374634 and batch: 1400, loss is 4.5309827709198 and perplexity is 92.84976630808683
At time: 311.26354146003723 and batch: 1450, loss is 4.607633638381958 and perplexity is 100.2466489185867
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.037319607204861 and perplexity of 154.05652911044234
Finished 25 epochs...
Completing Train Step...
At time: 312.559201002121 and batch: 50, loss is 4.759891204833984 and perplexity is 116.73322519750005
At time: 312.9769480228424 and batch: 100, loss is 4.760091257095337 and perplexity is 116.7565802792164
At time: 313.3880877494812 and batch: 150, loss is 4.663903799057007 and perplexity is 106.04927017132306
At time: 313.7748312950134 and batch: 200, loss is 4.709588298797607 and perplexity is 111.00644900819907
At time: 314.18197560310364 and batch: 250, loss is 4.729468612670899 and perplexity is 113.23537451532667
At time: 314.57557559013367 and batch: 300, loss is 4.7318704891204835 and perplexity is 113.50767878432985
At time: 314.9748773574829 and batch: 350, loss is 4.768579139709472 and perplexity is 117.75181416619952
At time: 315.3712296485901 and batch: 400, loss is 4.642159948348999 and perplexity is 103.76823973659006
At time: 315.765337228775 and batch: 450, loss is 4.6983051586151126 and perplexity is 109.76098725585611
At time: 316.1713013648987 and batch: 500, loss is 4.673490533828735 and perplexity is 107.07082526218205
At time: 316.5654983520508 and batch: 550, loss is 4.7311319065093995 and perplexity is 113.42387493839654
At time: 316.96214056015015 and batch: 600, loss is 4.6319046974182125 and perplexity is 102.70950845581791
At time: 317.3501582145691 and batch: 650, loss is 4.74108057975769 and perplexity is 114.55792379584987
At time: 317.74183416366577 and batch: 700, loss is 4.786872625350952 and perplexity is 119.92572890190685
At time: 318.13666582107544 and batch: 750, loss is 4.712992324829101 and perplexity is 111.38496171834811
At time: 318.5258758068085 and batch: 800, loss is 4.657521314620972 and perplexity is 105.37456778413852
At time: 318.9279899597168 and batch: 850, loss is 4.6331542873382565 and perplexity is 102.83793344485183
At time: 319.33121943473816 and batch: 900, loss is 4.570588274002075 and perplexity is 96.60092087128525
At time: 319.73851799964905 and batch: 950, loss is 4.659445695877075 and perplexity is 105.57754386629709
At time: 320.13428592681885 and batch: 1000, loss is 4.697615184783936 and perplexity is 109.68528116757872
At time: 320.5465576648712 and batch: 1050, loss is 4.615086498260498 and perplexity is 100.9965641817843
At time: 320.9410126209259 and batch: 1100, loss is 4.727000541687012 and perplexity is 112.95624616911147
At time: 321.3267171382904 and batch: 1150, loss is 4.670673942565918 and perplexity is 106.76967481918939
At time: 321.73602533340454 and batch: 1200, loss is 4.624164257049561 and perplexity is 101.9175605969975
At time: 322.1347818374634 and batch: 1250, loss is 4.629898710250854 and perplexity is 102.5036810125154
At time: 322.53693652153015 and batch: 1300, loss is 4.6814681434631344 and perplexity is 107.92841070207271
At time: 322.93218421936035 and batch: 1350, loss is 4.628261566162109 and perplexity is 102.33600500941081
At time: 323.3276216983795 and batch: 1400, loss is 4.530705585479736 and perplexity is 92.82403327132923
At time: 323.7278082370758 and batch: 1450, loss is 4.607345991134643 and perplexity is 100.21781739282608
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.03729248046875 and perplexity of 154.0523501163125
Finished 26 epochs...
Completing Train Step...
At time: 324.97896671295166 and batch: 50, loss is 4.758718681335449 and perplexity is 116.59643295962485
At time: 325.39372658729553 and batch: 100, loss is 4.75907829284668 and perplexity is 116.6383699191403
At time: 325.7813136577606 and batch: 150, loss is 4.662835159301758 and perplexity is 105.93600223729075
At time: 326.18298530578613 and batch: 200, loss is 4.708690891265869 and perplexity is 110.90687567040179
At time: 326.5774621963501 and batch: 250, loss is 4.7284159755706785 and perplexity is 113.11624147198555
At time: 326.96932458877563 and batch: 300, loss is 4.731095657348633 and perplexity is 113.41976349263783
At time: 327.3811283111572 and batch: 350, loss is 4.767901334762573 and perplexity is 117.67202844668363
At time: 327.77955746650696 and batch: 400, loss is 4.641776647567749 and perplexity is 103.72847291104462
At time: 328.18982458114624 and batch: 450, loss is 4.6974471950531 and perplexity is 109.66685671432158
At time: 328.59633803367615 and batch: 500, loss is 4.672295618057251 and perplexity is 106.94296105310441
At time: 329.0046532154083 and batch: 550, loss is 4.730389995574951 and perplexity is 113.3397557336896
At time: 329.40630316734314 and batch: 600, loss is 4.631293506622314 and perplexity is 102.64675252947433
At time: 329.8019690513611 and batch: 650, loss is 4.740369968414306 and perplexity is 114.47654655294642
At time: 330.2050943374634 and batch: 700, loss is 4.786110219955444 and perplexity is 119.83433172440955
At time: 330.6019220352173 and batch: 750, loss is 4.712413101196289 and perplexity is 111.32046359740221
At time: 331.00909304618835 and batch: 800, loss is 4.656830234527588 and perplexity is 105.30177067520764
At time: 331.3992283344269 and batch: 850, loss is 4.632752981185913 and perplexity is 102.7966722292097
At time: 331.7972252368927 and batch: 900, loss is 4.570265865325927 and perplexity is 96.56978091643805
At time: 332.21605348587036 and batch: 950, loss is 4.658626184463501 and perplexity is 105.49105730728307
At time: 332.61762976646423 and batch: 1000, loss is 4.696975173950196 and perplexity is 109.61510385884407
At time: 333.0411853790283 and batch: 1050, loss is 4.614714345932007 and perplexity is 100.9589850682654
At time: 333.43354845046997 and batch: 1100, loss is 4.726790647506714 and perplexity is 112.93253979841396
At time: 333.8236927986145 and batch: 1150, loss is 4.670751628875732 and perplexity is 106.7779696834207
At time: 334.236141204834 and batch: 1200, loss is 4.624152956008911 and perplexity is 101.91640882901035
At time: 334.6374042034149 and batch: 1250, loss is 4.629732131958008 and perplexity is 102.48660754639573
At time: 335.03090143203735 and batch: 1300, loss is 4.681096334457397 and perplexity is 107.88828940619052
At time: 335.42715978622437 and batch: 1350, loss is 4.62810718536377 and perplexity is 102.32020751470485
At time: 335.83104038238525 and batch: 1400, loss is 4.530310831069946 and perplexity is 92.78739780634231
At time: 336.2254960536957 and batch: 1450, loss is 4.606934299468994 and perplexity is 100.17656704445086
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.037315955528846 and perplexity of 154.0559665469372
Annealing...
Finished 27 epochs...
Completing Train Step...
At time: 337.5414445400238 and batch: 50, loss is 4.757131414413452 and perplexity is 116.41151009816055
At time: 337.936895608902 and batch: 100, loss is 4.7579412841796875 and perplexity is 116.50582644745563
At time: 338.3320255279541 and batch: 150, loss is 4.66141282081604 and perplexity is 105.78543249024274
At time: 338.7308084964752 and batch: 200, loss is 4.707809371948242 and perplexity is 110.80915219593417
At time: 339.12522292137146 and batch: 250, loss is 4.727363224029541 and perplexity is 112.99722083502014
At time: 339.5263705253601 and batch: 300, loss is 4.729855279922486 and perplexity is 113.27916739246304
At time: 339.9305341243744 and batch: 350, loss is 4.765184144973755 and perplexity is 117.35272521275667
At time: 340.3330090045929 and batch: 400, loss is 4.6387269115448 and perplexity is 103.41261034414347
At time: 340.73080682754517 and batch: 450, loss is 4.694750518798828 and perplexity is 109.37151909988143
At time: 341.1284520626068 and batch: 500, loss is 4.667906951904297 and perplexity is 106.47465247628438
At time: 341.5249526500702 and batch: 550, loss is 4.726457033157349 and perplexity is 112.89487016654115
At time: 341.92611145973206 and batch: 600, loss is 4.627756977081299 and perplexity is 102.28438040441065
At time: 342.3316421508789 and batch: 650, loss is 4.737878351211548 and perplexity is 114.19166986944528
At time: 342.72857213020325 and batch: 700, loss is 4.781998157501221 and perplexity is 119.34257722373337
At time: 343.1680669784546 and batch: 750, loss is 4.708256340026855 and perplexity is 110.85869142018511
At time: 343.5558030605316 and batch: 800, loss is 4.651308650970459 and perplexity is 104.72194041347953
At time: 343.9505877494812 and batch: 850, loss is 4.627782249450684 and perplexity is 102.28696540571895
At time: 344.3473308086395 and batch: 900, loss is 4.565188446044922 and perplexity is 96.08069833822631
At time: 344.75796699523926 and batch: 950, loss is 4.650634384155273 and perplexity is 104.65135368405572
At time: 345.1612739562988 and batch: 1000, loss is 4.69125916481018 and perplexity is 108.99033023027783
At time: 345.5587546825409 and batch: 1050, loss is 4.607412490844727 and perplexity is 100.224482070225
At time: 345.97430419921875 and batch: 1100, loss is 4.721880512237549 and perplexity is 112.37938489576534
At time: 346.3721754550934 and batch: 1150, loss is 4.6623820781707765 and perplexity is 105.88801550534774
At time: 346.76709246635437 and batch: 1200, loss is 4.617894821166992 and perplexity is 101.28059378320023
At time: 347.15947008132935 and batch: 1250, loss is 4.621464233398438 and perplexity is 101.64275193481376
At time: 347.57450795173645 and batch: 1300, loss is 4.672351427078247 and perplexity is 106.94892960161113
At time: 347.9739091396332 and batch: 1350, loss is 4.620757989883423 and perplexity is 101.57099274312603
At time: 348.3723154067993 and batch: 1400, loss is 4.519927263259888 and perplexity is 91.82891839906193
At time: 348.7843291759491 and batch: 1450, loss is 4.5975573444366455 and perplexity is 99.24160627323784
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.034510425013354 and perplexity of 153.6243635524776
Finished 28 epochs...
Completing Train Step...
At time: 350.07653188705444 and batch: 50, loss is 4.754655361175537 and perplexity is 116.12362555745713
At time: 350.47894048690796 and batch: 100, loss is 4.756386966705322 and perplexity is 116.32488006603332
At time: 350.88270711898804 and batch: 150, loss is 4.660090055465698 and perplexity is 105.64559569159911
At time: 351.2812166213989 and batch: 200, loss is 4.70704421043396 and perplexity is 110.72439772680768
At time: 351.6696186065674 and batch: 250, loss is 4.726333084106446 and perplexity is 112.88087782171904
At time: 352.05933260917664 and batch: 300, loss is 4.729014892578125 and perplexity is 113.18400900435964
At time: 352.4560344219208 and batch: 350, loss is 4.764120292663574 and perplexity is 117.22794563022522
At time: 352.856379032135 and batch: 400, loss is 4.637675886154175 and perplexity is 103.30397816255159
At time: 353.2681028842926 and batch: 450, loss is 4.693199253082275 and perplexity is 109.20198634111006
At time: 353.6848747730255 and batch: 500, loss is 4.666717872619629 and perplexity is 106.34812091562013
At time: 354.0828695297241 and batch: 550, loss is 4.7257817935943605 and perplexity is 112.81866481507586
At time: 354.47111988067627 and batch: 600, loss is 4.627205247879028 and perplexity is 102.22796268988684
At time: 354.8604254722595 and batch: 650, loss is 4.7375898265838625 and perplexity is 114.15872751298049
At time: 355.2696259021759 and batch: 700, loss is 4.781283950805664 and perplexity is 119.25737238656961
At time: 355.66527462005615 and batch: 750, loss is 4.707456779479981 and perplexity is 110.77008861062313
At time: 356.0582962036133 and batch: 800, loss is 4.650714254379272 and perplexity is 104.65971254492388
At time: 356.44438767433167 and batch: 850, loss is 4.6273317050933835 and perplexity is 102.24089097069776
At time: 356.82935094833374 and batch: 900, loss is 4.564641981124878 and perplexity is 96.02820795047518
At time: 357.2427430152893 and batch: 950, loss is 4.650475950241089 and perplexity is 104.63477467384028
At time: 357.638388633728 and batch: 1000, loss is 4.691344804763794 and perplexity is 108.99966455679306
At time: 358.0380971431732 and batch: 1050, loss is 4.6076115703582765 and perplexity is 100.24443669757416
At time: 358.43471574783325 and batch: 1100, loss is 4.7221145343780515 and perplexity is 112.40568723751213
At time: 358.84980511665344 and batch: 1150, loss is 4.662472848892212 and perplexity is 105.89762747314253
At time: 359.23670387268066 and batch: 1200, loss is 4.618159303665161 and perplexity is 101.30738427031136
At time: 359.62254905700684 and batch: 1250, loss is 4.621728811264038 and perplexity is 101.66964791505804
At time: 360.02867245674133 and batch: 1300, loss is 4.6726609802246095 and perplexity is 106.98204110388983
At time: 360.4215793609619 and batch: 1350, loss is 4.621342325210572 and perplexity is 101.63036160637223
At time: 360.8216633796692 and batch: 1400, loss is 4.520302028656006 and perplexity is 91.86333914949105
At time: 361.20868396759033 and batch: 1450, loss is 4.598091039657593 and perplexity is 99.29458518026225
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.034290281116453 and perplexity of 153.5905478087276
Finished 29 epochs...
Completing Train Step...
At time: 362.5597274303436 and batch: 50, loss is 4.753522062301636 and perplexity is 115.99209732785435
At time: 362.9798939228058 and batch: 100, loss is 4.75555567741394 and perplexity is 116.22822062046048
At time: 363.3807442188263 and batch: 150, loss is 4.659472980499268 and perplexity is 105.58042454899251
At time: 363.7978718280792 and batch: 200, loss is 4.706725187301636 and perplexity is 110.68907971655088
At time: 364.193443775177 and batch: 250, loss is 4.725795402526855 and perplexity is 112.82020016711671
At time: 364.5968744754791 and batch: 300, loss is 4.728563489913941 and perplexity is 113.13292897085104
At time: 364.99281191825867 and batch: 350, loss is 4.763443193435669 and perplexity is 117.14859754504518
At time: 365.3847758769989 and batch: 400, loss is 4.637115097045898 and perplexity is 103.24606265746641
At time: 365.77326130867004 and batch: 450, loss is 4.692176122665405 and perplexity is 109.09031560390714
At time: 366.1618311405182 and batch: 500, loss is 4.66603642463684 and perplexity is 106.27567489005128
At time: 366.5729966163635 and batch: 550, loss is 4.725379753112793 and perplexity is 112.77331626133181
At time: 366.97251200675964 and batch: 600, loss is 4.62690544128418 and perplexity is 102.19731866636417
At time: 367.3796043395996 and batch: 650, loss is 4.737457256317139 and perplexity is 114.14359446314369
At time: 367.7834062576294 and batch: 700, loss is 4.780935926437378 and perplexity is 119.21587513632734
At time: 368.1876049041748 and batch: 750, loss is 4.706962652206421 and perplexity is 110.71536760942898
At time: 368.5753300189972 and batch: 800, loss is 4.650349445343018 and perplexity is 104.62153869956094
At time: 368.9628915786743 and batch: 850, loss is 4.627019510269165 and perplexity is 102.20897687568011
At time: 369.3680908679962 and batch: 900, loss is 4.564355163574219 and perplexity is 96.00066932454604
At time: 369.77020740509033 and batch: 950, loss is 4.650341749191284 and perplexity is 104.6207335194229
At time: 370.17437839508057 and batch: 1000, loss is 4.6913760471343995 and perplexity is 109.00307001790605
At time: 370.57514929771423 and batch: 1050, loss is 4.607757015228271 and perplexity is 100.25901779698471
At time: 370.976482629776 and batch: 1100, loss is 4.722311563491822 and perplexity is 112.42783661241545
At time: 371.3790616989136 and batch: 1150, loss is 4.662471532821655 and perplexity is 105.89748810448472
At time: 371.7736530303955 and batch: 1200, loss is 4.618343286514282 and perplexity is 101.32602480622329
At time: 372.1826972961426 and batch: 1250, loss is 4.6217053031921385 and perplexity is 101.66725788575742
At time: 372.5734751224518 and batch: 1300, loss is 4.6728404712677 and perplexity is 107.00124514546472
At time: 372.96496081352234 and batch: 1350, loss is 4.621667194366455 and perplexity is 101.66338353977278
At time: 373.3506033420563 and batch: 1400, loss is 4.520305900573731 and perplexity is 91.86369483747079
At time: 373.75637221336365 and batch: 1450, loss is 4.598303642272949 and perplexity is 99.3156977129726
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.034147344083867 and perplexity of 153.56859560051967
Finished 30 epochs...
Completing Train Step...
At time: 375.09461092948914 and batch: 50, loss is 4.752642126083374 and perplexity is 115.89007657284482
At time: 375.4971787929535 and batch: 100, loss is 4.7549638748168945 and perplexity is 116.15945680695592
At time: 375.8965034484863 and batch: 150, loss is 4.658910522460937 and perplexity is 105.52105668804504
At time: 376.28422236442566 and batch: 200, loss is 4.706457929611206 and perplexity is 110.65950116147424
At time: 376.6837377548218 and batch: 250, loss is 4.725394029617309 and perplexity is 112.77492628158345
At time: 377.0760419368744 and batch: 300, loss is 4.728194274902344 and perplexity is 113.091166305345
At time: 377.4681451320648 and batch: 350, loss is 4.762842979431152 and perplexity is 117.07830441376035
At time: 377.8668339252472 and batch: 400, loss is 4.6365998840332034 and perplexity is 103.19288264316984
At time: 378.25549507141113 and batch: 450, loss is 4.691312990188599 and perplexity is 108.99619683393108
At time: 378.6522364616394 and batch: 500, loss is 4.665477266311646 and perplexity is 106.21626657254636
At time: 379.0574269294739 and batch: 550, loss is 4.725061063766479 and perplexity is 112.73738233307508
At time: 379.4575979709625 and batch: 600, loss is 4.626590938568115 and perplexity is 102.16518238580771
At time: 379.86147141456604 and batch: 650, loss is 4.737294044494629 and perplexity is 114.12496639926495
At time: 380.2600619792938 and batch: 700, loss is 4.780547723770142 and perplexity is 119.16960419745459
At time: 380.65930795669556 and batch: 750, loss is 4.706401758193969 and perplexity is 110.653285435038
At time: 381.06396770477295 and batch: 800, loss is 4.650016584396362 and perplexity is 104.58672007035128
At time: 381.47458839416504 and batch: 850, loss is 4.626724939346314 and perplexity is 102.17887351704289
At time: 381.87199425697327 and batch: 900, loss is 4.563994960784912 and perplexity is 95.96609584278612
At time: 382.27192854881287 and batch: 950, loss is 4.6501344871520995 and perplexity is 104.59905185982278
At time: 382.67112135887146 and batch: 1000, loss is 4.691412239074707 and perplexity is 109.00701512189957
At time: 383.06570386886597 and batch: 1050, loss is 4.607787122726441 and perplexity is 100.2620363906204
At time: 383.46327805519104 and batch: 1100, loss is 4.722318925857544 and perplexity is 112.42866435031301
At time: 383.8709981441498 and batch: 1150, loss is 4.662445774078369 and perplexity is 105.89476035340589
At time: 384.2650990486145 and batch: 1200, loss is 4.618484926223755 and perplexity is 101.34037761137849
At time: 384.6548833847046 and batch: 1250, loss is 4.621733322143554 and perplexity is 101.67010653562461
At time: 385.05288672447205 and batch: 1300, loss is 4.672954626083374 and perplexity is 107.01346055009155
At time: 385.4580352306366 and batch: 1350, loss is 4.621933450698853 and perplexity is 101.69045566331548
At time: 385.8636894226074 and batch: 1400, loss is 4.520336351394653 and perplexity is 91.86649220498242
At time: 386.2619585990906 and batch: 1450, loss is 4.598381986618042 and perplexity is 99.32347884106709
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.034087352263621 and perplexity of 153.5593830172796
Finished 31 epochs...
Completing Train Step...
At time: 387.5585069656372 and batch: 50, loss is 4.7519106197357175 and perplexity is 115.80533324512135
At time: 387.96303248405457 and batch: 100, loss is 4.754490461349487 and perplexity is 116.1044783705297
At time: 388.35857701301575 and batch: 150, loss is 4.658491525650025 and perplexity is 105.4768529630652
At time: 388.7621281147003 and batch: 200, loss is 4.706290340423584 and perplexity is 110.64095737948395
At time: 389.16523122787476 and batch: 250, loss is 4.725093097686767 and perplexity is 112.74099381123881
At time: 389.5587592124939 and batch: 300, loss is 4.727915191650391 and perplexity is 113.05960885866762
At time: 389.95850706100464 and batch: 350, loss is 4.762369651794433 and perplexity is 117.02290112960827
At time: 390.3523530960083 and batch: 400, loss is 4.636240100860595 and perplexity is 103.15576225850721
At time: 390.75499272346497 and batch: 450, loss is 4.6906032371521 and perplexity is 108.91886389915041
At time: 391.1428349018097 and batch: 500, loss is 4.665036602020264 and perplexity is 106.16947116799305
At time: 391.5402855873108 and batch: 550, loss is 4.724840698242187 and perplexity is 112.71254163782686
At time: 391.93788027763367 and batch: 600, loss is 4.626424541473389 and perplexity is 102.14818381057255
At time: 392.3291025161743 and batch: 650, loss is 4.737213592529297 and perplexity is 114.11578519075283
At time: 392.72492718696594 and batch: 700, loss is 4.7803263759613035 and perplexity is 119.14322918581854
At time: 393.129522562027 and batch: 750, loss is 4.706097679138184 and perplexity is 110.61964320369152
At time: 393.5467526912689 and batch: 800, loss is 4.649788055419922 and perplexity is 104.56282170510283
At time: 393.9731795787811 and batch: 850, loss is 4.626479501724243 and perplexity is 102.15379805465781
At time: 394.39559388160706 and batch: 900, loss is 4.563772821426392 and perplexity is 95.94478036340702
At time: 394.807519197464 and batch: 950, loss is 4.6499611759185795 and perplexity is 104.58092523993872
At time: 395.21221685409546 and batch: 1000, loss is 4.691383256912231 and perplexity is 109.0038559086569
At time: 395.60852789878845 and batch: 1050, loss is 4.607857875823974 and perplexity is 100.2691304912219
At time: 395.99691462516785 and batch: 1100, loss is 4.722445344924926 and perplexity is 112.44287837565022
At time: 396.41004824638367 and batch: 1150, loss is 4.662386751174926 and perplexity is 105.88851032163976
At time: 396.81607460975647 and batch: 1200, loss is 4.618536891937256 and perplexity is 101.34564397324148
At time: 397.2360165119171 and batch: 1250, loss is 4.621756753921509 and perplexity is 101.67248887489667
At time: 397.6381323337555 and batch: 1300, loss is 4.673038539886474 and perplexity is 107.02244083332879
At time: 398.0427043437958 and batch: 1350, loss is 4.622141017913818 and perplexity is 101.71156545876099
At time: 398.4391989707947 and batch: 1400, loss is 4.520332756042481 and perplexity is 91.86616191318386
At time: 398.828729391098 and batch: 1450, loss is 4.598415088653565 and perplexity is 99.32676670480909
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.034060747195513 and perplexity of 153.55529761378216
Finished 32 epochs...
Completing Train Step...
At time: 400.11347365379333 and batch: 50, loss is 4.751287565231324 and perplexity is 115.73320268357918
At time: 400.5156009197235 and batch: 100, loss is 4.754090881347656 and perplexity is 116.0580946104784
At time: 400.9161376953125 and batch: 150, loss is 4.658107967376709 and perplexity is 105.43640420119242
At time: 401.32071256637573 and batch: 200, loss is 4.706145248413086 and perplexity is 110.6249054250677
At time: 401.728173494339 and batch: 250, loss is 4.724853029251099 and perplexity is 112.71393150575148
At time: 402.115300655365 and batch: 300, loss is 4.727664489746093 and perplexity is 113.03126815211058
At time: 402.5117976665497 and batch: 350, loss is 4.761946020126342 and perplexity is 116.97333702200194
At time: 402.9175715446472 and batch: 400, loss is 4.635915594100952 and perplexity is 103.12229294716077
At time: 403.31603717803955 and batch: 450, loss is 4.689963436126709 and perplexity is 108.84919978630508
At time: 403.7176716327667 and batch: 500, loss is 4.664658946990967 and perplexity is 106.12938330341696
At time: 404.1231815814972 and batch: 550, loss is 4.724653244018555 and perplexity is 112.6914151760246
At time: 404.5353276729584 and batch: 600, loss is 4.626279344558716 and perplexity is 102.13335328614306
At time: 404.9336929321289 and batch: 650, loss is 4.737163639068603 and perplexity is 114.11008485473967
At time: 405.33741450309753 and batch: 700, loss is 4.780143957138062 and perplexity is 119.12149720037513
At time: 405.7353663444519 and batch: 750, loss is 4.70587082862854 and perplexity is 110.59455192734617
At time: 406.1295566558838 and batch: 800, loss is 4.64954535484314 and perplexity is 104.53744732727762
At time: 406.5266315937042 and batch: 850, loss is 4.62626543045044 and perplexity is 102.13193220149341
At time: 406.9220390319824 and batch: 900, loss is 4.563568096160889 and perplexity is 95.92514005327595
At time: 407.31366300582886 and batch: 950, loss is 4.649791231155396 and perplexity is 104.56315376949222
At time: 407.71308279037476 and batch: 1000, loss is 4.691344537734985 and perplexity is 108.99963545074635
At time: 408.1059548854828 and batch: 1050, loss is 4.607906274795532 and perplexity is 100.27398353145678
At time: 408.5045208930969 and batch: 1100, loss is 4.722548589706421 and perplexity is 112.45448811537096
At time: 408.89900517463684 and batch: 1150, loss is 4.662316789627075 and perplexity is 105.88110245669388
At time: 409.2862751483917 and batch: 1200, loss is 4.618575372695923 and perplexity is 101.34954390554483
At time: 409.6724901199341 and batch: 1250, loss is 4.62176812171936 and perplexity is 101.67364467376669
At time: 410.05875396728516 and batch: 1300, loss is 4.67309419631958 and perplexity is 107.02839748640933
At time: 410.4624180793762 and batch: 1350, loss is 4.6223132610321045 and perplexity is 101.72908608482172
At time: 410.84873485565186 and batch: 1400, loss is 4.520286607742309 and perplexity is 91.86192254378889
At time: 411.24549555778503 and batch: 1450, loss is 4.598401508331299 and perplexity is 99.32541782446675
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.034045618823451 and perplexity of 153.55297458967965
Finished 33 epochs...
Completing Train Step...
At time: 412.5281910896301 and batch: 50, loss is 4.7507295989990235 and perplexity is 115.66864547657144
At time: 412.9284749031067 and batch: 100, loss is 4.75373966217041 and perplexity is 116.01733993930662
At time: 413.33569979667664 and batch: 150, loss is 4.6577614402771 and perplexity is 105.39987395957628
At time: 413.7393057346344 and batch: 200, loss is 4.706018695831299 and perplexity is 110.6109064434985
At time: 414.142502784729 and batch: 250, loss is 4.724638519287109 and perplexity is 112.6897558374166
At time: 414.5425503253937 and batch: 300, loss is 4.727421550750733 and perplexity is 113.00381178462757
At time: 414.942706823349 and batch: 350, loss is 4.761562662124634 and perplexity is 116.92850295156691
At time: 415.346715927124 and batch: 400, loss is 4.635624694824219 and perplexity is 103.09229910953168
At time: 415.7472858428955 and batch: 450, loss is 4.68936562538147 and perplexity is 108.78414801132455
At time: 416.1448757648468 and batch: 500, loss is 4.664312686920166 and perplexity is 106.09264129715221
At time: 416.5367033481598 and batch: 550, loss is 4.724489278793335 and perplexity is 112.67293921750371
At time: 416.927205324173 and batch: 600, loss is 4.62615587234497 and perplexity is 102.12074343341479
At time: 417.31449842453003 and batch: 650, loss is 4.737116432189941 and perplexity is 114.10469820095436
At time: 417.7027471065521 and batch: 700, loss is 4.7799673271179195 and perplexity is 119.10045862600184
At time: 418.0909161567688 and batch: 750, loss is 4.705660810470581 and perplexity is 110.571327502131
At time: 418.4795083999634 and batch: 800, loss is 4.649314270019532 and perplexity is 104.51329310064665
At time: 418.8785262107849 and batch: 850, loss is 4.626060905456543 and perplexity is 102.11104580465117
At time: 419.27243852615356 and batch: 900, loss is 4.563373527526855 and perplexity is 95.90647784540533
At time: 419.67506980895996 and batch: 950, loss is 4.649622173309326 and perplexity is 104.54547804208998
At time: 420.0716075897217 and batch: 1000, loss is 4.691315040588379 and perplexity is 108.99642031993828
At time: 420.4688618183136 and batch: 1050, loss is 4.607920246124268 and perplexity is 100.27538450203103
At time: 420.8721833229065 and batch: 1100, loss is 4.722632369995117 and perplexity is 112.46390997952817
At time: 421.2880470752716 and batch: 1150, loss is 4.6622419357299805 and perplexity is 105.87317714017041
At time: 421.6887767314911 and batch: 1200, loss is 4.618616094589234 and perplexity is 101.35367113489256
At time: 422.0777657032013 and batch: 1250, loss is 4.621744709014893 and perplexity is 101.67126424663803
At time: 422.4669563770294 and batch: 1300, loss is 4.673125448226929 and perplexity is 107.03174238023819
At time: 422.8531262874603 and batch: 1350, loss is 4.622454223632812 and perplexity is 101.74342709211294
At time: 423.24259400367737 and batch: 1400, loss is 4.520207872390747 and perplexity is 91.85469004775253
At time: 423.646235704422 and batch: 1450, loss is 4.598352012634277 and perplexity is 99.32050176534243
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0340268387753735 and perplexity of 153.55009088451254
Finished 34 epochs...
Completing Train Step...
At time: 424.89366698265076 and batch: 50, loss is 4.750219144821167 and perplexity is 115.60961700018883
At time: 425.3085470199585 and batch: 100, loss is 4.753410787582397 and perplexity is 115.97919105787436
At time: 425.70544171333313 and batch: 150, loss is 4.657448587417602 and perplexity is 105.36690446518654
At time: 426.0980830192566 and batch: 200, loss is 4.705897817611694 and perplexity is 110.59753680212427
At time: 426.48617935180664 and batch: 250, loss is 4.724438924789428 and perplexity is 112.66726582672231
At time: 426.874085187912 and batch: 300, loss is 4.727181692123413 and perplexity is 112.97671009586786
At time: 427.2670474052429 and batch: 350, loss is 4.761202383041382 and perplexity is 116.88638364552556
At time: 427.6571445465088 and batch: 400, loss is 4.635354127883911 and perplexity is 103.06440951476364
At time: 428.0569067001343 and batch: 450, loss is 4.688804864883423 and perplexity is 108.72316325882427
At time: 428.45381689071655 and batch: 500, loss is 4.663991279602051 and perplexity is 106.0585478250804
At time: 428.8573682308197 and batch: 550, loss is 4.7243242263793945 and perplexity is 112.6543438115506
At time: 429.2542006969452 and batch: 600, loss is 4.626037807464599 and perplexity is 102.10868727177657
At time: 429.6647837162018 and batch: 650, loss is 4.737069311141968 and perplexity is 114.09932159467316
At time: 430.0691888332367 and batch: 700, loss is 4.779792575836182 and perplexity is 119.07964748664101
At time: 430.4637703895569 and batch: 750, loss is 4.705470151901245 and perplexity is 110.55024814056418
At time: 430.8678939342499 and batch: 800, loss is 4.64908844947815 and perplexity is 104.48969451683983
At time: 431.26554131507874 and batch: 850, loss is 4.625864114761352 and perplexity is 102.09095327803658
At time: 431.66568541526794 and batch: 900, loss is 4.563190650939942 and perplexity is 95.88894039971701
At time: 432.06364369392395 and batch: 950, loss is 4.6494529247283936 and perplexity is 104.5277853655609
At time: 432.4511785507202 and batch: 1000, loss is 4.691273975372314 and perplexity is 108.99194445028944
At time: 432.84795451164246 and batch: 1050, loss is 4.607916536331177 and perplexity is 100.27501250179247
At time: 433.23549461364746 and batch: 1100, loss is 4.722699031829834 and perplexity is 112.471407279996
At time: 433.63215041160583 and batch: 1150, loss is 4.662162656784058 and perplexity is 105.86478395899091
At time: 434.03893184661865 and batch: 1200, loss is 4.618645963668823 and perplexity is 101.35669852097475
At time: 434.47648763656616 and batch: 1250, loss is 4.6217074203491215 and perplexity is 101.66747313153026
At time: 434.88117694854736 and batch: 1300, loss is 4.673143358230591 and perplexity is 107.0336593363024
At time: 435.2792775630951 and batch: 1350, loss is 4.6225653076171875 and perplexity is 101.75472978514081
At time: 435.67933416366577 and batch: 1400, loss is 4.520120725631714 and perplexity is 91.84668555800062
At time: 436.0750412940979 and batch: 1450, loss is 4.5982904052734375 and perplexity is 99.31438307983139
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.034017970419337 and perplexity of 153.54872915367534
Finished 35 epochs...
Completing Train Step...
At time: 437.40371656417847 and batch: 50, loss is 4.7497513961791995 and perplexity is 115.55555340391119
At time: 437.79899978637695 and batch: 100, loss is 4.7531013011932375 and perplexity is 115.94330263059254
At time: 438.1901550292969 and batch: 150, loss is 4.657141742706298 and perplexity is 105.33457814763837
At time: 438.5759172439575 and batch: 200, loss is 4.705756092071534 and perplexity is 110.58186341716628
At time: 438.96089935302734 and batch: 250, loss is 4.724240636825561 and perplexity is 112.64492747877303
At time: 439.35979104042053 and batch: 300, loss is 4.726948461532593 and perplexity is 112.95036354355372
At time: 439.75256276130676 and batch: 350, loss is 4.7608636856079105 and perplexity is 116.84680123098659
At time: 440.15577363967896 and batch: 400, loss is 4.635091695785523 and perplexity is 103.03736565424927
At time: 440.5505301952362 and batch: 450, loss is 4.68828784942627 and perplexity is 108.66696623148657
At time: 440.93818855285645 and batch: 500, loss is 4.66369550704956 and perplexity is 106.02718325629463
At time: 441.3393919467926 and batch: 550, loss is 4.724160060882569 and perplexity is 112.6358513731809
At time: 441.7419934272766 and batch: 600, loss is 4.625921201705933 and perplexity is 102.09678150498478
At time: 442.1455891132355 and batch: 650, loss is 4.737014999389649 and perplexity is 114.09312482885902
At time: 442.5484790802002 and batch: 700, loss is 4.779613742828369 and perplexity is 119.05835401915583
At time: 442.9514648914337 and batch: 750, loss is 4.705276136398315 and perplexity is 110.52880175910467
At time: 443.3529243469238 and batch: 800, loss is 4.648867988586426 and perplexity is 104.4666611646807
At time: 443.74671745300293 and batch: 850, loss is 4.625671682357788 and perplexity is 102.07130956061957
At time: 444.14402961730957 and batch: 900, loss is 4.563005132675171 and perplexity is 95.87115289988742
At time: 444.5445899963379 and batch: 950, loss is 4.649295291900635 and perplexity is 104.511309653765
At time: 444.93299174308777 and batch: 1000, loss is 4.691222372055054 and perplexity is 108.98632024951613
At time: 445.32130575180054 and batch: 1050, loss is 4.607905759811401 and perplexity is 100.27393189195982
At time: 445.7141954898834 and batch: 1100, loss is 4.722749195098877 and perplexity is 112.47704935497026
At time: 446.10158705711365 and batch: 1150, loss is 4.662073564529419 and perplexity is 105.85535264683585
At time: 446.4888460636139 and batch: 1200, loss is 4.618669223785401 and perplexity is 101.35905611701715
At time: 446.89177083969116 and batch: 1250, loss is 4.621658439636231 and perplexity is 101.6624935081722
At time: 447.2858099937439 and batch: 1300, loss is 4.673137865066528 and perplexity is 107.03307138446634
At time: 447.67771100997925 and batch: 1350, loss is 4.622650175094605 and perplexity is 101.76336581882695
At time: 448.07467007637024 and batch: 1400, loss is 4.520022068023682 and perplexity is 91.83762463066982
At time: 448.4822361469269 and batch: 1450, loss is 4.598182640075684 and perplexity is 99.303681022364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.034015883747329 and perplexity of 153.54840874817458
Finished 36 epochs...
Completing Train Step...
At time: 449.83639001846313 and batch: 50, loss is 4.749299221038818 and perplexity is 115.50331386692899
At time: 450.2239637374878 and batch: 100, loss is 4.752805233001709 and perplexity is 115.90898058774614
At time: 450.6234908103943 and batch: 150, loss is 4.656828422546386 and perplexity is 105.30157987055156
At time: 451.01575994491577 and batch: 200, loss is 4.7056380653381344 and perplexity is 110.56881257124347
At time: 451.41397428512573 and batch: 250, loss is 4.724044380187988 and perplexity is 112.62282233327807
At time: 451.82485008239746 and batch: 300, loss is 4.726708927154541 and perplexity is 112.92331128857349
At time: 452.21770572662354 and batch: 350, loss is 4.760539407730103 and perplexity is 116.80891654117016
At time: 452.60479497909546 and batch: 400, loss is 4.634848842620849 and perplexity is 103.01234574212593
At time: 453.0051188468933 and batch: 450, loss is 4.68780897140503 and perplexity is 108.61494046771512
At time: 453.4003686904907 and batch: 500, loss is 4.66343900680542 and perplexity is 105.99999074549577
At time: 453.7976996898651 and batch: 550, loss is 4.723981189727783 and perplexity is 112.61570587015392
At time: 454.1967816352844 and batch: 600, loss is 4.625787801742554 and perplexity is 102.08316270646472
At time: 454.60152888298035 and batch: 650, loss is 4.736947937011719 and perplexity is 114.08547372915586
At time: 455.01717495918274 and batch: 700, loss is 4.779426107406616 and perplexity is 119.03601655040195
At time: 455.4115753173828 and batch: 750, loss is 4.705082988739013 and perplexity is 110.50745544132145
At time: 455.82121419906616 and batch: 800, loss is 4.648651027679444 and perplexity is 104.44399844167636
At time: 456.22041845321655 and batch: 850, loss is 4.625488958358765 and perplexity is 102.05266038662884
At time: 456.6068494319916 and batch: 900, loss is 4.562818403244019 and perplexity is 95.85325260535043
At time: 456.9993209838867 and batch: 950, loss is 4.649141540527344 and perplexity is 104.49524213161476
At time: 457.38692808151245 and batch: 1000, loss is 4.691167230606079 and perplexity is 108.98031075158686
At time: 457.7910521030426 and batch: 1050, loss is 4.607896699905395 and perplexity is 100.27302342367737
At time: 458.20608043670654 and batch: 1100, loss is 4.722782754898072 and perplexity is 112.48082412550055
At time: 458.60970973968506 and batch: 1150, loss is 4.661974086761474 and perplexity is 105.84482291637525
At time: 459.014084815979 and batch: 1200, loss is 4.618684492111206 and perplexity is 101.36060371192384
At time: 459.421822309494 and batch: 1250, loss is 4.621594953536987 and perplexity is 101.65603955789024
At time: 459.8211030960083 and batch: 1300, loss is 4.673102970123291 and perplexity is 107.0293365366799
At time: 460.226922750473 and batch: 1350, loss is 4.6227137470245365 and perplexity is 101.76983531802551
At time: 460.62586665153503 and batch: 1400, loss is 4.5199220180511475 and perplexity is 91.82843673847975
At time: 461.01266145706177 and batch: 1450, loss is 4.598085489273071 and perplexity is 99.29403405866304
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.034015362079327 and perplexity of 153.54832864690385
Finished 37 epochs...
Completing Train Step...
At time: 462.25937509536743 and batch: 50, loss is 4.74888056755066 and perplexity is 115.45496812244815
At time: 462.6780438423157 and batch: 100, loss is 4.752514734268188 and perplexity is 115.87531406595944
At time: 463.07849526405334 and batch: 150, loss is 4.656537609100342 and perplexity is 105.27096120761071
At time: 463.4800274372101 and batch: 200, loss is 4.705545654296875 and perplexity is 110.55859526424622
At time: 463.878515958786 and batch: 250, loss is 4.723852510452271 and perplexity is 112.60121549503671
At time: 464.2712323665619 and batch: 300, loss is 4.726496849060059 and perplexity is 112.89936526719582
At time: 464.6755130290985 and batch: 350, loss is 4.7602219581604 and perplexity is 116.7718414859183
At time: 465.074209690094 and batch: 400, loss is 4.634614782333374 and perplexity is 102.9882374643733
At time: 465.4866871833801 and batch: 450, loss is 4.687345733642578 and perplexity is 108.5646375777227
At time: 465.87410974502563 and batch: 500, loss is 4.66316858291626 and perplexity is 105.97132969123902
At time: 466.2680706977844 and batch: 550, loss is 4.723818140029907 and perplexity is 112.59734541021012
At time: 466.6656684875488 and batch: 600, loss is 4.625677938461304 and perplexity is 102.07194813129568
At time: 467.0588297843933 and batch: 650, loss is 4.736887588500976 and perplexity is 114.07858904846117
At time: 467.4605371952057 and batch: 700, loss is 4.779222116470337 and perplexity is 119.0117367584479
At time: 467.8531348705292 and batch: 750, loss is 4.704877033233642 and perplexity is 110.48469816606227
At time: 468.25633549690247 and batch: 800, loss is 4.648425006866455 and perplexity is 104.42039459181797
At time: 468.65451097488403 and batch: 850, loss is 4.625332937240601 and perplexity is 102.03673925849215
At time: 469.05939197540283 and batch: 900, loss is 4.562632083892822 and perplexity is 95.83539495317969
At time: 469.45737886428833 and batch: 950, loss is 4.648970918655396 and perplexity is 104.47741447872957
At time: 469.8449082374573 and batch: 1000, loss is 4.691094818115235 and perplexity is 108.97241950154832
At time: 470.24722695350647 and batch: 1050, loss is 4.607867012023926 and perplexity is 100.27004657423176
At time: 470.64166951179504 and batch: 1100, loss is 4.722804441452026 and perplexity is 112.48326347341221
At time: 471.03948760032654 and batch: 1150, loss is 4.66187089920044 and perplexity is 105.83390161073153
At time: 471.4435579776764 and batch: 1200, loss is 4.618685035705567 and perplexity is 101.36065881099138
At time: 471.85223865509033 and batch: 1250, loss is 4.62150860786438 and perplexity is 101.64726237772122
At time: 472.25097131729126 and batch: 1300, loss is 4.673063354492188 and perplexity is 107.02509658595113
At time: 472.64556431770325 and batch: 1350, loss is 4.622771434783935 and perplexity is 101.77570636114142
At time: 473.06523966789246 and batch: 1400, loss is 4.5198195266723635 and perplexity is 91.81902559767548
At time: 473.4671723842621 and batch: 1450, loss is 4.597989778518677 and perplexity is 99.28453100653586
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.03401118873531 and perplexity of 153.54768783824233
Finished 38 epochs...
Completing Train Step...
At time: 474.76691579818726 and batch: 50, loss is 4.748478889465332 and perplexity is 115.40860170472155
At time: 475.1803011894226 and batch: 100, loss is 4.752233295440674 and perplexity is 115.84270684211555
At time: 475.5921080112457 and batch: 150, loss is 4.656254510879517 and perplexity is 105.24116340383995
At time: 475.9945020675659 and batch: 200, loss is 4.705452928543091 and perplexity is 110.5483441104433
At time: 476.38852882385254 and batch: 250, loss is 4.723677501678467 and perplexity is 112.58151101866255
At time: 476.7814302444458 and batch: 300, loss is 4.726293134689331 and perplexity is 112.8763683865219
At time: 477.1853950023651 and batch: 350, loss is 4.759930601119995 and perplexity is 116.73782414361705
At time: 477.5876965522766 and batch: 400, loss is 4.634387979507446 and perplexity is 102.96488208971164
At time: 477.9835214614868 and batch: 450, loss is 4.686898593902588 and perplexity is 108.51610486516488
At time: 478.3771507740021 and batch: 500, loss is 4.662890615463257 and perplexity is 105.94187720423947
At time: 478.78156423568726 and batch: 550, loss is 4.72367488861084 and perplexity is 112.58121683594506
At time: 479.17719554901123 and batch: 600, loss is 4.6255659580230715 and perplexity is 102.06051870976047
At time: 479.56856894493103 and batch: 650, loss is 4.736836099624634 and perplexity is 114.0727154213109
At time: 479.9540889263153 and batch: 700, loss is 4.778941316604614 and perplexity is 118.97832297025982
At time: 480.35693979263306 and batch: 750, loss is 4.704685459136963 and perplexity is 110.46353418711399
At time: 480.75239300727844 and batch: 800, loss is 4.648198432922364 and perplexity is 104.396738331219
At time: 481.1378560066223 and batch: 850, loss is 4.625182952880859 and perplexity is 102.0214364911009
At time: 481.5249743461609 and batch: 900, loss is 4.562471017837525 and perplexity is 95.81996036718401
At time: 481.90892028808594 and batch: 950, loss is 4.648734731674194 and perplexity is 104.45274118746991
At time: 482.3053982257843 and batch: 1000, loss is 4.691006755828857 and perplexity is 108.96282356366122
At time: 482.70211005210876 and batch: 1050, loss is 4.60782525062561 and perplexity is 100.26585924431265
At time: 483.10931301116943 and batch: 1100, loss is 4.722804679870605 and perplexity is 112.48329029151526
At time: 483.5054943561554 and batch: 1150, loss is 4.661760969161987 and perplexity is 105.82226792531533
At time: 483.89405846595764 and batch: 1200, loss is 4.6186644554138185 and perplexity is 101.3585728005267
At time: 484.2984354496002 and batch: 1250, loss is 4.621452722549439 and perplexity is 101.64158194717814
At time: 484.6916124820709 and batch: 1300, loss is 4.673008670806885 and perplexity is 107.0192442192659
At time: 485.0805730819702 and batch: 1350, loss is 4.6228276634216305 and perplexity is 101.78142923135367
At time: 485.4805238246918 and batch: 1400, loss is 4.519713096618652 and perplexity is 91.80925381386434
At time: 485.88733553886414 and batch: 1450, loss is 4.5978787231445315 and perplexity is 99.27350553802815
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.034009623731303 and perplexity of 153.54744753568372
Finished 39 epochs...
Completing Train Step...
At time: 487.2239830493927 and batch: 50, loss is 4.748079900741577 and perplexity is 115.36256415885859
At time: 487.61147022247314 and batch: 100, loss is 4.75194935798645 and perplexity is 115.80981942804964
At time: 488.0164623260498 and batch: 150, loss is 4.6559849548339844 and perplexity is 105.2127988350978
At time: 488.41102290153503 and batch: 200, loss is 4.705343036651612 and perplexity is 110.53619641128817
At time: 488.81228852272034 and batch: 250, loss is 4.723497896194458 and perplexity is 112.5612925776114
At time: 489.2127594947815 and batch: 300, loss is 4.726090288162231 and perplexity is 112.85347412929184
At time: 489.604150056839 and batch: 350, loss is 4.759650936126709 and perplexity is 116.70518122556517
At time: 490.00422835350037 and batch: 400, loss is 4.634166984558106 and perplexity is 102.94212988496415
At time: 490.4078652858734 and batch: 450, loss is 4.686460208892822 and perplexity is 108.46854345733969
At time: 490.8116374015808 and batch: 500, loss is 4.662616300582886 and perplexity is 105.91281975649521
At time: 491.20657753944397 and batch: 550, loss is 4.723539352416992 and perplexity is 112.56595904033149
At time: 491.5981059074402 and batch: 600, loss is 4.6254433917999265 and perplexity is 102.04801030401968
At time: 491.98384070396423 and batch: 650, loss is 4.736800355911255 and perplexity is 114.068638111736
At time: 492.36928963661194 and batch: 700, loss is 4.778708620071411 and perplexity is 118.95064034792836
At time: 492.76834440231323 and batch: 750, loss is 4.70450343132019 and perplexity is 110.44342858109823
At time: 493.1527738571167 and batch: 800, loss is 4.647959098815918 and perplexity is 104.37175562086128
At time: 493.5488820075989 and batch: 850, loss is 4.6250279521942135 and perplexity is 102.00562432387224
At time: 493.945193529129 and batch: 900, loss is 4.562382869720459 and perplexity is 95.81151439035425
At time: 494.34126019477844 and batch: 950, loss is 4.648579874038696 and perplexity is 104.4365671353184
At time: 494.736647605896 and batch: 1000, loss is 4.690928506851196 and perplexity is 108.95429766768999
At time: 495.12683176994324 and batch: 1050, loss is 4.607781181335449 and perplexity is 100.26144069643021
At time: 495.5399568080902 and batch: 1100, loss is 4.722815647125244 and perplexity is 112.48452393116729
At time: 495.92759561538696 and batch: 1150, loss is 4.661660289764404 and perplexity is 105.81161433943701
At time: 496.3308217525482 and batch: 1200, loss is 4.618652095794678 and perplexity is 101.357320054912
At time: 496.7291326522827 and batch: 1250, loss is 4.621402339935303 and perplexity is 101.63646110757648
At time: 497.13896012306213 and batch: 1300, loss is 4.672984428405762 and perplexity is 107.01664984726668
At time: 497.539443731308 and batch: 1350, loss is 4.622873210906983 and perplexity is 101.78606522508885
At time: 497.9351053237915 and batch: 1400, loss is 4.519588975906372 and perplexity is 91.79785909106228
At time: 498.3330774307251 and batch: 1450, loss is 4.597772493362426 and perplexity is 99.26296029528538
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.034005450387286 and perplexity of 153.54680673069936
Finished 40 epochs...
Completing Train Step...
At time: 499.60476303100586 and batch: 50, loss is 4.747704916000366 and perplexity is 115.31931306734852
At time: 499.9935836791992 and batch: 100, loss is 4.75167610168457 and perplexity is 115.7781779883796
At time: 500.3790023326874 and batch: 150, loss is 4.65571626663208 and perplexity is 105.18453319485353
At time: 500.7652440071106 and batch: 200, loss is 4.705224580764771 and perplexity is 110.52310352359439
At time: 501.1679759025574 and batch: 250, loss is 4.723326215744018 and perplexity is 112.54196966293038
At time: 501.5640890598297 and batch: 300, loss is 4.725907363891602 and perplexity is 112.83283237784497
At time: 501.96545910835266 and batch: 350, loss is 4.7593506240844725 and perplexity is 116.67013851638886
At time: 502.3693780899048 and batch: 400, loss is 4.633945255279541 and perplexity is 102.91930713110074
At time: 502.7859470844269 and batch: 450, loss is 4.685992918014526 and perplexity is 108.41786893719264
At time: 503.181277513504 and batch: 500, loss is 4.6623525714874265 and perplexity is 105.8848911472986
At time: 503.57034492492676 and batch: 550, loss is 4.723370456695557 and perplexity is 112.54694873689498
At time: 503.97283124923706 and batch: 600, loss is 4.625242786407471 and perplexity is 102.02754097606075
At time: 504.36556029319763 and batch: 650, loss is 4.736736106872558 and perplexity is 114.06130954682106
At time: 504.76976203918457 and batch: 700, loss is 4.778519983291626 and perplexity is 118.92820399840666
At time: 505.15511202812195 and batch: 750, loss is 4.7043289470672605 and perplexity is 110.42415962308503
At time: 505.5677046775818 and batch: 800, loss is 4.6476693439483645 and perplexity is 104.3415177776277
At time: 505.96266055107117 and batch: 850, loss is 4.62486005783081 and perplexity is 101.98849959212605
At time: 506.3498091697693 and batch: 900, loss is 4.562108678817749 and perplexity is 95.78524734599043
At time: 506.7504472732544 and batch: 950, loss is 4.648390045166016 and perplexity is 104.41674394107932
At time: 507.1545567512512 and batch: 1000, loss is 4.690851192474366 and perplexity is 108.94587425969227
At time: 507.56625533103943 and batch: 1050, loss is 4.607681674957275 and perplexity is 100.25146453994986
At time: 507.9723069667816 and batch: 1100, loss is 4.722767629623413 and perplexity is 112.47912283500811
At time: 508.3751654624939 and batch: 1150, loss is 4.661479787826538 and perplexity is 105.79251686161777
At time: 508.77889251708984 and batch: 1200, loss is 4.6186143493652345 and perplexity is 101.35349425018765
At time: 509.175386428833 and batch: 1250, loss is 4.621358413696289 and perplexity is 101.63199669814638
At time: 509.5731954574585 and batch: 1300, loss is 4.672946510314941 and perplexity is 107.01259205715073
At time: 509.9589467048645 and batch: 1350, loss is 4.6228787708282475 and perplexity is 101.78663114917059
At time: 510.35296416282654 and batch: 1400, loss is 4.519457445144654 and perplexity is 91.78578564276422
At time: 510.74019598960876 and batch: 1450, loss is 4.597613649368286 and perplexity is 99.24719422240803
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.033958500267094 and perplexity of 153.53959785889822
Finished 41 epochs...
Completing Train Step...
At time: 512.0062229633331 and batch: 50, loss is 4.747294569015503 and perplexity is 115.27200184260799
At time: 512.4214622974396 and batch: 100, loss is 4.751370811462403 and perplexity is 115.74283743753621
At time: 512.813747882843 and batch: 150, loss is 4.655422763824463 and perplexity is 105.1536657691026
At time: 513.2048816680908 and batch: 200, loss is 4.705066156387329 and perplexity is 110.5055953566226
At time: 513.594729423523 and batch: 250, loss is 4.723133697509765 and perplexity is 112.52030536710441
At time: 513.9947967529297 and batch: 300, loss is 4.725737066268921 and perplexity is 112.81361885078609
At time: 514.401052236557 and batch: 350, loss is 4.759037103652954 and perplexity is 116.63356577766586
At time: 514.8008880615234 and batch: 400, loss is 4.633712291717529 and perplexity is 102.89533347531423
At time: 515.2112984657288 and batch: 450, loss is 4.685534677505493 and perplexity is 108.36819885903267
At time: 515.6339666843414 and batch: 500, loss is 4.662108364105225 and perplexity is 105.85903643230145
At time: 516.0369153022766 and batch: 550, loss is 4.723211030960083 and perplexity is 112.52900728701971
At time: 516.4308512210846 and batch: 600, loss is 4.625095510482788 and perplexity is 102.0125158820649
At time: 516.8284637928009 and batch: 650, loss is 4.73668080329895 and perplexity is 114.05500172321685
At time: 517.2279181480408 and batch: 700, loss is 4.778353443145752 and perplexity is 118.90839932714643
At time: 517.6316044330597 and batch: 750, loss is 4.704148988723755 and perplexity is 110.40428966217256
At time: 518.0299549102783 and batch: 800, loss is 4.647428102493286 and perplexity is 104.31634931401442
At time: 518.4198598861694 and batch: 850, loss is 4.6246982765197755 and perplexity is 101.9720010935619
At time: 518.8207592964172 and batch: 900, loss is 4.561901817321777 and perplexity is 95.76543511569686
At time: 519.2182822227478 and batch: 950, loss is 4.648209733963013 and perplexity is 104.39791812966898
At time: 519.6326813697815 and batch: 1000, loss is 4.69075532913208 and perplexity is 108.93543084463585
At time: 520.0408971309662 and batch: 1050, loss is 4.607632961273193 and perplexity is 100.24658104072508
At time: 520.4409611225128 and batch: 1100, loss is 4.722754249572754 and perplexity is 112.47761786871473
At time: 520.8300981521606 and batch: 1150, loss is 4.661376419067383 and perplexity is 105.78158178560426
At time: 521.2179863452911 and batch: 1200, loss is 4.618588380813598 and perplexity is 101.35086228091308
At time: 521.6219892501831 and batch: 1250, loss is 4.621312131881714 and perplexity is 101.62729309376687
At time: 522.0077741146088 and batch: 1300, loss is 4.672902708053589 and perplexity is 107.00790476628318
At time: 522.4019951820374 and batch: 1350, loss is 4.622898807525635 and perplexity is 101.78867063752925
At time: 522.7997612953186 and batch: 1400, loss is 4.5193151760101316 and perplexity is 91.77272828733075
At time: 523.1901848316193 and batch: 1450, loss is 4.597496118545532 and perplexity is 99.23553030346346
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.033947023571047 and perplexity of 153.53783574171408
Finished 42 epochs...
Completing Train Step...
At time: 524.492678642273 and batch: 50, loss is 4.746949110031128 and perplexity is 115.23218697152298
At time: 524.903920173645 and batch: 100, loss is 4.751120567321777 and perplexity is 115.71387709437734
At time: 525.3138201236725 and batch: 150, loss is 4.655166416168213 and perplexity is 105.12671332808176
At time: 525.7196626663208 and batch: 200, loss is 4.704914979934692 and perplexity is 110.48889077542151
At time: 526.1128215789795 and batch: 250, loss is 4.722970676422119 and perplexity is 112.50196367962275
At time: 526.5085160732269 and batch: 300, loss is 4.725566301345825 and perplexity is 112.79435588660503
At time: 526.8969190120697 and batch: 350, loss is 4.758748893737793 and perplexity is 116.59995567118376
At time: 527.3010630607605 and batch: 400, loss is 4.633492889404297 and perplexity is 102.87276047750348
At time: 527.6846661567688 and batch: 450, loss is 4.685099506378174 and perplexity is 108.32105040733616
At time: 528.0824122428894 and batch: 500, loss is 4.661860113143921 and perplexity is 105.83276008644341
At time: 528.483473777771 and batch: 550, loss is 4.723047180175781 and perplexity is 112.51057083137408
At time: 528.8821017742157 and batch: 600, loss is 4.624957551956177 and perplexity is 101.99844335641265
At time: 529.277036190033 and batch: 650, loss is 4.736630306243897 and perplexity is 114.04924242693073
At time: 529.6651091575623 and batch: 700, loss is 4.778181381225586 and perplexity is 118.88794147969307
At time: 530.0780148506165 and batch: 750, loss is 4.703961029052734 and perplexity is 110.38354005831377
At time: 530.4739708900452 and batch: 800, loss is 4.647206449508667 and perplexity is 104.29322984618858
At time: 530.877247095108 and batch: 850, loss is 4.624526376724243 and perplexity is 101.95447363395043
At time: 531.2732632160187 and batch: 900, loss is 4.561723613739014 and perplexity is 95.74837089255239
At time: 531.6677191257477 and batch: 950, loss is 4.648026838302612 and perplexity is 104.37882594947988
At time: 532.0630030632019 and batch: 1000, loss is 4.690612535476685 and perplexity is 108.91987666680889
At time: 532.4529309272766 and batch: 1050, loss is 4.607594728469849 and perplexity is 100.24274840617284
At time: 532.8489320278168 and batch: 1100, loss is 4.722705745697022 and perplexity is 112.47216240062176
At time: 533.2357397079468 and batch: 1150, loss is 4.661262626647949 and perplexity is 105.76954532832312
At time: 533.6298115253448 and batch: 1200, loss is 4.618560285568237 and perplexity is 101.34801484356963
At time: 534.0255787372589 and batch: 1250, loss is 4.621258773803711 and perplexity is 101.6218706014029
At time: 534.4150471687317 and batch: 1300, loss is 4.672844696044922 and perplexity is 107.00169720284279
At time: 534.8266489505768 and batch: 1350, loss is 4.622927045822143 and perplexity is 101.79154501677549
At time: 535.2112624645233 and batch: 1400, loss is 4.519169931411743 and perplexity is 91.75939976223921
At time: 535.607414484024 and batch: 1450, loss is 4.597385997772217 and perplexity is 99.22460301179804
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0339376335470085 and perplexity of 153.53639402451458
Finished 43 epochs...
Completing Train Step...
At time: 536.9491493701935 and batch: 50, loss is 4.746614866256714 and perplexity is 115.1936777665051
At time: 537.3591628074646 and batch: 100, loss is 4.75087082862854 and perplexity is 115.68498247012538
At time: 537.7537562847137 and batch: 150, loss is 4.65490876197815 and perplexity is 105.09963047905977
At time: 538.1428236961365 and batch: 200, loss is 4.704724264144898 and perplexity is 110.46782080860531
At time: 538.5413415431976 and batch: 250, loss is 4.722801094055176 and perplexity is 112.48288694792053
At time: 538.9299998283386 and batch: 300, loss is 4.725388593673706 and perplexity is 112.77431324511059
At time: 539.330947637558 and batch: 350, loss is 4.7584600925445555 and perplexity is 116.56628632696192
At time: 539.7317233085632 and batch: 400, loss is 4.633246192932129 and perplexity is 102.84738526052838
At time: 540.1229438781738 and batch: 450, loss is 4.684684982299805 and perplexity is 108.2761580288768
At time: 540.5217123031616 and batch: 500, loss is 4.661626720428467 and perplexity is 105.80806237342814
At time: 540.924394607544 and batch: 550, loss is 4.722879467010498 and perplexity is 112.49170290965576
At time: 541.3265497684479 and batch: 600, loss is 4.624827299118042 and perplexity is 101.98515863488527
At time: 541.7403764724731 and batch: 650, loss is 4.736572198867798 and perplexity is 114.04261551724524
At time: 542.1459965705872 and batch: 700, loss is 4.778028383255005 and perplexity is 118.86975325733609
At time: 542.537778377533 and batch: 750, loss is 4.703790826797485 and perplexity is 110.36475412960257
At time: 542.9299960136414 and batch: 800, loss is 4.6469938182830814 and perplexity is 104.27105620639372
At time: 543.3240511417389 and batch: 850, loss is 4.624359512329102 and perplexity is 101.93746248169283
At time: 543.7284026145935 and batch: 900, loss is 4.561554708480835 and perplexity is 95.73219985497164
At time: 544.1329474449158 and batch: 950, loss is 4.647841272354126 and perplexity is 104.3594585906574
At time: 544.5285377502441 and batch: 1000, loss is 4.69049262046814 and perplexity is 108.90681632194898
At time: 544.9182360172272 and batch: 1050, loss is 4.607554330825805 and perplexity is 100.23869891710025
At time: 545.3072907924652 and batch: 1100, loss is 4.722681331634521 and perplexity is 112.46941653173837
At time: 545.7079048156738 and batch: 1150, loss is 4.661145238876343 and perplexity is 105.75713000581099
At time: 546.1434185504913 and batch: 1200, loss is 4.618533182144165 and perplexity is 101.34526800256901
At time: 546.539300441742 and batch: 1250, loss is 4.621206855773925 and perplexity is 101.61659473105574
At time: 546.9540767669678 and batch: 1300, loss is 4.6727893257141115 and perplexity is 106.99577264749523
At time: 547.3466665744781 and batch: 1350, loss is 4.622944374084472 and perplexity is 101.79330890265291
At time: 547.7466740608215 and batch: 1400, loss is 4.519025344848632 and perplexity is 91.74613354507598
At time: 548.1397423744202 and batch: 1450, loss is 4.59729172706604 and perplexity is 99.21524947929095
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.033943893563034 and perplexity of 153.53735516781006
Annealing...
Finished 44 epochs...
Completing Train Step...
At time: 549.4100422859192 and batch: 50, loss is 4.746235084533692 and perplexity is 115.14993761946164
At time: 549.810138463974 and batch: 100, loss is 4.751019248962402 and perplexity is 115.70215374809833
At time: 550.2037734985352 and batch: 150, loss is 4.654903259277344 and perplexity is 105.0990521488296
At time: 550.6019225120544 and batch: 200, loss is 4.704201059341431 and perplexity is 110.41003863140418
At time: 551.0005040168762 and batch: 250, loss is 4.723279848098755 and perplexity is 112.53675147778218
At time: 551.3938374519348 and batch: 300, loss is 4.725121841430664 and perplexity is 112.74423445606553
At time: 551.782687664032 and batch: 350, loss is 4.757906866073609 and perplexity is 116.50181660656811
At time: 552.1995320320129 and batch: 400, loss is 4.631628217697144 and perplexity is 102.68111528481782
At time: 552.604578256607 and batch: 450, loss is 4.68408392906189 and perplexity is 108.21109784777946
At time: 553.0028820037842 and batch: 500, loss is 4.660493936538696 and perplexity is 105.6882725657553
At time: 553.4138474464417 and batch: 550, loss is 4.721456642150879 and perplexity is 112.33176073009231
At time: 553.8120718002319 and batch: 600, loss is 4.623084917068481 and perplexity is 101.80761624341285
At time: 554.2066116333008 and batch: 650, loss is 4.735537719726563 and perplexity is 113.92470181043127
At time: 554.5964508056641 and batch: 700, loss is 4.776676864624023 and perplexity is 118.7092070861572
At time: 554.9931206703186 and batch: 750, loss is 4.702750511169434 and perplexity is 110.24999965188326
At time: 555.3899652957916 and batch: 800, loss is 4.64515983581543 and perplexity is 104.08000016769161
At time: 555.7926754951477 and batch: 850, loss is 4.622620058059693 and perplexity is 101.76030105413686
At time: 556.2249553203583 and batch: 900, loss is 4.559988985061645 and perplexity is 95.58242698972671
At time: 556.6214356422424 and batch: 950, loss is 4.645322284698486 and perplexity is 104.09690922085859
At time: 557.0230565071106 and batch: 1000, loss is 4.6887549209594725 and perplexity is 108.71773333302386
At time: 557.4211821556091 and batch: 1050, loss is 4.6052216529846195 and perplexity is 100.00514683209767
At time: 557.8265361785889 and batch: 1100, loss is 4.7212049102783205 and perplexity is 112.30348680448935
At time: 558.2154636383057 and batch: 1150, loss is 4.658335018157959 and perplexity is 105.46034633707598
At time: 558.6048150062561 and batch: 1200, loss is 4.6163465118408205 and perplexity is 101.12390143070358
At time: 558.9998888969421 and batch: 1250, loss is 4.619179430007935 and perplexity is 101.41078333280986
At time: 559.4067549705505 and batch: 1300, loss is 4.669877510070801 and perplexity is 106.6846738339368
At time: 559.8019244670868 and batch: 1350, loss is 4.62016342163086 and perplexity is 101.51061980515435
At time: 560.2012231349945 and batch: 1400, loss is 4.515967435836792 and perplexity is 91.46601072982875
At time: 560.6179058551788 and batch: 1450, loss is 4.594095869064331 and perplexity is 98.89867775892614
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0334003155048075 and perplexity of 153.45391830969982
Finished 45 epochs...
Completing Train Step...
At time: 561.9913954734802 and batch: 50, loss is 4.7458163928985595 and perplexity is 115.10173539543256
At time: 562.4025032520294 and batch: 100, loss is 4.750611028671265 and perplexity is 115.65493142042199
At time: 562.8075017929077 and batch: 150, loss is 4.654797811508178 and perplexity is 105.08797027252896
At time: 563.1941533088684 and batch: 200, loss is 4.7038970375061036 and perplexity is 110.37647667086384
At time: 563.5835921764374 and batch: 250, loss is 4.7230620861053465 and perplexity is 112.51224791851749
At time: 563.9885349273682 and batch: 300, loss is 4.724862413406372 and perplexity is 112.71498923574913
At time: 564.3883266448975 and batch: 350, loss is 4.757612724304199 and perplexity is 116.46755359543039
At time: 564.8028864860535 and batch: 400, loss is 4.631479549407959 and perplexity is 102.66585099376294
At time: 565.1983413696289 and batch: 450, loss is 4.683802366256714 and perplexity is 108.18063391647449
At time: 565.5901420116425 and batch: 500, loss is 4.660212936401368 and perplexity is 105.65857831888943
At time: 565.9785120487213 and batch: 550, loss is 4.721234436035156 and perplexity is 112.30680269888447
At time: 566.3929667472839 and batch: 600, loss is 4.622889356613159 and perplexity is 101.78770864625788
At time: 566.8014559745789 and batch: 650, loss is 4.735418014526367 and perplexity is 113.91106524739385
At time: 567.2000396251678 and batch: 700, loss is 4.776352596282959 and perplexity is 118.67071968896582
At time: 567.6030685901642 and batch: 750, loss is 4.70245545387268 and perplexity is 110.21747438366373
At time: 567.999303817749 and batch: 800, loss is 4.645004053115844 and perplexity is 104.06378756714676
At time: 568.3997375965118 and batch: 850, loss is 4.622562208175659 and perplexity is 101.75441440279437
At time: 568.7930493354797 and batch: 900, loss is 4.559958457946777 and perplexity is 95.57950917853505
At time: 569.2004971504211 and batch: 950, loss is 4.645254144668579 and perplexity is 104.08981629600981
At time: 569.5965452194214 and batch: 1000, loss is 4.688661327362061 and perplexity is 108.70755852541463
At time: 569.9905724525452 and batch: 1050, loss is 4.605308227539062 and perplexity is 100.01380510791442
At time: 570.377765417099 and batch: 1100, loss is 4.721162643432617 and perplexity is 112.29874019065353
At time: 570.7781763076782 and batch: 1150, loss is 4.6582998847961425 and perplexity is 105.45664122565773
At time: 571.1852602958679 and batch: 1200, loss is 4.616415796279907 and perplexity is 101.13090798621228
At time: 571.5794050693512 and batch: 1250, loss is 4.619363594055176 and perplexity is 101.42946127295201
At time: 571.9945955276489 and batch: 1300, loss is 4.669873752593994 and perplexity is 106.68427296950232
At time: 572.3895781040192 and batch: 1350, loss is 4.620233783721924 and perplexity is 101.51776255591551
At time: 572.7827186584473 and batch: 1400, loss is 4.5161488914489745 and perplexity is 91.48260925670199
At time: 573.1793878078461 and batch: 1450, loss is 4.594237117767334 and perplexity is 98.91264805550823
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.033329890324519 and perplexity of 153.44311167037114
Finished 46 epochs...
Completing Train Step...
At time: 574.432678937912 and batch: 50, loss is 4.745588207244873 and perplexity is 115.07547382707146
At time: 574.8467924594879 and batch: 100, loss is 4.750468835830689 and perplexity is 115.63848728634349
At time: 575.2492015361786 and batch: 150, loss is 4.654730615615844 and perplexity is 105.08090902983884
At time: 575.6514520645142 and batch: 200, loss is 4.703736953735351 and perplexity is 110.35880860249925
At time: 576.0467128753662 and batch: 250, loss is 4.722966709136963 and perplexity is 112.50151735313753
At time: 576.4486682415009 and batch: 300, loss is 4.724732408523559 and perplexity is 112.70033668925423
At time: 576.8514320850372 and batch: 350, loss is 4.757449455261231 and perplexity is 116.44853960165857
At time: 577.2443735599518 and batch: 400, loss is 4.63134656906128 and perplexity is 102.65219936102523
At time: 577.6393656730652 and batch: 450, loss is 4.683643236160278 and perplexity is 108.1634204913902
At time: 578.0327301025391 and batch: 500, loss is 4.660041160583496 and perplexity is 105.64043028892455
At time: 578.417160987854 and batch: 550, loss is 4.7211107158660885 and perplexity is 112.29290894175381
At time: 578.8042404651642 and batch: 600, loss is 4.622756481170654 and perplexity is 101.7741844579661
At time: 579.1911020278931 and batch: 650, loss is 4.73537202835083 and perplexity is 113.90582703359543
At time: 579.599529504776 and batch: 700, loss is 4.776156454086304 and perplexity is 118.64744563591394
At time: 579.9945847988129 and batch: 750, loss is 4.702289638519287 and perplexity is 110.19920014931482
At time: 580.3935508728027 and batch: 800, loss is 4.644917459487915 and perplexity is 104.05477669639285
At time: 580.788330078125 and batch: 850, loss is 4.622489137649536 and perplexity is 101.74697942584075
At time: 581.1785628795624 and batch: 900, loss is 4.559941291809082 and perplexity is 95.57786846160207
At time: 581.5885319709778 and batch: 950, loss is 4.645204763412476 and perplexity is 104.08467633704345
At time: 581.9837622642517 and batch: 1000, loss is 4.688599338531494 and perplexity is 108.70082007984423
At time: 582.3745925426483 and batch: 1050, loss is 4.60539098739624 and perplexity is 100.0220825786574
At time: 582.7681028842926 and batch: 1100, loss is 4.721133003234863 and perplexity is 112.29541168311582
At time: 583.1707410812378 and batch: 1150, loss is 4.658263902664185 and perplexity is 105.45284673914462
At time: 583.56591796875 and batch: 1200, loss is 4.61647216796875 and perplexity is 101.13660906697795
At time: 583.9609320163727 and batch: 1250, loss is 4.619502573013306 and perplexity is 101.44355881341149
At time: 584.3655898571014 and batch: 1300, loss is 4.669838743209839 and perplexity is 106.68053808418502
At time: 584.7684836387634 and batch: 1350, loss is 4.620261211395263 and perplexity is 101.52054699013017
At time: 585.1723845005035 and batch: 1400, loss is 4.516257553100586 and perplexity is 91.49255044822094
At time: 585.5762143135071 and batch: 1450, loss is 4.594300327301025 and perplexity is 98.91890047547213
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.033297025240385 and perplexity of 153.4380688324634
Finished 47 epochs...
Completing Train Step...
At time: 586.911787033081 and batch: 50, loss is 4.74542236328125 and perplexity is 115.05639083681926
At time: 587.2962965965271 and batch: 100, loss is 4.750375747680664 and perplexity is 115.62772321450188
At time: 587.6830487251282 and batch: 150, loss is 4.6546797180175785 and perplexity is 105.07556080005281
At time: 588.0812640190125 and batch: 200, loss is 4.703599996566773 and perplexity is 110.34369520751287
At time: 588.4745750427246 and batch: 250, loss is 4.72289999961853 and perplexity is 112.49401268141125
At time: 588.869714975357 and batch: 300, loss is 4.724621534347534 and perplexity is 112.68784182497774
At time: 589.261093378067 and batch: 350, loss is 4.757318305969238 and perplexity is 116.43326845955785
At time: 589.6599571704865 and batch: 400, loss is 4.63124002456665 and perplexity is 102.64126291694099
At time: 590.0626676082611 and batch: 450, loss is 4.683505916595459 and perplexity is 108.14856855731291
At time: 590.4655623435974 and batch: 500, loss is 4.659913063049316 and perplexity is 105.62689887698359
At time: 590.8668751716614 and batch: 550, loss is 4.721018476486206 and perplexity is 112.28255159115295
At time: 591.2580277919769 and batch: 600, loss is 4.622634477615357 and perplexity is 101.76176840304154
At time: 591.6540176868439 and batch: 650, loss is 4.735335006713867 and perplexity is 113.90161013147778
At time: 592.0409696102142 and batch: 700, loss is 4.776003370285034 and perplexity is 118.62928402408477
At time: 592.4352161884308 and batch: 750, loss is 4.70214412689209 and perplexity is 110.18316605098751
At time: 592.8324255943298 and batch: 800, loss is 4.644867467880249 and perplexity is 104.04957496084313
At time: 593.2211084365845 and batch: 850, loss is 4.6224190139770505 and perplexity is 101.73984480413495
At time: 593.6221849918365 and batch: 900, loss is 4.559932088851928 and perplexity is 95.57698886662122
At time: 594.0104968547821 and batch: 950, loss is 4.645142755508423 and perplexity is 104.07822246451737
At time: 594.4044470787048 and batch: 1000, loss is 4.688550100326538 and perplexity is 108.69546797835129
At time: 594.810756444931 and batch: 1050, loss is 4.605457468032837 and perplexity is 100.0287323314184
At time: 595.2170362472534 and batch: 1100, loss is 4.72110502243042 and perplexity is 112.2922696111207
At time: 595.6122443675995 and batch: 1150, loss is 4.658219671249389 and perplexity is 105.44818251369252
At time: 596.0038816928864 and batch: 1200, loss is 4.616512441635132 and perplexity is 101.14068229105183
At time: 596.4005477428436 and batch: 1250, loss is 4.619614782333374 and perplexity is 101.4549423648296
At time: 596.8019924163818 and batch: 1300, loss is 4.669798564910889 and perplexity is 106.67625192773953
At time: 597.2072093486786 and batch: 1350, loss is 4.620277576446533 and perplexity is 101.52220839268102
At time: 597.6043591499329 and batch: 1400, loss is 4.51633653640747 and perplexity is 91.49977711779998
At time: 598.0060420036316 and batch: 1450, loss is 4.594330081939697 and perplexity is 98.92184381540241
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0332782451923075 and perplexity of 153.43518728521167
Finished 48 epochs...
Completing Train Step...
At time: 599.329653263092 and batch: 50, loss is 4.745284805297851 and perplexity is 115.04056500022865
At time: 599.7205731868744 and batch: 100, loss is 4.750310525894165 and perplexity is 115.62018201375302
At time: 600.1180341243744 and batch: 150, loss is 4.654638586044311 and perplexity is 105.07123892377919
At time: 600.5220849514008 and batch: 200, loss is 4.703487586975098 and perplexity is 110.33129221491143
At time: 600.9228193759918 and batch: 250, loss is 4.722849931716919 and perplexity is 112.4883804832498
At time: 601.3267779350281 and batch: 300, loss is 4.724517831802368 and perplexity is 112.67615641488506
At time: 601.7240445613861 and batch: 350, loss is 4.757205514907837 and perplexity is 116.42013656821982
At time: 602.1218705177307 and batch: 400, loss is 4.631142873764038 and perplexity is 102.63129172023018
At time: 602.5167455673218 and batch: 450, loss is 4.683390798568726 and perplexity is 108.13611942408014
At time: 602.9153892993927 and batch: 500, loss is 4.65980544090271 and perplexity is 105.61553169507833
At time: 603.3073761463165 and batch: 550, loss is 4.720940446853637 and perplexity is 112.27379056672264
At time: 603.7049317359924 and batch: 600, loss is 4.622523107528687 and perplexity is 101.75043581714203
At time: 604.1101415157318 and batch: 650, loss is 4.735300550460815 and perplexity is 113.89768557638922
At time: 604.5083048343658 and batch: 700, loss is 4.775876874923706 and perplexity is 118.61427891899619
At time: 604.940256357193 and batch: 750, loss is 4.702038774490356 and perplexity is 110.17155860126047
At time: 605.3457581996918 and batch: 800, loss is 4.644819774627686 and perplexity is 104.04461261652153
At time: 605.7492096424103 and batch: 850, loss is 4.62235876083374 and perplexity is 101.73371484336216
At time: 606.1534667015076 and batch: 900, loss is 4.5599206447601315 and perplexity is 95.57589508104567
At time: 606.5508069992065 and batch: 950, loss is 4.645078182220459 and perplexity is 104.0715020084707
At time: 606.9554271697998 and batch: 1000, loss is 4.68849931716919 and perplexity is 108.68994821945444
At time: 607.3473403453827 and batch: 1050, loss is 4.605508861541748 and perplexity is 100.03387329106965
At time: 607.7488858699799 and batch: 1100, loss is 4.721082448959351 and perplexity is 112.28973481343102
At time: 608.1416637897491 and batch: 1150, loss is 4.6581696510314945 and perplexity is 105.44290810454122
At time: 608.5368249416351 and batch: 1200, loss is 4.616543111801147 and perplexity is 101.1437843401385
At time: 608.9338328838348 and batch: 1250, loss is 4.619703645706177 and perplexity is 101.46395839378707
At time: 609.3287537097931 and batch: 1300, loss is 4.6697696018218995 and perplexity is 106.67316229870471
At time: 609.7162501811981 and batch: 1350, loss is 4.620291013717651 and perplexity is 101.52357258328517
At time: 610.1048445701599 and batch: 1400, loss is 4.516403617858887 and perplexity is 91.50591526152884
At time: 610.5043060779572 and batch: 1450, loss is 4.594345464706421 and perplexity is 98.92336551875366
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.033264681824252 and perplexity of 153.43310620140716
Finished 49 epochs...
Completing Train Step...
At time: 611.7758848667145 and batch: 50, loss is 4.745149984359741 and perplexity is 115.02505616881565
At time: 612.1882433891296 and batch: 100, loss is 4.750266237258911 and perplexity is 115.61506146707563
At time: 612.5834453105927 and batch: 150, loss is 4.65459547996521 and perplexity is 105.06670981225973
At time: 612.9753224849701 and batch: 200, loss is 4.703395137786865 and perplexity is 110.32109264798758
At time: 613.3777096271515 and batch: 250, loss is 4.722811231613159 and perplexity is 112.48402725548905
At time: 613.7824306488037 and batch: 300, loss is 4.72441933631897 and perplexity is 112.6650588689296
At time: 614.1834604740143 and batch: 350, loss is 4.757101583480835 and perplexity is 116.4080374860428
At time: 614.5772883892059 and batch: 400, loss is 4.631045541763306 and perplexity is 102.62130289739328
At time: 614.9899537563324 and batch: 450, loss is 4.683293294906616 and perplexity is 108.12557627043637
At time: 615.392813205719 and batch: 500, loss is 4.659705476760864 and perplexity is 105.60497445676825
At time: 615.7898058891296 and batch: 550, loss is 4.720868015289307 and perplexity is 112.26565869494424
At time: 616.1817035675049 and batch: 600, loss is 4.622420845031738 and perplexity is 101.74003109552523
At time: 616.582590341568 and batch: 650, loss is 4.735266523361206 and perplexity is 113.89381003443397
At time: 617.0008175373077 and batch: 700, loss is 4.775764007568359 and perplexity is 118.60089199451578
At time: 617.3868856430054 and batch: 750, loss is 4.701954784393311 and perplexity is 110.16230566994466
At time: 617.7797365188599 and batch: 800, loss is 4.644767332077026 and perplexity is 104.0391563947239
At time: 618.1757657527924 and batch: 850, loss is 4.622299928665161 and perplexity is 101.72772980435842
At time: 618.5801906585693 and batch: 900, loss is 4.55990777015686 and perplexity is 95.57466458723526
At time: 618.9846937656403 and batch: 950, loss is 4.645012531280518 and perplexity is 104.06466984081432
At time: 619.3811550140381 and batch: 1000, loss is 4.688448801040649 and perplexity is 108.68445776273857
At time: 619.7913951873779 and batch: 1050, loss is 4.605550556182862 and perplexity is 100.03804425446857
At time: 620.1867566108704 and batch: 1100, loss is 4.721061038970947 and perplexity is 112.28733071724676
At time: 620.5878484249115 and batch: 1150, loss is 4.6581174087524415 and perplexity is 105.43739967059969
At time: 620.9837102890015 and batch: 1200, loss is 4.616567802429199 and perplexity is 101.1462816745277
At time: 621.3730096817017 and batch: 1250, loss is 4.619777421951294 and perplexity is 101.47144429978974
At time: 621.7689242362976 and batch: 1300, loss is 4.669741172790527 and perplexity is 106.67012972713384
At time: 622.1626930236816 and batch: 1350, loss is 4.620300903320312 and perplexity is 101.5245766160435
At time: 622.5620408058167 and batch: 1400, loss is 4.516458950042725 and perplexity is 91.51097862373646
At time: 622.9712665081024 and batch: 1450, loss is 4.5943474864959715 and perplexity is 98.92356552118258
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.033254770132212 and perplexity of 153.43158542724643
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc1f716f898>
SETTINGS FOR THIS RUN
{'batch_size': 20, 'lr': 26.410164837461025, 'num_layers': 1, 'wordvec_source': '', 'seq_len': 35, 'anneal': 3.150272923004872, 'wordvec_dim': 200, 'dropout': 0.2756808995762696, 'tune_wordvecs': True, 'data': 'ptb'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.6000010967254639 and batch: 50, loss is 6.412367944717407 and perplexity is 609.3348453175287
At time: 1.0045654773712158 and batch: 100, loss is 5.7773404312133785 and perplexity is 322.89927458954503
At time: 1.3916015625 and batch: 150, loss is 5.618303432464599 and perplexity is 275.42171509129497
At time: 1.7834596633911133 and batch: 200, loss is 5.574934673309326 and perplexity is 263.73232631407603
At time: 2.169828414916992 and batch: 250, loss is 5.556933498382568 and perplexity is 259.02730954059325
At time: 2.555655002593994 and batch: 300, loss is 5.582942609786987 and perplexity is 265.85275683536463
At time: 2.9737000465393066 and batch: 350, loss is 5.592930679321289 and perplexity is 268.5214178566715
At time: 3.379692554473877 and batch: 400, loss is 5.499895133972168 and perplexity is 244.66627373861866
At time: 3.781708240509033 and batch: 450, loss is 5.507686386108398 and perplexity is 246.57997575329455
At time: 4.169548988342285 and batch: 500, loss is 5.498764371871948 and perplexity is 244.389770748086
At time: 4.5614097118377686 and batch: 550, loss is 5.548116788864136 and perplexity is 256.75357913418816
At time: 4.961996078491211 and batch: 600, loss is 5.372950668334961 and perplexity is 215.49779303079572
At time: 5.353136301040649 and batch: 650, loss is 5.544895210266113 and perplexity is 255.92775823638522
At time: 5.745686292648315 and batch: 700, loss is 5.535439329147339 and perplexity is 253.51914152307356
At time: 6.1459431648254395 and batch: 750, loss is 5.478467016220093 and perplexity is 239.47930794282126
At time: 6.555419206619263 and batch: 800, loss is 5.409558839797974 and perplexity is 223.5329520827953
At time: 6.9631125926971436 and batch: 850, loss is 5.360388555526733 and perplexity is 212.80761796336049
At time: 7.3797993659973145 and batch: 900, loss is 5.358396396636963 and perplexity is 212.38409337962628
At time: 7.781312942504883 and batch: 950, loss is 5.382541637420655 and perplexity is 217.57456892888723
At time: 8.176218748092651 and batch: 1000, loss is 5.42119215965271 and perplexity is 226.148567056821
At time: 8.58063292503357 and batch: 1050, loss is 5.330874814987182 and perplexity is 206.61864820668475
At time: 8.976252555847168 and batch: 1100, loss is 5.4251648044586185 and perplexity is 227.04876188034896
At time: 9.38618516921997 and batch: 1150, loss is 5.412511100769043 and perplexity is 224.1938547915866
At time: 9.791561126708984 and batch: 1200, loss is 5.367329320907593 and perplexity is 214.28980351171796
At time: 10.187916994094849 and batch: 1250, loss is 5.386559867858887 and perplexity is 218.45059253800565
At time: 10.598233461380005 and batch: 1300, loss is 5.461936082839966 and perplexity is 235.5530333603331
At time: 11.003735780715942 and batch: 1350, loss is 5.38854416847229 and perplexity is 218.88449453640558
At time: 11.404138326644897 and batch: 1400, loss is 5.285066919326782 and perplexity is 197.3673906991565
At time: 11.800170660018921 and batch: 1450, loss is 5.354465703964234 and perplexity is 211.55091533613043
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.3171407585470085 and perplexity of 203.800333775432
Finished 1 epochs...
Completing Train Step...
At time: 13.059133291244507 and batch: 50, loss is 5.346130237579346 and perplexity is 209.79486869402987
At time: 13.459680795669556 and batch: 100, loss is 5.38358962059021 and perplexity is 217.80270293466782
At time: 13.868802785873413 and batch: 150, loss is 5.257981042861939 and perplexity is 192.0932714479358
At time: 14.259132385253906 and batch: 200, loss is 5.2879125690460205 and perplexity is 197.9298290307875
At time: 14.647151708602905 and batch: 250, loss is 5.3187157344818115 and perplexity is 204.1215672977637
At time: 15.07064175605774 and batch: 300, loss is 5.310021114349365 and perplexity is 202.35450092666971
At time: 15.474462509155273 and batch: 350, loss is 5.3775630283355715 and perplexity is 216.49404219531746
At time: 15.875745296478271 and batch: 400, loss is 5.23208104133606 and perplexity is 187.18193182117756
At time: 16.272942304611206 and batch: 450, loss is 5.264071359634399 and perplexity is 193.2667501221214
At time: 16.67711043357849 and batch: 500, loss is 5.284871091842652 and perplexity is 197.3287445237016
At time: 17.08269691467285 and batch: 550, loss is 5.341113758087158 and perplexity is 208.74507238001544
At time: 17.474550485610962 and batch: 600, loss is 5.203170595169067 and perplexity is 181.84789486858895
At time: 17.87284016609192 and batch: 650, loss is 5.350548791885376 and perplexity is 210.72390971205618
At time: 18.27068328857422 and batch: 700, loss is 5.364654493331909 and perplexity is 213.7173811429581
At time: 18.677526712417603 and batch: 750, loss is 5.321054353713989 and perplexity is 204.59948854083558
At time: 19.074220895767212 and batch: 800, loss is 5.265587978363037 and perplexity is 193.56008447694205
At time: 19.462948322296143 and batch: 850, loss is 5.20854043006897 and perplexity is 182.8270145436772
At time: 19.86663246154785 and batch: 900, loss is 5.174899253845215 and perplexity is 176.7788035945589
At time: 20.264930486679077 and batch: 950, loss is 5.23713532447815 and perplexity is 188.1303971908432
At time: 20.673417806625366 and batch: 1000, loss is 5.340911474227905 and perplexity is 208.7028508916811
At time: 21.070181369781494 and batch: 1050, loss is 5.2185245132446285 and perplexity is 184.66151733901498
At time: 21.469313144683838 and batch: 1100, loss is 5.33909128189087 and perplexity is 208.3233170788256
At time: 21.8712100982666 and batch: 1150, loss is 5.325949449539184 and perplexity is 205.60347795041693
At time: 22.269326210021973 and batch: 1200, loss is 5.261562509536743 and perplexity is 192.78248055109677
At time: 22.66266179084778 and batch: 1250, loss is 5.286751556396484 and perplexity is 197.70016334374426
At time: 23.050412893295288 and batch: 1300, loss is 5.352384643554688 and perplexity is 211.11112287767952
At time: 23.443784952163696 and batch: 1350, loss is 5.3050652027130125 and perplexity is 201.35413082129347
At time: 23.835545539855957 and batch: 1400, loss is 5.150490818023681 and perplexity is 172.51614357312457
At time: 24.24326801300049 and batch: 1450, loss is 5.2389093780517575 and perplexity is 188.46444681763907
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.403129382011218 and perplexity of 222.10036671201948
Annealing...
Finished 2 epochs...
Completing Train Step...
At time: 25.53104543685913 and batch: 50, loss is 5.237928524017334 and perplexity is 188.27968133343103
At time: 25.94525384902954 and batch: 100, loss is 5.201091012954712 and perplexity is 181.4701201636267
At time: 26.345343828201294 and batch: 150, loss is 5.090975885391235 and perplexity is 162.5484132988909
At time: 26.738548040390015 and batch: 200, loss is 5.133722171783448 and perplexity is 169.6474010757589
At time: 27.144237995147705 and batch: 250, loss is 5.14354736328125 and perplexity is 171.3224345659968
At time: 27.540770769119263 and batch: 300, loss is 5.165823268890381 and perplexity is 175.18162080008753
At time: 27.94337272644043 and batch: 350, loss is 5.179875707626342 and perplexity is 177.6607277474459
At time: 28.33793044090271 and batch: 400, loss is 5.065378952026367 and perplexity is 158.44047203666202
At time: 28.725257635116577 and batch: 450, loss is 5.112196025848388 and perplexity is 166.03457102301292
At time: 29.13815999031067 and batch: 500, loss is 5.0894632816314695 and perplexity is 162.30272781702627
At time: 29.54977822303772 and batch: 550, loss is 5.145768938064575 and perplexity is 171.70346325159565
At time: 29.94886350631714 and batch: 600, loss is 5.027723999023437 and perplexity is 152.58533281932682
At time: 30.345256805419922 and batch: 650, loss is 5.155512781143188 and perplexity is 173.3846923682692
At time: 30.741147756576538 and batch: 700, loss is 5.173011293411255 and perplexity is 176.44536706433937
At time: 31.138153791427612 and batch: 750, loss is 5.110432996749878 and perplexity is 165.7421051316343
At time: 31.53397488594055 and batch: 800, loss is 5.022979516983032 and perplexity is 151.86310909166622
At time: 31.935750722885132 and batch: 850, loss is 4.986703290939331 and perplexity is 146.45281445416893
At time: 32.32791757583618 and batch: 900, loss is 4.9541082763671875 and perplexity is 141.7561426934765
At time: 32.72300052642822 and batch: 950, loss is 5.004143590927124 and perplexity is 149.0293983621004
At time: 33.11092185974121 and batch: 1000, loss is 5.058152904510498 and perplexity is 157.29970025668325
At time: 33.50380992889404 and batch: 1050, loss is 4.945881462097168 and perplexity is 140.59472516946605
At time: 33.899794816970825 and batch: 1100, loss is 5.059893188476562 and perplexity is 157.57368473915867
At time: 34.28555703163147 and batch: 1150, loss is 5.024459924697876 and perplexity is 152.088094904242
At time: 34.68609857559204 and batch: 1200, loss is 4.982208957672119 and perplexity is 145.79608358722587
At time: 35.07309675216675 and batch: 1250, loss is 4.955270156860352 and perplexity is 141.9209421105328
At time: 35.46649193763733 and batch: 1300, loss is 5.0407587432861325 and perplexity is 154.58726258747575
At time: 35.85365676879883 and batch: 1350, loss is 4.990823516845703 and perplexity is 147.0574779540423
At time: 36.241175174713135 and batch: 1400, loss is 4.879191675186157 and perplexity is 131.5243065453785
At time: 36.62864112854004 and batch: 1450, loss is 4.9667657947540285 and perplexity is 143.56182731144614
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.153339614216079 and perplexity of 173.00830761072885
Finished 3 epochs...
Completing Train Step...
At time: 37.902862787246704 and batch: 50, loss is 5.025409364700318 and perplexity is 152.23256199600493
At time: 38.29298496246338 and batch: 100, loss is 5.072820243835449 and perplexity is 159.62387137267325
At time: 38.694618940353394 and batch: 150, loss is 4.960261974334717 and perplexity is 142.63115670537675
At time: 39.09915590286255 and batch: 200, loss is 5.0350187969207765 and perplexity is 153.7024817180613
At time: 39.50387763977051 and batch: 250, loss is 5.045375957489013 and perplexity is 155.30267542807314
At time: 39.89776682853699 and batch: 300, loss is 5.056645545959473 and perplexity is 157.0627718213401
At time: 40.29461097717285 and batch: 350, loss is 5.072785882949829 and perplexity is 159.6183866493174
At time: 40.68250298500061 and batch: 400, loss is 4.92905707359314 and perplexity is 138.24909214159453
At time: 41.077330589294434 and batch: 450, loss is 4.996264448165894 and perplexity is 147.8597882700935
At time: 41.47330904006958 and batch: 500, loss is 4.984329824447632 and perplexity is 146.10562578976365
At time: 41.89243292808533 and batch: 550, loss is 5.042735166549683 and perplexity is 154.89309457667665
At time: 42.28714847564697 and batch: 600, loss is 4.938929796218872 and perplexity is 139.62074692384712
At time: 42.6740243434906 and batch: 650, loss is 5.055154066085816 and perplexity is 156.8286904654764
At time: 43.07811498641968 and batch: 700, loss is 5.062849063873291 and perplexity is 158.04014197215287
At time: 43.47203493118286 and batch: 750, loss is 5.03496994972229 and perplexity is 153.69497396579683
At time: 43.863489627838135 and batch: 800, loss is 4.954844856262207 and perplexity is 141.860595882517
At time: 44.24967432022095 and batch: 850, loss is 4.913095645904541 and perplexity is 136.0599565951833
At time: 44.638081312179565 and batch: 900, loss is 4.880329294204712 and perplexity is 131.67401623805762
At time: 45.0454888343811 and batch: 950, loss is 4.948802928924561 and perplexity is 141.00606856563155
At time: 45.45531868934631 and batch: 1000, loss is 4.992187356948852 and perplexity is 147.2581776699952
At time: 45.862865686416626 and batch: 1050, loss is 4.873525257110596 and perplexity is 130.78114236534225
At time: 46.26037836074829 and batch: 1100, loss is 5.017676420211792 and perplexity is 151.05989596901546
At time: 46.65634274482727 and batch: 1150, loss is 4.986295499801636 and perplexity is 146.3931044697727
At time: 47.046079874038696 and batch: 1200, loss is 4.92637110710144 and perplexity is 137.87825795963366
At time: 47.43447971343994 and batch: 1250, loss is 4.891694202423095 and perplexity is 133.17901523617644
At time: 47.83693838119507 and batch: 1300, loss is 5.007445135116577 and perplexity is 149.5222386256035
At time: 48.22899651527405 and batch: 1350, loss is 4.948989315032959 and perplexity is 141.03235258742419
At time: 48.64001941680908 and batch: 1400, loss is 4.81184196472168 and perplexity is 122.95789315886498
At time: 49.03142166137695 and batch: 1450, loss is 4.906450986862183 and perplexity is 135.15888155780274
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.1480285122863245 and perplexity of 172.09187863237474
Finished 4 epochs...
Completing Train Step...
At time: 50.36547923088074 and batch: 50, loss is 4.9726314449310305 and perplexity is 144.4063852885736
At time: 50.762091636657715 and batch: 100, loss is 5.00951265335083 and perplexity is 149.83169837699214
At time: 51.14863991737366 and batch: 150, loss is 4.888875579833984 and perplexity is 132.80416238796127
At time: 51.5559983253479 and batch: 200, loss is 4.961192407608032 and perplexity is 142.76392723686862
At time: 51.94797229766846 and batch: 250, loss is 4.9736826133728025 and perplexity is 144.55826053282664
At time: 52.34466552734375 and batch: 300, loss is 4.985996713638306 and perplexity is 146.34937076958784
At time: 52.7385618686676 and batch: 350, loss is 5.024016733169556 and perplexity is 152.02070568329106
At time: 53.12997770309448 and batch: 400, loss is 4.8987157440185545 and perplexity is 134.11742792770417
At time: 53.532541275024414 and batch: 450, loss is 4.938382635116577 and perplexity is 139.54437277844323
At time: 53.94443607330322 and batch: 500, loss is 4.923908529281616 and perplexity is 137.53913974362067
At time: 54.346160888671875 and batch: 550, loss is 4.985740842819214 and perplexity is 146.3119290265445
At time: 54.73426961898804 and batch: 600, loss is 4.882276201248169 and perplexity is 131.9306230214343
At time: 55.13188147544861 and batch: 650, loss is 5.002279424667359 and perplexity is 148.75184157234045
At time: 55.536906480789185 and batch: 700, loss is 4.9911340141296385 and perplexity is 147.1031459910633
At time: 55.930646896362305 and batch: 750, loss is 4.973564863204956 and perplexity is 144.54123977550347
At time: 56.325435400009155 and batch: 800, loss is 4.895779209136963 and perplexity is 133.7241651199413
At time: 56.713520765304565 and batch: 850, loss is 4.847984285354614 and perplexity is 127.4831610084721
At time: 57.117154359817505 and batch: 900, loss is 4.825432996749878 and perplexity is 124.64042559989078
At time: 57.509849548339844 and batch: 950, loss is 4.888284578323364 and perplexity is 132.72569811590887
At time: 57.908658027648926 and batch: 1000, loss is 4.941891260147095 and perplexity is 140.03484159005865
At time: 58.303269386291504 and batch: 1050, loss is 4.836446542739868 and perplexity is 126.02074581704223
At time: 58.69071865081787 and batch: 1100, loss is 4.961933193206787 and perplexity is 142.86972387966392
At time: 59.08457159996033 and batch: 1150, loss is 4.92950855255127 and perplexity is 138.31152278967858
At time: 59.48421335220337 and batch: 1200, loss is 4.884474267959595 and perplexity is 132.22093427698223
At time: 59.9076783657074 and batch: 1250, loss is 4.848809738159179 and perplexity is 127.58843578496352
At time: 60.31492495536804 and batch: 1300, loss is 4.944944906234741 and perplexity is 140.4631119965469
At time: 60.716660022735596 and batch: 1350, loss is 4.911010217666626 and perplexity is 135.77650897720994
At time: 61.11090421676636 and batch: 1400, loss is 4.786929769515991 and perplexity is 119.93258215336144
At time: 61.51786279678345 and batch: 1450, loss is 4.862331647872924 and perplexity is 129.3253921118406
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.155240572415865 and perplexity of 173.33750196493352
Annealing...
Finished 5 epochs...
Completing Train Step...
At time: 62.82458019256592 and batch: 50, loss is 4.921546964645386 and perplexity is 137.21471540040855
At time: 63.22424387931824 and batch: 100, loss is 4.915151853561401 and perplexity is 136.34001194703322
At time: 63.63660955429077 and batch: 150, loss is 4.805172719955444 and perplexity is 122.14058531588051
At time: 64.03218722343445 and batch: 200, loss is 4.861149673461914 and perplexity is 129.17262310998169
At time: 64.44410252571106 and batch: 250, loss is 4.867093925476074 and perplexity is 129.9427443648586
At time: 64.83205938339233 and batch: 300, loss is 4.865915832519531 and perplexity is 129.7897498715311
At time: 65.23540997505188 and batch: 350, loss is 4.8861505317687985 and perplexity is 132.44275730894913
At time: 65.6563413143158 and batch: 400, loss is 4.76006854057312 and perplexity is 116.75392800589182
At time: 66.04571866989136 and batch: 450, loss is 4.810538339614868 and perplexity is 122.7977065965602
At time: 66.45598030090332 and batch: 500, loss is 4.798316888809204 and perplexity is 121.30607398989063
At time: 66.85264897346497 and batch: 550, loss is 4.852030725479126 and perplexity is 128.00005907963072
At time: 67.246426820755 and batch: 600, loss is 4.7443212890625 and perplexity is 114.92977493071345
At time: 67.65106701850891 and batch: 650, loss is 4.865693407058716 and perplexity is 129.76088453691852
At time: 68.06366729736328 and batch: 700, loss is 4.871343955993653 and perplexity is 130.49618022053727
At time: 68.45003128051758 and batch: 750, loss is 4.822534732818603 and perplexity is 124.27970773029173
At time: 68.83643579483032 and batch: 800, loss is 4.754567070007324 and perplexity is 116.11337331949724
At time: 69.25732111930847 and batch: 850, loss is 4.699360628128051 and perplexity is 109.87689779087218
At time: 69.65322613716125 and batch: 900, loss is 4.665955448150635 and perplexity is 106.26706940775514
At time: 70.04904532432556 and batch: 950, loss is 4.744271726608276 and perplexity is 114.92407887016098
At time: 70.44786643981934 and batch: 1000, loss is 4.788526124954224 and perplexity is 120.12419007959043
At time: 70.83979368209839 and batch: 1050, loss is 4.674277830123901 and perplexity is 107.1551549180883
At time: 71.23010182380676 and batch: 1100, loss is 4.821582765579223 and perplexity is 124.16145381586958
At time: 71.61828184127808 and batch: 1150, loss is 4.779264354705811 and perplexity is 119.01676371037327
At time: 72.02289175987244 and batch: 1200, loss is 4.714145994186401 and perplexity is 111.51353728813338
At time: 72.42007565498352 and batch: 1250, loss is 4.691805286407471 and perplexity is 109.04986845958908
At time: 72.8215696811676 and batch: 1300, loss is 4.774959888458252 and perplexity is 118.50556108462726
At time: 73.2253520488739 and batch: 1350, loss is 4.719095487594604 and perplexity is 112.06684096276632
At time: 73.63345289230347 and batch: 1400, loss is 4.597521705627441 and perplexity is 99.2380694835906
At time: 74.03428816795349 and batch: 1450, loss is 4.681464214324951 and perplexity is 107.92798663726622
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.031082022903312 and perplexity of 153.09857927528606
Finished 6 epochs...
Completing Train Step...
At time: 75.3011224269867 and batch: 50, loss is 4.831137657165527 and perplexity is 125.35348886010128
At time: 75.71201753616333 and batch: 100, loss is 4.845999298095703 and perplexity is 127.23035954499338
At time: 76.1054995059967 and batch: 150, loss is 4.747725076675415 and perplexity is 115.32163800598228
At time: 76.49347567558289 and batch: 200, loss is 4.810546445846557 and perplexity is 122.7987020272554
At time: 76.89622449874878 and batch: 250, loss is 4.8245445728302006 and perplexity is 124.52974123902612
At time: 77.29258608818054 and batch: 300, loss is 4.824865074157715 and perplexity is 124.56965958300762
At time: 77.71347665786743 and batch: 350, loss is 4.8454188632965085 and perplexity is 127.1565320448973
At time: 78.1162588596344 and batch: 400, loss is 4.723793935775757 and perplexity is 112.59462010842725
At time: 78.52434802055359 and batch: 450, loss is 4.774194564819336 and perplexity is 118.41490067408897
At time: 78.9106011390686 and batch: 500, loss is 4.765860223770142 and perplexity is 117.43209172795714
At time: 79.30691623687744 and batch: 550, loss is 4.815582103729248 and perplexity is 123.41863385138062
At time: 79.70103359222412 and batch: 600, loss is 4.709737997055054 and perplexity is 111.02306772404634
At time: 80.09158253669739 and batch: 650, loss is 4.836391248703003 and perplexity is 126.01377781392357
At time: 80.48714303970337 and batch: 700, loss is 4.842632627487182 and perplexity is 126.80273706891876
At time: 80.88826394081116 and batch: 750, loss is 4.796435995101929 and perplexity is 121.0781246001577
At time: 81.28594636917114 and batch: 800, loss is 4.730503301620484 and perplexity is 113.35259854078353
At time: 81.68103218078613 and batch: 850, loss is 4.677251214981079 and perplexity is 107.47424258321784
At time: 82.08330583572388 and batch: 900, loss is 4.641643953323364 and perplexity is 103.7147096528833
At time: 82.4782464504242 and batch: 950, loss is 4.721159715652465 and perplexity is 112.29841140511226
At time: 82.86790347099304 and batch: 1000, loss is 4.770104141235351 and perplexity is 117.93152285566283
At time: 83.27899551391602 and batch: 1050, loss is 4.657659959793091 and perplexity is 105.38917847205319
At time: 83.67323541641235 and batch: 1100, loss is 4.80564356803894 and perplexity is 122.1981085176755
At time: 84.07069540023804 and batch: 1150, loss is 4.758098564147949 and perplexity is 116.52415192121877
At time: 84.46578788757324 and batch: 1200, loss is 4.701345710754395 and perplexity is 110.09522914290469
At time: 84.85634064674377 and batch: 1250, loss is 4.677521448135376 and perplexity is 107.50328961135506
At time: 85.25201201438904 and batch: 1300, loss is 4.7670239734649655 and perplexity is 117.56883283964902
At time: 85.64184546470642 and batch: 1350, loss is 4.710034923553467 and perplexity is 111.05603830946669
At time: 86.0454580783844 and batch: 1400, loss is 4.589217538833618 and perplexity is 98.41739223876183
At time: 86.42802834510803 and batch: 1450, loss is 4.674309520721436 and perplexity is 107.15855078278477
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.027518508780716 and perplexity of 152.55398124358186
Finished 7 epochs...
Completing Train Step...
At time: 87.69519376754761 and batch: 50, loss is 4.804093208312988 and perplexity is 122.0088042743974
At time: 88.09831762313843 and batch: 100, loss is 4.817789001464844 and perplexity is 123.69130692508311
At time: 88.49295997619629 and batch: 150, loss is 4.720541934967041 and perplexity is 112.22905704064156
At time: 88.89366912841797 and batch: 200, loss is 4.783334789276123 and perplexity is 119.50220095986307
At time: 89.27625489234924 and batch: 250, loss is 4.800184631347657 and perplexity is 121.53285422207134
At time: 89.66659164428711 and batch: 300, loss is 4.799897699356079 and perplexity is 121.49798756058685
At time: 90.05212569236755 and batch: 350, loss is 4.818295412063598 and perplexity is 123.75396137698405
At time: 90.44127106666565 and batch: 400, loss is 4.6997597026824955 and perplexity is 109.92075561559065
At time: 90.83748269081116 and batch: 450, loss is 4.751141719818115 and perplexity is 115.71632475762578
At time: 91.23014497756958 and batch: 500, loss is 4.7432909679412845 and perplexity is 114.81142133771904
At time: 91.6318621635437 and batch: 550, loss is 4.787724075317382 and perplexity is 120.02788314319562
At time: 92.01606178283691 and batch: 600, loss is 4.685714168548584 and perplexity is 108.3876517258392
At time: 92.41982793807983 and batch: 650, loss is 4.811563577651977 and perplexity is 122.92366803542866
At time: 92.82073092460632 and batch: 700, loss is 4.822016477584839 and perplexity is 124.21531580847629
At time: 93.21659255027771 and batch: 750, loss is 4.7741750144958495 and perplexity is 118.41258564710503
At time: 93.62891244888306 and batch: 800, loss is 4.707303810119629 and perplexity is 110.75314547694543
At time: 94.01232600212097 and batch: 850, loss is 4.656851167678833 and perplexity is 105.30397499617119
At time: 94.4009461402893 and batch: 900, loss is 4.624918231964111 and perplexity is 101.99443285727607
At time: 94.78772306442261 and batch: 950, loss is 4.704117794036865 and perplexity is 110.4008456886423
At time: 95.17885637283325 and batch: 1000, loss is 4.752976589202881 and perplexity is 115.9288440121532
At time: 95.56667041778564 and batch: 1050, loss is 4.640061597824097 and perplexity is 103.5507258862325
At time: 95.96775698661804 and batch: 1100, loss is 4.790235357284546 and perplexity is 120.32968579886257
At time: 96.36316990852356 and batch: 1150, loss is 4.737262792587281 and perplexity is 114.12139983212023
At time: 96.75655436515808 and batch: 1200, loss is 4.686304941177368 and perplexity is 108.45170310181398
At time: 97.144376039505 and batch: 1250, loss is 4.661479473114014 and perplexity is 105.79248356739295
At time: 97.5296688079834 and batch: 1300, loss is 4.74903865814209 and perplexity is 115.47322190948017
At time: 97.94099569320679 and batch: 1350, loss is 4.692941904067993 and perplexity is 109.17388693340007
At time: 98.33414721488953 and batch: 1400, loss is 4.575397367477417 and perplexity is 97.06660258550662
At time: 98.72022247314453 and batch: 1450, loss is 4.6601786708831785 and perplexity is 105.65495793497972
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.023011818910256 and perplexity of 151.8680146419931
Finished 8 epochs...
Completing Train Step...
At time: 100.02806544303894 and batch: 50, loss is 4.784656562805176 and perplexity is 119.66026024203109
At time: 100.42513704299927 and batch: 100, loss is 4.794476051330566 and perplexity is 120.84105068566127
At time: 100.81908893585205 and batch: 150, loss is 4.69727427482605 and perplexity is 109.6478947360607
At time: 101.2162253856659 and batch: 200, loss is 4.756750268936157 and perplexity is 116.36714883216654
At time: 101.60692071914673 and batch: 250, loss is 4.774964656829834 and perplexity is 118.5061261645243
At time: 102.00778198242188 and batch: 300, loss is 4.776531629562378 and perplexity is 118.69196759906745
At time: 102.40145230293274 and batch: 350, loss is 4.796109008789062 and perplexity is 121.03854018275996
At time: 102.81236362457275 and batch: 400, loss is 4.680421085357666 and perplexity is 107.815462526807
At time: 103.20950412750244 and batch: 450, loss is 4.730476274490356 and perplexity is 113.34953498675219
At time: 103.60174298286438 and batch: 500, loss is 4.726121387481689 and perplexity is 112.85698385011045
At time: 103.99072742462158 and batch: 550, loss is 4.764472284317017 and perplexity is 117.26921615165067
At time: 104.38106727600098 and batch: 600, loss is 4.665148735046387 and perplexity is 106.18137693957964
At time: 104.78463816642761 and batch: 650, loss is 4.791573352813721 and perplexity is 120.49079413757183
At time: 105.17815279960632 and batch: 700, loss is 4.803711538314819 and perplexity is 121.96224605979543
At time: 105.57537770271301 and batch: 750, loss is 4.755258960723877 and perplexity is 116.19373888345243
At time: 105.99826383590698 and batch: 800, loss is 4.690556735992431 and perplexity is 108.91379916342827
At time: 106.38905358314514 and batch: 850, loss is 4.640159463882446 and perplexity is 103.5608604835226
At time: 106.77675247192383 and batch: 900, loss is 4.607830476760864 and perplexity is 100.26638324862371
At time: 107.16664719581604 and batch: 950, loss is 4.688876218795777 and perplexity is 108.73092135866837
At time: 107.56266736984253 and batch: 1000, loss is 4.739356441497803 and perplexity is 114.36058026910872
At time: 107.95222425460815 and batch: 1050, loss is 4.626639947891236 and perplexity is 102.17018955494093
At time: 108.34845805168152 and batch: 1100, loss is 4.774532613754272 and perplexity is 118.4549374719596
At time: 108.74543261528015 and batch: 1150, loss is 4.720384492874145 and perplexity is 112.21138885391197
At time: 109.13569808006287 and batch: 1200, loss is 4.672424526214599 and perplexity is 106.95674776174567
At time: 109.53592705726624 and batch: 1250, loss is 4.649844055175781 and perplexity is 104.56867736154639
At time: 109.94103908538818 and batch: 1300, loss is 4.734435682296753 and perplexity is 113.79922167945625
At time: 110.34289789199829 and batch: 1350, loss is 4.6778200817108155 and perplexity is 107.53539849726025
At time: 110.74024057388306 and batch: 1400, loss is 4.56149543762207 and perplexity is 95.72652589342673
At time: 111.1371808052063 and batch: 1450, loss is 4.645316152572632 and perplexity is 104.09627088746738
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.022939828725962 and perplexity of 151.8570820291557
Finished 9 epochs...
Completing Train Step...
At time: 112.42720556259155 and batch: 50, loss is 4.7681772327423095 and perplexity is 117.7044984005949
At time: 112.82601261138916 and batch: 100, loss is 4.775653648376465 and perplexity is 118.58780401811985
At time: 113.21529483795166 and batch: 150, loss is 4.681107788085938 and perplexity is 107.889525125658
At time: 113.60448431968689 and batch: 200, loss is 4.739818716049195 and perplexity is 114.41345847623263
At time: 114.00273656845093 and batch: 250, loss is 4.757143983840942 and perplexity is 116.41297333339172
At time: 114.39811706542969 and batch: 300, loss is 4.758395671844482 and perplexity is 116.55877728706322
At time: 114.79189205169678 and batch: 350, loss is 4.777868957519531 and perplexity is 118.85080387004761
At time: 115.19215726852417 and batch: 400, loss is 4.6639188861846925 and perplexity is 106.05087016227273
At time: 115.58709573745728 and batch: 450, loss is 4.715051164627075 and perplexity is 111.6145217429984
At time: 116.0044686794281 and batch: 500, loss is 4.713224420547485 and perplexity is 111.41081669135349
At time: 116.39843702316284 and batch: 550, loss is 4.747901678085327 and perplexity is 115.3420057682823
At time: 116.7906744480133 and batch: 600, loss is 4.647743740081787 and perplexity is 104.34928067186688
At time: 117.18322587013245 and batch: 650, loss is 4.7744976425170895 and perplexity is 118.45079502867942
At time: 117.57809376716614 and batch: 700, loss is 4.789096384048462 and perplexity is 120.1927115270537
At time: 117.97645568847656 and batch: 750, loss is 4.738822565078736 and perplexity is 114.29954214688907
At time: 118.37018752098083 and batch: 800, loss is 4.675124044418335 and perplexity is 107.24586951848482
At time: 118.78018426895142 and batch: 850, loss is 4.624077787399292 and perplexity is 101.9087482021843
At time: 119.17595553398132 and batch: 900, loss is 4.592473955154419 and perplexity is 98.73840262916323
At time: 119.59007000923157 and batch: 950, loss is 4.672536602020264 and perplexity is 106.96873569718855
At time: 119.98573112487793 and batch: 1000, loss is 4.725703992843628 and perplexity is 112.80988777969101
At time: 120.37609601020813 and batch: 1050, loss is 4.613270845413208 and perplexity is 100.81335585415223
At time: 120.76543140411377 and batch: 1100, loss is 4.759831886291504 and perplexity is 116.7263009580923
At time: 121.15202116966248 and batch: 1150, loss is 4.70487382888794 and perplexity is 110.48434413546173
At time: 121.5466878414154 and batch: 1200, loss is 4.659544439315796 and perplexity is 105.58796947075169
At time: 121.94165825843811 and batch: 1250, loss is 4.636486415863037 and perplexity is 103.1811741998825
At time: 122.34815311431885 and batch: 1300, loss is 4.7211809253692625 and perplexity is 112.30079324787394
At time: 122.74949169158936 and batch: 1350, loss is 4.663724126815796 and perplexity is 106.03021777291747
At time: 123.14794826507568 and batch: 1400, loss is 4.549700756072998 and perplexity is 94.60409437803635
At time: 123.552081823349 and batch: 1450, loss is 4.63184741973877 and perplexity is 102.70362566199483
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0218808426816235 and perplexity of 151.69635261867506
Finished 10 epochs...
Completing Train Step...
At time: 124.81389141082764 and batch: 50, loss is 4.753846759796143 and perplexity is 116.02976578633537
At time: 125.230703830719 and batch: 100, loss is 4.75940393447876 and perplexity is 116.67635841326585
At time: 125.6409969329834 and batch: 150, loss is 4.664772701263428 and perplexity is 106.14145666088638
At time: 126.05799126625061 and batch: 200, loss is 4.722372798919678 and perplexity is 112.43472138988737
At time: 126.45402002334595 and batch: 250, loss is 4.739884738922119 and perplexity is 114.4210126308332
At time: 126.84208798408508 and batch: 300, loss is 4.741680517196655 and perplexity is 114.6266720035149
At time: 127.23342275619507 and batch: 350, loss is 4.76103458404541 and perplexity is 116.86677187317092
At time: 127.6210446357727 and batch: 400, loss is 4.647997941970825 and perplexity is 104.37580982787134
At time: 128.0155725479126 and batch: 450, loss is 4.699882144927979 and perplexity is 109.93421538373872
At time: 128.4096179008484 and batch: 500, loss is 4.700108528137207 and perplexity is 109.95910546146283
At time: 128.81931900978088 and batch: 550, loss is 4.733320932388306 and perplexity is 113.67243468853054
At time: 129.22280716896057 and batch: 600, loss is 4.63450888633728 and perplexity is 102.97733199981377
At time: 129.6267066001892 and batch: 650, loss is 4.7603957462310795 and perplexity is 116.79213680245066
At time: 130.0285928249359 and batch: 700, loss is 4.775887231826783 and perplexity is 118.61550740194807
At time: 130.42349910736084 and batch: 750, loss is 4.725569372177124 and perplexity is 112.79470225957522
At time: 130.82451605796814 and batch: 800, loss is 4.663650884628296 and perplexity is 106.02245217221486
At time: 131.22341203689575 and batch: 850, loss is 4.61232361793518 and perplexity is 100.71790788594076
At time: 131.63390517234802 and batch: 900, loss is 4.580482110977173 and perplexity is 97.56141830143885
At time: 132.02993893623352 and batch: 950, loss is 4.659557313919067 and perplexity is 105.5893288827198
At time: 132.41793775558472 and batch: 1000, loss is 4.714745302200317 and perplexity is 111.58038827485541
At time: 132.8238594532013 and batch: 1050, loss is 4.601791524887085 and perplexity is 99.66270401517373
At time: 133.2187786102295 and batch: 1100, loss is 4.74809588432312 and perplexity is 115.36440808054601
At time: 133.61207246780396 and batch: 1150, loss is 4.689469718933106 and perplexity is 108.79547232903676
At time: 134.00326013565063 and batch: 1200, loss is 4.647319345474243 and perplexity is 104.30500479573476
At time: 134.40486025810242 and batch: 1250, loss is 4.626434907913208 and perplexity is 102.14924272906129
At time: 134.8002872467041 and batch: 1300, loss is 4.709853181838989 and perplexity is 111.03585662864339
At time: 135.18793511390686 and batch: 1350, loss is 4.65008731842041 and perplexity is 104.59411817156946
At time: 135.58728742599487 and batch: 1400, loss is 4.53884370803833 and perplexity is 93.58252880909967
At time: 135.989511013031 and batch: 1450, loss is 4.61921947479248 and perplexity is 101.41484438709047
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0215193267561435 and perplexity of 151.64152188305542
Finished 11 epochs...
Completing Train Step...
At time: 137.31088280677795 and batch: 50, loss is 4.739928922653198 and perplexity is 114.4260682897732
At time: 137.698091506958 and batch: 100, loss is 4.744877519607544 and perplexity is 114.9937201645624
At time: 138.09419703483582 and batch: 150, loss is 4.651292161941528 and perplexity is 104.72021366461061
At time: 138.48962545394897 and batch: 200, loss is 4.707397565841675 and perplexity is 110.76352970485132
At time: 138.8851387500763 and batch: 250, loss is 4.726099042892456 and perplexity is 112.85446213533768
At time: 139.28867149353027 and batch: 300, loss is 4.7283139896392825 and perplexity is 113.10470579499139
At time: 139.6811647415161 and batch: 350, loss is 4.746696920394897 and perplexity is 115.20313027226175
At time: 140.07137751579285 and batch: 400, loss is 4.635140829086303 and perplexity is 103.04242834449994
At time: 140.45486164093018 and batch: 450, loss is 4.686578979492188 and perplexity is 108.48142709634202
At time: 140.83729934692383 and batch: 500, loss is 4.685883941650391 and perplexity is 108.40605459578224
At time: 141.24552011489868 and batch: 550, loss is 4.716467304229736 and perplexity is 111.77269545906829
At time: 141.64791321754456 and batch: 600, loss is 4.620003080368042 and perplexity is 101.49434476900012
At time: 142.04893946647644 and batch: 650, loss is 4.746976699829101 and perplexity is 115.23536624813914
At time: 142.43309473991394 and batch: 700, loss is 4.763765211105347 and perplexity is 117.18632753796882
At time: 142.8297438621521 and batch: 750, loss is 4.711854658126831 and perplexity is 111.25831481091204
At time: 143.22390508651733 and batch: 800, loss is 4.651602087020874 and perplexity is 104.75267411503368
At time: 143.61469864845276 and batch: 850, loss is 4.601768045425415 and perplexity is 99.66036401600594
At time: 144.01658606529236 and batch: 900, loss is 4.569733581542969 and perplexity is 96.51839206607151
At time: 144.40470242500305 and batch: 950, loss is 4.647947254180909 and perplexity is 104.37051938283204
At time: 144.79989862442017 and batch: 1000, loss is 4.704404153823853 and perplexity is 110.43246457827016
At time: 145.19424748420715 and batch: 1050, loss is 4.592163972854614 and perplexity is 98.70780021538555
At time: 145.5870862007141 and batch: 1100, loss is 4.737032241821289 and perplexity is 114.09509208872467
At time: 145.98288416862488 and batch: 1150, loss is 4.677259397506714 and perplexity is 107.47512199756078
At time: 146.39727902412415 and batch: 1200, loss is 4.636850080490112 and perplexity is 103.21870436690257
At time: 146.79748821258545 and batch: 1250, loss is 4.6164161968231205 and perplexity is 101.13094849351927
At time: 147.18967390060425 and batch: 1300, loss is 4.69946699142456 and perplexity is 109.8885852814804
At time: 147.58927512168884 and batch: 1350, loss is 4.639190034866333 and perplexity is 103.46051422758107
At time: 147.983092546463 and batch: 1400, loss is 4.529553050994873 and perplexity is 92.71711199902232
At time: 148.37104845046997 and batch: 1450, loss is 4.610331411361694 and perplexity is 100.51745674412118
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.022805760049413 and perplexity of 151.8367241158532
Annealing...
Finished 12 epochs...
Completing Train Step...
At time: 149.637460231781 and batch: 50, loss is 4.725779714584351 and perplexity is 112.81843026418628
At time: 150.02201414108276 and batch: 100, loss is 4.71562557220459 and perplexity is 111.67865238684881
At time: 150.42036318778992 and batch: 150, loss is 4.615916786193847 and perplexity is 101.08045523237826
At time: 150.82203793525696 and batch: 200, loss is 4.665626077651978 and perplexity is 106.23207393366822
At time: 151.22858500480652 and batch: 250, loss is 4.685460729598999 and perplexity is 108.36018555388372
At time: 151.6260952949524 and batch: 300, loss is 4.678665733337402 and perplexity is 107.62637444347192
At time: 152.02359342575073 and batch: 350, loss is 4.6958676528930665 and perplexity is 109.49377002543109
At time: 152.432941198349 and batch: 400, loss is 4.583227758407593 and perplexity is 97.8296556329656
At time: 152.8295612335205 and batch: 450, loss is 4.639914855957032 and perplexity is 103.53553177421341
At time: 153.23270797729492 and batch: 500, loss is 4.626620807647705 and perplexity is 102.16823401134613
At time: 153.62784051895142 and batch: 550, loss is 4.657957468032837 and perplexity is 105.4205372855501
At time: 154.02130341529846 and batch: 600, loss is 4.565719985961914 and perplexity is 96.13178264011563
At time: 154.40877866744995 and batch: 650, loss is 4.687882137298584 and perplexity is 108.62288766761625
At time: 154.79354906082153 and batch: 700, loss is 4.698326148986816 and perplexity is 109.76329120395748
At time: 155.19520950317383 and batch: 750, loss is 4.6489965438842775 and perplexity is 104.48009177069154
At time: 155.58905243873596 and batch: 800, loss is 4.587166919708252 and perplexity is 98.21578243507605
At time: 155.99794220924377 and batch: 850, loss is 4.533263025283813 and perplexity is 93.06172896545299
At time: 156.40861797332764 and batch: 900, loss is 4.496056623458863 and perplexity is 89.66285883060877
At time: 156.80904126167297 and batch: 950, loss is 4.576420650482178 and perplexity is 97.16598002721426
At time: 157.1938054561615 and batch: 1000, loss is 4.632143125534058 and perplexity is 102.73400021004383
At time: 157.57772135734558 and batch: 1050, loss is 4.5220161724090575 and perplexity is 92.02094115608617
At time: 157.98379755020142 and batch: 1100, loss is 4.657340593338013 and perplexity is 105.35552607772996
At time: 158.3777027130127 and batch: 1150, loss is 4.596109647750854 and perplexity is 99.09803847513062
At time: 158.78085851669312 and batch: 1200, loss is 4.557651615142822 and perplexity is 95.35927639445202
At time: 159.18610286712646 and batch: 1250, loss is 4.531704006195068 and perplexity is 92.91675698996613
At time: 159.58608150482178 and batch: 1300, loss is 4.615222311019897 and perplexity is 101.01028173534392
At time: 159.9837052822113 and batch: 1350, loss is 4.549155263900757 and perplexity is 94.5525026578103
At time: 160.38870787620544 and batch: 1400, loss is 4.436420106887818 and perplexity is 84.47199901873985
At time: 160.8020303249359 and batch: 1450, loss is 4.520921831130981 and perplexity is 91.92029392298694
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.972138233673879 and perplexity of 144.33517999481433
Finished 13 epochs...
Completing Train Step...
At time: 162.08215975761414 and batch: 50, loss is 4.6840306091308594 and perplexity is 108.20532819332564
At time: 162.49294233322144 and batch: 100, loss is 4.6867564868927 and perplexity is 108.5006850616349
At time: 162.89454126358032 and batch: 150, loss is 4.590488882064819 and perplexity is 98.54259409461922
At time: 163.29096794128418 and batch: 200, loss is 4.643614015579224 and perplexity is 103.9192354859103
At time: 163.6904833316803 and batch: 250, loss is 4.665806150436401 and perplexity is 106.25120516147153
At time: 164.0782880783081 and batch: 300, loss is 4.660974779129028 and perplexity is 105.73910420853355
At time: 164.47368931770325 and batch: 350, loss is 4.681389398574829 and perplexity is 107.9199122260372
At time: 164.8694348335266 and batch: 400, loss is 4.571372556686401 and perplexity is 96.67671301816378
At time: 165.2732663154602 and batch: 450, loss is 4.6259587860107425 and perplexity is 102.10061881365178
At time: 165.6627299785614 and batch: 500, loss is 4.6121915912628175 and perplexity is 100.70461131348567
At time: 166.0519142150879 and batch: 550, loss is 4.646196537017822 and perplexity is 104.18795597830098
At time: 166.4641501903534 and batch: 600, loss is 4.553814163208008 and perplexity is 94.99404098961091
At time: 166.8537654876709 and batch: 650, loss is 4.676649742126465 and perplexity is 107.40961918029332
At time: 167.25784420967102 and batch: 700, loss is 4.688016042709351 and perplexity is 108.6374338338915
At time: 167.64770698547363 and batch: 750, loss is 4.640585241317749 and perplexity is 103.60496374951849
At time: 168.04685044288635 and batch: 800, loss is 4.579885816574096 and perplexity is 97.50326031511358
At time: 168.44132614135742 and batch: 850, loss is 4.5278028392791745 and perplexity is 92.55497934797617
At time: 168.8526771068573 and batch: 900, loss is 4.491276817321777 and perplexity is 89.23531036110106
At time: 169.24900889396667 and batch: 950, loss is 4.572192649841309 and perplexity is 96.75602944773408
At time: 169.64056873321533 and batch: 1000, loss is 4.629064579010009 and perplexity is 102.41821513971392
At time: 170.04228448867798 and batch: 1050, loss is 4.518735666275024 and perplexity is 91.71956050498254
At time: 170.42987394332886 and batch: 1100, loss is 4.655398445129395 and perplexity is 105.15110860026307
At time: 170.8210587501526 and batch: 1150, loss is 4.596861782073975 and perplexity is 99.17260154843
At time: 171.21391081809998 and batch: 1200, loss is 4.55669303894043 and perplexity is 95.26791105873728
At time: 171.59736609458923 and batch: 1250, loss is 4.533705387115479 and perplexity is 93.1029050290241
At time: 171.9975550174713 and batch: 1300, loss is 4.618077383041382 and perplexity is 101.29908544612562
At time: 172.38934063911438 and batch: 1350, loss is 4.551845607757568 and perplexity is 94.80722389269829
At time: 172.78144574165344 and batch: 1400, loss is 4.440203008651733 and perplexity is 84.79215346745035
At time: 173.17620015144348 and batch: 1450, loss is 4.523884372711182 and perplexity is 92.19301539067685
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.970845540364583 and perplexity of 144.14871941747495
Finished 14 epochs...
Completing Train Step...
At time: 174.42175912857056 and batch: 50, loss is 4.675237092971802 and perplexity is 107.25799419422479
At time: 174.82617163658142 and batch: 100, loss is 4.678340950012207 and perplexity is 107.59142486752845
At time: 175.2112193107605 and batch: 150, loss is 4.582314243316651 and perplexity is 97.74032757368042
At time: 175.60731554031372 and batch: 200, loss is 4.635320806503296 and perplexity is 103.06097532356269
At time: 176.00192165374756 and batch: 250, loss is 4.657612104415893 and perplexity is 105.38413515384075
At time: 176.40992164611816 and batch: 300, loss is 4.653107271194458 and perplexity is 104.91046490456124
At time: 176.81399631500244 and batch: 350, loss is 4.675815505981445 and perplexity is 107.32005155911841
At time: 177.20872163772583 and batch: 400, loss is 4.566930732727051 and perplexity is 96.24824437358062
At time: 177.6143491268158 and batch: 450, loss is 4.618705224990845 and perplexity is 101.36270523090592
At time: 178.0246067047119 and batch: 500, loss is 4.604705410003662 and perplexity is 99.95353320071973
At time: 178.4618480205536 and batch: 550, loss is 4.640291051864624 and perplexity is 103.57448874482431
At time: 178.87099480628967 and batch: 600, loss is 4.547640428543091 and perplexity is 94.4093796149204
At time: 179.27772760391235 and batch: 650, loss is 4.670536623001099 and perplexity is 106.7550142605212
At time: 179.6623604297638 and batch: 700, loss is 4.682392625808716 and perplexity is 108.02823474802783
At time: 180.04525089263916 and batch: 750, loss is 4.636583576202392 and perplexity is 103.19119980482056
At time: 180.45180368423462 and batch: 800, loss is 4.5760009765625 and perplexity is 97.12521055505734
At time: 180.84982419013977 and batch: 850, loss is 4.524753503799438 and perplexity is 92.273178037351
At time: 181.2602617740631 and batch: 900, loss is 4.488447780609131 and perplexity is 88.98321715063338
At time: 181.66390657424927 and batch: 950, loss is 4.569618492126465 and perplexity is 96.50728445984298
At time: 182.06020951271057 and batch: 1000, loss is 4.627035007476807 and perplexity is 102.21056084169108
At time: 182.46017861366272 and batch: 1050, loss is 4.517282133102417 and perplexity is 91.58633992493304
At time: 182.8507866859436 and batch: 1100, loss is 4.653653793334961 and perplexity is 104.96781646692378
At time: 183.24720406532288 and batch: 1150, loss is 4.596141967773438 and perplexity is 99.10124137773079
At time: 183.6372413635254 and batch: 1200, loss is 4.555061130523682 and perplexity is 95.11256933903901
At time: 184.0461778640747 and batch: 1250, loss is 4.533735485076904 and perplexity is 93.10570727883905
At time: 184.44059133529663 and batch: 1300, loss is 4.618303699493408 and perplexity is 101.32201369015881
At time: 184.83352708816528 and batch: 1350, loss is 4.551716613769531 and perplexity is 94.79499511952973
At time: 185.23169612884521 and batch: 1400, loss is 4.440308113098144 and perplexity is 84.80106596816407
At time: 185.62286686897278 and batch: 1450, loss is 4.523187198638916 and perplexity is 92.12876321078193
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.970769898504273 and perplexity of 144.13781615255377
Finished 15 epochs...
Completing Train Step...
At time: 186.9291787147522 and batch: 50, loss is 4.669239482879639 and perplexity is 106.61662782106201
At time: 187.3182029724121 and batch: 100, loss is 4.671991338729859 and perplexity is 106.91042547104938
At time: 187.71420073509216 and batch: 150, loss is 4.576399927139282 and perplexity is 97.16396644415649
At time: 188.1186399459839 and batch: 200, loss is 4.628292675018311 and perplexity is 102.33918861499376
At time: 188.5153796672821 and batch: 250, loss is 4.650789356231689 and perplexity is 104.66757297837229
At time: 188.9264361858368 and batch: 300, loss is 4.647067375183106 and perplexity is 104.27872634414284
At time: 189.34072136878967 and batch: 350, loss is 4.670831241607666 and perplexity is 106.78647090769591
At time: 189.73497796058655 and batch: 400, loss is 4.562986698150635 and perplexity is 95.8693855770569
At time: 190.13178610801697 and batch: 450, loss is 4.613248882293701 and perplexity is 100.81114170268464
At time: 190.53918528556824 and batch: 500, loss is 4.59853042602539 and perplexity is 99.33822345371571
At time: 190.95331025123596 and batch: 550, loss is 4.635040073394776 and perplexity is 103.03204675638622
At time: 191.35848355293274 and batch: 600, loss is 4.542944383621216 and perplexity is 93.967068296963
At time: 191.755446434021 and batch: 650, loss is 4.66526237487793 and perplexity is 106.19344405900779
At time: 192.1484079360962 and batch: 700, loss is 4.677953376770019 and perplexity is 107.54973338993338
At time: 192.55370998382568 and batch: 750, loss is 4.632444896697998 and perplexity is 102.76500704711279
At time: 192.95647931098938 and batch: 800, loss is 4.572902526855469 and perplexity is 96.82473871369929
At time: 193.35129165649414 and batch: 850, loss is 4.521470193862915 and perplexity is 91.97071340930289
At time: 193.74055337905884 and batch: 900, loss is 4.485333271026612 and perplexity is 88.70650919659768
At time: 194.15295839309692 and batch: 950, loss is 4.566799592971802 and perplexity is 96.23562322995528
At time: 194.55821633338928 and batch: 1000, loss is 4.6249596118927006 and perplexity is 101.99865346694789
At time: 194.95566582679749 and batch: 1050, loss is 4.5160205078125 and perplexity is 91.47086514054372
At time: 195.35680222511292 and batch: 1100, loss is 4.651532497406006 and perplexity is 104.74538467042339
At time: 195.76025772094727 and batch: 1150, loss is 4.594384794235229 and perplexity is 98.92725620461661
At time: 196.16670393943787 and batch: 1200, loss is 4.5531312942504885 and perplexity is 94.9291946511654
At time: 196.56344556808472 and batch: 1250, loss is 4.5330593967437744 and perplexity is 93.04278087070219
At time: 196.9583034515381 and batch: 1300, loss is 4.617471923828125 and perplexity is 101.23777154495397
At time: 197.35978150367737 and batch: 1350, loss is 4.549846725463867 and perplexity is 94.61790468798323
At time: 197.74613285064697 and batch: 1400, loss is 4.439097385406495 and perplexity is 84.69845709754975
At time: 198.15594625473022 and batch: 1450, loss is 4.521315689086914 and perplexity is 91.95650459252225
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.970995780749199 and perplexity of 144.17037800347853
Annealing...
Finished 16 epochs...
Completing Train Step...
At time: 199.44898796081543 and batch: 50, loss is 4.665038137435913 and perplexity is 106.16963418238575
At time: 199.83998727798462 and batch: 100, loss is 4.664145336151123 and perplexity is 106.07488809758863
At time: 200.22867512702942 and batch: 150, loss is 4.565036134719849 and perplexity is 96.06606527416744
At time: 200.61692881584167 and batch: 200, loss is 4.616623115539551 and perplexity is 101.15187654470103
At time: 201.02172803878784 and batch: 250, loss is 4.640435829162597 and perplexity is 103.5894850649809
At time: 201.41469645500183 and batch: 300, loss is 4.635470886230468 and perplexity is 103.07644384734822
At time: 201.80906438827515 and batch: 350, loss is 4.656166391372681 and perplexity is 105.23189001301124
At time: 202.2116367816925 and batch: 400, loss is 4.548787078857422 and perplexity is 94.51769624851462
At time: 202.61641597747803 and batch: 450, loss is 4.598238525390625 and perplexity is 99.30923079492669
At time: 203.01227712631226 and batch: 500, loss is 4.577929458618164 and perplexity is 97.31269550333923
At time: 203.40063953399658 and batch: 550, loss is 4.6177599811553955 and perplexity is 101.26693802745184
At time: 203.80049562454224 and batch: 600, loss is 4.523919515609741 and perplexity is 92.19625537739553
At time: 204.19425058364868 and batch: 650, loss is 4.644759759902954 and perplexity is 104.03836859510407
At time: 204.58502578735352 and batch: 700, loss is 4.656363687515259 and perplexity is 105.25265390723776
At time: 204.96847486495972 and batch: 750, loss is 4.610258340835571 and perplexity is 100.5101121490123
At time: 205.35626745224 and batch: 800, loss is 4.550493764877319 and perplexity is 94.67914601217322
At time: 205.7433648109436 and batch: 850, loss is 4.497448348999024 and perplexity is 89.78773179553895
At time: 206.12752652168274 and batch: 900, loss is 4.459824943542481 and perplexity is 86.47237022448464
At time: 206.53383898735046 and batch: 950, loss is 4.5387442016601565 and perplexity is 93.57321721388678
At time: 206.9465458393097 and batch: 1000, loss is 4.599112901687622 and perplexity is 99.39610240611101
At time: 207.35221481323242 and batch: 1050, loss is 4.486251010894775 and perplexity is 88.78795606445536
At time: 207.74833512306213 and batch: 1100, loss is 4.625272426605225 and perplexity is 102.03056513736978
At time: 208.1395890712738 and batch: 1150, loss is 4.563623456954956 and perplexity is 95.93045069219956
At time: 208.53942584991455 and batch: 1200, loss is 4.523751087188721 and perplexity is 92.18072821532276
At time: 208.93665766716003 and batch: 1250, loss is 4.505227422714233 and perplexity is 90.48892094496298
At time: 209.34563326835632 and batch: 1300, loss is 4.584389104843139 and perplexity is 97.9433357530499
At time: 209.74788880348206 and batch: 1350, loss is 4.51399640083313 and perplexity is 91.28590557612478
At time: 210.1467161178589 and batch: 1400, loss is 4.402884654998779 and perplexity is 81.68616553239647
At time: 210.5341112613678 and batch: 1450, loss is 4.485458517074585 and perplexity is 88.71762003208369
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.958971854967949 and perplexity of 142.44726413499586
Finished 17 epochs...
Completing Train Step...
At time: 211.77142691612244 and batch: 50, loss is 4.652824039459229 and perplexity is 104.8807551391154
At time: 212.18915724754333 and batch: 100, loss is 4.655450267791748 and perplexity is 105.15655795185889
At time: 212.57498359680176 and batch: 150, loss is 4.554994525909424 and perplexity is 95.10623461401043
At time: 212.9667191505432 and batch: 200, loss is 4.607926120758057 and perplexity is 100.27597358492338
At time: 213.36766481399536 and batch: 250, loss is 4.632049589157105 and perplexity is 102.7243912932729
At time: 213.7701542377472 and batch: 300, loss is 4.629163064956665 and perplexity is 102.42830239130485
At time: 214.17930030822754 and batch: 350, loss is 4.650977563858032 and perplexity is 104.68727406772715
At time: 214.56924295425415 and batch: 400, loss is 4.545678749084472 and perplexity is 94.22436020794633
At time: 214.96766924858093 and batch: 450, loss is 4.593291435241699 and perplexity is 98.81915230829294
At time: 215.36889147758484 and batch: 500, loss is 4.572292051315308 and perplexity is 96.76564761770165
At time: 215.76905632019043 and batch: 550, loss is 4.613888454437256 and perplexity is 100.87563832360017
At time: 216.17243671417236 and batch: 600, loss is 4.519835891723633 and perplexity is 91.82052823303223
At time: 216.56882548332214 and batch: 650, loss is 4.641441087722779 and perplexity is 103.69367164003671
At time: 216.9889109134674 and batch: 700, loss is 4.653899641036987 and perplexity is 104.99362573583363
At time: 217.38724637031555 and batch: 750, loss is 4.6072591781616214 and perplexity is 100.20911756378291
At time: 217.78818583488464 and batch: 800, loss is 4.547709655761719 and perplexity is 94.41591553991285
At time: 218.1833415031433 and batch: 850, loss is 4.496205101013183 and perplexity is 89.67617274098532
At time: 218.58729100227356 and batch: 900, loss is 4.458592834472657 and perplexity is 86.36589244243261
At time: 218.98207068443298 and batch: 950, loss is 4.5370926189422605 and perplexity is 93.41880085627264
At time: 219.37711191177368 and batch: 1000, loss is 4.597296810150146 and perplexity is 99.21575380003046
At time: 219.77914428710938 and batch: 1050, loss is 4.485628185272216 and perplexity is 88.73267386781512
At time: 220.16347527503967 and batch: 1100, loss is 4.625251836776734 and perplexity is 102.02846436716008
At time: 220.56226682662964 and batch: 1150, loss is 4.564333362579346 and perplexity is 95.99857643725986
At time: 220.95646500587463 and batch: 1200, loss is 4.5248171043396 and perplexity is 92.27904684794439
At time: 221.34850430488586 and batch: 1250, loss is 4.507062730789184 and perplexity is 90.65514848498067
At time: 221.74997854232788 and batch: 1300, loss is 4.584446125030517 and perplexity is 97.94892065963165
At time: 222.1442379951477 and batch: 1350, loss is 4.515373182296753 and perplexity is 91.41167287598935
At time: 222.55346155166626 and batch: 1400, loss is 4.404821443557739 and perplexity is 81.84452767071043
At time: 222.95537447929382 and batch: 1450, loss is 4.487993431091309 and perplexity is 88.94279685199366
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.958239433092949 and perplexity of 142.34297084071684
Finished 18 epochs...
Completing Train Step...
At time: 224.21011018753052 and batch: 50, loss is 4.649540557861328 and perplexity is 104.5369458642469
At time: 224.62178921699524 and batch: 100, loss is 4.652275943756104 and perplexity is 104.82328619856153
At time: 225.02572464942932 and batch: 150, loss is 4.550813407897949 and perplexity is 94.70941437767337
At time: 225.41422057151794 and batch: 200, loss is 4.603968830108642 and perplexity is 99.87993654596349
At time: 225.79983615875244 and batch: 250, loss is 4.628394479751587 and perplexity is 102.34960775914453
At time: 226.18787741661072 and batch: 300, loss is 4.625914106369018 and perplexity is 102.09605709649207
At time: 226.57291960716248 and batch: 350, loss is 4.648644971847534 and perplexity is 104.44336594829295
At time: 226.96024632453918 and batch: 400, loss is 4.544778661727905 and perplexity is 94.13958820946777
At time: 227.36623978614807 and batch: 450, loss is 4.590779209136963 and perplexity is 98.57120783091435
At time: 227.75340819358826 and batch: 500, loss is 4.569128141403199 and perplexity is 96.45997364350208
At time: 228.156347990036 and batch: 550, loss is 4.611800346374512 and perplexity is 100.66521885563184
At time: 228.55177450180054 and batch: 600, loss is 4.51743185043335 and perplexity is 91.60005301381443
At time: 228.9464249610901 and batch: 650, loss is 4.6396257686614994 and perplexity is 103.50560529323248
At time: 229.34110283851624 and batch: 700, loss is 4.652240018844605 and perplexity is 104.81952049892344
At time: 229.73297905921936 and batch: 750, loss is 4.605726528167724 and perplexity is 100.0556496966647
At time: 230.12729692459106 and batch: 800, loss is 4.546087474822998 and perplexity is 94.26288000063853
At time: 230.51686215400696 and batch: 850, loss is 4.49543872833252 and perplexity is 89.60747369998666
At time: 230.91310596466064 and batch: 900, loss is 4.458126878738403 and perplexity is 86.3256591338035
At time: 231.29803681373596 and batch: 950, loss is 4.535549154281616 and perplexity is 93.27472345630163
At time: 231.69808411598206 and batch: 1000, loss is 4.595912961959839 and perplexity is 99.07854921573814
At time: 232.08286023139954 and batch: 1050, loss is 4.4851284599304195 and perplexity is 88.68834297959465
At time: 232.46882891654968 and batch: 1100, loss is 4.625150785446167 and perplexity is 102.01815477598787
At time: 232.85922718048096 and batch: 1150, loss is 4.564417009353638 and perplexity is 96.00660674436541
At time: 233.2471911907196 and batch: 1200, loss is 4.525414657592774 and perplexity is 92.33420497090479
At time: 233.6455819606781 and batch: 1250, loss is 4.507825937271118 and perplexity is 90.72436349123606
At time: 234.03897619247437 and batch: 1300, loss is 4.583974866867066 and perplexity is 97.90277230591781
At time: 234.43546223640442 and batch: 1350, loss is 4.515507297515869 and perplexity is 91.42393339466959
At time: 234.83504700660706 and batch: 1400, loss is 4.405134553909302 and perplexity is 81.87015805190234
At time: 235.23122477531433 and batch: 1450, loss is 4.488650970458984 and perplexity is 89.00129947417575
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.957994770799947 and perplexity of 142.3081491430301
Finished 19 epochs...
Completing Train Step...
At time: 236.50151014328003 and batch: 50, loss is 4.647243146896362 and perplexity is 104.29705720550481
At time: 236.8930606842041 and batch: 100, loss is 4.650121994018555 and perplexity is 104.59774509806205
At time: 237.29731225967407 and batch: 150, loss is 4.547802085876465 and perplexity is 94.42464281714547
At time: 237.68571281433105 and batch: 200, loss is 4.601035795211792 and perplexity is 99.5874144051091
At time: 238.0739734172821 and batch: 250, loss is 4.625688228607178 and perplexity is 102.07299847193568
At time: 238.47518706321716 and batch: 300, loss is 4.623593883514404 and perplexity is 101.85944609272842
At time: 238.8761270046234 and batch: 350, loss is 4.646985177993774 and perplexity is 104.27015527819388
At time: 239.28130769729614 and batch: 400, loss is 4.544289588928223 and perplexity is 94.09355835439375
At time: 239.67687606811523 and batch: 450, loss is 4.588865718841553 and perplexity is 98.38277312281092
At time: 240.07407450675964 and batch: 500, loss is 4.566825590133667 and perplexity is 96.23812511555039
At time: 240.47725367546082 and batch: 550, loss is 4.610332393646241 and perplexity is 100.51755548091404
At time: 240.86165046691895 and batch: 600, loss is 4.5156418991088865 and perplexity is 91.4362400299722
At time: 241.2669095993042 and batch: 650, loss is 4.638115949630738 and perplexity is 103.34944847450255
At time: 241.6520836353302 and batch: 700, loss is 4.650958633422851 and perplexity is 104.68529231082893
At time: 242.0547947883606 and batch: 750, loss is 4.604518327713013 and perplexity is 99.93483541383699
At time: 242.45129871368408 and batch: 800, loss is 4.545042943954468 and perplexity is 94.16447091733136
At time: 242.8561806678772 and batch: 850, loss is 4.495246343612671 and perplexity is 89.59023624942671
At time: 243.25234293937683 and batch: 900, loss is 4.457683048248291 and perplexity is 86.28735367539488
At time: 243.6414155960083 and batch: 950, loss is 4.5341675758361815 and perplexity is 93.14594608737283
At time: 244.05348801612854 and batch: 1000, loss is 4.594784002304078 and perplexity is 98.96675664744566
At time: 244.45054507255554 and batch: 1050, loss is 4.484234542846679 and perplexity is 88.60909837900468
At time: 244.85960221290588 and batch: 1100, loss is 4.625005369186401 and perplexity is 102.00332075607209
At time: 245.25670385360718 and batch: 1150, loss is 4.564234046936035 and perplexity is 95.98904275031408
At time: 245.65328001976013 and batch: 1200, loss is 4.525747671127319 and perplexity is 92.36495863126996
At time: 246.04960560798645 and batch: 1250, loss is 4.508312110900879 and perplexity is 90.76848200810308
At time: 246.4535689353943 and batch: 1300, loss is 4.583278245925904 and perplexity is 97.83459493418121
At time: 246.85817861557007 and batch: 1350, loss is 4.5153692436218265 and perplexity is 91.41131283583444
At time: 247.24344277381897 and batch: 1400, loss is 4.405212392807007 and perplexity is 81.87653098278778
At time: 247.6350338459015 and batch: 1450, loss is 4.488720989227295 and perplexity is 89.00753145371819
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.957945212339744 and perplexity of 142.30109674503865
Finished 20 epochs...
Completing Train Step...
At time: 248.89785861968994 and batch: 50, loss is 4.6454027652740475 and perplexity is 104.1052873371601
At time: 249.29092073440552 and batch: 100, loss is 4.648146257400513 and perplexity is 104.39129151901345
At time: 249.69757986068726 and batch: 150, loss is 4.545240831375122 and perplexity is 94.18310672543365
At time: 250.0984606742859 and batch: 200, loss is 4.598471164703369 and perplexity is 99.33233671369634
At time: 250.50224256515503 and batch: 250, loss is 4.623589677810669 and perplexity is 101.85901770297633
At time: 250.89572072029114 and batch: 300, loss is 4.62163743019104 and perplexity is 101.66035765802349
At time: 251.2894811630249 and batch: 350, loss is 4.645658226013183 and perplexity is 104.13188554806587
At time: 251.68193197250366 and batch: 400, loss is 4.543768482208252 and perplexity is 94.04453834226747
At time: 252.06582927703857 and batch: 450, loss is 4.58749752998352 and perplexity is 98.24825895018161
At time: 252.45872616767883 and batch: 500, loss is 4.564803428649903 and perplexity is 96.04371271855086
At time: 252.86076068878174 and batch: 550, loss is 4.60908145904541 and perplexity is 100.3918932068022
At time: 253.26477789878845 and batch: 600, loss is 4.514085140228271 and perplexity is 91.29400659160483
At time: 253.66156601905823 and batch: 650, loss is 4.6366002655029295 and perplexity is 103.19292200813803
At time: 254.06678462028503 and batch: 700, loss is 4.64980110168457 and perplexity is 104.56418586824574
At time: 254.47059416770935 and batch: 750, loss is 4.603380079269409 and perplexity is 99.82114945667169
At time: 254.86000633239746 and batch: 800, loss is 4.544111423492431 and perplexity is 94.07679562787796
At time: 255.26206827163696 and batch: 850, loss is 4.4946910095214845 and perplexity is 89.54049754907624
At time: 255.65540027618408 and batch: 900, loss is 4.457134590148926 and perplexity is 86.24004165291579
At time: 256.05240774154663 and batch: 950, loss is 4.533039531707764 and perplexity is 93.04093259086778
At time: 256.45511269569397 and batch: 1000, loss is 4.593680038452148 and perplexity is 98.85756121056178
At time: 256.85442900657654 and batch: 1050, loss is 4.483509473800659 and perplexity is 88.54487395096035
At time: 257.26436948776245 and batch: 1100, loss is 4.624633960723877 and perplexity is 101.96544289405234
At time: 257.65540599823 and batch: 1150, loss is 4.564088954925537 and perplexity is 95.9751165174326
At time: 258.0467071533203 and batch: 1200, loss is 4.525715885162353 and perplexity is 92.36202276859068
At time: 258.43365144729614 and batch: 1250, loss is 4.508277807235718 and perplexity is 90.76536836989402
At time: 258.8291347026825 and batch: 1300, loss is 4.582542819976807 and perplexity is 97.76267128484791
At time: 259.2165529727936 and batch: 1350, loss is 4.514984531402588 and perplexity is 91.37615255053919
At time: 259.6080393791199 and batch: 1400, loss is 4.404931507110596 and perplexity is 81.85353626595764
At time: 260.0043110847473 and batch: 1450, loss is 4.488536787033081 and perplexity is 88.9911375810629
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.9579770340878735 and perplexity of 142.30562508674737
Annealing...
Finished 21 epochs...
Completing Train Step...
At time: 261.2696363925934 and batch: 50, loss is 4.643763732910156 and perplexity is 103.9347951612273
At time: 261.67212677001953 and batch: 100, loss is 4.646265287399292 and perplexity is 104.19511918625284
At time: 262.0602684020996 and batch: 150, loss is 4.542067680358887 and perplexity is 93.8847231630336
At time: 262.45351457595825 and batch: 200, loss is 4.59540699005127 and perplexity is 99.0284309333839
At time: 262.84789276123047 and batch: 250, loss is 4.6206410694122315 and perplexity is 101.55911770902598
At time: 263.2352707386017 and batch: 300, loss is 4.619317035675049 and perplexity is 101.4247389914698
At time: 263.63855361938477 and batch: 350, loss is 4.641229343414307 and perplexity is 103.671717419665
At time: 264.0294613838196 and batch: 400, loss is 4.538591938018799 and perplexity is 93.55897049975606
At time: 264.41788816452026 and batch: 450, loss is 4.583266048431397 and perplexity is 97.83340160452475
At time: 264.8028635978699 and batch: 500, loss is 4.5573656940460205 and perplexity is 95.33201506303574
At time: 265.2068302631378 and batch: 550, loss is 4.602986459732056 and perplexity is 99.78186563395171
At time: 265.602881193161 and batch: 600, loss is 4.508597288131714 and perplexity is 90.79437080372134
At time: 265.9937973022461 and batch: 650, loss is 4.631907148361206 and perplexity is 102.70976019127652
At time: 266.38524889945984 and batch: 700, loss is 4.64260269165039 and perplexity is 103.81419260154155
At time: 266.77162432670593 and batch: 750, loss is 4.596792297363281 and perplexity is 99.16571080830597
At time: 267.18567943573 and batch: 800, loss is 4.536281490325928 and perplexity is 93.34305691678593
At time: 267.58034443855286 and batch: 850, loss is 4.487127103805542 and perplexity is 88.86577664737788
At time: 267.992488861084 and batch: 900, loss is 4.449731922149658 and perplexity is 85.60399239166776
At time: 268.39541006088257 and batch: 950, loss is 4.52189980506897 and perplexity is 92.01023354695157
At time: 268.7901222705841 and batch: 1000, loss is 4.582973108291626 and perplexity is 97.80474647150875
At time: 269.17930579185486 and batch: 1050, loss is 4.473200702667237 and perplexity is 87.63677385044002
At time: 269.57325863838196 and batch: 1100, loss is 4.615745601654052 and perplexity is 101.06315330212077
At time: 269.96248507499695 and batch: 1150, loss is 4.5516728496551515 and perplexity is 94.79084659129971
At time: 270.35810708999634 and batch: 1200, loss is 4.516618871688843 and perplexity is 91.52561438033183
At time: 270.7481472492218 and batch: 1250, loss is 4.496776189804077 and perplexity is 89.72740042443354
At time: 271.14773178100586 and batch: 1300, loss is 4.567365942001342 and perplexity is 96.29014161853978
At time: 271.54478907585144 and batch: 1350, loss is 4.503187341690063 and perplexity is 90.30450439076269
At time: 271.9558687210083 and batch: 1400, loss is 4.389926061630249 and perplexity is 80.634456779782
At time: 272.34831643104553 and batch: 1450, loss is 4.475007696151733 and perplexity is 87.795276092921
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.952485956697383 and perplexity of 141.52635535952362
Finished 22 epochs...
Completing Train Step...
At time: 273.6578230857849 and batch: 50, loss is 4.6387972736358645 and perplexity is 103.41988692764455
At time: 274.07011556625366 and batch: 100, loss is 4.6430550479888915 and perplexity is 103.86116423274781
At time: 274.460729598999 and batch: 150, loss is 4.539585733413697 and perplexity is 93.65199518988827
At time: 274.8483057022095 and batch: 200, loss is 4.5931907081604 and perplexity is 98.8091990447945
At time: 275.2483706474304 and batch: 250, loss is 4.617730588912964 and perplexity is 101.26396160880103
At time: 275.65249395370483 and batch: 300, loss is 4.61738299369812 and perplexity is 101.22876885708011
At time: 276.0485637187958 and batch: 350, loss is 4.639178438186645 and perplexity is 103.45931443609406
At time: 276.45279359817505 and batch: 400, loss is 4.5363904476165775 and perplexity is 93.35322787745862
At time: 276.8498330116272 and batch: 450, loss is 4.580462713241577 and perplexity is 97.55952584919692
At time: 277.24014544487 and batch: 500, loss is 4.555170679092408 and perplexity is 95.12298935561645
At time: 277.64395475387573 and batch: 550, loss is 4.601729211807251 and perplexity is 99.65649391862901
At time: 278.03006863594055 and batch: 600, loss is 4.50793119430542 and perplexity is 90.73391337126328
At time: 278.4273726940155 and batch: 650, loss is 4.6312540340423585 and perplexity is 102.64270087729302
At time: 278.81954312324524 and batch: 700, loss is 4.641528549194336 and perplexity is 103.70274123776396
At time: 279.2120361328125 and batch: 750, loss is 4.595447111129761 and perplexity is 99.03240414053833
At time: 279.62219166755676 and batch: 800, loss is 4.535254535675048 and perplexity is 93.24724703498015
At time: 280.0224230289459 and batch: 850, loss is 4.4865082836151124 and perplexity is 88.81080172210149
At time: 280.42412400245667 and batch: 900, loss is 4.4491628074645995 and perplexity is 85.5552877630723
At time: 280.81868171691895 and batch: 950, loss is 4.52133544921875 and perplexity is 91.95832168312906
At time: 281.225200176239 and batch: 1000, loss is 4.5827727890014645 and perplexity is 97.78515625633563
At time: 281.6221673488617 and batch: 1050, loss is 4.473424682617187 and perplexity is 87.6564049290628
At time: 282.01924681663513 and batch: 1100, loss is 4.616043663024902 and perplexity is 101.09328081383707
At time: 282.43149185180664 and batch: 1150, loss is 4.552068462371826 and perplexity is 94.82835447444418
At time: 282.82903718948364 and batch: 1200, loss is 4.517574596405029 and perplexity is 91.6131294856724
At time: 283.23063921928406 and batch: 1250, loss is 4.497008867263794 and perplexity is 89.74828039708663
At time: 283.6345865726471 and batch: 1300, loss is 4.568104820251465 and perplexity is 96.36131460072919
At time: 284.0382537841797 and batch: 1350, loss is 4.504119672775269 and perplexity is 90.38873734774079
At time: 284.43600034713745 and batch: 1400, loss is 4.39058708190918 and perplexity is 80.68777541130086
At time: 284.8335955142975 and batch: 1450, loss is 4.4761842918395995 and perplexity is 87.8986364309268
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.952205820980235 and perplexity of 141.48671432516372
Finished 23 epochs...
Completing Train Step...
At time: 286.1294810771942 and batch: 50, loss is 4.636680154800415 and perplexity is 103.20116634749562
At time: 286.51508474349976 and batch: 100, loss is 4.64154052734375 and perplexity is 103.70398341213257
At time: 286.9078891277313 and batch: 150, loss is 4.538304576873779 and perplexity is 93.53208914937917
At time: 287.29249596595764 and batch: 200, loss is 4.592135944366455 and perplexity is 98.7050336237479
At time: 287.6919665336609 and batch: 250, loss is 4.616297559738159 and perplexity is 101.1189513242593
At time: 288.0857515335083 and batch: 300, loss is 4.616332101821899 and perplexity is 101.12244424386965
At time: 288.4765067100525 and batch: 350, loss is 4.637963485717774 and perplexity is 103.33369261431604
At time: 288.89266204833984 and batch: 400, loss is 4.535335264205933 and perplexity is 93.25477505210107
At time: 289.2818377017975 and batch: 450, loss is 4.578867435455322 and perplexity is 97.40401537895156
At time: 289.6878604888916 and batch: 500, loss is 4.553863124847412 and perplexity is 94.9986921674551
At time: 290.0863139629364 and batch: 550, loss is 4.601075229644775 and perplexity is 99.59134165576235
At time: 290.48675084114075 and batch: 600, loss is 4.5076828289031985 and perplexity is 90.7113810046197
At time: 290.88230562210083 and batch: 650, loss is 4.6309898853302 and perplexity is 102.61559152065225
At time: 291.27117896080017 and batch: 700, loss is 4.6409940433502195 and perplexity is 103.64732632763742
At time: 291.6769528388977 and batch: 750, loss is 4.594741840362548 and perplexity is 98.96258410480043
At time: 292.0694012641907 and batch: 800, loss is 4.534602394104004 and perplexity is 93.18645645299048
At time: 292.4631986618042 and batch: 850, loss is 4.486149182319641 and perplexity is 88.77891537370841
At time: 292.8587064743042 and batch: 900, loss is 4.4487978458404545 and perplexity is 85.52406906345627
At time: 293.26880288124084 and batch: 950, loss is 4.5208984470367435 and perplexity is 91.91814447530302
At time: 293.65973687171936 and batch: 1000, loss is 4.5826068878173825 and perplexity is 97.76893492873299
At time: 294.047874212265 and batch: 1050, loss is 4.473541469573974 and perplexity is 87.66664265164196
At time: 294.4388618469238 and batch: 1100, loss is 4.616308994293213 and perplexity is 101.12010758108585
At time: 294.841849565506 and batch: 1150, loss is 4.552277193069458 and perplexity is 94.84815012893743
At time: 295.2374062538147 and batch: 1200, loss is 4.518188266754151 and perplexity is 91.66936700071086
At time: 295.63344073295593 and batch: 1250, loss is 4.4970201396942135 and perplexity is 89.74929208403474
At time: 296.02615189552307 and batch: 1300, loss is 4.56852198600769 and perplexity is 96.4015216273197
At time: 296.4267542362213 and batch: 1350, loss is 4.504659681320191 and perplexity is 90.43756121974086
At time: 296.82279348373413 and batch: 1400, loss is 4.390839290618897 and perplexity is 80.70812813748678
At time: 297.2223958969116 and batch: 1450, loss is 4.4766914176940915 and perplexity is 87.94322340668406
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.952087924011752 and perplexity of 141.47003445373662
Finished 24 epochs...
Completing Train Step...
At time: 298.51866149902344 and batch: 50, loss is 4.635060024261475 and perplexity is 103.03410235552222
At time: 298.9219560623169 and batch: 100, loss is 4.640379505157471 and perplexity is 103.58365065460326
At time: 299.31261825561523 and batch: 150, loss is 4.537352256774902 and perplexity is 93.44305906029243
At time: 299.70139360427856 and batch: 200, loss is 4.591314878463745 and perplexity is 98.62402354807011
At time: 300.10938000679016 and batch: 250, loss is 4.615264720916748 and perplexity is 101.01456566181304
At time: 300.50214862823486 and batch: 300, loss is 4.615522317886352 and perplexity is 101.04059005957247
At time: 300.89093232154846 and batch: 350, loss is 4.637050504684448 and perplexity is 103.23939396584456
At time: 301.2798843383789 and batch: 400, loss is 4.534578304290772 and perplexity is 93.18421163569748
At time: 301.6704640388489 and batch: 450, loss is 4.577672204971313 and perplexity is 97.2876646773098
At time: 302.0594847202301 and batch: 500, loss is 4.5528560066223145 and perplexity is 94.90306541501815
At time: 302.4489760398865 and batch: 550, loss is 4.600570783615113 and perplexity is 99.54111586804002
At time: 302.8531413078308 and batch: 600, loss is 4.507489442825317 and perplexity is 90.69384038253875
At time: 303.2458026409149 and batch: 650, loss is 4.630828199386596 and perplexity is 102.59900136314258
At time: 303.6505959033966 and batch: 700, loss is 4.640564289093017 and perplexity is 103.60279301777565
At time: 304.0461013317108 and batch: 750, loss is 4.594201192855835 and perplexity is 98.90909469120824
At time: 304.45266556739807 and batch: 800, loss is 4.534095296859741 and perplexity is 93.13921383703307
At time: 304.84060502052307 and batch: 850, loss is 4.485903525352478 and perplexity is 88.7571088931763
At time: 305.2286834716797 and batch: 900, loss is 4.448545169830322 and perplexity is 85.50246191283432
At time: 305.6197211742401 and batch: 950, loss is 4.520523014068604 and perplexity is 91.88364185061343
At time: 306.006954908371 and batch: 1000, loss is 4.582438306808472 and perplexity is 97.75245433223941
At time: 306.39437103271484 and batch: 1050, loss is 4.47357759475708 and perplexity is 87.66980968236443
At time: 306.78294372558594 and batch: 1100, loss is 4.616475629806518 and perplexity is 101.13695918611702
At time: 307.16943407058716 and batch: 1150, loss is 4.552383642196656 and perplexity is 94.85824716913596
At time: 307.6084830760956 and batch: 1200, loss is 4.518630027770996 and perplexity is 91.70987189957461
At time: 308.00003814697266 and batch: 1250, loss is 4.4969469165802005 and perplexity is 89.742720601983
At time: 308.3958888053894 and batch: 1300, loss is 4.568746099472046 and perplexity is 96.42312892745373
At time: 308.7921760082245 and batch: 1350, loss is 4.505024490356445 and perplexity is 90.47055967799253
At time: 309.1887743473053 and batch: 1400, loss is 4.390925664901733 and perplexity is 80.71509954524456
At time: 309.5854082107544 and batch: 1450, loss is 4.476961145401001 and perplexity is 87.96694733002764
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.9520326272035255 and perplexity of 141.4622118286567
Finished 25 epochs...
Completing Train Step...
At time: 310.8824031352997 and batch: 50, loss is 4.633687915802002 and perplexity is 102.89282533792651
At time: 311.31244921684265 and batch: 100, loss is 4.639358491897583 and perplexity is 103.47794434673126
At time: 311.7070813179016 and batch: 150, loss is 4.53658085823059 and perplexity is 93.37100501532301
At time: 312.11011004447937 and batch: 200, loss is 4.590623197555542 and perplexity is 98.55583078042818
At time: 312.5003204345703 and batch: 250, loss is 4.614458360671997 and perplexity is 100.93314436378323
At time: 312.9182331562042 and batch: 300, loss is 4.614828262329102 and perplexity is 100.97048660719324
At time: 313.3200581073761 and batch: 350, loss is 4.636258878707886 and perplexity is 103.1576993198449
At time: 313.71102690696716 and batch: 400, loss is 4.5339711475372315 and perplexity is 93.12765138448631
At time: 314.102499961853 and batch: 450, loss is 4.576659421920777 and perplexity is 97.18918325807238
At time: 314.49095582962036 and batch: 500, loss is 4.551963291168213 and perplexity is 94.81838178669639
At time: 314.88653326034546 and batch: 550, loss is 4.600170087814331 and perplexity is 99.50123815085706
At time: 315.28290486335754 and batch: 600, loss is 4.507322597503662 and perplexity is 90.67870980183636
At time: 315.67572379112244 and batch: 650, loss is 4.630657014846801 and perplexity is 102.58143950351312
At time: 316.07321071624756 and batch: 700, loss is 4.640183391571045 and perplexity is 103.56333848518965
At time: 316.46339654922485 and batch: 750, loss is 4.593712320327759 and perplexity is 98.86075256956723
At time: 316.8542401790619 and batch: 800, loss is 4.533649015426636 and perplexity is 93.09765680895832
At time: 317.24056911468506 and batch: 850, loss is 4.485682353973389 and perplexity is 88.7374805316943
At time: 317.6686210632324 and batch: 900, loss is 4.448313217163086 and perplexity is 85.482631688664
At time: 318.0773196220398 and batch: 950, loss is 4.5200732231140135 and perplexity is 91.84232271281803
At time: 318.4766356945038 and batch: 1000, loss is 4.58226978302002 and perplexity is 97.73598210632478
At time: 318.88571095466614 and batch: 1050, loss is 4.473495874404907 and perplexity is 87.66264556737329
At time: 319.2901928424835 and batch: 1100, loss is 4.616582841873169 and perplexity is 101.14780286980258
At time: 319.6815855503082 and batch: 1150, loss is 4.552466602325439 and perplexity is 94.86611694797172
At time: 320.0672187805176 and batch: 1200, loss is 4.518950910568237 and perplexity is 91.73930474179818
At time: 320.4641170501709 and batch: 1250, loss is 4.496850633621216 and perplexity is 89.73408032325861
At time: 320.86640524864197 and batch: 1300, loss is 4.568808679580688 and perplexity is 96.42916328615112
At time: 321.26298117637634 and batch: 1350, loss is 4.505294914245606 and perplexity is 90.49502838690779
At time: 321.65836477279663 and batch: 1400, loss is 4.390928897857666 and perplexity is 80.71536049402636
At time: 322.04722833633423 and batch: 1450, loss is 4.477079753875732 and perplexity is 87.9773815742599
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.952024802183494 and perplexity of 141.4611048883463
Finished 26 epochs...
Completing Train Step...
At time: 323.3675105571747 and batch: 50, loss is 4.632451820373535 and perplexity is 102.76571856114127
At time: 323.7800130844116 and batch: 100, loss is 4.638442935943604 and perplexity is 103.3832478552623
At time: 324.1841399669647 and batch: 150, loss is 4.535923004150391 and perplexity is 93.30960071844945
At time: 324.5842626094818 and batch: 200, loss is 4.589997234344483 and perplexity is 98.49415776065882
At time: 324.9857084751129 and batch: 250, loss is 4.613758001327515 and perplexity is 100.86247964119791
At time: 325.3796229362488 and batch: 300, loss is 4.614218788146973 and perplexity is 100.9089664518267
At time: 325.77016496658325 and batch: 350, loss is 4.63553406715393 and perplexity is 103.08295651799376
At time: 326.16743898391724 and batch: 400, loss is 4.533333387374878 and perplexity is 93.06827721367262
At time: 326.57398557662964 and batch: 450, loss is 4.575740251541138 and perplexity is 97.09989088333998
At time: 326.9765064716339 and batch: 500, loss is 4.5510382556915285 and perplexity is 94.73071197479653
At time: 327.3794775009155 and batch: 550, loss is 4.599641799926758 and perplexity is 99.44868673430403
At time: 327.78311824798584 and batch: 600, loss is 4.50710883140564 and perplexity is 90.65932783954538
At time: 328.1887288093567 and batch: 650, loss is 4.630529479980469 and perplexity is 102.56835762755323
At time: 328.5806736946106 and batch: 700, loss is 4.639758615493775 and perplexity is 103.51935659840684
At time: 328.97871947288513 and batch: 750, loss is 4.593077116012573 and perplexity is 98.79797573310199
At time: 329.37188935279846 and batch: 800, loss is 4.533197021484375 and perplexity is 93.05558674046628
At time: 329.77827882766724 and batch: 850, loss is 4.485357050895691 and perplexity is 88.70861865085402
At time: 330.18551754951477 and batch: 900, loss is 4.447983598709106 and perplexity is 85.45445967902681
At time: 330.59377932548523 and batch: 950, loss is 4.519668693542481 and perplexity is 91.80517729107974
At time: 330.9924490451813 and batch: 1000, loss is 4.582020778656005 and perplexity is 97.71164844997814
At time: 331.38354897499084 and batch: 1050, loss is 4.473292007446289 and perplexity is 87.64477587201911
At time: 331.7830216884613 and batch: 1100, loss is 4.616654119491577 and perplexity is 101.15501270124514
At time: 332.17192673683167 and batch: 1150, loss is 4.552496871948242 and perplexity is 94.8689885530095
At time: 332.57611656188965 and batch: 1200, loss is 4.519179763793946 and perplexity is 91.76030198016383
At time: 332.9766228199005 and batch: 1250, loss is 4.496743984222412 and perplexity is 89.72451074784372
At time: 333.37574577331543 and batch: 1300, loss is 4.568733177185059 and perplexity is 96.42188292816013
At time: 333.7813060283661 and batch: 1350, loss is 4.505473289489746 and perplexity is 90.51117189944851
At time: 334.1784088611603 and batch: 1400, loss is 4.390948667526245 and perplexity is 80.71695622572601
At time: 334.5797219276428 and batch: 1450, loss is 4.4770275974273686 and perplexity is 87.97279310616078
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.951894906850962 and perplexity of 141.4427309444571
Finished 27 epochs...
Completing Train Step...
At time: 335.87952756881714 and batch: 50, loss is 4.631241502761841 and perplexity is 102.64141464087439
At time: 336.27375841140747 and batch: 100, loss is 4.6376652336120605 and perplexity is 103.30287771843493
At time: 336.6716248989105 and batch: 150, loss is 4.535321283340454 and perplexity is 93.25347127874979
At time: 337.07690691947937 and batch: 200, loss is 4.589435958862305 and perplexity is 98.4388909161833
At time: 337.4897162914276 and batch: 250, loss is 4.613067979812622 and perplexity is 100.79290636648877
At time: 337.87731647491455 and batch: 300, loss is 4.613661479949951 and perplexity is 100.85274472553976
At time: 338.2817325592041 and batch: 350, loss is 4.634901752471924 and perplexity is 103.01779625418962
At time: 338.67202162742615 and batch: 400, loss is 4.532795677185058 and perplexity is 93.01824690477477
At time: 339.0662076473236 and batch: 450, loss is 4.574903221130371 and perplexity is 97.01864932735825
At time: 339.45761251449585 and batch: 500, loss is 4.55029691696167 and perplexity is 94.66051045387083
At time: 339.8490881919861 and batch: 550, loss is 4.599288673400879 and perplexity is 99.41357496486775
At time: 340.2419934272766 and batch: 600, loss is 4.506965494155883 and perplexity is 90.64633391210725
At time: 340.6338334083557 and batch: 650, loss is 4.630388193130493 and perplexity is 102.55386709108205
At time: 341.0381863117218 and batch: 700, loss is 4.639393911361695 and perplexity is 103.48160954497672
At time: 341.44447350502014 and batch: 750, loss is 4.592645483016968 and perplexity is 98.75534046893192
At time: 341.8461654186249 and batch: 800, loss is 4.532792406082153 and perplexity is 93.01794263301475
At time: 342.25685834884644 and batch: 850, loss is 4.48516254901886 and perplexity is 88.69136633589352
At time: 342.6539032459259 and batch: 900, loss is 4.4477745628356935 and perplexity is 85.43659849828961
At time: 343.0558919906616 and batch: 950, loss is 4.519293098449707 and perplexity is 91.77070219174239
At time: 343.4460847377777 and batch: 1000, loss is 4.581804771423339 and perplexity is 97.69054430660309
At time: 343.8417766094208 and batch: 1050, loss is 4.473193759918213 and perplexity is 87.63616541242605
At time: 344.2396070957184 and batch: 1100, loss is 4.616714115142822 and perplexity is 101.16108174416514
At time: 344.63004875183105 and batch: 1150, loss is 4.552474565505982 and perplexity is 94.86687238699619
At time: 345.01776576042175 and batch: 1200, loss is 4.519446134567261 and perplexity is 91.78474749840316
At time: 345.4068989753723 and batch: 1250, loss is 4.496620817184448 and perplexity is 89.71346032615995
At time: 345.8048746585846 and batch: 1300, loss is 4.568721628189087 and perplexity is 96.4207693586529
At time: 346.1952269077301 and batch: 1350, loss is 4.50558445930481 and perplexity is 90.52123456901197
At time: 346.5936758518219 and batch: 1400, loss is 4.390674381256104 and perplexity is 80.69481970887583
At time: 346.9821660518646 and batch: 1450, loss is 4.477075681686402 and perplexity is 87.97702331443477
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.9518782134748935 and perplexity of 141.4403698074651
Finished 28 epochs...
Completing Train Step...
At time: 348.28743529319763 and batch: 50, loss is 4.630253210067749 and perplexity is 102.54002499025144
At time: 348.6919527053833 and batch: 100, loss is 4.636874904632569 and perplexity is 103.22126671452784
At time: 349.089968919754 and batch: 150, loss is 4.534791898727417 and perplexity is 93.20411739068963
At time: 349.49011850357056 and batch: 200, loss is 4.588951940536499 and perplexity is 98.39125621797126
At time: 349.8880298137665 and batch: 250, loss is 4.61247296333313 and perplexity is 100.7329507652391
At time: 350.2850167751312 and batch: 300, loss is 4.613148975372314 and perplexity is 100.80107047497671
At time: 350.6842210292816 and batch: 350, loss is 4.634243211746216 and perplexity is 102.9499771731479
At time: 351.09032249450684 and batch: 400, loss is 4.53232931137085 and perplexity is 92.97487648834664
At time: 351.49305415153503 and batch: 450, loss is 4.574112091064453 and perplexity is 96.94192531026071
At time: 351.88043689727783 and batch: 500, loss is 4.5495835876464845 and perplexity is 94.59301041451434
At time: 352.29012989997864 and batch: 550, loss is 4.598851957321167 and perplexity is 99.37016893688403
At time: 352.6844530105591 and batch: 600, loss is 4.506750020980835 and perplexity is 90.62680416287681
At time: 353.08502197265625 and batch: 650, loss is 4.630236892700196 and perplexity is 102.53835182062566
At time: 353.4930930137634 and batch: 700, loss is 4.639041652679444 and perplexity is 103.44516366912615
At time: 353.8828601837158 and batch: 750, loss is 4.592187614440918 and perplexity is 98.71013385194851
At time: 354.28188157081604 and batch: 800, loss is 4.532360382080078 and perplexity is 92.9777653285785
At time: 354.6710205078125 and batch: 850, loss is 4.484803323745727 and perplexity is 88.65951187740288
At time: 355.06370973587036 and batch: 900, loss is 4.447495355606079 and perplexity is 85.41274731218193
At time: 355.4513716697693 and batch: 950, loss is 4.518880214691162 and perplexity is 91.73281938043405
At time: 355.86380338668823 and batch: 1000, loss is 4.581614208221436 and perplexity is 97.67192985735517
At time: 356.264372587204 and batch: 1050, loss is 4.473056001663208 and perplexity is 87.62409363871583
At time: 356.6641414165497 and batch: 1100, loss is 4.616718254089355 and perplexity is 101.1615004453402
At time: 357.07418608665466 and batch: 1150, loss is 4.552399177551269 and perplexity is 94.85972083709069
At time: 357.47801399230957 and batch: 1200, loss is 4.519611320495605 and perplexity is 91.79991029943277
At time: 357.8738522529602 and batch: 1250, loss is 4.496472368240356 and perplexity is 89.70014344616654
At time: 358.27659702301025 and batch: 1300, loss is 4.5686940574646 and perplexity is 96.41811100483267
At time: 358.6837522983551 and batch: 1350, loss is 4.50553858757019 and perplexity is 90.51708229819903
At time: 359.0889403820038 and batch: 1400, loss is 4.390626859664917 and perplexity is 80.69098505375793
At time: 359.4839942455292 and batch: 1450, loss is 4.477074785232544 and perplexity is 87.97694444712818
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.951895950186966 and perplexity of 141.44287851682785
Annealing...
Finished 29 epochs...
Completing Train Step...
At time: 360.8079924583435 and batch: 50, loss is 4.629212503433227 and perplexity is 102.43336641570974
At time: 361.214120388031 and batch: 100, loss is 4.636264610290527 and perplexity is 103.15829057841806
At time: 361.6248641014099 and batch: 150, loss is 4.534146394729614 and perplexity is 93.14397317405675
At time: 362.0253026485443 and batch: 200, loss is 4.588354368209838 and perplexity is 98.33247788997024
At time: 362.4372572898865 and batch: 250, loss is 4.612352075576783 and perplexity is 100.72077412084927
At time: 362.8441119194031 and batch: 300, loss is 4.612474842071533 and perplexity is 100.73314001627993
At time: 363.24374055862427 and batch: 350, loss is 4.632605485916137 and perplexity is 102.78151132441559
At time: 363.6429660320282 and batch: 400, loss is 4.530115461349487 and perplexity is 92.76927172907172
At time: 364.032518863678 and batch: 450, loss is 4.5724289894104 and perplexity is 96.77889942847497
At time: 364.42439818382263 and batch: 500, loss is 4.546770563125611 and perplexity is 94.32729186832964
At time: 364.8139269351959 and batch: 550, loss is 4.596681175231933 and perplexity is 99.15469191539708
At time: 365.2120966911316 and batch: 600, loss is 4.504669046401977 and perplexity is 90.43840817886417
At time: 365.61515522003174 and batch: 650, loss is 4.628641500473022 and perplexity is 102.3748933559964
At time: 366.02321696281433 and batch: 700, loss is 4.636239881515503 and perplexity is 103.15573963179949
At time: 366.4251124858856 and batch: 750, loss is 4.589795303344727 and perplexity is 98.47427074488215
At time: 366.83241605758667 and batch: 800, loss is 4.529088687896729 and perplexity is 92.67406758853484
At time: 367.23374366760254 and batch: 850, loss is 4.482059688568115 and perplexity is 88.41659591056182
At time: 367.6321048736572 and batch: 900, loss is 4.444619636535645 and perplexity is 85.16747707904871
At time: 368.04775762557983 and batch: 950, loss is 4.514414291381836 and perplexity is 91.32406106514901
At time: 368.4455282688141 and batch: 1000, loss is 4.5786966037750245 and perplexity is 97.38737710854893
At time: 368.85621881484985 and batch: 1050, loss is 4.468963375091553 and perplexity is 87.26621377861363
At time: 369.2485611438751 and batch: 1100, loss is 4.614070014953613 and perplexity is 100.89395501932613
At time: 369.6415946483612 and batch: 1150, loss is 4.5481799030303955 and perplexity is 94.46032480716505
At time: 370.0535900592804 and batch: 1200, loss is 4.516143026351929 and perplexity is 91.4820727038942
At time: 370.45991802215576 and batch: 1250, loss is 4.492488412857056 and perplexity is 89.34349298828378
At time: 370.87690138816833 and batch: 1300, loss is 4.563679943084717 and perplexity is 95.93586958513002
At time: 371.2782015800476 and batch: 1350, loss is 4.501471633911133 and perplexity is 90.14970108669743
At time: 371.67663168907166 and batch: 1400, loss is 4.385123081207276 and perplexity is 80.24809963807246
At time: 372.0755093097687 and batch: 1450, loss is 4.471802530288696 and perplexity is 87.51432815394055
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.95075193225828 and perplexity of 141.28115785122807
Finished 30 epochs...
Completing Train Step...
At time: 373.3532428741455 and batch: 50, loss is 4.6283488273620605 and perplexity is 102.3449353616371
At time: 373.7728943824768 and batch: 100, loss is 4.635599527359009 and perplexity is 103.08970457032959
At time: 374.1696593761444 and batch: 150, loss is 4.533496789932251 and perplexity is 93.0834860507272
At time: 374.5785276889801 and batch: 200, loss is 4.588119878768921 and perplexity is 98.30942266541474
At time: 374.9721748828888 and batch: 250, loss is 4.612020254135132 and perplexity is 100.68735835271708
At time: 375.3622477054596 and batch: 300, loss is 4.612045612335205 and perplexity is 100.68991163526822
At time: 375.76000356674194 and batch: 350, loss is 4.632165327072143 and perplexity is 102.73628108818156
At time: 376.1570956707001 and batch: 400, loss is 4.52962142944336 and perplexity is 92.72345206804853
At time: 376.55444955825806 and batch: 450, loss is 4.5717895984649655 and perplexity is 96.7170396548683
At time: 376.94247794151306 and batch: 500, loss is 4.546198577880859 and perplexity is 94.27335347665624
At time: 377.34172439575195 and batch: 550, loss is 4.596238994598389 and perplexity is 99.11085732302519
At time: 377.7319347858429 and batch: 600, loss is 4.504310998916626 and perplexity is 90.40603273055638
At time: 378.1214089393616 and batch: 650, loss is 4.628443622589112 and perplexity is 102.35463763287947
At time: 378.520959854126 and batch: 700, loss is 4.635789566040039 and perplexity is 103.1092974634587
At time: 378.9402415752411 and batch: 750, loss is 4.5894483375549315 and perplexity is 98.44010946849846
At time: 379.34150409698486 and batch: 800, loss is 4.528870916366577 and perplexity is 92.65388801237901
At time: 379.7406642436981 and batch: 850, loss is 4.481830310821533 and perplexity is 88.39631743683566
At time: 380.14768528938293 and batch: 900, loss is 4.4444731426239015 and perplexity is 85.15500147600034
At time: 380.54431438446045 and batch: 950, loss is 4.514271640777588 and perplexity is 91.31103456179704
At time: 380.9452922344208 and batch: 1000, loss is 4.578676328659058 and perplexity is 97.38540258820126
At time: 381.3512020111084 and batch: 1050, loss is 4.4691693973541256 and perplexity is 87.28419441356439
At time: 381.7486643791199 and batch: 1100, loss is 4.614155206680298 and perplexity is 100.90255071570218
At time: 382.1458692550659 and batch: 1150, loss is 4.5480697727203365 and perplexity is 94.4499224351245
At time: 382.5497622489929 and batch: 1200, loss is 4.516236238479614 and perplexity is 91.49060033996933
At time: 382.9533808231354 and batch: 1250, loss is 4.492751502990723 and perplexity is 89.36700147208583
At time: 383.34414291381836 and batch: 1300, loss is 4.563699312210083 and perplexity is 95.93772779701109
At time: 383.73433780670166 and batch: 1350, loss is 4.501733713150024 and perplexity is 90.17333054800487
At time: 384.146258354187 and batch: 1400, loss is 4.385401868820191 and perplexity is 80.27047493304414
At time: 384.54291009902954 and batch: 1450, loss is 4.47205376625061 and perplexity is 87.5363176625176
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.950650728665865 and perplexity of 141.2668604140012
Finished 31 epochs...
Completing Train Step...
At time: 385.8514258861542 and batch: 50, loss is 4.627830877304077 and perplexity is 102.29193952221603
At time: 386.24947476387024 and batch: 100, loss is 4.635265169143676 and perplexity is 103.05524144252631
At time: 386.64001417160034 and batch: 150, loss is 4.533165454864502 and perplexity is 93.05264933649481
At time: 387.0467209815979 and batch: 200, loss is 4.587982063293457 and perplexity is 98.29587503914527
At time: 387.44940161705017 and batch: 250, loss is 4.611775455474853 and perplexity is 100.66271323895383
At time: 387.8450040817261 and batch: 300, loss is 4.611728267669678 and perplexity is 100.6579632985236
At time: 388.23425483703613 and batch: 350, loss is 4.631897230148315 and perplexity is 102.70874149906078
At time: 388.6247236728668 and batch: 400, loss is 4.529321994781494 and perplexity is 92.69569160896079
At time: 389.0261764526367 and batch: 450, loss is 4.5713835716247555 and perplexity is 96.67777791206284
At time: 389.4141879081726 and batch: 500, loss is 4.545822591781616 and perplexity is 94.23791466888702
At time: 389.8079752922058 and batch: 550, loss is 4.595979776382446 and perplexity is 99.08516931295325
At time: 390.1968994140625 and batch: 600, loss is 4.504061002731323 and perplexity is 90.38343439211222
At time: 390.59321641921997 and batch: 650, loss is 4.628342027664185 and perplexity is 102.34423944936351
At time: 390.9936857223511 and batch: 700, loss is 4.635534648895264 and perplexity is 103.08301648562777
At time: 391.3947775363922 and batch: 750, loss is 4.589250335693359 and perplexity is 98.42062007310227
At time: 391.7913818359375 and batch: 800, loss is 4.528681621551514 and perplexity is 92.63635077168959
At time: 392.1807713508606 and batch: 850, loss is 4.481645674705505 and perplexity is 88.37999779075732
At time: 392.5815291404724 and batch: 900, loss is 4.444368896484375 and perplexity is 85.14612485851964
At time: 392.9703040122986 and batch: 950, loss is 4.514138174057007 and perplexity is 91.29884839070344
At time: 393.36913299560547 and batch: 1000, loss is 4.578680505752564 and perplexity is 97.38580937698356
At time: 393.76111602783203 and batch: 1050, loss is 4.469285202026367 and perplexity is 87.29430291638498
At time: 394.16507506370544 and batch: 1100, loss is 4.61422869682312 and perplexity is 100.90996633104935
At time: 394.5536344051361 and batch: 1150, loss is 4.547961111068726 and perplexity is 94.43965990813986
At time: 394.9418752193451 and batch: 1200, loss is 4.516335916519165 and perplexity is 91.4997203981758
At time: 395.337867975235 and batch: 1250, loss is 4.492928438186645 and perplexity is 89.3828150389473
At time: 395.7289025783539 and batch: 1300, loss is 4.56369794845581 and perplexity is 95.93759696161408
At time: 396.12241554260254 and batch: 1350, loss is 4.5019190311431885 and perplexity is 90.19004283715509
At time: 396.5214343070984 and batch: 1400, loss is 4.385579795837402 and perplexity is 80.28475848989677
At time: 396.910528421402 and batch: 1450, loss is 4.4721754455566405 and perplexity is 87.54696966895445
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.950612125233707 and perplexity of 141.26140713359746
Finished 32 epochs...
Completing Train Step...
At time: 398.2201533317566 and batch: 50, loss is 4.627401142120362 and perplexity is 102.24799052068532
At time: 398.609756231308 and batch: 100, loss is 4.635001268386841 and perplexity is 103.02804867456759
At time: 399.0192985534668 and batch: 150, loss is 4.532876796722412 and perplexity is 93.02579280798513
At time: 399.410142660141 and batch: 200, loss is 4.58789532661438 and perplexity is 98.287349551119
At time: 399.8026452064514 and batch: 250, loss is 4.611595401763916 and perplexity is 100.64459017549352
At time: 400.2038278579712 and batch: 300, loss is 4.61146203994751 and perplexity is 100.63116892509731
At time: 400.60075092315674 and batch: 350, loss is 4.631670074462891 and perplexity is 102.68541327415626
At time: 401.00991559028625 and batch: 400, loss is 4.529079780578614 and perplexity is 92.6732421148102
At time: 401.4109935760498 and batch: 450, loss is 4.571057596206665 and perplexity is 96.64626846891886
At time: 401.81914019584656 and batch: 500, loss is 4.545516633987427 and perplexity is 94.20908625474985
At time: 402.21601963043213 and batch: 550, loss is 4.595762786865234 and perplexity is 99.06367120241782
At time: 402.61874198913574 and batch: 600, loss is 4.503852195739746 and perplexity is 90.36456366932646
At time: 403.0084934234619 and batch: 650, loss is 4.628263397216797 and perplexity is 102.33619239240403
At time: 403.3981273174286 and batch: 700, loss is 4.635338068008423 and perplexity is 103.06275432647067
At time: 403.7879960536957 and batch: 750, loss is 4.5890758609771725 and perplexity is 98.40344966129302
At time: 404.1758861541748 and batch: 800, loss is 4.5285028457641605 and perplexity is 92.61979111541973
At time: 404.5757396221161 and batch: 850, loss is 4.48150586605072 and perplexity is 88.3676423658741
At time: 404.97176790237427 and batch: 900, loss is 4.44429801940918 and perplexity is 85.14009016408879
At time: 405.3657879829407 and batch: 950, loss is 4.513997049331665 and perplexity is 91.28596477491999
At time: 405.7652280330658 and batch: 1000, loss is 4.578678159713745 and perplexity is 97.3855809063624
At time: 406.15887784957886 and batch: 1050, loss is 4.469375877380371 and perplexity is 87.30221871708305
At time: 406.55303931236267 and batch: 1100, loss is 4.614307088851929 and perplexity is 100.91787717810668
At time: 406.9419345855713 and batch: 1150, loss is 4.547861185073852 and perplexity is 94.43022340265199
At time: 407.34201765060425 and batch: 1200, loss is 4.5164049243927 and perplexity is 91.5060348171793
At time: 407.7378270626068 and batch: 1250, loss is 4.49305136680603 and perplexity is 89.39380342037623
At time: 408.1492567062378 and batch: 1300, loss is 4.563686847686768 and perplexity is 95.93653198641873
At time: 408.5539598464966 and batch: 1350, loss is 4.502064266204834 and perplexity is 90.20314254483175
At time: 408.9420118331909 and batch: 1400, loss is 4.385691184997558 and perplexity is 80.29370183980517
At time: 409.34622406959534 and batch: 1450, loss is 4.472224988937378 and perplexity is 87.551307149251
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.950594910189637 and perplexity of 141.25897533318008
Finished 33 epochs...
Completing Train Step...
At time: 410.6491184234619 and batch: 50, loss is 4.627026624679566 and perplexity is 102.20970403487486
At time: 411.0709273815155 and batch: 100, loss is 4.634774675369263 and perplexity is 103.00470588287995
At time: 411.45925116539 and batch: 150, loss is 4.532630596160889 and perplexity is 93.00289262469428
At time: 411.8477852344513 and batch: 200, loss is 4.587834062576294 and perplexity is 98.28132825563911
At time: 412.24371910095215 and batch: 250, loss is 4.611451177597046 and perplexity is 100.63007584000964
At time: 412.6372740268707 and batch: 300, loss is 4.611228618621826 and perplexity is 100.607682205499
At time: 413.0365400314331 and batch: 350, loss is 4.631464757919312 and perplexity is 102.66433242422448
At time: 413.42496156692505 and batch: 400, loss is 4.528863191604614 and perplexity is 92.65317228591363
At time: 413.8270950317383 and batch: 450, loss is 4.570764379501343 and perplexity is 96.61793432272222
At time: 414.21662735939026 and batch: 500, loss is 4.545234041213989 and perplexity is 94.1824672091342
At time: 414.6057040691376 and batch: 550, loss is 4.5955711936950685 and perplexity is 99.0446930976996
At time: 415.00087428092957 and batch: 600, loss is 4.503673715591431 and perplexity is 90.34843682780361
At time: 415.391179561615 and batch: 650, loss is 4.628186740875244 and perplexity is 102.3283479749528
At time: 415.78798723220825 and batch: 700, loss is 4.635168514251709 and perplexity is 103.04528113066219
At time: 416.17903447151184 and batch: 750, loss is 4.588924293518066 and perplexity is 98.38853603069968
At time: 416.57102632522583 and batch: 800, loss is 4.528319931030273 and perplexity is 92.6028511403079
At time: 416.9621822834015 and batch: 850, loss is 4.481379342079163 and perplexity is 88.3564624480835
At time: 417.35350608825684 and batch: 900, loss is 4.444231338500977 and perplexity is 85.13441313482899
At time: 417.7611439228058 and batch: 950, loss is 4.513849601745606 and perplexity is 91.27250587203862
At time: 418.1551811695099 and batch: 1000, loss is 4.578666000366211 and perplexity is 97.38439676843853
At time: 418.5606064796448 and batch: 1050, loss is 4.469446220397949 and perplexity is 87.30836003458572
At time: 418.9596893787384 and batch: 1100, loss is 4.614376363754272 and perplexity is 100.92486849635155
At time: 419.36808943748474 and batch: 1150, loss is 4.547762794494629 and perplexity is 94.42093281533582
At time: 419.7599792480469 and batch: 1200, loss is 4.516463556289673 and perplexity is 91.5114001468733
At time: 420.3030686378479 and batch: 1250, loss is 4.493133697509766 and perplexity is 89.40116357810074
At time: 420.7091021537781 and batch: 1300, loss is 4.563666019439697 and perplexity is 95.93453381743672
At time: 421.1099622249603 and batch: 1350, loss is 4.502180023193359 and perplexity is 90.21358479333821
At time: 421.5172345638275 and batch: 1400, loss is 4.385763912200928 and perplexity is 80.29954158853991
At time: 421.9070129394531 and batch: 1450, loss is 4.4722514247894285 and perplexity is 87.5536216732467
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.9505917801816235 and perplexity of 141.2585331921472
Finished 34 epochs...
Completing Train Step...
At time: 423.2181327342987 and batch: 50, loss is 4.626692695617676 and perplexity is 102.17557894228761
At time: 423.6106266975403 and batch: 100, loss is 4.634574089050293 and perplexity is 102.98404662014232
At time: 424.012491941452 and batch: 150, loss is 4.532416143417358 and perplexity is 92.98295003766235
At time: 424.404239654541 and batch: 200, loss is 4.587784738540649 and perplexity is 98.27648074345139
At time: 424.7907557487488 and batch: 250, loss is 4.611337013244629 and perplexity is 100.61858812832376
At time: 425.1881365776062 and batch: 300, loss is 4.611017265319824 and perplexity is 100.58642068658337
At time: 425.5769832134247 and batch: 350, loss is 4.631275072097778 and perplexity is 102.64486030283746
At time: 425.97902607917786 and batch: 400, loss is 4.528662786483765 and perplexity is 92.63460597617852
At time: 426.3850266933441 and batch: 450, loss is 4.570497779846192 and perplexity is 96.59217944802327
At time: 426.7734637260437 and batch: 500, loss is 4.544974737167358 and perplexity is 94.15804848033957
At time: 427.1891782283783 and batch: 550, loss is 4.595390748977661 and perplexity is 99.02682261840818
At time: 427.57819747924805 and batch: 600, loss is 4.503512277603149 and perplexity is 90.33385233519499
At time: 427.9874885082245 and batch: 650, loss is 4.628114843368531 and perplexity is 102.32099108634144
At time: 428.38071751594543 and batch: 700, loss is 4.6350124645233155 and perplexity is 103.02920219711876
At time: 428.7753551006317 and batch: 750, loss is 4.588778696060181 and perplexity is 98.37421195276849
At time: 429.17334389686584 and batch: 800, loss is 4.528142080307007 and perplexity is 92.58638312072411
At time: 429.56509375572205 and batch: 850, loss is 4.481263980865479 and perplexity is 88.34627012724924
At time: 429.9617533683777 and batch: 900, loss is 4.444168176651001 and perplexity is 85.12903605761363
At time: 430.352335691452 and batch: 950, loss is 4.513701915740967 and perplexity is 91.25902719564343
At time: 430.7421967983246 and batch: 1000, loss is 4.578652696609497 and perplexity is 97.38310119873418
At time: 431.1297023296356 and batch: 1050, loss is 4.46950138092041 and perplexity is 87.31317614216871
At time: 431.5185685157776 and batch: 1100, loss is 4.614439392089844 and perplexity is 100.93122982330053
At time: 431.91215801239014 and batch: 1150, loss is 4.547665557861328 and perplexity is 94.41175208807448
At time: 432.29952573776245 and batch: 1200, loss is 4.5165034198760985 and perplexity is 91.51504819219359
At time: 432.70772194862366 and batch: 1250, loss is 4.493201246261597 and perplexity is 89.40720271907861
At time: 433.10623836517334 and batch: 1300, loss is 4.56364501953125 and perplexity is 95.9325192221628
At time: 433.5042486190796 and batch: 1350, loss is 4.502275218963623 and perplexity is 90.22217315381221
At time: 433.9003801345825 and batch: 1400, loss is 4.385807609558105 and perplexity is 80.30305054295532
At time: 434.2889573574066 and batch: 1450, loss is 4.472242069244385 and perplexity is 87.55280256522703
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.950590215177617 and perplexity of 141.25831212214982
Finished 35 epochs...
Completing Train Step...
At time: 435.6180148124695 and batch: 50, loss is 4.626381607055664 and perplexity is 102.14379823192577
At time: 436.0023527145386 and batch: 100, loss is 4.6343935775756835 and perplexity is 102.965458495761
At time: 436.41578912734985 and batch: 150, loss is 4.532216520309448 and perplexity is 92.96439034472657
At time: 436.8110861778259 and batch: 200, loss is 4.587737503051758 and perplexity is 98.27183871547209
At time: 437.2236862182617 and batch: 250, loss is 4.61122579574585 and perplexity is 100.6073982028907
At time: 437.6185863018036 and batch: 300, loss is 4.610829200744629 and perplexity is 100.56750572277957
At time: 438.00788950920105 and batch: 350, loss is 4.631097974777222 and perplexity is 102.62668378266301
At time: 438.3995656967163 and batch: 400, loss is 4.528480968475342 and perplexity is 92.61776486766365
At time: 438.7870569229126 and batch: 450, loss is 4.570239152908325 and perplexity is 96.56720133857597
At time: 439.1968698501587 and batch: 500, loss is 4.544730730056763 and perplexity is 94.13507604982279
At time: 439.59723567962646 and batch: 550, loss is 4.595220890045166 and perplexity is 99.01000345651268
At time: 439.9932680130005 and batch: 600, loss is 4.50335807800293 and perplexity is 90.31992396518079
At time: 440.38266229629517 and batch: 650, loss is 4.628048362731934 and perplexity is 102.31418894782458
At time: 440.77355766296387 and batch: 700, loss is 4.634860486984253 and perplexity is 103.01354526229858
At time: 441.1776192188263 and batch: 750, loss is 4.588650226593018 and perplexity is 98.36157468194544
At time: 441.5750639438629 and batch: 800, loss is 4.5279664707183835 and perplexity is 92.57012549161169
At time: 441.96710872650146 and batch: 850, loss is 4.481152329444885 and perplexity is 88.33640669132896
At time: 442.3560709953308 and batch: 900, loss is 4.444102897644043 and perplexity is 85.1234791000548
At time: 442.7682023048401 and batch: 950, loss is 4.51355239868164 and perplexity is 91.2453834342731
At time: 443.1646590232849 and batch: 1000, loss is 4.578632698059082 and perplexity is 97.38115369734898
At time: 443.55720591545105 and batch: 1050, loss is 4.4695413780212405 and perplexity is 87.31666848592005
At time: 443.96538519859314 and batch: 1100, loss is 4.614492673873901 and perplexity is 100.93660776256438
At time: 444.3529236316681 and batch: 1150, loss is 4.547565221786499 and perplexity is 94.40227965867336
At time: 444.74538922309875 and batch: 1200, loss is 4.5165431022644045 and perplexity is 91.51867979992674
At time: 445.14915013313293 and batch: 1250, loss is 4.493256597518921 and perplexity is 89.41215165712667
At time: 445.54933428764343 and batch: 1300, loss is 4.56361798286438 and perplexity is 95.92992556166074
At time: 445.95775985717773 and batch: 1350, loss is 4.502354354858398 and perplexity is 90.22931324872845
At time: 446.3545699119568 and batch: 1400, loss is 4.38584114074707 and perplexity is 80.30574324486203
At time: 446.7555525302887 and batch: 1450, loss is 4.472239894866943 and perplexity is 87.55261219259513
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.950594910189637 and perplexity of 141.25897533318008
Annealing...
Finished 36 epochs...
Completing Train Step...
At time: 448.0548837184906 and batch: 50, loss is 4.626102190017701 and perplexity is 102.11526150138752
At time: 448.4489371776581 and batch: 100, loss is 4.6345133972167964 and perplexity is 102.977796519199
At time: 448.8470227718353 and batch: 150, loss is 4.532625141143799 and perplexity is 93.0023852937094
At time: 449.23990535736084 and batch: 200, loss is 4.587230091094971 and perplexity is 98.22198705822542
At time: 449.6335732936859 and batch: 250, loss is 4.611244535446167 and perplexity is 100.60928357304827
At time: 450.02777767181396 and batch: 300, loss is 4.610578842163086 and perplexity is 100.54233093619096
At time: 450.427127122879 and batch: 350, loss is 4.63090576171875 and perplexity is 102.60695948958634
At time: 450.8267893791199 and batch: 400, loss is 4.527249383926391 and perplexity is 92.50376847200324
At time: 451.2277398109436 and batch: 450, loss is 4.569870347976685 and perplexity is 96.53159344507456
At time: 451.6248049736023 and batch: 500, loss is 4.543963994979858 and perplexity is 94.06292704816806
At time: 452.0181610584259 and batch: 550, loss is 4.59415488243103 and perplexity is 98.90451427507732
At time: 452.41168999671936 and batch: 600, loss is 4.502426061630249 and perplexity is 90.23578353348668
At time: 452.80265522003174 and batch: 650, loss is 4.6272484493255615 and perplexity is 102.23237918114988
At time: 453.2075867652893 and batch: 700, loss is 4.633912124633789 and perplexity is 102.91589740447866
At time: 453.60690116882324 and batch: 750, loss is 4.587882061004638 and perplexity is 98.28604571814542
At time: 454.0091106891632 and batch: 800, loss is 4.5268237590789795 and perplexity is 92.46440494730366
At time: 454.3991301059723 and batch: 850, loss is 4.4802354097366335 and perplexity is 88.2554464217831
At time: 454.78834223747253 and batch: 900, loss is 4.44327260017395 and perplexity is 85.05283062439655
At time: 455.1926078796387 and batch: 950, loss is 4.512045888900757 and perplexity is 91.10802486366273
At time: 455.5901367664337 and batch: 1000, loss is 4.577474622726441 and perplexity is 97.26844426099346
At time: 455.9892783164978 and batch: 1050, loss is 4.467992162704467 and perplexity is 87.18150089457777
At time: 456.3878700733185 and batch: 1100, loss is 4.613541851043701 and perplexity is 100.84068054362272
At time: 456.7826581001282 and batch: 1150, loss is 4.546079559326172 and perplexity is 94.26213386606409
At time: 457.2025465965271 and batch: 1200, loss is 4.515271205902099 and perplexity is 91.40235151844747
At time: 457.6031560897827 and batch: 1250, loss is 4.492124710083008 and perplexity is 89.31100442049005
At time: 458.01997113227844 and batch: 1300, loss is 4.561937875747681 and perplexity is 95.76888832880147
At time: 458.4166452884674 and batch: 1350, loss is 4.5005202293396 and perplexity is 90.06397303645718
At time: 458.8252990245819 and batch: 1400, loss is 4.383942565917969 and perplexity is 80.15342142504633
At time: 459.225328207016 and batch: 1450, loss is 4.4702419185638425 and perplexity is 87.37785878287882
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.95035389957265 and perplexity of 141.22493452264317
Finished 37 epochs...
Completing Train Step...
At time: 460.52937269210815 and batch: 50, loss is 4.625805435180664 and perplexity is 102.08496279946722
At time: 460.9268171787262 and batch: 100, loss is 4.634304876327515 and perplexity is 102.95632573612374
At time: 461.3238708972931 and batch: 150, loss is 4.532504510879517 and perplexity is 92.99116706803488
At time: 461.72091150283813 and batch: 200, loss is 4.587028455734253 and perplexity is 98.20218402899711
At time: 462.11339688301086 and batch: 250, loss is 4.6111234760284425 and perplexity is 100.5971046089653
At time: 462.5017912387848 and batch: 300, loss is 4.610346088409424 and perplexity is 100.51893205445799
At time: 462.88968420028687 and batch: 350, loss is 4.630732803344727 and perplexity is 102.58921429134415
At time: 463.28914070129395 and batch: 400, loss is 4.527122125625611 and perplexity is 92.49199734861415
At time: 463.67717576026917 and batch: 450, loss is 4.569724931716919 and perplexity is 96.51755720238022
At time: 464.06542325019836 and batch: 500, loss is 4.543814811706543 and perplexity is 94.04889547947711
At time: 464.4570722579956 and batch: 550, loss is 4.594018287658692 and perplexity is 98.8910053581114
At time: 464.84995198249817 and batch: 600, loss is 4.502320795059204 and perplexity is 90.22628522190469
At time: 465.2492706775665 and batch: 650, loss is 4.627191867828369 and perplexity is 102.22659488371792
At time: 465.6379699707031 and batch: 700, loss is 4.633754930496216 and perplexity is 102.89972090020271
At time: 466.02549290657043 and batch: 750, loss is 4.587709798812866 and perplexity is 98.26911620668861
At time: 466.4306654930115 and batch: 800, loss is 4.5267548084259035 and perplexity is 92.458029685988
At time: 466.8264961242676 and batch: 850, loss is 4.480182886123657 and perplexity is 88.25081104860655
At time: 467.2562086582184 and batch: 900, loss is 4.443223962783813 and perplexity is 85.04869397728991
At time: 467.6499922275543 and batch: 950, loss is 4.511974849700928 and perplexity is 91.10155285236436
At time: 468.04874634742737 and batch: 1000, loss is 4.5774072170257565 and perplexity is 97.2618880343196
At time: 468.4620432853699 and batch: 1050, loss is 4.468099374771118 and perplexity is 87.19084830453096
At time: 468.8597288131714 and batch: 1100, loss is 4.613566608428955 and perplexity is 100.84317712610451
At time: 469.26919174194336 and batch: 1150, loss is 4.546051158905029 and perplexity is 94.25945681977927
At time: 469.6563994884491 and batch: 1200, loss is 4.515299463272095 and perplexity is 91.4049343450046
At time: 470.07663226127625 and batch: 1250, loss is 4.492251062393189 and perplexity is 89.32228978517409
At time: 470.46486043930054 and batch: 1300, loss is 4.5619885349273686 and perplexity is 95.77374002501423
At time: 470.8672425746918 and batch: 1350, loss is 4.5005724906921385 and perplexity is 90.0686800244988
At time: 471.25760316848755 and batch: 1400, loss is 4.384089603424072 and perplexity is 80.1652078507404
At time: 471.64626932144165 and batch: 1450, loss is 4.470332927703858 and perplexity is 87.3858113285347
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.950305906116453 and perplexity of 141.21815681257843
Finished 38 epochs...
Completing Train Step...
At time: 472.91665506362915 and batch: 50, loss is 4.625630922317505 and perplexity is 102.0671492147187
At time: 473.321485042572 and batch: 100, loss is 4.63423077583313 and perplexity is 102.94869690414023
At time: 473.71710658073425 and batch: 150, loss is 4.532450284957886 and perplexity is 92.98612467301255
At time: 474.1177499294281 and batch: 200, loss is 4.586907262802124 and perplexity is 98.19028333952745
At time: 474.5345094203949 and batch: 250, loss is 4.611025190353393 and perplexity is 100.58721784050262
At time: 474.9321463108063 and batch: 300, loss is 4.610212020874023 and perplexity is 100.50545663230487
At time: 475.33935809135437 and batch: 350, loss is 4.630635490417481 and perplexity is 102.57923152033179
At time: 475.74326610565186 and batch: 400, loss is 4.527019186019897 and perplexity is 92.48247674890725
At time: 476.1453516483307 and batch: 450, loss is 4.569620666503906 and perplexity is 96.50749430333332
At time: 476.54044485092163 and batch: 500, loss is 4.543712291717529 and perplexity is 94.03925408197223
At time: 476.9288899898529 and batch: 550, loss is 4.593925180435181 and perplexity is 98.88179831979987
At time: 477.34016513824463 and batch: 600, loss is 4.502229814529419 and perplexity is 90.21807676008538
At time: 477.7387115955353 and batch: 650, loss is 4.627155675888061 and perplexity is 102.2228951718483
At time: 478.12658858299255 and batch: 700, loss is 4.6336598968505855 and perplexity is 102.88994242924046
At time: 478.52196073532104 and batch: 750, loss is 4.587612247467041 and perplexity is 98.25953038971187
At time: 478.9102189540863 and batch: 800, loss is 4.526703338623047 and perplexity is 92.45327101189265
At time: 479.33450078964233 and batch: 850, loss is 4.480126695632935 and perplexity is 88.24585233154474
At time: 479.73357105255127 and batch: 900, loss is 4.443207445144654 and perplexity is 85.04728918525376
At time: 480.14588165283203 and batch: 950, loss is 4.511912403106689 and perplexity is 91.09586404828394
At time: 480.55247735977173 and batch: 1000, loss is 4.5773508262634275 and perplexity is 97.2564035169473
At time: 480.9484007358551 and batch: 1050, loss is 4.468176717758179 and perplexity is 87.19759216597505
At time: 481.3583929538727 and batch: 1100, loss is 4.613593082427979 and perplexity is 100.84584688361676
At time: 481.74799513816833 and batch: 1150, loss is 4.546021528244019 and perplexity is 94.2566638911456
At time: 482.1392734050751 and batch: 1200, loss is 4.515331554412842 and perplexity is 91.40786768068439
At time: 482.52928614616394 and batch: 1250, loss is 4.4923561096191404 and perplexity is 89.33167333678108
At time: 482.9504041671753 and batch: 1300, loss is 4.56201247215271 and perplexity is 95.77603261004997
At time: 483.3534605503082 and batch: 1350, loss is 4.50060227394104 and perplexity is 90.07136260236197
At time: 483.7486665248871 and batch: 1400, loss is 4.384171352386475 and perplexity is 80.17176154117806
At time: 484.14267444610596 and batch: 1450, loss is 4.4703880786895756 and perplexity is 87.39063087506737
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.950284517728365 and perplexity of 141.21513641613626
Finished 39 epochs...
Completing Train Step...
At time: 485.518905878067 and batch: 50, loss is 4.625481090545654 and perplexity is 102.05185745852816
At time: 485.93192863464355 and batch: 100, loss is 4.634175672531128 and perplexity is 102.94302424729649
At time: 486.329318523407 and batch: 150, loss is 4.532402000427246 and perplexity is 92.98163499001872
At time: 486.7342486381531 and batch: 200, loss is 4.586807765960693 and perplexity is 98.18051420248318
At time: 487.1226725578308 and batch: 250, loss is 4.610948600769043 and perplexity is 100.57951420231025
At time: 487.5252730846405 and batch: 300, loss is 4.610099382400513 and perplexity is 100.49413648864419
At time: 487.9249222278595 and batch: 350, loss is 4.630556516647339 and perplexity is 102.57113077155789
At time: 488.31412529945374 and batch: 400, loss is 4.52692590713501 and perplexity is 92.4738504889347
At time: 488.7147991657257 and batch: 450, loss is 4.569535503387451 and perplexity is 96.49927577431993
At time: 489.12162232398987 and batch: 500, loss is 4.543622961044312 and perplexity is 94.0308538673002
At time: 489.52715945243835 and batch: 550, loss is 4.593840942382813 and perplexity is 98.87346906051995
At time: 489.92138028144836 and batch: 600, loss is 4.502146348953247 and perplexity is 90.210546970571
At time: 490.3160467147827 and batch: 650, loss is 4.627125577926636 and perplexity is 102.21981851739336
At time: 490.7081286907196 and batch: 700, loss is 4.633582525253296 and perplexity is 102.88198197801002
At time: 491.09615778923035 and batch: 750, loss is 4.587535219192505 and perplexity is 98.25196191912612
At time: 491.49426221847534 and batch: 800, loss is 4.526655178070069 and perplexity is 92.44881851845417
At time: 491.88298416137695 and batch: 850, loss is 4.480088171958923 and perplexity is 88.24245284257745
At time: 492.28168416023254 and batch: 900, loss is 4.443199586868286 and perplexity is 85.04662086277698
At time: 492.69349694252014 and batch: 950, loss is 4.511851205825805 and perplexity is 91.09028939968285
At time: 493.0821077823639 and batch: 1000, loss is 4.577304382324218 and perplexity is 97.25188665134598
At time: 493.4852063655853 and batch: 1050, loss is 4.468236169815063 and perplexity is 87.20277639628976
At time: 493.8821988105774 and batch: 1100, loss is 4.613613710403443 and perplexity is 100.84792715072767
At time: 494.28539657592773 and batch: 1150, loss is 4.545989761352539 and perplexity is 94.25366969749088
At time: 494.6818883419037 and batch: 1200, loss is 4.5153594398498536 and perplexity is 91.41041666456059
At time: 495.08025884628296 and batch: 1250, loss is 4.492450532913208 and perplexity is 89.34010872588442
At time: 495.4794809818268 and batch: 1300, loss is 4.562026395797729 and perplexity is 95.77736617081337
At time: 495.8824279308319 and batch: 1350, loss is 4.500622253417969 and perplexity is 90.07316219905047
At time: 496.28102564811707 and batch: 1400, loss is 4.384228162765503 and perplexity is 80.17631625871492
At time: 496.67665457725525 and batch: 1450, loss is 4.470425729751587 and perplexity is 87.39392128707301
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.950278257712339 and perplexity of 141.2142524098862
Finished 40 epochs...
Completing Train Step...
At time: 497.9981269836426 and batch: 50, loss is 4.625347080230713 and perplexity is 102.03818237329153
At time: 498.40125250816345 and batch: 100, loss is 4.634129495620727 and perplexity is 102.93827076624086
At time: 498.7984199523926 and batch: 150, loss is 4.5323599910736085 and perplexity is 92.97772897367781
At time: 499.2013850212097 and batch: 200, loss is 4.586720485687255 and perplexity is 98.17194535430846
At time: 499.5901472568512 and batch: 250, loss is 4.610884485244751 and perplexity is 100.57306570075083
At time: 499.98839116096497 and batch: 300, loss is 4.609997425079346 and perplexity is 100.48389089801016
At time: 500.38552594184875 and batch: 350, loss is 4.630486249923706 and perplexity is 102.56392368747134
At time: 500.78609466552734 and batch: 400, loss is 4.526839685440064 and perplexity is 92.4658775805311
At time: 501.1825850009918 and batch: 450, loss is 4.569459867477417 and perplexity is 96.49197723979826
At time: 501.572105884552 and batch: 500, loss is 4.5435398578643795 and perplexity is 94.02303992901814
At time: 501.9746689796448 and batch: 550, loss is 4.59376088142395 and perplexity is 98.86555347264992
At time: 502.3684105873108 and batch: 600, loss is 4.502068872451782 and perplexity is 90.20355804373877
At time: 502.77800035476685 and batch: 650, loss is 4.627099180221558 and perplexity is 102.21712018438609
At time: 503.1680064201355 and batch: 700, loss is 4.633513374328613 and perplexity is 102.87486783980054
At time: 503.55989027023315 and batch: 750, loss is 4.58746600151062 and perplexity is 98.24516138144288
At time: 503.9635663032532 and batch: 800, loss is 4.5266085052490235 and perplexity is 92.4445037719831
At time: 504.37045764923096 and batch: 850, loss is 4.480063118934631 and perplexity is 88.24024212995548
At time: 504.7671446800232 and batch: 900, loss is 4.44319785118103 and perplexity is 85.04647324856907
At time: 505.1600852012634 and batch: 950, loss is 4.511788835525513 and perplexity is 91.08460824814867
At time: 505.55615425109863 and batch: 1000, loss is 4.577265510559082 and perplexity is 97.24810637232252
At time: 505.9460952281952 and batch: 1050, loss is 4.468283319473267 and perplexity is 87.20688807432259
At time: 506.3389699459076 and batch: 1100, loss is 4.613632011413574 and perplexity is 100.84977278655263
At time: 506.7390248775482 and batch: 1150, loss is 4.545960321426391 and perplexity is 94.25089491726071
At time: 507.1279990673065 and batch: 1200, loss is 4.515381870269775 and perplexity is 91.41246706158712
At time: 507.5229663848877 and batch: 1250, loss is 4.492534542083741 and perplexity is 89.34761442958336
At time: 507.9239616394043 and batch: 1300, loss is 4.562037591934204 and perplexity is 95.77843851327924
At time: 508.31866812705994 and batch: 1350, loss is 4.500636596679687 and perplexity is 90.07445415125504
At time: 508.7077302932739 and batch: 1400, loss is 4.384272918701172 and perplexity is 80.17990470506916
At time: 509.10243487358093 and batch: 1450, loss is 4.470456380844116 and perplexity is 87.39660004729411
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.950272519364316 and perplexity of 141.21344207568498
Finished 41 epochs...
Completing Train Step...
At time: 510.41236877441406 and batch: 50, loss is 4.6252244853973385 and perplexity is 102.02567378608536
At time: 510.80203080177307 and batch: 100, loss is 4.634090270996094 and perplexity is 102.93423313039752
At time: 511.1982378959656 and batch: 150, loss is 4.532323045730591 and perplexity is 92.97429394304244
At time: 511.5851514339447 and batch: 200, loss is 4.586642208099366 and perplexity is 98.16426099198827
At time: 511.98922538757324 and batch: 250, loss is 4.6108284759521485 and perplexity is 100.56743283223408
At time: 512.3843402862549 and batch: 300, loss is 4.609903564453125 and perplexity is 100.4744598596939
At time: 512.7880935668945 and batch: 350, loss is 4.630420789718628 and perplexity is 102.55721005173356
At time: 513.1897337436676 and batch: 400, loss is 4.526758193969727 and perplexity is 92.45834270722916
At time: 513.5782039165497 and batch: 450, loss is 4.569390392303466 and perplexity is 96.48527367576301
At time: 513.9774224758148 and batch: 500, loss is 4.54346113204956 and perplexity is 94.01563817994614
At time: 514.3652586936951 and batch: 550, loss is 4.593683948516846 and perplexity is 98.85794775077768
At time: 514.7550749778748 and batch: 600, loss is 4.50199598312378 and perplexity is 90.19698340662286
At time: 515.1572189331055 and batch: 650, loss is 4.6270737457275395 and perplexity is 102.2145203767167
At time: 515.5563192367554 and batch: 700, loss is 4.6334484100341795 and perplexity is 102.86818486367613
At time: 515.9525599479675 and batch: 750, loss is 4.587399682998657 and perplexity is 98.23864612457596
At time: 516.3438642024994 and batch: 800, loss is 4.526561298370361 and perplexity is 92.44013985851473
At time: 516.7400391101837 and batch: 850, loss is 4.480040073394775 and perplexity is 88.23820860937045
At time: 517.137437582016 and batch: 900, loss is 4.443197317123413 and perplexity is 85.04642782886438
At time: 517.5555994510651 and batch: 950, loss is 4.511725673675537 and perplexity is 91.0788553574709
At time: 517.9748606681824 and batch: 1000, loss is 4.577229824066162 and perplexity is 97.24463599038626
At time: 518.3716683387756 and batch: 1050, loss is 4.468323993682861 and perplexity is 87.21043521770432
At time: 518.7650399208069 and batch: 1100, loss is 4.613649625778198 and perplexity is 100.85154920686793
At time: 519.1539001464844 and batch: 1150, loss is 4.5459331703186034 and perplexity is 94.24833593579346
At time: 519.5450718402863 and batch: 1200, loss is 4.515399017333984 and perplexity is 91.41403453046807
At time: 519.9344635009766 and batch: 1250, loss is 4.492608661651611 and perplexity is 89.35423708158619
At time: 520.3352806568146 and batch: 1300, loss is 4.562046756744385 and perplexity is 95.77931630851005
At time: 520.7414062023163 and batch: 1350, loss is 4.50064787864685 and perplexity is 90.07547037402149
At time: 521.1480538845062 and batch: 1400, loss is 4.384309892654419 and perplexity is 80.18286932792363
At time: 521.5560479164124 and batch: 1450, loss is 4.470481452941894 and perplexity is 87.39879129086542
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.950268867688301 and perplexity of 141.2129264108871
Finished 42 epochs...
Completing Train Step...
At time: 522.8389048576355 and batch: 50, loss is 4.625109672546387 and perplexity is 102.01396060003272
At time: 523.2410202026367 and batch: 100, loss is 4.634055728912354 and perplexity is 102.93067762890458
At time: 523.6286947727203 and batch: 150, loss is 4.5322911834716795 and perplexity is 92.97133161921015
At time: 524.0222964286804 and batch: 200, loss is 4.586570034027099 and perplexity is 98.15717633318889
At time: 524.416220664978 and batch: 250, loss is 4.610777835845948 and perplexity is 100.56234021570152
At time: 524.8020961284637 and batch: 300, loss is 4.609815492630005 and perplexity is 100.46561128049795
At time: 525.206864118576 and batch: 350, loss is 4.630357456207276 and perplexity is 102.55071494918745
At time: 525.6011712551117 and batch: 400, loss is 4.526679887771606 and perplexity is 92.45110292939069
At time: 525.9929814338684 and batch: 450, loss is 4.569325504302978 and perplexity is 96.47901314239657
At time: 526.3879585266113 and batch: 500, loss is 4.543385753631592 and perplexity is 94.00855169696311
At time: 526.7761144638062 and batch: 550, loss is 4.5936071395874025 and perplexity is 98.85035486924825
At time: 527.1981587409973 and batch: 600, loss is 4.501924905776978 and perplexity is 90.19057267218447
At time: 527.5911207199097 and batch: 650, loss is 4.627048854827881 and perplexity is 102.21197619700995
At time: 528.0034446716309 and batch: 700, loss is 4.6333877468109135 and perplexity is 102.86194473728578
At time: 528.3976619243622 and batch: 750, loss is 4.58733452796936 and perplexity is 98.23224559122534
At time: 528.7881824970245 and batch: 800, loss is 4.526513643264771 and perplexity is 92.4357347188535
At time: 529.174028635025 and batch: 850, loss is 4.480017724037171 and perplexity is 88.2362365641289
At time: 529.5608403682709 and batch: 900, loss is 4.443197698593139 and perplexity is 85.0464602715081
At time: 529.9499084949493 and batch: 950, loss is 4.5116617965698245 and perplexity is 91.07303768960892
At time: 530.3376257419586 and batch: 1000, loss is 4.577194766998291 and perplexity is 97.24122693833829
At time: 530.7378861904144 and batch: 1050, loss is 4.468359508514404 and perplexity is 87.21353253661994
At time: 531.130411863327 and batch: 1100, loss is 4.61366644859314 and perplexity is 100.85324582808778
At time: 531.5375826358795 and batch: 1150, loss is 4.545907964706421 and perplexity is 94.24596037872784
At time: 531.9432179927826 and batch: 1200, loss is 4.515414218902588 and perplexity is 91.41542417774772
At time: 532.3396575450897 and batch: 1250, loss is 4.492674036026001 and perplexity is 89.36007874988007
At time: 532.7401757240295 and batch: 1300, loss is 4.562054176330566 and perplexity is 95.7800269540381
At time: 533.1366209983826 and batch: 1350, loss is 4.5006571388244625 and perplexity is 90.0763044927377
At time: 533.5281009674072 and batch: 1400, loss is 4.384341564178467 and perplexity is 80.18540888181332
At time: 533.917459487915 and batch: 1450, loss is 4.470501661300659 and perplexity is 87.40055749484144
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.95026365100828 and perplexity of 141.2121897501566
Finished 43 epochs...
Completing Train Step...
At time: 535.188152551651 and batch: 50, loss is 4.625000476837158 and perplexity is 102.00282172142373
At time: 535.5998666286469 and batch: 100, loss is 4.634024410247803 and perplexity is 102.92745402801965
At time: 535.9901323318481 and batch: 150, loss is 4.532263154983521 and perplexity is 92.96872580986137
At time: 536.3876075744629 and batch: 200, loss is 4.586498718261719 and perplexity is 98.15017642863587
At time: 536.7792644500732 and batch: 250, loss is 4.610731353759766 and perplexity is 100.55766597697199
At time: 537.1884305477142 and batch: 300, loss is 4.609732046127319 and perplexity is 100.45722812637375
At time: 537.5986313819885 and batch: 350, loss is 4.630296077728271 and perplexity is 102.54442073544969
At time: 537.9904911518097 and batch: 400, loss is 4.526604127883911 and perplexity is 92.44409910952315
At time: 538.3957183361053 and batch: 450, loss is 4.569263982772827 and perplexity is 96.47307778845848
At time: 538.7947099208832 and batch: 500, loss is 4.543313980102539 and perplexity is 94.00180461358059
At time: 539.1951172351837 and batch: 550, loss is 4.593531875610352 and perplexity is 98.84291527837803
At time: 539.5956788063049 and batch: 600, loss is 4.501859865188599 and perplexity is 90.1847068150331
At time: 539.9899952411652 and batch: 650, loss is 4.627024450302124 and perplexity is 102.2094817926417
At time: 540.3812556266785 and batch: 700, loss is 4.633329610824585 and perplexity is 102.85596493049552
At time: 540.7713432312012 and batch: 750, loss is 4.587273664474488 and perplexity is 98.22626701538984
At time: 541.1701514720917 and batch: 800, loss is 4.526466388702392 and perplexity is 92.43136681186378
At time: 541.5710818767548 and batch: 850, loss is 4.479995474815369 and perplexity is 88.23427339837016
At time: 541.9732127189636 and batch: 900, loss is 4.4431976890563964 and perplexity is 85.04645946044187
At time: 542.3666839599609 and batch: 950, loss is 4.511597032546997 and perplexity is 91.06713962431033
At time: 542.7657322883606 and batch: 1000, loss is 4.577160024642945 and perplexity is 97.2378486077636
At time: 543.1646184921265 and batch: 1050, loss is 4.4683912658691405 and perplexity is 87.21630225168967
At time: 543.5559504032135 and batch: 1100, loss is 4.613682413101197 and perplexity is 100.85485591339544
At time: 543.9658644199371 and batch: 1150, loss is 4.545883769989014 and perplexity is 94.24368015193453
At time: 544.3641655445099 and batch: 1200, loss is 4.515429744720459 and perplexity is 91.41684348799201
At time: 544.7644448280334 and batch: 1250, loss is 4.4927327346801755 and perplexity is 89.36532422018915
At time: 545.1652798652649 and batch: 1300, loss is 4.562060022354126 and perplexity is 95.78058688796898
At time: 545.5800793170929 and batch: 1350, loss is 4.500664939880371 and perplexity is 90.07700718576598
At time: 545.9776463508606 and batch: 1400, loss is 4.384368801116944 and perplexity is 80.18759291660487
At time: 546.3779768943787 and batch: 1450, loss is 4.470517625808716 and perplexity is 87.4019528128835
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.950260521000267 and perplexity of 141.2117477555629
Finished 44 epochs...
Completing Train Step...
At time: 547.6878659725189 and batch: 50, loss is 4.6248955726623535 and perplexity is 101.99212176082837
At time: 548.0821409225464 and batch: 100, loss is 4.633995447158814 and perplexity is 102.92447297417966
At time: 548.4895117282867 and batch: 150, loss is 4.532237482070923 and perplexity is 92.96633906252686
At time: 548.8948724269867 and batch: 200, loss is 4.586427793502808 and perplexity is 98.1432153978932
At time: 549.2919383049011 and batch: 250, loss is 4.610688409805298 and perplexity is 100.55334772586492
At time: 549.6929702758789 and batch: 300, loss is 4.609652280807495 and perplexity is 100.44921544301499
At time: 550.0897691249847 and batch: 350, loss is 4.630236358642578 and perplexity is 102.53829705925239
At time: 550.4966378211975 and batch: 400, loss is 4.526530179977417 and perplexity is 92.43726331467573
At time: 550.8939754962921 and batch: 450, loss is 4.569205255508423 and perplexity is 96.46741235487063
At time: 551.28808426857 and batch: 500, loss is 4.543244504928589 and perplexity is 93.99527404871215
At time: 551.6828768253326 and batch: 550, loss is 4.593460931777954 and perplexity is 98.83590323189645
At time: 552.0773429870605 and batch: 600, loss is 4.501799688339234 and perplexity is 90.17927994680363
At time: 552.4801914691925 and batch: 650, loss is 4.627000255584717 and perplexity is 102.20700889302906
At time: 552.8769545555115 and batch: 700, loss is 4.633272371292114 and perplexity is 102.8500776716446
At time: 553.2688689231873 and batch: 750, loss is 4.587215423583984 and perplexity is 98.22054639671664
At time: 553.6569442749023 and batch: 800, loss is 4.526419324874878 and perplexity is 92.42701674032556
At time: 554.0659749507904 and batch: 850, loss is 4.479973549842835 and perplexity is 88.23233888555646
At time: 554.4647657871246 and batch: 900, loss is 4.443196897506714 and perplexity is 85.04639214197051
At time: 554.8537242412567 and batch: 950, loss is 4.511531820297241 and perplexity is 91.06120112489016
At time: 555.2427582740784 and batch: 1000, loss is 4.577125635147095 and perplexity is 97.23450470467033
At time: 555.6468935012817 and batch: 1050, loss is 4.468420181274414 and perplexity is 87.21882418287692
At time: 556.0494129657745 and batch: 1100, loss is 4.6136977481842045 and perplexity is 100.85640254284144
At time: 556.4563059806824 and batch: 1150, loss is 4.545860176086426 and perplexity is 94.2414566019567
At time: 556.8567261695862 and batch: 1200, loss is 4.51544415473938 and perplexity is 91.41816081592772
At time: 557.248012304306 and batch: 1250, loss is 4.492785930633545 and perplexity is 89.37007822025487
At time: 557.6357250213623 and batch: 1300, loss is 4.5620639038085935 and perplexity is 95.78095865667733
At time: 558.0429003238678 and batch: 1350, loss is 4.500671501159668 and perplexity is 90.07759820810728
At time: 558.4299387931824 and batch: 1400, loss is 4.384392509460449 and perplexity is 80.18949405413892
At time: 558.8229022026062 and batch: 1450, loss is 4.470529546737671 and perplexity is 87.40299473156381
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.950260521000267 and perplexity of 141.2117477555629
Finished 45 epochs...
Completing Train Step...
At time: 560.1404201984406 and batch: 50, loss is 4.624794445037842 and perplexity is 101.98180806134454
At time: 560.5313129425049 and batch: 100, loss is 4.633968114852905 and perplexity is 102.92165984944364
At time: 560.9282486438751 and batch: 150, loss is 4.532213344573974 and perplexity is 92.96409511488315
At time: 561.3242497444153 and batch: 200, loss is 4.5863589000701905 and perplexity is 98.1364542077998
At time: 561.7272474765778 and batch: 250, loss is 4.610648193359375 and perplexity is 100.54930390890826
At time: 562.1242845058441 and batch: 300, loss is 4.609575862884522 and perplexity is 100.44153961589564
At time: 562.532710313797 and batch: 350, loss is 4.630178194046021 and perplexity is 102.53233313401864
At time: 562.927815914154 and batch: 400, loss is 4.526458196640014 and perplexity is 92.43060961144272
At time: 563.3229901790619 and batch: 450, loss is 4.5691486167907716 and perplexity is 96.46194871906786
At time: 563.7128541469574 and batch: 500, loss is 4.543176221847534 and perplexity is 93.98885598092069
At time: 564.1025140285492 and batch: 550, loss is 4.593392353057862 and perplexity is 98.829125424563
At time: 564.5106916427612 and batch: 600, loss is 4.501742429733277 and perplexity is 90.17411655477339
At time: 564.9168708324432 and batch: 650, loss is 4.626976613998413 and perplexity is 102.20459258577024
At time: 565.3239135742188 and batch: 700, loss is 4.6332155418396 and perplexity is 102.84423292411793
At time: 565.7320024967194 and batch: 750, loss is 4.58715859413147 and perplexity is 98.21496473544212
At time: 566.1403608322144 and batch: 800, loss is 4.5263720226287845 and perplexity is 92.42264483823523
At time: 566.5385506153107 and batch: 850, loss is 4.479952454566956 and perplexity is 88.23047761965825
At time: 566.9345798492432 and batch: 900, loss is 4.443195247650147 and perplexity is 85.04625182773769
At time: 567.337370634079 and batch: 950, loss is 4.511466035842895 and perplexity is 91.05521091049572
At time: 567.7292439937592 and batch: 1000, loss is 4.5770917320251465 and perplexity is 97.23120820728086
At time: 568.1230766773224 and batch: 1050, loss is 4.468446941375732 and perplexity is 87.22115819867798
At time: 568.5267107486725 and batch: 1100, loss is 4.613712425231934 and perplexity is 100.85788282793843
At time: 568.9314141273499 and batch: 1150, loss is 4.545837106704712 and perplexity is 94.23928253489841
At time: 569.3316266536713 and batch: 1200, loss is 4.5154572868347165 and perplexity is 91.4193613358137
At time: 569.7254519462585 and batch: 1250, loss is 4.492834672927857 and perplexity is 89.3744344290751
At time: 570.1266334056854 and batch: 1300, loss is 4.562066583633423 and perplexity is 95.78121533321246
At time: 570.5173602104187 and batch: 1350, loss is 4.500677118301391 and perplexity is 90.07810418816359
At time: 570.9157345294952 and batch: 1400, loss is 4.3844130325317385 and perplexity is 80.19113980572995
At time: 571.3094358444214 and batch: 1450, loss is 4.470538110733032 and perplexity is 87.40374325361039
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.950259477664263 and perplexity of 141.2116004243391
Finished 46 epochs...
Completing Train Step...
At time: 572.5648744106293 and batch: 50, loss is 4.624696569442749 and perplexity is 101.97182701965008
At time: 572.9870088100433 and batch: 100, loss is 4.633941898345947 and perplexity is 102.91896163840104
At time: 573.3930959701538 and batch: 150, loss is 4.532190351486206 and perplexity is 92.96195760785893
At time: 573.7971322536469 and batch: 200, loss is 4.586291837692261 and perplexity is 98.12987316449168
At time: 574.2014179229736 and batch: 250, loss is 4.610610103607177 and perplexity is 100.54547408377773
At time: 574.6069920063019 and batch: 300, loss is 4.60950267791748 and perplexity is 100.43418907410714
At time: 575.0083236694336 and batch: 350, loss is 4.6301217365264895 and perplexity is 102.52654457622346
At time: 575.4132039546967 and batch: 400, loss is 4.526387958526612 and perplexity is 92.42411768779584
At time: 575.813428401947 and batch: 450, loss is 4.569093475341797 and perplexity is 96.45662981409195
At time: 576.2020318508148 and batch: 500, loss is 4.543108825683594 and perplexity is 93.98252170602974
At time: 576.609188079834 and batch: 550, loss is 4.593325262069702 and perplexity is 98.8224951032992
At time: 577.0144200325012 and batch: 600, loss is 4.501687078475952 and perplexity is 90.16912544217743
At time: 577.4148926734924 and batch: 650, loss is 4.626953268051148 and perplexity is 102.20220655059371
At time: 577.8029909133911 and batch: 700, loss is 4.633159618377686 and perplexity is 102.83848167939121
At time: 578.206300497055 and batch: 750, loss is 4.587102956771851 and perplexity is 98.20950046613933
At time: 578.6197738647461 and batch: 800, loss is 4.526324481964111 and perplexity is 92.41825110871
At time: 579.0307581424713 and batch: 850, loss is 4.4799318027496335 and perplexity is 88.22865551876713
At time: 579.4334943294525 and batch: 900, loss is 4.443192558288574 and perplexity is 85.0460231079237
At time: 579.8278522491455 and batch: 950, loss is 4.511400232315063 and perplexity is 91.04921935352527
At time: 580.2290885448456 and batch: 1000, loss is 4.577058267593384 and perplexity is 97.22795447459109
At time: 580.6308612823486 and batch: 1050, loss is 4.468471956253052 and perplexity is 87.22334005253931
At time: 581.0400836467743 and batch: 1100, loss is 4.613726663589477 and perplexity is 100.85931888875878
At time: 581.4471530914307 and batch: 1150, loss is 4.545814542770386 and perplexity is 94.23715614990623
At time: 581.8431558609009 and batch: 1200, loss is 4.515469760894775 and perplexity is 91.42050171353009
At time: 582.2419333457947 and batch: 1250, loss is 4.492879695892334 and perplexity is 89.37845842164695
At time: 582.6320056915283 and batch: 1300, loss is 4.562067642211914 and perplexity is 95.78131672520048
At time: 583.028927564621 and batch: 1350, loss is 4.500681953430176 and perplexity is 90.07853972845095
At time: 583.4176762104034 and batch: 1400, loss is 4.384431200027466 and perplexity is 80.19259669115368
At time: 583.8077096939087 and batch: 1450, loss is 4.470544404983521 and perplexity is 87.40429339639545
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.950257912660256 and perplexity of 141.21137942779163
Finished 47 epochs...
Completing Train Step...
At time: 585.1272912025452 and batch: 50, loss is 4.624601173400879 and perplexity is 101.9620997749478
At time: 585.5309290885925 and batch: 100, loss is 4.633916454315186 and perplexity is 102.9163429984897
At time: 585.9281432628632 and batch: 150, loss is 4.532168188095093 and perplexity is 92.95989727846582
At time: 586.3261506557465 and batch: 200, loss is 4.586226768493653 and perplexity is 98.12348814002183
At time: 586.7170798778534 and batch: 250, loss is 4.61057370185852 and perplexity is 100.54181411931648
At time: 587.117603302002 and batch: 300, loss is 4.609432258605957 and perplexity is 100.42711681667382
At time: 587.5114343166351 and batch: 350, loss is 4.63006628036499 and perplexity is 102.5208590052609
At time: 587.930342912674 and batch: 400, loss is 4.52631893157959 and perplexity is 92.41773815330315
At time: 588.3271884918213 and batch: 450, loss is 4.5690399932861325 and perplexity is 96.45147125319352
At time: 588.7259502410889 and batch: 500, loss is 4.543042364120484 and perplexity is 93.9762756882945
At time: 589.1448194980621 and batch: 550, loss is 4.593259696960449 and perplexity is 98.81601600801471
At time: 589.5474178791046 and batch: 600, loss is 4.501633558273316 and perplexity is 90.16429970145064
At time: 589.947732925415 and batch: 650, loss is 4.626930150985718 and perplexity is 102.19984396280596
At time: 590.344607591629 and batch: 700, loss is 4.633103981018066 and perplexity is 102.83276017696936
At time: 590.7510070800781 and batch: 750, loss is 4.5870485019683835 and perplexity is 98.20415263270175
At time: 591.1423170566559 and batch: 800, loss is 4.5262770843505855 and perplexity is 92.41387080796996
At time: 591.5346739292145 and batch: 850, loss is 4.479911499023437 and perplexity is 88.22686416648843
At time: 591.931610584259 and batch: 900, loss is 4.443189096450806 and perplexity is 85.04572869289845
At time: 592.3279402256012 and batch: 950, loss is 4.511334905624389 and perplexity is 91.04327160361198
At time: 592.7184824943542 and batch: 1000, loss is 4.577025785446167 and perplexity is 97.22479635315176
At time: 593.122278213501 and batch: 1050, loss is 4.468495693206787 and perplexity is 87.22541049349964
At time: 593.5197730064392 and batch: 1100, loss is 4.613740119934082 and perplexity is 100.86067609564185
At time: 593.9186754226685 and batch: 1150, loss is 4.545792198181152 and perplexity is 94.23505048288669
At time: 594.3199610710144 and batch: 1200, loss is 4.515481548309326 and perplexity is 91.4215793312334
At time: 594.7091157436371 and batch: 1250, loss is 4.492921533584595 and perplexity is 89.38219788830992
At time: 595.1170995235443 and batch: 1300, loss is 4.562067785263062 and perplexity is 95.78133042682876
At time: 595.5131876468658 and batch: 1350, loss is 4.50068660736084 and perplexity is 90.07895894870465
At time: 595.9031598567963 and batch: 1400, loss is 4.384447040557862 and perplexity is 80.1938669944802
At time: 596.299501657486 and batch: 1450, loss is 4.470548906326294 and perplexity is 87.40468683396537
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.950257390992254 and perplexity of 141.21130576235265
Finished 48 epochs...
Completing Train Step...
At time: 597.5836298465729 and batch: 50, loss is 4.6245081329345705 and perplexity is 101.9526136149442
At time: 597.972706079483 and batch: 100, loss is 4.633891372680664 and perplexity is 102.91376172075981
At time: 598.3867082595825 and batch: 150, loss is 4.532146797180176 and perplexity is 92.9579088024802
At time: 598.7836081981659 and batch: 200, loss is 4.586163425445557 and perplexity is 98.1172728960416
At time: 599.2134976387024 and batch: 250, loss is 4.610538854598999 and perplexity is 100.53831057367194
At time: 599.6096115112305 and batch: 300, loss is 4.609364023208618 and perplexity is 100.42026436624674
At time: 600.0019314289093 and batch: 350, loss is 4.6300119972229 and perplexity is 102.51529400194865
At time: 600.3894941806793 and batch: 400, loss is 4.526251487731933 and perplexity is 92.41150535563463
At time: 600.7802636623383 and batch: 450, loss is 4.568987655639648 and perplexity is 96.44642334228722
At time: 601.1812336444855 and batch: 500, loss is 4.542976875305175 and perplexity is 93.9701214948502
At time: 601.576771736145 and batch: 550, loss is 4.593195295333862 and perplexity is 98.80965230076968
At time: 601.9706826210022 and batch: 600, loss is 4.501581401824951 and perplexity is 90.15959717444355
At time: 602.3643021583557 and batch: 650, loss is 4.626907081604004 and perplexity is 102.19748630278943
At time: 602.7665197849274 and batch: 700, loss is 4.633048677444458 and perplexity is 102.82707331510098
At time: 603.1659336090088 and batch: 750, loss is 4.58699522972107 and perplexity is 98.19892121614136
At time: 603.5688099861145 and batch: 800, loss is 4.526229496002197 and perplexity is 92.40947308913097
At time: 603.9733617305756 and batch: 850, loss is 4.479891147613525 and perplexity is 88.2250686436813
At time: 604.3784098625183 and batch: 900, loss is 4.443184700012207 and perplexity is 85.04535479539607
At time: 604.7828681468964 and batch: 950, loss is 4.511270275115967 and perplexity is 91.03738762082426
At time: 605.1719396114349 and batch: 1000, loss is 4.576993751525879 and perplexity is 97.22168191165953
At time: 605.5652737617493 and batch: 1050, loss is 4.468517942428589 and perplexity is 87.22735121259413
At time: 605.9541494846344 and batch: 1100, loss is 4.613753442764282 and perplexity is 100.86201985425464
At time: 606.3482534885406 and batch: 1150, loss is 4.545769834518433 and perplexity is 94.23294306556626
At time: 606.7425928115845 and batch: 1200, loss is 4.515492916107178 and perplexity is 91.42261859917359
At time: 607.1314535140991 and batch: 1250, loss is 4.492960634231568 and perplexity is 89.38569285840255
At time: 607.539475440979 and batch: 1300, loss is 4.562066888809204 and perplexity is 95.78124456332408
At time: 607.9377398490906 and batch: 1350, loss is 4.500690841674805 and perplexity is 90.07934037210605
At time: 608.3337647914886 and batch: 1400, loss is 4.384460496902466 and perplexity is 80.19494611805011
At time: 608.7349441051483 and batch: 1450, loss is 4.470552062988281 and perplexity is 87.40496274145325
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.950255304320246 and perplexity of 141.21101110098107
Finished 49 epochs...
Completing Train Step...
At time: 610.0152103900909 and batch: 50, loss is 4.624417362213134 and perplexity is 101.94335972265166
At time: 610.417055606842 and batch: 100, loss is 4.633866338729859 and perplexity is 102.91118541495935
At time: 610.8051898479462 and batch: 150, loss is 4.532125854492188 and perplexity is 92.95596203438546
At time: 611.2129051685333 and batch: 200, loss is 4.58610161781311 and perplexity is 98.11120868711089
At time: 611.6124203205109 and batch: 250, loss is 4.6105058479309085 and perplexity is 100.53499219378911
At time: 612.0127036571503 and batch: 300, loss is 4.609297790527344 and perplexity is 100.4136134831388
At time: 612.4022746086121 and batch: 350, loss is 4.629958610534668 and perplexity is 102.50982119599756
At time: 612.7915163040161 and batch: 400, loss is 4.526185007095337 and perplexity is 92.40536198413962
At time: 613.1816353797913 and batch: 450, loss is 4.568936586380005 and perplexity is 96.4414980206192
At time: 613.5833697319031 and batch: 500, loss is 4.54291187286377 and perplexity is 93.96401340605635
At time: 613.9884858131409 and batch: 550, loss is 4.593131790161133 and perplexity is 98.80337757597385
At time: 614.3906180858612 and batch: 600, loss is 4.501530694961548 and perplexity is 90.15502557997172
At time: 614.7827541828156 and batch: 650, loss is 4.626884450912476 and perplexity is 102.19517352917191
At time: 615.1747133731842 and batch: 700, loss is 4.632993965148926 and perplexity is 102.82144756377731
At time: 615.5712821483612 and batch: 750, loss is 4.586942958831787 and perplexity is 98.19378840535224
At time: 615.9756157398224 and batch: 800, loss is 4.52618179321289 and perplexity is 92.405065004646
At time: 616.3629274368286 and batch: 850, loss is 4.479870305061341 and perplexity is 88.22322982724698
At time: 616.764274597168 and batch: 900, loss is 4.4431797218322755 and perplexity is 85.04493142537137
At time: 617.1528732776642 and batch: 950, loss is 4.51120665550232 and perplexity is 91.03159604162731
At time: 617.5586380958557 and batch: 1000, loss is 4.576962490081787 and perplexity is 97.21864266899172
At time: 617.9580645561218 and batch: 1050, loss is 4.4685390853881835 and perplexity is 87.22919547645289
At time: 618.3473868370056 and batch: 1100, loss is 4.613766098022461 and perplexity is 100.8632962972332
At time: 618.7430596351624 and batch: 1150, loss is 4.545747909545899 and perplexity is 94.23087703352664
At time: 619.143372297287 and batch: 1200, loss is 4.515503940582275 and perplexity is 91.42362649111139
At time: 619.5339124202728 and batch: 1250, loss is 4.492997140884399 and perplexity is 89.3889560904243
At time: 619.92702460289 and batch: 1300, loss is 4.562064962387085 and perplexity is 95.78106004839373
At time: 620.3124649524689 and batch: 1350, loss is 4.500694971084595 and perplexity is 90.07971234738407
At time: 620.708868265152 and batch: 1400, loss is 4.384472322463989 and perplexity is 80.19589447392673
At time: 621.1072204113007 and batch: 1450, loss is 4.470553903579712 and perplexity is 87.40512361842677
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.9502584343282585 and perplexity of 141.21145309326903
Annealing...
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc1f716f898>
SETTINGS FOR THIS RUN
{'batch_size': 20, 'lr': 14.33456185346495, 'num_layers': 1, 'wordvec_source': '', 'seq_len': 35, 'anneal': 2.0, 'wordvec_dim': 200, 'dropout': 0.19729647227169755, 'tune_wordvecs': True, 'data': 'ptb'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.6619057655334473 and batch: 50, loss is 6.409867734909057 and perplexity is 607.8132832654929
At time: 1.0875201225280762 and batch: 100, loss is 5.633677234649658 and perplexity is 279.6887099812214
At time: 1.4891648292541504 and batch: 150, loss is 5.435762748718262 and perplexity is 229.46780781847846
At time: 1.902897834777832 and batch: 200, loss is 5.377614488601685 and perplexity is 216.505183323001
At time: 2.3179211616516113 and batch: 250, loss is 5.339219970703125 and perplexity is 208.35012768414106
At time: 2.726816415786743 and batch: 300, loss is 5.349833517074585 and perplexity is 210.57323809963623
At time: 3.1178836822509766 and batch: 350, loss is 5.36451268196106 and perplexity is 213.68707573704015
At time: 3.508953332901001 and batch: 400, loss is 5.238529014587402 and perplexity is 188.3927754591869
At time: 3.908660411834717 and batch: 450, loss is 5.252552690505982 and perplexity is 191.05334657823784
At time: 4.3160858154296875 and batch: 500, loss is 5.240706863403321 and perplexity is 188.80351354252744
At time: 4.719653844833374 and batch: 550, loss is 5.291097764968872 and perplexity is 198.56127942797886
At time: 5.1289427280426025 and batch: 600, loss is 5.112501039505005 and perplexity is 166.08522155880524
At time: 5.531692743301392 and batch: 650, loss is 5.275214204788208 and perplexity is 195.4323345711283
At time: 5.925177812576294 and batch: 700, loss is 5.280853395462036 and perplexity is 196.53752803915054
At time: 6.3176515102386475 and batch: 750, loss is 5.221098852157593 and perplexity is 185.13751109057006
At time: 6.727619886398315 and batch: 800, loss is 5.1212132453918455 and perplexity is 167.53851169286273
At time: 7.130810499191284 and batch: 850, loss is 5.07941104888916 and perplexity is 160.6793957476194
At time: 7.562261343002319 and batch: 900, loss is 5.062942676544189 and perplexity is 158.0549372244528
At time: 7.971350908279419 and batch: 950, loss is 5.102296466827393 and perplexity is 164.39901100632827
At time: 8.376586198806763 and batch: 1000, loss is 5.1473744678497315 and perplexity is 171.97935969677536
At time: 8.778468132019043 and batch: 1050, loss is 5.055007438659668 and perplexity is 156.8056967640422
At time: 9.174856424331665 and batch: 1100, loss is 5.163850440979004 and perplexity is 174.83635829275002
At time: 9.568135976791382 and batch: 1150, loss is 5.120865478515625 and perplexity is 167.48025747803487
At time: 9.963499546051025 and batch: 1200, loss is 5.05838171005249 and perplexity is 157.33569541764479
At time: 10.356565952301025 and batch: 1250, loss is 5.042383003234863 and perplexity is 154.8385565147638
At time: 10.759809732437134 and batch: 1300, loss is 5.149831867218017 and perplexity is 172.4025013677505
At time: 11.162163734436035 and batch: 1350, loss is 5.0884130096435545 and perplexity is 162.13235529284376
At time: 11.570894718170166 and batch: 1400, loss is 4.938143653869629 and perplexity is 139.51102827474628
At time: 11.962603569030762 and batch: 1450, loss is 5.037625894546509 and perplexity is 154.10372190211558
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0194519564636755 and perplexity of 151.32834654185126
Finished 1 epochs...
Completing Train Step...
At time: 13.297774076461792 and batch: 50, loss is 4.965117149353027 and perplexity is 143.32533976071127
At time: 13.726138591766357 and batch: 100, loss is 4.963790788650512 and perplexity is 143.13536467797107
At time: 14.122132778167725 and batch: 150, loss is 4.826613473892212 and perplexity is 124.78764765235957
At time: 14.522144794464111 and batch: 200, loss is 4.921889057159424 and perplexity is 137.26166355721153
At time: 14.92330265045166 and batch: 250, loss is 4.951936826705933 and perplexity is 141.44866032750363
At time: 15.313491821289062 and batch: 300, loss is 4.958321685791016 and perplexity is 142.35467941564366
At time: 15.698887825012207 and batch: 350, loss is 4.983593378067017 and perplexity is 145.99806644117103
At time: 16.086450576782227 and batch: 400, loss is 4.843571300506592 and perplexity is 126.92181925786791
At time: 16.482215642929077 and batch: 450, loss is 4.888408813476563 and perplexity is 132.74218833765912
At time: 16.879661321640015 and batch: 500, loss is 4.870260887145996 and perplexity is 130.35492038387503
At time: 17.2656409740448 and batch: 550, loss is 4.9390020751953125 and perplexity is 139.63083893324028
At time: 17.66457486152649 and batch: 600, loss is 4.833905305862427 and perplexity is 125.70090381971382
At time: 18.077068328857422 and batch: 650, loss is 4.947208871841431 and perplexity is 140.78147589759467
At time: 18.467730283737183 and batch: 700, loss is 4.957086524963379 and perplexity is 142.17895703703846
At time: 18.863584280014038 and batch: 750, loss is 4.925546035766602 and perplexity is 137.7645454781989
At time: 19.25820827484131 and batch: 800, loss is 4.840373058319091 and perplexity is 126.5165409755108
At time: 19.654272079467773 and batch: 850, loss is 4.803488864898681 and perplexity is 121.93509133325551
At time: 20.0555100440979 and batch: 900, loss is 4.760138139724732 and perplexity is 116.76205426301539
At time: 20.46240472793579 and batch: 950, loss is 4.842926168441773 and perplexity is 126.8399643289981
At time: 20.847124814987183 and batch: 1000, loss is 4.885184803009033 and perplexity is 132.31491526949617
At time: 21.231918811798096 and batch: 1050, loss is 4.7874628448486325 and perplexity is 119.99653229809533
At time: 21.62395453453064 and batch: 1100, loss is 4.932524271011353 and perplexity is 138.72926097598227
At time: 22.017208099365234 and batch: 1150, loss is 4.872507381439209 and perplexity is 130.64809114853824
At time: 22.42289924621582 and batch: 1200, loss is 4.8206517791748045 and perplexity is 124.04591498130134
At time: 22.808626174926758 and batch: 1250, loss is 4.781631937026978 and perplexity is 119.29887953048848
At time: 23.195159435272217 and batch: 1300, loss is 4.893040657043457 and perplexity is 133.35845551356215
At time: 23.586289405822754 and batch: 1350, loss is 4.863756456375122 and perplexity is 129.50978736283756
At time: 23.97555136680603 and batch: 1400, loss is 4.7055497741699215 and perplexity is 110.55905075256116
At time: 24.374923944473267 and batch: 1450, loss is 4.811786365509033 and perplexity is 122.95105698686135
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.001966688368055 and perplexity of 148.70532874539634
Finished 2 epochs...
Completing Train Step...
At time: 25.69257950782776 and batch: 50, loss is 4.854239463806152 and perplexity is 128.2830901717275
At time: 26.092684507369995 and batch: 100, loss is 4.870202236175537 and perplexity is 130.34727516549233
At time: 26.47754716873169 and batch: 150, loss is 4.733551368713379 and perplexity is 113.69863196492841
At time: 26.862465620040894 and batch: 200, loss is 4.824106140136719 and perplexity is 124.47515529616146
At time: 27.267444610595703 and batch: 250, loss is 4.860838451385498 and perplexity is 129.13242799312962
At time: 27.665014266967773 and batch: 300, loss is 4.863908386230468 and perplexity is 129.52946526088976
At time: 28.090850114822388 and batch: 350, loss is 4.882537412643432 and perplexity is 131.96508930484868
At time: 28.477118253707886 and batch: 400, loss is 4.7482790279388425 and perplexity is 115.3855382702382
At time: 28.881465911865234 and batch: 450, loss is 4.795539979934692 and perplexity is 120.9696853529555
At time: 29.2789888381958 and batch: 500, loss is 4.790105104446411 and perplexity is 120.31401353647588
At time: 29.667353630065918 and batch: 550, loss is 4.8493361663818355 and perplexity is 127.65561962062736
At time: 30.075146913528442 and batch: 600, loss is 4.746229085922241 and perplexity is 115.14924688179909
At time: 30.46053695678711 and batch: 650, loss is 4.857261371612549 and perplexity is 128.67133616969937
At time: 30.853107690811157 and batch: 700, loss is 4.875508298873902 and perplexity is 131.04074414802133
At time: 31.256967306137085 and batch: 750, loss is 4.8566755676269535 and perplexity is 128.5959820616626
At time: 31.655465126037598 and batch: 800, loss is 4.771048946380615 and perplexity is 118.04299781801225
At time: 32.0529727935791 and batch: 850, loss is 4.728918838500976 and perplexity is 113.17313774094974
At time: 32.450517892837524 and batch: 900, loss is 4.670980024337768 and perplexity is 106.8023600723629
At time: 32.850971937179565 and batch: 950, loss is 4.7608928394317624 and perplexity is 116.85020781170452
At time: 33.24007225036621 and batch: 1000, loss is 4.804050416946411 and perplexity is 122.00358346263168
At time: 33.638405323028564 and batch: 1050, loss is 4.6879009437561034 and perplexity is 108.62493049854794
At time: 34.03217935562134 and batch: 1100, loss is 4.842398061752319 and perplexity is 126.77299697985481
At time: 34.42020034790039 and batch: 1150, loss is 4.795917024612427 and perplexity is 121.01530492875375
At time: 34.82503700256348 and batch: 1200, loss is 4.750472040176391 and perplexity is 115.63885783262695
At time: 35.21950078010559 and batch: 1250, loss is 4.716158638000488 and perplexity is 111.73820032664312
At time: 35.6216835975647 and batch: 1300, loss is 4.817258100509644 and perplexity is 123.62565652055991
At time: 36.01672601699829 and batch: 1350, loss is 4.789643678665161 and perplexity is 120.25851035506871
At time: 36.4268753528595 and batch: 1400, loss is 4.647107067108155 and perplexity is 104.28286544967708
At time: 36.82068228721619 and batch: 1450, loss is 4.736609621047974 and perplexity is 114.04688332040561
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.986684945913462 and perplexity of 146.45012779814263
Finished 3 epochs...
Completing Train Step...
At time: 38.12912702560425 and batch: 50, loss is 4.8022027015686035 and perplexity is 121.7783637004052
At time: 38.53491830825806 and batch: 100, loss is 4.825255851745606 and perplexity is 124.61834812668015
At time: 38.92982721328735 and batch: 150, loss is 4.6998756408691404 and perplexity is 109.93350036745879
At time: 39.33102297782898 and batch: 200, loss is 4.78372465133667 and perplexity is 119.5487994170643
At time: 39.718665599823 and batch: 250, loss is 4.818587827682495 and perplexity is 123.7901542596152
At time: 40.10682678222656 and batch: 300, loss is 4.826720476150513 and perplexity is 124.80100092686895
At time: 40.51174211502075 and batch: 350, loss is 4.831806535720825 and perplexity is 125.43736316836755
At time: 40.906747579574585 and batch: 400, loss is 4.718194580078125 and perplexity is 111.96592456838958
At time: 41.30095362663269 and batch: 450, loss is 4.758342676162719 and perplexity is 116.55260033887267
At time: 41.68667769432068 and batch: 500, loss is 4.757095260620117 and perplexity is 116.40730145656227
At time: 42.087714195251465 and batch: 550, loss is 4.803717470169067 and perplexity is 121.96296952420853
At time: 42.509106159210205 and batch: 600, loss is 4.702719688415527 and perplexity is 110.24660149564633
At time: 42.916136503219604 and batch: 650, loss is 4.81029372215271 and perplexity is 122.76767180688049
At time: 43.31710147857666 and batch: 700, loss is 4.81922830581665 and perplexity is 123.8694645421819
At time: 43.71453833580017 and batch: 750, loss is 4.8138242530822755 and perplexity is 123.20187289852372
At time: 44.119621992111206 and batch: 800, loss is 4.723412265777588 and perplexity is 112.55165431987443
At time: 44.507444620132446 and batch: 850, loss is 4.698177928924561 and perplexity is 109.74702328774738
At time: 44.90510010719299 and batch: 900, loss is 4.653644580841064 and perplexity is 104.96684945600953
At time: 45.291961431503296 and batch: 950, loss is 4.736000185012817 and perplexity is 113.97740021491762
At time: 45.68391299247742 and batch: 1000, loss is 4.768150310516358 and perplexity is 117.70132957614952
At time: 46.07242965698242 and batch: 1050, loss is 4.671760005950928 and perplexity is 106.88569644565584
At time: 46.46290445327759 and batch: 1100, loss is 4.828047313690186 and perplexity is 124.96670148443792
At time: 46.85152792930603 and batch: 1150, loss is 4.7686826038360595 and perplexity is 117.76399788508432
At time: 47.24180579185486 and batch: 1200, loss is 4.699164714813232 and perplexity is 109.85537355211527
At time: 47.645681381225586 and batch: 1250, loss is 4.672842569351197 and perplexity is 107.00146964324675
At time: 48.04094862937927 and batch: 1300, loss is 4.775557603836059 and perplexity is 118.57641485392755
At time: 48.430301904678345 and batch: 1350, loss is 4.7430916595458985 and perplexity is 114.7885407377838
At time: 48.825892210006714 and batch: 1400, loss is 4.60638355255127 and perplexity is 100.12141029902085
At time: 49.22277808189392 and batch: 1450, loss is 4.699216976165771 and perplexity is 109.86111489254456
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.003207214877137 and perplexity of 148.88991611683858
Annealing...
Finished 4 epochs...
Completing Train Step...
At time: 50.56590938568115 and batch: 50, loss is 4.737952861785889 and perplexity is 114.20017867334617
At time: 50.972166776657104 and batch: 100, loss is 4.7140424442291256 and perplexity is 111.50199066394809
At time: 51.37961196899414 and batch: 150, loss is 4.588618783950806 and perplexity is 98.3584819827669
At time: 51.77771329879761 and batch: 200, loss is 4.662506437301635 and perplexity is 105.90118446574762
At time: 52.16979908943176 and batch: 250, loss is 4.701045246124267 and perplexity is 110.06215438974704
At time: 52.56670570373535 and batch: 300, loss is 4.689226274490356 and perplexity is 108.76898989953288
At time: 52.970428705215454 and batch: 350, loss is 4.685720958709717 and perplexity is 108.38838769795792
At time: 53.37419939041138 and batch: 400, loss is 4.560079860687256 and perplexity is 95.59111349726669
At time: 53.76607823371887 and batch: 450, loss is 4.601078462600708 and perplexity is 99.59166363070172
At time: 54.17219591140747 and batch: 500, loss is 4.5972813129425045 and perplexity is 99.21421624480642
At time: 54.57371401786804 and batch: 550, loss is 4.644938793182373 and perplexity is 104.05699659288501
At time: 54.96997570991516 and batch: 600, loss is 4.5485718631744385 and perplexity is 94.49735674673089
At time: 55.38250803947449 and batch: 650, loss is 4.643433294296265 and perplexity is 103.90045676525753
At time: 55.78228950500488 and batch: 700, loss is 4.657516536712646 and perplexity is 105.37406431531653
At time: 56.19583868980408 and batch: 750, loss is 4.628483657836914 and perplexity is 102.35873550819
At time: 56.60774207115173 and batch: 800, loss is 4.541412420272827 and perplexity is 93.8232244022962
At time: 57.001198291778564 and batch: 850, loss is 4.484272918701172 and perplexity is 88.61249889411918
At time: 57.39820313453674 and batch: 900, loss is 4.439999465942383 and perplexity is 84.77489639913674
At time: 57.790748834609985 and batch: 950, loss is 4.535112390518188 and perplexity is 93.23399333242072
At time: 58.204713582992554 and batch: 1000, loss is 4.559183540344239 and perplexity is 95.50547162463742
At time: 58.59895968437195 and batch: 1050, loss is 4.452636766433716 and perplexity is 85.85302017801959
At time: 59.0077178478241 and batch: 1100, loss is 4.60717080116272 and perplexity is 100.2002617740399
At time: 59.400415897369385 and batch: 1150, loss is 4.5438878631591795 and perplexity is 94.05576613886349
At time: 59.79202604293823 and batch: 1200, loss is 4.471651763916015 and perplexity is 87.50113493069941
At time: 60.19649577140808 and batch: 1250, loss is 4.446531295776367 and perplexity is 85.33044399258957
At time: 60.60694694519043 and batch: 1300, loss is 4.527060461044312 and perplexity is 92.48629404417188
At time: 61.00306582450867 and batch: 1350, loss is 4.490977869033814 and perplexity is 89.20863760492874
At time: 61.414132595062256 and batch: 1400, loss is 4.351447124481201 and perplexity is 77.5906650713812
At time: 61.82153582572937 and batch: 1450, loss is 4.438321695327759 and perplexity is 84.63278281943094
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.877191527276977 and perplexity of 131.26150139084015
Finished 5 epochs...
Completing Train Step...
At time: 63.17498850822449 and batch: 50, loss is 4.571152257919311 and perplexity is 96.65541760324254
At time: 63.587456703186035 and batch: 100, loss is 4.585471038818359 and perplexity is 98.0493613216373
At time: 63.98922276496887 and batch: 150, loss is 4.456380414962768 and perplexity is 86.1750260730981
At time: 64.38566374778748 and batch: 200, loss is 4.5402197170257566 and perplexity is 93.71138784507107
At time: 64.78817844390869 and batch: 250, loss is 4.592026824951172 and perplexity is 98.69426357581472
At time: 65.17567920684814 and batch: 300, loss is 4.580208234786987 and perplexity is 97.53470221050289
At time: 65.57048058509827 and batch: 350, loss is 4.58291934967041 and perplexity is 97.79948876451488
At time: 65.97351169586182 and batch: 400, loss is 4.452577929496766 and perplexity is 85.84796899788384
At time: 66.36874437332153 and batch: 450, loss is 4.49445086479187 and perplexity is 89.51899745217354
At time: 66.75543308258057 and batch: 500, loss is 4.499342174530029 and perplexity is 89.95793521130089
At time: 67.14036154747009 and batch: 550, loss is 4.539959316253662 and perplexity is 93.68698850426362
At time: 67.53307223320007 and batch: 600, loss is 4.4504380035400395 and perplexity is 85.66445712163612
At time: 67.93152284622192 and batch: 650, loss is 4.547297954559326 and perplexity is 94.37705239451084
At time: 68.34791946411133 and batch: 700, loss is 4.568964929580688 and perplexity is 96.44423152008969
At time: 68.7344958782196 and batch: 750, loss is 4.539411478042602 and perplexity is 93.63567724849848
At time: 69.12107229232788 and batch: 800, loss is 4.460272607803344 and perplexity is 86.51108948015315
At time: 69.52686619758606 and batch: 850, loss is 4.411502003669739 and perplexity is 82.39312538734498
At time: 69.9286253452301 and batch: 900, loss is 4.355092968940735 and perplexity is 77.87406486961864
At time: 70.32144451141357 and batch: 950, loss is 4.464459095001221 and perplexity is 86.87402623368291
At time: 70.70762801170349 and batch: 1000, loss is 4.48663519859314 and perplexity is 88.82207385833698
At time: 71.12095880508423 and batch: 1050, loss is 4.389023685455323 and perplexity is 80.56172698685715
At time: 71.52708625793457 and batch: 1100, loss is 4.5413227367401126 and perplexity is 93.8148103813863
At time: 71.92360496520996 and batch: 1150, loss is 4.476702508926391 and perplexity is 87.94419881081325
At time: 72.3163583278656 and batch: 1200, loss is 4.410396795272828 and perplexity is 82.30211411579398
At time: 72.70311498641968 and batch: 1250, loss is 4.379503183364868 and perplexity is 79.79837839342302
At time: 73.09219098091125 and batch: 1300, loss is 4.469544715881348 and perplexity is 87.3169599372309
At time: 73.4805097579956 and batch: 1350, loss is 4.432110614776612 and perplexity is 84.10875087503409
At time: 73.8746817111969 and batch: 1400, loss is 4.2974788856506345 and perplexity is 73.5142221140394
At time: 74.27365279197693 and batch: 1450, loss is 4.380128107070923 and perplexity is 79.84826187684807
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.866632445245727 and perplexity of 129.88279219169243
Finished 6 epochs...
Completing Train Step...
At time: 75.58665752410889 and batch: 50, loss is 4.4993232727050785 and perplexity is 89.95623485822657
At time: 76.00187349319458 and batch: 100, loss is 4.521590051651001 and perplexity is 91.98173747622772
At time: 76.40460276603699 and batch: 150, loss is 4.391211338043213 and perplexity is 80.73816097515527
At time: 76.81889843940735 and batch: 200, loss is 4.467447252273559 and perplexity is 87.13400772629464
At time: 77.21014285087585 and batch: 250, loss is 4.523900103569031 and perplexity is 92.19446567730375
At time: 77.60450839996338 and batch: 300, loss is 4.508053617477417 and perplexity is 90.74502198470789
At time: 77.9976453781128 and batch: 350, loss is 4.512974271774292 and perplexity is 91.19264726850545
At time: 78.39992880821228 and batch: 400, loss is 4.385495190620422 and perplexity is 80.27796626781732
At time: 78.79387044906616 and batch: 450, loss is 4.423474321365356 and perplexity is 83.38549066311649
At time: 79.18368434906006 and batch: 500, loss is 4.435439567565918 and perplexity is 84.38921149694582
At time: 79.57508707046509 and batch: 550, loss is 4.479367332458496 and perplexity is 88.17886711725852
At time: 79.96357154846191 and batch: 600, loss is 4.3834481620788575 and perplexity is 80.1138030603187
At time: 80.36036682128906 and batch: 650, loss is 4.4811273956298825 and perplexity is 88.33420415516542
At time: 80.7598888874054 and batch: 700, loss is 4.510586175918579 and perplexity is 90.97513031453519
At time: 81.14915251731873 and batch: 750, loss is 4.482963418960571 and perplexity is 88.49653679254519
At time: 81.54503989219666 and batch: 800, loss is 4.402286729812622 and perplexity is 81.63733791574967
At time: 81.9483745098114 and batch: 850, loss is 4.35639078617096 and perplexity is 77.97519678396961
At time: 82.34506869316101 and batch: 900, loss is 4.296684832572937 and perplexity is 73.4558710896864
At time: 82.73415923118591 and batch: 950, loss is 4.415167932510376 and perplexity is 82.6957270411482
At time: 83.12289047241211 and batch: 1000, loss is 4.436400575637817 and perplexity is 84.47034919112062
At time: 83.52977228164673 and batch: 1050, loss is 4.335824775695801 and perplexity is 76.38793582819704
At time: 83.93565535545349 and batch: 1100, loss is 4.493341064453125 and perplexity is 89.41970434642944
At time: 84.33801436424255 and batch: 1150, loss is 4.420305328369141 and perplexity is 83.12166088537089
At time: 84.72436666488647 and batch: 1200, loss is 4.362324223518372 and perplexity is 78.439233032351
At time: 85.1279559135437 and batch: 1250, loss is 4.335555181503296 and perplexity is 76.3673448600478
At time: 85.5201735496521 and batch: 1300, loss is 4.421484727859497 and perplexity is 83.2197523630057
At time: 85.90945982933044 and batch: 1350, loss is 4.386995801925659 and perplexity is 80.39852272312733
At time: 86.29644703865051 and batch: 1400, loss is 4.262806782722473 and perplexity is 71.0090108751157
At time: 86.69395041465759 and batch: 1450, loss is 4.340618019104004 and perplexity is 76.75496071517684
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.876698551014957 and perplexity of 131.19680853386905
Annealing...
Finished 7 epochs...
Completing Train Step...
At time: 88.02147507667542 and batch: 50, loss is 4.439565439224243 and perplexity is 84.7381098128301
At time: 88.42271685600281 and batch: 100, loss is 4.429952383041382 and perplexity is 83.92742044661352
At time: 88.8374514579773 and batch: 150, loss is 4.294052104949952 and perplexity is 73.26273613621723
At time: 89.23533344268799 and batch: 200, loss is 4.364270162582398 and perplexity is 78.59201960853159
At time: 89.62867546081543 and batch: 250, loss is 4.416063575744629 and perplexity is 82.76982608777578
At time: 90.0403323173523 and batch: 300, loss is 4.399136419296265 and perplexity is 81.38055962961923
At time: 90.44055700302124 and batch: 350, loss is 4.405033893585205 and perplexity is 81.8619173900198
At time: 90.84278559684753 and batch: 400, loss is 4.259723091125489 and perplexity is 70.79037825600605
At time: 91.23155212402344 and batch: 450, loss is 4.300929269790649 and perplexity is 73.76831252276341
At time: 91.63171124458313 and batch: 500, loss is 4.306260986328125 and perplexity is 74.16267463386029
At time: 92.03399109840393 and batch: 550, loss is 4.349538040161133 and perplexity is 77.44267925295837
At time: 92.4233775138855 and batch: 600, loss is 4.2614575242996215 and perplexity is 70.91326597592524
At time: 92.81550765037537 and batch: 650, loss is 4.342617564201355 and perplexity is 76.90858926299082
At time: 93.20383667945862 and batch: 700, loss is 4.38376823425293 and perplexity is 80.1394493635525
At time: 93.601886510849 and batch: 750, loss is 4.342153663635254 and perplexity is 76.87291959912201
At time: 94.00389170646667 and batch: 800, loss is 4.27500048160553 and perplexity is 71.88017392753997
At time: 94.39545702934265 and batch: 850, loss is 4.214360513687134 and perplexity is 67.65089021696548
At time: 94.78928899765015 and batch: 900, loss is 4.154674224853515 and perplexity is 63.73119912483668
At time: 95.19574522972107 and batch: 950, loss is 4.270522971153259 and perplexity is 71.55904915372889
At time: 95.5968382358551 and batch: 1000, loss is 4.290118899345398 and perplexity is 72.9751446807593
At time: 95.98829245567322 and batch: 1050, loss is 4.189822325706482 and perplexity is 66.01106144971705
At time: 96.38737440109253 and batch: 1100, loss is 4.336900281906128 and perplexity is 76.47013572289949
At time: 96.78085899353027 and batch: 1150, loss is 4.271802988052368 and perplexity is 71.65070459367152
At time: 97.18161869049072 and batch: 1200, loss is 4.206014924049377 and perplexity is 67.08865301234174
At time: 97.58376264572144 and batch: 1250, loss is 4.185029339790344 and perplexity is 65.6954283785571
At time: 97.98201823234558 and batch: 1300, loss is 4.256901450157166 and perplexity is 70.59091476407441
At time: 98.38076305389404 and batch: 1350, loss is 4.2231677579879765 and perplexity is 68.24933961093342
At time: 98.77697134017944 and batch: 1400, loss is 4.101958689689636 and perplexity is 60.45859131886602
At time: 99.16972517967224 and batch: 1450, loss is 4.173669347763061 and perplexity is 64.95335180827081
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8005391960470085 and perplexity of 121.57595312221272
Finished 8 epochs...
Completing Train Step...
At time: 100.45292711257935 and batch: 50, loss is 4.354114680290222 and perplexity is 77.79791880827419
At time: 100.84020972251892 and batch: 100, loss is 4.365496273040772 and perplexity is 78.68844120540291
At time: 101.23281168937683 and batch: 150, loss is 4.233357639312744 and perplexity is 68.94834763811265
At time: 101.61944675445557 and batch: 200, loss is 4.3085337829589845 and perplexity is 74.33142300362618
At time: 102.02154779434204 and batch: 250, loss is 4.359603457450866 and perplexity is 78.22610829150945
At time: 102.41328167915344 and batch: 300, loss is 4.349082136154175 and perplexity is 77.40738087212542
At time: 102.80389857292175 and batch: 350, loss is 4.356884021759033 and perplexity is 78.0136664125255
At time: 103.19167423248291 and batch: 400, loss is 4.207437801361084 and perplexity is 67.18417987997546
At time: 103.57853841781616 and batch: 450, loss is 4.254564208984375 and perplexity is 70.4261194299018
At time: 103.9794352054596 and batch: 500, loss is 4.266204719543457 and perplexity is 71.25070540661406
At time: 104.38199043273926 and batch: 550, loss is 4.309411182403564 and perplexity is 74.39666997252577
At time: 104.77522659301758 and batch: 600, loss is 4.220623664855957 and perplexity is 68.07592761642925
At time: 105.1795563697815 and batch: 650, loss is 4.302791423797608 and perplexity is 73.90580846108854
At time: 105.57444190979004 and batch: 700, loss is 4.348150615692139 and perplexity is 77.33530788687229
At time: 105.97988271713257 and batch: 750, loss is 4.303884100914002 and perplexity is 73.98660778250817
At time: 106.37284588813782 and batch: 800, loss is 4.2439840078353885 and perplexity is 69.68492482831651
At time: 106.76237082481384 and batch: 850, loss is 4.183531222343444 and perplexity is 65.59708259628133
At time: 107.14941596984863 and batch: 900, loss is 4.122642230987549 and perplexity is 61.72211107566546
At time: 107.53790712356567 and batch: 950, loss is 4.242701826095581 and perplexity is 69.59563334634846
At time: 107.93063950538635 and batch: 1000, loss is 4.264082188606262 and perplexity is 71.09963396371369
At time: 108.31711983680725 and batch: 1050, loss is 4.163718028068542 and perplexity is 64.31018572251725
At time: 108.74080729484558 and batch: 1100, loss is 4.312775816917419 and perplexity is 74.64740916235067
At time: 109.14154076576233 and batch: 1150, loss is 4.245720477104187 and perplexity is 69.8060356809839
At time: 109.53813409805298 and batch: 1200, loss is 4.180453729629517 and perplexity is 65.39551836784246
At time: 109.93074989318848 and batch: 1250, loss is 4.161653361320496 and perplexity is 64.1775435985061
At time: 110.33585572242737 and batch: 1300, loss is 4.235584692955017 and perplexity is 69.10207041775121
At time: 110.73488783836365 and batch: 1350, loss is 4.201702179908753 and perplexity is 66.7999398376861
At time: 111.12406158447266 and batch: 1400, loss is 4.084150366783142 and perplexity is 59.39145535525309
At time: 111.51983857154846 and batch: 1450, loss is 4.156360554695129 and perplexity is 63.83876161519169
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.802615434695513 and perplexity of 121.82863603906127
Annealing...
Finished 9 epochs...
Completing Train Step...
At time: 112.81070399284363 and batch: 50, loss is 4.316797881126404 and perplexity is 74.94825043092645
At time: 113.22157263755798 and batch: 100, loss is 4.316647639274597 and perplexity is 74.93699091283865
At time: 113.61311459541321 and batch: 150, loss is 4.1778169631958 and perplexity is 65.22331279280675
At time: 114.00026488304138 and batch: 200, loss is 4.247846660614013 and perplexity is 69.95461401936903
At time: 114.39697408676147 and batch: 250, loss is 4.293660507202149 and perplexity is 73.23405223039143
At time: 114.80390739440918 and batch: 300, loss is 4.285040979385376 and perplexity is 72.60552198845761
At time: 115.21408081054688 and batch: 350, loss is 4.283476972579956 and perplexity is 72.49205521249095
At time: 115.61928200721741 and batch: 400, loss is 4.13726044178009 and perplexity is 62.63100492161669
At time: 116.02222013473511 and batch: 450, loss is 4.18181321144104 and perplexity is 65.4844828447108
At time: 116.41678023338318 and batch: 500, loss is 4.189759888648987 and perplexity is 66.00694004194364
At time: 116.80798864364624 and batch: 550, loss is 4.229367117881775 and perplexity is 68.67375602547934
At time: 117.19643354415894 and batch: 600, loss is 4.145639462471008 and perplexity is 63.15799615974609
At time: 117.59129524230957 and batch: 650, loss is 4.222785587310791 and perplexity is 68.22326169802108
At time: 117.99888706207275 and batch: 700, loss is 4.271978011131287 and perplexity is 71.66324621810105
At time: 118.38657093048096 and batch: 750, loss is 4.2237417078018185 and perplexity is 68.28852255014266
At time: 118.78980135917664 and batch: 800, loss is 4.161047048568726 and perplexity is 64.1386437293801
At time: 119.17545533180237 and batch: 850, loss is 4.098670029640198 and perplexity is 60.260090145293894
At time: 119.56192541122437 and batch: 900, loss is 4.0372738265991215 and perplexity is 56.67163531677961
At time: 119.96872901916504 and batch: 950, loss is 4.156407690048217 and perplexity is 63.84177074867887
At time: 120.37391185760498 and batch: 1000, loss is 4.177104105949402 and perplexity is 65.17683444982832
At time: 120.76989674568176 and batch: 1050, loss is 4.0819287109375 and perplexity is 59.25965444362624
At time: 121.15662980079651 and batch: 1100, loss is 4.220218501091003 and perplexity is 68.04835130413198
At time: 121.54544615745544 and batch: 1150, loss is 4.149769992828369 and perplexity is 63.41941170093481
At time: 121.94976305961609 and batch: 1200, loss is 4.085242757797241 and perplexity is 59.456369496754604
At time: 122.34602904319763 and batch: 1250, loss is 4.070486516952514 and perplexity is 58.585458478184876
At time: 122.75034356117249 and batch: 1300, loss is 4.140331497192383 and perplexity is 62.823643859280374
At time: 123.1499834060669 and batch: 1350, loss is 4.099879431724548 and perplexity is 60.33301291150306
At time: 123.54040193557739 and batch: 1400, loss is 3.9840580940246584 and perplexity is 53.7346526436571
At time: 123.92690324783325 and batch: 1450, loss is 4.06259635925293 and perplexity is 58.125028791959046
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.758093679053152 and perplexity of 116.52358269108086
Finished 10 epochs...
Completing Train Step...
At time: 125.20590686798096 and batch: 50, loss is 4.26679151058197 and perplexity is 71.29252695108815
At time: 125.6184709072113 and batch: 100, loss is 4.27458508014679 and perplexity is 71.8503209993402
At time: 126.00646710395813 and batch: 150, loss is 4.141929674148559 and perplexity is 62.92412743307769
At time: 126.41478443145752 and batch: 200, loss is 4.212482018470764 and perplexity is 67.52392762995082
At time: 126.81099081039429 and batch: 250, loss is 4.259271912574768 and perplexity is 70.75844635977452
At time: 127.20875072479248 and batch: 300, loss is 4.2558196258544925 and perplexity is 70.51458908986328
At time: 127.61019659042358 and batch: 350, loss is 4.251888847351074 and perplexity is 70.23795590696442
At time: 128.00520539283752 and batch: 400, loss is 4.106910886764527 and perplexity is 60.75873675421746
At time: 128.40105748176575 and batch: 450, loss is 4.157831811904908 and perplexity is 63.93275397999892
At time: 128.7871880531311 and batch: 500, loss is 4.164986438751221 and perplexity is 64.39180920419736
At time: 129.20476245880127 and batch: 550, loss is 4.205940952301026 and perplexity is 67.08369053092784
At time: 129.59333062171936 and batch: 600, loss is 4.122796649932861 and perplexity is 61.731642874886475
At time: 129.99081540107727 and batch: 650, loss is 4.201711926460266 and perplexity is 66.80059090991367
At time: 130.393474817276 and batch: 700, loss is 4.2528652095794675 and perplexity is 70.30656708334159
At time: 130.7886312007904 and batch: 750, loss is 4.204443073272705 and perplexity is 66.98328249605736
At time: 131.17987155914307 and batch: 800, loss is 4.143074345588684 and perplexity is 62.99619612426224
At time: 131.57666492462158 and batch: 850, loss is 4.0833492803573606 and perplexity is 59.34389671839317
At time: 131.99132776260376 and batch: 900, loss is 4.023320665359497 and perplexity is 55.88637800260163
At time: 132.38609313964844 and batch: 950, loss is 4.141488127708435 and perplexity is 62.89634964165543
At time: 132.79933214187622 and batch: 1000, loss is 4.164582071304321 and perplexity is 64.36577651644863
At time: 133.19453620910645 and batch: 1050, loss is 4.073154544830322 and perplexity is 58.74197481677102
At time: 133.58243417739868 and batch: 1100, loss is 4.209831566810608 and perplexity is 67.34519568868002
At time: 133.98290586471558 and batch: 1150, loss is 4.137586765289306 and perplexity is 62.651446225986135
At time: 134.3840410709381 and batch: 1200, loss is 4.077463283538818 and perplexity is 58.995624700591726
At time: 134.78378462791443 and batch: 1250, loss is 4.063385372161865 and perplexity is 58.17090828738506
At time: 135.17444252967834 and batch: 1300, loss is 4.1328810119628905 and perplexity is 62.357316568081345
At time: 135.56466698646545 and batch: 1350, loss is 4.08945366859436 and perplexity is 59.707262839036154
At time: 135.9589536190033 and batch: 1400, loss is 3.978322162628174 and perplexity is 53.427316634247696
At time: 136.35585856437683 and batch: 1450, loss is 4.057774152755737 and perplexity is 57.845412625757405
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.757640871227297 and perplexity of 116.47083184484096
Finished 11 epochs...
Completing Train Step...
At time: 137.66470408439636 and batch: 50, loss is 4.24684024810791 and perplexity is 69.88424623640813
At time: 138.0536332130432 and batch: 100, loss is 4.253044834136963 and perplexity is 70.31919700363093
At time: 138.4573233127594 and batch: 150, loss is 4.123570017814636 and perplexity is 61.77940261031738
At time: 138.85985255241394 and batch: 200, loss is 4.192201752662658 and perplexity is 66.16831696354654
At time: 139.28268027305603 and batch: 250, loss is 4.238972735404968 and perplexity is 69.3365882195074
At time: 139.6873927116394 and batch: 300, loss is 4.236643142700196 and perplexity is 69.17525020830948
At time: 140.0980818271637 and batch: 350, loss is 4.231136536598205 and perplexity is 68.7953762215128
At time: 140.504558801651 and batch: 400, loss is 4.087518177032471 and perplexity is 59.591811699022564
At time: 140.9001123905182 and batch: 450, loss is 4.139590950012207 and perplexity is 62.77713720928164
At time: 141.29108238220215 and batch: 500, loss is 4.148959474563599 and perplexity is 63.36802993515294
At time: 141.69143629074097 and batch: 550, loss is 4.187070255279541 and perplexity is 65.82964411079992
At time: 142.09840202331543 and batch: 600, loss is 4.104935841560364 and perplexity is 60.638853928549935
At time: 142.49196338653564 and batch: 650, loss is 4.185248517990113 and perplexity is 65.70982896237149
At time: 142.89224410057068 and batch: 700, loss is 4.237486305236817 and perplexity is 69.23360078379925
At time: 143.29399275779724 and batch: 750, loss is 4.1895220804214475 and perplexity is 65.99124491481611
At time: 143.68748831748962 and batch: 800, loss is 4.12952832698822 and perplexity is 62.1486022020267
At time: 144.09001922607422 and batch: 850, loss is 4.070244002342224 and perplexity is 58.57125237121722
At time: 144.47947192192078 and batch: 900, loss is 4.010579147338867 and perplexity is 55.17881797703431
At time: 144.88655519485474 and batch: 950, loss is 4.129572901725769 and perplexity is 62.15137252140157
At time: 145.28192830085754 and batch: 1000, loss is 4.154147505760193 and perplexity is 63.697639524434315
At time: 145.67252707481384 and batch: 1050, loss is 4.064371790885925 and perplexity is 58.22831747060692
At time: 146.08347415924072 and batch: 1100, loss is 4.19790867805481 and perplexity is 66.54701418235352
At time: 146.47275018692017 and batch: 1150, loss is 4.12520661354065 and perplexity is 61.880593298122555
At time: 146.88082647323608 and batch: 1200, loss is 4.0677150535583495 and perplexity is 58.42331581459553
At time: 147.2708649635315 and batch: 1250, loss is 4.055834636688233 and perplexity is 57.733329247430454
At time: 147.65919017791748 and batch: 1300, loss is 4.123931455612182 and perplexity is 61.801736057363414
At time: 148.0484435558319 and batch: 1350, loss is 4.079888153076172 and perplexity is 59.13885498095444
At time: 148.4426610469818 and batch: 1400, loss is 3.971048827171326 and perplexity is 53.04013160798212
At time: 148.8411042690277 and batch: 1450, loss is 4.049714431762696 and perplexity is 57.38106849494809
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.760050455729167 and perplexity of 116.75181654841568
Annealing...
Finished 12 epochs...
Completing Train Step...
At time: 150.15205264091492 and batch: 50, loss is 4.231011037826538 and perplexity is 68.78674302803954
At time: 150.5491247177124 and batch: 100, loss is 4.234319596290589 and perplexity is 69.01470489352941
At time: 150.95217537879944 and batch: 150, loss is 4.100223507881164 and perplexity is 60.353775634476854
At time: 151.34950137138367 and batch: 200, loss is 4.164289779663086 and perplexity is 64.3469656872493
At time: 151.74827909469604 and batch: 250, loss is 4.209698796272278 and perplexity is 67.33625482434934
At time: 152.1505663394928 and batch: 300, loss is 4.204636068344116 and perplexity is 66.99621118699272
At time: 152.54492950439453 and batch: 350, loss is 4.198018622398377 and perplexity is 66.55433105236101
At time: 152.9527850151062 and batch: 400, loss is 4.053695921897888 and perplexity is 57.609986067230366
At time: 153.3520655632019 and batch: 450, loss is 4.106684761047363 and perplexity is 60.74499919456127
At time: 153.76224446296692 and batch: 500, loss is 4.108473043441773 and perplexity is 60.85372559494797
At time: 154.149498462677 and batch: 550, loss is 4.148446636199951 and perplexity is 63.33554070994604
At time: 154.54071855545044 and batch: 600, loss is 4.067633838653564 and perplexity is 58.41857116323522
At time: 154.92882680892944 and batch: 650, loss is 4.145885152816772 and perplexity is 63.17351537604309
At time: 155.3252592086792 and batch: 700, loss is 4.1980876541137695 and perplexity is 66.55892557058229
At time: 155.7278709411621 and batch: 750, loss is 4.147547254562378 and perplexity is 63.27860349560624
At time: 156.1297664642334 and batch: 800, loss is 4.087252812385559 and perplexity is 59.57600023694655
At time: 156.52698588371277 and batch: 850, loss is 4.026572055816651 and perplexity is 56.06838216167849
At time: 156.918550491333 and batch: 900, loss is 3.9650837421417235 and perplexity is 52.72468448278034
At time: 157.31433176994324 and batch: 950, loss is 4.082071962356568 and perplexity is 59.26814408128053
At time: 157.70042824745178 and batch: 1000, loss is 4.10746160030365 and perplexity is 60.79220662847858
At time: 158.1031312942505 and batch: 1050, loss is 4.01843822479248 and perplexity is 55.614181116780884
At time: 158.4883623123169 and batch: 1100, loss is 4.146136078834534 and perplexity is 63.189369243675145
At time: 158.87477850914001 and batch: 1150, loss is 4.073887462615967 and perplexity is 58.785043635901985
At time: 159.29307341575623 and batch: 1200, loss is 4.01634865283966 and perplexity is 55.4980926136202
At time: 159.6840741634369 and batch: 1250, loss is 4.0031795310974125 and perplexity is 54.77202281952209
At time: 160.08146786689758 and batch: 1300, loss is 4.070457439422608 and perplexity is 58.58375498253073
At time: 160.48082971572876 and batch: 1350, loss is 4.018383803367615 and perplexity is 55.611154596156325
At time: 160.88478422164917 and batch: 1400, loss is 3.911991834640503 and perplexity is 49.99844148490804
At time: 161.2833023071289 and batch: 1450, loss is 3.990966124534607 and perplexity is 54.10713835360758
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.738322983440171 and perplexity of 114.2424544555047
Finished 13 epochs...
Completing Train Step...
At time: 162.57975149154663 and batch: 50, loss is 4.203704814910889 and perplexity is 66.93384977695706
At time: 162.98806071281433 and batch: 100, loss is 4.210288162231445 and perplexity is 67.37595221775773
At time: 163.37574362754822 and batch: 150, loss is 4.078707423210144 and perplexity is 59.06906917583541
At time: 163.76993823051453 and batch: 200, loss is 4.143929500579834 and perplexity is 63.050090676614666
At time: 164.16671776771545 and batch: 250, loss is 4.18996753692627 and perplexity is 66.02064769246783
At time: 164.56947779655457 and batch: 300, loss is 4.186368975639343 and perplexity is 65.78349530516377
At time: 164.95686531066895 and batch: 350, loss is 4.180469498634339 and perplexity is 65.39654959821765
At time: 165.34541845321655 and batch: 400, loss is 4.037355861663818 and perplexity is 56.67628456874753
At time: 165.75665187835693 and batch: 450, loss is 4.091593799591064 and perplexity is 59.83518103499061
At time: 166.1479685306549 and batch: 500, loss is 4.093942852020263 and perplexity is 59.975902228374174
At time: 166.5491759777069 and batch: 550, loss is 4.135106320381165 and perplexity is 62.496235340811374
At time: 166.95189785957336 and batch: 600, loss is 4.054718632698059 and perplexity is 57.66893456067142
At time: 167.35693669319153 and batch: 650, loss is 4.1340220928192135 and perplexity is 62.42851192037055
At time: 167.7453854084015 and batch: 700, loss is 4.187314538955689 and perplexity is 65.84572718259878
At time: 168.1328706741333 and batch: 750, loss is 4.136466422080994 and perplexity is 62.58129440810994
At time: 168.52410364151 and batch: 800, loss is 4.077931656837463 and perplexity is 59.023263147988494
At time: 168.91194367408752 and batch: 850, loss is 4.0174942350387575 and perplexity is 55.56170667121116
At time: 169.33269906044006 and batch: 900, loss is 3.95709680557251 and perplexity is 52.3052529882216
At time: 169.7395532131195 and batch: 950, loss is 4.073575005531311 and perplexity is 58.76667870182246
At time: 170.13840508460999 and batch: 1000, loss is 4.101198716163635 and perplexity is 60.41266184484713
At time: 170.53853964805603 and batch: 1050, loss is 4.0122285747528075 and perplexity is 55.26990653340407
At time: 170.93400502204895 and batch: 1100, loss is 4.140624384880066 and perplexity is 62.842046825931774
At time: 171.34047985076904 and batch: 1150, loss is 4.068872022628784 and perplexity is 58.49094890113554
At time: 171.72700214385986 and batch: 1200, loss is 4.012665963172912 and perplexity is 55.29408623807798
At time: 172.1229431629181 and batch: 1250, loss is 4.000523061752319 and perplexity is 54.62671570732847
At time: 172.51218366622925 and batch: 1300, loss is 4.0681933450698855 and perplexity is 58.45126587423075
At time: 172.9006896018982 and batch: 1350, loss is 4.014639925956726 and perplexity is 55.40334250490257
At time: 173.30016803741455 and batch: 1400, loss is 3.9094950199127196 and perplexity is 49.873760357452674
At time: 173.69307160377502 and batch: 1450, loss is 3.9882439041137694 and perplexity is 53.96004709491715
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.737445537860577 and perplexity of 114.14225688422728
Finished 14 epochs...
Completing Train Step...
At time: 174.97933721542358 and batch: 50, loss is 4.192291297912598 and perplexity is 66.17424228731545
At time: 175.3978419303894 and batch: 100, loss is 4.199223594665527 and perplexity is 66.63457551200281
At time: 175.79398584365845 and batch: 150, loss is 4.067524452209472 and perplexity is 58.412181312954615
At time: 176.20186710357666 and batch: 200, loss is 4.132928624153137 and perplexity is 62.36028560718171
At time: 176.58989930152893 and batch: 250, loss is 4.177318577766418 and perplexity is 65.19081454305454
At time: 176.99141788482666 and batch: 300, loss is 4.174921789169312 and perplexity is 65.03475304004625
At time: 177.3878562450409 and batch: 350, loss is 4.169284110069275 and perplexity is 64.66913954620307
At time: 177.78452253341675 and batch: 400, loss is 4.027266616821289 and perplexity is 56.1073386007668
At time: 178.17589378356934 and batch: 450, loss is 4.081409916877747 and perplexity is 59.228918860326225
At time: 178.58167457580566 and batch: 500, loss is 4.0834368181228635 and perplexity is 59.34909177788676
At time: 178.9713671207428 and batch: 550, loss is 4.1252441453933715 and perplexity is 61.88291583502084
At time: 179.36106252670288 and batch: 600, loss is 4.045519933700562 and perplexity is 57.14088778524469
At time: 179.79135179519653 and batch: 650, loss is 4.125081987380981 and perplexity is 61.87288183795661
At time: 180.1977617740631 and batch: 700, loss is 4.178982157707214 and perplexity is 65.29935493222749
At time: 180.63089966773987 and batch: 750, loss is 4.1283850002288816 and perplexity is 62.07758664680188
At time: 181.0294964313507 and batch: 800, loss is 4.070771226882934 and perplexity is 58.60214071467833
At time: 181.4381651878357 and batch: 850, loss is 4.011179494857788 and perplexity is 55.21195438918997
At time: 181.83953547477722 and batch: 900, loss is 3.9510154247283937 and perplexity is 51.98813007460931
At time: 182.22854447364807 and batch: 950, loss is 4.066711039543152 and perplexity is 58.364687423491524
At time: 182.6434681415558 and batch: 1000, loss is 4.095409154891968 and perplexity is 60.06390957298746
At time: 183.04166674613953 and batch: 1050, loss is 4.006482238769531 and perplexity is 54.953217851912996
At time: 183.46426630020142 and batch: 1100, loss is 4.135299911499024 and perplexity is 62.50833522805054
At time: 183.86573362350464 and batch: 1150, loss is 4.063816542625427 and perplexity is 58.195995272872096
At time: 184.27428221702576 and batch: 1200, loss is 4.008149442672729 and perplexity is 55.04491248679628
At time: 184.6717882156372 and batch: 1250, loss is 3.9963859605789183 and perplexity is 54.40118629834055
At time: 185.07008743286133 and batch: 1300, loss is 4.0648522424697875 and perplexity is 58.25630007956743
At time: 185.48112797737122 and batch: 1350, loss is 4.010577511787415 and perplexity is 55.17872772931223
At time: 185.88067412376404 and batch: 1400, loss is 3.9059982395172117 and perplexity is 49.69966732992042
At time: 186.279465675354 and batch: 1450, loss is 3.984745750427246 and perplexity is 53.77161632928928
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.737462752904648 and perplexity of 114.1442218651235
Annealing...
Finished 15 epochs...
Completing Train Step...
At time: 187.57576537132263 and batch: 50, loss is 4.185345664024353 and perplexity is 65.71621272173921
At time: 187.97561192512512 and batch: 100, loss is 4.1898663091659545 and perplexity is 66.01396490841468
At time: 188.36877727508545 and batch: 150, loss is 4.055173482894897 and perplexity is 57.69517125333788
At time: 188.75942850112915 and batch: 200, loss is 4.1208924961090085 and perplexity is 61.614208173404386
At time: 189.1674942970276 and batch: 250, loss is 4.162842063903809 and perplexity is 64.25387697022208
At time: 189.56178855895996 and batch: 300, loss is 4.159620213508606 and perplexity is 64.04719372135226
At time: 189.97014236450195 and batch: 350, loss is 4.152395377159118 and perplexity is 63.58613078575501
At time: 190.36589074134827 and batch: 400, loss is 4.010056376457214 and perplexity is 55.14997963629107
At time: 190.76607012748718 and batch: 450, loss is 4.065013527870178 and perplexity is 58.26569672800178
At time: 191.1710262298584 and batch: 500, loss is 4.062904267311096 and perplexity is 58.142928712328704
At time: 191.56440424919128 and batch: 550, loss is 4.105791416168213 and perplexity is 60.69075719261153
At time: 191.96169924736023 and batch: 600, loss is 4.025184297561646 and perplexity is 55.99062676681332
At time: 192.35051727294922 and batch: 650, loss is 4.105625548362732 and perplexity is 60.680691384722834
At time: 192.74905252456665 and batch: 700, loss is 4.157498817443848 and perplexity is 63.91146827125155
At time: 193.14484286308289 and batch: 750, loss is 4.106324439048767 and perplexity is 60.7231153778938
At time: 193.54043626785278 and batch: 800, loss is 4.046876039505005 and perplexity is 57.21842944030213
At time: 193.9387607574463 and batch: 850, loss is 3.987014193534851 and perplexity is 53.8937326363179
At time: 194.3322877883911 and batch: 900, loss is 3.926526527404785 and perplexity is 50.73046041875178
At time: 194.72636580467224 and batch: 950, loss is 4.040347590446472 and perplexity is 56.846098532588236
At time: 195.1180546283722 and batch: 1000, loss is 4.070904335975647 and perplexity is 58.60994171164017
At time: 195.51770639419556 and batch: 1050, loss is 3.9786862659454347 and perplexity is 53.44677323935885
At time: 195.91555762290955 and batch: 1100, loss is 4.108922595977783 and perplexity is 60.8810886917288
At time: 196.3029763698578 and batch: 1150, loss is 4.033692674636841 and perplexity is 56.46904854228044
At time: 196.70598077774048 and batch: 1200, loss is 3.979810886383057 and perplexity is 53.506914384510544
At time: 197.11105179786682 and batch: 1250, loss is 3.9671348476409913 and perplexity is 52.83293935620057
At time: 197.50918459892273 and batch: 1300, loss is 4.033950877189636 and perplexity is 56.48363087728504
At time: 197.90499567985535 and batch: 1350, loss is 3.976370177268982 and perplexity is 53.32312901383327
At time: 198.30566883087158 and batch: 1400, loss is 3.8722861766815186 and perplexity is 48.05211622939405
At time: 198.69168758392334 and batch: 1450, loss is 3.9506154108047484 and perplexity is 51.96733825750059
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.726818638989049 and perplexity of 112.93570099184977
Finished 16 epochs...
Completing Train Step...
At time: 199.96889305114746 and batch: 50, loss is 4.170044918060302 and perplexity is 64.71835906527026
At time: 200.3758623600006 and batch: 100, loss is 4.175919256210327 and perplexity is 65.09965542633873
At time: 200.7683970928192 and batch: 150, loss is 4.042370934486389 and perplexity is 56.96123418748755
At time: 201.1676845550537 and batch: 200, loss is 4.109821019172668 and perplexity is 60.935810251817934
At time: 201.5627646446228 and batch: 250, loss is 4.151240429878235 and perplexity is 63.51273454945249
At time: 201.95885229110718 and batch: 300, loss is 4.149751124382019 and perplexity is 63.418215086456726
At time: 202.35551285743713 and batch: 350, loss is 4.142527666091919 and perplexity is 62.9617668072252
At time: 202.7470531463623 and batch: 400, loss is 4.001286125183105 and perplexity is 54.66841526410875
At time: 203.14923548698425 and batch: 450, loss is 4.055914025306702 and perplexity is 57.737912798617536
At time: 203.54525327682495 and batch: 500, loss is 4.054313364028931 and perplexity is 57.645567883522894
At time: 203.95000958442688 and batch: 550, loss is 4.098033289909363 and perplexity is 60.22173236497203
At time: 204.34694266319275 and batch: 600, loss is 4.017649626731872 and perplexity is 55.57034116973045
At time: 204.73468208312988 and batch: 650, loss is 4.098897352218628 and perplexity is 60.27379018146689
At time: 205.13049960136414 and batch: 700, loss is 4.150799226760864 and perplexity is 63.48471871376804
At time: 205.51865601539612 and batch: 750, loss is 4.1001291084289555 and perplexity is 60.34807854002375
At time: 205.9142472743988 and batch: 800, loss is 4.041208701133728 and perplexity is 56.89507039763555
At time: 206.30208206176758 and batch: 850, loss is 3.9823306369781495 and perplexity is 53.641908468159066
At time: 206.69383764266968 and batch: 900, loss is 3.9224803495407103 and perplexity is 50.525610661523366
At time: 207.1076946258545 and batch: 950, loss is 4.036589708328247 and perplexity is 56.632878474262675
At time: 207.4974400997162 and batch: 1000, loss is 4.067765464782715 and perplexity is 58.426261079713825
At time: 207.9075789451599 and batch: 1050, loss is 3.975639748573303 and perplexity is 53.28419449143543
At time: 208.30152225494385 and batch: 1100, loss is 4.106589479446411 and perplexity is 60.73921158951868
At time: 208.71179270744324 and batch: 1150, loss is 4.031055011749268 and perplexity is 56.32029849112973
At time: 209.10665726661682 and batch: 1200, loss is 3.9779508018493654 and perplexity is 53.40747950792607
At time: 209.4986686706543 and batch: 1250, loss is 3.9656516551971435 and perplexity is 52.754636023571514
At time: 209.90231895446777 and batch: 1300, loss is 4.033174715042114 and perplexity is 56.439807430293875
At time: 210.29644227027893 and batch: 1350, loss is 3.9751222133636475 and perplexity is 53.25662517932819
At time: 210.68487191200256 and batch: 1400, loss is 3.871532368659973 and perplexity is 48.01590780754206
At time: 211.07165360450745 and batch: 1450, loss is 3.9500675058364867 and perplexity is 51.93887289355124
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.72642582298344 and perplexity of 112.89134675299336
Finished 17 epochs...
Completing Train Step...
At time: 212.3535554409027 and batch: 50, loss is 4.163969550132752 and perplexity is 64.32636318758927
At time: 212.75401067733765 and batch: 100, loss is 4.16901355266571 and perplexity is 64.65164519843606
At time: 213.1505069732666 and batch: 150, loss is 4.035831489562988 and perplexity is 56.58995463795836
At time: 213.54947018623352 and batch: 200, loss is 4.1036859798431395 and perplexity is 60.563111090345366
At time: 213.93689799308777 and batch: 250, loss is 4.145286455154419 and perplexity is 63.135704859728044
At time: 214.34149289131165 and batch: 300, loss is 4.143904075622559 and perplexity is 63.04848765113156
At time: 214.74398565292358 and batch: 350, loss is 4.136732892990112 and perplexity is 62.59797272456908
At time: 215.1428678035736 and batch: 400, loss is 3.9963369798660278 and perplexity is 54.398521754709726
At time: 215.54205965995789 and batch: 450, loss is 4.050195622444153 and perplexity is 57.40868637460017
At time: 215.94443607330322 and batch: 500, loss is 4.04909321308136 and perplexity is 57.34543337299175
At time: 216.34835815429688 and batch: 550, loss is 4.09325156211853 and perplexity is 59.9344558202086
At time: 216.74332070350647 and batch: 600, loss is 4.01254367351532 and perplexity is 55.287324756643095
At time: 217.1366889476776 and batch: 650, loss is 4.0943769931793215 and perplexity is 60.0019458889866
At time: 217.5243215560913 and batch: 700, loss is 4.1458901596069335 and perplexity is 63.17383167337014
At time: 217.91769361495972 and batch: 750, loss is 4.095466918945313 and perplexity is 60.06737920807327
At time: 218.3148262500763 and batch: 800, loss is 4.0369783210754395 and perplexity is 56.65489100964688
At time: 218.70368766784668 and batch: 850, loss is 3.978733501434326 and perplexity is 53.44929788344841
At time: 219.10624504089355 and batch: 900, loss is 3.9193933486938475 and perplexity is 50.36987855486725
At time: 219.49507236480713 and batch: 950, loss is 4.033747181892395 and perplexity is 56.472126599027696
At time: 219.9063422679901 and batch: 1000, loss is 4.064793810844422 and perplexity is 58.252896168714976
At time: 220.3151364326477 and batch: 1050, loss is 3.9732722568511964 and perplexity is 53.1581938136916
At time: 220.72020387649536 and batch: 1100, loss is 4.10451021194458 and perplexity is 60.613049728356245
At time: 221.11893391609192 and batch: 1150, loss is 4.028629546165466 and perplexity is 56.183861074486394
At time: 221.50496292114258 and batch: 1200, loss is 3.97617223739624 and perplexity is 53.312575284998395
At time: 221.90408396720886 and batch: 1250, loss is 3.9635783338546755 and perplexity is 52.64537201962613
At time: 222.2982256412506 and batch: 1300, loss is 4.032025480270386 and perplexity is 56.374982097983114
At time: 222.70361828804016 and batch: 1350, loss is 3.973298258781433 and perplexity is 53.15957604730893
At time: 223.09654068946838 and batch: 1400, loss is 3.8701353597640993 and perplexity is 47.948875990115894
At time: 223.48684549331665 and batch: 1450, loss is 3.9485319900512694 and perplexity is 51.859181133992344
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.726179595686432 and perplexity of 112.86355324372747
Finished 18 epochs...
Completing Train Step...
At time: 224.8251941204071 and batch: 50, loss is 4.1588208103179936 and perplexity is 63.99601464942383
At time: 225.23772835731506 and batch: 100, loss is 4.163661198616028 and perplexity is 64.30653111371723
At time: 225.64345526695251 and batch: 150, loss is 4.0304112005233765 and perplexity is 56.284050520392896
At time: 226.04905772209167 and batch: 200, loss is 4.098584480285645 and perplexity is 60.25493515398287
At time: 226.45246815681458 and batch: 250, loss is 4.140013480186463 and perplexity is 62.80366804865134
At time: 226.84741377830505 and batch: 300, loss is 4.138674302101135 and perplexity is 62.71961904357635
At time: 227.25124883651733 and batch: 350, loss is 4.131849794387818 and perplexity is 62.29304575159524
At time: 227.63992285728455 and batch: 400, loss is 3.99210129737854 and perplexity is 54.168594182624204
At time: 228.02769827842712 and batch: 450, loss is 4.0452505970001225 and perplexity is 57.12549971944689
At time: 228.43170642852783 and batch: 500, loss is 4.044203691482544 and perplexity is 57.065726012767215
At time: 228.81950092315674 and batch: 550, loss is 4.089166488647461 and perplexity is 59.690118572327165
At time: 229.20874047279358 and batch: 600, loss is 4.008411712646485 and perplexity is 55.05935100786208
At time: 229.5984344482422 and batch: 650, loss is 4.090089449882507 and perplexity is 59.7452356694441
At time: 229.99727296829224 and batch: 700, loss is 4.141363916397094 and perplexity is 62.888537688764416
At time: 230.4115810394287 and batch: 750, loss is 4.091703004837036 and perplexity is 59.8417157074571
At time: 230.8061146736145 and batch: 800, loss is 4.033453121185302 and perplexity is 56.45552280693002
At time: 231.21557140350342 and batch: 850, loss is 3.975889048576355 and perplexity is 53.29747989724181
At time: 231.60565972328186 and batch: 900, loss is 3.916824426651001 and perplexity is 50.24064832581388
At time: 232.00593328475952 and batch: 950, loss is 4.030790095329285 and perplexity is 56.30538029540584
At time: 232.3948631286621 and batch: 1000, loss is 4.0620503616333 and perplexity is 58.09330132694613
At time: 232.78294157981873 and batch: 1050, loss is 3.9695307207107544 and perplexity is 52.95967212999771
At time: 233.1749575138092 and batch: 1100, loss is 4.102249631881714 and perplexity is 60.476183833032486
At time: 233.56283140182495 and batch: 1150, loss is 4.025982618331909 and perplexity is 56.035343093712726
At time: 233.96170711517334 and batch: 1200, loss is 3.9742680597305298 and perplexity is 53.211155261355984
At time: 234.35539031028748 and batch: 1250, loss is 3.961401524543762 and perplexity is 52.5308977231975
At time: 234.75543189048767 and batch: 1300, loss is 4.029853649139405 and perplexity is 56.252678016833805
At time: 235.15352392196655 and batch: 1350, loss is 3.971338849067688 and perplexity is 53.05551663842438
At time: 235.54416489601135 and batch: 1400, loss is 3.8678998517990113 and perplexity is 47.84180561884718
At time: 235.94469571113586 and batch: 1450, loss is 3.9466695737838746 and perplexity is 51.762687634857265
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.7260194436097755 and perplexity of 112.84547935862042
Finished 19 epochs...
Completing Train Step...
At time: 237.2540900707245 and batch: 50, loss is 4.153796310424805 and perplexity is 63.67527313827323
At time: 237.65692472457886 and batch: 100, loss is 4.158005399703979 and perplexity is 63.94385288934066
At time: 238.0440948009491 and batch: 150, loss is 4.024942326545715 and perplexity is 55.977080296964594
At time: 238.44083499908447 and batch: 200, loss is 4.093845596313477 and perplexity is 59.9700695132498
At time: 238.83713388442993 and batch: 250, loss is 4.13529589176178 and perplexity is 62.50808396147241
At time: 239.24037075042725 and batch: 300, loss is 4.134122877120972 and perplexity is 62.43480405142295
At time: 239.64729237556458 and batch: 350, loss is 4.12709171295166 and perplexity is 61.9973543866546
At time: 240.03346133232117 and batch: 400, loss is 3.9879947662353517 and perplexity is 53.946605277767034
At time: 240.44863963127136 and batch: 450, loss is 4.041250562667846 and perplexity is 56.89745216241798
At time: 240.84332036972046 and batch: 500, loss is 4.039813361167908 and perplexity is 56.815737792900094
At time: 241.24254417419434 and batch: 550, loss is 4.084916749000549 and perplexity is 59.43698935649906
At time: 241.63826537132263 and batch: 600, loss is 4.004300227165222 and perplexity is 54.8334400187006
At time: 242.0266854763031 and batch: 650, loss is 4.08591745376587 and perplexity is 59.496498005312574
At time: 242.43706631660461 and batch: 700, loss is 4.137229022979736 and perplexity is 62.62903716148956
At time: 242.83228206634521 and batch: 750, loss is 4.0881122207641605 and perplexity is 59.62722235792105
At time: 243.2458131313324 and batch: 800, loss is 4.03015634059906 and perplexity is 56.26970779930707
At time: 243.63839507102966 and batch: 850, loss is 3.973042769432068 and perplexity is 53.14599607665488
At time: 244.0327079296112 and batch: 900, loss is 3.913331208229065 and perplexity is 50.065452943573355
At time: 244.41941165924072 and batch: 950, loss is 4.027633352279663 and perplexity is 56.12791892484332
At time: 244.8065469264984 and batch: 1000, loss is 4.059122543334961 and perplexity is 57.92346344486218
At time: 245.19953870773315 and batch: 1050, loss is 3.9666448259353637 and perplexity is 52.807056411264256
At time: 245.58674502372742 and batch: 1100, loss is 4.099252786636352 and perplexity is 60.29521736873844
At time: 245.97547435760498 and batch: 1150, loss is 4.022805223464966 and perplexity is 55.857579244726224
At time: 246.36293363571167 and batch: 1200, loss is 3.971714148521423 and perplexity is 53.075432081730156
At time: 246.74952340126038 and batch: 1250, loss is 3.9586782026290894 and perplexity is 52.38803379875424
At time: 247.1486885547638 and batch: 1300, loss is 4.027417755126953 and perplexity is 56.1158192097145
At time: 247.5452573299408 and batch: 1350, loss is 3.9689589595794676 and perplexity is 52.92940050284266
At time: 247.93947553634644 and batch: 1400, loss is 3.8655210590362548 and perplexity is 47.728135130752904
At time: 248.3263761997223 and batch: 1450, loss is 3.9440617418289183 and perplexity is 51.62787510458345
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.725931281717415 and perplexity of 112.83553112614976
Finished 20 epochs...
Completing Train Step...
At time: 249.61651015281677 and batch: 50, loss is 4.1495494413375855 and perplexity is 63.40542599748013
At time: 250.02721571922302 and batch: 100, loss is 4.153450531959534 and perplexity is 63.65325940620834
At time: 250.4380805492401 and batch: 150, loss is 4.020496621131897 and perplexity is 55.72877504300927
At time: 250.8320610523224 and batch: 200, loss is 4.089503560066223 and perplexity is 59.710241796571786
At time: 251.22279119491577 and batch: 250, loss is 4.130677952766418 and perplexity is 62.220090921961244
At time: 251.6206386089325 and batch: 300, loss is 4.129931654930115 and perplexity is 62.17367352548724
At time: 252.00933957099915 and batch: 350, loss is 4.122855014801026 and perplexity is 61.73524593922959
At time: 252.39593863487244 and batch: 400, loss is 3.9840438032150267 and perplexity is 53.73388473745256
At time: 252.80419301986694 and batch: 450, loss is 4.036821031570435 and perplexity is 56.64598049066782
At time: 253.20404767990112 and batch: 500, loss is 4.036116194725037 and perplexity is 56.60606838388835
At time: 253.6144073009491 and batch: 550, loss is 4.081187686920166 and perplexity is 59.215757882636254
At time: 254.01114082336426 and batch: 600, loss is 4.000639753341675 and perplexity is 54.633090557544115
At time: 254.40315127372742 and batch: 650, loss is 4.082294278144836 and perplexity is 59.281321790203265
At time: 254.79163312911987 and batch: 700, loss is 4.133776350021362 and perplexity is 62.41317244804517
At time: 255.1799600124359 and batch: 750, loss is 4.0849154090881346 and perplexity is 59.43690971619248
At time: 255.5855357646942 and batch: 800, loss is 4.0267612075805665 and perplexity is 56.07898859814574
At time: 255.97904229164124 and batch: 850, loss is 3.9701452016830445 and perplexity is 52.99222484130688
At time: 256.37626791000366 and batch: 900, loss is 3.910262722969055 and perplexity is 49.91206329647051
At time: 256.762845993042 and batch: 950, loss is 4.0248021268844605 and perplexity is 55.96923287938443
At time: 257.16130352020264 and batch: 1000, loss is 4.056247692108155 and perplexity is 57.75718123774406
At time: 257.55873584747314 and batch: 1050, loss is 3.963972568511963 and perplexity is 52.66613074145699
At time: 257.94798398017883 and batch: 1100, loss is 4.096594443321228 and perplexity is 60.13514483884874
At time: 258.3489203453064 and batch: 1150, loss is 4.0202501773834225 and perplexity is 55.715042726981025
At time: 258.73773074150085 and batch: 1200, loss is 3.969466013908386 and perplexity is 52.95624538982761
At time: 259.1505391597748 and batch: 1250, loss is 3.956444573402405 and perplexity is 52.27114894264404
At time: 259.5580589771271 and batch: 1300, loss is 4.025156941413879 and perplexity is 55.98909509990429
At time: 259.9603202342987 and batch: 1350, loss is 3.9669986248016356 and perplexity is 52.825742793369194
At time: 260.35572719573975 and batch: 1400, loss is 3.8631200647354125 and perplexity is 47.613677611225306
At time: 260.7450132369995 and batch: 1450, loss is 3.9414916610717774 and perplexity is 51.495357659456225
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.7261373405782585 and perplexity of 112.85878428283351
Annealing...
Finished 21 epochs...
Completing Train Step...
At time: 262.066694021225 and batch: 50, loss is 4.146420168876648 and perplexity is 63.207323264403236
At time: 262.490079164505 and batch: 100, loss is 4.1495639610290525 and perplexity is 63.40634663138658
At time: 262.89694237709045 and batch: 150, loss is 4.015353870391846 and perplexity is 55.442911536335124
At time: 263.3034420013428 and batch: 200, loss is 4.084228682518005 and perplexity is 59.39610682286302
At time: 263.70889806747437 and batch: 250, loss is 4.124808449745178 and perplexity is 61.85595959067958
At time: 264.11461353302 and batch: 300, loss is 4.123458490371704 and perplexity is 61.77251289572168
At time: 264.51006150245667 and batch: 350, loss is 4.115549697875976 and perplexity is 61.28589373074898
At time: 264.89989042282104 and batch: 400, loss is 3.9762751388549806 and perplexity is 53.31806150902983
At time: 265.28899335861206 and batch: 450, loss is 4.02973135471344 and perplexity is 56.24579904850507
At time: 265.6897192001343 and batch: 500, loss is 4.026534180641175 and perplexity is 56.066258602080815
At time: 266.08711218833923 and batch: 550, loss is 4.070787048339843 and perplexity is 58.60306789325706
At time: 266.48220562934875 and batch: 600, loss is 3.9909736919403076 and perplexity is 54.107547805824055
At time: 266.8863489627838 and batch: 650, loss is 4.071717276573181 and perplexity is 58.65760748477262
At time: 267.2747275829315 and batch: 700, loss is 4.122449622154236 and perplexity is 61.71022399667653
At time: 267.67891001701355 and batch: 750, loss is 4.073939819335937 and perplexity is 58.788121508543014
At time: 268.08114981651306 and batch: 800, loss is 4.014704537391663 and perplexity is 55.40692231000902
At time: 268.48873233795166 and batch: 850, loss is 3.957186808586121 and perplexity is 52.30996083047504
At time: 268.8878049850464 and batch: 900, loss is 3.8964698696136475 and perplexity is 49.22835947911203
At time: 269.2781927585602 and batch: 950, loss is 4.010095934867859 and perplexity is 55.15216132498437
At time: 269.67937421798706 and batch: 1000, loss is 4.041945433616638 and perplexity is 56.93700228851134
At time: 270.07347774505615 and batch: 1050, loss is 3.949081506729126 and perplexity is 51.88768645028149
At time: 270.46594977378845 and batch: 1100, loss is 4.08239716053009 and perplexity is 59.287421107740826
At time: 270.87057876586914 and batch: 1150, loss is 4.003126626014709 and perplexity is 54.76912517777567
At time: 271.26106786727905 and batch: 1200, loss is 3.954049606323242 and perplexity is 52.14611105231861
At time: 271.6681113243103 and batch: 1250, loss is 3.9399554920196533 and perplexity is 51.41631281335913
At time: 272.0854377746582 and batch: 1300, loss is 4.007423033714295 and perplexity is 55.004941888507574
At time: 272.48445439338684 and batch: 1350, loss is 3.948729019165039 and perplexity is 51.86939990915704
At time: 272.87574434280396 and batch: 1400, loss is 3.843835196495056 and perplexity is 46.70425137950602
At time: 273.2747266292572 and batch: 1450, loss is 3.9218319606781007 and perplexity is 50.49286103668723
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.721523708767361 and perplexity of 112.33929469384381
Finished 22 epochs...
Completing Train Step...
At time: 274.5929522514343 and batch: 50, loss is 4.1385856628417965 and perplexity is 62.71405986938251
At time: 275.00139355659485 and batch: 100, loss is 4.142874727249145 and perplexity is 62.98362218323101
At time: 275.39946246147156 and batch: 150, loss is 4.009009299278259 and perplexity is 55.09226357305357
At time: 275.79900765419006 and batch: 200, loss is 4.078730373382569 and perplexity is 59.070424836714224
At time: 276.1929199695587 and batch: 250, loss is 4.118752641677856 and perplexity is 61.4825037014775
At time: 276.5795338153839 and batch: 300, loss is 4.118458275794983 and perplexity is 61.46440801350139
At time: 276.983003616333 and batch: 350, loss is 4.110733256340027 and perplexity is 60.991423525143574
At time: 277.37992000579834 and batch: 400, loss is 3.97201858997345 and perplexity is 53.09159290322723
At time: 277.78407192230225 and batch: 450, loss is 4.025357422828674 and perplexity is 56.00032099815738
At time: 278.1803889274597 and batch: 500, loss is 4.0222455549240115 and perplexity is 55.82632626132069
At time: 278.57069730758667 and batch: 550, loss is 4.066890172958374 and perplexity is 58.3751434257598
At time: 278.96894907951355 and batch: 600, loss is 3.987371954917908 and perplexity is 53.91301718207115
At time: 279.35666847229004 and batch: 650, loss is 4.068255038261413 and perplexity is 58.45487203060787
At time: 279.7454147338867 and batch: 700, loss is 4.119341411590576 and perplexity is 61.518713408362586
At time: 280.1315083503723 and batch: 750, loss is 4.070754904747009 and perplexity is 58.60118421037817
At time: 280.5184850692749 and batch: 800, loss is 4.011931848526001 and perplexity is 55.25350893550146
At time: 280.91937232017517 and batch: 850, loss is 3.9551912641525266 and perplexity is 52.20567806437118
At time: 281.3077199459076 and batch: 900, loss is 3.8944913244247434 and perplexity is 49.13105523746917
At time: 281.7047028541565 and batch: 950, loss is 4.008175101280212 and perplexity is 55.04632488071967
At time: 282.09896874427795 and batch: 1000, loss is 4.0402093029022215 and perplexity is 56.83823796874351
At time: 282.4883773326874 and batch: 1050, loss is 3.947953395843506 and perplexity is 51.82918439097658
At time: 282.8752267360687 and batch: 1100, loss is 4.081482644081116 and perplexity is 59.23322657059546
At time: 283.2690734863281 and batch: 1150, loss is 4.002363858222961 and perplexity is 54.727364981798786
At time: 283.6654043197632 and batch: 1200, loss is 3.9537542629241944 and perplexity is 52.130712316702684
At time: 284.05719208717346 and batch: 1250, loss is 3.9397600793838503 and perplexity is 51.40626639777924
At time: 284.4513900279999 and batch: 1300, loss is 4.0068832111358645 and perplexity is 54.975256991960485
At time: 284.84032917022705 and batch: 1350, loss is 3.9487932825088503 and perplexity is 51.87273331734352
At time: 285.23477005958557 and batch: 1400, loss is 3.8437588739395143 and perplexity is 46.700686927711835
At time: 285.63906741142273 and batch: 1450, loss is 3.922039623260498 and perplexity is 50.50334760339882
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.721271743122329 and perplexity of 112.31099261671915
Finished 23 epochs...
Completing Train Step...
At time: 286.9425141811371 and batch: 50, loss is 4.135188608169556 and perplexity is 62.50137822939591
At time: 287.3435318470001 and batch: 100, loss is 4.139684863090515 and perplexity is 62.78303308032973
At time: 287.7329318523407 and batch: 150, loss is 4.005544137954712 and perplexity is 54.90169036623615
At time: 288.13960552215576 and batch: 200, loss is 4.075695419311524 and perplexity is 58.891420582622395
At time: 288.5360531806946 and batch: 250, loss is 4.115529146194458 and perplexity is 61.28463421552208
At time: 288.9299418926239 and batch: 300, loss is 4.115446748733521 and perplexity is 61.279584725303714
At time: 289.32699155807495 and batch: 350, loss is 4.107767882347107 and perplexity is 60.8108290414608
At time: 289.72897720336914 and batch: 400, loss is 3.969654040336609 and perplexity is 52.96620349966492
At time: 290.12413334846497 and batch: 450, loss is 4.022622561454773 and perplexity is 55.84737711881564
At time: 290.5099587440491 and batch: 500, loss is 4.0196115589141845 and perplexity is 55.67947343049489
At time: 290.91689372062683 and batch: 550, loss is 4.064649543762207 and perplexity is 58.24449279953351
At time: 291.30393171310425 and batch: 600, loss is 3.985289707183838 and perplexity is 53.800873719960734
At time: 291.69087171554565 and batch: 650, loss is 4.0658793258667 and perplexity is 58.316164895961556
At time: 292.08237051963806 and batch: 700, loss is 4.117277140617371 and perplexity is 61.39185309604319
At time: 292.46904587745667 and batch: 750, loss is 4.068833742141724 and perplexity is 58.48870988197863
At time: 292.8597996234894 and batch: 800, loss is 4.0099921131134035 and perplexity is 55.14643562806467
At time: 293.24675822257996 and batch: 850, loss is 3.953520860671997 and perplexity is 52.118546310881115
At time: 293.6340301036835 and batch: 900, loss is 3.892958469390869 and perplexity is 49.055802142906096
At time: 294.04449248313904 and batch: 950, loss is 4.006522011756897 and perplexity is 54.955403549017895
At time: 294.44197034835815 and batch: 1000, loss is 4.038740544319153 and perplexity is 56.75481759607118
At time: 294.84897685050964 and batch: 1050, loss is 3.9468099594116213 and perplexity is 51.76995488235135
At time: 295.24085116386414 and batch: 1100, loss is 4.08062596321106 and perplexity is 59.18250432801029
At time: 295.6415321826935 and batch: 1150, loss is 4.001366677284241 and perplexity is 54.672819097190676
At time: 296.0327343940735 and batch: 1200, loss is 3.9531159830093383 and perplexity is 52.09744894688352
At time: 296.4211599826813 and batch: 1250, loss is 3.939224534034729 and perplexity is 51.37874338146374
At time: 296.81068754196167 and batch: 1300, loss is 4.006005563735962 and perplexity is 54.92702926716682
At time: 297.1998858451843 and batch: 1350, loss is 3.948238282203674 and perplexity is 51.84395192210242
At time: 297.5904622077942 and batch: 1400, loss is 3.8430267333984376 and perplexity is 46.66650797494116
At time: 297.977010011673 and batch: 1450, loss is 3.921763653755188 and perplexity is 50.48941214251378
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.721254006410256 and perplexity of 112.30900060664644
Finished 24 epochs...
Completing Train Step...
At time: 299.30255031585693 and batch: 50, loss is 4.132579245567322 and perplexity is 62.33850206435852
At time: 299.6897642612457 and batch: 100, loss is 4.137194948196411 and perplexity is 62.626903126977034
At time: 300.07772064208984 and batch: 150, loss is 4.002831835746765 and perplexity is 54.75298215220974
At time: 300.4668765068054 and batch: 200, loss is 4.073261051177979 and perplexity is 58.748231543147526
At time: 300.8674256801605 and batch: 250, loss is 4.112864122390747 and perplexity is 61.12152664585116
At time: 301.26969289779663 and batch: 300, loss is 4.112983484268188 and perplexity is 61.12882266144805
At time: 301.67013144493103 and batch: 350, loss is 4.105392603874207 and perplexity is 60.6665577983393
At time: 302.05767011642456 and batch: 400, loss is 3.9678302145004274 and perplexity is 52.86969040756618
At time: 302.45547223091125 and batch: 450, loss is 4.020400586128235 and perplexity is 55.72342338687125
At time: 302.8454134464264 and batch: 500, loss is 4.017349424362183 and perplexity is 55.55366132541652
At time: 303.24417090415955 and batch: 550, loss is 4.062627873420715 and perplexity is 58.12686058273247
At time: 303.6505961418152 and batch: 600, loss is 3.98337682723999 and perplexity is 53.69805747657659
At time: 304.05234599113464 and batch: 650, loss is 4.06391432762146 and perplexity is 58.20168624628035
At time: 304.4424433708191 and batch: 700, loss is 4.115425209999085 and perplexity is 61.27826485481619
At time: 304.8308711051941 and batch: 750, loss is 4.067198896408081 and perplexity is 58.39316798357406
At time: 305.2298414707184 and batch: 800, loss is 4.008171525001526 and perplexity is 55.04612802007325
At time: 305.62375473976135 and batch: 850, loss is 3.9518435525894167 and perplexity is 52.03120072510794
At time: 306.02643871307373 and batch: 900, loss is 3.89143714427948 and perplexity is 48.98122905858253
At time: 306.42486786842346 and batch: 950, loss is 4.004937195777893 and perplexity is 54.868378325038265
At time: 306.8234522342682 and batch: 1000, loss is 4.037333669662476 and perplexity is 56.67502682252031
At time: 307.2186462879181 and batch: 1050, loss is 3.945726294517517 and perplexity is 51.713883986194006
At time: 307.626993894577 and batch: 1100, loss is 4.079767513275146 and perplexity is 59.13172091159168
At time: 308.0218138694763 and batch: 1150, loss is 4.000211381912232 and perplexity is 54.60969231437433
At time: 308.41593527793884 and batch: 1200, loss is 3.9522347545623777 and perplexity is 52.0515594154074
At time: 308.82168459892273 and batch: 1250, loss is 3.9383403968811037 and perplexity is 51.33333760096017
At time: 309.2180685997009 and batch: 1300, loss is 4.005038909912109 and perplexity is 54.873959498472715
At time: 309.62140417099 and batch: 1350, loss is 3.947340989112854 and perplexity is 51.79745356668821
At time: 310.02444338798523 and batch: 1400, loss is 3.8421160984039306 and perplexity is 46.624031163078755
At time: 310.4148075580597 and batch: 1450, loss is 3.9208849716186522 and perplexity is 50.44506748326307
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.721171061197917 and perplexity of 112.29968549907062
Finished 25 epochs...
Completing Train Step...
At time: 311.7086811065674 and batch: 50, loss is 4.13010320186615 and perplexity is 62.184340143569244
At time: 312.11074233055115 and batch: 100, loss is 4.134820365905762 and perplexity is 62.47836681753372
At time: 312.5078582763672 and batch: 150, loss is 4.000348634719849 and perplexity is 54.617188162368905
At time: 312.9117486476898 and batch: 200, loss is 4.071127729415894 and perplexity is 58.6230362507144
At time: 313.30947613716125 and batch: 250, loss is 4.110402784347534 and perplexity is 60.97127089800907
At time: 313.7125515937805 and batch: 300, loss is 4.110953140258789 and perplexity is 61.00483603290248
At time: 314.1154360771179 and batch: 350, loss is 4.103148012161255 and perplexity is 60.530538856054626
At time: 314.5037372112274 and batch: 400, loss is 3.966163983345032 and perplexity is 52.78167063324242
At time: 314.8915388584137 and batch: 450, loss is 4.0182299184799195 and perplexity is 55.6025975382945
At time: 315.28723311424255 and batch: 500, loss is 4.015109939575195 and perplexity is 55.429388951001265
At time: 315.69519686698914 and batch: 550, loss is 4.0607946538925175 and perplexity is 58.0203989004323
At time: 316.09765243530273 and batch: 600, loss is 3.9816651344299316 and perplexity is 53.606221517577644
At time: 316.4931228160858 and batch: 650, loss is 4.061966614723206 and perplexity is 58.08843639617711
At time: 316.8812620639801 and batch: 700, loss is 4.11354031085968 and perplexity is 61.16287029384635
At time: 317.28381276130676 and batch: 750, loss is 4.065623579025268 and perplexity is 58.30125262794902
At time: 317.681911945343 and batch: 800, loss is 4.006433744430542 and perplexity is 54.950552996553625
At time: 318.0790767669678 and batch: 850, loss is 3.950413703918457 and perplexity is 51.95685714460368
At time: 318.47616505622864 and batch: 900, loss is 3.88970552444458 and perplexity is 48.89648558372319
At time: 318.8793468475342 and batch: 950, loss is 4.003338813781738 and perplexity is 54.7807477491894
At time: 319.26881074905396 and batch: 1000, loss is 4.035980010032654 and perplexity is 56.5983600287704
At time: 319.6558310985565 and batch: 1050, loss is 3.944397406578064 and perplexity is 51.64520767113242
At time: 320.066210269928 and batch: 1100, loss is 4.07864426612854 and perplexity is 59.06533866361859
At time: 320.4646542072296 and batch: 1150, loss is 3.9989425563812255 and perplexity is 54.54044608250897
At time: 320.8632957935333 and batch: 1200, loss is 3.951273827552795 and perplexity is 52.00156569008167
At time: 321.2832043170929 and batch: 1250, loss is 3.937321128845215 and perplexity is 51.281041827000955
At time: 321.69082021713257 and batch: 1300, loss is 4.004076633453369 and perplexity is 54.82118097688655
At time: 322.0845055580139 and batch: 1350, loss is 3.946412901878357 and perplexity is 51.74940331211645
At time: 322.47316670417786 and batch: 1400, loss is 3.8412090873718263 and perplexity is 46.581761824728574
At time: 322.87327098846436 and batch: 1450, loss is 3.9201226806640626 and perplexity is 50.40662831739251
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.721134022769765 and perplexity of 112.29552617226571
Finished 26 epochs...
Completing Train Step...
At time: 324.24476170539856 and batch: 50, loss is 4.127890729904175 and perplexity is 62.0469111195189
At time: 324.65674567222595 and batch: 100, loss is 4.1325538539886475 and perplexity is 62.336919211474566
At time: 325.0543258190155 and batch: 150, loss is 3.9980939388275147 and perplexity is 54.49418173572098
At time: 325.4484736919403 and batch: 200, loss is 4.0691106986999515 and perplexity is 58.50491095715617
At time: 325.8493490219116 and batch: 250, loss is 4.108154902458191 and perplexity is 60.83436861012091
At time: 326.24323177337646 and batch: 300, loss is 4.109063229560852 and perplexity is 60.889651219448005
At time: 326.6501364707947 and batch: 350, loss is 4.101170616149902 and perplexity is 60.41096427207068
At time: 327.0417082309723 and batch: 400, loss is 3.964671154022217 and perplexity is 52.70293539137489
At time: 327.4314148426056 and batch: 450, loss is 4.016352915763855 and perplexity is 55.49832919828625
At time: 327.8187487125397 and batch: 500, loss is 4.013067660331726 and perplexity is 55.316302177160075
At time: 328.2155022621155 and batch: 550, loss is 4.058923635482788 and perplexity is 57.91194315893358
At time: 328.61649322509766 and batch: 600, loss is 3.9799186897277834 and perplexity is 53.5126829197753
At time: 329.0105028152466 and batch: 650, loss is 4.060108094215393 and perplexity is 57.98057810533689
At time: 329.42604637145996 and batch: 700, loss is 4.111723999977112 and perplexity is 61.05188033357177
At time: 329.822913646698 and batch: 750, loss is 4.064083456993103 and perplexity is 58.21153069337285
At time: 330.2217392921448 and batch: 800, loss is 4.004958090782165 and perplexity is 54.869524812015634
At time: 330.6191620826721 and batch: 850, loss is 3.949259567260742 and perplexity is 51.89692642192788
At time: 331.02014923095703 and batch: 900, loss is 3.888469409942627 and perplexity is 48.8360812698142
At time: 331.4217219352722 and batch: 950, loss is 4.001780533790589 and perplexity is 54.69545048184429
At time: 331.8091983795166 and batch: 1000, loss is 4.034713444709777 and perplexity is 56.526719886663145
At time: 332.21455359458923 and batch: 1050, loss is 3.943335371017456 and perplexity is 51.590387739561784
At time: 332.6193380355835 and batch: 1100, loss is 4.077522315979004 and perplexity is 58.99910745907495
At time: 333.0187132358551 and batch: 1150, loss is 3.997751221656799 and perplexity is 54.475508843879155
At time: 333.4058268070221 and batch: 1200, loss is 3.950225977897644 and perplexity is 51.94710440600801
At time: 333.80217576026917 and batch: 1250, loss is 3.936245331764221 and perplexity is 51.22590349603871
At time: 334.18953943252563 and batch: 1300, loss is 4.003111081123352 and perplexity is 54.76827380429232
At time: 334.59435629844666 and batch: 1350, loss is 3.9454034852981565 and perplexity is 51.69719296182753
At time: 334.9941782951355 and batch: 1400, loss is 3.840238165855408 and perplexity is 46.53655653884383
At time: 335.38174510002136 and batch: 1450, loss is 3.9190541553497313 and perplexity is 50.35279632457069
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.721038035857371 and perplexity of 112.28474778873297
Finished 27 epochs...
Completing Train Step...
At time: 336.71203231811523 and batch: 50, loss is 4.125850892066955 and perplexity is 61.92047448149506
At time: 337.0981433391571 and batch: 100, loss is 4.130635509490967 and perplexity is 62.21745015354545
At time: 337.4894320964813 and batch: 150, loss is 3.9958913993835448 and perplexity is 54.37428823453265
At time: 337.8867201805115 and batch: 200, loss is 4.067257347106934 and perplexity is 58.39658120480252
At time: 338.28300428390503 and batch: 250, loss is 4.105969200134277 and perplexity is 60.701547995316105
At time: 338.7073073387146 and batch: 300, loss is 4.107302308082581 and perplexity is 60.782523674091145
At time: 339.10588002204895 and batch: 350, loss is 4.099374232292175 and perplexity is 60.30254040562126
At time: 339.500901222229 and batch: 400, loss is 3.963025531768799 and perplexity is 52.61627759063336
At time: 339.88799953460693 and batch: 450, loss is 4.014480447769165 and perplexity is 55.39450758476229
At time: 340.28149032592773 and batch: 500, loss is 4.011166577339172 and perplexity is 55.21124119234772
At time: 340.6767203807831 and batch: 550, loss is 4.057244176864624 and perplexity is 57.81476407386843
At time: 341.0647006034851 and batch: 600, loss is 3.9782062196731567 and perplexity is 53.42112247237013
At time: 341.4794850349426 and batch: 650, loss is 4.058449807167054 and perplexity is 57.88450934041895
At time: 341.8811354637146 and batch: 700, loss is 4.109885969161987 and perplexity is 60.93976816057462
At time: 342.28927183151245 and batch: 750, loss is 4.062591791152954 and perplexity is 58.1247632716229
At time: 342.67733359336853 and batch: 800, loss is 4.003438892364502 and perplexity is 54.78623040313044
At time: 343.0761022567749 and batch: 850, loss is 3.9477758264541625 and perplexity is 51.81998193141584
At time: 343.4669120311737 and batch: 900, loss is 3.886959834098816 and perplexity is 48.7624151175342
At time: 343.8544545173645 and batch: 950, loss is 4.0002439498901365 and perplexity is 54.61147087058884
At time: 344.2493209838867 and batch: 1000, loss is 4.03325879573822 and perplexity is 56.44455312809869
At time: 344.6458373069763 and batch: 1050, loss is 3.9421606636047364 and perplexity is 51.52981971048041
At time: 345.04409170150757 and batch: 1100, loss is 4.076306457519531 and perplexity is 58.92741648703871
At time: 345.4427673816681 and batch: 1150, loss is 3.9965134763717653 and perplexity is 54.40812375105119
At time: 345.8371217250824 and batch: 1200, loss is 3.949103608131409 and perplexity is 51.88883325358619
At time: 346.22642755508423 and batch: 1250, loss is 3.9351105880737305 and perplexity is 51.16780819312996
At time: 346.6271798610687 and batch: 1300, loss is 4.002022452354431 and perplexity is 54.70868392731711
At time: 347.02895188331604 and batch: 1350, loss is 3.9442437219619753 and perplexity is 51.63727120709049
At time: 347.41553020477295 and batch: 1400, loss is 3.839027829170227 and perplexity is 46.4802657095625
At time: 347.81324887275696 and batch: 1450, loss is 3.917788853645325 and perplexity is 50.28912513568623
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.720894055488782 and perplexity of 112.2685821531544
Finished 28 epochs...
Completing Train Step...
At time: 349.1495475769043 and batch: 50, loss is 4.123890347480774 and perplexity is 61.79919555569431
At time: 349.543009519577 and batch: 100, loss is 4.128692927360535 and perplexity is 62.09670496337113
At time: 349.9503209590912 and batch: 150, loss is 3.993836717605591 and perplexity is 54.2626810731728
At time: 350.3484025001526 and batch: 200, loss is 4.06521409034729 and perplexity is 58.2773838124243
At time: 350.7469012737274 and batch: 250, loss is 4.103915400505066 and perplexity is 60.57700711333649
At time: 351.14514327049255 and batch: 300, loss is 4.105446672439575 and perplexity is 60.66983804076347
At time: 351.5372498035431 and batch: 350, loss is 4.097503838539123 and perplexity is 60.18985632540419
At time: 351.9397339820862 and batch: 400, loss is 3.961471915245056 and perplexity is 52.534595540072274
At time: 352.32967233657837 and batch: 450, loss is 4.012586226463318 and perplexity is 55.28967744535499
At time: 352.7286298274994 and batch: 500, loss is 4.009331321716308 and perplexity is 55.11000737488486
At time: 353.1319885253906 and batch: 550, loss is 4.055553121566772 and perplexity is 57.71707872972561
At time: 353.5425851345062 and batch: 600, loss is 3.976431703567505 and perplexity is 53.326409889516185
At time: 353.94389820098877 and batch: 650, loss is 4.056705026626587 and perplexity is 57.78360163142995
At time: 354.3381862640381 and batch: 700, loss is 4.108141837120056 and perplexity is 60.83357379371708
At time: 354.7275414466858 and batch: 750, loss is 4.061097755432129 and perplexity is 58.037987638119944
At time: 355.1243317127228 and batch: 800, loss is 4.001810655593872 and perplexity is 54.697098032257685
At time: 355.5215654373169 and batch: 850, loss is 3.946359658241272 and perplexity is 51.74664805901764
At time: 355.9220805168152 and batch: 900, loss is 3.8855730676651 and perplexity is 48.69483990337128
At time: 356.325807094574 and batch: 950, loss is 3.9987221574783325 and perplexity is 54.528426752601305
At time: 356.713933467865 and batch: 1000, loss is 4.031860847473144 and perplexity is 56.365701690936504
At time: 357.10204243659973 and batch: 1050, loss is 3.940960865020752 and perplexity is 51.46803137994665
At time: 357.50644874572754 and batch: 1100, loss is 4.075059671401977 and perplexity is 58.85399238380697
At time: 357.906103849411 and batch: 1150, loss is 3.9953201532363893 and perplexity is 54.34323600195289
At time: 358.3174705505371 and batch: 1200, loss is 3.948107566833496 and perplexity is 51.83717556363217
At time: 358.7113618850708 and batch: 1250, loss is 3.933900899887085 and perplexity is 51.10594852302176
At time: 359.11212396621704 and batch: 1300, loss is 4.001065058708191 and perplexity is 54.65633124599203
At time: 359.52062821388245 and batch: 1350, loss is 3.9431864261627196 and perplexity is 51.58270418898098
At time: 359.92635345458984 and batch: 1400, loss is 3.8378545904159544 and perplexity is 46.42576523780757
At time: 360.3265278339386 and batch: 1450, loss is 3.916671667098999 and perplexity is 50.23297417304835
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.720982739049146 and perplexity of 112.27853897223328
Annealing...
Finished 29 epochs...
Completing Train Step...
At time: 361.602196931839 and batch: 50, loss is 4.122405300140381 and perplexity is 61.70748893588567
At time: 362.01714420318604 and batch: 100, loss is 4.127187867164611 and perplexity is 62.00331598008226
At time: 362.406450510025 and batch: 150, loss is 3.991915183067322 and perplexity is 54.15851357013048
At time: 362.805716753006 and batch: 200, loss is 4.063055629730225 and perplexity is 58.15173003275158
At time: 363.214551448822 and batch: 250, loss is 4.101047658920288 and perplexity is 60.40353676390775
At time: 363.6107771396637 and batch: 300, loss is 4.10276472568512 and perplexity is 60.50734276477593
At time: 364.03053641319275 and batch: 350, loss is 4.094028372764587 and perplexity is 59.98103163150628
At time: 364.426340341568 and batch: 400, loss is 3.95786337852478 and perplexity is 52.34536415252662
At time: 364.8267116546631 and batch: 450, loss is 4.009264254570008 and perplexity is 55.10631142789731
At time: 365.22332859039307 and batch: 500, loss is 4.004225425720215 and perplexity is 54.829338551552205
At time: 365.621461391449 and batch: 550, loss is 4.050221385955811 and perplexity is 57.41016544301379
At time: 366.02175760269165 and batch: 600, loss is 3.9713154458999633 and perplexity is 53.05427498579913
At time: 366.413871049881 and batch: 650, loss is 4.051715588569641 and perplexity is 57.49601198236884
At time: 366.8056764602661 and batch: 700, loss is 4.102679738998413 and perplexity is 60.502200664701036
At time: 367.20977091789246 and batch: 750, loss is 4.055442152023315 and perplexity is 57.7106742472071
At time: 367.6202824115753 and batch: 800, loss is 3.99549560546875 and perplexity is 54.35277148050916
At time: 368.00589632987976 and batch: 850, loss is 3.9396582412719727 and perplexity is 51.40103154722879
At time: 368.39777636528015 and batch: 900, loss is 3.8784477424621584 and perplexity is 48.3491065274695
At time: 368.80175042152405 and batch: 950, loss is 3.9909948968887328 and perplexity is 54.108695165749495
At time: 369.1969406604767 and batch: 1000, loss is 4.024088020324707 and perplexity is 55.929279150348755
At time: 369.60934829711914 and batch: 1050, loss is 3.9332356023788453 and perplexity is 51.071959170582616
At time: 370.0118227005005 and batch: 1100, loss is 4.067794766426086 and perplexity is 58.42797309026174
At time: 370.40736413002014 and batch: 1150, loss is 3.985962495803833 and perplexity is 53.837082514611986
At time: 370.8090875148773 and batch: 1200, loss is 3.940195770263672 and perplexity is 51.42866851906003
At time: 371.20750856399536 and batch: 1250, loss is 3.924830436706543 and perplexity is 50.6444898842394
At time: 371.59395456314087 and batch: 1300, loss is 3.9917183351516723 and perplexity is 54.14785362884755
At time: 371.97986578941345 and batch: 1350, loss is 3.9338281106948854 and perplexity is 51.10222869769537
At time: 372.3869206905365 and batch: 1400, loss is 3.8273657894134523 and perplexity is 45.94135948360078
At time: 372.7758400440216 and batch: 1450, loss is 3.906104950904846 and perplexity is 49.70497113336924
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.718903370392629 and perplexity of 112.04531306285249
Finished 30 epochs...
Completing Train Step...
At time: 374.0799708366394 and batch: 50, loss is 4.118514919281006 and perplexity is 61.4678896704433
At time: 374.4881889820099 and batch: 100, loss is 4.124382958412171 and perplexity is 61.829646014475216
At time: 374.8811249732971 and batch: 150, loss is 3.9889402341842652 and perplexity is 53.99763418330591
At time: 375.2795536518097 and batch: 200, loss is 4.060502219200134 and perplexity is 58.00343420358174
At time: 375.6914892196655 and batch: 250, loss is 4.09838638305664 and perplexity is 60.24300000049447
At time: 376.09754371643066 and batch: 300, loss is 4.100650658607483 and perplexity is 60.37956130036609
At time: 376.4931061267853 and batch: 350, loss is 4.091929845809936 and perplexity is 59.855291800217
At time: 376.90703225135803 and batch: 400, loss is 3.9559884023666383 and perplexity is 52.2473097962676
At time: 377.3143608570099 and batch: 450, loss is 4.007364540100098 and perplexity is 55.00172454475578
At time: 377.71682119369507 and batch: 500, loss is 4.002183933258056 and perplexity is 54.71751904836628
At time: 378.12287855148315 and batch: 550, loss is 4.048543839454651 and perplexity is 57.3139379564522
At time: 378.52479672431946 and batch: 600, loss is 3.9696836948394774 and perplexity is 52.96777420938773
At time: 378.9257733821869 and batch: 650, loss is 4.050388126373291 and perplexity is 57.41973883608097
At time: 379.320693731308 and batch: 700, loss is 4.101302361488342 and perplexity is 60.418923659298734
At time: 379.7199158668518 and batch: 750, loss is 4.054083662033081 and perplexity is 57.63232810218846
At time: 380.1069357395172 and batch: 800, loss is 3.9942604684829712 and perplexity is 54.28567980440869
At time: 380.4956443309784 and batch: 850, loss is 3.938651933670044 and perplexity is 51.3493323154636
At time: 380.88782930374146 and batch: 900, loss is 3.8775703716278076 and perplexity is 48.3067050351717
At time: 381.28967237472534 and batch: 950, loss is 3.990216474533081 and perplexity is 54.06659213689278
At time: 381.68646812438965 and batch: 1000, loss is 4.023470997810364 and perplexity is 55.894780170320224
At time: 382.08927750587463 and batch: 1050, loss is 3.9329632043838503 and perplexity is 51.05804916591878
At time: 382.4939663410187 and batch: 1100, loss is 4.067520685195923 and perplexity is 58.41196127389062
At time: 382.8909344673157 and batch: 1150, loss is 3.9856470823287964 and perplexity is 53.82010425105754
At time: 383.2859103679657 and batch: 1200, loss is 3.940153932571411 and perplexity is 51.426516907262695
At time: 383.68193221092224 and batch: 1250, loss is 3.9247668886184695 and perplexity is 50.64127162599396
At time: 384.0722179412842 and batch: 1300, loss is 3.991566467285156 and perplexity is 54.13963093423786
At time: 384.4731104373932 and batch: 1350, loss is 3.9340322160720826 and perplexity is 51.11266000186575
At time: 384.8677906990051 and batch: 1400, loss is 3.8275230932235718 and perplexity is 45.94858680291715
At time: 385.2638053894043 and batch: 1450, loss is 3.90644278049469 and perplexity is 49.72176578008501
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.718792255108173 and perplexity of 112.03286380768371
Finished 31 epochs...
Completing Train Step...
At time: 386.64871096611023 and batch: 50, loss is 4.116777272224426 and perplexity is 61.36117291776072
At time: 387.04827308654785 and batch: 100, loss is 4.122813119888305 and perplexity is 61.73265960066679
At time: 387.4527497291565 and batch: 150, loss is 3.9874284505844115 and perplexity is 53.916063119950415
At time: 387.85466957092285 and batch: 200, loss is 4.058996520042419 and perplexity is 57.91616419923057
At time: 388.25672602653503 and batch: 250, loss is 4.096723093986511 and perplexity is 60.14288176290867
At time: 388.64785265922546 and batch: 300, loss is 4.099299974441529 and perplexity is 60.2980626348391
At time: 389.0493047237396 and batch: 350, loss is 4.090556864738464 and perplexity is 59.77316800765503
At time: 389.4400990009308 and batch: 400, loss is 3.9548451328277587 and perplexity is 52.18761117080163
At time: 389.84424018859863 and batch: 450, loss is 4.006117181777954 and perplexity is 54.9331604567954
At time: 390.2395672798157 and batch: 500, loss is 4.000885334014892 and perplexity is 54.64650903629528
At time: 390.6269586086273 and batch: 550, loss is 4.047423152923584 and perplexity is 57.24974297608567
At time: 391.0164361000061 and batch: 600, loss is 3.9686248970031737 and perplexity is 52.9117217240226
At time: 391.403847694397 and batch: 650, loss is 4.049487438201904 and perplexity is 57.368044840087215
At time: 391.8021252155304 and batch: 700, loss is 4.1003365802764895 and perplexity is 60.36060036629188
At time: 392.2274284362793 and batch: 750, loss is 4.053201932907104 and perplexity is 57.58153439633861
At time: 392.61732482910156 and batch: 800, loss is 3.9933317279815674 and perplexity is 54.23528589998044
At time: 393.01402258872986 and batch: 850, loss is 3.937866291999817 and perplexity is 51.30900598335591
At time: 393.40172028541565 and batch: 900, loss is 3.8768377017974855 and perplexity is 48.27132513226657
At time: 393.7985246181488 and batch: 950, loss is 3.98961621761322 and perplexity is 54.03414802920355
At time: 394.19271087646484 and batch: 1000, loss is 4.02287305355072 and perplexity is 55.86136819761747
At time: 394.5821771621704 and batch: 1050, loss is 3.9326514625549316 and perplexity is 51.042134717019366
At time: 394.9894196987152 and batch: 1100, loss is 4.067229061126709 and perplexity is 58.39492942362261
At time: 395.37890458106995 and batch: 1150, loss is 3.9852858877182005 and perplexity is 53.800668229764725
At time: 395.78267097473145 and batch: 1200, loss is 3.9399343299865723 and perplexity is 51.415224751159315
At time: 396.178603887558 and batch: 1250, loss is 3.924564881324768 and perplexity is 50.63104275295146
At time: 396.58377265930176 and batch: 1300, loss is 3.9912823629379273 and perplexity is 54.12425181447291
At time: 396.982946395874 and batch: 1350, loss is 3.9340011644363404 and perplexity is 51.11107289480682
At time: 397.3866882324219 and batch: 1400, loss is 3.827426428794861 and perplexity is 45.94414542368892
At time: 397.77326226234436 and batch: 1450, loss is 3.906337270736694 and perplexity is 49.71651992535973
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.7187969501201925 and perplexity of 112.0333898045606
Annealing...
Finished 32 epochs...
Completing Train Step...
At time: 399.0806813240051 and batch: 50, loss is 4.115568799972534 and perplexity is 61.28706443099004
At time: 399.4777011871338 and batch: 100, loss is 4.121747469902038 and perplexity is 61.666909232472825
At time: 399.86491870880127 and batch: 150, loss is 3.986363253593445 and perplexity is 53.85866246867822
At time: 400.2660827636719 and batch: 200, loss is 4.057809324264526 and perplexity is 57.84744717197479
At time: 400.6698331832886 and batch: 250, loss is 4.095269088745117 and perplexity is 60.055497241763945
At time: 401.0674810409546 and batch: 300, loss is 4.097792997360229 and perplexity is 60.207263269866274
At time: 401.47156023979187 and batch: 350, loss is 4.088714671134949 and perplexity is 59.6631556230573
At time: 401.8742344379425 and batch: 400, loss is 3.952843899726868 and perplexity is 52.08327603015999
At time: 402.29079127311707 and batch: 450, loss is 4.003957853317261 and perplexity is 54.81466969626156
At time: 402.7036600112915 and batch: 500, loss is 3.9981112766265867 and perplexity is 54.49512655308501
At time: 403.1097798347473 and batch: 550, loss is 4.044269323348999 and perplexity is 57.069471465785256
At time: 403.51245379447937 and batch: 600, loss is 3.9657372999191285 and perplexity is 52.75915437319082
At time: 403.91570591926575 and batch: 650, loss is 4.046827483177185 and perplexity is 57.21565119093623
At time: 404.31359219551086 and batch: 700, loss is 4.097283215522766 and perplexity is 60.176578522495895
At time: 404.70574498176575 and batch: 750, loss is 4.050208826065063 and perplexity is 57.409444382136236
At time: 405.09939408302307 and batch: 800, loss is 3.9899739027023315 and perplexity is 54.05347869519583
At time: 405.48796343803406 and batch: 850, loss is 3.9342760705947875 and perplexity is 51.1251255750061
At time: 405.88933801651 and batch: 900, loss is 3.8731830739974975 and perplexity is 48.095233376403634
At time: 406.2868552207947 and batch: 950, loss is 3.9855965900421144 and perplexity is 53.81738681952969
At time: 406.69035243988037 and batch: 1000, loss is 4.018946242332459 and perplexity is 55.64244127397972
At time: 407.0916850566864 and batch: 1050, loss is 3.9282480478286743 and perplexity is 50.817869158854336
At time: 407.4881727695465 and batch: 1100, loss is 4.0634809541702275 and perplexity is 58.17646864535829
At time: 407.8923828601837 and batch: 1150, loss is 3.9803271770477293 and perplexity is 53.53454663742601
At time: 408.28186893463135 and batch: 1200, loss is 3.935707507133484 and perplexity is 51.19836035076167
At time: 408.6817555427551 and batch: 1250, loss is 3.9198811531066893 and perplexity is 50.39445519771069
At time: 409.08212661743164 and batch: 1300, loss is 3.9861861991882326 and perplexity is 53.84912739936723
At time: 409.4735314846039 and batch: 1350, loss is 3.9292162704467772 and perplexity is 50.86709599660094
At time: 409.8877341747284 and batch: 1400, loss is 3.82169641494751 and perplexity is 45.68163763907099
At time: 410.2762522697449 and batch: 1450, loss is 3.9005219459533693 and perplexity is 49.42824124439305
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.718128171741453 and perplexity of 111.95848934445827
Finished 33 epochs...
Completing Train Step...
At time: 411.5598087310791 and batch: 50, loss is 4.113846969604492 and perplexity is 61.18162929903929
At time: 411.9777092933655 and batch: 100, loss is 4.120306687355042 and perplexity is 61.57812460095588
At time: 412.3686800003052 and batch: 150, loss is 3.9850783205032347 and perplexity is 53.78950213379479
At time: 412.78774094581604 and batch: 200, loss is 4.05667462348938 and perplexity is 57.781844855367126
At time: 413.18897128105164 and batch: 250, loss is 4.094068083763123 and perplexity is 59.98341358546014
At time: 413.5822947025299 and batch: 300, loss is 4.096707501411438 and perplexity is 60.141943987820866
At time: 413.98512506484985 and batch: 350, loss is 4.087698149681091 and perplexity is 59.602537560362016
At time: 414.39052867889404 and batch: 400, loss is 3.9522022914886477 and perplexity is 52.049869689223335
At time: 414.776957988739 and batch: 450, loss is 4.002938466072083 and perplexity is 54.75882079179124
At time: 415.1648361682892 and batch: 500, loss is 3.9971071434020997 and perplexity is 54.44043365001649
At time: 415.56149983406067 and batch: 550, loss is 4.043339343070984 and perplexity is 57.01642265384308
At time: 415.9620041847229 and batch: 600, loss is 3.9649970054626467 and perplexity is 52.72011151706772
At time: 416.36210322380066 and batch: 650, loss is 4.046198177337646 and perplexity is 57.179656374590735
At time: 416.7594904899597 and batch: 700, loss is 4.096466979980469 and perplexity is 60.12748030087471
At time: 417.1577377319336 and batch: 750, loss is 4.049495763778687 and perplexity is 57.36852246413765
At time: 417.5455605983734 and batch: 800, loss is 3.989331030845642 and perplexity is 54.01874040231834
At time: 417.936443567276 and batch: 850, loss is 3.933853063583374 and perplexity is 51.103503861819036
At time: 418.3231837749481 and batch: 900, loss is 3.8728892612457275 and perplexity is 48.08110445926795
At time: 418.7086353302002 and batch: 950, loss is 3.9852537012100218 and perplexity is 53.7989366019844
At time: 419.11216926574707 and batch: 1000, loss is 4.018565835952759 and perplexity is 55.62127855980799
At time: 419.5077157020569 and batch: 1050, loss is 3.928049578666687 and perplexity is 50.80778437974034
At time: 419.9097590446472 and batch: 1100, loss is 4.063345470428467 and perplexity is 58.168587213618785
At time: 420.29820823669434 and batch: 1150, loss is 3.9800912284851075 and perplexity is 53.52191672815937
At time: 420.6849639415741 and batch: 1200, loss is 3.935575394630432 and perplexity is 51.19159685400465
At time: 421.0757143497467 and batch: 1250, loss is 3.919931230545044 and perplexity is 50.39697888612368
At time: 421.4628264904022 and batch: 1300, loss is 3.986076683998108 and perplexity is 53.84323042485208
At time: 421.8608114719391 and batch: 1350, loss is 3.9292543077468873 and perplexity is 50.869030880395734
At time: 422.2504448890686 and batch: 1400, loss is 3.821716728210449 and perplexity is 45.68256559161269
At time: 422.66571855545044 and batch: 1450, loss is 3.9007155084609986 and perplexity is 49.43780962472599
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.717916896200587 and perplexity of 111.93483775265689
Finished 34 epochs...
Completing Train Step...
At time: 423.97237968444824 and batch: 50, loss is 4.112657098770142 and perplexity is 61.108874355814635
At time: 424.37507677078247 and batch: 100, loss is 4.119323863983154 and perplexity is 61.5176339116019
At time: 424.77236127853394 and batch: 150, loss is 3.983904047012329 and perplexity is 53.726375618500654
At time: 425.16793298721313 and batch: 200, loss is 4.055617060661316 and perplexity is 57.720769225461495
At time: 425.57314109802246 and batch: 250, loss is 4.093007483482361 and perplexity is 59.91982888510627
At time: 425.9935324192047 and batch: 300, loss is 4.09587420463562 and perplexity is 60.0918487747929
At time: 426.3897385597229 and batch: 350, loss is 4.086892232894898 and perplexity is 59.554522225623366
At time: 426.7766695022583 and batch: 400, loss is 3.9516333103179933 and perplexity is 52.02026271713871
At time: 427.1757791042328 and batch: 450, loss is 4.001951913833619 and perplexity is 54.70482499378059
At time: 427.57520365715027 and batch: 500, loss is 3.9961014938354493 and perplexity is 54.38571317093284
At time: 427.96863293647766 and batch: 550, loss is 4.042635841369629 and perplexity is 56.97632560932417
At time: 428.36140394210815 and batch: 600, loss is 3.964416823387146 and perplexity is 52.689533124722445
At time: 428.75489711761475 and batch: 650, loss is 4.045376124382019 and perplexity is 57.13267098395185
At time: 429.1613383293152 and batch: 700, loss is 4.095628604888916 and perplexity is 60.077092044153694
At time: 429.56564021110535 and batch: 750, loss is 4.048924593925476 and perplexity is 57.33576464961153
At time: 429.9620451927185 and batch: 800, loss is 3.9887784337997436 and perplexity is 53.98889805210555
At time: 430.362318277359 and batch: 850, loss is 3.9335777282714846 and perplexity is 51.08943519953323
At time: 430.75495648384094 and batch: 900, loss is 3.8724906969070436 and perplexity is 48.06194486408527
At time: 431.15508103370667 and batch: 950, loss is 3.984771075248718 and perplexity is 53.772978103116365
At time: 431.5497133731842 and batch: 1000, loss is 4.018044381141663 and perplexity is 55.5922821373227
At time: 431.9460346698761 and batch: 1050, loss is 3.927766146659851 and perplexity is 50.79338586804661
At time: 432.33445024490356 and batch: 1100, loss is 4.063156933784485 and perplexity is 58.1576213371676
At time: 432.745156288147 and batch: 1150, loss is 3.979835262298584 and perplexity is 53.50821868043235
At time: 433.14203238487244 and batch: 1200, loss is 3.935493450164795 and perplexity is 51.18740215782376
At time: 433.53970646858215 and batch: 1250, loss is 3.9198891496658326 and perplexity is 50.394858181563414
At time: 433.93385648727417 and batch: 1300, loss is 3.9857682275772093 and perplexity is 53.826624695909125
At time: 434.32146859169006 and batch: 1350, loss is 3.9292597913742067 and perplexity is 50.869309827967996
At time: 434.7123558521271 and batch: 1400, loss is 3.821736750602722 and perplexity is 45.68348027501805
At time: 435.116411447525 and batch: 1450, loss is 3.900855469703674 and perplexity is 49.44472948624114
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.717906462840545 and perplexity of 111.93366990228563
Finished 35 epochs...
Completing Train Step...
At time: 436.4500164985657 and batch: 50, loss is 4.1118000745773315 and perplexity is 61.05652500762941
At time: 436.853639125824 and batch: 100, loss is 4.118569946289062 and perplexity is 61.471272157566595
At time: 437.25512075424194 and batch: 150, loss is 3.9831539678573606 and perplexity is 53.68609169403194
At time: 437.6627039909363 and batch: 200, loss is 4.054938440322876 and perplexity is 57.6816120254536
At time: 438.0514986515045 and batch: 250, loss is 4.092283821105957 and perplexity is 59.876482845182316
At time: 438.44287157058716 and batch: 300, loss is 4.095255861282348 and perplexity is 60.05470286516393
At time: 438.833322763443 and batch: 350, loss is 4.086229386329651 and perplexity is 59.515059795334274
At time: 439.2249925136566 and batch: 400, loss is 3.9512372541427614 and perplexity is 51.99966385027588
At time: 439.62999415397644 and batch: 450, loss is 4.001216073036193 and perplexity is 54.66458575838536
At time: 440.0317840576172 and batch: 500, loss is 3.9954333448410035 and perplexity is 54.349387548181
At time: 440.4409158229828 and batch: 550, loss is 4.042140526771545 and perplexity is 56.94811139153852
At time: 440.846693277359 and batch: 600, loss is 3.9639410638809203 and perplexity is 52.66447154057593
At time: 441.25041365623474 and batch: 650, loss is 4.044938941001892 and perplexity is 57.10769898880372
At time: 441.6470687389374 and batch: 700, loss is 4.095061779022217 and perplexity is 60.04304844369514
At time: 442.0384774208069 and batch: 750, loss is 4.048501515388489 and perplexity is 57.31151224888339
At time: 442.43365597724915 and batch: 800, loss is 3.9883184671401977 and perplexity is 53.96407066933784
At time: 442.8650252819061 and batch: 850, loss is 3.933271622657776 and perplexity is 51.0737988299298
At time: 443.2775709629059 and batch: 900, loss is 3.87217716217041 and perplexity is 48.04687813695481
At time: 443.68276715278625 and batch: 950, loss is 3.9844415283203123 and perplexity is 53.75526030293491
At time: 444.0904965400696 and batch: 1000, loss is 4.017794213294983 and perplexity is 55.57837647525567
At time: 444.4788691997528 and batch: 1050, loss is 3.927559804916382 and perplexity is 50.782906153488376
At time: 444.8663671016693 and batch: 1100, loss is 4.062941584587097 and perplexity is 58.14509848853178
At time: 445.26361632347107 and batch: 1150, loss is 3.9796132469177246 and perplexity is 53.496340351517546
At time: 445.66388177871704 and batch: 1200, loss is 3.935392255783081 and perplexity is 51.182222542389276
At time: 446.066561460495 and batch: 1250, loss is 3.9198377752304077 and perplexity is 50.392269240679276
At time: 446.4653387069702 and batch: 1300, loss is 3.98559805393219 and perplexity is 53.8174656023258
At time: 446.85776948928833 and batch: 1350, loss is 3.9293258476257322 and perplexity is 50.87267017487766
At time: 447.2593638896942 and batch: 1400, loss is 3.8216932916641237 and perplexity is 45.68149496259391
At time: 447.6536672115326 and batch: 1450, loss is 3.900912489891052 and perplexity is 49.44754891436269
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.7179382845886755 and perplexity of 111.93723188401054
Annealing...
Finished 36 epochs...
Completing Train Step...
At time: 448.9874360561371 and batch: 50, loss is 4.111152024269104 and perplexity is 61.01697012593985
At time: 449.38592195510864 and batch: 100, loss is 4.118070340156555 and perplexity is 61.4405684035542
At time: 449.7892611026764 and batch: 150, loss is 3.9828639888763426 and perplexity is 53.67052611282242
At time: 450.1758782863617 and batch: 200, loss is 4.054282298088074 and perplexity is 57.64377709753672
At time: 450.5701279640198 and batch: 250, loss is 4.091753268241883 and perplexity is 59.844723631434015
At time: 450.97002696990967 and batch: 300, loss is 4.094398608207703 and perplexity is 60.00324284676677
At time: 451.3712272644043 and batch: 350, loss is 4.085410437583923 and perplexity is 59.46633996400828
At time: 451.77572202682495 and batch: 400, loss is 3.9504567527770997 and perplexity is 51.95909387614644
At time: 452.17208075523376 and batch: 450, loss is 4.000190453529358 and perplexity is 54.60854943378431
At time: 452.5688772201538 and batch: 500, loss is 3.9940209007263183 and perplexity is 54.27267626355632
At time: 452.9559094905853 and batch: 550, loss is 4.0403819751739505 and perplexity is 56.84805320379973
At time: 453.3553876876831 and batch: 600, loss is 3.962321553230286 and perplexity is 52.57924989531373
At time: 453.7527446746826 and batch: 650, loss is 4.0435164213180546 and perplexity is 57.026519915997234
At time: 454.1557619571686 and batch: 700, loss is 4.093318753242492 and perplexity is 59.938483018953725
At time: 454.5614595413208 and batch: 750, loss is 4.046905608177185 and perplexity is 57.22012133829838
At time: 454.966463804245 and batch: 800, loss is 3.9866305065155028 and perplexity is 53.87305827717637
At time: 455.3607110977173 and batch: 850, loss is 3.9315302991867065 and perplexity is 50.984940213520886
At time: 455.7493188381195 and batch: 900, loss is 3.870326189994812 and perplexity is 47.95802695829641
At time: 456.1379463672638 and batch: 950, loss is 3.982267379760742 and perplexity is 53.63851533761409
At time: 456.5254809856415 and batch: 1000, loss is 4.015886149406433 and perplexity is 55.472430490116395
At time: 456.91349744796753 and batch: 1050, loss is 3.9250015926361086 and perplexity is 50.653158730824
At time: 457.31342101097107 and batch: 1100, loss is 4.0608857727050784 and perplexity is 58.02568589115292
At time: 457.7088677883148 and batch: 1150, loss is 3.976962990760803 and perplexity is 53.35474905560646
At time: 458.10313630104065 and batch: 1200, loss is 3.933120746612549 and perplexity is 51.06609359842966
At time: 458.49050855636597 and batch: 1250, loss is 3.9174872255325317 and perplexity is 50.27395880918773
At time: 458.8899471759796 and batch: 1300, loss is 3.9828521013259888 and perplexity is 53.66988810553292
At time: 459.2846779823303 and batch: 1350, loss is 3.9266154956817627 and perplexity is 50.734974021186254
At time: 459.6733982563019 and batch: 1400, loss is 3.818594217300415 and perplexity is 45.540143754742864
At time: 460.0639388561249 and batch: 1450, loss is 3.8978966283798218 and perplexity is 49.29864660200432
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.717662322215545 and perplexity of 111.906345681769
Finished 37 epochs...
Completing Train Step...
At time: 461.4051105976105 and batch: 50, loss is 4.110443844795227 and perplexity is 60.9737744570868
At time: 461.8063428401947 and batch: 100, loss is 4.117338399887085 and perplexity is 61.39561403132519
At time: 462.2012093067169 and batch: 150, loss is 3.982227339744568 and perplexity is 53.63636769358855
At time: 462.5889139175415 and batch: 200, loss is 4.053627209663391 and perplexity is 57.6060276923543
At time: 463.0081477165222 and batch: 250, loss is 4.091206693649292 and perplexity is 59.812022963487706
At time: 463.4081811904907 and batch: 300, loss is 4.0938546848297115 and perplexity is 59.97061455467697
At time: 463.8065493106842 and batch: 350, loss is 4.084913234710694 and perplexity is 59.43678047805735
At time: 464.191148519516 and batch: 400, loss is 3.950163164138794 and perplexity is 51.94384151559718
At time: 464.5832300186157 and batch: 450, loss is 3.9997047901153566 and perplexity is 54.582034498420825
At time: 464.98827624320984 and batch: 500, loss is 3.9935896968841553 and perplexity is 54.249278721944464
At time: 465.38083815574646 and batch: 550, loss is 4.039953846931457 and perplexity is 56.82372015589661
At time: 465.7854537963867 and batch: 600, loss is 3.961971192359924 and perplexity is 52.560831410304075
At time: 466.1771593093872 and batch: 650, loss is 4.043211364746094 and perplexity is 57.00912625448109
At time: 466.5651307106018 and batch: 700, loss is 4.092874178886413 and perplexity is 59.91184182889497
At time: 466.94953179359436 and batch: 750, loss is 4.046552882194519 and perplexity is 57.199941873891014
At time: 467.33540296554565 and batch: 800, loss is 3.986309313774109 and perplexity is 53.855757420504574
At time: 467.7364432811737 and batch: 850, loss is 3.931360297203064 and perplexity is 50.976273409256535
At time: 468.1239266395569 and batch: 900, loss is 3.8702377462387085 and perplexity is 47.95378555782237
At time: 468.5176773071289 and batch: 950, loss is 3.982100582122803 and perplexity is 53.6295693060624
At time: 468.911278963089 and batch: 1000, loss is 4.0157715654373165 and perplexity is 55.46607460300264
At time: 469.3300185203552 and batch: 1050, loss is 3.924965224266052 and perplexity is 50.65131659150076
At time: 469.76829528808594 and batch: 1100, loss is 4.0607990598678585 and perplexity is 58.02065453744229
At time: 470.1771020889282 and batch: 1150, loss is 3.976880669593811 and perplexity is 53.350357011181224
At time: 470.5888924598694 and batch: 1200, loss is 3.933131318092346 and perplexity is 51.06663344545995
At time: 470.98933720588684 and batch: 1250, loss is 3.917607946395874 and perplexity is 50.280028291247994
At time: 471.38284277915955 and batch: 1300, loss is 3.982889609336853 and perplexity is 53.67190119403231
At time: 471.7808439731598 and batch: 1350, loss is 3.9267494583129885 and perplexity is 50.74177106706621
At time: 472.1748642921448 and batch: 1400, loss is 3.8187091159820556 and perplexity is 45.545376557837336
At time: 472.56327080726624 and batch: 1450, loss is 3.898070774078369 and perplexity is 49.30723249683089
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.7176492805154915 and perplexity of 111.90488624229137
Finished 38 epochs...
Completing Train Step...
At time: 473.8807621002197 and batch: 50, loss is 4.109946188926696 and perplexity is 60.943438049573494
At time: 474.29704213142395 and batch: 100, loss is 4.116840958595276 and perplexity is 61.36508091261663
At time: 474.69209480285645 and batch: 150, loss is 3.981835336685181 and perplexity is 53.615346193873535
At time: 475.0839743614197 and batch: 200, loss is 4.053196210861206 and perplexity is 57.58120491309855
At time: 475.47828221321106 and batch: 250, loss is 4.090797657966614 and perplexity is 59.787562714740766
At time: 475.87043499946594 and batch: 300, loss is 4.093431262969971 and perplexity is 59.945227060721706
At time: 476.29421043395996 and batch: 350, loss is 4.084544186592102 and perplexity is 59.41484949309005
At time: 476.68575072288513 and batch: 400, loss is 3.949999284744263 and perplexity is 51.93532968777563
At time: 477.0965528488159 and batch: 450, loss is 3.999336938858032 and perplexity is 54.561960120822135
At time: 477.4928328990936 and batch: 500, loss is 3.993241310119629 and perplexity is 54.230382283078356
At time: 477.9010717868805 and batch: 550, loss is 4.039637460708618 and perplexity is 56.805744757442966
At time: 478.29092168807983 and batch: 600, loss is 3.9616661214828492 and perplexity is 52.54479907698928
At time: 478.67594861984253 and batch: 650, loss is 4.042950897216797 and perplexity is 56.99427916189491
At time: 479.09812474250793 and batch: 700, loss is 4.092507882118225 and perplexity is 59.88990033365157
At time: 479.5012834072113 and batch: 750, loss is 4.046275596618653 and perplexity is 57.184083353840016
At time: 479.91926622390747 and batch: 800, loss is 3.9860571813583374 and perplexity is 53.842180349964664
At time: 480.3214304447174 and batch: 850, loss is 3.9312253189086914 and perplexity is 50.96939318316931
At time: 480.7220239639282 and batch: 900, loss is 3.870169425010681 and perplexity is 47.95050940822105
At time: 481.12963223457336 and batch: 950, loss is 3.9819473695755003 and perplexity is 53.62135321255867
At time: 481.5311496257782 and batch: 1000, loss is 4.0156570196151735 and perplexity is 55.45972155975042
At time: 481.9208936691284 and batch: 1050, loss is 3.924890565872192 and perplexity is 50.6475351867157
At time: 482.30924892425537 and batch: 1100, loss is 4.060689854621887 and perplexity is 58.01431872355046
At time: 482.72204065322876 and batch: 1150, loss is 3.9767640972137452 and perplexity is 53.344138195565186
At time: 483.13676357269287 and batch: 1200, loss is 3.9331016683578492 and perplexity is 51.065119355782926
At time: 483.56596088409424 and batch: 1250, loss is 3.9177197647094726 and perplexity is 50.28565083356496
At time: 483.96995425224304 and batch: 1300, loss is 3.982907495498657 and perplexity is 53.67286118692666
At time: 484.3668088912964 and batch: 1350, loss is 3.9268206644058226 and perplexity is 50.745384318968625
At time: 484.7639739513397 and batch: 1400, loss is 3.8187596464157103 and perplexity is 45.54767804361282
At time: 485.15482926368713 and batch: 1450, loss is 3.8981550312042237 and perplexity is 49.311387157552346
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.717652410523504 and perplexity of 111.90523650603014
Annealing...
Finished 39 epochs...
Completing Train Step...
At time: 486.4859793186188 and batch: 50, loss is 4.109546976089478 and perplexity is 60.919113502418654
At time: 486.8801591396332 and batch: 100, loss is 4.116531233787537 and perplexity is 61.34607756778466
At time: 487.272997379303 and batch: 150, loss is 3.98186215877533 and perplexity is 53.61678428880879
At time: 487.66295099258423 and batch: 200, loss is 4.052718849182129 and perplexity is 57.55372441202886
At time: 488.0554986000061 and batch: 250, loss is 4.090449934005737 and perplexity is 59.766776760719004
At time: 488.45339369773865 and batch: 300, loss is 4.092911977767944 and perplexity is 59.91410647230676
At time: 488.8449385166168 and batch: 350, loss is 4.08415337562561 and perplexity is 59.39163405505507
At time: 489.2396478652954 and batch: 400, loss is 3.949503870010376 and perplexity is 51.9096065325802
At time: 489.6287500858307 and batch: 450, loss is 3.998843541145325 and perplexity is 54.535046014722894
At time: 490.0253629684448 and batch: 500, loss is 3.9925285625457763 and perplexity is 54.19174348116889
At time: 490.41774106025696 and batch: 550, loss is 4.03875120639801 and perplexity is 56.755422723637864
At time: 490.80296874046326 and batch: 600, loss is 3.9608023500442506 and perplexity is 52.4994319765232
At time: 491.19440960884094 and batch: 650, loss is 4.042157659530639 and perplexity is 56.94908707816993
At time: 491.5788416862488 and batch: 700, loss is 4.0915418100357055 and perplexity is 59.83207031139707
At time: 491.9866659641266 and batch: 750, loss is 4.045356197357178 and perplexity is 57.131532511141096
At time: 492.385933637619 and batch: 800, loss is 3.985189142227173 and perplexity is 53.79546350946989
At time: 492.7869665622711 and batch: 850, loss is 3.930403118133545 and perplexity is 50.9275033318793
At time: 493.18942046165466 and batch: 900, loss is 3.8692826223373413 and perplexity is 47.90800561731302
At time: 493.60648226737976 and batch: 950, loss is 3.9808009576797487 and perplexity is 53.55991627811441
At time: 494.01624369621277 and batch: 1000, loss is 4.014740014076233 and perplexity is 55.40888799878269
At time: 494.4142732620239 and batch: 1050, loss is 3.9235491943359375 and perplexity is 50.57964356875638
At time: 494.81097769737244 and batch: 1100, loss is 4.059574999809265 and perplexity is 57.94967722076102
At time: 495.1982002258301 and batch: 1150, loss is 3.975336055755615 and perplexity is 53.26801492120609
At time: 495.5936589241028 and batch: 1200, loss is 3.931792597770691 and perplexity is 50.99831524519267
At time: 495.99550557136536 and batch: 1250, loss is 3.9164705371856687 and perplexity is 50.22287183528181
At time: 496.3944618701935 and batch: 1300, loss is 3.9816120529174803 and perplexity is 53.603376093783055
At time: 496.80005168914795 and batch: 1350, loss is 3.9253423738479616 and perplexity is 50.67042331719672
At time: 497.20813822746277 and batch: 1400, loss is 3.8170851564407347 and perplexity is 45.47147273366525
At time: 497.6150221824646 and batch: 1450, loss is 3.89655415058136 and perplexity is 49.23250866773418
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.717532948551015 and perplexity of 111.89186888422238
Finished 40 epochs...
Completing Train Step...
At time: 498.9574222564697 and batch: 50, loss is 4.109191408157349 and perplexity is 60.89745646970482
At time: 499.3491940498352 and batch: 100, loss is 4.116179070472717 and perplexity is 61.3244775333503
At time: 499.73846316337585 and batch: 150, loss is 3.9814809656143186 and perplexity is 53.59634983230745
At time: 500.1266508102417 and batch: 200, loss is 4.052360558509827 and perplexity is 57.53310714312394
At time: 500.52062582969666 and batch: 250, loss is 4.090170774459839 and perplexity is 59.75009462305601
At time: 500.90842294692993 and batch: 300, loss is 4.092609734535217 and perplexity is 59.896000575410866
At time: 501.3054940700531 and batch: 350, loss is 4.083893513679504 and perplexity is 59.3762024345794
At time: 501.711056470871 and batch: 400, loss is 3.949368281364441 and perplexity is 51.90256865645824
At time: 502.118234872818 and batch: 450, loss is 3.998627600669861 and perplexity is 54.523270962357984
At time: 502.53252148628235 and batch: 500, loss is 3.992339587211609 and perplexity is 54.18150354591349
At time: 502.93944096565247 and batch: 550, loss is 4.038538823127746 and perplexity is 56.74337010128759
At time: 503.3516540527344 and batch: 600, loss is 3.9606292724609373 and perplexity is 52.49034628799856
At time: 503.7549657821655 and batch: 650, loss is 4.041990761756897 and perplexity is 56.93958319543041
At time: 504.18018794059753 and batch: 700, loss is 4.091309385299683 and perplexity is 59.8181654742259
At time: 504.58573961257935 and batch: 750, loss is 4.04516749382019 and perplexity is 57.12075260601784
At time: 504.9858317375183 and batch: 800, loss is 3.984999556541443 and perplexity is 53.78526562634816
At time: 505.37314677238464 and batch: 850, loss is 3.930317454338074 and perplexity is 50.92314087550499
At time: 505.76065039634705 and batch: 900, loss is 3.869258852005005 and perplexity is 47.90686684163253
At time: 506.155556678772 and batch: 950, loss is 3.980705051422119 and perplexity is 53.554779793299666
At time: 506.5489270687103 and batch: 1000, loss is 4.014702949523926 and perplexity is 55.40683433121453
At time: 506.95659494400024 and batch: 1050, loss is 3.9235620594024656 and perplexity is 50.580294283421594
At time: 507.3628776073456 and batch: 1100, loss is 4.059524126052857 and perplexity is 57.946729177987784
At time: 507.7892382144928 and batch: 1150, loss is 3.975262370109558 and perplexity is 53.264089977720204
At time: 508.18141412734985 and batch: 1200, loss is 3.9318399953842165 and perplexity is 51.000732500914744
At time: 508.5685455799103 and batch: 1250, loss is 3.916583662033081 and perplexity is 50.22855361136374
At time: 508.97514247894287 and batch: 1300, loss is 3.981669864654541 and perplexity is 53.6064750876456
At time: 509.36365938186646 and batch: 1350, loss is 3.925443019866943 and perplexity is 50.67552335022842
At time: 509.7810842990875 and batch: 1400, loss is 3.817135043144226 and perplexity is 45.473741212125816
At time: 510.18040466308594 and batch: 1450, loss is 3.8966269302368164 and perplexity is 49.23609192314474
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.717527731870994 and perplexity of 111.89128518166791
Finished 41 epochs...
Completing Train Step...
At time: 511.55935049057007 and batch: 50, loss is 4.108969283103943 and perplexity is 60.88393112114921
At time: 511.96936082839966 and batch: 100, loss is 4.11590530872345 and perplexity is 61.30769153489486
At time: 512.3619487285614 and batch: 150, loss is 3.9812831401824953 and perplexity is 53.58574815993251
At time: 512.7629082202911 and batch: 200, loss is 4.052088279724121 and perplexity is 57.51744423100921
At time: 513.1591613292694 and batch: 250, loss is 4.089932436943054 and perplexity is 59.73585563078633
At time: 513.5527038574219 and batch: 300, loss is 4.092367887496948 and perplexity is 59.881516656584594
At time: 513.9406323432922 and batch: 350, loss is 4.083693161010742 and perplexity is 59.36430744559685
At time: 514.3569302558899 and batch: 400, loss is 3.9492693185806274 and perplexity is 51.89743248792589
At time: 514.7535688877106 and batch: 450, loss is 3.9984652853012084 and perplexity is 54.514421715735374
At time: 515.1414542198181 and batch: 500, loss is 3.992172794342041 and perplexity is 54.172467211078626
At time: 515.5456471443176 and batch: 550, loss is 4.038360347747803 and perplexity is 56.7332437104321
At time: 515.9521887302399 and batch: 600, loss is 3.9604708766937256 and perplexity is 52.4820326977632
At time: 516.3477714061737 and batch: 650, loss is 4.041851363182068 and perplexity is 56.93164645187983
At time: 516.7388334274292 and batch: 700, loss is 4.091095566749573 and perplexity is 59.80537660811109
At time: 517.142853975296 and batch: 750, loss is 4.045002012252808 and perplexity is 57.111300956404996
At time: 517.5602366924286 and batch: 800, loss is 3.9848505067825317 and perplexity is 53.777249542886075
At time: 517.9690136909485 and batch: 850, loss is 3.9302482128143312 and perplexity is 50.91961500170685
At time: 518.3672721385956 and batch: 900, loss is 3.8692472696304323 and perplexity is 47.90631196956953
At time: 518.7641839981079 and batch: 950, loss is 3.9806226253509522 and perplexity is 53.550365665131224
At time: 519.162356376648 and batch: 1000, loss is 4.014679923057556 and perplexity is 55.40555852229588
At time: 519.570155620575 and batch: 1050, loss is 3.923557324409485 and perplexity is 50.5800547866502
At time: 519.9707098007202 and batch: 1100, loss is 4.059459390640259 and perplexity is 57.94297809398106
At time: 520.369410276413 and batch: 1150, loss is 3.9751887273788453 and perplexity is 53.26016760911406
At time: 520.7717123031616 and batch: 1200, loss is 3.931873984336853 and perplexity is 51.00246599185574
At time: 521.1704058647156 and batch: 1250, loss is 3.9166867399215697 and perplexity is 50.23373133146149
At time: 521.5638957023621 and batch: 1300, loss is 3.981706895828247 and perplexity is 53.60846023509229
At time: 521.956184387207 and batch: 1350, loss is 3.9255189418792726 and perplexity is 50.679370883991425
At time: 522.3442711830139 and batch: 1400, loss is 3.817159824371338 and perplexity is 45.47486812119747
At time: 522.7402622699738 and batch: 1450, loss is 3.8966679620742797 and perplexity is 49.23811221191366
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.717527731870994 and perplexity of 111.89128518166791
Finished 42 epochs...
Completing Train Step...
At time: 524.0718474388123 and batch: 50, loss is 4.108761978149414 and perplexity is 60.871310888740155
At time: 524.5023944377899 and batch: 100, loss is 4.115664176940918 and perplexity is 61.29291008416251
At time: 524.9021408557892 and batch: 150, loss is 3.981115097999573 and perplexity is 53.57674425037768
At time: 525.2932660579681 and batch: 200, loss is 4.051842813491821 and perplexity is 57.50332737335914
At time: 525.6964483261108 and batch: 250, loss is 4.089718012809754 and perplexity is 59.72304819487647
At time: 526.1078827381134 and batch: 300, loss is 4.092150783538818 and perplexity is 59.86851755342904
At time: 526.5242431163788 and batch: 350, loss is 4.0835167503356935 and perplexity is 59.35383587172245
At time: 526.9124233722687 and batch: 400, loss is 3.9491853952407836 and perplexity is 51.89307726481718
At time: 527.3052427768707 and batch: 450, loss is 3.9983229494094847 and perplexity is 54.5066629091001
At time: 527.6965379714966 and batch: 500, loss is 3.9920194292068483 and perplexity is 54.16415968038014
At time: 528.0876574516296 and batch: 550, loss is 4.038196024894714 and perplexity is 56.723921907874185
At time: 528.4893038272858 and batch: 600, loss is 3.96031879901886 and perplexity is 52.47405195911978
At time: 528.8872730731964 and batch: 650, loss is 4.041720128059387 and perplexity is 56.92417551050897
At time: 529.2880909442902 and batch: 700, loss is 4.090893921852111 and perplexity is 59.79331837485877
At time: 529.682014465332 and batch: 750, loss is 4.044845275878906 and perplexity is 57.10235023965404
At time: 530.0971043109894 and batch: 800, loss is 3.9847178983688356 and perplexity is 53.77011869994659
At time: 530.5140051841736 and batch: 850, loss is 3.9301831769943236 and perplexity is 50.916303510474684
At time: 530.9151697158813 and batch: 900, loss is 3.869237308502197 and perplexity is 47.905834771029454
At time: 531.3110868930817 and batch: 950, loss is 3.9805389547348025 and perplexity is 53.5458852604827
At time: 531.7035460472107 and batch: 1000, loss is 4.014654092788696 and perplexity is 55.40412740030613
At time: 532.107479095459 and batch: 1050, loss is 3.92354287147522 and perplexity is 50.579323761725995
At time: 532.4977495670319 and batch: 1100, loss is 4.059386405944824 and perplexity is 57.93874929769287
At time: 532.8906593322754 and batch: 1150, loss is 3.975108995437622 and perplexity is 53.25592124184852
At time: 533.2931153774261 and batch: 1200, loss is 3.931898775100708 and perplexity is 51.0037303976189
At time: 533.6932353973389 and batch: 1250, loss is 3.916775345802307 and perplexity is 50.23818253266723
At time: 534.099160194397 and batch: 1300, loss is 3.9817328357696535 and perplexity is 53.60985085344588
At time: 534.5086181163788 and batch: 1350, loss is 3.9255815982818603 and perplexity is 50.68254637053766
At time: 534.916024684906 and batch: 1400, loss is 3.8171701574325563 and perplexity is 45.475338018221386
At time: 535.3248081207275 and batch: 1450, loss is 3.896691632270813 and perplexity is 49.239277701500285
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.717530861879006 and perplexity of 111.89163540283519
Annealing...
Finished 43 epochs...
Completing Train Step...
At time: 536.6454925537109 and batch: 50, loss is 4.108558130264282 and perplexity is 60.858903665386364
At time: 537.0403592586517 and batch: 100, loss is 4.115506567955017 and perplexity is 61.28325053199735
At time: 537.4308340549469 and batch: 150, loss is 3.9812284994125364 and perplexity is 53.58282027338594
At time: 537.8399481773376 and batch: 200, loss is 4.051588625907898 and perplexity is 57.488712599032326
At time: 538.2493159770966 and batch: 250, loss is 4.0895061206817624 and perplexity is 59.71039469174053
At time: 538.6526823043823 and batch: 300, loss is 4.091875929832458 and perplexity is 59.85206473064844
At time: 539.0512020587921 and batch: 350, loss is 4.0834012222290035 and perplexity is 59.34697923151436
At time: 539.4425926208496 and batch: 400, loss is 3.948850016593933 and perplexity is 51.87567635289344
At time: 539.8456125259399 and batch: 450, loss is 3.998063282966614 and perplexity is 54.49251119527184
At time: 540.2446701526642 and batch: 500, loss is 3.9916342592239378 and perplexity is 54.14330128919265
At time: 540.6439139842987 and batch: 550, loss is 4.0377884149551395 and perplexity is 56.70080538507518
At time: 541.0460832118988 and batch: 600, loss is 3.9598572635650635 and perplexity is 52.449838911756
At time: 541.4495432376862 and batch: 650, loss is 4.041305460929871 and perplexity is 56.900575819396195
At time: 541.8507015705109 and batch: 700, loss is 4.090382823944092 and perplexity is 59.762765943230846
At time: 542.2679874897003 and batch: 750, loss is 4.044339017868042 and perplexity is 57.07344903375684
At time: 542.6700277328491 and batch: 800, loss is 3.9842525148391723 and perplexity is 53.74510079422777
At time: 543.0674514770508 and batch: 850, loss is 3.9297850036621096 and perplexity is 50.89603403189261
At time: 543.4668850898743 and batch: 900, loss is 3.8688331174850465 and perplexity is 47.886475575615904
At time: 543.8681781291962 and batch: 950, loss is 3.979933557510376 and perplexity is 53.51347854062545
At time: 544.2744674682617 and batch: 1000, loss is 4.014305505752564 and perplexity is 55.38481760551375
At time: 544.6819379329681 and batch: 1050, loss is 3.922879705429077 and perplexity is 50.54579239123244
At time: 545.1147136688232 and batch: 1100, loss is 4.058817610740662 and perplexity is 57.90580338558382
At time: 545.5195984840393 and batch: 1150, loss is 3.974357900619507 and perplexity is 53.215936013598466
At time: 545.9328353404999 and batch: 1200, loss is 3.931181302070618 and perplexity is 50.96714972101828
At time: 546.3375506401062 and batch: 1250, loss is 3.9163701343536377 and perplexity is 50.21782956984992
At time: 546.7344949245453 and batch: 1300, loss is 3.981053285598755 and perplexity is 53.573432645537736
At time: 547.1406497955322 and batch: 1350, loss is 3.9248222970962523 and perplexity is 50.64407765950605
At time: 547.5378365516663 and batch: 1400, loss is 3.8162944507598877 and perplexity is 45.43553239284663
At time: 547.9355130195618 and batch: 1450, loss is 3.8958546209335325 and perplexity is 49.19808111123632
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.717471913394765 and perplexity of 111.88503975493252
Finished 44 epochs...
Completing Train Step...
At time: 549.2469055652618 and batch: 50, loss is 4.1083564281463625 and perplexity is 60.84662953352358
At time: 549.6462593078613 and batch: 100, loss is 4.115378994941711 and perplexity is 61.27543294172917
At time: 550.059900522232 and batch: 150, loss is 3.9810219192504883 and perplexity is 53.57175226894531
At time: 550.4597177505493 and batch: 200, loss is 4.051414179801941 and perplexity is 57.47868479166435
At time: 550.8623602390289 and batch: 250, loss is 4.089369807243347 and perplexity is 59.70225591725575
At time: 551.2506895065308 and batch: 300, loss is 4.091730532646179 and perplexity is 59.84336304145949
At time: 551.6499664783478 and batch: 350, loss is 4.083280067443848 and perplexity is 59.33978949654014
At time: 552.0598268508911 and batch: 400, loss is 3.9487724256515504 and perplexity is 51.87165142642942
At time: 552.465327501297 and batch: 450, loss is 3.9979604196548464 and perplexity is 54.48690620338273
At time: 552.8675758838654 and batch: 500, loss is 3.991539030075073 and perplexity is 54.13814551418808
At time: 553.2606725692749 and batch: 550, loss is 4.037683076858521 and perplexity is 56.69483294472744
At time: 553.6554932594299 and batch: 600, loss is 3.959786205291748 and perplexity is 52.44611204918102
At time: 554.0590350627899 and batch: 650, loss is 4.041242575645446 and perplexity is 56.89699772300787
At time: 554.4572339057922 and batch: 700, loss is 4.0902756357192995 and perplexity is 59.75636042174509
At time: 554.8738512992859 and batch: 750, loss is 4.0442504835128785 and perplexity is 57.068396296423394
At time: 555.299542427063 and batch: 800, loss is 3.984159164428711 and perplexity is 53.7400839011765
At time: 555.7014462947845 and batch: 850, loss is 3.929742512702942 and perplexity is 50.89387145653404
At time: 556.0878992080688 and batch: 900, loss is 3.8688155794143677 and perplexity is 47.88563574658721
At time: 556.4974536895752 and batch: 950, loss is 3.9798702716827394 and perplexity is 53.51009200300734
At time: 556.899569272995 and batch: 1000, loss is 4.01428412437439 and perplexity is 55.38363341444331
At time: 557.3029363155365 and batch: 1050, loss is 3.922916502952576 and perplexity is 50.54765238543711
At time: 557.7020611763 and batch: 1100, loss is 4.058797316551209 and perplexity is 57.90462824616375
At time: 558.1163413524628 and batch: 1150, loss is 3.97429545879364 and perplexity is 53.21261321713038
At time: 558.5264890193939 and batch: 1200, loss is 3.93125901222229 and perplexity is 50.97111053984932
At time: 558.9210817813873 and batch: 1250, loss is 3.916460008621216 and perplexity is 50.2223430633223
At time: 559.3281168937683 and batch: 1300, loss is 3.9810729026794434 and perplexity is 53.57448361019709
At time: 559.7362275123596 and batch: 1350, loss is 3.9248721694946287 and perplexity is 50.64660346410594
At time: 560.1510500907898 and batch: 1400, loss is 3.816296195983887 and perplexity is 45.435611688097374
At time: 560.5557770729065 and batch: 1450, loss is 3.8958757877349854 and perplexity is 49.199122488272344
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.717468783386752 and perplexity of 111.88468955440965
Finished 45 epochs...
Completing Train Step...
At time: 561.9139597415924 and batch: 50, loss is 4.108276467323304 and perplexity is 60.8417643814591
At time: 562.3386924266815 and batch: 100, loss is 4.11523898601532 and perplexity is 61.26685443469663
At time: 562.7387990951538 and batch: 150, loss is 3.9809090757369994 and perplexity is 53.56570738526489
At time: 563.1305470466614 and batch: 200, loss is 4.051275572776794 and perplexity is 57.470718394268125
At time: 563.5241324901581 and batch: 250, loss is 4.089239621162415 and perplexity is 59.694484020442424
At time: 563.9179170131683 and batch: 300, loss is 4.091603379249573 and perplexity is 59.8357542383373
At time: 564.307112455368 and batch: 350, loss is 4.083177208900452 and perplexity is 59.333686206120234
At time: 564.7099268436432 and batch: 400, loss is 3.948711256980896 and perplexity is 51.86847860350669
At time: 565.1088118553162 and batch: 450, loss is 3.9978709411621094 and perplexity is 54.48203101525724
At time: 565.5190193653107 and batch: 500, loss is 3.9914494276046755 and perplexity is 54.133294819927606
At time: 565.9203519821167 and batch: 550, loss is 4.037593011856079 and perplexity is 56.6897269543988
At time: 566.3136518001556 and batch: 600, loss is 3.9597084426879885 and perplexity is 52.44203386151832
At time: 566.7120895385742 and batch: 650, loss is 4.041184496879578 and perplexity is 56.89369331155749
At time: 567.1153438091278 and batch: 700, loss is 4.090165891647339 and perplexity is 59.74980287525938
At time: 567.5198819637299 and batch: 750, loss is 4.0441640186309815 and perplexity is 57.063462097598105
At time: 567.915253162384 and batch: 800, loss is 3.9840729236602783 and perplexity is 53.735449514884614
At time: 568.3155364990234 and batch: 850, loss is 3.9297040414810183 and perplexity is 50.89191354477255
At time: 568.7115643024445 and batch: 900, loss is 3.868803815841675 and perplexity is 47.8850724437434
At time: 569.1009075641632 and batch: 950, loss is 3.979821829795837 and perplexity is 53.50749993596522
At time: 569.4900300502777 and batch: 1000, loss is 4.014284687042236 and perplexity is 55.38366457704183
At time: 569.8770327568054 and batch: 1050, loss is 3.9229465198516844 and perplexity is 50.54916969199124
At time: 570.2691764831543 and batch: 1100, loss is 4.058771228790283 and perplexity is 57.90311766376952
At time: 570.6649100780487 and batch: 1150, loss is 3.974249367713928 and perplexity is 53.21016064685415
At time: 571.0502722263336 and batch: 1200, loss is 3.9313348150253296 and perplexity is 50.97497443934763
At time: 571.4548110961914 and batch: 1250, loss is 3.916539330482483 and perplexity is 50.22632695105388
At time: 571.841362953186 and batch: 1300, loss is 3.9810833597183226 and perplexity is 53.575043843584325
At time: 572.236022233963 and batch: 1350, loss is 3.9249159574508665 and perplexity is 50.648821223917246
At time: 572.631236076355 and batch: 1400, loss is 3.816290225982666 and perplexity is 45.4353404382498
At time: 573.023864030838 and batch: 1450, loss is 3.8958858013153077 and perplexity is 49.19961515010381
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.717469826722756 and perplexity of 111.88480628779548
Annealing...
Finished 46 epochs...
Completing Train Step...
At time: 574.3303995132446 and batch: 50, loss is 4.108168978691101 and perplexity is 60.8352249348893
At time: 574.7402365207672 and batch: 100, loss is 4.115148072242737 and perplexity is 61.2612846870129
At time: 575.1411266326904 and batch: 150, loss is 3.980995984077454 and perplexity is 53.57036289429737
At time: 575.5480978488922 and batch: 200, loss is 4.051138753890991 and perplexity is 57.46285585249549
At time: 575.9414269924164 and batch: 250, loss is 4.089117641448975 and perplexity is 59.68720294846822
At time: 576.347412109375 and batch: 300, loss is 4.0914679479599 and perplexity is 59.8276511536902
At time: 576.7530102729797 and batch: 350, loss is 4.083176608085632 and perplexity is 59.333650557572994
At time: 577.1492373943329 and batch: 400, loss is 3.9484837818145753 and perplexity is 51.85668115457375
At time: 577.5396373271942 and batch: 450, loss is 3.9976828145980834 and perplexity is 54.471782462003965
At time: 577.9433553218842 and batch: 500, loss is 3.9912205743789673 and perplexity is 54.12090765826487
At time: 578.3529658317566 and batch: 550, loss is 4.03741379737854 and perplexity is 56.67956824492194
At time: 578.7532708644867 and batch: 600, loss is 3.959416055679321 and perplexity is 52.42670273352967
At time: 579.1441481113434 and batch: 650, loss is 4.041016368865967 and perplexity is 56.88412869197681
At time: 579.534969329834 and batch: 700, loss is 4.089897117614746 and perplexity is 59.73374583774799
At time: 579.9354741573334 and batch: 750, loss is 4.043894462585449 and perplexity is 57.04808236935317
At time: 580.3251333236694 and batch: 800, loss is 3.983818883895874 and perplexity is 53.721800307743784
At time: 580.7281732559204 and batch: 850, loss is 3.9294893598556517 and perplexity is 50.88098915872918
At time: 581.127090215683 and batch: 900, loss is 3.8686030673980714 and perplexity is 47.875460554796625
At time: 581.5255603790283 and batch: 950, loss is 3.9794887590408323 and perplexity is 53.489681120191065
At time: 581.9272058010101 and batch: 1000, loss is 4.014160113334656 and perplexity is 55.376765658326924
At time: 582.3174703121185 and batch: 1050, loss is 3.92263286113739 and perplexity is 50.53331699071592
At time: 582.7255022525787 and batch: 1100, loss is 4.058505139350891 and perplexity is 57.88771230534382
At time: 583.1254730224609 and batch: 1150, loss is 3.973904356956482 and perplexity is 53.19180573552854
At time: 583.5430834293365 and batch: 1200, loss is 3.9309575939178467 and perplexity is 50.95574922934119
At time: 583.9465494155884 and batch: 1250, loss is 3.916369605064392 and perplexity is 50.21780299009981
At time: 584.350732088089 and batch: 1300, loss is 3.9807483100891115 and perplexity is 53.55709655179418
At time: 584.7588028907776 and batch: 1350, loss is 3.9244393587112425 and perplexity is 50.62468781099239
At time: 585.1705188751221 and batch: 1400, loss is 3.815842695236206 and perplexity is 45.415011275729746
At time: 585.5794665813446 and batch: 1450, loss is 3.8954622602462767 and perplexity is 49.178781504770875
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.717435396634615 and perplexity of 111.88095415036841
Finished 47 epochs...
Completing Train Step...
At time: 586.9863700866699 and batch: 50, loss is 4.108055386543274 and perplexity is 60.828314923494375
At time: 587.3903498649597 and batch: 100, loss is 4.1150639486312866 and perplexity is 61.25613138326325
At time: 587.8028755187988 and batch: 150, loss is 3.980847706794739 and perplexity is 53.56242021532733
At time: 588.2157926559448 and batch: 200, loss is 4.051059560775757 and perplexity is 57.45830537011608
At time: 588.6174190044403 and batch: 250, loss is 4.089051470756531 and perplexity is 59.68325353558823
At time: 589.0188174247742 and batch: 300, loss is 4.0913920545578 and perplexity is 59.82311080199806
At time: 589.427980184555 and batch: 350, loss is 4.083102264404297 and perplexity is 59.329239639527444
At time: 589.8375723361969 and batch: 400, loss is 3.948437843322754 and perplexity is 51.85429899156756
At time: 590.2421207427979 and batch: 450, loss is 3.9976293087005614 and perplexity is 54.46886797836544
At time: 590.6405379772186 and batch: 500, loss is 3.991172251701355 and perplexity is 54.118292454279356
At time: 591.0408751964569 and batch: 550, loss is 4.037363314628601 and perplexity is 56.67670697667455
At time: 591.4372582435608 and batch: 600, loss is 3.9593867826461793 and perplexity is 52.42516806738531
At time: 591.8281419277191 and batch: 650, loss is 4.040991101264954 and perplexity is 56.882691384667766
At time: 592.2328014373779 and batch: 700, loss is 4.089847145080566 and perplexity is 59.73076086567634
At time: 592.6349277496338 and batch: 750, loss is 4.043854084014892 and perplexity is 57.045778895839895
At time: 593.0460398197174 and batch: 800, loss is 3.9837732315063477 and perplexity is 53.719347835171114
At time: 593.4460883140564 and batch: 850, loss is 3.929468421936035 and perplexity is 50.8799238278211
At time: 593.858617067337 and batch: 900, loss is 3.8685992670059206 and perplexity is 47.87527860961785
At time: 594.2577800750732 and batch: 950, loss is 3.97945107460022 and perplexity is 53.48766542945984
At time: 594.6626961231232 and batch: 1000, loss is 4.014146780967712 and perplexity is 55.37602735988865
At time: 595.075355052948 and batch: 1050, loss is 3.9226687955856323 and perplexity is 50.53513291020667
At time: 595.4820024967194 and batch: 1100, loss is 4.058500704765319 and perplexity is 57.88745559789925
At time: 595.8819289207458 and batch: 1150, loss is 3.9738711500167847 and perplexity is 53.1900394277701
At time: 596.310779094696 and batch: 1200, loss is 3.9310139513015745 and perplexity is 50.95862104297684
At time: 596.7151470184326 and batch: 1250, loss is 3.9164165925979613 and perplexity is 50.2201626562406
At time: 597.1196632385254 and batch: 1300, loss is 3.9807602310180665 and perplexity is 53.55773500594269
At time: 597.5232713222504 and batch: 1350, loss is 3.9244498920440676 and perplexity is 50.625221060486716
At time: 597.9367990493774 and batch: 1400, loss is 3.815840229988098 and perplexity is 45.414899316597136
At time: 598.3423285484314 and batch: 1450, loss is 3.895469837188721 and perplexity is 49.17915413097949
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.7174317449586 and perplexity of 111.88054559811756
Finished 48 epochs...
Completing Train Step...
At time: 599.7012903690338 and batch: 50, loss is 4.108019151687622 and perplexity is 60.826110858215806
At time: 600.1031029224396 and batch: 100, loss is 4.114984526634216 and perplexity is 61.25126649216822
At time: 600.5183165073395 and batch: 150, loss is 3.9807811546325684 and perplexity is 53.55885563906736
At time: 600.9172480106354 and batch: 200, loss is 4.050990552902221 and perplexity is 57.454340431453105
At time: 601.3234186172485 and batch: 250, loss is 4.088982710838318 and perplexity is 59.67914986104219
At time: 601.7202081680298 and batch: 300, loss is 4.091325922012329 and perplexity is 59.819154678218446
At time: 602.1216957569122 and batch: 350, loss is 4.083045349121094 and perplexity is 59.325862995143396
At time: 602.5206532478333 and batch: 400, loss is 3.9484047412872316 and perplexity is 51.85258253712958
At time: 602.9136829376221 and batch: 450, loss is 3.997574276924133 and perplexity is 54.465870542278424
At time: 603.3180673122406 and batch: 500, loss is 3.991122832298279 and perplexity is 54.115618026655625
At time: 603.7187359333038 and batch: 550, loss is 4.037321276664734 and perplexity is 56.67432445339312
At time: 604.1279363632202 and batch: 600, loss is 3.959345417022705 and perplexity is 52.42299951247458
At time: 604.5286922454834 and batch: 650, loss is 4.040969862937927 and perplexity is 56.88148330429482
At time: 604.9386284351349 and batch: 700, loss is 4.089793467521668 and perplexity is 59.727554750290935
At time: 605.3351142406464 and batch: 750, loss is 4.043811583518982 and perplexity is 57.04335447346719
At time: 605.7465326786041 and batch: 800, loss is 3.983727312088013 and perplexity is 53.71688113060045
At time: 606.1388976573944 and batch: 850, loss is 3.9294494867324827 and perplexity is 50.87896041522794
At time: 606.5609118938446 and batch: 900, loss is 3.8685925579071045 and perplexity is 47.87495741072029
At time: 606.9746415615082 and batch: 950, loss is 3.9794246625900267 and perplexity is 53.486252731351485
At time: 607.3897249698639 and batch: 1000, loss is 4.014150247573853 and perplexity is 55.37621932709789
At time: 607.7982225418091 and batch: 1050, loss is 3.922696042060852 and perplexity is 50.53650983321129
At time: 608.202761888504 and batch: 1100, loss is 4.058492603302002 and perplexity is 57.88698662670088
At time: 608.6147227287292 and batch: 1150, loss is 3.9738477993011476 and perplexity is 53.188797416785675
At time: 609.0165092945099 and batch: 1200, loss is 3.9310583114624023 and perplexity is 50.9608816257414
At time: 609.4153280258179 and batch: 1250, loss is 3.916461319923401 and perplexity is 50.22240892003368
At time: 609.8127465248108 and batch: 1300, loss is 3.9807676029205323 and perplexity is 53.55812982979675
At time: 610.2126908302307 and batch: 1350, loss is 3.924462924003601 and perplexity is 50.62588081061784
At time: 610.6083252429962 and batch: 1400, loss is 3.815834197998047 and perplexity is 45.4146253752025
At time: 611.0170683860779 and batch: 1450, loss is 3.8954725456237793 and perplexity is 49.17928732970506
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.717431223290598 and perplexity of 111.88048723363208
Finished 49 epochs...
Completing Train Step...
At time: 612.3566439151764 and batch: 50, loss is 4.107985663414001 and perplexity is 60.82407393087888
At time: 612.7719509601593 and batch: 100, loss is 4.114913263320923 and perplexity is 61.24690167950194
At time: 613.1604452133179 and batch: 150, loss is 3.9807329988479614 and perplexity is 53.556276532451356
At time: 613.5732309818268 and batch: 200, loss is 4.05092104434967 and perplexity is 57.450347002202285
At time: 613.9685146808624 and batch: 250, loss is 4.088920822143555 and perplexity is 59.675456510642235
At time: 614.3747754096985 and batch: 300, loss is 4.091261234283447 and perplexity is 59.81528523811267
At time: 614.767302274704 and batch: 350, loss is 4.082994508743286 and perplexity is 59.32284692252472
At time: 615.165061712265 and batch: 400, loss is 3.9483694934844973 and perplexity is 51.85075487973969
At time: 615.5556132793427 and batch: 450, loss is 3.997521719932556 and perplexity is 54.46300805520161
At time: 615.9452545642853 and batch: 500, loss is 3.991073875427246 and perplexity is 54.112968760173445
At time: 616.3568842411041 and batch: 550, loss is 4.037280411720276 and perplexity is 56.67200850759293
At time: 616.7675075531006 and batch: 600, loss is 3.959301624298096 and perplexity is 52.420703816761495
At time: 617.1710925102234 and batch: 650, loss is 4.040949473381042 and perplexity is 56.88032352787901
At time: 617.5606942176819 and batch: 700, loss is 4.08973961353302 and perplexity is 59.72433826984636
At time: 617.9584093093872 and batch: 750, loss is 4.043768429756165 and perplexity is 57.04089289119158
At time: 618.3775534629822 and batch: 800, loss is 3.9836825227737425 and perplexity is 53.71447524220932
At time: 618.789733171463 and batch: 850, loss is 3.929431986808777 and perplexity is 50.87807004509317
At time: 619.190438747406 and batch: 900, loss is 3.8685851383209227 and perplexity is 47.87460219966559
At time: 619.5884656906128 and batch: 950, loss is 3.9794021129608153 and perplexity is 53.48504664978288
At time: 619.9984803199768 and batch: 1000, loss is 4.014160175323486 and perplexity is 55.37676909106795
At time: 620.3995530605316 and batch: 1050, loss is 3.9227197790145873 and perplexity is 50.53770943024448
At time: 620.8080930709839 and batch: 1100, loss is 4.058482871055603 and perplexity is 57.88642325902516
At time: 621.2060947418213 and batch: 1150, loss is 3.973827953338623 and perplexity is 53.18774184437988
At time: 621.6018929481506 and batch: 1200, loss is 3.931094365119934 and perplexity is 50.962718985036624
At time: 622.0013620853424 and batch: 1250, loss is 3.9165035104751587 and perplexity is 50.224527875876255
At time: 622.4026918411255 and batch: 1300, loss is 3.9807727193832396 and perplexity is 53.55840385867172
At time: 622.814667224884 and batch: 1350, loss is 3.9244760036468507 and perplexity is 50.62654298340854
At time: 623.2051849365234 and batch: 1400, loss is 3.8158267164230346 and perplexity is 45.41428560354711
At time: 623.6022610664368 and batch: 1450, loss is 3.895472731590271 and perplexity is 49.17929647540544
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.7174317449586 and perplexity of 111.88054559811756
Annealing...
Finished Training.
Improved accuracyfrom -118.05899012925926 to -111.88048723363208
<pretraining.langmodel.trainer.TrainLangModel object at 0x7fc1edec7c50>
Saving Model Parameters and Results...
/home-nfs/siddsach/Interpreting-Attention/interpreting_language/trained_models/langmodel/



RESULTS:
[{'best_accuracy': -118.05899012925926, 'params': {'batch_size': 20, 'lr': 14.518175663874873, 'num_layers': 1, 'wordvec_source': '', 'seq_len': 35, 'anneal': 2.0074897365311104, 'wordvec_dim': 200, 'dropout': 0.4746396332197276, 'tune_wordvecs': True, 'data': 'ptb'}}, {'best_accuracy': -129.81132959852954, 'params': {'batch_size': 20, 'lr': 14.711765920568743, 'num_layers': 1, 'wordvec_source': '', 'seq_len': 35, 'anneal': 2.1350035374060834, 'wordvec_dim': 200, 'dropout': 0.7670515392427568, 'tune_wordvecs': True, 'data': 'ptb'}}, {'best_accuracy': -154.86455465005716, 'params': {'batch_size': 20, 'lr': 23.81289885111111, 'num_layers': 1, 'wordvec_source': '', 'seq_len': 35, 'anneal': 3.846529973176787, 'wordvec_dim': 200, 'dropout': 0.9642517586214361, 'tune_wordvecs': True, 'data': 'ptb'}}, {'best_accuracy': -153.43158542724643, 'params': {'batch_size': 20, 'lr': 24.58191061908424, 'num_layers': 1, 'wordvec_source': '', 'seq_len': 35, 'anneal': 3.5317084089400117, 'wordvec_dim': 200, 'dropout': 0.8125441635649477, 'tune_wordvecs': True, 'data': 'ptb'}}, {'best_accuracy': -141.21101110098107, 'params': {'batch_size': 20, 'lr': 26.410164837461025, 'num_layers': 1, 'wordvec_source': '', 'seq_len': 35, 'anneal': 3.150272923004872, 'wordvec_dim': 200, 'dropout': 0.2756808995762696, 'tune_wordvecs': True, 'data': 'ptb'}}, {'best_accuracy': -111.88048723363208, 'params': {'batch_size': 20, 'lr': 14.33456185346495, 'num_layers': 1, 'wordvec_source': '', 'seq_len': 35, 'anneal': 2.0, 'wordvec_dim': 200, 'dropout': 0.19729647227169755, 'tune_wordvecs': True, 'data': 'ptb'}}]
