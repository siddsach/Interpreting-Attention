Building Bayesian Optimizer for 
 data:ptb 
 choices:[{'domain': [0, 30], 'type': 'continuous', 'name': 'lr'}, {'domain': [0, 1], 'type': 'continuous', 'name': 'dropout'}, {'domain': [2, 8], 'type': 'continuous', 'name': 'anneal'}]
SETTINGS FOR THIS RUN
{'batch_size': 20, 'seq_len': 35, 'anneal': 5.135761720632871, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'dropout': 0.25248092910318143, 'lr': 24.94667119673739, 'num_layers': 1, 'wordvec_dim': 200, 'data': 'ptb'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.9436776638031006 and batch: 50, loss is 6.870360927581787 and perplexity is 963.2961832378423
At time: 1.331648349761963 and batch: 100, loss is 5.971770324707031 and perplexity is 392.19937677304
At time: 1.6980526447296143 and batch: 150, loss is 5.946216230392456 and perplexity is 382.3040484599569
At time: 2.064927577972412 and batch: 200, loss is 5.923974637985229 and perplexity is 373.89486115452235
At time: 2.4354984760284424 and batch: 250, loss is 5.9744033527374265 and perplexity is 393.23340944669576
At time: 2.805621385574341 and batch: 300, loss is 6.06594765663147 and perplexity is 430.9308587198842
At time: 3.176696538925171 and batch: 350, loss is 6.165780153274536 and perplexity is 476.1724855883183
At time: 3.5479636192321777 and batch: 400, loss is 6.108855333328247 and perplexity is 449.8235223676353
At time: 3.9183661937713623 and batch: 450, loss is 6.236323575973511 and perplexity is 510.9764872693355
At time: 4.285079717636108 and batch: 500, loss is 6.21819185256958 and perplexity is 501.79509173618106
At time: 4.650890827178955 and batch: 550, loss is 6.33528353691101 and perplexity is 564.1293317992855
At time: 5.015307188034058 and batch: 600, loss is 6.342835006713867 and perplexity is 568.4054626292889
At time: 5.3800742626190186 and batch: 650, loss is 6.440901908874512 and perplexity is 626.9720165119585
At time: 5.743880748748779 and batch: 700, loss is 6.464170646667481 and perplexity is 641.7319201781745
At time: 6.106501817703247 and batch: 750, loss is 6.2938172721862795 and perplexity is 541.2153572493635
At time: 6.470512866973877 and batch: 800, loss is 6.228705244064331 and perplexity is 507.09848948489844
At time: 6.835156440734863 and batch: 850, loss is 6.203010110855103 and perplexity is 494.2345049144591
At time: 7.207895278930664 and batch: 900, loss is 6.2120265293121335 and perplexity is 498.71088013692446
At time: 7.60424017906189 and batch: 950, loss is 6.289194660186768 and perplexity is 538.719302236303
At time: 7.987468481063843 and batch: 1000, loss is 6.447879991531372 and perplexity is 631.3623794090983
At time: 8.361508846282959 and batch: 1050, loss is 6.518672380447388 and perplexity is 677.6780891647248
At time: 8.747389316558838 and batch: 1100, loss is 6.456119022369385 and perplexity is 636.5856814491488
At time: 9.125621557235718 and batch: 1150, loss is 6.767477283477783 and perplexity is 869.1165913072335
At time: 9.494460821151733 and batch: 1200, loss is 6.3756171989440915 and perplexity is 587.3478295543996
At time: 9.861129760742188 and batch: 1250, loss is 6.454289646148681 and perplexity is 635.4221912961546
At time: 10.225704908370972 and batch: 1300, loss is 6.455065107345581 and perplexity is 635.9151276509594
At time: 10.59151816368103 and batch: 1350, loss is 6.285908966064453 and perplexity is 536.9521401582194
At time: 10.95555830001831 and batch: 1400, loss is 6.30805853843689 and perplexity is 548.9780936501884
At time: 11.3204927444458 and batch: 1450, loss is 6.392566318511963 and perplexity is 597.3877012914731
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 6.235636914897169 and perplexity of 510.625740040618
Finished 1 epochs...
Completing Train Step...
At time: 12.57291293144226 and batch: 50, loss is 6.339287242889404 and perplexity is 566.3924672188953
At time: 12.93198823928833 and batch: 100, loss is 6.422075452804566 and perplexity is 615.2787719366581
At time: 13.291240692138672 and batch: 150, loss is 6.201378555297851 and perplexity is 493.4287913233564
At time: 13.664422035217285 and batch: 200, loss is 6.277776279449463 and perplexity is 532.6029858010548
At time: 14.02266550064087 and batch: 250, loss is 6.273911762237549 and perplexity is 530.54870435495
At time: 14.380908012390137 and batch: 300, loss is 6.440613689422608 and perplexity is 626.791337019923
At time: 14.738081455230713 and batch: 350, loss is 6.219869441986084 and perplexity is 502.63760436887856
At time: 15.097295999526978 and batch: 400, loss is 6.3352655410766605 and perplexity is 564.1191799126246
At time: 15.45510482788086 and batch: 450, loss is 6.256662883758545 and perplexity is 521.47580782034
At time: 15.812369346618652 and batch: 500, loss is 6.22094422340393 and perplexity is 503.17812034219526
At time: 16.171458959579468 and batch: 550, loss is 6.334676580429077 and perplexity is 563.7870337352241
At time: 16.527349948883057 and batch: 600, loss is 6.105723781585693 and perplexity is 448.4170800551304
At time: 16.88543200492859 and batch: 650, loss is 6.239259691238403 and perplexity is 512.4789777969089
At time: 17.24385643005371 and batch: 700, loss is 6.219295654296875 and perplexity is 502.34927982580524
At time: 17.604058265686035 and batch: 750, loss is 6.196489295959473 and perplexity is 491.022178069859
At time: 17.963343381881714 and batch: 800, loss is 6.247739219665528 and perplexity is 516.8430342791268
At time: 18.3218936920166 and batch: 850, loss is 6.136905117034912 and perplexity is 462.6195994992868
At time: 18.681793928146362 and batch: 900, loss is 6.1621965980529785 and perplexity is 474.46914901439794
At time: 19.041499614715576 and batch: 950, loss is 6.266859121322632 and perplexity is 526.8200985690994
At time: 19.402504682540894 and batch: 1000, loss is 6.353337707519532 and perplexity is 574.4067146520474
At time: 19.763453245162964 and batch: 1050, loss is 6.147257986068726 and perplexity is 467.4339176273427
At time: 20.123178005218506 and batch: 1100, loss is 6.378030071258545 and perplexity is 588.7667360029284
At time: 20.481887817382812 and batch: 1150, loss is 6.385244474411011 and perplexity is 593.0296954635785
At time: 20.843219995498657 and batch: 1200, loss is 6.263666553497314 and perplexity is 525.1408716219302
At time: 21.206467628479004 and batch: 1250, loss is 6.248452043533325 and perplexity is 517.2115836696611
At time: 21.571223258972168 and batch: 1300, loss is 6.379863834381103 and perplexity is 589.8473852557499
At time: 21.936431884765625 and batch: 1350, loss is 6.29223219871521 and perplexity is 540.3581706757712
At time: 22.30005717277527 and batch: 1400, loss is 6.253331079483032 and perplexity is 519.7412437129267
At time: 22.664682388305664 and batch: 1450, loss is 6.308861789703369 and perplexity is 549.4192381504021
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 6.437826564169337 and perplexity of 625.0468232744325
Annealing...
Finished 2 epochs...
Completing Train Step...
At time: 23.903144359588623 and batch: 50, loss is 6.1066114044189455 and perplexity is 448.81528199463
At time: 24.2696635723114 and batch: 100, loss is 5.875943775177002 and perplexity is 356.3608265154583
At time: 24.636821031570435 and batch: 150, loss is 5.805023584365845 and perplexity is 331.96302238859187
At time: 25.004290103912354 and batch: 200, loss is 5.71968861579895 and perplexity is 304.8099951613524
At time: 25.37013292312622 and batch: 250, loss is 5.686098604202271 and perplexity is 294.741471468705
At time: 25.73696279525757 and batch: 300, loss is 5.742231292724609 and perplexity is 311.7592616578442
At time: 26.102234840393066 and batch: 350, loss is 5.737581567764282 and perplexity is 310.31303172861715
At time: 26.470648765563965 and batch: 400, loss is 5.634598913192749 and perplexity is 279.94661189702975
At time: 26.837424755096436 and batch: 450, loss is 5.661387004852295 and perplexity is 287.5471954501144
At time: 27.204358100891113 and batch: 500, loss is 5.665784587860108 and perplexity is 288.814492590629
At time: 27.573348999023438 and batch: 550, loss is 5.693320417404175 and perplexity is 296.87774391408857
At time: 27.940815925598145 and batch: 600, loss is 5.548027925491333 and perplexity is 256.73076415888977
At time: 28.306756734848022 and batch: 650, loss is 5.749211654663086 and perplexity is 313.94306715102573
At time: 28.674492835998535 and batch: 700, loss is 5.722773876190185 and perplexity is 305.7518655768943
At time: 29.052867650985718 and batch: 750, loss is 5.6523409175872805 and perplexity is 284.9577482680645
At time: 29.42375636100769 and batch: 800, loss is 5.6294818878173825 and perplexity is 278.5177767906636
At time: 29.79062008857727 and batch: 850, loss is 5.58360110282898 and perplexity is 266.02787667720605
At time: 30.15323829650879 and batch: 900, loss is 5.516345949172973 and perplexity is 248.72452262195623
At time: 30.515430688858032 and batch: 950, loss is 5.557360162734986 and perplexity is 259.1378508402159
At time: 30.878695487976074 and batch: 1000, loss is 5.607483625411987 and perplexity is 272.45776885437715
At time: 31.241060733795166 and batch: 1050, loss is 5.487988080978393 and perplexity is 241.77029495326096
At time: 31.625389575958252 and batch: 1100, loss is 5.5947350025177 and perplexity is 269.0063546394238
At time: 31.988327980041504 and batch: 1150, loss is 5.61012152671814 and perplexity is 273.1774343446605
At time: 32.35209798812866 and batch: 1200, loss is 5.553968315124512 and perplexity is 258.26038369871816
At time: 32.71525192260742 and batch: 1250, loss is 5.589099264144897 and perplexity is 267.4945692189922
At time: 33.078407287597656 and batch: 1300, loss is 5.714659671783448 and perplexity is 303.28097067205107
At time: 33.44105005264282 and batch: 1350, loss is 5.576133918762207 and perplexity is 264.0487958315722
At time: 33.803733587265015 and batch: 1400, loss is 5.491772594451905 and perplexity is 242.68701146085124
At time: 34.1670343875885 and batch: 1450, loss is 5.506848440170288 and perplexity is 246.3734416085016
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.635832436064369 and perplexity of 280.29214551363367
Finished 3 epochs...
Completing Train Step...
At time: 35.39068913459778 and batch: 50, loss is 5.624358234405517 and perplexity is 277.0943977975189
At time: 35.76568579673767 and batch: 100, loss is 5.629996995925904 and perplexity is 278.66128051264815
At time: 36.12770700454712 and batch: 150, loss is 5.581469993591309 and perplexity is 265.461545882474
At time: 36.49005055427551 and batch: 200, loss is 5.543168144226074 and perplexity is 255.4861355619647
At time: 36.85130524635315 and batch: 250, loss is 5.5421842765808105 and perplexity is 255.23489463354878
At time: 37.22022986412048 and batch: 300, loss is 5.611468124389648 and perplexity is 273.5455422326452
At time: 37.59517240524292 and batch: 350, loss is 5.641264657974244 and perplexity is 281.8188977216427
At time: 37.964600801467896 and batch: 400, loss is 5.531969318389892 and perplexity is 252.6409519196434
At time: 38.32587027549744 and batch: 450, loss is 5.55173059463501 and perplexity is 257.6831152700684
At time: 38.68803906440735 and batch: 500, loss is 5.552215366363526 and perplexity is 257.8080630423941
At time: 39.04943656921387 and batch: 550, loss is 5.613553419113159 and perplexity is 274.1165604722433
At time: 39.411251068115234 and batch: 600, loss is 5.46039529800415 and perplexity is 235.19037627851355
At time: 39.77368497848511 and batch: 650, loss is 5.643115482330322 and perplexity is 282.34097799195484
At time: 40.135756492614746 and batch: 700, loss is 5.618500356674194 and perplexity is 275.4759576355044
At time: 40.496821880340576 and batch: 750, loss is 5.564160451889038 and perplexity is 260.90606853840023
At time: 40.85859560966492 and batch: 800, loss is 5.532924365997315 and perplexity is 252.88235131191848
At time: 41.23836016654968 and batch: 850, loss is 5.478715677261352 and perplexity is 239.53886452128785
At time: 41.613304138183594 and batch: 900, loss is 5.440790319442749 and perplexity is 230.624378385273
At time: 41.97590351104736 and batch: 950, loss is 5.48874984741211 and perplexity is 241.9545376146541
At time: 42.336668968200684 and batch: 1000, loss is 5.545271148681641 and perplexity is 256.02398939966827
At time: 42.69871950149536 and batch: 1050, loss is 5.424641332626343 and perplexity is 226.92993935178822
At time: 43.0608069896698 and batch: 1100, loss is 5.5350736808776855 and perplexity is 253.42645963317057
At time: 43.42277479171753 and batch: 1150, loss is 5.521941614151001 and perplexity is 250.12020296043258
At time: 43.784876585006714 and batch: 1200, loss is 5.47756100654602 and perplexity is 239.2624356321256
At time: 44.14768195152283 and batch: 1250, loss is 5.5065114402771 and perplexity is 246.29042777360743
At time: 44.509663581848145 and batch: 1300, loss is 5.5950966072082515 and perplexity is 269.10364618852975
At time: 44.87236213684082 and batch: 1350, loss is 5.491865224838257 and perplexity is 242.70949269369214
At time: 45.234347343444824 and batch: 1400, loss is 5.418845329284668 and perplexity is 225.61845701443917
At time: 45.59679055213928 and batch: 1450, loss is 5.454223985671997 and perplexity is 233.74341243420065
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.597126235309829 and perplexity of 269.6503811577151
Finished 4 epochs...
Completing Train Step...
At time: 46.83002233505249 and batch: 50, loss is 5.567476148605347 and perplexity is 261.7725896999365
At time: 47.21651029586792 and batch: 100, loss is 5.5732789230346675 and perplexity is 263.29601275517234
At time: 47.578563928604126 and batch: 150, loss is 5.522164525985718 and perplexity is 250.17596392843322
At time: 47.939409494400024 and batch: 200, loss is 5.497298927307129 and perplexity is 244.03189337561696
At time: 48.29966902732849 and batch: 250, loss is 5.490446529388428 and perplexity is 242.3654059756197
At time: 48.660688400268555 and batch: 300, loss is 5.548063840866089 and perplexity is 256.73998490607823
At time: 49.02167773246765 and batch: 350, loss is 5.57341423034668 and perplexity is 263.3316410412513
At time: 49.38317823410034 and batch: 400, loss is 5.4696384525299075 and perplexity is 237.37435514734742
At time: 49.74455690383911 and batch: 450, loss is 5.483612270355224 and perplexity is 240.71466523052308
At time: 50.10550594329834 and batch: 500, loss is 5.4825382328033445 and perplexity is 240.4562674300875
At time: 50.480440616607666 and batch: 550, loss is 5.5411178016662594 and perplexity is 254.96283811761452
At time: 50.84215593338013 and batch: 600, loss is 5.397349672317505 and perplexity is 220.82039356927515
At time: 51.20478439331055 and batch: 650, loss is 5.561975326538086 and perplexity is 260.33657850397407
At time: 51.566980838775635 and batch: 700, loss is 5.5464598751068115 and perplexity is 256.32851284301796
At time: 51.927669525146484 and batch: 750, loss is 5.497598295211792 and perplexity is 244.10495962850763
At time: 52.31942653656006 and batch: 800, loss is 5.454783792495728 and perplexity is 233.87430022400412
At time: 52.69356727600098 and batch: 850, loss is 5.406026439666748 and perplexity is 222.7447372182723
At time: 53.05866575241089 and batch: 900, loss is 5.374863452911377 and perplexity is 215.91038836275197
At time: 53.421056270599365 and batch: 950, loss is 5.4287121391296385 and perplexity is 227.85561005955287
At time: 53.783003091812134 and batch: 1000, loss is 5.483953609466552 and perplexity is 240.79684458515254
At time: 54.142685413360596 and batch: 1050, loss is 5.362069358825684 and perplexity is 213.1656064795351
At time: 54.50406789779663 and batch: 1100, loss is 5.476703872680664 and perplexity is 239.05744356121107
At time: 54.86602783203125 and batch: 1150, loss is 5.45899621963501 and perplexity is 234.86155658632808
At time: 55.23128938674927 and batch: 1200, loss is 5.415817365646363 and perplexity is 224.93632578592732
At time: 55.60476326942444 and batch: 1250, loss is 5.436745681762695 and perplexity is 229.6934701967524
At time: 55.96764802932739 and batch: 1300, loss is 5.507241792678833 and perplexity is 246.4703722825092
At time: 56.32967162132263 and batch: 1350, loss is 5.4313016033172605 and perplexity is 228.4463985844957
At time: 56.69177055358887 and batch: 1400, loss is 5.349388084411621 and perplexity is 210.47946278828437
At time: 57.05432415008545 and batch: 1450, loss is 5.40036244392395 and perplexity is 221.4866781588142
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.558376214443109 and perplexity of 259.4012821034309
Finished 5 epochs...
Completing Train Step...
At time: 58.289408922195435 and batch: 50, loss is 5.512084846496582 and perplexity is 247.66693673417086
At time: 58.65320587158203 and batch: 100, loss is 5.517263154983521 and perplexity is 248.95275885312884
At time: 59.016958713531494 and batch: 150, loss is 5.470893592834472 and perplexity is 237.67248032308657
At time: 59.38003754615784 and batch: 200, loss is 5.448697109222412 and perplexity is 232.45510491045286
At time: 59.75684380531311 and batch: 250, loss is 5.441446857452393 and perplexity is 230.77584177092757
At time: 60.12259078025818 and batch: 300, loss is 5.491543970108032 and perplexity is 242.631533644121
At time: 60.49458718299866 and batch: 350, loss is 5.5163868808746335 and perplexity is 248.73470354827165
At time: 60.86935877799988 and batch: 400, loss is 5.412493324279785 and perplexity is 224.18986944735792
At time: 61.24405550956726 and batch: 450, loss is 5.417171669006348 and perplexity is 225.24116418296165
At time: 61.609535932540894 and batch: 500, loss is 5.415764780044555 and perplexity is 224.9244976848642
At time: 61.97249150276184 and batch: 550, loss is 5.474888257980346 and perplexity is 238.62380113536608
At time: 62.335803508758545 and batch: 600, loss is 5.3267520141601565 and perplexity is 205.76855426111157
At time: 62.71782565116882 and batch: 650, loss is 5.481931543350219 and perplexity is 240.31042939237275
At time: 63.09250807762146 and batch: 700, loss is 5.47636417388916 and perplexity is 238.97624982802057
At time: 63.455801486968994 and batch: 750, loss is 5.423237705230713 and perplexity is 226.61163771273488
At time: 63.818413496017456 and batch: 800, loss is 5.379015817642212 and perplexity is 216.8087910012609
At time: 64.18198013305664 and batch: 850, loss is 5.331357736587524 and perplexity is 206.7184529119215
At time: 64.54414296150208 and batch: 900, loss is 5.299278316497802 and perplexity is 200.19228236201968
At time: 64.90839219093323 and batch: 950, loss is 5.352576961517334 and perplexity is 211.15172724307266
At time: 65.27216696739197 and batch: 1000, loss is 5.406677465438843 and perplexity is 222.88979699650355
At time: 65.63559341430664 and batch: 1050, loss is 5.285499382019043 and perplexity is 197.452763191181
At time: 65.99806809425354 and batch: 1100, loss is 5.403490648269654 and perplexity is 222.18061857577115
At time: 66.3609082698822 and batch: 1150, loss is 5.379877395629883 and perplexity is 216.99566917662216
At time: 66.72468733787537 and batch: 1200, loss is 5.335071859359741 and perplexity is 207.4876582025156
At time: 67.08865761756897 and batch: 1250, loss is 5.3490578556060795 and perplexity is 210.40996788193826
At time: 67.46012878417969 and batch: 1300, loss is 5.418016719818115 and perplexity is 225.43158485783903
At time: 67.83711624145508 and batch: 1350, loss is 5.352774953842163 and perplexity is 211.19353780338952
At time: 68.20453143119812 and batch: 1400, loss is 5.262605285644531 and perplexity is 192.98361436635827
At time: 68.56805992126465 and batch: 1450, loss is 5.319102249145508 and perplexity is 204.20047852589198
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.4865983490251065 and perplexity of 241.43453241301398
Finished 6 epochs...
Completing Train Step...
At time: 69.80172967910767 and batch: 50, loss is 5.42780876159668 and perplexity is 227.64986336812805
At time: 70.16300129890442 and batch: 100, loss is 5.438173627853393 and perplexity is 230.02169437702463
At time: 70.53097248077393 and batch: 150, loss is 5.383810739517212 and perplexity is 217.85086855960833
At time: 70.90639019012451 and batch: 200, loss is 5.368863039016723 and perplexity is 214.6187158288797
At time: 71.27326035499573 and batch: 250, loss is 5.365185804367066 and perplexity is 213.83096171659824
At time: 71.63405013084412 and batch: 300, loss is 5.427156190872193 and perplexity is 227.50135419350062
At time: 71.99417042732239 and batch: 350, loss is 5.4488639068603515 and perplexity is 232.49388110667803
At time: 72.35579943656921 and batch: 400, loss is 5.35108717918396 and perplexity is 210.837391334344
At time: 72.71737670898438 and batch: 450, loss is 5.359225540161133 and perplexity is 212.56026330027035
At time: 73.07881832122803 and batch: 500, loss is 5.365865688323975 and perplexity is 213.97639138900843
At time: 73.43975973129272 and batch: 550, loss is 5.421264047622681 and perplexity is 226.16482500258684
At time: 73.80136489868164 and batch: 600, loss is 5.275807027816772 and perplexity is 195.54822570766143
At time: 74.1639449596405 and batch: 650, loss is 5.419312705993653 and perplexity is 225.72393047236358
At time: 74.52600526809692 and batch: 700, loss is 5.418355550765991 and perplexity is 225.5079809973749
At time: 74.88704252243042 and batch: 750, loss is 5.367830715179443 and perplexity is 214.39727413203994
At time: 75.2488284111023 and batch: 800, loss is 5.325288152694702 and perplexity is 205.46755796591546
At time: 75.62871599197388 and batch: 850, loss is 5.280895071029663 and perplexity is 196.5457190228724
At time: 76.01505064964294 and batch: 900, loss is 5.243136005401611 and perplexity is 189.26270157737332
At time: 76.3874180316925 and batch: 950, loss is 5.299624767303467 and perplexity is 200.26165115527508
At time: 76.7517192363739 and batch: 1000, loss is 5.351461906433105 and perplexity is 210.916412654812
At time: 77.11359763145447 and batch: 1050, loss is 5.230321207046509 and perplexity is 186.85281232200495
At time: 77.48181009292603 and batch: 1100, loss is 5.350818862915039 and perplexity is 210.78082782094702
At time: 77.8477475643158 and batch: 1150, loss is 5.329388189315796 and perplexity is 206.31171182635362
At time: 78.22150468826294 and batch: 1200, loss is 5.278631467819213 and perplexity is 196.1013206628237
At time: 78.58243107795715 and batch: 1250, loss is 5.289998865127563 and perplexity is 198.3432003150224
At time: 78.94495344161987 and batch: 1300, loss is 5.3634576416015625 and perplexity is 213.4617461346484
At time: 79.30653214454651 and batch: 1350, loss is 5.297863492965698 and perplexity is 199.9092458805389
At time: 79.6672306060791 and batch: 1400, loss is 5.207047843933106 and perplexity is 182.5543330274568
At time: 80.02900767326355 and batch: 1450, loss is 5.263161563873291 and perplexity is 193.0909968140276
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.445463262052617 and perplexity of 231.7045947988889
Finished 7 epochs...
Completing Train Step...
At time: 81.28960418701172 and batch: 50, loss is 5.37243182182312 and perplexity is 215.38601175374282
At time: 81.67171335220337 and batch: 100, loss is 5.377852106094361 and perplexity is 216.5566348544634
At time: 82.03356623649597 and batch: 150, loss is 5.329301958084106 and perplexity is 206.29392208035776
At time: 82.39602303504944 and batch: 200, loss is 5.308547258377075 and perplexity is 202.05647921144973
At time: 82.7564845085144 and batch: 250, loss is 5.31758755683899 and perplexity is 203.89141176169724
At time: 83.11808061599731 and batch: 300, loss is 5.371110134124756 and perplexity is 215.10152675318375
At time: 83.47940564155579 and batch: 350, loss is 5.3976917552948 and perplexity is 220.89594538871373
At time: 83.84079241752625 and batch: 400, loss is 5.304975633621216 and perplexity is 201.33609652233622
At time: 84.20213770866394 and batch: 450, loss is 5.310393371582031 and perplexity is 202.42984287562481
At time: 84.56418585777283 and batch: 500, loss is 5.313824758529663 and perplexity is 203.12565110719353
At time: 84.92639231681824 and batch: 550, loss is 5.377412948608399 and perplexity is 216.46155326655597
At time: 85.28800177574158 and batch: 600, loss is 5.242726135253906 and perplexity is 189.18514434120638
At time: 85.6509952545166 and batch: 650, loss is 5.384777898788452 and perplexity is 218.0616669682694
At time: 86.01396870613098 and batch: 700, loss is 5.38796854019165 and perplexity is 218.75853468766059
At time: 86.3754198551178 and batch: 750, loss is 5.340591344833374 and perplexity is 208.63604966747647
At time: 86.73806190490723 and batch: 800, loss is 5.297386045455933 and perplexity is 199.81382249055682
At time: 87.09970831871033 and batch: 850, loss is 5.249907445907593 and perplexity is 190.54863158680433
At time: 87.47362637519836 and batch: 900, loss is 5.21790153503418 and perplexity is 184.5465130637027
At time: 87.8357903957367 and batch: 950, loss is 5.273373537063598 and perplexity is 195.07293944551316
At time: 88.20181655883789 and batch: 1000, loss is 5.327313194274902 and perplexity is 205.88405988870227
At time: 88.5713095664978 and batch: 1050, loss is 5.214661073684693 and perplexity is 183.9494650988103
At time: 88.93299078941345 and batch: 1100, loss is 5.329312944412232 and perplexity is 206.29618850552586
At time: 89.2957398891449 and batch: 1150, loss is 5.308943424224854 and perplexity is 202.13654294604714
At time: 89.65698671340942 and batch: 1200, loss is 5.261748542785645 and perplexity is 192.81834783843556
At time: 90.01763916015625 and batch: 1250, loss is 5.271779918670655 and perplexity is 194.7623151952454
At time: 90.38066172599792 and batch: 1300, loss is 5.346803874969482 and perplexity is 209.93624197365833
At time: 90.74236464500427 and batch: 1350, loss is 5.281388721466064 and perplexity is 196.64276785496915
At time: 91.109050989151 and batch: 1400, loss is 5.192085599899292 and perplexity is 179.84324311884455
At time: 91.48586010932922 and batch: 1450, loss is 5.2470370864868165 and perplexity is 190.00247273809325
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.432283841646635 and perplexity of 228.67089763112764
Finished 8 epochs...
Completing Train Step...
At time: 92.71168041229248 and batch: 50, loss is 5.3578902626037594 and perplexity is 212.2766257606596
At time: 93.08707880973816 and batch: 100, loss is 5.36112868309021 and perplexity is 212.96518104833146
At time: 93.44771766662598 and batch: 150, loss is 5.306986837387085 and perplexity is 201.74143190726392
At time: 93.80934810638428 and batch: 200, loss is 5.291635465621948 and perplexity is 198.6680746669648
At time: 94.16967105865479 and batch: 250, loss is 5.298197221755982 and perplexity is 199.9759724850083
At time: 94.53082275390625 and batch: 300, loss is 5.352117338180542 and perplexity is 211.05469928149364
At time: 94.89109134674072 and batch: 350, loss is 5.381875448226928 and perplexity is 217.42967137218926
At time: 95.2523422241211 and batch: 400, loss is 5.289808712005615 and perplexity is 198.30548832190559
At time: 95.61360239982605 and batch: 450, loss is 5.2941538524627685 and perplexity is 199.1690282646059
At time: 95.97434902191162 and batch: 500, loss is 5.297256851196289 and perplexity is 199.78800935918375
At time: 96.33628129959106 and batch: 550, loss is 5.363151521682739 and perplexity is 213.39641124291583
At time: 96.69803857803345 and batch: 600, loss is 5.230039863586426 and perplexity is 186.8002498996537
At time: 97.07293200492859 and batch: 650, loss is 5.374583959579468 and perplexity is 215.85005128121335
At time: 97.43475294113159 and batch: 700, loss is 5.372536344528198 and perplexity is 215.40852565891387
At time: 97.79713249206543 and batch: 750, loss is 5.328636150360108 and perplexity is 206.1566157085165
At time: 98.1581392288208 and batch: 800, loss is 5.287330741882324 and perplexity is 197.8147015751399
At time: 98.52052807807922 and batch: 850, loss is 5.241847915649414 and perplexity is 189.01907117359698
At time: 98.88156723976135 and batch: 900, loss is 5.2056968307495115 and perplexity is 182.30786624423953
At time: 99.24316310882568 and batch: 950, loss is 5.263656644821167 and perplexity is 193.1866161554606
At time: 99.6046724319458 and batch: 1000, loss is 5.314884519577026 and perplexity is 203.34102986480843
At time: 99.96694445610046 and batch: 1050, loss is 5.201636962890625 and perplexity is 181.56922081363538
At time: 100.32898497581482 and batch: 1100, loss is 5.321296825408935 and perplexity is 204.6491041405534
At time: 100.69142079353333 and batch: 1150, loss is 5.296739950180053 and perplexity is 199.68476541986158
At time: 101.05294299125671 and batch: 1200, loss is 5.2475865459442135 and perplexity is 190.10690008033615
At time: 101.41517996788025 and batch: 1250, loss is 5.259860591888428 and perplexity is 192.45465968634687
At time: 101.7761013507843 and batch: 1300, loss is 5.3310149383544925 and perplexity is 206.64760233594822
At time: 102.13702821731567 and batch: 1350, loss is 5.268762979507446 and perplexity is 194.17561460401964
At time: 102.49891662597656 and batch: 1400, loss is 5.1759905433654785 and perplexity is 176.9718257526995
At time: 102.86083316802979 and batch: 1450, loss is 5.2323824977874756 and perplexity is 187.2383675281401
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.422451443142361 and perplexity of 226.43353160143894
Finished 9 epochs...
Completing Train Step...
At time: 104.08565378189087 and batch: 50, loss is 5.3430033206939695 and perplexity is 209.1398821545636
At time: 104.44852542877197 and batch: 100, loss is 5.34677716255188 and perplexity is 209.93063414399253
At time: 104.8112244606018 and batch: 150, loss is 5.2935308074951175 and perplexity is 199.04497565302432
At time: 105.17460799217224 and batch: 200, loss is 5.274460554122925 and perplexity is 195.28510234996054
At time: 105.53601145744324 and batch: 250, loss is 5.284867000579834 and perplexity is 197.3279372015978
At time: 105.8983223438263 and batch: 300, loss is 5.3334778308868405 and perplexity is 207.1571804330291
At time: 106.27358150482178 and batch: 350, loss is 5.363068742752075 and perplexity is 213.37874724729906
At time: 106.63646864891052 and batch: 400, loss is 5.269770879745483 and perplexity is 194.37142291324446
At time: 106.99913287162781 and batch: 450, loss is 5.274299097061157 and perplexity is 195.2535747363746
At time: 107.37532782554626 and batch: 500, loss is 5.28035530090332 and perplexity is 196.43965814210583
At time: 107.76224327087402 and batch: 550, loss is 5.339659776687622 and perplexity is 208.44178147063178
At time: 108.13164067268372 and batch: 600, loss is 5.206326103210449 and perplexity is 182.42262366693532
At time: 108.50198888778687 and batch: 650, loss is 5.350190753936768 and perplexity is 210.64847606056094
At time: 108.87249541282654 and batch: 700, loss is 5.348823175430298 and perplexity is 210.36059462737822
At time: 109.24171042442322 and batch: 750, loss is 5.296417350769043 and perplexity is 199.62035762166687
At time: 109.61064291000366 and batch: 800, loss is 5.25419620513916 and perplexity is 191.36760372142587
At time: 109.98172640800476 and batch: 850, loss is 5.207194557189942 and perplexity is 182.58111813302176
At time: 110.35111165046692 and batch: 900, loss is 5.170299272537232 and perplexity is 175.9674918424246
At time: 110.72682881355286 and batch: 950, loss is 5.2349435997009275 and perplexity is 187.71851866503346
At time: 111.10201358795166 and batch: 1000, loss is 5.278937120437622 and perplexity is 196.16126870612908
At time: 111.46877312660217 and batch: 1050, loss is 5.163994054794312 and perplexity is 174.861469012299
At time: 111.84578704833984 and batch: 1100, loss is 5.282154836654663 and perplexity is 196.79347658890467
At time: 112.2205753326416 and batch: 1150, loss is 5.253998804092407 and perplexity is 191.32983128441856
At time: 112.58480930328369 and batch: 1200, loss is 5.206949796676636 and perplexity is 182.5364349533896
At time: 112.94825005531311 and batch: 1250, loss is 5.215013179779053 and perplexity is 184.0142462307723
At time: 113.31256246566772 and batch: 1300, loss is 5.285085201263428 and perplexity is 197.3709989902723
At time: 113.675461769104 and batch: 1350, loss is 5.215636682510376 and perplexity is 184.12901539162414
At time: 114.03735375404358 and batch: 1400, loss is 5.120028400421143 and perplexity is 167.34012208355907
At time: 114.40088629722595 and batch: 1450, loss is 5.181095533370971 and perplexity is 177.8775751080697
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.374540932158119 and perplexity of 215.84076400991387
Finished 10 epochs...
Completing Train Step...
At time: 115.625328540802 and batch: 50, loss is 5.298148193359375 and perplexity is 199.96616822406307
At time: 115.98619818687439 and batch: 100, loss is 5.290015306472778 and perplexity is 198.3464613708578
At time: 116.34830904006958 and batch: 150, loss is 5.2314039325714115 and perplexity is 187.05523219411234
At time: 116.71110892295837 and batch: 200, loss is 5.216175670623779 and perplexity is 184.22828549255183
At time: 117.07350540161133 and batch: 250, loss is 5.224056215286255 and perplexity is 185.6858403443198
At time: 117.45111036300659 and batch: 300, loss is 5.276642808914184 and perplexity is 195.71172953552698
At time: 117.8261148929596 and batch: 350, loss is 5.3152117252349855 and perplexity is 203.40757508666834
At time: 118.20273947715759 and batch: 400, loss is 5.221491947174072 and perplexity is 185.21030202948344
At time: 118.5844075679779 and batch: 450, loss is 5.226229963302612 and perplexity is 186.08991358903106
At time: 118.95813274383545 and batch: 500, loss is 5.224989604949951 and perplexity is 185.8592384998261
At time: 119.32558345794678 and batch: 550, loss is 5.287082633972168 and perplexity is 197.76562827092312
At time: 119.6936707496643 and batch: 600, loss is 5.156032857894897 and perplexity is 173.47488916846854
At time: 120.06004786491394 and batch: 650, loss is 5.297275218963623 and perplexity is 199.79167905255767
At time: 120.42819333076477 and batch: 700, loss is 5.302472095489502 and perplexity is 200.83267435863553
At time: 120.79607558250427 and batch: 750, loss is 5.255139646530151 and perplexity is 191.5482330328579
At time: 121.16468048095703 and batch: 800, loss is 5.202599020004272 and perplexity is 181.7439848271403
At time: 121.53102397918701 and batch: 850, loss is 5.153509683609009 and perplexity is 173.03773353072935
At time: 121.89821887016296 and batch: 900, loss is 5.11979115486145 and perplexity is 167.3004260916714
At time: 122.2651731967926 and batch: 950, loss is 5.187640819549561 and perplexity is 179.04565327473426
At time: 122.63283658027649 and batch: 1000, loss is 5.22863772392273 and perplexity is 186.5385133985269
At time: 123.00038051605225 and batch: 1050, loss is 5.120624961853028 and perplexity is 167.4399805292882
At time: 123.36771202087402 and batch: 1100, loss is 5.239168567657471 and perplexity is 188.5133011742979
At time: 123.73536229133606 and batch: 1150, loss is 5.207527351379395 and perplexity is 182.64189017997143
At time: 124.10317993164062 and batch: 1200, loss is 5.165256481170655 and perplexity is 175.08235814178155
At time: 124.47021961212158 and batch: 1250, loss is 5.173021831512451 and perplexity is 176.44722647327038
At time: 124.83744239807129 and batch: 1300, loss is 5.245791749954224 and perplexity is 189.76600299027845
At time: 125.205007314682 and batch: 1350, loss is 5.175238265991211 and perplexity is 176.83874391580642
At time: 125.57105112075806 and batch: 1400, loss is 5.0880547046661375 and perplexity is 162.07427286917414
At time: 125.92997813224792 and batch: 1450, loss is 5.146985883712769 and perplexity is 171.9125442282685
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.352385170439369 and perplexity of 211.1112341089256
Finished 11 epochs...
Completing Train Step...
At time: 127.14350938796997 and batch: 50, loss is 5.260088462829589 and perplexity is 192.49851950778014
At time: 127.52039527893066 and batch: 100, loss is 5.253867530822754 and perplexity is 191.30471644037365
At time: 127.88203883171082 and batch: 150, loss is 5.196522626876831 and perplexity is 180.64298536719932
At time: 128.24396181106567 and batch: 200, loss is 5.182775983810425 and perplexity is 178.1767408535316
At time: 128.60423398017883 and batch: 250, loss is 5.191351146697998 and perplexity is 179.7112051669884
At time: 128.96574997901917 and batch: 300, loss is 5.242352876663208 and perplexity is 189.11454253803308
At time: 129.32556557655334 and batch: 350, loss is 5.2790882015228275 and perplexity is 196.19090720233226
At time: 129.6883249282837 and batch: 400, loss is 5.184098777770996 and perplexity is 178.41258792439726
At time: 130.04913854599 and batch: 450, loss is 5.18244044303894 and perplexity is 178.11696532156995
At time: 130.41100025177002 and batch: 500, loss is 5.179854907989502 and perplexity is 177.6570325072579
At time: 130.77258801460266 and batch: 550, loss is 5.2481289482116695 and perplexity is 190.2100424638014
At time: 131.13337588310242 and batch: 600, loss is 5.117580633163453 and perplexity is 166.93101331761287
At time: 131.49414038658142 and batch: 650, loss is 5.256231012344361 and perplexity is 191.75739634224414
At time: 131.8543405532837 and batch: 700, loss is 5.266220121383667 and perplexity is 193.68248081533645
At time: 132.2162024974823 and batch: 750, loss is 5.217022256851196 and perplexity is 184.38431665934982
At time: 132.60510087013245 and batch: 800, loss is 5.160376853942871 and perplexity is 174.23010253578903
At time: 132.9763195514679 and batch: 850, loss is 5.123031549453735 and perplexity is 167.8434247775376
At time: 133.3395619392395 and batch: 900, loss is 5.084334897994995 and perplexity is 161.4725078264282
At time: 133.70002484321594 and batch: 950, loss is 5.153520641326904 and perplexity is 173.03962963978702
At time: 134.06066489219666 and batch: 1000, loss is 5.190601987838745 and perplexity is 179.57662334340765
At time: 134.4443895816803 and batch: 1050, loss is 5.086392259597778 and perplexity is 161.80505713372384
At time: 134.80498719215393 and batch: 1100, loss is 5.210191640853882 and perplexity is 183.12914985776197
At time: 135.1656985282898 and batch: 1150, loss is 5.17485821723938 and perplexity is 176.77154934132176
At time: 135.5268199443817 and batch: 1200, loss is 5.134046125411987 and perplexity is 169.70236786977517
At time: 135.8875126838684 and batch: 1250, loss is 5.141939764022827 and perplexity is 171.047238009395
At time: 136.24816346168518 and batch: 1300, loss is 5.2138733959198 and perplexity is 183.80462924476737
At time: 136.60865235328674 and batch: 1350, loss is 5.14188591003418 and perplexity is 171.0380266814167
At time: 136.97031044960022 and batch: 1400, loss is 5.053278379440307 and perplexity is 156.53480469011222
At time: 137.33049869537354 and batch: 1450, loss is 5.11328309059143 and perplexity is 166.21515948919185
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.326185438368055 and perplexity of 205.6520037999443
Finished 12 epochs...
Completing Train Step...
At time: 138.6903111934662 and batch: 50, loss is 5.228546962738037 and perplexity is 186.52158371035102
At time: 139.07470393180847 and batch: 100, loss is 5.221293973922729 and perplexity is 185.1736389730805
At time: 139.45355916023254 and batch: 150, loss is 5.155568542480469 and perplexity is 173.39436080013954
At time: 139.8411431312561 and batch: 200, loss is 5.151163682937622 and perplexity is 172.6322626950838
At time: 140.21186470985413 and batch: 250, loss is 5.1638056087493895 and perplexity is 174.82852016469184
At time: 140.5856113433838 and batch: 300, loss is 5.206959848403931 and perplexity is 182.53826976907666
At time: 140.95728635787964 and batch: 350, loss is 5.24180004119873 and perplexity is 189.0100222060047
At time: 141.32894206047058 and batch: 400, loss is 5.1485120391845705 and perplexity is 172.17510980529698
At time: 141.7005159854889 and batch: 450, loss is 5.150854539871216 and perplexity is 172.57890287636752
At time: 142.0704665184021 and batch: 500, loss is 5.14755090713501 and perplexity is 172.00970628916966
At time: 142.439790725708 and batch: 550, loss is 5.213215131759643 and perplexity is 183.68367705847686
At time: 142.81434869766235 and batch: 600, loss is 5.088547744750977 and perplexity is 162.15420168485568
At time: 143.18778800964355 and batch: 650, loss is 5.226925792694092 and perplexity is 186.2194454811868
At time: 143.55148100852966 and batch: 700, loss is 5.2370662498474125 and perplexity is 188.11740260193022
At time: 143.94605803489685 and batch: 750, loss is 5.188950357437133 and perplexity is 179.2802739300924
At time: 144.31032872200012 and batch: 800, loss is 5.127404594421387 and perplexity is 168.57901884231399
At time: 144.67538905143738 and batch: 850, loss is 5.091292495727539 and perplexity is 162.59988595464858
At time: 145.0413842201233 and batch: 900, loss is 5.058898696899414 and perplexity is 157.41705693233158
At time: 145.40537452697754 and batch: 950, loss is 5.123273735046387 and perplexity is 167.88407895956988
At time: 145.77079033851624 and batch: 1000, loss is 5.160352964401245 and perplexity is 174.22594030821892
At time: 146.13835072517395 and batch: 1050, loss is 5.0597749710083 and perplexity is 157.555057878116
At time: 146.5024893283844 and batch: 1100, loss is 5.179883089065552 and perplexity is 177.6620391441476
At time: 146.86647176742554 and batch: 1150, loss is 5.142337741851807 and perplexity is 171.1153245654022
At time: 147.23152709007263 and batch: 1200, loss is 5.10414475440979 and perplexity is 164.70314863725096
At time: 147.59547519683838 and batch: 1250, loss is 5.112267551422119 and perplexity is 166.04644716568333
At time: 147.95917439460754 and batch: 1300, loss is 5.183423862457276 and perplexity is 178.29221516192632
At time: 148.32627964019775 and batch: 1350, loss is 5.113154678344727 and perplexity is 166.19381679748648
At time: 148.7066526412964 and batch: 1400, loss is 5.023387680053711 and perplexity is 151.92510665629337
At time: 149.08240866661072 and batch: 1450, loss is 5.082213497161865 and perplexity is 161.130322997717
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.3046447232238245 and perplexity of 201.26948333673255
Finished 13 epochs...
Completing Train Step...
At time: 150.37733030319214 and batch: 50, loss is 5.200889377593994 and perplexity is 181.433533059239
At time: 150.73976016044617 and batch: 100, loss is 5.187970399856567 and perplexity is 179.10467292143116
At time: 151.1030240058899 and batch: 150, loss is 5.122846088409424 and perplexity is 167.81229924707347
At time: 151.4651017189026 and batch: 200, loss is 5.122746143341065 and perplexity is 167.79552807346573
At time: 151.82807993888855 and batch: 250, loss is 5.134336833953857 and perplexity is 169.75170896928256
At time: 152.18966794013977 and batch: 300, loss is 5.180274744033813 and perplexity is 177.73163499234008
At time: 152.55167984962463 and batch: 350, loss is 5.211606283187866 and perplexity is 183.3883954323858
At time: 152.91468453407288 and batch: 400, loss is 5.117153034210205 and perplexity is 166.85964904978422
At time: 153.28880500793457 and batch: 450, loss is 5.11747314453125 and perplexity is 166.91307109562882
At time: 153.65132522583008 and batch: 500, loss is 5.117496700286865 and perplexity is 166.91700290544875
At time: 154.01365685462952 and batch: 550, loss is 5.180886058807373 and perplexity is 177.84031818297532
At time: 154.3751311302185 and batch: 600, loss is 5.057131671905518 and perplexity is 157.1391426713021
At time: 154.73841881752014 and batch: 650, loss is 5.193546724319458 and perplexity is 180.10620853898254
At time: 155.09982752799988 and batch: 700, loss is 5.2100394821166995 and perplexity is 183.1012872773996
At time: 155.462393283844 and batch: 750, loss is 5.1542502117156985 and perplexity is 173.16592029301893
At time: 155.8244183063507 and batch: 800, loss is 5.095723705291748 and perplexity is 163.32199885964158
At time: 156.18686437606812 and batch: 850, loss is 5.057287998199463 and perplexity is 157.1637095712858
At time: 156.54983592033386 and batch: 900, loss is 5.021346483230591 and perplexity is 151.61531389279898
At time: 156.91214871406555 and batch: 950, loss is 5.090140609741211 and perplexity is 162.41269725535614
At time: 157.27407312393188 and batch: 1000, loss is 5.129866189956665 and perplexity is 168.99450337006635
At time: 157.63635635375977 and batch: 1050, loss is 5.034325799942017 and perplexity is 153.59600326148845
At time: 157.99879956245422 and batch: 1100, loss is 5.156184682846069 and perplexity is 173.50122898451616
At time: 158.36031126976013 and batch: 1150, loss is 5.1161699295043945 and perplexity is 166.69568915167267
At time: 158.72428941726685 and batch: 1200, loss is 5.075855283737183 and perplexity is 160.10907212092337
At time: 159.08700346946716 and batch: 1250, loss is 5.078063068389892 and perplexity is 160.4629489713089
At time: 159.44982814788818 and batch: 1300, loss is 5.151857881546021 and perplexity is 172.7521453779928
At time: 159.81182837486267 and batch: 1350, loss is 5.081633424758911 and perplexity is 161.03688284771323
At time: 160.17279982566833 and batch: 1400, loss is 4.987797517776489 and perplexity is 146.61315476245784
At time: 160.53414869308472 and batch: 1450, loss is 5.049249792098999 and perplexity is 155.90545909547575
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.282701280381945 and perplexity of 196.90104253644864
Finished 14 epochs...
Completing Train Step...
At time: 161.76792860031128 and batch: 50, loss is 5.174254894256592 and perplexity is 176.66493116873212
At time: 162.12815189361572 and batch: 100, loss is 5.161806879043579 and perplexity is 174.47943418848521
At time: 162.50300693511963 and batch: 150, loss is 5.0914839744567875 and perplexity is 162.6310233551669
At time: 162.86585426330566 and batch: 200, loss is 5.097776937484741 and perplexity is 163.65768134463676
At time: 163.22777652740479 and batch: 250, loss is 5.111814050674439 and perplexity is 165.9711620499625
At time: 163.59040355682373 and batch: 300, loss is 5.146561660766602 and perplexity is 171.8396304492155
At time: 163.95266914367676 and batch: 350, loss is 5.1819703578948975 and perplexity is 178.03325485933416
At time: 164.31427764892578 and batch: 400, loss is 5.082549304962158 and perplexity is 161.18444090314222
At time: 164.67533707618713 and batch: 450, loss is 5.08430362701416 and perplexity is 161.46745850167966
At time: 165.03588581085205 and batch: 500, loss is 5.091191568374634 and perplexity is 162.5834760066967
At time: 165.3969864845276 and batch: 550, loss is 5.155978746414185 and perplexity is 173.46550243931642
At time: 165.7593216896057 and batch: 600, loss is 5.033984527587891 and perplexity is 153.5435941352727
At time: 166.12184381484985 and batch: 650, loss is 5.168109521865845 and perplexity is 175.58258848401536
At time: 166.4840099811554 and batch: 700, loss is 5.184881496429443 and perplexity is 178.5522894522315
At time: 166.84618067741394 and batch: 750, loss is 5.131139812469482 and perplexity is 169.20987569650933
At time: 167.21077132225037 and batch: 800, loss is 5.0717771530151365 and perplexity is 159.45745598601164
At time: 167.57468366622925 and batch: 850, loss is 5.03500563621521 and perplexity is 153.7004588982655
At time: 167.94866132736206 and batch: 900, loss is 4.993106508255005 and perplexity is 147.39359244014008
At time: 168.31054067611694 and batch: 950, loss is 5.063613452911377 and perplexity is 158.16099230670517
At time: 168.67341017723083 and batch: 1000, loss is 5.107350301742554 and perplexity is 165.23195948735014
At time: 169.05076265335083 and batch: 1050, loss is 5.009034719467163 and perplexity is 149.76010584110247
At time: 169.4238133430481 and batch: 1100, loss is 5.12720965385437 and perplexity is 168.54615915574078
At time: 169.784907579422 and batch: 1150, loss is 5.0856830024719235 and perplexity is 161.69033643199919
At time: 170.14807844161987 and batch: 1200, loss is 5.047946033477783 and perplexity is 155.7023284545207
At time: 170.51710963249207 and batch: 1250, loss is 5.054229021072388 and perplexity is 156.68368394651776
At time: 170.88632655143738 and batch: 1300, loss is 5.126303968429565 and perplexity is 168.3935784614717
At time: 171.25446128845215 and batch: 1350, loss is 5.053119831085205 and perplexity is 156.5099883216615
At time: 171.62141680717468 and batch: 1400, loss is 4.96268235206604 and perplexity is 142.97679610107136
At time: 171.99104642868042 and batch: 1450, loss is 5.028595523834229 and perplexity is 152.718372687994
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.265155498798077 and perplexity of 193.47639179480566
Finished 15 epochs...
Completing Train Step...
At time: 173.31501746177673 and batch: 50, loss is 5.146473045349121 and perplexity is 171.8244034833055
At time: 173.69143533706665 and batch: 100, loss is 5.137047691345215 and perplexity is 170.21250593948378
At time: 174.0512979030609 and batch: 150, loss is 5.065814876556397 and perplexity is 158.509555181397
At time: 174.41430759429932 and batch: 200, loss is 5.076063470840454 and perplexity is 160.14240823480978
At time: 174.77612686157227 and batch: 250, loss is 5.090203561782837 and perplexity is 162.42292178805852
At time: 175.13871598243713 and batch: 300, loss is 5.12999267578125 and perplexity is 169.01588013107556
At time: 175.5011613368988 and batch: 350, loss is 5.163491067886352 and perplexity is 174.77353809858226
At time: 175.86371064186096 and batch: 400, loss is 5.057843723297119 and perplexity is 157.25107366209585
At time: 176.22654032707214 and batch: 450, loss is 5.059855642318726 and perplexity is 157.56776856378613
At time: 176.58828043937683 and batch: 500, loss is 5.067721929550171 and perplexity is 158.81212972428986
At time: 176.95025992393494 and batch: 550, loss is 5.131692800521851 and perplexity is 169.30347261271538
At time: 177.31261610984802 and batch: 600, loss is 5.009467678070068 and perplexity is 149.8249598058263
At time: 177.67507219314575 and batch: 650, loss is 5.144734983444214 and perplexity is 171.52602141164783
At time: 178.0390486717224 and batch: 700, loss is 5.162623472213745 and perplexity is 174.62197109218852
At time: 178.40137457847595 and batch: 750, loss is 5.111853427886963 and perplexity is 165.97769766035967
At time: 178.76436305046082 and batch: 800, loss is 5.04997631072998 and perplexity is 156.01876847188277
At time: 179.1268548965454 and batch: 850, loss is 5.0107668685913085 and perplexity is 150.01973747270344
At time: 179.489595413208 and batch: 900, loss is 4.972774906158447 and perplexity is 144.42710349194783
At time: 179.8520495891571 and batch: 950, loss is 5.044332046508789 and perplexity is 155.14063785105347
At time: 180.21615648269653 and batch: 1000, loss is 5.090596389770508 and perplexity is 162.48673859126873
At time: 180.57907485961914 and batch: 1050, loss is 4.9914930725097655 and perplexity is 147.15597409199302
At time: 180.9417724609375 and batch: 1100, loss is 5.1126162815094 and perplexity is 166.1043626555461
At time: 181.32647609710693 and batch: 1150, loss is 5.066384916305542 and perplexity is 158.59993768683262
At time: 181.68916726112366 and batch: 1200, loss is 5.0277150440216065 and perplexity is 152.58396642351013
At time: 182.05188250541687 and batch: 1250, loss is 5.032630739212036 and perplexity is 153.33586924184394
At time: 182.41470909118652 and batch: 1300, loss is 5.103077306747436 and perplexity is 164.52743044792604
At time: 182.7793688774109 and batch: 1350, loss is 5.032986650466919 and perplexity is 153.39045291638024
At time: 183.14204335212708 and batch: 1400, loss is 4.947070951461792 and perplexity is 140.762060601906
At time: 183.50503158569336 and batch: 1450, loss is 5.0114381980896 and perplexity is 150.1204839610558
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.251484667134081 and perplexity of 190.8494060648156
Finished 16 epochs...
Completing Train Step...
At time: 184.72983050346375 and batch: 50, loss is 5.127316961288452 and perplexity is 168.56424638203364
At time: 185.11981391906738 and batch: 100, loss is 5.119830570220947 and perplexity is 167.30702042806803
At time: 185.49255776405334 and batch: 150, loss is 5.045615978240967 and perplexity is 155.3399557668583
At time: 185.86792492866516 and batch: 200, loss is 5.054066190719604 and perplexity is 156.65817316400657
At time: 186.23256468772888 and batch: 250, loss is 5.0720346164703365 and perplexity is 159.49851573905335
At time: 186.59655690193176 and batch: 300, loss is 5.109292659759522 and perplexity is 165.5532110002452
At time: 186.96020436286926 and batch: 350, loss is 5.146013307571411 and perplexity is 171.74542746941128
At time: 187.3240945339203 and batch: 400, loss is 5.038409252166748 and perplexity is 154.22448752213342
At time: 187.68796563148499 and batch: 450, loss is 5.038190097808838 and perplexity is 154.1906922569216
At time: 188.05172991752625 and batch: 500, loss is 5.049988527297973 and perplexity is 156.0206744974185
At time: 188.41537380218506 and batch: 550, loss is 5.11127477645874 and perplexity is 165.88168221097288
At time: 188.77913999557495 and batch: 600, loss is 4.990365953445434 and perplexity is 146.99020522633745
At time: 189.15875029563904 and batch: 650, loss is 5.1203661632537845 and perplexity is 167.39665290367614
At time: 189.5356104373932 and batch: 700, loss is 5.142139854431153 and perplexity is 171.08146634535794
At time: 189.90107560157776 and batch: 750, loss is 5.094591245651245 and perplexity is 163.13714797536517
At time: 190.26485419273376 and batch: 800, loss is 5.0324818134307865 and perplexity is 153.31303527804872
At time: 190.6421880722046 and batch: 850, loss is 4.993362312316894 and perplexity is 147.4313011425967
At time: 191.00594091415405 and batch: 900, loss is 4.954783506393433 and perplexity is 141.8518930205378
At time: 191.37848925590515 and batch: 950, loss is 5.028405790328979 and perplexity is 152.6893996444934
At time: 191.75342321395874 and batch: 1000, loss is 5.07479510307312 and perplexity is 159.9394175266706
At time: 192.12120914459229 and batch: 1050, loss is 4.972031002044678 and perplexity is 144.31970352811067
At time: 192.48382019996643 and batch: 1100, loss is 5.092685737609863 and perplexity is 162.82658481232247
At time: 192.84801077842712 and batch: 1150, loss is 5.0492080783844 and perplexity is 155.898955835289
At time: 193.21102046966553 and batch: 1200, loss is 5.011166276931763 and perplexity is 150.07966857477714
At time: 193.5750527381897 and batch: 1250, loss is 5.017778520584106 and perplexity is 151.0753200280233
At time: 193.9388678073883 and batch: 1300, loss is 5.0856549930572506 and perplexity is 161.68580764374212
At time: 194.30305433273315 and batch: 1350, loss is 5.018895072937012 and perplexity is 151.24409773910727
At time: 194.66560101509094 and batch: 1400, loss is 4.929869213104248 and perplexity is 138.3614152965599
At time: 195.02936363220215 and batch: 1450, loss is 4.997889804840088 and perplexity is 148.10030857649562
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.245178744324252 and perplexity of 189.6497110095293
Finished 17 epochs...
Completing Train Step...
At time: 196.25291395187378 and batch: 50, loss is 5.1109734058380125 and perplexity is 165.83169787772076
At time: 196.61459732055664 and batch: 100, loss is 5.105098180770874 and perplexity is 164.86025584409023
At time: 196.9779748916626 and batch: 150, loss is 5.030168972015381 and perplexity is 152.9588562783478
At time: 197.34022784233093 and batch: 200, loss is 5.041668100357056 and perplexity is 154.72790154360737
At time: 197.7014365196228 and batch: 250, loss is 5.0550875568389895 and perplexity is 156.81826025424937
At time: 198.06229734420776 and batch: 300, loss is 5.0970738506317135 and perplexity is 163.54265622155066
At time: 198.42409586906433 and batch: 350, loss is 5.129638586044312 and perplexity is 168.95604393685784
At time: 198.78731155395508 and batch: 400, loss is 5.022321729660034 and perplexity is 151.76324831085327
At time: 199.14970588684082 and batch: 450, loss is 5.023612947463989 and perplexity is 151.95933428666618
At time: 199.51209115982056 and batch: 500, loss is 5.032292785644532 and perplexity is 153.28405759326617
At time: 199.89844250679016 and batch: 550, loss is 5.095812139511108 and perplexity is 163.33644275177278
At time: 200.26135897636414 and batch: 600, loss is 4.97489450454712 and perplexity is 144.73355561076556
At time: 200.6376235485077 and batch: 650, loss is 5.104147319793701 and perplexity is 164.70357116460048
At time: 201.01402068138123 and batch: 700, loss is 5.1292151355743405 and perplexity is 168.8845145662899
At time: 201.37896823883057 and batch: 750, loss is 5.078040742874146 and perplexity is 160.4593665932043
At time: 201.7406620979309 and batch: 800, loss is 5.012125606536865 and perplexity is 150.22371352621084
At time: 202.10337805747986 and batch: 850, loss is 4.977992267608642 and perplexity is 145.18260103216744
At time: 202.46624398231506 and batch: 900, loss is 4.939906997680664 and perplexity is 139.75725120706755
At time: 202.83818769454956 and batch: 950, loss is 5.011147613525391 and perplexity is 150.0768676030722
At time: 203.21343302726746 and batch: 1000, loss is 5.059707431793213 and perplexity is 157.54441709251307
At time: 203.5817232131958 and batch: 1050, loss is 4.955817813873291 and perplexity is 141.998687396695
At time: 203.944974899292 and batch: 1100, loss is 5.080402212142944 and perplexity is 160.83873421249584
At time: 204.30701565742493 and batch: 1150, loss is 5.032889747619629 and perplexity is 153.37558966490295
At time: 204.67184114456177 and batch: 1200, loss is 4.996583108901977 and perplexity is 147.90691288704463
At time: 205.03419661521912 and batch: 1250, loss is 5.002884893417359 and perplexity is 148.84193343506894
At time: 205.39740419387817 and batch: 1300, loss is 5.068970651626587 and perplexity is 159.01056580665238
At time: 205.7600622177124 and batch: 1350, loss is 5.0047938346862795 and perplexity is 149.12633531122358
At time: 206.12197756767273 and batch: 1400, loss is 4.911377153396606 and perplexity is 135.82633937136256
At time: 206.4845426082611 and batch: 1450, loss is 4.982607412338257 and perplexity is 145.85418829231241
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.236184666299413 and perplexity of 187.9516344746669
Finished 18 epochs...
Completing Train Step...
At time: 207.7195963859558 and batch: 50, loss is 5.097727928161621 and perplexity is 163.64966078899332
At time: 208.09536504745483 and batch: 100, loss is 5.088965368270874 and perplexity is 162.22193523590704
At time: 208.46277809143066 and batch: 150, loss is 5.018336391448974 and perplexity is 151.1596240606629
At time: 208.8419988155365 and batch: 200, loss is 5.023963203430176 and perplexity is 152.0125682723342
At time: 209.2232165336609 and batch: 250, loss is 5.041892232894898 and perplexity is 154.7625849875543
At time: 209.58461475372314 and batch: 300, loss is 5.0799065113067625 and perplexity is 160.7590260747837
At time: 209.94552421569824 and batch: 350, loss is 5.114700012207031 and perplexity is 166.45084027268013
At time: 210.30615973472595 and batch: 400, loss is 5.004829540252685 and perplexity is 149.13166004655267
At time: 210.66709208488464 and batch: 450, loss is 5.012463121414185 and perplexity is 150.27442482187908
At time: 211.02899312973022 and batch: 500, loss is 5.016840839385987 and perplexity is 150.93372593636653
At time: 211.39098262786865 and batch: 550, loss is 5.083362646102906 and perplexity is 161.31559216830698
At time: 211.75344038009644 and batch: 600, loss is 4.962832431793213 and perplexity is 142.9982556299021
At time: 212.11551594734192 and batch: 650, loss is 5.088507413864136 and perplexity is 162.1476619939734
At time: 212.47807621955872 and batch: 700, loss is 5.112699060440064 and perplexity is 166.11811316618378
At time: 212.84238147735596 and batch: 750, loss is 5.063780975341797 and perplexity is 158.1874900399544
At time: 213.2065670490265 and batch: 800, loss is 5.0020177364349365 and perplexity is 148.712920058723
At time: 213.5812222957611 and batch: 850, loss is 4.965198669433594 and perplexity is 143.33702413020475
At time: 213.95688247680664 and batch: 900, loss is 4.922582550048828 and perplexity is 137.35688655929735
At time: 214.32674264907837 and batch: 950, loss is 5.000663948059082 and perplexity is 148.5117304510117
At time: 214.69072437286377 and batch: 1000, loss is 5.0469056224823 and perplexity is 155.54041828114174
At time: 215.07149648666382 and batch: 1050, loss is 4.940923357009888 and perplexity is 139.89936700128158
At time: 215.4462857246399 and batch: 1100, loss is 5.070784368515015 and perplexity is 159.29922765159492
At time: 215.81055879592896 and batch: 1150, loss is 5.023138246536255 and perplexity is 151.88721616832552
At time: 216.17425322532654 and batch: 1200, loss is 4.986269769668579 and perplexity is 146.3893378041747
At time: 216.53785514831543 and batch: 1250, loss is 4.996965494155884 and perplexity is 147.96348112422402
At time: 216.90211462974548 and batch: 1300, loss is 5.059035272598266 and perplexity is 157.43855774510428
At time: 217.26622986793518 and batch: 1350, loss is 4.995251302719116 and perplexity is 147.71006065957707
At time: 217.63884043693542 and batch: 1400, loss is 4.906060943603515 and perplexity is 135.10617402697886
At time: 218.02008271217346 and batch: 1450, loss is 4.972975721359253 and perplexity is 144.4561095620698
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.228771242321047 and perplexity of 186.56342138486053
Finished 19 epochs...
Completing Train Step...
At time: 219.3382806777954 and batch: 50, loss is 5.089163618087769 and perplexity is 162.25409889297805
At time: 219.71902203559875 and batch: 100, loss is 5.083306512832642 and perplexity is 161.30653725071744
At time: 220.08411312103271 and batch: 150, loss is 5.007450885772705 and perplexity is 149.52309847905371
At time: 220.45496439933777 and batch: 200, loss is 5.012097845077514 and perplexity is 150.2195431545823
At time: 220.82867813110352 and batch: 250, loss is 5.02910285949707 and perplexity is 152.79587182220473
At time: 221.19617104530334 and batch: 300, loss is 5.071101942062378 and perplexity is 159.34982490616204
At time: 221.5610864162445 and batch: 350, loss is 5.107865867614746 and perplexity is 165.3171694104339
At time: 221.926509141922 and batch: 400, loss is 5.000913028717041 and perplexity is 148.5487264578506
At time: 222.29003024101257 and batch: 450, loss is 5.003271884918213 and perplexity is 148.89954514518115
At time: 222.65840339660645 and batch: 500, loss is 5.007638187408447 and perplexity is 149.55110702292114
At time: 223.0389769077301 and batch: 550, loss is 5.076542510986328 and perplexity is 160.21914125504233
At time: 223.412113904953 and batch: 600, loss is 4.95198881149292 and perplexity is 141.45601369711036
At time: 223.77722263336182 and batch: 650, loss is 5.080816230773926 and perplexity is 160.9053382317443
At time: 224.1431086063385 and batch: 700, loss is 5.105142965316772 and perplexity is 164.86763920111383
At time: 224.50839185714722 and batch: 750, loss is 5.052521829605102 and perplexity is 156.41642309585438
At time: 224.87358474731445 and batch: 800, loss is 4.996083431243896 and perplexity is 147.83302556865763
At time: 225.2384912967682 and batch: 850, loss is 4.956184577941895 and perplexity is 142.05077696472802
At time: 225.603848695755 and batch: 900, loss is 4.9157809638977055 and perplexity is 136.4258118437721
At time: 225.96878743171692 and batch: 950, loss is 4.988656997680664 and perplexity is 146.73921999016838
At time: 226.3490104675293 and batch: 1000, loss is 5.037809619903564 and perplexity is 154.13203726449095
At time: 226.72350335121155 and batch: 1050, loss is 4.932174043655396 and perplexity is 138.6806827009337
At time: 227.08870339393616 and batch: 1100, loss is 5.058065824508667 and perplexity is 157.28600319487555
At time: 227.46512746810913 and batch: 1150, loss is 5.0132721900939945 and perplexity is 150.39605634987385
At time: 227.85599541664124 and batch: 1200, loss is 4.975010347366333 and perplexity is 144.75032292505006
At time: 228.25786685943604 and batch: 1250, loss is 4.981909017562867 and perplexity is 145.75236005153494
At time: 228.63129544258118 and batch: 1300, loss is 5.045407514572144 and perplexity is 155.3075764048419
At time: 229.00985527038574 and batch: 1350, loss is 4.983658323287964 and perplexity is 146.00754862576184
At time: 229.37757515907288 and batch: 1400, loss is 4.890231161117554 and perplexity is 132.98431130053484
At time: 229.74370408058167 and batch: 1450, loss is 4.959489440917968 and perplexity is 142.52101192129348
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.224425747863248 and perplexity of 185.7544699910775
Finished 20 epochs...
Completing Train Step...
At time: 230.97566199302673 and batch: 50, loss is 5.075734205245972 and perplexity is 160.08968752959402
At time: 231.35343098640442 and batch: 100, loss is 5.071104221343994 and perplexity is 159.35018810970237
At time: 231.71721839904785 and batch: 150, loss is 4.99376519203186 and perplexity is 147.49071018972452
At time: 232.08269047737122 and batch: 200, loss is 5.003464479446411 and perplexity is 148.92822514454403
At time: 232.4462058544159 and batch: 250, loss is 5.018648920059204 and perplexity is 151.20687315085505
At time: 232.81032395362854 and batch: 300, loss is 5.061325464248657 and perplexity is 157.79953541174413
At time: 233.1744475364685 and batch: 350, loss is 5.094465284347534 and perplexity is 163.11660030165555
At time: 233.5380415916443 and batch: 400, loss is 4.986014337539673 and perplexity is 146.3519500391917
At time: 233.90186619758606 and batch: 450, loss is 4.987625360488892 and perplexity is 146.5879164119532
At time: 234.2639708518982 and batch: 500, loss is 4.992483406066895 and perplexity is 147.30177977748323
At time: 234.6266531944275 and batch: 550, loss is 5.062712202072143 and perplexity is 158.0185137937385
At time: 234.99172854423523 and batch: 600, loss is 4.944272985458374 and perplexity is 140.36876361415216
At time: 235.35534024238586 and batch: 650, loss is 5.070196733474732 and perplexity is 159.2056453423518
At time: 235.71915006637573 and batch: 700, loss is 5.089396352767944 and perplexity is 162.29186544341366
At time: 236.08205103874207 and batch: 750, loss is 5.0430670261383055 and perplexity is 154.9445058655161
At time: 236.44635891914368 and batch: 800, loss is 4.982532529830933 and perplexity is 145.84326677390985
At time: 236.81000351905823 and batch: 850, loss is 4.944194107055664 and perplexity is 140.35769198694976
At time: 237.17372822761536 and batch: 900, loss is 4.899592514038086 and perplexity is 134.23506963243156
At time: 237.5596890449524 and batch: 950, loss is 4.975626077651977 and perplexity is 144.83947752750947
At time: 237.92235708236694 and batch: 1000, loss is 5.024557256698609 and perplexity is 152.10289866323475
At time: 238.28536891937256 and batch: 1050, loss is 4.920930166244506 and perplexity is 137.13010767900843
At time: 238.64870309829712 and batch: 1100, loss is 5.046938152313232 and perplexity is 155.54547806694808
At time: 239.0126965045929 and batch: 1150, loss is 5.002092351913452 and perplexity is 148.72401675840229
At time: 239.3781442642212 and batch: 1200, loss is 4.962157211303711 and perplexity is 142.90173286847804
At time: 239.75115036964417 and batch: 1250, loss is 4.969814691543579 and perplexity is 144.00020044347082
At time: 240.12244391441345 and batch: 1300, loss is 5.030434312820435 and perplexity is 152.99944788948008
At time: 240.48428606987 and batch: 1350, loss is 4.971598892211914 and perplexity is 144.2573550368229
At time: 240.84678721427917 and batch: 1400, loss is 4.873631582260132 and perplexity is 130.79504842912985
At time: 241.22160863876343 and batch: 1450, loss is 4.947547206878662 and perplexity is 140.82911526206254
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.212599012586805 and perplexity of 183.57054087956718
Finished 21 epochs...
Completing Train Step...
At time: 242.4635307788849 and batch: 50, loss is 5.064422988891602 and perplexity is 158.28908115991797
At time: 242.82540321350098 and batch: 100, loss is 5.057676649093628 and perplexity is 157.22480325883
At time: 243.1876826286316 and batch: 150, loss is 4.981357564926148 and perplexity is 145.67200668585048
At time: 243.5494101047516 and batch: 200, loss is 4.989041128158569 and perplexity is 146.79559782439964
At time: 243.9124002456665 and batch: 250, loss is 5.003752355575561 and perplexity is 148.97110419715165
At time: 244.2885980606079 and batch: 300, loss is 5.043542175292969 and perplexity is 155.01814510992477
At time: 244.66204142570496 and batch: 350, loss is 5.078049001693725 and perplexity is 160.46069180363514
At time: 245.02634191513062 and batch: 400, loss is 4.969737339019775 and perplexity is 143.98906209533345
At time: 245.3886947631836 and batch: 450, loss is 4.972408876419068 and perplexity is 144.37424855072763
At time: 245.75160956382751 and batch: 500, loss is 4.980476779937744 and perplexity is 145.54375745741964
At time: 246.1140205860138 and batch: 550, loss is 5.045266027450562 and perplexity is 155.2856039373437
At time: 246.47491455078125 and batch: 600, loss is 4.9268019485473635 and perplexity is 137.93767442627347
At time: 246.85077333450317 and batch: 650, loss is 5.053801794052124 and perplexity is 156.61675874024746
At time: 247.21360445022583 and batch: 700, loss is 5.077790985107422 and perplexity is 160.41929562438014
At time: 247.5924208164215 and batch: 750, loss is 5.025972719192505 and perplexity is 152.31834705509297
At time: 247.96602272987366 and batch: 800, loss is 4.967368412017822 and perplexity is 143.64836621930684
At time: 248.32784032821655 and batch: 850, loss is 4.925653438568116 and perplexity is 137.7793425709429
At time: 248.68979692459106 and batch: 900, loss is 4.885993118286133 and perplexity is 132.42191067408103
At time: 249.0514063835144 and batch: 950, loss is 4.962557611465454 and perplexity is 142.95896220198452
At time: 249.41262578964233 and batch: 1000, loss is 5.01180944442749 and perplexity is 150.17622598733996
At time: 249.77444291114807 and batch: 1050, loss is 4.900856437683106 and perplexity is 134.4048397765799
At time: 250.13724040985107 and batch: 1100, loss is 5.02954550743103 and perplexity is 152.86352157059056
At time: 250.49958086013794 and batch: 1150, loss is 4.985922203063965 and perplexity is 146.33846660016042
At time: 250.8614947795868 and batch: 1200, loss is 4.946841535568237 and perplexity is 140.72977125198102
At time: 251.22376918792725 and batch: 1250, loss is 4.955691137313843 and perplexity is 141.98070063080428
At time: 251.5867166519165 and batch: 1300, loss is 5.016496343612671 and perplexity is 150.88173886090868
At time: 251.9495928287506 and batch: 1350, loss is 4.95753963470459 and perplexity is 142.2433943049416
At time: 252.31167316436768 and batch: 1400, loss is 4.861316833496094 and perplexity is 129.19421741487795
At time: 252.67428016662598 and batch: 1450, loss is 4.932745704650879 and perplexity is 138.75998370254595
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.204911191239316 and perplexity of 182.1646942296585
Finished 22 epochs...
Completing Train Step...
At time: 253.89500379562378 and batch: 50, loss is 5.0486518669128415 and perplexity is 155.81226715850264
At time: 254.25675129890442 and batch: 100, loss is 5.042337589263916 and perplexity is 154.83152484072605
At time: 254.6182463169098 and batch: 150, loss is 4.965857648849488 and perplexity is 143.43151140780822
At time: 254.98011875152588 and batch: 200, loss is 4.9741425037384035 and perplexity is 144.62475677343193
At time: 255.34296941757202 and batch: 250, loss is 4.991771841049195 and perplexity is 147.19700226637534
At time: 255.7152407169342 and batch: 300, loss is 5.031536331176758 and perplexity is 153.1681490283643
At time: 256.08958101272583 and batch: 350, loss is 5.065889291763305 and perplexity is 158.52135114163679
At time: 256.47156286239624 and batch: 400, loss is 4.957243413925171 and perplexity is 142.20126509589497
At time: 256.8334674835205 and batch: 450, loss is 4.9584592342376705 and perplexity is 142.37426142737812
At time: 257.19560742378235 and batch: 500, loss is 4.964854726791382 and perplexity is 143.28773289256372
At time: 257.57527804374695 and batch: 550, loss is 5.030722875595092 and perplexity is 153.04360420531222
At time: 257.94369411468506 and batch: 600, loss is 4.913903493881225 and perplexity is 136.16991676539686
At time: 258.3104200363159 and batch: 650, loss is 5.037048864364624 and perplexity is 154.01482505398604
At time: 258.68836879730225 and batch: 700, loss is 5.06089451789856 and perplexity is 157.73154692865788
At time: 259.0640766620636 and batch: 750, loss is 5.013336706161499 and perplexity is 150.4057596250029
At time: 259.4323968887329 and batch: 800, loss is 4.954464015960693 and perplexity is 141.8065799367855
At time: 259.7947874069214 and batch: 850, loss is 4.913051023483276 and perplexity is 136.05388540593947
At time: 260.15761518478394 and batch: 900, loss is 4.870961179733277 and perplexity is 130.44623893945726
At time: 260.51900267601013 and batch: 950, loss is 4.9520707702636715 and perplexity is 141.4676077332184
At time: 260.895792722702 and batch: 1000, loss is 4.9969895362854 and perplexity is 147.96703852416448
At time: 261.26962757110596 and batch: 1050, loss is 4.8913756942749025 and perplexity is 133.13660338927338
At time: 261.6321737766266 and batch: 1100, loss is 5.012698917388916 and perplexity is 150.30986310429515
At time: 261.9946596622467 and batch: 1150, loss is 4.97158881187439 and perplexity is 144.2559008813229
At time: 262.35764384269714 and batch: 1200, loss is 4.927274580001831 and perplexity is 138.0028835186837
At time: 262.7204284667969 and batch: 1250, loss is 4.941401014328003 and perplexity is 139.9662069197466
At time: 263.08376836776733 and batch: 1300, loss is 5.00331901550293 and perplexity is 148.90656303318517
At time: 263.44602060317993 and batch: 1350, loss is 4.940454435348511 and perplexity is 139.83378053634058
At time: 263.80864238739014 and batch: 1400, loss is 4.846552734375 and perplexity is 127.30079293019115
At time: 264.1715271472931 and batch: 1450, loss is 4.9096950244903566 and perplexity is 135.59805401620218
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.184917221721421 and perplexity of 178.5586683988497
Finished 23 epochs...
Completing Train Step...
At time: 265.3831925392151 and batch: 50, loss is 5.027001953125 and perplexity is 152.4751989712344
At time: 265.75999188423157 and batch: 100, loss is 5.025194301605224 and perplexity is 152.1998259103362
At time: 266.13980293273926 and batch: 150, loss is 4.946803159713745 and perplexity is 140.7243707303823
At time: 266.50534105300903 and batch: 200, loss is 4.953079490661621 and perplexity is 141.610380991831
At time: 266.8695366382599 and batch: 250, loss is 4.967790660858154 and perplexity is 143.709034382988
At time: 267.23314809799194 and batch: 300, loss is 5.013281507492065 and perplexity is 150.3974576563274
At time: 267.60739040374756 and batch: 350, loss is 5.04508903503418 and perplexity is 155.25812199519294
At time: 267.97228145599365 and batch: 400, loss is 4.928602600097657 and perplexity is 138.18627586868834
At time: 268.3340919017792 and batch: 450, loss is 4.935529136657715 and perplexity is 139.14675070256905
At time: 268.6967046260834 and batch: 500, loss is 4.937853755950928 and perplexity is 139.47059017975664
At time: 269.07603454589844 and batch: 550, loss is 5.0061266994476314 and perplexity is 149.3252330710114
At time: 269.4459261894226 and batch: 600, loss is 4.892390031814575 and perplexity is 133.2717173579962
At time: 269.8154549598694 and batch: 650, loss is 5.010681562423706 and perplexity is 150.00694040967684
At time: 270.1858425140381 and batch: 700, loss is 5.036639566421509 and perplexity is 153.95180000177422
At time: 270.55378913879395 and batch: 750, loss is 4.982891330718994 and perplexity is 145.8956048564598
At time: 270.9391589164734 and batch: 800, loss is 4.93022515296936 and perplexity is 138.4106724058216
At time: 271.34471249580383 and batch: 850, loss is 4.888129043579101 and perplexity is 132.70505626369956
At time: 271.7140905857086 and batch: 900, loss is 4.846096172332763 and perplexity is 127.24268548602868
At time: 272.07648491859436 and batch: 950, loss is 4.921376066207886 and perplexity is 137.19126762359588
At time: 272.4386579990387 and batch: 1000, loss is 4.9706525802612305 and perplexity is 144.1209071490934
At time: 272.8003511428833 and batch: 1050, loss is 4.867670621871948 and perplexity is 130.0177034894548
At time: 273.16148614883423 and batch: 1100, loss is 4.993552169799805 and perplexity is 147.4592947356463
At time: 273.52496242523193 and batch: 1150, loss is 4.94493411064148 and perplexity is 140.4615956221067
At time: 273.8859658241272 and batch: 1200, loss is 4.904653635025024 and perplexity is 134.91617167659098
At time: 274.249370098114 and batch: 1250, loss is 4.916471548080445 and perplexity is 136.52005789021769
At time: 274.61306858062744 and batch: 1300, loss is 4.974503097534179 and perplexity is 144.67691696719595
At time: 274.9776191711426 and batch: 1350, loss is 4.9067728805541995 and perplexity is 135.2023953522285
At time: 275.34064960479736 and batch: 1400, loss is 4.821477146148681 and perplexity is 124.14834064633722
At time: 275.70467734336853 and batch: 1450, loss is 4.890670318603515 and perplexity is 133.0427251818657
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.171214046641293 and perplexity of 176.12853599539866
Finished 24 epochs...
Completing Train Step...
At time: 276.9379906654358 and batch: 50, loss is 5.0053330993652345 and perplexity is 149.20677556390308
At time: 277.32080125808716 and batch: 100, loss is 5.00404993057251 and perplexity is 149.01544086944392
At time: 277.6840252876282 and batch: 150, loss is 4.918940448760987 and perplexity is 136.8575287736771
At time: 278.0484220981598 and batch: 200, loss is 4.922644901275635 and perplexity is 137.3654511966897
At time: 278.409921169281 and batch: 250, loss is 4.939677171707153 and perplexity is 139.7251350514584
At time: 278.77019476890564 and batch: 300, loss is 4.994996347427368 and perplexity is 147.67240599829907
At time: 279.1295962333679 and batch: 350, loss is 5.0355738830566406 and perplexity is 153.78782351854474
At time: 279.4923896789551 and batch: 400, loss is 4.922435216903686 and perplexity is 137.33665082792726
At time: 279.8563623428345 and batch: 450, loss is 4.927302017211914 and perplexity is 138.0066699847356
At time: 280.2204329967499 and batch: 500, loss is 4.928133945465088 and perplexity is 138.12152940339564
At time: 280.5841977596283 and batch: 550, loss is 4.991122121810913 and perplexity is 147.1013966039678
At time: 280.9477868080139 and batch: 600, loss is 4.884870538711548 and perplexity is 132.27333994876378
At time: 281.3303382396698 and batch: 650, loss is 4.999342174530029 and perplexity is 148.31556125113582
At time: 281.7033312320709 and batch: 700, loss is 5.0324986743927 and perplexity is 153.3156203050904
At time: 282.0633668899536 and batch: 750, loss is 4.983191804885864 and perplexity is 145.93944930351108
At time: 282.4237003326416 and batch: 800, loss is 4.9187969303131105 and perplexity is 136.83788860296445
At time: 282.79480719566345 and batch: 850, loss is 4.880833778381348 and perplexity is 131.74046045434253
At time: 283.170583486557 and batch: 900, loss is 4.8402156734466555 and perplexity is 126.49663075267337
At time: 283.53602957725525 and batch: 950, loss is 4.925247526168823 and perplexity is 137.72342757648948
At time: 283.8998832702637 and batch: 1000, loss is 4.96752890586853 and perplexity is 143.67142274891543
At time: 284.2951238155365 and batch: 1050, loss is 4.862505035400391 and perplexity is 129.34781746589965
At time: 284.6570839881897 and batch: 1100, loss is 4.986749324798584 and perplexity is 146.4595563975944
At time: 285.02021646499634 and batch: 1150, loss is 4.939194898605347 and perplexity is 139.65776562371408
At time: 285.3831434249878 and batch: 1200, loss is 4.899956216812134 and perplexity is 134.28390017899576
At time: 285.7463335990906 and batch: 1250, loss is 4.911231651306152 and perplexity is 135.80657779275563
At time: 286.1094057559967 and batch: 1300, loss is 4.96933349609375 and perplexity is 143.93092487112474
At time: 286.4733855724335 and batch: 1350, loss is 4.907746887207031 and perplexity is 135.33414753811712
At time: 286.83610224723816 and batch: 1400, loss is 4.813086242675781 and perplexity is 123.11098217749935
At time: 287.203821182251 and batch: 1450, loss is 4.884430980682373 and perplexity is 132.21521091662083
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.178421411758814 and perplexity of 177.40254426834835
Annealing...
Finished 25 epochs...
Completing Train Step...
At time: 288.44400215148926 and batch: 50, loss is 4.995001945495606 and perplexity is 147.67323268081853
At time: 288.80548787117004 and batch: 100, loss is 4.952808256149292 and perplexity is 141.5719765777386
At time: 289.1665389537811 and batch: 150, loss is 4.85972975730896 and perplexity is 128.98933897075756
At time: 289.52820467948914 and batch: 200, loss is 4.861156816482544 and perplexity is 129.1735457959888
At time: 289.89182019233704 and batch: 250, loss is 4.8946772480010985 and perplexity is 133.5768874490914
At time: 290.2543931007385 and batch: 300, loss is 4.911041927337647 and perplexity is 135.78081447390448
At time: 290.6192219257355 and batch: 350, loss is 4.935713129043579 and perplexity is 139.17235500064174
At time: 290.9838240146637 and batch: 400, loss is 4.816323308944702 and perplexity is 123.51014629703684
At time: 291.346905708313 and batch: 450, loss is 4.839050559997559 and perplexity is 126.34933365249708
At time: 291.7091338634491 and batch: 500, loss is 4.824395341873169 and perplexity is 124.51115893312424
At time: 292.0710802078247 and batch: 550, loss is 4.883592443466187 and perplexity is 132.1043900119414
At time: 292.4330711364746 and batch: 600, loss is 4.77683572769165 and perplexity is 118.7280670929901
At time: 292.809396982193 and batch: 650, loss is 4.8910638618469235 and perplexity is 133.09509355137877
At time: 293.1818799972534 and batch: 700, loss is 4.924258937835694 and perplexity is 137.58734307964474
At time: 293.5680465698242 and batch: 750, loss is 4.864249534606934 and perplexity is 129.5736615659882
At time: 293.9296541213989 and batch: 800, loss is 4.806815814971924 and perplexity is 122.34143886847055
At time: 294.29068207740784 and batch: 850, loss is 4.754241514205932 and perplexity is 116.07557808975588
At time: 294.651504278183 and batch: 900, loss is 4.706435432434082 and perplexity is 110.65701166307962
At time: 295.01340889930725 and batch: 950, loss is 4.79783447265625 and perplexity is 121.24756809357588
At time: 295.37649869918823 and batch: 1000, loss is 4.840497331619263 and perplexity is 126.532264580576
At time: 295.7373700141907 and batch: 1050, loss is 4.732536373138427 and perplexity is 113.58328690387174
At time: 296.09850311279297 and batch: 1100, loss is 4.848159885406494 and perplexity is 127.50554902376977
At time: 296.45886301994324 and batch: 1150, loss is 4.8030381011962895 and perplexity is 121.88013980604204
At time: 296.8214235305786 and batch: 1200, loss is 4.757539510726929 and perplexity is 116.45902690133448
At time: 297.1820788383484 and batch: 1250, loss is 4.7688495063781735 and perplexity is 117.78365463603608
At time: 297.54235100746155 and batch: 1300, loss is 4.822631025314331 and perplexity is 124.29167550971188
At time: 297.94673013687134 and batch: 1350, loss is 4.746372222900391 and perplexity is 115.16573017669027
At time: 298.3442771434784 and batch: 1400, loss is 4.645893840789795 and perplexity is 104.15642344965003
At time: 298.72718262672424 and batch: 1450, loss is 4.718676891326904 and perplexity is 112.01994001837137
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.051461505074786 and perplexity of 156.25065882299447
Finished 26 epochs...
Completing Train Step...
At time: 299.96683859825134 and batch: 50, loss is 4.902713584899902 and perplexity is 134.65468127510823
At time: 300.3319947719574 and batch: 100, loss is 4.891727590560913 and perplexity is 133.1834619097243
At time: 300.6953411102295 and batch: 150, loss is 4.812781133651733 and perplexity is 123.07342563558892
At time: 301.0588707923889 and batch: 200, loss is 4.818838663101197 and perplexity is 123.82120910945535
At time: 301.42404556274414 and batch: 250, loss is 4.856439628601074 and perplexity is 128.56564482993215
At time: 301.7875418663025 and batch: 300, loss is 4.878740520477295 and perplexity is 131.46498211840418
At time: 302.1520965099335 and batch: 350, loss is 4.9041252708435055 and perplexity is 134.8449056328398
At time: 302.5156846046448 and batch: 400, loss is 4.789488477706909 and perplexity is 120.23984756730235
At time: 302.8796536922455 and batch: 450, loss is 4.811623697280884 and perplexity is 122.931058382885
At time: 303.26573872566223 and batch: 500, loss is 4.798344163894654 and perplexity is 121.30938266854632
At time: 303.62900733947754 and batch: 550, loss is 4.86056342124939 and perplexity is 129.09691756732516
At time: 303.99256134033203 and batch: 600, loss is 4.755803050994873 and perplexity is 116.25697596811086
At time: 304.3564190864563 and batch: 650, loss is 4.869954071044922 and perplexity is 130.3149315303728
At time: 304.7204968929291 and batch: 700, loss is 4.903980770111084 and perplexity is 134.8254218529567
At time: 305.08422350883484 and batch: 750, loss is 4.845735282897949 and perplexity is 127.19677323030167
At time: 305.46482157707214 and batch: 800, loss is 4.790094738006592 and perplexity is 120.31276631495975
At time: 305.83830881118774 and batch: 850, loss is 4.739702253341675 and perplexity is 114.40013435097872
At time: 306.20196413993835 and batch: 900, loss is 4.694813899993896 and perplexity is 109.37845141715536
At time: 306.56430745124817 and batch: 950, loss is 4.786174211502075 and perplexity is 119.84200035399725
At time: 306.92701053619385 and batch: 1000, loss is 4.831246337890625 and perplexity is 125.36711310849729
At time: 307.2904555797577 and batch: 1050, loss is 4.726757373809814 and perplexity is 112.92878217782987
At time: 307.6685447692871 and batch: 1100, loss is 4.841357612609864 and perplexity is 126.64116471813519
At time: 308.0378005504608 and batch: 1150, loss is 4.797834367752075 and perplexity is 121.24755537420042
At time: 308.4015600681305 and batch: 1200, loss is 4.753195972442627 and perplexity is 115.95427964750664
At time: 308.7653727531433 and batch: 1250, loss is 4.766431541442871 and perplexity is 117.49920192610254
At time: 309.1294116973877 and batch: 1300, loss is 4.822228126525879 and perplexity is 124.24160863085393
At time: 309.49268555641174 and batch: 1350, loss is 4.748741846084595 and perplexity is 115.43895315084164
At time: 309.855660200119 and batch: 1400, loss is 4.652179870605469 and perplexity is 104.81321597894313
At time: 310.21868348121643 and batch: 1450, loss is 4.726096954345703 and perplexity is 112.85422643376333
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.045697595319178 and perplexity of 155.35263467757815
Finished 27 epochs...
Completing Train Step...
At time: 311.429710149765 and batch: 50, loss is 4.889086589813233 and perplexity is 132.83218834828557
At time: 311.8040521144867 and batch: 100, loss is 4.879897260665894 and perplexity is 131.61714093375608
At time: 312.16508293151855 and batch: 150, loss is 4.801383028030395 and perplexity is 121.678586096271
At time: 312.5489959716797 and batch: 200, loss is 4.807538299560547 and perplexity is 122.4298606104297
At time: 312.91084694862366 and batch: 250, loss is 4.844377603530884 and perplexity is 127.02419797317144
At time: 313.27443075180054 and batch: 300, loss is 4.866963968276978 and perplexity is 129.92585846700382
At time: 313.6366846561432 and batch: 350, loss is 4.892383470535278 and perplexity is 133.27084292790497
At time: 313.9988441467285 and batch: 400, loss is 4.778636474609375 and perplexity is 118.94205890858059
At time: 314.36091780662537 and batch: 450, loss is 4.801081619262695 and perplexity is 121.64191663010716
At time: 314.72338342666626 and batch: 500, loss is 4.7866206455230715 and perplexity is 119.89551384433207
At time: 315.0855875015259 and batch: 550, loss is 4.850104579925537 and perplexity is 127.75374962505718
At time: 315.4478666782379 and batch: 600, loss is 4.746441545486451 and perplexity is 115.17371403965943
At time: 315.82442021369934 and batch: 650, loss is 4.860573692321777 and perplexity is 129.09824353792
At time: 316.2078242301941 and batch: 700, loss is 4.89474570274353 and perplexity is 133.58603173349783
At time: 316.5760862827301 and batch: 750, loss is 4.836925735473633 and perplexity is 126.0811485138523
At time: 316.95634484291077 and batch: 800, loss is 4.78255630493164 and perplexity is 119.40920656931974
At time: 317.32731223106384 and batch: 850, loss is 4.731970624923706 and perplexity is 113.51904553601678
At time: 317.68900084495544 and batch: 900, loss is 4.6895708560943605 and perplexity is 108.80647615070373
At time: 318.05059695243835 and batch: 950, loss is 4.779502964019775 and perplexity is 119.04516560705622
At time: 318.4129776954651 and batch: 1000, loss is 4.825852737426758 and perplexity is 124.69275323774946
At time: 318.7735114097595 and batch: 1050, loss is 4.724257354736328 and perplexity is 112.64681068236052
At time: 319.1351146697998 and batch: 1100, loss is 4.836595983505249 and perplexity is 126.03957986100293
At time: 319.49682784080505 and batch: 1150, loss is 4.793765459060669 and perplexity is 120.75521247075575
At time: 319.8699698448181 and batch: 1200, loss is 4.750411329269409 and perplexity is 115.63183750579287
At time: 320.2400140762329 and batch: 1250, loss is 4.76351523399353 and perplexity is 117.15703729936365
At time: 320.60148191452026 and batch: 1300, loss is 4.819755744934082 and perplexity is 123.93481537601488
At time: 320.9625267982483 and batch: 1350, loss is 4.7468777275085445 and perplexity is 115.2239617009079
At time: 321.32323479652405 and batch: 1400, loss is 4.649629573822022 and perplexity is 104.54625173509041
At time: 321.68404841423035 and batch: 1450, loss is 4.723058214187622 and perplexity is 112.51181228119395
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.045242179153312 and perplexity of 155.28190068426068
Finished 28 epochs...
Completing Train Step...
At time: 322.9121255874634 and batch: 50, loss is 4.87049898147583 and perplexity is 130.38596084641685
At time: 323.30023670196533 and batch: 100, loss is 4.864123916625976 and perplexity is 129.5573858065224
At time: 323.66272020339966 and batch: 150, loss is 4.784926776885986 and perplexity is 119.69259849819123
At time: 324.0247857570648 and batch: 200, loss is 4.789016275405884 and perplexity is 120.18308343773722
At time: 324.3863408565521 and batch: 250, loss is 4.814149208068848 and perplexity is 123.24191446697847
At time: 324.7575743198395 and batch: 300, loss is 4.850836009979248 and perplexity is 127.84722673882493
At time: 325.1308617591858 and batch: 350, loss is 4.8771091556549075 and perplexity is 131.25068961335333
At time: 325.49453258514404 and batch: 400, loss is 4.7602238273620605 and perplexity is 116.77205975624226
At time: 325.8567109107971 and batch: 450, loss is 4.784998064041138 and perplexity is 119.7011313471685
At time: 326.2167980670929 and batch: 500, loss is 4.77057409286499 and perplexity is 117.9869579919107
At time: 326.5786819458008 and batch: 550, loss is 4.83315113067627 and perplexity is 125.60613905628374
At time: 326.9393951892853 and batch: 600, loss is 4.729941139221191 and perplexity is 113.288893879882
At time: 327.30019426345825 and batch: 650, loss is 4.846140899658203 and perplexity is 127.24837683831078
At time: 327.6617069244385 and batch: 700, loss is 4.878385314941406 and perplexity is 131.41829332153068
At time: 328.02323842048645 and batch: 750, loss is 4.81977611541748 and perplexity is 123.93734001382786
At time: 328.3841848373413 and batch: 800, loss is 4.766273393630981 and perplexity is 117.48062115371211
At time: 328.74505138397217 and batch: 850, loss is 4.716650028228759 and perplexity is 111.79312087901452
At time: 329.1314947605133 and batch: 900, loss is 4.67329704284668 and perplexity is 107.05011002722281
At time: 329.4944324493408 and batch: 950, loss is 4.757844762802124 and perplexity is 116.49458168728135
At time: 329.86578488349915 and batch: 1000, loss is 4.810274057388305 and perplexity is 122.76525763327508
At time: 330.23979210853577 and batch: 1050, loss is 4.7098047733306885 and perplexity is 111.03048167855383
At time: 330.6043426990509 and batch: 1100, loss is 4.825872850418091 and perplexity is 124.6952612072359
At time: 330.98560523986816 and batch: 1150, loss is 4.777986927032471 and perplexity is 118.86482546853695
At time: 331.3458733558655 and batch: 1200, loss is 4.735518760681153 and perplexity is 113.92254192731104
At time: 331.7071444988251 and batch: 1250, loss is 4.7466514110565186 and perplexity is 115.19788757332068
At time: 332.0687167644501 and batch: 1300, loss is 4.807755355834961 and perplexity is 122.45643766410457
At time: 332.4309186935425 and batch: 1350, loss is 4.73172513961792 and perplexity is 113.49118169863205
At time: 332.7933840751648 and batch: 1400, loss is 4.635947484970092 and perplexity is 103.12558165915024
At time: 333.1568078994751 and batch: 1450, loss is 4.712223978042602 and perplexity is 111.29941231096235
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.030681903545673 and perplexity of 153.03733382365354
Finished 29 epochs...
Completing Train Step...
At time: 334.3812429904938 and batch: 50, loss is 4.853808612823486 and perplexity is 128.22783118131753
At time: 334.7436740398407 and batch: 100, loss is 4.849748401641846 and perplexity is 127.70825461642866
At time: 335.10600113868713 and batch: 150, loss is 4.7688143825531 and perplexity is 117.77951769620715
At time: 335.46809458732605 and batch: 200, loss is 4.775409002304077 and perplexity is 118.55879552618521
At time: 335.8309247493744 and batch: 250, loss is 4.800838346481323 and perplexity is 121.61232806190971
At time: 336.19291257858276 and batch: 300, loss is 4.835347461700439 and perplexity is 125.88231489207766
At time: 336.5555028915405 and batch: 350, loss is 4.861051445007324 and perplexity is 129.15993530600016
At time: 336.917751789093 and batch: 400, loss is 4.737492504119873 and perplexity is 114.14761784495198
At time: 337.27979469299316 and batch: 450, loss is 4.767029819488525 and perplexity is 117.56952015182469
At time: 337.656010389328 and batch: 500, loss is 4.747902679443359 and perplexity is 115.34212126698405
At time: 338.0285677909851 and batch: 550, loss is 4.812459106445313 and perplexity is 123.03379902491265
At time: 338.3906252384186 and batch: 600, loss is 4.710470323562622 and perplexity is 111.10440263771379
At time: 338.7539553642273 and batch: 650, loss is 4.829874429702759 and perplexity is 125.19523886433355
At time: 339.1155655384064 and batch: 700, loss is 4.861106767654419 and perplexity is 129.16708097317664
At time: 339.4776556491852 and batch: 750, loss is 4.797477474212647 and perplexity is 121.2042906259297
At time: 339.8398187160492 and batch: 800, loss is 4.750843553543091 and perplexity is 115.68182719537376
At time: 340.2153515815735 and batch: 850, loss is 4.698210506439209 and perplexity is 109.75059863124376
At time: 340.57744693756104 and batch: 900, loss is 4.658152627944946 and perplexity is 105.44111315606847
At time: 340.9399185180664 and batch: 950, loss is 4.738508338928223 and perplexity is 114.26363188402217
At time: 341.3015582561493 and batch: 1000, loss is 4.792384357452392 and perplexity is 120.5885523663649
At time: 341.6639688014984 and batch: 1050, loss is 4.694937915802002 and perplexity is 109.39201691534792
At time: 342.02739548683167 and batch: 1100, loss is 4.8138801383972165 and perplexity is 123.20875826638566
At time: 342.38935136795044 and batch: 1150, loss is 4.76021635055542 and perplexity is 116.77118667739437
At time: 342.74938583374023 and batch: 1200, loss is 4.717875270843506 and perplexity is 111.93017852203735
At time: 343.11035776138306 and batch: 1250, loss is 4.72902138710022 and perplexity is 113.18474408279394
At time: 343.47252321243286 and batch: 1300, loss is 4.787918615341186 and perplexity is 120.05123564186361
At time: 343.85511088371277 and batch: 1350, loss is 4.712825536727905 and perplexity is 111.3663855812637
At time: 344.2269711494446 and batch: 1400, loss is 4.618195457458496 and perplexity is 101.31104698275567
At time: 344.58888125419617 and batch: 1450, loss is 4.692030963897705 and perplexity is 109.07448133739517
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.013247758914263 and perplexity of 150.39238204167424
Finished 30 epochs...
Completing Train Step...
At time: 345.8232305049896 and batch: 50, loss is 4.8364393997192385 and perplexity is 126.01984565147009
At time: 346.1854302883148 and batch: 100, loss is 4.8307154178619385 and perplexity is 125.30057086307787
At time: 346.547709941864 and batch: 150, loss is 4.748071727752685 and perplexity is 115.36162130575616
At time: 346.91047263145447 and batch: 200, loss is 4.753750658035278 and perplexity is 116.01861565731268
At time: 347.27441000938416 and batch: 250, loss is 4.778612642288208 and perplexity is 118.93922427701057
At time: 347.63957715034485 and batch: 300, loss is 4.8218470287323 and perplexity is 124.1942694489359
At time: 348.0025007724762 and batch: 350, loss is 4.848867626190185 and perplexity is 127.59582184207035
At time: 348.36553978919983 and batch: 400, loss is 4.725675706863403 and perplexity is 112.8066968865651
At time: 348.72909688949585 and batch: 450, loss is 4.757640342712403 and perplexity is 116.47077028828788
At time: 349.09239649772644 and batch: 500, loss is 4.738317899703979 and perplexity is 114.24187367848057
At time: 349.4553294181824 and batch: 550, loss is 4.802556772232055 and perplexity is 121.82148948077095
At time: 349.83149909973145 and batch: 600, loss is 4.701679773330689 and perplexity is 110.13201398266692
At time: 350.1950681209564 and batch: 650, loss is 4.819333477020264 and perplexity is 123.88249272794175
At time: 350.5584030151367 and batch: 700, loss is 4.852243432998657 and perplexity is 128.02728855055136
At time: 350.92171478271484 and batch: 750, loss is 4.789170560836792 and perplexity is 120.20162736704549
At time: 351.28541135787964 and batch: 800, loss is 4.741697797775268 and perplexity is 114.62865283584655
At time: 351.6487789154053 and batch: 850, loss is 4.688624229431152 and perplexity is 108.70352577472302
At time: 352.0121111869812 and batch: 900, loss is 4.648466348648071 and perplexity is 104.42471160620335
At time: 352.3765330314636 and batch: 950, loss is 4.730308094024658 and perplexity is 113.33047341210866
At time: 352.7403690814972 and batch: 1000, loss is 4.783094091415405 and perplexity is 119.47344049717078
At time: 353.10401487350464 and batch: 1050, loss is 4.689757394790649 and perplexity is 108.82677466208273
At time: 353.46714901924133 and batch: 1100, loss is 4.807461881637574 and perplexity is 122.42050513223957
At time: 353.8297824859619 and batch: 1150, loss is 4.7503870010375975 and perplexity is 115.62902442186409
At time: 354.1925609111786 and batch: 1200, loss is 4.710419998168946 and perplexity is 111.09881140560353
At time: 354.55438804626465 and batch: 1250, loss is 4.720813512802124 and perplexity is 112.25954010406086
At time: 354.9152407646179 and batch: 1300, loss is 4.780848417282105 and perplexity is 119.20544311225447
At time: 355.2783088684082 and batch: 1350, loss is 4.70615553855896 and perplexity is 110.62604377733872
At time: 355.64143323898315 and batch: 1400, loss is 4.611875381469726 and perplexity is 100.67277256330651
At time: 356.00478625297546 and batch: 1450, loss is 4.684574613571167 and perplexity is 108.26420838641887
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.008205316005609 and perplexity of 149.63594578742183
Finished 31 epochs...
Completing Train Step...
At time: 357.21894121170044 and batch: 50, loss is 4.828530015945435 and perplexity is 125.02703775413072
At time: 357.6088898181915 and batch: 100, loss is 4.82158971786499 and perplexity is 124.16231702477833
At time: 357.98149371147156 and batch: 150, loss is 4.7387560272216795 and perplexity is 114.29193715330491
At time: 358.34581875801086 and batch: 200, loss is 4.745903625488281 and perplexity is 115.11177645584002
At time: 358.70755648612976 and batch: 250, loss is 4.7725013160705565 and perplexity is 118.21456444908209
At time: 359.08266520500183 and batch: 300, loss is 4.813989953994751 and perplexity is 123.22228925273924
At time: 359.4547007083893 and batch: 350, loss is 4.840286712646485 and perplexity is 126.50561729129763
At time: 359.84000182151794 and batch: 400, loss is 4.717614793777466 and perplexity is 111.90102707434121
At time: 360.2233774662018 and batch: 450, loss is 4.750241060256958 and perplexity is 115.61215066309003
At time: 360.5946502685547 and batch: 500, loss is 4.73159348487854 and perplexity is 113.4762410302101
At time: 360.95682096481323 and batch: 550, loss is 4.795768775939941 and perplexity is 120.99736590019907
At time: 361.3191499710083 and batch: 600, loss is 4.694943971633911 and perplexity is 109.3926793770205
At time: 361.6817467212677 and batch: 650, loss is 4.811590824127197 and perplexity is 122.9270173177316
At time: 362.0437865257263 and batch: 700, loss is 4.845364503860473 and perplexity is 127.14962007539424
At time: 362.4058163166046 and batch: 750, loss is 4.782988624572754 and perplexity is 119.46084067506428
At time: 362.7681303024292 and batch: 800, loss is 4.735657730102539 and perplexity is 113.93837477716107
At time: 363.13073778152466 and batch: 850, loss is 4.681838569641113 and perplexity is 107.96839761638705
At time: 363.49811005592346 and batch: 900, loss is 4.640406532287598 and perplexity is 103.58645026124101
At time: 363.87217020988464 and batch: 950, loss is 4.723456020355225 and perplexity is 112.55657907771106
At time: 364.2360827922821 and batch: 1000, loss is 4.776851739883423 and perplexity is 118.72996820478961
At time: 364.5982897281647 and batch: 1050, loss is 4.684251203536987 and perplexity is 108.22920031636988
At time: 364.9607036113739 and batch: 1100, loss is 4.801327066421509 and perplexity is 121.67177695735299
At time: 365.3395690917969 and batch: 1150, loss is 4.742451639175415 and perplexity is 114.71509723858834
At time: 365.709260225296 and batch: 1200, loss is 4.703035326004028 and perplexity is 110.28140495943455
At time: 366.07167053222656 and batch: 1250, loss is 4.71576265335083 and perplexity is 111.69396247386675
At time: 366.433935880661 and batch: 1300, loss is 4.776941165924073 and perplexity is 118.74058623050958
At time: 366.79474782943726 and batch: 1350, loss is 4.700532608032226 and perplexity is 110.00574679649056
At time: 367.17360043525696 and batch: 1400, loss is 4.607319145202637 and perplexity is 100.2151269882279
At time: 367.5650556087494 and batch: 1450, loss is 4.679147644042969 and perplexity is 107.67825324498845
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.005311623597756 and perplexity of 149.20357126829236
Finished 32 epochs...
Completing Train Step...
At time: 368.7850351333618 and batch: 50, loss is 4.823120384216309 and perplexity is 124.35251363218856
At time: 369.1603558063507 and batch: 100, loss is 4.814089412689209 and perplexity is 123.23454539023608
At time: 369.5220913887024 and batch: 150, loss is 4.732181348800659 and perplexity is 113.54296922995837
At time: 369.8843557834625 and batch: 200, loss is 4.739977970123291 and perplexity is 114.43168073657247
At time: 370.2461941242218 and batch: 250, loss is 4.767243986129761 and perplexity is 117.59470231756096
At time: 370.60831093788147 and batch: 300, loss is 4.8082785892486575 and perplexity is 122.52052772958238
At time: 370.9697346687317 and batch: 350, loss is 4.833619804382324 and perplexity is 125.6650211481447
At time: 371.3309893608093 and batch: 400, loss is 4.711640005111694 and perplexity is 111.23443544115987
At time: 371.6932897567749 and batch: 450, loss is 4.744965028762818 and perplexity is 115.00378360819103
At time: 372.0556616783142 and batch: 500, loss is 4.7266724491119385 and perplexity is 112.91919214234314
At time: 372.41796803474426 and batch: 550, loss is 4.789017181396485 and perplexity is 120.1831923225305
At time: 372.78960037231445 and batch: 600, loss is 4.688721971511841 and perplexity is 108.7141512027777
At time: 373.16321897506714 and batch: 650, loss is 4.805845117568969 and perplexity is 122.22273997116324
At time: 373.5261960029602 and batch: 700, loss is 4.840209722518921 and perplexity is 126.49587798260494
At time: 373.8884575366974 and batch: 750, loss is 4.777577476501465 and perplexity is 118.81616616509959
At time: 374.25018882751465 and batch: 800, loss is 4.730268087387085 and perplexity is 113.32593953162609
At time: 374.6118485927582 and batch: 850, loss is 4.676136989593505 and perplexity is 107.35455874339004
At time: 374.9735553264618 and batch: 900, loss is 4.635520267486572 and perplexity is 103.08153401729857
At time: 375.33553528785706 and batch: 950, loss is 4.719224605560303 and perplexity is 112.08131173949225
At time: 375.71279644966125 and batch: 1000, loss is 4.772236471176147 and perplexity is 118.18326007082831
At time: 376.0871114730835 and batch: 1050, loss is 4.680345945358276 and perplexity is 107.80736157737502
At time: 376.450651884079 and batch: 1100, loss is 4.797032327651977 and perplexity is 121.15034895968354
At time: 376.8127703666687 and batch: 1150, loss is 4.7371117305755615 and perplexity is 114.10416172592566
At time: 377.1752007007599 and batch: 1200, loss is 4.697713546752929 and perplexity is 109.69607055842816
At time: 377.57881021499634 and batch: 1250, loss is 4.710830917358399 and perplexity is 111.144473420192
At time: 377.9470613002777 and batch: 1300, loss is 4.771160030364991 and perplexity is 118.0561112328692
At time: 378.30905985832214 and batch: 1350, loss is 4.695442695617675 and perplexity is 109.44724973651647
At time: 378.66894268989563 and batch: 1400, loss is 4.603002967834473 and perplexity is 99.78351285680523
At time: 379.02891850471497 and batch: 1450, loss is 4.674380321502685 and perplexity is 107.16613796048362
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.001098111144498 and perplexity of 148.57622276120185
Finished 33 epochs...
Completing Train Step...
At time: 380.25298833847046 and batch: 50, loss is 4.81700213432312 and perplexity is 123.59401658225377
At time: 380.61772441864014 and batch: 100, loss is 4.80807975769043 and perplexity is 122.49616920384109
At time: 380.9814326763153 and batch: 150, loss is 4.724027614593506 and perplexity is 112.62093416053767
At time: 381.34482622146606 and batch: 200, loss is 4.73386326789856 and perplexity is 113.73410000653351
At time: 381.7084147930145 and batch: 250, loss is 4.7599171447753905 and perplexity is 116.73625328979595
At time: 382.0826554298401 and batch: 300, loss is 4.800117282867432 and perplexity is 121.52466944466136
At time: 382.4575273990631 and batch: 350, loss is 4.823062372207642 and perplexity is 124.34529990233347
At time: 382.8251323699951 and batch: 400, loss is 4.7006336688995365 and perplexity is 110.01686463445063
At time: 383.18862676620483 and batch: 450, loss is 4.736425943374634 and perplexity is 114.02593737793558
At time: 383.55260014533997 and batch: 500, loss is 4.716933965682983 and perplexity is 111.82486763999064
At time: 383.9164798259735 and batch: 550, loss is 4.779894542694092 and perplexity is 119.09179028320715
At time: 384.2796130180359 and batch: 600, loss is 4.67898847579956 and perplexity is 107.66111565048273
At time: 384.6431727409363 and batch: 650, loss is 4.796195487976075 and perplexity is 121.0490079499276
At time: 385.0065176486969 and batch: 700, loss is 4.8319455337524415 and perplexity is 125.45479992674855
At time: 385.370329618454 and batch: 750, loss is 4.766495666503906 and perplexity is 117.50673681118256
At time: 385.73409056663513 and batch: 800, loss is 4.7219945907592775 and perplexity is 112.39220570114237
At time: 386.0973708629608 and batch: 850, loss is 4.664440298080445 and perplexity is 106.10618076608048
At time: 386.4607594013214 and batch: 900, loss is 4.623076782226563 and perplexity is 101.80678805791722
At time: 386.8369925022125 and batch: 950, loss is 4.70862494468689 and perplexity is 110.89956198252507
At time: 387.2004146575928 and batch: 1000, loss is 4.763372135162354 and perplexity is 117.14027346373325
At time: 387.5791530609131 and batch: 1050, loss is 4.672403888702393 and perplexity is 106.95454046333481
At time: 387.9561927318573 and batch: 1100, loss is 4.788887910842895 and perplexity is 120.16765717886676
At time: 388.33798480033875 and batch: 1150, loss is 4.729202108383179 and perplexity is 113.20520082338449
At time: 388.7024595737457 and batch: 1200, loss is 4.690067224502563 and perplexity is 108.86049765424751
At time: 389.0639588832855 and batch: 1250, loss is 4.702875471115112 and perplexity is 110.26377734666283
At time: 389.42543625831604 and batch: 1300, loss is 4.763390016555786 and perplexity is 117.14236811377744
At time: 389.7882936000824 and batch: 1350, loss is 4.686021566390991 and perplexity is 108.42097497760876
At time: 390.1512382030487 and batch: 1400, loss is 4.590691509246827 and perplexity is 98.56256352587478
At time: 390.51404333114624 and batch: 1450, loss is 4.66490927696228 and perplexity is 106.15595399447625
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.9918473724626065 and perplexity of 147.2081206838961
Finished 34 epochs...
Completing Train Step...
At time: 391.72653675079346 and batch: 50, loss is 4.806607437133789 and perplexity is 122.31594827985396
At time: 392.0877466201782 and batch: 100, loss is 4.79714225769043 and perplexity is 121.1636677542576
At time: 392.44966888427734 and batch: 150, loss is 4.710069284439087 and perplexity is 111.05985435885754
At time: 392.81098556518555 and batch: 200, loss is 4.72395806312561 and perplexity is 112.61310148164128
At time: 393.1721441745758 and batch: 250, loss is 4.749420766830444 and perplexity is 115.5173536618701
At time: 393.5342152118683 and batch: 300, loss is 4.79269926071167 and perplexity is 120.62653207418967
At time: 393.8950250148773 and batch: 350, loss is 4.814360208511353 and perplexity is 123.26792130909728
At time: 394.25613808631897 and batch: 400, loss is 4.690987186431885 and perplexity is 108.96069124777583
At time: 394.6168358325958 and batch: 450, loss is 4.728221979141235 and perplexity is 113.09429945343338
At time: 394.9779291152954 and batch: 500, loss is 4.7084348678588865 and perplexity is 110.87848454878579
At time: 395.3391194343567 and batch: 550, loss is 4.7706755256652835 and perplexity is 117.9989263464395
At time: 395.70064210891724 and batch: 600, loss is 4.66944149017334 and perplexity is 106.63816733300773
At time: 396.0621380805969 and batch: 650, loss is 4.785950756072998 and perplexity is 119.81522400015886
At time: 396.4361991882324 and batch: 700, loss is 4.823639965057373 and perplexity is 124.41714160408404
At time: 396.79650044441223 and batch: 750, loss is 4.757596607208252 and perplexity is 116.46567649182118
At time: 397.15780782699585 and batch: 800, loss is 4.711627168655395 and perplexity is 111.23300759435469
At time: 397.5185568332672 and batch: 850, loss is 4.654059286117554 and perplexity is 105.01038878970716
At time: 397.87978744506836 and batch: 900, loss is 4.615109043121338 and perplexity is 100.99884116093604
At time: 398.2408142089844 and batch: 950, loss is 4.698730363845825 and perplexity is 109.8076681255371
At time: 398.6023998260498 and batch: 1000, loss is 4.754795885086059 and perplexity is 116.13994485002303
At time: 398.9636974334717 and batch: 1050, loss is 4.664541864395142 and perplexity is 106.11695812712665
At time: 399.3257095813751 and batch: 1100, loss is 4.780499191284179 and perplexity is 119.16382074065562
At time: 399.686931848526 and batch: 1150, loss is 4.720112314224243 and perplexity is 112.18085146559118
At time: 400.0483000278473 and batch: 1200, loss is 4.682140665054321 and perplexity is 108.00101930126102
At time: 400.40931010246277 and batch: 1250, loss is 4.694763383865356 and perplexity is 109.37292618080204
At time: 400.77104592323303 and batch: 1300, loss is 4.755069417953491 and perplexity is 116.17171728736608
At time: 401.131716966629 and batch: 1350, loss is 4.677296228408814 and perplexity is 107.47908047615395
At time: 401.4925379753113 and batch: 1400, loss is 4.580742244720459 and perplexity is 97.58680061963744
At time: 401.85318994522095 and batch: 1450, loss is 4.657733507156372 and perplexity is 105.39692985329152
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.986549312232906 and perplexity of 146.43026557531522
Finished 35 epochs...
Completing Train Step...
At time: 403.04750084877014 and batch: 50, loss is 4.7987377643585205 and perplexity is 121.3571394957742
At time: 403.4213879108429 and batch: 100, loss is 4.788351793289184 and perplexity is 120.10325045479516
At time: 403.7819118499756 and batch: 150, loss is 4.70149754524231 and perplexity is 110.11194666475956
At time: 404.14270877838135 and batch: 200, loss is 4.716428833007813 and perplexity is 111.76839550960895
At time: 404.5042202472687 and batch: 250, loss is 4.740581121444702 and perplexity is 114.50072117484282
At time: 404.8658173084259 and batch: 300, loss is 4.784806537628174 and perplexity is 119.6782076141741
At time: 405.22734117507935 and batch: 350, loss is 4.805879812240601 and perplexity is 122.2269805225543
At time: 405.60250902175903 and batch: 400, loss is 4.68336329460144 and perplexity is 108.13314529268946
At time: 405.9645879268646 and batch: 450, loss is 4.721024808883667 and perplexity is 112.28326261114876
At time: 406.32643580436707 and batch: 500, loss is 4.700884361267089 and perplexity is 110.04444848010192
At time: 406.6883614063263 and batch: 550, loss is 4.7627550220489505 and perplexity is 117.06800696546644
At time: 407.050420999527 and batch: 600, loss is 4.661477947235108 and perplexity is 105.79232214099703
At time: 407.41237449645996 and batch: 650, loss is 4.778414907455445 and perplexity is 118.91570817444205
At time: 407.77424597740173 and batch: 700, loss is 4.816428203582763 and perplexity is 123.52310252863725
At time: 408.1367812156677 and batch: 750, loss is 4.74904161453247 and perplexity is 115.47356329390726
At time: 408.499507188797 and batch: 800, loss is 4.703067445755005 and perplexity is 110.28494722758735
At time: 408.8618049621582 and batch: 850, loss is 4.646282682418823 and perplexity is 104.19693167815029
At time: 409.2238178253174 and batch: 900, loss is 4.607580003738403 and perplexity is 100.24127236949032
At time: 409.5857253074646 and batch: 950, loss is 4.689696311950684 and perplexity is 108.82012741664045
At time: 409.9474346637726 and batch: 1000, loss is 4.7473658847808835 and perplexity is 115.28022284678643
At time: 410.30953550338745 and batch: 1050, loss is 4.6571480178833005 and perplexity is 105.33523914283461
At time: 410.67141675949097 and batch: 1100, loss is 4.773182287216186 and perplexity is 118.29509257201728
At time: 411.0335285663605 and batch: 1150, loss is 4.712858648300171 and perplexity is 111.3700731584382
At time: 411.395938873291 and batch: 1200, loss is 4.673615922927857 and perplexity is 107.08425161824563
At time: 411.75871181488037 and batch: 1250, loss is 4.685428323745728 and perplexity is 108.35667410650628
At time: 412.1364266872406 and batch: 1300, loss is 4.746615905761718 and perplexity is 115.1937975109719
At time: 412.50808477401733 and batch: 1350, loss is 4.6698099136352536 and perplexity is 106.67746257398854
At time: 412.8698170185089 and batch: 1400, loss is 4.573782758712769 and perplexity is 96.9100044545952
At time: 413.2329909801483 and batch: 1450, loss is 4.651571941375733 and perplexity is 104.74951632568927
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.98036128639156 and perplexity of 145.52694906339508
Finished 36 epochs...
Completing Train Step...
At time: 414.4413344860077 and batch: 50, loss is 4.790980987548828 and perplexity is 120.4194407121172
At time: 414.8140482902527 and batch: 100, loss is 4.7806039142608645 and perplexity is 119.17630058412853
At time: 415.1763918399811 and batch: 150, loss is 4.693127040863037 and perplexity is 109.1941009080469
At time: 415.5378303527832 and batch: 200, loss is 4.708130550384522 and perplexity is 110.84474742206547
At time: 415.8994188308716 and batch: 250, loss is 4.733550539016724 and perplexity is 113.69853762959288
At time: 416.26193165779114 and batch: 300, loss is 4.777071399688721 and perplexity is 118.75605127108426
At time: 416.62370324134827 and batch: 350, loss is 4.798923931121826 and perplexity is 121.3797342647704
At time: 416.98525071144104 and batch: 400, loss is 4.676714468002319 and perplexity is 107.41657158696785
At time: 417.34853506088257 and batch: 450, loss is 4.714824142456055 and perplexity is 111.58918564799137
At time: 417.7369303703308 and batch: 500, loss is 4.69423134803772 and perplexity is 109.3147513424218
At time: 418.11497807502747 and batch: 550, loss is 4.755563192367553 and perplexity is 116.22909407342895
At time: 418.4829695224762 and batch: 600, loss is 4.653672876358033 and perplexity is 104.96981958929999
At time: 418.8646709918976 and batch: 650, loss is 4.769396619796753 and perplexity is 117.84811328546493
At time: 419.23786187171936 and batch: 700, loss is 4.808873567581177 and perplexity is 122.59344647925728
At time: 419.60283160209656 and batch: 750, loss is 4.74196231842041 and perplexity is 114.65897849175063
At time: 419.96550154685974 and batch: 800, loss is 4.695343627929687 and perplexity is 109.4364075875906
At time: 420.3387978076935 and batch: 850, loss is 4.63858702659607 and perplexity is 103.39814548817883
At time: 420.70106172561646 and batch: 900, loss is 4.601876106262207 and perplexity is 99.67113398023166
At time: 421.0623097419739 and batch: 950, loss is 4.682936897277832 and perplexity is 108.08704743764281
At time: 421.42526388168335 and batch: 1000, loss is 4.741388607025146 and perplexity is 114.5932161953138
At time: 421.78768658638 and batch: 1050, loss is 4.651075086593628 and perplexity is 104.69748395491624
At time: 422.15010237693787 and batch: 1100, loss is 4.767481698989868 and perplexity is 117.62265941333128
At time: 422.512624502182 and batch: 1150, loss is 4.706419477462768 and perplexity is 110.65524614771726
At time: 422.87400698661804 and batch: 1200, loss is 4.668044567108154 and perplexity is 106.48930601554231
At time: 423.2366259098053 and batch: 1250, loss is 4.678061866760254 and perplexity is 107.5614020924159
At time: 423.5983362197876 and batch: 1300, loss is 4.740156888961792 and perplexity is 114.45215655167752
At time: 423.9604103565216 and batch: 1350, loss is 4.663922681808471 and perplexity is 106.0512726922412
At time: 424.3229806423187 and batch: 1400, loss is 4.567352533340454 and perplexity is 96.28885050534
At time: 424.6848075389862 and batch: 1450, loss is 4.644840316772461 and perplexity is 104.04674993796951
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.975949540097489 and perplexity of 144.88633523706332
Finished 37 epochs...
Completing Train Step...
At time: 425.91841101646423 and batch: 50, loss is 4.783344268798828 and perplexity is 119.50333378905975
At time: 426.28136587142944 and batch: 100, loss is 4.772525901794434 and perplexity is 118.21747087545006
At time: 426.6435737609863 and batch: 150, loss is 4.684911861419677 and perplexity is 108.3007264152351
At time: 427.00550961494446 and batch: 200, loss is 4.701147089004516 and perplexity is 110.07336400735669
At time: 427.37006187438965 and batch: 250, loss is 4.726447162628173 and perplexity is 112.89375583993093
At time: 427.7332112789154 and batch: 300, loss is 4.770117149353028 and perplexity is 117.9330569327676
At time: 428.09674859046936 and batch: 350, loss is 4.792373046875 and perplexity is 120.58718844792413
At time: 428.46009063720703 and batch: 400, loss is 4.670169696807862 and perplexity is 106.71585023512236
At time: 428.82310247421265 and batch: 450, loss is 4.70724160194397 and perplexity is 110.74625594011184
At time: 429.18668961524963 and batch: 500, loss is 4.687168970108032 and perplexity is 108.54544900462768
At time: 429.54967427253723 and batch: 550, loss is 4.748867282867431 and perplexity is 115.45343434995739
At time: 429.91353130340576 and batch: 600, loss is 4.6471800613403325 and perplexity is 104.29047777519442
At time: 430.2775390148163 and batch: 650, loss is 4.761968784332275 and perplexity is 116.9759998574431
At time: 430.64064621925354 and batch: 700, loss is 4.801674222946167 and perplexity is 121.71402344123742
At time: 431.00412774086 and batch: 750, loss is 4.7357769870758055 and perplexity is 113.95196353313673
At time: 431.36778807640076 and batch: 800, loss is 4.689122686386108 and perplexity is 108.75772330962062
At time: 431.7312922477722 and batch: 850, loss is 4.631504669189453 and perplexity is 102.66842996989833
At time: 432.0938184261322 and batch: 900, loss is 4.595344686508179 and perplexity is 99.02226130346692
At time: 432.4575300216675 and batch: 950, loss is 4.676140851974488 and perplexity is 107.35497338839684
At time: 432.81981444358826 and batch: 1000, loss is 4.734728946685791 and perplexity is 113.83259983274772
At time: 433.1825170516968 and batch: 1050, loss is 4.645442876815796 and perplexity is 104.10946324448986
At time: 433.5590350627899 and batch: 1100, loss is 4.76186785697937 and perplexity is 116.96419437518209
At time: 433.922292470932 and batch: 1150, loss is 4.6990608215332035 and perplexity is 109.84396090988683
At time: 434.2857937812805 and batch: 1200, loss is 4.66058780670166 and perplexity is 105.69819400678075
At time: 434.64940452575684 and batch: 1250, loss is 4.670918588638306 and perplexity is 106.79579879621792
At time: 435.01256108283997 and batch: 1300, loss is 4.7339741897583005 and perplexity is 113.74671630412085
At time: 435.37540316581726 and batch: 1350, loss is 4.657327070236206 and perplexity is 105.35410135385821
At time: 435.73891711235046 and batch: 1400, loss is 4.561226768493652 and perplexity is 95.70081058575781
At time: 436.10272192955017 and batch: 1450, loss is 4.638672132492065 and perplexity is 103.40694565446258
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.973109057825854 and perplexity of 144.4753721134695
Finished 38 epochs...
Completing Train Step...
At time: 437.32720017433167 and batch: 50, loss is 4.777378377914428 and perplexity is 118.79251238909384
At time: 437.69000363349915 and batch: 100, loss is 4.766065788269043 and perplexity is 117.45623407836818
At time: 438.05238819122314 and batch: 150, loss is 4.6772495460510255 and perplexity is 107.47406321637408
At time: 438.4133412837982 and batch: 200, loss is 4.694973001480102 and perplexity is 109.39585507577202
At time: 438.7736611366272 and batch: 250, loss is 4.719678707122803 and perplexity is 112.13221959607402
At time: 439.1354742050171 and batch: 300, loss is 4.763734626770019 and perplexity is 117.18274352683919
At time: 439.49733567237854 and batch: 350, loss is 4.785513715744019 and perplexity is 119.7628713561868
At time: 439.8589336872101 and batch: 400, loss is 4.664410228729248 and perplexity is 106.10299027003522
At time: 440.2209208011627 and batch: 450, loss is 4.700121755599976 and perplexity is 109.96055995105598
At time: 440.58328676223755 and batch: 500, loss is 4.681959018707276 and perplexity is 107.98140309228803
At time: 440.9454028606415 and batch: 550, loss is 4.742625465393067 and perplexity is 114.7350394632394
At time: 441.30783104896545 and batch: 600, loss is 4.6410853290557865 and perplexity is 103.65678827881524
At time: 441.66952776908875 and batch: 650, loss is 4.755069818496704 and perplexity is 116.17176381916828
At time: 442.0314767360687 and batch: 700, loss is 4.7949790763854985 and perplexity is 120.90185205284399
At time: 442.39330673217773 and batch: 750, loss is 4.7283700466156 and perplexity is 113.11104628051812
At time: 442.7783281803131 and batch: 800, loss is 4.6831458568572994 and perplexity is 108.10963562154775
At time: 443.1519639492035 and batch: 850, loss is 4.624887399673462 and perplexity is 101.99128818375657
At time: 443.51742601394653 and batch: 900, loss is 4.589183073043824 and perplexity is 98.41400026406268
At time: 443.8797082901001 and batch: 950, loss is 4.67040545463562 and perplexity is 106.74101229812133
At time: 444.241902589798 and batch: 1000, loss is 4.729107303619385 and perplexity is 113.19446893978505
At time: 444.60421991348267 and batch: 1050, loss is 4.639824028015137 and perplexity is 103.52612828200577
At time: 444.9654977321625 and batch: 1100, loss is 4.755902938842773 and perplexity is 116.26858920724473
At time: 445.32620787620544 and batch: 1150, loss is 4.692180633544922 and perplexity is 109.0908076982872
At time: 445.68651056289673 and batch: 1200, loss is 4.65382227897644 and perplexity is 104.98550352678187
At time: 446.0465750694275 and batch: 1250, loss is 4.663272829055786 and perplexity is 105.98237736908864
At time: 446.4071283340454 and batch: 1300, loss is 4.727591800689697 and perplexity is 113.0230523144897
At time: 446.76925253868103 and batch: 1350, loss is 4.650514755249024 and perplexity is 104.63883510588381
At time: 447.1295223236084 and batch: 1400, loss is 4.555358428955078 and perplexity is 95.14085036045289
At time: 447.4905915260315 and batch: 1450, loss is 4.6311929988861085 and perplexity is 102.63643625519009
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.966303377069979 and perplexity of 143.49545713029823
Finished 39 epochs...
Completing Train Step...
At time: 448.69525241851807 and batch: 50, loss is 4.769679803848266 and perplexity is 117.88149071740344
At time: 449.0744366645813 and batch: 100, loss is 4.7592191314697265 and perplexity is 116.65479826339966
At time: 449.43631291389465 and batch: 150, loss is 4.669001731872559 and perplexity is 106.5912826234686
At time: 449.7973837852478 and batch: 200, loss is 4.687972297668457 and perplexity is 108.63268158885019
At time: 450.1584734916687 and batch: 250, loss is 4.713989601135254 and perplexity is 111.49609870946452
At time: 450.5189950466156 and batch: 300, loss is 4.757618446350097 and perplexity is 116.46822003002443
At time: 450.87939739227295 and batch: 350, loss is 4.778507785797119 and perplexity is 118.92675338113864
At time: 451.2405083179474 and batch: 400, loss is 4.6581383800506595 and perplexity is 105.43961085293711
At time: 451.60040855407715 and batch: 450, loss is 4.693290586471558 and perplexity is 109.21196058412276
At time: 451.9735074043274 and batch: 500, loss is 4.676138305664063 and perplexity is 107.35470002965698
At time: 452.3348546028137 and batch: 550, loss is 4.735788125991821 and perplexity is 113.95323284155766
At time: 452.69579219818115 and batch: 600, loss is 4.635329809188843 and perplexity is 103.06190315329209
At time: 453.0567772388458 and batch: 650, loss is 4.749012794494629 and perplexity is 115.47023538939882
At time: 453.41794443130493 and batch: 700, loss is 4.7898775005340575 and perplexity is 120.28663271239355
At time: 453.7795011997223 and batch: 750, loss is 4.723331508636474 and perplexity is 112.542565337049
At time: 454.1408221721649 and batch: 800, loss is 4.676783838272095 and perplexity is 107.42402336198005
At time: 454.502393245697 and batch: 850, loss is 4.61949969291687 and perplexity is 101.44326664660004
At time: 454.86391949653625 and batch: 900, loss is 4.583004808425903 and perplexity is 97.80784694424723
At time: 455.22538900375366 and batch: 950, loss is 4.664222888946533 and perplexity is 106.08311482068191
At time: 455.5873529911041 and batch: 1000, loss is 4.724803285598755 and perplexity is 112.70832484257744
At time: 455.94848561286926 and batch: 1050, loss is 4.63536639213562 and perplexity is 103.06567353037529
At time: 456.3093321323395 and batch: 1100, loss is 4.7516280460357665 and perplexity is 115.77261432660285
At time: 456.6863522529602 and batch: 1150, loss is 4.686882858276367 and perplexity is 108.51439730973456
At time: 457.06030678749084 and batch: 1200, loss is 4.647368593215942 and perplexity is 104.31014170815847
At time: 457.4245705604553 and batch: 1250, loss is 4.658421125411987 and perplexity is 105.46942762888487
At time: 457.78565096855164 and batch: 1300, loss is 4.721982831954956 and perplexity is 112.39088411095847
At time: 458.14653301239014 and batch: 1350, loss is 4.645255184173584 and perplexity is 104.08992449795103
At time: 458.507630109787 and batch: 1400, loss is 4.5509498500823975 and perplexity is 94.72233761867648
At time: 458.86880588531494 and batch: 1450, loss is 4.6266216468811034 and perplexity is 102.16831975437634
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.9636699969951925 and perplexity of 143.1180761645119
Finished 40 epochs...
Completing Train Step...
At time: 460.06257605552673 and batch: 50, loss is 4.763097066879272 and perplexity is 117.10805632099206
At time: 460.4396617412567 and batch: 100, loss is 4.753026142120361 and perplexity is 115.93458876692765
At time: 460.80266547203064 and batch: 150, loss is 4.66252182006836 and perplexity is 105.90281353149382
At time: 461.1785719394684 and batch: 200, loss is 4.68217604637146 and perplexity is 108.00484058717684
At time: 461.54112339019775 and batch: 250, loss is 4.707853326797485 and perplexity is 110.81402290255849
At time: 461.90303897857666 and batch: 300, loss is 4.752198848724365 and perplexity is 115.83871650998384
At time: 462.26534390449524 and batch: 350, loss is 4.772459573745728 and perplexity is 118.20963000132176
At time: 462.62704396247864 and batch: 400, loss is 4.6512093925476075 and perplexity is 104.71154639469161
At time: 462.9896342754364 and batch: 450, loss is 4.686856126785278 and perplexity is 108.5114965968602
At time: 463.3524925708771 and batch: 500, loss is 4.671385097503662 and perplexity is 106.84563160595918
At time: 463.71538186073303 and batch: 550, loss is 4.72954496383667 and perplexity is 113.24402049823867
At time: 464.0782389640808 and batch: 600, loss is 4.629157199859619 and perplexity is 102.42770164113277
At time: 464.4411358833313 and batch: 650, loss is 4.743833045959473 and perplexity is 114.87367495709809
At time: 464.8040232658386 and batch: 700, loss is 4.784767780303955 and perplexity is 119.67356929696467
At time: 465.16680908203125 and batch: 750, loss is 4.7169836902618405 and perplexity is 111.83042822268746
At time: 465.52881145477295 and batch: 800, loss is 4.670405492782593 and perplexity is 106.7410163699679
At time: 465.8914985656738 and batch: 850, loss is 4.6138777160644535 and perplexity is 100.87455508920526
At time: 466.254052400589 and batch: 900, loss is 4.578230772018433 and perplexity is 97.34202154045275
At time: 466.61753153800964 and batch: 950, loss is 4.6592636394500735 and perplexity is 105.55832454544274
At time: 466.98053336143494 and batch: 1000, loss is 4.718683538436889 and perplexity is 112.02068462970794
At time: 467.3438241481781 and batch: 1050, loss is 4.629378433227539 and perplexity is 102.45036457334116
At time: 467.70697259902954 and batch: 1100, loss is 4.744457101821899 and perplexity is 114.94538492057777
At time: 468.0719141960144 and batch: 1150, loss is 4.680676364898682 and perplexity is 107.8429891219341
At time: 468.45366048812866 and batch: 1200, loss is 4.641842288970947 and perplexity is 103.73528201703532
At time: 468.82348823547363 and batch: 1250, loss is 4.653403263092041 and perplexity is 104.94152214826417
At time: 469.1864013671875 and batch: 1300, loss is 4.716244707107544 and perplexity is 111.74781794765335
At time: 469.54940366744995 and batch: 1350, loss is 4.639662265777588 and perplexity is 103.50938301826228
At time: 469.9120190143585 and batch: 1400, loss is 4.545424079895019 and perplexity is 94.20036722177228
At time: 470.27482628822327 and batch: 1450, loss is 4.6210270023345945 and perplexity is 101.59832028041092
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.958031809228098 and perplexity of 142.31342011080105
Finished 41 epochs...
Completing Train Step...
At time: 471.48206615448 and batch: 50, loss is 4.757310819625855 and perplexity is 116.43239680339167
At time: 471.84313678741455 and batch: 100, loss is 4.748570232391358 and perplexity is 115.41914394556201
At time: 472.20428133010864 and batch: 150, loss is 4.6566646289825435 and perplexity is 105.28433356196201
At time: 472.5654673576355 and batch: 200, loss is 4.676386270523071 and perplexity is 107.38132352342276
At time: 472.92682099342346 and batch: 250, loss is 4.702498083114624 and perplexity is 110.22217297119353
At time: 473.2877209186554 and batch: 300, loss is 4.7465466785430905 and perplexity is 115.1858232407885
At time: 473.65002703666687 and batch: 350, loss is 4.766269817352295 and perplexity is 117.48020101102188
At time: 474.0115113258362 and batch: 400, loss is 4.64510663986206 and perplexity is 104.07446368011668
At time: 474.37255787849426 and batch: 450, loss is 4.682208328247071 and perplexity is 108.00832724228363
At time: 474.73257541656494 and batch: 500, loss is 4.665772342681885 and perplexity is 106.2476131075304
At time: 475.09317350387573 and batch: 550, loss is 4.723812017440796 and perplexity is 112.59665602503958
At time: 475.4537892341614 and batch: 600, loss is 4.623847341537475 and perplexity is 101.8852664586174
At time: 475.81471037864685 and batch: 650, loss is 4.738819398880005 and perplexity is 114.29918025239671
At time: 476.1746406555176 and batch: 700, loss is 4.779395446777344 and perplexity is 119.03236688717928
At time: 476.53452706336975 and batch: 750, loss is 4.711074724197387 and perplexity is 111.17157450650849
At time: 476.8955190181732 and batch: 800, loss is 4.664890794754029 and perplexity is 106.15399201615826
At time: 477.25662755966187 and batch: 850, loss is 4.60791259765625 and perplexity is 100.27461755189267
At time: 477.61763215065 and batch: 900, loss is 4.572086334228516 and perplexity is 96.74574331796967
At time: 477.97853899002075 and batch: 950, loss is 4.654488000869751 and perplexity is 105.055417944157
At time: 478.3393461704254 and batch: 1000, loss is 4.714140949249267 and perplexity is 111.51297471076728
At time: 478.7003846168518 and batch: 1050, loss is 4.625271816253662 and perplexity is 102.03050286287387
At time: 479.0610845088959 and batch: 1100, loss is 4.742186203002929 and perplexity is 114.68465174309769
At time: 479.42170238494873 and batch: 1150, loss is 4.676778059005738 and perplexity is 107.42340253172986
At time: 479.79655599594116 and batch: 1200, loss is 4.6378945636749265 and perplexity is 103.32657089055081
At time: 480.1835660934448 and batch: 1250, loss is 4.650207662582398 and perplexity is 104.60670622050357
At time: 480.5446951389313 and batch: 1300, loss is 4.712166595458984 and perplexity is 111.29302584636645
At time: 480.90629529953003 and batch: 1350, loss is 4.633851842880249 and perplexity is 102.90969364070473
At time: 481.26806116104126 and batch: 1400, loss is 4.539941749572754 and perplexity is 93.68534274928659
At time: 481.6302840709686 and batch: 1450, loss is 4.616179332733155 and perplexity is 101.10699704016855
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.954132862580129 and perplexity of 141.75962798303135
Finished 42 epochs...
Completing Train Step...
At time: 482.85071444511414 and batch: 50, loss is 4.752178506851196 and perplexity is 115.83636015747092
At time: 483.2120599746704 and batch: 100, loss is 4.743207521438599 and perplexity is 114.80184112586319
At time: 483.57353496551514 and batch: 150, loss is 4.6517538356781 and perplexity is 104.76857139883677
At time: 483.93517684936523 and batch: 200, loss is 4.672651357650757 and perplexity is 106.98101166625135
At time: 484.2973053455353 and batch: 250, loss is 4.697633953094482 and perplexity is 109.68733979431647
At time: 484.65941190719604 and batch: 300, loss is 4.742395477294922 and perplexity is 114.70865480391781
At time: 485.0214283466339 and batch: 350, loss is 4.761491231918335 and perplexity is 116.92015102277239
At time: 485.38378643989563 and batch: 400, loss is 4.639704074859619 and perplexity is 103.51371074101631
At time: 485.74573278427124 and batch: 450, loss is 4.677964448928833 and perplexity is 107.55092420425429
At time: 486.1079566478729 and batch: 500, loss is 4.6594468688964845 and perplexity is 105.5776677108779
At time: 486.46948623657227 and batch: 550, loss is 4.718269033432007 and perplexity is 111.97426111733238
At time: 486.82994174957275 and batch: 600, loss is 4.619174575805664 and perplexity is 101.41029106554986
At time: 487.19208335876465 and batch: 650, loss is 4.733802337646484 and perplexity is 113.72717037026489
At time: 487.5630292892456 and batch: 700, loss is 4.77475754737854 and perplexity is 118.48158496720409
At time: 487.93624114990234 and batch: 750, loss is 4.706527280807495 and perplexity is 110.66717579638
At time: 488.31407928466797 and batch: 800, loss is 4.660816926956176 and perplexity is 105.72241437847643
At time: 488.6873698234558 and batch: 850, loss is 4.603232641220092 and perplexity is 99.80643310601691
At time: 489.060907125473 and batch: 900, loss is 4.567015476226807 and perplexity is 96.25640113226548
At time: 489.42156744003296 and batch: 950, loss is 4.650155725479126 and perplexity is 104.6012733922836
At time: 489.78223180770874 and batch: 1000, loss is 4.708879842758178 and perplexity is 110.92783367002738
At time: 490.1565878391266 and batch: 1050, loss is 4.619951362609863 and perplexity is 101.48909584475336
At time: 490.51951122283936 and batch: 1100, loss is 4.737062139511108 and perplexity is 114.09850331939151
At time: 490.87985348701477 and batch: 1150, loss is 4.671429042816162 and perplexity is 106.85032707380051
At time: 491.240389585495 and batch: 1200, loss is 4.633356399536133 and perplexity is 102.85872034617786
At time: 491.6008024215698 and batch: 1250, loss is 4.6451711750030515 and perplexity is 104.08118035703237
At time: 491.9624397754669 and batch: 1300, loss is 4.706577415466309 and perplexity is 110.67272419656284
At time: 492.32390999794006 and batch: 1350, loss is 4.629024677276611 and perplexity is 102.4141285569297
At time: 492.6849205493927 and batch: 1400, loss is 4.535501852035522 and perplexity is 93.2703114567279
At time: 493.04618072509766 and batch: 1450, loss is 4.61205078125 and perplexity is 100.69043209418726
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.9511410965878735 and perplexity of 141.33615013813167
Finished 43 epochs...
Completing Train Step...
At time: 494.25019121170044 and batch: 50, loss is 4.748270750045776 and perplexity is 115.38458312504432
At time: 494.6245620250702 and batch: 100, loss is 4.738431911468506 and perplexity is 114.25489933860668
At time: 494.9857358932495 and batch: 150, loss is 4.645799694061279 and perplexity is 104.14661792471458
At time: 495.3463361263275 and batch: 200, loss is 4.668017807006836 and perplexity is 106.48645638905236
At time: 495.7077786922455 and batch: 250, loss is 4.692490558624268 and perplexity is 109.12462291534027
At time: 496.06899404525757 and batch: 300, loss is 4.737274551391602 and perplexity is 114.12274177121952
At time: 496.42990732192993 and batch: 350, loss is 4.757463588714599 and perplexity is 116.45018543329347
At time: 496.7915389537811 and batch: 400, loss is 4.634331645965577 and perplexity is 102.95908187659015
At time: 497.1535279750824 and batch: 450, loss is 4.6735694789886475 and perplexity is 107.0792783192639
At time: 497.52841782569885 and batch: 500, loss is 4.654749259948731 and perplexity is 105.08286821155056
At time: 497.90081667900085 and batch: 550, loss is 4.714381103515625 and perplexity is 111.53975824335939
At time: 498.27791571617126 and batch: 600, loss is 4.615550336837768 and perplexity is 101.0434211506183
At time: 498.6384994983673 and batch: 650, loss is 4.729146194458008 and perplexity is 113.19887125321391
At time: 498.9986319541931 and batch: 700, loss is 4.770127677917481 and perplexity is 117.93429860509517
At time: 499.3595521450043 and batch: 750, loss is 4.701078491210938 and perplexity is 110.06581347643183
At time: 499.7204394340515 and batch: 800, loss is 4.655126857757568 and perplexity is 105.1225547646398
At time: 500.08165073394775 and batch: 850, loss is 4.598573188781739 and perplexity is 99.34247152079024
At time: 500.4433698654175 and batch: 900, loss is 4.5622673606872555 and perplexity is 95.80044793410741
At time: 500.8045129776001 and batch: 950, loss is 4.645881290435791 and perplexity is 104.15511625786682
At time: 501.16532254219055 and batch: 1000, loss is 4.705035724639893 and perplexity is 110.50223252942298
At time: 501.5260000228882 and batch: 1050, loss is 4.616029586791992 and perplexity is 101.09185781128598
At time: 501.89894366264343 and batch: 1100, loss is 4.734015960693359 and perplexity is 113.75146771005534
At time: 502.27410531044006 and batch: 1150, loss is 4.6678314113616945 and perplexity is 106.46660962704733
At time: 502.6387138366699 and batch: 1200, loss is 4.629548540115357 and perplexity is 102.46779356836852
At time: 502.99914264678955 and batch: 1250, loss is 4.641010627746582 and perplexity is 103.64904527023295
At time: 503.3603780269623 and batch: 1300, loss is 4.7027538394927975 and perplexity is 110.2503666001436
At time: 503.72149991989136 and batch: 1350, loss is 4.625120668411255 and perplexity is 102.01508233792539
At time: 504.0830636024475 and batch: 1400, loss is 4.532326917648316 and perplexity is 92.97465393255607
At time: 504.44456934928894 and batch: 1450, loss is 4.608712177276612 and perplexity is 100.35482715523551
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.9497581547142095 and perplexity of 141.14082555024928
Finished 44 epochs...
Completing Train Step...
At time: 505.63635182380676 and batch: 50, loss is 4.744895114898681 and perplexity is 114.99574353034842
At time: 506.01088547706604 and batch: 100, loss is 4.733845529556274 and perplexity is 113.73208257003108
At time: 506.37326097488403 and batch: 150, loss is 4.642981281280518 and perplexity is 103.85350301910924
At time: 506.73557925224304 and batch: 200, loss is 4.665275897979736 and perplexity is 106.19488013347303
At time: 507.0974624156952 and batch: 250, loss is 4.688226127624512 and perplexity is 108.66025931752277
At time: 507.47217202186584 and batch: 300, loss is 4.734766359329224 and perplexity is 113.83685869088339
At time: 507.8345127105713 and batch: 350, loss is 4.753677282333374 and perplexity is 116.01010302226902
At time: 508.1972908973694 and batch: 400, loss is 4.6296718788146975 and perplexity is 102.48043259217593
At time: 508.55961322784424 and batch: 450, loss is 4.669223279953003 and perplexity is 106.61490033365847
At time: 508.93757009506226 and batch: 500, loss is 4.650594158172607 and perplexity is 104.64714406518507
At time: 509.31578397750854 and batch: 550, loss is 4.7105075454711915 and perplexity is 111.10853823259734
At time: 509.6780664920807 and batch: 600, loss is 4.6121554183959965 and perplexity is 100.70096860487637
At time: 510.03999280929565 and batch: 650, loss is 4.725488996505737 and perplexity is 112.78563667398336
At time: 510.4025001525879 and batch: 700, loss is 4.765665292739868 and perplexity is 117.40920280028301
At time: 510.764671087265 and batch: 750, loss is 4.6977553558349605 and perplexity is 109.7006569463163
At time: 511.12738394737244 and batch: 800, loss is 4.6510379600524905 and perplexity is 104.69359697162676
At time: 511.49083137512207 and batch: 850, loss is 4.595078239440918 and perplexity is 98.99588062703204
At time: 511.85351181030273 and batch: 900, loss is 4.557238283157349 and perplexity is 95.31986950003264
At time: 512.2165565490723 and batch: 950, loss is 4.642183723449707 and perplexity is 103.77070686626817
At time: 512.5787131786346 and batch: 1000, loss is 4.701987428665161 and perplexity is 110.16590189689637
At time: 512.941029548645 and batch: 1050, loss is 4.612432146072388 and perplexity is 100.72883920603427
At time: 513.3032939434052 and batch: 1100, loss is 4.7309488010406495 and perplexity is 113.40310830790833
At time: 513.6673173904419 and batch: 1150, loss is 4.66408709526062 and perplexity is 106.06871038154537
At time: 514.0295178890228 and batch: 1200, loss is 4.625842056274414 and perplexity is 102.08870133091453
At time: 514.3923237323761 and batch: 1250, loss is 4.638444051742554 and perplexity is 103.38336321024607
At time: 514.75443983078 and batch: 1300, loss is 4.698594732284546 and perplexity is 109.79277575002973
At time: 515.1168003082275 and batch: 1350, loss is 4.62125485420227 and perplexity is 101.6214722849531
At time: 515.478884935379 and batch: 1400, loss is 4.52824275970459 and perplexity is 92.59570513126037
At time: 515.8412418365479 and batch: 1450, loss is 4.6049137210845945 and perplexity is 99.97435679808152
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.946337055956197 and perplexity of 140.65879385640713
Finished 45 epochs...
Completing Train Step...
At time: 517.0455017089844 and batch: 50, loss is 4.741514768600464 and perplexity is 114.60767436800344
At time: 517.4069681167603 and batch: 100, loss is 4.72968620300293 and perplexity is 113.26001611885528
At time: 517.7951638698578 and batch: 150, loss is 4.63948657989502 and perplexity is 103.49119947829503
At time: 518.1685497760773 and batch: 200, loss is 4.661689329147339 and perplexity is 105.8146870880399
At time: 518.5332062244415 and batch: 250, loss is 4.684087400436401 and perplexity is 108.21147348967837
At time: 518.8931930065155 and batch: 300, loss is 4.730193128585816 and perplexity is 113.31744507341728
At time: 519.2547543048859 and batch: 350, loss is 4.750350732803344 and perplexity is 115.6248308373673
At time: 519.6157937049866 and batch: 400, loss is 4.625827026367188 and perplexity is 102.08716695873544
At time: 519.9760963916779 and batch: 450, loss is 4.665470199584961 and perplexity is 106.21551597387315
At time: 520.3365709781647 and batch: 500, loss is 4.646264066696167 and perplexity is 104.19499199502295
At time: 520.6985378265381 and batch: 550, loss is 4.706403713226319 and perplexity is 110.65350176600207
At time: 521.0584924221039 and batch: 600, loss is 4.608638153076172 and perplexity is 100.34739874433959
At time: 521.4174952507019 and batch: 650, loss is 4.7218451499938965 and perplexity is 112.37541097883887
At time: 521.777402639389 and batch: 700, loss is 4.761455135345459 and perplexity is 116.91593068219073
At time: 522.1381731033325 and batch: 750, loss is 4.694610557556152 and perplexity is 109.35621239735242
At time: 522.4984319210052 and batch: 800, loss is 4.647290468215942 and perplexity is 104.30199279665852
At time: 522.8594350814819 and batch: 850, loss is 4.591115961074829 and perplexity is 98.60440746587614
At time: 523.2193534374237 and batch: 900, loss is 4.553420753479004 and perplexity is 94.95667675989581
At time: 523.5800817012787 and batch: 950, loss is 4.638483953475952 and perplexity is 103.38748846794462
At time: 523.940532207489 and batch: 1000, loss is 4.69803261756897 and perplexity is 109.73107695764085
At time: 524.3011617660522 and batch: 1050, loss is 4.6092846393585205 and perplexity is 100.41229293543913
At time: 524.6615424156189 and batch: 1100, loss is 4.727881278991699 and perplexity is 113.05577477175297
At time: 525.0220859050751 and batch: 1150, loss is 4.660895595550537 and perplexity is 105.73073173936125
At time: 525.3826372623444 and batch: 1200, loss is 4.621890850067139 and perplexity is 101.68612367793826
At time: 525.7432882785797 and batch: 1250, loss is 4.63572138786316 and perplexity is 103.1022678991725
At time: 526.1031546592712 and batch: 1300, loss is 4.6949791431427 and perplexity is 109.39652695026673
At time: 526.4631106853485 and batch: 1350, loss is 4.617386407852173 and perplexity is 101.22911446828155
At time: 526.823246717453 and batch: 1400, loss is 4.524783544540405 and perplexity is 92.27595003362681
At time: 527.1838262081146 and batch: 1450, loss is 4.602163934707642 and perplexity is 99.6998262968143
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.9449160323183765 and perplexity of 140.4590563349505
Finished 46 epochs...
Completing Train Step...
At time: 528.385894536972 and batch: 50, loss is 4.739511499404907 and perplexity is 114.37831415619468
At time: 528.7448019981384 and batch: 100, loss is 4.726227941513062 and perplexity is 112.86900985740662
At time: 529.1040027141571 and batch: 150, loss is 4.636340570449829 and perplexity is 103.16612679622014
At time: 529.4642877578735 and batch: 200, loss is 4.656860218048096 and perplexity is 105.30492804034246
At time: 529.8244409561157 and batch: 250, loss is 4.680148077011109 and perplexity is 107.78603202321861
At time: 530.1837072372437 and batch: 300, loss is 4.726627922058105 and perplexity is 112.91416429533422
At time: 530.5445091724396 and batch: 350, loss is 4.747711162567139 and perplexity is 115.3200334193877
At time: 530.9056253433228 and batch: 400, loss is 4.622713565826416 and perplexity is 101.76981687752429
At time: 531.2663097381592 and batch: 450, loss is 4.661399822235108 and perplexity is 105.78405743867391
At time: 531.6259462833405 and batch: 500, loss is 4.642685413360596 and perplexity is 103.82278064430103
At time: 531.986474275589 and batch: 550, loss is 4.703295040130615 and perplexity is 110.31005031784349
At time: 532.3474309444427 and batch: 600, loss is 4.605252752304077 and perplexity is 100.00825697246776
At time: 532.7087936401367 and batch: 650, loss is 4.718017616271973 and perplexity is 111.94611240528823
At time: 533.0700440406799 and batch: 700, loss is 4.757553901672363 and perplexity is 116.46070286889531
At time: 533.4295637607574 and batch: 750, loss is 4.690794773101807 and perplexity is 108.9397277752157
At time: 533.7893211841583 and batch: 800, loss is 4.6436042213439945 and perplexity is 103.91821768145745
At time: 534.149662733078 and batch: 850, loss is 4.5876671504974365 and perplexity is 98.2649252837922
At time: 534.5107908248901 and batch: 900, loss is 4.550259408950805 and perplexity is 94.65695999300208
At time: 534.870715379715 and batch: 950, loss is 4.635082778930664 and perplexity is 103.03644688911093
At time: 535.2423632144928 and batch: 1000, loss is 4.695995712280274 and perplexity is 109.50779262836735
At time: 535.6023662090302 and batch: 1050, loss is 4.607660589218139 and perplexity is 100.24935068600674
At time: 535.9635031223297 and batch: 1100, loss is 4.726297607421875 and perplexity is 112.87687325345733
At time: 536.3244912624359 and batch: 1150, loss is 4.659157104492188 and perplexity is 105.54707949278904
At time: 536.6841335296631 and batch: 1200, loss is 4.619260444641113 and perplexity is 101.41899942302913
At time: 537.0443124771118 and batch: 1250, loss is 4.632456388473511 and perplexity is 102.76618800628997
At time: 537.4036440849304 and batch: 1300, loss is 4.691513748168945 and perplexity is 109.01808088689855
At time: 537.7630839347839 and batch: 1350, loss is 4.614035511016846 and perplexity is 100.89047384073947
At time: 538.1228573322296 and batch: 1400, loss is 4.521502332687378 and perplexity is 91.97366928741586
At time: 538.4827110767365 and batch: 1450, loss is 4.599312210083008 and perplexity is 99.4159148581176
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.94356699886485 and perplexity of 140.26970012175434
Finished 47 epochs...
Completing Train Step...
At time: 539.6709716320038 and batch: 50, loss is 4.736102495193482 and perplexity is 113.98906185986759
At time: 540.0582084655762 and batch: 100, loss is 4.723807153701782 and perplexity is 112.59610838562259
At time: 540.4328045845032 and batch: 150, loss is 4.632642612457276 and perplexity is 102.78532731726091
At time: 540.7959809303284 and batch: 200, loss is 4.653624839782715 and perplexity is 104.96477731976287
At time: 541.1582450866699 and batch: 250, loss is 4.676138381958008 and perplexity is 107.35470822017092
At time: 541.5210390090942 and batch: 300, loss is 4.725031051635742 and perplexity is 112.73399889478989
At time: 541.8833708763123 and batch: 350, loss is 4.74392557144165 and perplexity is 114.88430419099288
At time: 542.2462992668152 and batch: 400, loss is 4.61842562675476 and perplexity is 101.33436835897291
At time: 542.6088440418243 and batch: 450, loss is 4.657582054138183 and perplexity is 105.38096837889465
At time: 542.971339225769 and batch: 500, loss is 4.638734292984009 and perplexity is 103.41337368085745
At time: 543.333801984787 and batch: 550, loss is 4.698771886825561 and perplexity is 109.81222776177977
At time: 543.6964917182922 and batch: 600, loss is 4.602287673950196 and perplexity is 99.71216384110645
At time: 544.0583922863007 and batch: 650, loss is 4.713667917251587 and perplexity is 111.46023797963655
At time: 544.4333171844482 and batch: 700, loss is 4.752981567382813 and perplexity is 115.92942112823452
At time: 544.7960603237152 and batch: 750, loss is 4.687793521881104 and perplexity is 108.61326243155611
At time: 545.1669683456421 and batch: 800, loss is 4.639587678909302 and perplexity is 103.50166286545931
At time: 545.545939207077 and batch: 850, loss is 4.583508777618408 and perplexity is 97.85715150883964
At time: 545.9167025089264 and batch: 900, loss is 4.546403646469116 and perplexity is 94.29268796254406
At time: 546.2787108421326 and batch: 950, loss is 4.632174186706543 and perplexity is 102.73719129810361
At time: 546.639787197113 and batch: 1000, loss is 4.692577610015869 and perplexity is 109.13412277910516
At time: 547.0027544498444 and batch: 1050, loss is 4.603512735366821 and perplexity is 99.83439221914495
At time: 547.3785519599915 and batch: 1100, loss is 4.7233053398132325 and perplexity is 112.53962026908417
At time: 547.75377368927 and batch: 1150, loss is 4.6566040897369385 and perplexity is 105.2779599207638
At time: 548.1157193183899 and batch: 1200, loss is 4.615374393463135 and perplexity is 101.02564479397853
At time: 548.4779131412506 and batch: 1250, loss is 4.62741901397705 and perplexity is 102.24981789844789
At time: 548.8396768569946 and batch: 1300, loss is 4.688028469085693 and perplexity is 108.63878381191681
At time: 549.2026462554932 and batch: 1350, loss is 4.610154151916504 and perplexity is 100.49964065458848
At time: 549.5652470588684 and batch: 1400, loss is 4.516888065338135 and perplexity is 91.55025581098005
At time: 549.9267601966858 and batch: 1450, loss is 4.595135774612427 and perplexity is 99.00157653585856
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.9412210578592415 and perplexity of 139.94102136162346
Finished 48 epochs...
Completing Train Step...
At time: 551.1154885292053 and batch: 50, loss is 4.731923570632935 and perplexity is 113.51370410350968
At time: 551.4895584583282 and batch: 100, loss is 4.721287317276001 and perplexity is 112.31274177899809
At time: 551.8651187419891 and batch: 150, loss is 4.628480587005615 and perplexity is 102.35842118226394
At time: 552.2381875514984 and batch: 200, loss is 4.650703563690185 and perplexity is 104.65859366645793
At time: 552.5987057685852 and batch: 250, loss is 4.67150279045105 and perplexity is 106.85820732328051
At time: 552.9601030349731 and batch: 300, loss is 4.721972036361694 and perplexity is 112.38967079123651
At time: 553.3203301429749 and batch: 350, loss is 4.7406198596954345 and perplexity is 114.50515681840272
At time: 553.6804001331329 and batch: 400, loss is 4.613494129180908 and perplexity is 100.83586835332613
At time: 554.0534245967865 and batch: 450, loss is 4.6542243480682375 and perplexity is 105.02772343992908
At time: 554.4127411842346 and batch: 500, loss is 4.635826416015625 and perplexity is 103.11309710856096
At time: 554.7740094661713 and batch: 550, loss is 4.695243921279907 and perplexity is 109.4254965939844
At time: 555.1355016231537 and batch: 600, loss is 4.59813232421875 and perplexity is 99.29868459825747
At time: 555.4970076084137 and batch: 650, loss is 4.709639949798584 and perplexity is 111.0121827504807
At time: 555.8569192886353 and batch: 700, loss is 4.750443468093872 and perplexity is 115.63555383683975
At time: 556.2158870697021 and batch: 750, loss is 4.6871490383148195 and perplexity is 108.5432855207451
At time: 556.5758407115936 and batch: 800, loss is 4.636746969223022 and perplexity is 103.20806190419626
At time: 556.9361498355865 and batch: 850, loss is 4.580546875 and perplexity is 97.56773697596988
At time: 557.2954964637756 and batch: 900, loss is 4.543986377716064 and perplexity is 94.06503245741324
At time: 557.655739068985 and batch: 950, loss is 4.628657712936401 and perplexity is 102.37655311866024
At time: 558.0293281078339 and batch: 1000, loss is 4.68972900390625 and perplexity is 108.82368501756285
At time: 558.4010672569275 and batch: 1050, loss is 4.601566877365112 and perplexity is 99.64031755030965
At time: 558.7630455493927 and batch: 1100, loss is 4.720772724151612 and perplexity is 112.2549612822955
At time: 559.1242172718048 and batch: 1150, loss is 4.653018865585327 and perplexity is 104.90119064096163
At time: 559.4844977855682 and batch: 1200, loss is 4.61143274307251 and perplexity is 100.62822078950603
At time: 559.8449890613556 and batch: 1250, loss is 4.623167095184326 and perplexity is 101.81598294526957
At time: 560.2055213451385 and batch: 1300, loss is 4.684187870025635 and perplexity is 108.22234599813936
At time: 560.5658373832703 and batch: 1350, loss is 4.607129364013672 and perplexity is 100.19610984688073
At time: 560.9263820648193 and batch: 1400, loss is 4.513242664337159 and perplexity is 91.21712598162578
At time: 561.2865169048309 and batch: 1450, loss is 4.592551078796387 and perplexity is 98.74601798803441
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.940013396434295 and perplexity of 139.77212199550948
Finished 49 epochs...
Completing Train Step...
At time: 562.5014936923981 and batch: 50, loss is 4.728441228866577 and perplexity is 113.11909806597146
At time: 562.8616571426392 and batch: 100, loss is 4.717953996658325 and perplexity is 111.93899066341132
At time: 563.234281539917 and batch: 150, loss is 4.624500598907471 and perplexity is 101.9518455040838
At time: 563.5943474769592 and batch: 200, loss is 4.646690492630005 and perplexity is 104.23943291649292
At time: 563.9553921222687 and batch: 250, loss is 4.668488454818726 and perplexity is 106.53658580247176
At time: 564.3153395652771 and batch: 300, loss is 4.7188624668121335 and perplexity is 112.04073010210091
At time: 564.675529718399 and batch: 350, loss is 4.736550283432007 and perplexity is 114.04011625101383
At time: 565.035562992096 and batch: 400, loss is 4.609627542495727 and perplexity is 100.44673052974292
At time: 565.3953890800476 and batch: 450, loss is 4.65111626625061 and perplexity is 104.70179545016472
At time: 565.7556593418121 and batch: 500, loss is 4.632621698379516 and perplexity is 102.78317767941179
At time: 566.1147186756134 and batch: 550, loss is 4.691372509002686 and perplexity is 109.0026843513694
At time: 566.4742879867554 and batch: 600, loss is 4.594870452880859 and perplexity is 98.97531275047474
At time: 566.8349142074585 and batch: 650, loss is 4.706041240692139 and perplexity is 110.61340017910206
At time: 567.1956629753113 and batch: 700, loss is 4.7480905151367185 and perplexity is 115.36378866919782
At time: 567.5567948818207 and batch: 750, loss is 4.685714244842529 and perplexity is 108.3876599951611
At time: 567.9181914329529 and batch: 800, loss is 4.634303693771362 and perplexity is 102.95620398455928
At time: 568.2795510292053 and batch: 850, loss is 4.579207048416138 and perplexity is 97.43710066278736
At time: 568.6405148506165 and batch: 900, loss is 4.540659160614013 and perplexity is 93.75257776326612
At time: 569.0242195129395 and batch: 950, loss is 4.62559401512146 and perplexity is 102.06338227194694
At time: 569.396143913269 and batch: 1000, loss is 4.688241853713989 and perplexity is 108.66196813191982
At time: 569.7578871250153 and batch: 1050, loss is 4.598089609146118 and perplexity is 99.29444313832037
At time: 570.1203880310059 and batch: 1100, loss is 4.716672582626343 and perplexity is 111.79564233394476
At time: 570.4806518554688 and batch: 1150, loss is 4.649756689071655 and perplexity is 104.55954200265785
At time: 570.8414289951324 and batch: 1200, loss is 4.607758274078369 and perplexity is 100.25914400813852
At time: 571.202162027359 and batch: 1250, loss is 4.619634914398193 and perplexity is 101.45698488286547
At time: 571.5626618862152 and batch: 1300, loss is 4.6805228424072265 and perplexity is 107.82643406837714
At time: 571.927561044693 and batch: 1350, loss is 4.6048320770263675 and perplexity is 99.96619481906697
At time: 572.3188498020172 and batch: 1400, loss is 4.511024789810181 and perplexity is 91.01504202275638
At time: 572.69677567482 and batch: 1450, loss is 4.589340600967407 and perplexity is 98.42950443831397
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.939777080829327 and perplexity of 139.73909556442666
Finished Training.
Improved accuracyfrom -10000000 to -139.73909556442666
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f83117ed8d0>
SETTINGS FOR THIS RUN
{'batch_size': 20, 'seq_len': 35, 'anneal': 2.7017793990391183, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'dropout': 0.40085188316593423, 'lr': 20.161345644570805, 'num_layers': 1, 'wordvec_dim': 200, 'data': 'ptb'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.5870604515075684 and batch: 50, loss is 6.677047672271729 and perplexity is 793.9715840620187
At time: 0.9624366760253906 and batch: 100, loss is 5.970340518951416 and perplexity is 391.63900855110126
At time: 1.325563907623291 and batch: 150, loss is 5.8825689315795895 and perplexity is 358.72961084586024
At time: 1.688561201095581 and batch: 200, loss is 5.864476556777954 and perplexity is 352.2976999925654
At time: 2.051752805709839 and batch: 250, loss is 5.872565336227417 and perplexity is 355.1589146551769
At time: 2.4156365394592285 and batch: 300, loss is 5.995264530181885 and perplexity is 401.5228848653958
At time: 2.777759313583374 and batch: 350, loss is 6.049995737075806 and perplexity is 424.111222086921
At time: 3.140380620956421 and batch: 400, loss is 5.97909854888916 and perplexity is 395.08405861812207
At time: 3.5036044120788574 and batch: 450, loss is 6.019824199676513 and perplexity is 411.50624643609746
At time: 3.867156982421875 and batch: 500, loss is 5.9872056579589845 and perplexity is 398.30006682334863
At time: 4.23043966293335 and batch: 550, loss is 6.075661678314209 and perplexity is 435.1373282155981
At time: 4.593614816665649 and batch: 600, loss is 5.967316160202026 and perplexity is 390.45634099593445
At time: 4.957179546356201 and batch: 650, loss is 6.181054286956787 and perplexity is 483.5014369948076
At time: 5.320885896682739 and batch: 700, loss is 6.136183443069458 and perplexity is 462.28585941866794
At time: 5.684118747711182 and batch: 750, loss is 6.090622510910034 and perplexity is 441.69628633785794
At time: 6.049152374267578 and batch: 800, loss is 6.069159307479858 and perplexity is 432.317083020574
At time: 6.412349700927734 and batch: 850, loss is 6.067844934463501 and perplexity is 431.7492303789869
At time: 6.776024103164673 and batch: 900, loss is 6.062612743377685 and perplexity is 429.49613535636183
At time: 7.1406660079956055 and batch: 950, loss is 6.057751798629761 and perplexity is 427.41344439674134
At time: 7.506972312927246 and batch: 1000, loss is 6.153811740875244 and perplexity is 470.5074254189287
At time: 7.891496419906616 and batch: 1050, loss is 5.99941128730774 and perplexity is 403.19135973857254
At time: 8.263075113296509 and batch: 1100, loss is 6.149090747833252 and perplexity is 468.291398177772
At time: 8.62770962715149 and batch: 1150, loss is 6.190791149139404 and perplexity is 488.2322179573805
At time: 8.991566896438599 and batch: 1200, loss is 6.186723871231079 and perplexity is 486.2504747253399
At time: 9.366964340209961 and batch: 1250, loss is 6.235391073226928 and perplexity is 510.50022238518574
At time: 9.730891466140747 and batch: 1300, loss is 6.3089137840271 and perplexity is 549.4478055748
At time: 10.094630718231201 and batch: 1350, loss is 6.2292611789703365 and perplexity is 507.3804816133566
At time: 10.458116292953491 and batch: 1400, loss is 6.193718214035034 and perplexity is 489.663398901401
At time: 10.82301378250122 and batch: 1450, loss is 6.228980617523193 and perplexity is 507.2381501784733
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 6.193380763388087 and perplexity of 489.4981895472252
Finished 1 epochs...
Completing Train Step...
At time: 12.015816450119019 and batch: 50, loss is 6.211153707504272 and perplexity is 498.2757843131071
At time: 12.387378692626953 and batch: 100, loss is 6.397621402740478 and perplexity is 600.4151921020972
At time: 12.747255325317383 and batch: 150, loss is 6.213742446899414 and perplexity is 499.56736152270616
At time: 13.108792781829834 and batch: 200, loss is 6.231249790191651 and perplexity is 508.39046803489555
At time: 13.469014644622803 and batch: 250, loss is 6.230025968551636 and perplexity is 507.7686693414931
At time: 13.82930850982666 and batch: 300, loss is 6.287447700500488 and perplexity is 537.7790029047272
At time: 14.189573287963867 and batch: 350, loss is 6.362311096191406 and perplexity is 579.5842847907858
At time: 14.549833297729492 and batch: 400, loss is 6.210877456665039 and perplexity is 498.13815422061055
At time: 14.910792827606201 and batch: 450, loss is 6.321612939834595 and perplexity is 556.4698213330363
At time: 15.272457838058472 and batch: 500, loss is 6.301675071716309 and perplexity is 545.4848715545403
At time: 15.631982803344727 and batch: 550, loss is 6.329756956100464 and perplexity is 561.0202247386824
At time: 15.992120265960693 and batch: 600, loss is 6.132214641571045 and perplexity is 460.4547746166741
At time: 16.35272741317749 and batch: 650, loss is 6.347473993301391 and perplexity is 571.0484135138207
At time: 16.71314811706543 and batch: 700, loss is 6.306494874954224 and perplexity is 548.1203474403457
At time: 17.073490381240845 and batch: 750, loss is 6.2396869945526126 and perplexity is 512.698008555536
At time: 17.4351966381073 and batch: 800, loss is 6.226041955947876 and perplexity is 505.74973695950405
At time: 17.797054529190063 and batch: 850, loss is 6.165615615844726 and perplexity is 476.0941438366454
At time: 18.157688856124878 and batch: 900, loss is 6.133525552749634 and perplexity is 461.0587857439246
At time: 18.531173944473267 and batch: 950, loss is 6.197937278747559 and perplexity is 491.7336847326582
At time: 18.89155650138855 and batch: 1000, loss is 6.314435787200928 and perplexity is 552.4902505655041
At time: 19.252768993377686 and batch: 1050, loss is 6.096909971237182 and perplexity is 444.48218314497797
At time: 19.6147677898407 and batch: 1100, loss is 6.272563209533692 and perplexity is 529.8337136748283
At time: 19.976380825042725 and batch: 1150, loss is 6.265617256164551 and perplexity is 526.1662651146327
At time: 20.336957931518555 and batch: 1200, loss is 6.264318113327026 and perplexity is 525.483143812115
At time: 20.697784900665283 and batch: 1250, loss is 6.241667966842652 and perplexity is 513.7146557461346
At time: 21.076255083084106 and batch: 1300, loss is 6.320922012329102 and perplexity is 556.0854738209242
At time: 21.445189952850342 and batch: 1350, loss is 6.236333379745483 and perplexity is 510.98149679085583
At time: 21.80525541305542 and batch: 1400, loss is 6.169505424499512 and perplexity is 477.94966543021354
At time: 22.165648221969604 and batch: 1450, loss is 6.219128255844116 and perplexity is 502.2651943717016
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 6.358847071981837 and perplexity of 577.5800641353514
Annealing...
Finished 2 epochs...
Completing Train Step...
At time: 23.361706495285034 and batch: 50, loss is 6.0827015209198 and perplexity is 438.2114344341287
At time: 23.719650983810425 and batch: 100, loss is 5.968079423904419 and perplexity is 390.75447591169166
At time: 24.079993963241577 and batch: 150, loss is 5.942673540115356 and perplexity is 380.9520598770138
At time: 24.439130544662476 and batch: 200, loss is 5.865993824005127 and perplexity is 352.83263546437956
At time: 24.798433780670166 and batch: 250, loss is 5.855649480819702 and perplexity is 349.2016261772922
At time: 25.156987190246582 and batch: 300, loss is 5.917778358459473 and perplexity is 371.5852669168279
At time: 25.51653790473938 and batch: 350, loss is 5.936444568634033 and perplexity is 378.5864955254004
At time: 25.87493371963501 and batch: 400, loss is 5.8103673458099365 and perplexity is 333.74170177502907
At time: 26.234002113342285 and batch: 450, loss is 5.862150106430054 and perplexity is 351.4790495299167
At time: 26.593913555145264 and batch: 500, loss is 5.863395643234253 and perplexity is 351.91710237084743
At time: 26.954246044158936 and batch: 550, loss is 5.897050561904908 and perplexity is 363.9623986558634
At time: 27.314157962799072 and batch: 600, loss is 5.722735328674316 and perplexity is 305.7400798291611
At time: 27.687143325805664 and batch: 650, loss is 5.9365467357635495 and perplexity is 378.6251765968553
At time: 28.048073530197144 and batch: 700, loss is 5.9107749652862545 and perplexity is 368.9920006263819
At time: 28.408573865890503 and batch: 750, loss is 5.848284854888916 and perplexity is 346.63933357042583
At time: 28.76862359046936 and batch: 800, loss is 5.7995460510253904 and perplexity is 330.14965479032554
At time: 29.129117965698242 and batch: 850, loss is 5.752065181732178 and perplexity is 314.84019156695246
At time: 29.488068342208862 and batch: 900, loss is 5.6970780563354495 and perplexity is 297.9954018448287
At time: 29.84744930267334 and batch: 950, loss is 5.768975067138672 and perplexity is 320.20937129478574
At time: 30.20695400238037 and batch: 1000, loss is 5.809698495864868 and perplexity is 333.51855329087454
At time: 30.567163228988647 and batch: 1050, loss is 5.667073163986206 and perplexity is 289.1868919315741
At time: 30.925812244415283 and batch: 1100, loss is 5.774721212387085 and perplexity is 322.05463735828494
At time: 31.28555417060852 and batch: 1150, loss is 5.741410722732544 and perplexity is 311.50354629350517
At time: 31.646215438842773 and batch: 1200, loss is 5.695842342376709 and perplexity is 297.62739219129037
At time: 32.0065221786499 and batch: 1250, loss is 5.685365390777588 and perplexity is 294.525442272445
At time: 32.36706590652466 and batch: 1300, loss is 5.755682554244995 and perplexity is 315.9811482103025
At time: 32.72564148902893 and batch: 1350, loss is 5.669709739685058 and perplexity is 289.9503610931132
At time: 33.08500123023987 and batch: 1400, loss is 5.576445007324219 and perplexity is 264.1309511698989
At time: 33.44465517997742 and batch: 1450, loss is 5.619611024856567 and perplexity is 275.7820899909223
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.7531493097289 and perplexity of 315.1817037211181
Finished 3 epochs...
Completing Train Step...
At time: 34.65459966659546 and batch: 50, loss is 5.707137527465821 and perplexity is 301.00820618966145
At time: 35.01411819458008 and batch: 100, loss is 5.72574146270752 and perplexity is 306.66055833614837
At time: 35.37378740310669 and batch: 150, loss is 5.650471754074097 and perplexity is 284.42561312093335
At time: 35.732497215270996 and batch: 200, loss is 5.6327801704406735 and perplexity is 279.4379237523329
At time: 36.09292674064636 and batch: 250, loss is 5.624463376998901 and perplexity is 277.12353375280355
At time: 36.45356512069702 and batch: 300, loss is 5.678596239089966 and perplexity is 292.5384874641699
At time: 36.82762360572815 and batch: 350, loss is 5.7045534896850585 and perplexity is 300.2313937012049
At time: 37.187548875808716 and batch: 400, loss is 5.575164785385132 and perplexity is 263.79302129019686
At time: 37.54740023612976 and batch: 450, loss is 5.6230196857452395 and perplexity is 276.723741588605
At time: 37.907790660858154 and batch: 500, loss is 5.603302841186523 and perplexity is 271.32105953614627
At time: 38.26720952987671 and batch: 550, loss is 5.672653350830078 and perplexity is 290.80511962870946
At time: 38.62694001197815 and batch: 600, loss is 5.5028910636901855 and perplexity is 245.40037580912986
At time: 38.986976146698 and batch: 650, loss is 5.686905336380005 and perplexity is 294.979344835
At time: 39.34698271751404 and batch: 700, loss is 5.66787486076355 and perplexity is 289.4188250884955
At time: 39.70668625831604 and batch: 750, loss is 5.612482376098633 and perplexity is 273.82312701296263
At time: 40.06710505485535 and batch: 800, loss is 5.548353853225708 and perplexity is 256.81445347279
At time: 40.42583346366882 and batch: 850, loss is 5.519135913848877 and perplexity is 249.419424178747
At time: 40.784371852874756 and batch: 900, loss is 5.48717432975769 and perplexity is 241.57363410796665
At time: 41.144208669662476 and batch: 950, loss is 5.538753604888916 and perplexity is 254.36076778420107
At time: 41.50555396080017 and batch: 1000, loss is 5.614796371459961 and perplexity is 274.457486127659
At time: 41.86577367782593 and batch: 1050, loss is 5.463780908584595 and perplexity is 235.98798874558807
At time: 42.22627067565918 and batch: 1100, loss is 5.577328767776489 and perplexity is 264.36448283658933
At time: 42.58638620376587 and batch: 1150, loss is 5.554696636199951 and perplexity is 258.4485486930649
At time: 42.947290897369385 and batch: 1200, loss is 5.5280154418945315 and perplexity is 251.64401298356952
At time: 43.307278871536255 and batch: 1250, loss is 5.5274746799468994 and perplexity is 251.50797026367684
At time: 43.66722655296326 and batch: 1300, loss is 5.594039936065673 and perplexity is 268.81944231270097
At time: 44.02515363693237 and batch: 1350, loss is 5.533701295852661 and perplexity is 253.078899502735
At time: 44.38425612449646 and batch: 1400, loss is 5.430139255523682 and perplexity is 228.1810186789024
At time: 44.74362874031067 and batch: 1450, loss is 5.490607538223267 and perplexity is 242.4044320889313
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.636161086905716 and perplexity of 280.3842789021081
Finished 4 epochs...
Completing Train Step...
At time: 45.940633058547974 and batch: 50, loss is 5.573061609268189 and perplexity is 263.23880112360445
At time: 46.302834272384644 and batch: 100, loss is 5.594885520935058 and perplexity is 269.04684809761267
At time: 46.66415739059448 and batch: 150, loss is 5.5301358509063725 and perplexity is 252.178167329184
At time: 47.024524211883545 and batch: 200, loss is 5.512575159072876 and perplexity is 247.78840072321108
At time: 47.38617300987244 and batch: 250, loss is 5.514282999038696 and perplexity is 248.21194522720182
At time: 47.74859404563904 and batch: 300, loss is 5.552667264938354 and perplexity is 257.9245924664196
At time: 48.110440254211426 and batch: 350, loss is 5.584627370834351 and perplexity is 266.3010327172543
At time: 48.47088003158569 and batch: 400, loss is 5.4680359745025635 and perplexity is 236.994272577288
At time: 48.831610679626465 and batch: 450, loss is 5.513804950714111 and perplexity is 248.093316280088
At time: 49.19381523132324 and batch: 500, loss is 5.48725040435791 and perplexity is 241.59201242465784
At time: 49.55549597740173 and batch: 550, loss is 5.547380056381225 and perplexity is 256.56449009490785
At time: 49.92677450180054 and batch: 600, loss is 5.3991969776153566 and perplexity is 221.2286932631717
At time: 50.300777435302734 and batch: 650, loss is 5.580048866271973 and perplexity is 265.0845591638966
At time: 50.66498565673828 and batch: 700, loss is 5.555518760681152 and perplexity is 258.6611129372383
At time: 51.026976108551025 and batch: 750, loss is 5.508800621032715 and perplexity is 246.8548768977027
At time: 51.389530658721924 and batch: 800, loss is 5.43705397605896 and perplexity is 229.7642943002758
At time: 51.75198745727539 and batch: 850, loss is 5.416211137771606 and perplexity is 225.02491688218396
At time: 52.11405611038208 and batch: 900, loss is 5.38137882232666 and perplexity is 217.3217169745927
At time: 52.47582221031189 and batch: 950, loss is 5.434868783950805 and perplexity is 229.26276334794494
At time: 52.837815284729004 and batch: 1000, loss is 5.499100303649902 and perplexity is 244.47188282954377
At time: 53.198896169662476 and batch: 1050, loss is 5.363794183731079 and perplexity is 213.53359709502226
At time: 53.56084895133972 and batch: 1100, loss is 5.470966863632202 and perplexity is 237.6898954133192
At time: 53.922765493392944 and batch: 1150, loss is 5.4559217548370365 and perplexity is 234.14059185644737
At time: 54.284534215927124 and batch: 1200, loss is 5.432472505569458 and perplexity is 228.71404364963078
At time: 54.64597272872925 and batch: 1250, loss is 5.429330291748047 and perplexity is 227.99650314375836
At time: 55.007126331329346 and batch: 1300, loss is 5.499046401977539 and perplexity is 244.4587057413503
At time: 55.36901140213013 and batch: 1350, loss is 5.443385534286499 and perplexity is 231.22367551142526
At time: 55.73165154457092 and batch: 1400, loss is 5.336113166809082 and perplexity is 207.70382917733824
At time: 56.09452486038208 and batch: 1450, loss is 5.403352184295654 and perplexity is 222.14985669413284
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.579141730936165 and perplexity of 264.84420062864467
Finished 5 epochs...
Completing Train Step...
At time: 57.283419370651245 and batch: 50, loss is 5.504216585159302 and perplexity is 245.7258749561892
At time: 57.65557146072388 and batch: 100, loss is 5.512587080001831 and perplexity is 247.7913546087385
At time: 58.01546788215637 and batch: 150, loss is 5.450011596679688 and perplexity is 232.76086514520787
At time: 58.375747203826904 and batch: 200, loss is 5.448212823867798 and perplexity is 232.3425575622554
At time: 58.73524713516235 and batch: 250, loss is 5.44454626083374 and perplexity is 231.49221879244942
At time: 59.09442734718323 and batch: 300, loss is 5.490701980590821 and perplexity is 242.42732641848366
At time: 59.454275369644165 and batch: 350, loss is 5.52138427734375 and perplexity is 249.98084060457828
At time: 59.81441783905029 and batch: 400, loss is 5.415495328903198 and perplexity is 224.86389968671028
At time: 60.173115253448486 and batch: 450, loss is 5.456486253738404 and perplexity is 234.27280127584098
At time: 60.53536891937256 and batch: 500, loss is 5.441524715423584 and perplexity is 230.79381020925175
At time: 60.8973925113678 and batch: 550, loss is 5.501597118377686 and perplexity is 245.08304649083314
At time: 61.25747752189636 and batch: 600, loss is 5.344348039627075 and perplexity is 209.42130568913444
At time: 61.61827206611633 and batch: 650, loss is 5.514553546905518 and perplexity is 248.27910752440116
At time: 61.97926449775696 and batch: 700, loss is 5.488776483535767 and perplexity is 241.96098243146946
At time: 62.34024214744568 and batch: 750, loss is 5.443622512817383 and perplexity is 231.2784770514913
At time: 62.70189189910889 and batch: 800, loss is 5.379902696609497 and perplexity is 217.00115944907856
At time: 63.06240940093994 and batch: 850, loss is 5.352750024795532 and perplexity is 211.18827301546088
At time: 63.42306852340698 and batch: 900, loss is 5.311799192428589 and perplexity is 202.71462309678893
At time: 63.78333640098572 and batch: 950, loss is 5.3712865829467775 and perplexity is 215.13948451289698
At time: 64.14415621757507 and batch: 1000, loss is 5.438162813186645 and perplexity is 230.01920678250644
At time: 64.52152919769287 and batch: 1050, loss is 5.302455930709839 and perplexity is 200.82942796894397
At time: 64.88138222694397 and batch: 1100, loss is 5.410974493026734 and perplexity is 223.84962132217535
At time: 65.24194812774658 and batch: 1150, loss is 5.390723114013672 and perplexity is 219.36195191776332
At time: 65.6028938293457 and batch: 1200, loss is 5.366692714691162 and perplexity is 214.15342870381556
At time: 65.96397829055786 and batch: 1250, loss is 5.361317873001099 and perplexity is 213.00547572350916
At time: 66.32509183883667 and batch: 1300, loss is 5.4408636474609375 and perplexity is 230.64129023393446
At time: 66.68570256233215 and batch: 1350, loss is 5.390897274017334 and perplexity is 219.40015932311704
At time: 67.04570436477661 and batch: 1400, loss is 5.273657960891724 and perplexity is 195.12843072886142
At time: 67.40702152252197 and batch: 1450, loss is 5.3378190994262695 and perplexity is 208.05846031665624
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.507603832799146 and perplexity of 246.55962060050487
Finished 6 epochs...
Completing Train Step...
At time: 68.60426211357117 and batch: 50, loss is 5.437264461517334 and perplexity is 229.81266143319007
At time: 68.99183344841003 and batch: 100, loss is 5.443615207672119 and perplexity is 231.27678753479114
At time: 69.35577368736267 and batch: 150, loss is 5.382622556686401 and perplexity is 217.59217561560058
At time: 69.7162127494812 and batch: 200, loss is 5.379823207855225 and perplexity is 216.983910982777
At time: 70.07606625556946 and batch: 250, loss is 5.384210243225097 and perplexity is 217.93791817652846
At time: 70.43493676185608 and batch: 300, loss is 5.425115232467651 and perplexity is 227.0375069001441
At time: 70.79409694671631 and batch: 350, loss is 5.452345533370972 and perplexity is 233.30474871668727
At time: 71.15254950523376 and batch: 400, loss is 5.341340293884278 and perplexity is 208.79236596802482
At time: 71.51221680641174 and batch: 450, loss is 5.388124446868897 and perplexity is 218.79264326273127
At time: 71.87296843528748 and batch: 500, loss is 5.36517110824585 and perplexity is 213.8278192539562
At time: 72.23256540298462 and batch: 550, loss is 5.412324705123901 and perplexity is 224.1520699277652
At time: 72.59174609184265 and batch: 600, loss is 5.279961004257202 and perplexity is 196.36221791195058
At time: 72.9511137008667 and batch: 650, loss is 5.452659654617309 and perplexity is 233.37804620667742
At time: 73.31028199195862 and batch: 700, loss is 5.427752923965454 and perplexity is 227.6371522938902
At time: 73.68323850631714 and batch: 750, loss is 5.386908102035522 and perplexity is 218.5266777471998
At time: 74.04362964630127 and batch: 800, loss is 5.308182573318481 and perplexity is 201.98280566712612
At time: 74.4045763015747 and batch: 850, loss is 5.296710109710693 and perplexity is 199.67880682164144
At time: 74.7636878490448 and batch: 900, loss is 5.252701320648193 and perplexity is 191.08174497468633
At time: 75.12322735786438 and batch: 950, loss is 5.322992067337037 and perplexity is 204.99632811360397
At time: 75.4833459854126 and batch: 1000, loss is 5.370071382522583 and perplexity is 214.8782057052676
At time: 75.84389805793762 and batch: 1050, loss is 5.2481826877594 and perplexity is 190.2202645401195
At time: 76.2038905620575 and batch: 1100, loss is 5.356105527877808 and perplexity is 211.89810617415608
At time: 76.56419396400452 and batch: 1150, loss is 5.340312166213989 and perplexity is 208.57781107303984
At time: 76.92233443260193 and batch: 1200, loss is 5.3118711280822755 and perplexity is 202.72920603022328
At time: 77.28121185302734 and batch: 1250, loss is 5.315604600906372 and perplexity is 203.4875046744628
At time: 77.64071559906006 and batch: 1300, loss is 5.396967525482178 and perplexity is 220.73602387652926
At time: 77.99988293647766 and batch: 1350, loss is 5.340347929000854 and perplexity is 208.58527053022675
At time: 78.35923099517822 and batch: 1400, loss is 5.228292074203491 and perplexity is 186.4740475556856
At time: 78.71849370002747 and batch: 1450, loss is 5.298003015518188 and perplexity is 199.93713967465192
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.484359349959936 and perplexity of 240.89456543899286
Finished 7 epochs...
Completing Train Step...
At time: 79.91249012947083 and batch: 50, loss is 5.401561756134033 and perplexity is 221.75246918765538
At time: 80.27227973937988 and batch: 100, loss is 5.404808006286621 and perplexity is 222.473502869246
At time: 80.6326117515564 and batch: 150, loss is 5.337960929870605 and perplexity is 208.08797143326868
At time: 81.00865077972412 and batch: 200, loss is 5.337255659103394 and perplexity is 207.94126481003593
At time: 81.37753367424011 and batch: 250, loss is 5.347462158203125 and perplexity is 210.07448497841762
At time: 81.73729515075684 and batch: 300, loss is 5.381125364303589 and perplexity is 217.26664202172714
At time: 82.0966284275055 and batch: 350, loss is 5.41003984451294 and perplexity is 223.64049834975458
At time: 82.45575618743896 and batch: 400, loss is 5.301811637878418 and perplexity is 200.70007668269312
At time: 82.82698798179626 and batch: 450, loss is 5.342696599960327 and perplexity is 209.07574445315944
At time: 83.18666458129883 and batch: 500, loss is 5.334885301589966 and perplexity is 207.44895337820068
At time: 83.54566502571106 and batch: 550, loss is 5.401421222686768 and perplexity is 221.72130773838512
At time: 83.90597200393677 and batch: 600, loss is 5.248642187118531 and perplexity is 190.30769071436671
At time: 84.26647138595581 and batch: 650, loss is 5.42737774848938 and perplexity is 227.55176443562286
At time: 84.62667989730835 and batch: 700, loss is 5.409672002792359 and perplexity is 223.5582491723169
At time: 84.98713660240173 and batch: 750, loss is 5.363208074569702 and perplexity is 213.40847976729083
At time: 85.34829139709473 and batch: 800, loss is 5.28166277885437 and perplexity is 196.69666664369998
At time: 85.70893096923828 and batch: 850, loss is 5.266720161437989 and perplexity is 193.77935403179015
At time: 86.06910109519958 and batch: 900, loss is 5.222665910720825 and perplexity is 185.42785985003817
At time: 86.42919135093689 and batch: 950, loss is 5.28907548904419 and perplexity is 198.1601394775581
At time: 86.78875494003296 and batch: 1000, loss is 5.3437392520904545 and perplexity is 209.29385140855328
At time: 87.14598536491394 and batch: 1050, loss is 5.22092713356018 and perplexity is 185.10572226628142
At time: 87.50545024871826 and batch: 1100, loss is 5.335016832351685 and perplexity is 207.47624109160378
At time: 87.86595010757446 and batch: 1150, loss is 5.310774621963501 and perplexity is 202.50703404408813
At time: 88.22697353363037 and batch: 1200, loss is 5.273457670211792 and perplexity is 195.08935223645636
At time: 88.58632254600525 and batch: 1250, loss is 5.2722835350036625 and perplexity is 194.86042538110453
At time: 88.94710922241211 and batch: 1300, loss is 5.361412687301636 and perplexity is 213.02567264616388
At time: 89.30777955055237 and batch: 1350, loss is 5.299429607391358 and perplexity is 200.22257192251064
At time: 89.66700625419617 and batch: 1400, loss is 5.184559783935547 and perplexity is 178.49485618889545
At time: 90.02538251876831 and batch: 1450, loss is 5.254793510437012 and perplexity is 191.48194274921997
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.461449256310096 and perplexity of 235.43838780301564
Finished 8 epochs...
Completing Train Step...
At time: 91.22123289108276 and batch: 50, loss is 5.358470344543457 and perplexity is 212.3997993194079
At time: 91.58278107643127 and batch: 100, loss is 5.362748718261718 and perplexity is 213.31047174795694
At time: 91.95687317848206 and batch: 150, loss is 5.288793611526489 and perplexity is 198.10429046099586
At time: 92.31860017776489 and batch: 200, loss is 5.290539875030517 and perplexity is 198.45053498251744
At time: 92.67988801002502 and batch: 250, loss is 5.2983823490142825 and perplexity is 200.0129969155304
At time: 93.04197430610657 and batch: 300, loss is 5.33779577255249 and perplexity is 208.05360701982008
At time: 93.40386581420898 and batch: 350, loss is 5.363470916748047 and perplexity is 213.46457988940634
At time: 93.76599168777466 and batch: 400, loss is 5.255908870697022 and perplexity is 191.6956332474637
At time: 94.12718772888184 and batch: 450, loss is 5.289939241409302 and perplexity is 198.33137470847456
At time: 94.48935437202454 and batch: 500, loss is 5.285105171203614 and perplexity is 197.37494051667247
At time: 94.85058903694153 and batch: 550, loss is 5.348132123947144 and perplexity is 210.2152748439728
At time: 95.21321725845337 and batch: 600, loss is 5.203701620101929 and perplexity is 181.9444862787063
At time: 95.57409262657166 and batch: 650, loss is 5.365542211532593 and perplexity is 213.90718618623228
At time: 95.93692779541016 and batch: 700, loss is 5.353912782669068 and perplexity is 211.43397666194997
At time: 96.30018353462219 and batch: 750, loss is 5.310111036300659 and perplexity is 202.3726978563856
At time: 96.69408178329468 and batch: 800, loss is 5.232301301956177 and perplexity is 187.22316517043006
At time: 97.07645773887634 and batch: 850, loss is 5.212065210342407 and perplexity is 183.47257666192613
At time: 97.44669127464294 and batch: 900, loss is 5.174563827514649 and perplexity is 176.71951727279983
At time: 97.82852959632874 and batch: 950, loss is 5.244417762756347 and perplexity is 189.5054459735711
At time: 98.20018529891968 and batch: 1000, loss is 5.292059888839722 and perplexity is 198.7524119065591
At time: 98.56316304206848 and batch: 1050, loss is 5.165176010131836 and perplexity is 175.0682696494084
At time: 98.92639565467834 and batch: 1100, loss is 5.280848350524902 and perplexity is 196.53653652217824
At time: 99.2897515296936 and batch: 1150, loss is 5.26065920829773 and perplexity is 192.60841852461252
At time: 99.6533453464508 and batch: 1200, loss is 5.220494546890259 and perplexity is 185.02566531533617
At time: 100.01655673980713 and batch: 1250, loss is 5.225815677642823 and perplexity is 186.01283517374318
At time: 100.38068652153015 and batch: 1300, loss is 5.311509370803833 and perplexity is 202.65588052820567
At time: 100.74358820915222 and batch: 1350, loss is 5.249831829071045 and perplexity is 190.53422344683105
At time: 101.10729265213013 and batch: 1400, loss is 5.136278915405273 and perplexity is 170.08170094654838
At time: 101.47107887268066 and batch: 1450, loss is 5.209029359817505 and perplexity is 182.9164259660944
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.414794921875 and perplexity of 224.70645857384903
Finished 9 epochs...
Completing Train Step...
At time: 102.67158818244934 and batch: 50, loss is 5.312155532836914 and perplexity is 202.7868713800835
At time: 103.0468225479126 and batch: 100, loss is 5.317853288650513 and perplexity is 203.94559939526883
At time: 103.40909767150879 and batch: 150, loss is 5.248754959106446 and perplexity is 190.32915330113062
At time: 103.7712516784668 and batch: 200, loss is 5.248720359802246 and perplexity is 190.32256815877886
At time: 104.1454975605011 and batch: 250, loss is 5.260397853851319 and perplexity is 192.55808603561132
At time: 104.51912546157837 and batch: 300, loss is 5.294002456665039 and perplexity is 199.13887719311913
At time: 104.88407707214355 and batch: 350, loss is 5.323593807220459 and perplexity is 205.11971970128164
At time: 105.24545550346375 and batch: 400, loss is 5.218397579193115 and perplexity is 184.6380789920542
At time: 105.60668516159058 and batch: 450, loss is 5.251061067581177 and perplexity is 190.7685794619996
At time: 105.96918630599976 and batch: 500, loss is 5.2494265079498295 and perplexity is 190.45701155061687
At time: 106.33039665222168 and batch: 550, loss is 5.307339553833008 and perplexity is 201.81260197881107
At time: 106.69223737716675 and batch: 600, loss is 5.170553750991822 and perplexity is 176.01227747605444
At time: 107.055006980896 and batch: 650, loss is 5.336280317306518 and perplexity is 207.73854987741493
At time: 107.41665267944336 and batch: 700, loss is 5.323772010803222 and perplexity is 205.15627602736518
At time: 107.77794408798218 and batch: 750, loss is 5.282256813049316 and perplexity is 196.81354590141913
At time: 108.14014291763306 and batch: 800, loss is 5.204870700836182 and perplexity is 182.15731845707728
At time: 108.5020170211792 and batch: 850, loss is 5.184662218093872 and perplexity is 178.51314109573812
At time: 108.86410546302795 and batch: 900, loss is 5.144001684188843 and perplexity is 171.4002876137543
At time: 109.23964309692383 and batch: 950, loss is 5.210549030303955 and perplexity is 183.1946099806039
At time: 109.60968470573425 and batch: 1000, loss is 5.264367332458496 and perplexity is 193.32396029386956
At time: 109.9712746143341 and batch: 1050, loss is 5.138470449447632 and perplexity is 170.4548495187072
At time: 110.33257412910461 and batch: 1100, loss is 5.258955678939819 and perplexity is 192.28058374644144
At time: 110.70729303359985 and batch: 1150, loss is 5.233855218887329 and perplexity is 187.51432057376093
At time: 111.06858134269714 and batch: 1200, loss is 5.194074048995971 and perplexity is 180.20120803272565
At time: 111.43152022361755 and batch: 1250, loss is 5.195707588195801 and perplexity is 180.49581432985934
At time: 111.79271697998047 and batch: 1300, loss is 5.279053373336792 and perplexity is 196.18407434790637
At time: 112.15418672561646 and batch: 1350, loss is 5.221589546203614 and perplexity is 185.22837925736826
At time: 112.51675486564636 and batch: 1400, loss is 5.105360412597657 and perplexity is 164.90349311899115
At time: 112.8799090385437 and batch: 1450, loss is 5.17827262878418 and perplexity is 177.37615175353162
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.405386117788462 and perplexity of 222.60215454403289
Finished 10 epochs...
Completing Train Step...
At time: 114.07991933822632 and batch: 50, loss is 5.283837699890137 and perplexity is 197.12493191440373
At time: 114.45508980751038 and batch: 100, loss is 5.2915348720550535 and perplexity is 198.64809094183983
At time: 114.81712651252747 and batch: 150, loss is 5.212134733200073 and perplexity is 183.48533264316993
At time: 115.17894744873047 and batch: 200, loss is 5.223727560043335 and perplexity is 185.62482374661622
At time: 115.54016470909119 and batch: 250, loss is 5.232981367111206 and perplexity is 187.35053242538388
At time: 115.90134739875793 and batch: 300, loss is 5.261839075088501 and perplexity is 192.83580491770115
At time: 116.26314806938171 and batch: 350, loss is 5.298399124145508 and perplexity is 200.01635218794294
At time: 116.6252818107605 and batch: 400, loss is 5.194073047637939 and perplexity is 180.20102758688896
At time: 116.98681735992432 and batch: 450, loss is 5.2260722827911374 and perplexity is 186.06057314954464
At time: 117.34955763816833 and batch: 500, loss is 5.2232788467407225 and perplexity is 185.54155010329904
At time: 117.71007323265076 and batch: 550, loss is 5.284571418762207 and perplexity is 197.2696192705357
At time: 118.0716016292572 and batch: 600, loss is 5.1496936798095705 and perplexity is 172.37867915887932
At time: 118.43419480323792 and batch: 650, loss is 5.310309753417969 and perplexity is 202.4129167714869
At time: 118.8220763206482 and batch: 700, loss is 5.299537582397461 and perplexity is 200.24419212313563
At time: 119.20589852333069 and batch: 750, loss is 5.257897939682007 and perplexity is 192.07730854952788
At time: 119.58182120323181 and batch: 800, loss is 5.182236442565918 and perplexity is 178.08063308241398
At time: 119.97213244438171 and batch: 850, loss is 5.161860876083374 and perplexity is 174.4888558158042
At time: 120.337562084198 and batch: 900, loss is 5.127515554428101 and perplexity is 168.5977254091977
At time: 120.69961309432983 and batch: 950, loss is 5.193968563079834 and perplexity is 180.18220034574657
At time: 121.06156945228577 and batch: 1000, loss is 5.241598920822144 and perplexity is 188.9720122615753
At time: 121.42356562614441 and batch: 1050, loss is 5.11782431602478 and perplexity is 166.97169650127842
At time: 121.78526759147644 and batch: 1100, loss is 5.233931293487549 and perplexity is 187.5285861933529
At time: 122.14802098274231 and batch: 1150, loss is 5.213341503143311 and perplexity is 183.70689088565473
At time: 122.50989198684692 and batch: 1200, loss is 5.17827956199646 and perplexity is 177.3773815443083
At time: 122.8719048500061 and batch: 1250, loss is 5.1797409343719485 and perplexity is 177.63678544641652
At time: 123.2334349155426 and batch: 1300, loss is 5.259392385482788 and perplexity is 192.36457227328415
At time: 123.59473204612732 and batch: 1350, loss is 5.2025645732879635 and perplexity is 181.73772445147947
At time: 123.95657467842102 and batch: 1400, loss is 5.087118644714355 and perplexity is 161.92263261638328
At time: 124.3191168308258 and batch: 1450, loss is 5.158096370697021 and perplexity is 173.83322641270766
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.383540748530983 and perplexity of 217.79205872817445
Finished 11 epochs...
Completing Train Step...
At time: 125.53493618965149 and batch: 50, loss is 5.264368715286255 and perplexity is 193.32422762779316
At time: 125.89838647842407 and batch: 100, loss is 5.268937940597534 and perplexity is 194.20959075338465
At time: 126.26260685920715 and batch: 150, loss is 5.196497535705566 and perplexity is 180.63845287997856
At time: 126.62598133087158 and batch: 200, loss is 5.208014850616455 and perplexity is 182.730949668542
At time: 126.98958086967468 and batch: 250, loss is 5.213840103149414 and perplexity is 183.79850998131423
At time: 127.35298037528992 and batch: 300, loss is 5.244876899719238 and perplexity is 189.59247490605773
At time: 127.71608543395996 and batch: 350, loss is 5.280072212219238 and perplexity is 196.384056168297
At time: 128.07811188697815 and batch: 400, loss is 5.17013256072998 and perplexity is 175.9381584290232
At time: 128.43879556655884 and batch: 450, loss is 5.206851921081543 and perplexity is 182.51856996547986
At time: 128.81504440307617 and batch: 500, loss is 5.2019651508331295 and perplexity is 181.62881942187377
At time: 129.21646785736084 and batch: 550, loss is 5.26592360496521 and perplexity is 193.62505929343996
At time: 129.60405158996582 and batch: 600, loss is 5.132749137878418 and perplexity is 169.48240868722385
At time: 129.97950100898743 and batch: 650, loss is 5.295730857849121 and perplexity is 199.48336668652087
At time: 130.34914779663086 and batch: 700, loss is 5.284847517013549 and perplexity is 197.324092587107
At time: 130.710839509964 and batch: 750, loss is 5.246212072372437 and perplexity is 189.84578266096744
At time: 131.07312536239624 and batch: 800, loss is 5.168843994140625 and perplexity is 175.71159639775945
At time: 131.43557929992676 and batch: 850, loss is 5.143062486648559 and perplexity is 171.23938445697573
At time: 131.79666471481323 and batch: 900, loss is 5.10648886680603 and perplexity is 165.08968419406978
At time: 132.15865540504456 and batch: 950, loss is 5.178874807357788 and perplexity is 177.4829960380274
At time: 132.5215311050415 and batch: 1000, loss is 5.224849233627319 and perplexity is 185.83315102370406
At time: 132.88395190238953 and batch: 1050, loss is 5.104522323608398 and perplexity is 164.76534721448465
At time: 133.24690055847168 and batch: 1100, loss is 5.220131196975708 and perplexity is 184.9584484680115
At time: 133.60938382148743 and batch: 1150, loss is 5.198303852081299 and perplexity is 180.96503794468003
At time: 133.9912805557251 and batch: 1200, loss is 5.1578278064727785 and perplexity is 173.78654729555956
At time: 134.3631627559662 and batch: 1250, loss is 5.161229295730591 and perplexity is 174.37868687662223
At time: 134.72530388832092 and batch: 1300, loss is 5.243276119232178 and perplexity is 189.2892217573533
At time: 135.08811235427856 and batch: 1350, loss is 5.185031976699829 and perplexity is 178.57916007072453
At time: 135.4512448310852 and batch: 1400, loss is 5.071651554107666 and perplexity is 159.43742956142657
At time: 135.81391620635986 and batch: 1450, loss is 5.142757987976074 and perplexity is 171.18725022953572
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.377289600861379 and perplexity of 216.4348548682716
Finished 12 epochs...
Completing Train Step...
At time: 137.0178689956665 and batch: 50, loss is 5.2494713497161865 and perplexity is 190.4655521709167
At time: 137.3779399394989 and batch: 100, loss is 5.252720136642456 and perplexity is 191.08534040152907
At time: 137.73830151557922 and batch: 150, loss is 5.177451963424683 and perplexity is 177.23064500452725
At time: 138.09800672531128 and batch: 200, loss is 5.193563089370728 and perplexity is 180.10915601043698
At time: 138.47187280654907 and batch: 250, loss is 5.20028094291687 and perplexity is 181.32317618201253
At time: 138.83286833763123 and batch: 300, loss is 5.230700941085815 and perplexity is 186.92378016878453
At time: 139.19409012794495 and batch: 350, loss is 5.264278259277344 and perplexity is 193.30674108062956
At time: 139.55436301231384 and batch: 400, loss is 5.156654615402221 and perplexity is 173.58278202126107
At time: 139.91594648361206 and batch: 450, loss is 5.197767210006714 and perplexity is 180.86795054421205
At time: 140.27676033973694 and batch: 500, loss is 5.1855597400665285 and perplexity is 178.67343248404077
At time: 140.6367633342743 and batch: 550, loss is 5.251357173919677 and perplexity is 190.82507561158621
At time: 141.0006458759308 and batch: 600, loss is 5.1237281227111815 and perplexity is 167.9603807481475
At time: 141.3605809211731 and batch: 650, loss is 5.277453689575196 and perplexity is 195.87049275245226
At time: 141.7213978767395 and batch: 700, loss is 5.26934250831604 and perplexity is 194.28817758020236
At time: 142.0818841457367 and batch: 750, loss is 5.23014123916626 and perplexity is 186.81918784320666
At time: 142.44228601455688 and batch: 800, loss is 5.155081386566162 and perplexity is 173.30991128347918
At time: 142.80261659622192 and batch: 850, loss is 5.130988254547119 and perplexity is 169.1842325425661
At time: 143.16310715675354 and batch: 900, loss is 5.093227033615112 and perplexity is 162.91474605074015
At time: 143.52248740196228 and batch: 950, loss is 5.162883529663086 and perplexity is 174.66738874193263
At time: 143.88298773765564 and batch: 1000, loss is 5.206350526809692 and perplexity is 182.42707913839783
At time: 144.24345660209656 and batch: 1050, loss is 5.094154367446899 and perplexity is 163.0658924772159
At time: 144.6043152809143 and batch: 1100, loss is 5.210111608505249 and perplexity is 183.11449418826737
At time: 144.96517395973206 and batch: 1150, loss is 5.1802221870422365 and perplexity is 177.72229419776107
At time: 145.32627940177917 and batch: 1200, loss is 5.143110179901123 and perplexity is 171.2475516149452
At time: 145.68723964691162 and batch: 1250, loss is 5.142517013549805 and perplexity is 171.14600345003615
At time: 146.04774165153503 and batch: 1300, loss is 5.226507511138916 and perplexity is 186.1415696100825
At time: 146.4079282283783 and batch: 1350, loss is 5.165903491973877 and perplexity is 175.195674973607
At time: 146.76888394355774 and batch: 1400, loss is 5.049266967773438 and perplexity is 155.90813689988082
At time: 147.1302559375763 and batch: 1450, loss is 5.120442180633545 and perplexity is 167.4093784422855
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.369009164663462 and perplexity of 214.65007941898898
Finished 13 epochs...
Completing Train Step...
At time: 148.33338475227356 and batch: 50, loss is 5.231155757904053 and perplexity is 187.00881558403645
At time: 148.71896958351135 and batch: 100, loss is 5.234879846572876 and perplexity is 187.70655140375462
At time: 149.08056902885437 and batch: 150, loss is 5.161475057601929 and perplexity is 174.42154777560214
At time: 149.44206142425537 and batch: 200, loss is 5.175338773727417 and perplexity is 176.8565184708562
At time: 149.80391192436218 and batch: 250, loss is 5.185652513504028 and perplexity is 178.69000940149905
At time: 150.16507387161255 and batch: 300, loss is 5.2110492134094235 and perplexity is 183.28626374945156
At time: 150.52558040618896 and batch: 350, loss is 5.247560567855835 and perplexity is 190.10196153063185
At time: 150.88565063476562 and batch: 400, loss is 5.145261907577515 and perplexity is 171.61642642801948
At time: 151.24576902389526 and batch: 450, loss is 5.176050224304199 and perplexity is 176.9823879125642
At time: 151.60698103904724 and batch: 500, loss is 5.167091693878174 and perplexity is 175.40396652994124
At time: 151.96629428863525 and batch: 550, loss is 5.237748985290527 and perplexity is 188.24588087349747
At time: 152.32695627212524 and batch: 600, loss is 5.107363119125366 and perplexity is 165.23407734220032
At time: 152.687979221344 and batch: 650, loss is 5.263088998794555 and perplexity is 193.07698565900697
At time: 153.04832935333252 and batch: 700, loss is 5.249071836471558 and perplexity is 190.38947385833754
At time: 153.40825176239014 and batch: 750, loss is 5.2131510257720945 and perplexity is 183.67190221238556
At time: 153.76881074905396 and batch: 800, loss is 5.139364528656006 and perplexity is 170.607317804834
At time: 154.12915539741516 and batch: 850, loss is 5.1146440601348875 and perplexity is 166.44152726380034
At time: 154.4884066581726 and batch: 900, loss is 5.0762294578552245 and perplexity is 160.1689920013098
At time: 154.84869647026062 and batch: 950, loss is 5.146808767318726 and perplexity is 171.88209839465182
At time: 155.2084197998047 and batch: 1000, loss is 5.19671257019043 and perplexity is 180.6773005532852
At time: 155.5663342475891 and batch: 1050, loss is 5.078678598403931 and perplexity is 160.56174913665603
At time: 155.9250795841217 and batch: 1100, loss is 5.192015008926392 and perplexity is 179.83054825741988
At time: 156.3010699748993 and batch: 1150, loss is 5.164570007324219 and perplexity is 174.96220992596713
At time: 156.68157815933228 and batch: 1200, loss is 5.110581407546997 and perplexity is 165.7667048749617
At time: 157.06954431533813 and batch: 1250, loss is 5.113146362304687 and perplexity is 166.1924347287983
At time: 157.43574690818787 and batch: 1300, loss is 5.192030391693115 and perplexity is 179.8333145700702
At time: 157.79599618911743 and batch: 1350, loss is 5.130539131164551 and perplexity is 169.10826500844433
At time: 158.1555061340332 and batch: 1400, loss is 5.016905117034912 and perplexity is 150.94342791322003
At time: 158.54194235801697 and batch: 1450, loss is 5.089266338348389 and perplexity is 162.27076653234047
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.3412126068376065 and perplexity of 208.76570758944794
Finished 14 epochs...
Completing Train Step...
At time: 159.77963638305664 and batch: 50, loss is 5.199139728546142 and perplexity is 181.11636559765836
At time: 160.16408848762512 and batch: 100, loss is 5.196494970321655 and perplexity is 180.6379894735923
At time: 160.52383542060852 and batch: 150, loss is 5.122560720443726 and perplexity is 167.76441782485523
At time: 160.88482332229614 and batch: 200, loss is 5.132075424194336 and perplexity is 169.36826452384
At time: 161.24489998817444 and batch: 250, loss is 5.147345247268677 and perplexity is 171.97433443337658
At time: 161.60448718070984 and batch: 300, loss is 5.174767112731933 and perplexity is 176.75544538997087
At time: 161.9641444683075 and batch: 350, loss is 5.21144585609436 and perplexity is 183.35897732491776
At time: 162.32471323013306 and batch: 400, loss is 5.102832365036011 and perplexity is 164.48713575266294
At time: 162.68511486053467 and batch: 450, loss is 5.139336318969726 and perplexity is 170.6025050938046
At time: 163.04527068138123 and batch: 500, loss is 5.132479953765869 and perplexity is 169.43679285525286
At time: 163.40575909614563 and batch: 550, loss is 5.197743406295777 and perplexity is 180.86364526704043
At time: 163.76525378227234 and batch: 600, loss is 5.070677804946899 and perplexity is 159.2822530619508
At time: 164.12605905532837 and batch: 650, loss is 5.222164802551269 and perplexity is 185.33496371205482
At time: 164.4869556427002 and batch: 700, loss is 5.21345440864563 and perplexity is 183.7276335754095
At time: 164.8476231098175 and batch: 750, loss is 5.173162527084351 and perplexity is 176.47205356319898
At time: 165.20811915397644 and batch: 800, loss is 5.099242506027221 and perplexity is 163.8977087394876
At time: 165.5682270526886 and batch: 850, loss is 5.076015043258667 and perplexity is 160.13465311301977
At time: 165.9281690120697 and batch: 900, loss is 5.036709680557251 and perplexity is 153.962594577599
At time: 166.3015923500061 and batch: 950, loss is 5.106419696807861 and perplexity is 165.07826533584208
At time: 166.66263270378113 and batch: 1000, loss is 5.1538394260406495 and perplexity is 173.09480082198593
At time: 167.0230860710144 and batch: 1050, loss is 5.038321390151977 and perplexity is 154.21093764320133
At time: 167.38350462913513 and batch: 1100, loss is 5.150522260665894 and perplexity is 172.52156802178186
At time: 167.74417543411255 and batch: 1150, loss is 5.130450887680054 and perplexity is 169.09334296427897
At time: 168.1038737297058 and batch: 1200, loss is 5.089209060668946 and perplexity is 162.2614723055705
At time: 168.46498584747314 and batch: 1250, loss is 5.08618314743042 and perplexity is 161.77122526498812
At time: 168.8240203857422 and batch: 1300, loss is 5.174685878753662 and perplexity is 176.74108742514593
At time: 169.19359183311462 and batch: 1350, loss is 5.117931079864502 and perplexity is 166.98952399237055
At time: 169.56782984733582 and batch: 1400, loss is 4.997864303588867 and perplexity is 148.09653188147615
At time: 169.93041825294495 and batch: 1450, loss is 5.0713445091247555 and perplexity is 159.3884826134336
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.322913536658654 and perplexity of 204.98023024498787
Finished 15 epochs...
Completing Train Step...
At time: 171.12954306602478 and batch: 50, loss is 5.1815046787261965 and perplexity is 177.95036778210064
At time: 171.49128556251526 and batch: 100, loss is 5.173489589691162 and perplexity is 176.52978041269898
At time: 171.8533821105957 and batch: 150, loss is 5.101331691741944 and perplexity is 164.2404794223948
At time: 172.21509861946106 and batch: 200, loss is 5.110153293609619 and perplexity is 165.69575302707267
At time: 172.5776445865631 and batch: 250, loss is 5.128919296264648 and perplexity is 168.83455927781628
At time: 172.93936777114868 and batch: 300, loss is 5.155819721221924 and perplexity is 173.43791924770971
At time: 173.30155658721924 and batch: 350, loss is 5.1896817111969 and perplexity is 179.4114391907399
At time: 173.66332912445068 and batch: 400, loss is 5.08751838684082 and perplexity is 161.98737285270593
At time: 174.02498841285706 and batch: 450, loss is 5.1234290981292725 and perplexity is 167.91016397391616
At time: 174.38811254501343 and batch: 500, loss is 5.11649528503418 and perplexity is 166.74993333977432
At time: 174.75072693824768 and batch: 550, loss is 5.181734008789062 and perplexity is 177.99118183089644
At time: 175.11342430114746 and batch: 600, loss is 5.054748687744141 and perplexity is 156.76512839522218
At time: 175.48870587348938 and batch: 650, loss is 5.206441287994385 and perplexity is 182.4436371876231
At time: 175.85139393806458 and batch: 700, loss is 5.19746353149414 and perplexity is 180.81303317305336
At time: 176.35626339912415 and batch: 750, loss is 5.161553707122803 and perplexity is 174.4352664862427
At time: 176.71965432167053 and batch: 800, loss is 5.091538181304932 and perplexity is 162.63983930929388
At time: 177.0825731754303 and batch: 850, loss is 5.060994539260864 and perplexity is 157.7473242418811
At time: 177.44430661201477 and batch: 900, loss is 5.023338642120361 and perplexity is 151.91765674570465
At time: 177.80648183822632 and batch: 950, loss is 5.093313751220703 and perplexity is 162.9288742400056
At time: 178.16819286346436 and batch: 1000, loss is 5.142350559234619 and perplexity is 171.11751783007807
At time: 178.5299723148346 and batch: 1050, loss is 5.0292528629302975 and perplexity is 152.81879344667925
At time: 178.89233684539795 and batch: 1100, loss is 5.141076307296753 and perplexity is 170.89960986568838
At time: 179.25509309768677 and batch: 1150, loss is 5.117492017745971 and perplexity is 166.91622131158672
At time: 179.61712193489075 and batch: 1200, loss is 5.069180603027344 and perplexity is 159.04395380248428
At time: 179.98077535629272 and batch: 1250, loss is 5.0783061504364015 and perplexity is 160.501959374506
At time: 180.34336066246033 and batch: 1300, loss is 5.163631019592285 and perplexity is 174.79799966507008
At time: 180.70565962791443 and batch: 1350, loss is 5.100996961593628 and perplexity is 164.18551238243424
At time: 181.06833958625793 and batch: 1400, loss is 4.9887699508667 and perplexity is 146.75579558869836
At time: 181.43173718452454 and batch: 1450, loss is 5.06118088722229 and perplexity is 157.77672287327633
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.323498326489049 and perplexity of 205.1001356553823
Annealing...
Finished 16 epochs...
Completing Train Step...
At time: 182.63328504562378 and batch: 50, loss is 5.1257611274719235 and perplexity is 168.3021923363889
At time: 182.99492764472961 and batch: 100, loss is 5.06933913230896 and perplexity is 159.0691689248407
At time: 183.35690593719482 and batch: 150, loss is 4.991121654510498 and perplexity is 147.10132786344013
At time: 183.71789050102234 and batch: 200, loss is 4.994322109222412 and perplexity is 147.57287317854266
At time: 184.07930779457092 and batch: 250, loss is 5.001432771682739 and perplexity is 148.62595368090504
At time: 184.4405882358551 and batch: 300, loss is 5.026393127441406 and perplexity is 152.38239640714858
At time: 184.8144805431366 and batch: 350, loss is 5.0534586906433105 and perplexity is 156.56303221385068
At time: 185.1751606464386 and batch: 400, loss is 4.953251132965088 and perplexity is 141.63468940993593
At time: 185.53635239601135 and batch: 450, loss is 4.986864671707154 and perplexity is 146.47645102900836
At time: 185.89773321151733 and batch: 500, loss is 4.983715763092041 and perplexity is 146.015935511617
At time: 186.25910019874573 and batch: 550, loss is 5.030317230224609 and perplexity is 152.98153536560415
At time: 186.6210126876831 and batch: 600, loss is 4.923252334594727 and perplexity is 137.44891689599567
At time: 186.98297834396362 and batch: 650, loss is 5.055998001098633 and perplexity is 156.96109955284814
At time: 187.3447597026825 and batch: 700, loss is 5.0630356979370115 and perplexity is 158.06964039870013
At time: 187.7060956954956 and batch: 750, loss is 5.009383850097656 and perplexity is 149.81240080963394
At time: 188.06712412834167 and batch: 800, loss is 4.948704919815063 and perplexity is 140.9922493636326
At time: 188.42860984802246 and batch: 850, loss is 4.902559471130371 and perplexity is 134.6339307336051
At time: 188.78934907913208 and batch: 900, loss is 4.871948442459106 and perplexity is 130.57508724198448
At time: 189.1504397392273 and batch: 950, loss is 4.941693601608276 and perplexity is 140.00716524320947
At time: 189.51230263710022 and batch: 1000, loss is 4.987145652770996 and perplexity is 146.51761392077213
At time: 189.87418031692505 and batch: 1050, loss is 4.8786281490325925 and perplexity is 131.45021003843132
At time: 190.23473358154297 and batch: 1100, loss is 4.9889091205596925 and perplexity is 146.77622096897935
At time: 190.59549927711487 and batch: 1150, loss is 4.959058580398559 and perplexity is 142.45961847102703
At time: 190.9566297531128 and batch: 1200, loss is 4.913242349624634 and perplexity is 136.07991856118304
At time: 191.31838607788086 and batch: 1250, loss is 4.916935300827026 and perplexity is 136.58338412475038
At time: 191.67956376075745 and batch: 1300, loss is 4.996004734039307 and perplexity is 147.82139198057084
At time: 192.03951501846313 and batch: 1350, loss is 4.922257566452027 and perplexity is 137.31225507690053
At time: 192.39964771270752 and batch: 1400, loss is 4.807908515930176 and perplexity is 122.47519454012273
At time: 192.76028847694397 and batch: 1450, loss is 4.881968765258789 and perplexity is 131.8900690340132
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.179633246527778 and perplexity of 177.61765715390715
Finished 17 epochs...
Completing Train Step...
At time: 193.94636344909668 and batch: 50, loss is 5.0313956165313725 and perplexity is 153.14659754292978
At time: 194.3193817138672 and batch: 100, loss is 5.022466249465943 and perplexity is 151.78518269098115
At time: 194.6796112060547 and batch: 150, loss is 4.955673503875732 and perplexity is 141.97819704498028
At time: 195.04037880897522 and batch: 200, loss is 4.962331104278564 and perplexity is 142.92658463662957
At time: 195.40071058273315 and batch: 250, loss is 4.97060037612915 and perplexity is 144.11338363860193
At time: 195.7608253955841 and batch: 300, loss is 5.000073432922363 and perplexity is 148.4240579147276
At time: 196.12212085723877 and batch: 350, loss is 5.032769632339478 and perplexity is 153.35716801936465
At time: 196.48341536521912 and batch: 400, loss is 4.932692012786865 and perplexity is 138.75253362037668
At time: 196.84463381767273 and batch: 450, loss is 4.96695294380188 and perplexity is 143.5886972850019
At time: 197.2060992717743 and batch: 500, loss is 4.961098394393921 and perplexity is 142.75050617209854
At time: 197.56732654571533 and batch: 550, loss is 5.009724006652832 and perplexity is 149.8633691479318
At time: 197.92901730537415 and batch: 600, loss is 4.903340425491333 and perplexity is 134.73911475555934
At time: 198.2898895740509 and batch: 650, loss is 5.036803541183471 and perplexity is 153.97704628135295
At time: 198.6509494781494 and batch: 700, loss is 5.0471892929077145 and perplexity is 155.58454675644043
At time: 199.01110410690308 and batch: 750, loss is 4.994563455581665 and perplexity is 147.6084936524718
At time: 199.3723692893982 and batch: 800, loss is 4.935970010757447 and perplexity is 139.20811042597813
At time: 199.73329901695251 and batch: 850, loss is 4.887909259796142 and perplexity is 132.67589304933432
At time: 200.09409093856812 and batch: 900, loss is 4.861895132064819 and perplexity is 129.26895185322314
At time: 200.4558219909668 and batch: 950, loss is 4.931840696334839 and perplexity is 138.63446157121527
At time: 200.81763529777527 and batch: 1000, loss is 4.978629751205444 and perplexity is 145.27518206517612
At time: 201.20011568069458 and batch: 1050, loss is 4.867614078521728 and perplexity is 130.0103520607508
At time: 201.56154584884644 and batch: 1100, loss is 4.978076105117798 and perplexity is 145.19477329004943
At time: 201.92298483848572 and batch: 1150, loss is 4.949975643157959 and perplexity is 141.17152538705656
At time: 202.28354573249817 and batch: 1200, loss is 4.908682804107666 and perplexity is 135.46086834485348
At time: 202.64492845535278 and batch: 1250, loss is 4.916211433410645 and perplexity is 136.4845516384872
At time: 203.0056290626526 and batch: 1300, loss is 4.988044090270996 and perplexity is 146.6493099910145
At time: 203.36636757850647 and batch: 1350, loss is 4.918637018203736 and perplexity is 136.81600831706353
At time: 203.72742819786072 and batch: 1400, loss is 4.8017287445068355 and perplexity is 121.7206596606576
At time: 204.0881814956665 and batch: 1450, loss is 4.880069913864136 and perplexity is 131.63986701589073
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.1752747103699255 and perplexity of 176.84518881140056
Finished 18 epochs...
Completing Train Step...
At time: 205.2781286239624 and batch: 50, loss is 5.019039554595947 and perplexity is 151.26595131593535
At time: 205.65364170074463 and batch: 100, loss is 5.0086096572875975 and perplexity is 149.69646201135245
At time: 206.01636934280396 and batch: 150, loss is 4.944547080993653 and perplexity is 140.4072433388708
At time: 206.37890601158142 and batch: 200, loss is 4.950121440887451 and perplexity is 141.19210937543986
At time: 206.74126148223877 and batch: 250, loss is 4.956618690490723 and perplexity is 142.1124563765139
At time: 207.10400557518005 and batch: 300, loss is 4.988761491775513 and perplexity is 146.75455417329195
At time: 207.46724915504456 and batch: 350, loss is 5.02139009475708 and perplexity is 151.62192621226254
At time: 207.82888412475586 and batch: 400, loss is 4.921320552825928 and perplexity is 137.1836518837447
At time: 208.19180178642273 and batch: 450, loss is 4.956387825012207 and perplexity is 142.07965130319468
At time: 208.55356359481812 and batch: 500, loss is 4.9515321159362795 and perplexity is 141.3914261137486
At time: 208.91591620445251 and batch: 550, loss is 4.999290342330933 and perplexity is 148.3078739286631
At time: 209.2785677909851 and batch: 600, loss is 4.89263768196106 and perplexity is 133.30472620547647
At time: 209.64221239089966 and batch: 650, loss is 5.029610452651977 and perplexity is 152.8734496481608
At time: 210.00461983680725 and batch: 700, loss is 5.039572992324829 and perplexity is 154.4040692245747
At time: 210.38349151611328 and batch: 750, loss is 4.989114589691162 and perplexity is 146.80638205010175
At time: 210.74611830711365 and batch: 800, loss is 4.926347160339356 and perplexity is 137.87495626132636
At time: 211.10854768753052 and batch: 850, loss is 4.879433450698852 and perplexity is 131.55610974648803
At time: 211.47129678726196 and batch: 900, loss is 4.854419937133789 and perplexity is 128.30624393714604
At time: 211.8344690799713 and batch: 950, loss is 4.92518759727478 and perplexity is 137.71517421110102
At time: 212.19792079925537 and batch: 1000, loss is 4.972424402236938 and perplexity is 144.3764900964167
At time: 212.56153297424316 and batch: 1050, loss is 4.862822742462158 and perplexity is 129.38891870966472
At time: 212.9245719909668 and batch: 1100, loss is 4.974759187698364 and perplexity is 144.71397204713406
At time: 213.28824758529663 and batch: 1150, loss is 4.944527730941773 and perplexity is 140.40452647771366
At time: 213.65114283561707 and batch: 1200, loss is 4.904201955795288 and perplexity is 134.85524660441976
At time: 214.0143711566925 and batch: 1250, loss is 4.913751335144043 and perplexity is 136.14919889906176
At time: 214.37656450271606 and batch: 1300, loss is 4.9830022716522215 and perplexity is 145.91179154888317
At time: 214.73869395256042 and batch: 1350, loss is 4.913980264663696 and perplexity is 136.1803710377421
At time: 215.10056710243225 and batch: 1400, loss is 4.799122123718262 and perplexity is 121.40379321353305
At time: 215.46257972717285 and batch: 1450, loss is 4.877671089172363 and perplexity is 131.32446450138607
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.173408703926282 and perplexity of 176.51550224384434
Finished 19 epochs...
Completing Train Step...
At time: 216.6633439064026 and batch: 50, loss is 5.011771326065063 and perplexity is 150.1705016246323
At time: 217.0240843296051 and batch: 100, loss is 5.001445846557617 and perplexity is 148.62789695935706
At time: 217.38538932800293 and batch: 150, loss is 4.936793298721313 and perplexity is 139.3227659785565
At time: 217.74599933624268 and batch: 200, loss is 4.943897533416748 and perplexity is 140.31607176752232
At time: 218.10733723640442 and batch: 250, loss is 4.947301826477051 and perplexity is 140.7945627966233
At time: 218.4686415195465 and batch: 300, loss is 4.9819371795654295 and perplexity is 145.75646478767075
At time: 218.85061240196228 and batch: 350, loss is 5.015178842544556 and perplexity is 150.68308290225494
At time: 219.2263367176056 and batch: 400, loss is 4.915299491882324 and perplexity is 136.36014244345154
At time: 219.61955547332764 and batch: 450, loss is 4.94918586730957 and perplexity is 141.06007554181667
At time: 219.99424767494202 and batch: 500, loss is 4.945441179275512 and perplexity is 140.53283735222973
At time: 220.3598403930664 and batch: 550, loss is 4.991192560195923 and perplexity is 147.11175855371252
At time: 220.7206473350525 and batch: 600, loss is 4.887028312683105 and perplexity is 132.5590640720136
At time: 221.08134722709656 and batch: 650, loss is 5.022171440124512 and perplexity is 151.74044159660343
At time: 221.44180536270142 and batch: 700, loss is 5.034698715209961 and perplexity is 153.65329223750294
At time: 221.80327224731445 and batch: 750, loss is 4.9826117038726805 and perplexity is 145.85481423192545
At time: 222.16389083862305 and batch: 800, loss is 4.920897636413574 and perplexity is 137.12564693234398
At time: 222.525084733963 and batch: 850, loss is 4.873336143493653 and perplexity is 130.75641220895994
At time: 222.8851432800293 and batch: 900, loss is 4.84867491722107 and perplexity is 127.57123535187438
At time: 223.24656009674072 and batch: 950, loss is 4.9209615421295165 and perplexity is 137.1344103249977
At time: 223.60818362236023 and batch: 1000, loss is 4.968440799713135 and perplexity is 143.80249558814063
At time: 223.9696044921875 and batch: 1050, loss is 4.858578414916992 and perplexity is 128.84091353733126
At time: 224.33124470710754 and batch: 1100, loss is 4.969722213745118 and perplexity is 143.98688423769195
At time: 224.6923427581787 and batch: 1150, loss is 4.938971214294433 and perplexity is 139.62652986625147
At time: 225.05383801460266 and batch: 1200, loss is 4.900953788757324 and perplexity is 134.4179248690258
At time: 225.41565680503845 and batch: 1250, loss is 4.909350852966309 and perplexity is 135.55139305744078
At time: 225.77719044685364 and batch: 1300, loss is 4.978967742919922 and perplexity is 145.32429217197048
At time: 226.13787198066711 and batch: 1350, loss is 4.909882583618164 and perplexity is 135.62348905415806
At time: 226.49950003623962 and batch: 1400, loss is 4.79549165725708 and perplexity is 120.96383991508408
At time: 226.860582113266 and batch: 1450, loss is 4.872849063873291 and perplexity is 130.69273893357763
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.168629703358707 and perplexity of 175.67394705647288
Finished 20 epochs...
Completing Train Step...
At time: 228.062509059906 and batch: 50, loss is 5.004314708709717 and perplexity is 149.05490212430058
At time: 228.4232964515686 and batch: 100, loss is 4.996157932281494 and perplexity is 147.84403969273046
At time: 228.79648518562317 and batch: 150, loss is 4.929655208587646 and perplexity is 138.33180849687042
At time: 229.15671610832214 and batch: 200, loss is 4.937738075256347 and perplexity is 139.4544570581744
At time: 229.52507662773132 and batch: 250, loss is 4.941613483428955 and perplexity is 139.99594857337385
At time: 229.88597106933594 and batch: 300, loss is 4.975309162139893 and perplexity is 144.79358292305895
At time: 230.24712419509888 and batch: 350, loss is 5.007574052810669 and perplexity is 149.54151593038864
At time: 230.60877442359924 and batch: 400, loss is 4.910120468139649 and perplexity is 135.65575562066002
At time: 230.97062349319458 and batch: 450, loss is 4.942931299209595 and perplexity is 140.18055905821777
At time: 231.33125400543213 and batch: 500, loss is 4.940146274566651 and perplexity is 139.79069588804043
At time: 231.69230604171753 and batch: 550, loss is 4.986245737075806 and perplexity is 146.38581973110735
At time: 232.0540680885315 and batch: 600, loss is 4.8809219455719 and perplexity is 131.752076152677
At time: 232.4154441356659 and batch: 650, loss is 5.016931047439575 and perplexity is 150.94734198813367
At time: 232.77652263641357 and batch: 700, loss is 5.028666667938232 and perplexity is 152.7292380862837
At time: 233.1377100944519 and batch: 750, loss is 4.977624158859253 and perplexity is 145.12916788167692
At time: 233.49957823753357 and batch: 800, loss is 4.914829788208007 and perplexity is 136.29610862315306
At time: 233.86074018478394 and batch: 850, loss is 4.866339492797851 and perplexity is 129.84474828258323
At time: 234.22252225875854 and batch: 900, loss is 4.844124393463135 and perplexity is 126.99203823915296
At time: 234.58448004722595 and batch: 950, loss is 4.916083812713623 and perplexity is 136.46713449629195
At time: 234.94534730911255 and batch: 1000, loss is 4.96311544418335 and perplexity is 143.03873163534863
At time: 235.30725765228271 and batch: 1050, loss is 4.855015268325806 and perplexity is 128.38265138790499
At time: 235.66926431655884 and batch: 1100, loss is 4.964554386138916 and perplexity is 143.24470422332922
At time: 236.03097796440125 and batch: 1150, loss is 4.93489405632019 and perplexity is 139.0584093920512
At time: 236.39236426353455 and batch: 1200, loss is 4.896600074768067 and perplexity is 133.83397975650047
At time: 236.75335550308228 and batch: 1250, loss is 4.906334915161133 and perplexity is 135.1431943469466
At time: 237.11389899253845 and batch: 1300, loss is 4.976197853088379 and perplexity is 144.92231686347276
At time: 237.4736716747284 and batch: 1350, loss is 4.904280576705933 and perplexity is 134.86584946351078
At time: 237.8351182937622 and batch: 1400, loss is 4.793067989349365 and perplexity is 120.67101873227963
At time: 238.19597935676575 and batch: 1450, loss is 4.869378337860107 and perplexity is 130.23992649333016
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.1681988055889425 and perplexity of 175.59826585108274
Finished 21 epochs...
Completing Train Step...
At time: 239.38529801368713 and batch: 50, loss is 4.999644861221314 and perplexity is 148.36046119260152
At time: 239.76125073432922 and batch: 100, loss is 4.992071161270141 and perplexity is 147.24106790015503
At time: 240.12209749221802 and batch: 150, loss is 4.923339929580688 and perplexity is 137.46095725927165
At time: 240.48222851753235 and batch: 200, loss is 4.931834936141968 and perplexity is 138.63366301227794
At time: 240.84351205825806 and batch: 250, loss is 4.935273265838623 and perplexity is 139.11115166406452
At time: 241.20507669448853 and batch: 300, loss is 4.970097017288208 and perplexity is 144.04086114679933
At time: 241.56611442565918 and batch: 350, loss is 5.002633457183838 and perplexity is 148.80451388444865
At time: 241.92795705795288 and batch: 400, loss is 4.906401634216309 and perplexity is 135.1522112739839
At time: 242.28898882865906 and batch: 450, loss is 4.937392845153808 and perplexity is 139.40632149106614
At time: 242.6505515575409 and batch: 500, loss is 4.9351066207885745 and perplexity is 139.08797141072407
At time: 243.01180863380432 and batch: 550, loss is 4.9801270866394045 and perplexity is 145.49287067872294
At time: 243.3732831478119 and batch: 600, loss is 4.8762691211700435 and perplexity is 131.14048080399692
At time: 243.73324823379517 and batch: 650, loss is 5.011715030670166 and perplexity is 150.16204795489492
At time: 244.09368681907654 and batch: 700, loss is 5.0254374122619625 and perplexity is 152.23683180805048
At time: 244.45482635498047 and batch: 750, loss is 4.972144536972046 and perplexity is 144.33608978535716
At time: 244.81635236740112 and batch: 800, loss is 4.9110189723968505 and perplexity is 135.77769766912016
At time: 245.17750239372253 and batch: 850, loss is 4.861783428192139 and perplexity is 129.25451281714692
At time: 245.53871989250183 and batch: 900, loss is 4.840690250396729 and perplexity is 126.55667738513736
At time: 245.89894104003906 and batch: 950, loss is 4.91320686340332 and perplexity is 136.07508968475645
At time: 246.26134777069092 and batch: 1000, loss is 4.96005841255188 and perplexity is 142.6021254077613
At time: 246.64297771453857 and batch: 1050, loss is 4.851697225570678 and perplexity is 127.95737818907854
At time: 247.01124548912048 and batch: 1100, loss is 4.9622508239746095 and perplexity is 142.9151109075351
At time: 247.38455772399902 and batch: 1150, loss is 4.931592121124267 and perplexity is 138.60000476346926
At time: 247.74428987503052 and batch: 1200, loss is 4.892534408569336 and perplexity is 133.29096008511763
At time: 248.10551571846008 and batch: 1250, loss is 4.902570390701294 and perplexity is 134.6354008863871
At time: 248.46578311920166 and batch: 1300, loss is 4.971938352584839 and perplexity is 144.3063330049302
At time: 248.82595252990723 and batch: 1350, loss is 4.901413049697876 and perplexity is 134.47967194955402
At time: 249.18632912635803 and batch: 1400, loss is 4.788481197357178 and perplexity is 120.1187933096159
At time: 249.54765152931213 and batch: 1450, loss is 4.865732164382934 and perplexity is 129.76591381905152
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.166629106570513 and perplexity of 175.32284564550343
Finished 22 epochs...
Completing Train Step...
At time: 250.73709440231323 and batch: 50, loss is 4.992654447555542 and perplexity is 147.32697664797044
At time: 251.11212968826294 and batch: 100, loss is 4.986512393951416 and perplexity is 146.42485972134
At time: 251.47463965415955 and batch: 150, loss is 4.917572994232177 and perplexity is 136.67051022497725
At time: 251.83575081825256 and batch: 200, loss is 4.925720319747925 and perplexity is 137.78855772408414
At time: 252.19673442840576 and batch: 250, loss is 4.92942172050476 and perplexity is 138.2995134385047
At time: 252.55830025672913 and batch: 300, loss is 4.964040203094482 and perplexity is 143.17106915778606
At time: 252.92106795310974 and batch: 350, loss is 4.996777181625366 and perplexity is 147.9356203700162
At time: 253.2833948135376 and batch: 400, loss is 4.900958681106568 and perplexity is 134.41858249006756
At time: 253.6456277370453 and batch: 450, loss is 4.932281246185303 and perplexity is 138.6955504178827
At time: 254.0075135231018 and batch: 500, loss is 4.930335760116577 and perplexity is 138.42598246212606
At time: 254.37059116363525 and batch: 550, loss is 4.973862009048462 and perplexity is 144.5841959859316
At time: 254.73293805122375 and batch: 600, loss is 4.870617437362671 and perplexity is 130.4014067458513
At time: 255.0955090522766 and batch: 650, loss is 5.008223972320557 and perplexity is 149.63873746879517
At time: 255.45736408233643 and batch: 700, loss is 5.020000972747803 and perplexity is 151.4114510791375
At time: 255.81997513771057 and batch: 750, loss is 4.967680282592774 and perplexity is 143.69317290445068
At time: 256.1824064254761 and batch: 800, loss is 4.90561915397644 and perplexity is 135.04649870367996
At time: 256.5582706928253 and batch: 850, loss is 4.8581779670715335 and perplexity is 128.78932980008588
At time: 256.9201636314392 and batch: 900, loss is 4.834896564483643 and perplexity is 125.82556770118555
At time: 257.28209471702576 and batch: 950, loss is 4.90781831741333 and perplexity is 135.3438148294593
At time: 257.6443464756012 and batch: 1000, loss is 4.955301885604858 and perplexity is 141.92544515528272
At time: 258.00756311416626 and batch: 1050, loss is 4.849026031494141 and perplexity is 127.61603529792974
At time: 258.37077355384827 and batch: 1100, loss is 4.958352880477905 and perplexity is 142.3591201945593
At time: 258.73365592956543 and batch: 1150, loss is 4.927440013885498 and perplexity is 138.0257157602225
At time: 259.0953862667084 and batch: 1200, loss is 4.88901382446289 and perplexity is 132.8225231192148
At time: 259.45815801620483 and batch: 1250, loss is 4.899598970413208 and perplexity is 134.23593630719338
At time: 259.82064628601074 and batch: 1300, loss is 4.967192678451538 and perplexity is 143.62312459758536
At time: 260.18298411369324 and batch: 1350, loss is 4.89734450340271 and perplexity is 133.93364669617867
At time: 260.5457954406738 and batch: 1400, loss is 4.783282642364502 and perplexity is 119.49596945162949
At time: 260.91080045700073 and batch: 1450, loss is 4.860177707672119 and perplexity is 129.04713273539568
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.1634745801615916 and perplexity of 174.7706565043462
Finished 23 epochs...
Completing Train Step...
At time: 262.1173689365387 and batch: 50, loss is 4.987336111068726 and perplexity is 146.54552207369215
At time: 262.47875475883484 and batch: 100, loss is 4.981087303161621 and perplexity is 145.63264243184736
At time: 262.83996176719666 and batch: 150, loss is 4.911211404800415 and perplexity is 135.80382821193405
At time: 263.1995270252228 and batch: 200, loss is 4.921425275802612 and perplexity is 137.19801891638843
At time: 263.5602226257324 and batch: 250, loss is 4.9224439716339115 and perplexity is 137.3378531785184
At time: 263.92114305496216 and batch: 300, loss is 4.959443054199219 and perplexity is 142.5144009925284
At time: 264.28111481666565 and batch: 350, loss is 4.991796178817749 and perplexity is 147.20058475654312
At time: 264.64189434051514 and batch: 400, loss is 4.895146045684815 and perplexity is 133.6395226650005
At time: 265.0028381347656 and batch: 450, loss is 4.926025791168213 and perplexity is 137.83065461988343
At time: 265.36330008506775 and batch: 500, loss is 4.925089778900147 and perplexity is 137.70170379543518
At time: 265.736953496933 and batch: 550, loss is 4.969719152450562 and perplexity is 143.98644345210187
At time: 266.0975284576416 and batch: 600, loss is 4.865575122833252 and perplexity is 129.74553677891225
At time: 266.45800256729126 and batch: 650, loss is 5.003651466369629 and perplexity is 148.9560753788778
At time: 266.81820821762085 and batch: 700, loss is 5.016291818618774 and perplexity is 150.85088292970119
At time: 267.17909693717957 and batch: 750, loss is 4.964304752349854 and perplexity is 143.20894996797162
At time: 267.5397140979767 and batch: 800, loss is 4.9023250961303715 and perplexity is 134.6023796036319
At time: 267.9008791446686 and batch: 850, loss is 4.853395147323608 and perplexity is 128.1748243560018
At time: 268.26177287101746 and batch: 900, loss is 4.829227056503296 and perplexity is 125.11421705049744
At time: 268.6223602294922 and batch: 950, loss is 4.904374494552612 and perplexity is 134.87851636849788
At time: 268.98275208473206 and batch: 1000, loss is 4.952633094787598 and perplexity is 141.5471808092372
At time: 269.3426558971405 and batch: 1050, loss is 4.845290765762329 and perplexity is 127.14024464989743
At time: 269.7049386501312 and batch: 1100, loss is 4.954182100296021 and perplexity is 141.7666080751594
At time: 270.0658218860626 and batch: 1150, loss is 4.923053121566772 and perplexity is 137.42153800827785
At time: 270.42704939842224 and batch: 1200, loss is 4.884476852416992 and perplexity is 132.2212759967955
At time: 270.78778195381165 and batch: 1250, loss is 4.895813798904419 and perplexity is 133.72879068771417
At time: 271.14888405799866 and batch: 1300, loss is 4.963136653900147 and perplexity is 143.041765478511
At time: 271.5103828907013 and batch: 1350, loss is 4.894329900741577 and perplexity is 133.53049794040135
At time: 271.87192392349243 and batch: 1400, loss is 4.779854764938355 and perplexity is 119.08705317327937
At time: 272.2314531803131 and batch: 1450, loss is 4.857776069641114 and perplexity is 128.73758009910622
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.161671695546207 and perplexity of 174.4558490425494
Finished 24 epochs...
Completing Train Step...
At time: 273.42898988723755 and batch: 50, loss is 4.982849082946777 and perplexity is 145.88944122237925
At time: 273.7899785041809 and batch: 100, loss is 4.977230720520019 and perplexity is 145.07207973396052
At time: 274.15147709846497 and batch: 150, loss is 4.90654465675354 and perplexity is 135.17154246851803
At time: 274.512898683548 and batch: 200, loss is 4.916810503005982 and perplexity is 136.5663398795852
At time: 274.88698625564575 and batch: 250, loss is 4.917299909591675 and perplexity is 136.63319270347804
At time: 275.24770855903625 and batch: 300, loss is 4.955939064025879 and perplexity is 142.01590580305518
At time: 275.60850739479065 and batch: 350, loss is 4.987281417846679 and perplexity is 146.53750724609384
At time: 275.96892523765564 and batch: 400, loss is 4.890507745742798 and perplexity is 133.02109780349525
At time: 276.3287765979767 and batch: 450, loss is 4.921185808181763 and perplexity is 137.16516836669177
At time: 276.68851375579834 and batch: 500, loss is 4.921222743988037 and perplexity is 137.1702347663433
At time: 277.0486671924591 and batch: 550, loss is 4.965192785263062 and perplexity is 143.3361807131926
At time: 277.40966176986694 and batch: 600, loss is 4.860755348205567 and perplexity is 129.121697123622
At time: 277.7713506221771 and batch: 650, loss is 4.999509601593018 and perplexity is 148.34039536884532
At time: 278.13223910331726 and batch: 700, loss is 5.0111460113525395 and perplexity is 150.07662715418195
At time: 278.49419260025024 and batch: 750, loss is 4.958805189132691 and perplexity is 142.42352502104313
At time: 278.85511112213135 and batch: 800, loss is 4.897498435974121 and perplexity is 133.95426503368924
At time: 279.2163882255554 and batch: 850, loss is 4.8502459049224855 and perplexity is 127.77180569919038
At time: 279.5782129764557 and batch: 900, loss is 4.824331369400024 and perplexity is 124.5031939011273
At time: 279.93978333473206 and batch: 950, loss is 4.9016440486907955 and perplexity is 134.51074020657242
At time: 280.3009366989136 and batch: 1000, loss is 4.946605577468872 and perplexity is 140.69656883997536
At time: 280.6615402698517 and batch: 1050, loss is 4.839845352172851 and perplexity is 126.44979503190824
At time: 281.0215060710907 and batch: 1100, loss is 4.948518266677857 and perplexity is 140.96593517385645
At time: 281.38190603256226 and batch: 1150, loss is 4.920712337493897 and perplexity is 137.10024005211378
At time: 281.74347281455994 and batch: 1200, loss is 4.8795898914337155 and perplexity is 131.5766920908891
At time: 282.10428166389465 and batch: 1250, loss is 4.892644300460815 and perplexity is 133.30560848569394
At time: 282.46530842781067 and batch: 1300, loss is 4.958553409576416 and perplexity is 142.3876702030547
At time: 282.8265919685364 and batch: 1350, loss is 4.888426065444946 and perplexity is 132.74447842144966
At time: 283.1881158351898 and batch: 1400, loss is 4.7729905128479 and perplexity is 118.27240878052237
At time: 283.5492877960205 and batch: 1450, loss is 4.853142786026001 and perplexity is 128.1424820721487
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.160621577857906 and perplexity of 174.27274602632667
Finished 25 epochs...
Completing Train Step...
At time: 284.7448296546936 and batch: 50, loss is 4.978802061080932 and perplexity is 145.3002165704936
At time: 285.12106943130493 and batch: 100, loss is 4.97183988571167 and perplexity is 144.29212431109502
At time: 285.4842565059662 and batch: 150, loss is 4.901377153396607 and perplexity is 134.47484471337563
At time: 285.846556186676 and batch: 200, loss is 4.912045316696167 and perplexity is 135.9171238725026
At time: 286.2090973854065 and batch: 250, loss is 4.912497816085815 and perplexity is 135.97864020509945
At time: 286.5716667175293 and batch: 300, loss is 4.949716329574585 and perplexity is 141.134922438964
At time: 286.93431639671326 and batch: 350, loss is 4.981957426071167 and perplexity is 145.7594158766459
At time: 287.3056797981262 and batch: 400, loss is 4.884782400131225 and perplexity is 132.26168207812785
At time: 287.69302320480347 and batch: 450, loss is 4.917400922775268 and perplexity is 136.6469951543606
At time: 288.05530190467834 and batch: 500, loss is 4.916202421188355 and perplexity is 136.4833216149113
At time: 288.4175343513489 and batch: 550, loss is 4.961013822555542 and perplexity is 142.73843400985174
At time: 288.78009724617004 and batch: 600, loss is 4.856267709732055 and perplexity is 128.5435438695188
At time: 289.1431128978729 and batch: 650, loss is 4.992985620498657 and perplexity is 147.37577543640037
At time: 289.5075697898865 and batch: 700, loss is 5.007248411178589 and perplexity is 149.49282691509282
At time: 289.8777494430542 and batch: 750, loss is 4.9544082736969 and perplexity is 141.79867553730566
At time: 290.23778653144836 and batch: 800, loss is 4.89280424118042 and perplexity is 133.32693118578098
At time: 290.6055836677551 and batch: 850, loss is 4.84430850982666 and perplexity is 127.01542170400339
At time: 290.9746551513672 and batch: 900, loss is 4.819122667312622 and perplexity is 123.85637984838884
At time: 291.33451652526855 and batch: 950, loss is 4.895551862716675 and perplexity is 133.6937668652934
At time: 291.7087330818176 and batch: 1000, loss is 4.940663528442383 and perplexity is 139.8630218711148
At time: 292.078373670578 and batch: 1050, loss is 4.836507034301758 and perplexity is 126.02836923936131
At time: 292.44829750061035 and batch: 1100, loss is 4.9471299266815185 and perplexity is 140.7703623201546
At time: 292.81890749931335 and batch: 1150, loss is 4.915068292617798 and perplexity is 136.32861972296325
At time: 293.19334602355957 and batch: 1200, loss is 4.874639978408814 and perplexity is 130.9270081749
At time: 293.6001274585724 and batch: 1250, loss is 4.886475162506104 and perplexity is 132.48575927840793
At time: 293.96967101097107 and batch: 1300, loss is 4.952656221389771 and perplexity is 141.55045435242928
At time: 294.3390996456146 and batch: 1350, loss is 4.881426830291748 and perplexity is 131.8186125579285
At time: 294.70871329307556 and batch: 1400, loss is 4.767497701644897 and perplexity is 117.6245417032343
At time: 295.07772421836853 and batch: 1450, loss is 4.845160055160522 and perplexity is 127.12362715807016
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.153727735209669 and perplexity of 173.07546879946867
Finished 26 epochs...
Completing Train Step...
At time: 296.41450572013855 and batch: 50, loss is 4.97252649307251 and perplexity is 144.39123036533795
At time: 296.7977247238159 and batch: 100, loss is 4.96353744506836 and perplexity is 143.0991068449894
At time: 297.1677243709564 and batch: 150, loss is 4.891258220672608 and perplexity is 133.12096427148572
At time: 297.5481457710266 and batch: 200, loss is 4.905802526473999 and perplexity is 135.07126478807382
At time: 297.917733669281 and batch: 250, loss is 4.904123983383179 and perplexity is 134.84473202548529
At time: 298.29954075813293 and batch: 300, loss is 4.9409552097320555 and perplexity is 139.90382324792148
At time: 298.6736283302307 and batch: 350, loss is 4.97193323135376 and perplexity is 144.30559398074504
At time: 299.0343015193939 and batch: 400, loss is 4.87404281616211 and perplexity is 130.84884684836345
At time: 299.39589285850525 and batch: 450, loss is 4.907889423370361 and perplexity is 135.3534389231021
At time: 299.75755763053894 and batch: 500, loss is 4.905897426605224 and perplexity is 135.0840836770745
At time: 300.12070202827454 and batch: 550, loss is 4.950703201293945 and perplexity is 141.27427325191158
At time: 300.4818186759949 and batch: 600, loss is 4.846731414794922 and perplexity is 127.32354112159602
At time: 300.84325337409973 and batch: 650, loss is 4.981357650756836 and perplexity is 145.67201918897962
At time: 301.2036533355713 and batch: 700, loss is 4.998124895095825 and perplexity is 148.13512960879595
At time: 301.5650804042816 and batch: 750, loss is 4.9451624774932865 and perplexity is 140.49367605741324
At time: 301.92516040802 and batch: 800, loss is 4.882126626968383 and perplexity is 131.9108910692472
At time: 302.28756070137024 and batch: 850, loss is 4.8292138671875 and perplexity is 125.11256689046047
At time: 302.64937949180603 and batch: 900, loss is 4.806206121444702 and perplexity is 122.26687081921979
At time: 303.0330948829651 and batch: 950, loss is 4.88187894821167 and perplexity is 131.87822358943754
At time: 303.3940818309784 and batch: 1000, loss is 4.924970970153809 and perplexity is 137.6853446004656
At time: 303.75669050216675 and batch: 1050, loss is 4.81919997215271 and perplexity is 123.86595491612161
At time: 304.117840051651 and batch: 1100, loss is 4.931874961853027 and perplexity is 138.6392120342678
At time: 304.48017859458923 and batch: 1150, loss is 4.899796476364136 and perplexity is 134.26245132179287
At time: 304.8417594432831 and batch: 1200, loss is 4.858332605361938 and perplexity is 128.8092471018176
At time: 305.20282196998596 and batch: 1250, loss is 4.869332056045533 and perplexity is 130.23389889268722
At time: 305.5626108646393 and batch: 1300, loss is 4.934121685028076 and perplexity is 138.95104613619543
At time: 305.9237654209137 and batch: 1350, loss is 4.864554929733276 and perplexity is 129.61323877376836
At time: 306.28462290763855 and batch: 1400, loss is 4.751017808914185 and perplexity is 115.70198713153802
At time: 306.6475007534027 and batch: 1450, loss is 4.828930740356445 and perplexity is 125.07714917996033
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.142635508480235 and perplexity of 171.16628458539054
Finished 27 epochs...
Completing Train Step...
At time: 307.85782194137573 and batch: 50, loss is 4.956739091873169 and perplexity is 142.12956794283193
At time: 308.219336271286 and batch: 100, loss is 4.949130334854126 and perplexity is 141.05224234695703
At time: 308.5812358856201 and batch: 150, loss is 4.87429443359375 and perplexity is 130.88177484159536
At time: 308.9416313171387 and batch: 200, loss is 4.89116509437561 and perplexity is 133.10856778625873
At time: 309.30609369277954 and batch: 250, loss is 4.889224920272827 and perplexity is 132.8505643569003
At time: 309.66775941848755 and batch: 300, loss is 4.926433372497558 and perplexity is 137.88684327126276
At time: 310.02694177627563 and batch: 350, loss is 4.956979990005493 and perplexity is 142.1638108146537
At time: 310.38560795783997 and batch: 400, loss is 4.859731931686401 and perplexity is 128.98961944257124
At time: 310.7432827949524 and batch: 450, loss is 4.894029884338379 and perplexity is 133.4904426096206
At time: 311.1021087169647 and batch: 500, loss is 4.890549688339234 and perplexity is 133.02667717072364
At time: 311.4612195491791 and batch: 550, loss is 4.940243692398071 and perplexity is 139.80431465783133
At time: 311.81933879852295 and batch: 600, loss is 4.833884162902832 and perplexity is 125.69824615867886
At time: 312.1955597400665 and batch: 650, loss is 4.969973468780518 and perplexity is 144.02306621264964
At time: 312.55342650413513 and batch: 700, loss is 4.984038467407227 and perplexity is 146.06306308781953
At time: 312.9112105369568 and batch: 750, loss is 4.933167123794556 and perplexity is 138.8184721392624
At time: 313.2699112892151 and batch: 800, loss is 4.868663911819458 and perplexity is 130.14691292792392
At time: 313.62817096710205 and batch: 850, loss is 4.818341093063355 and perplexity is 123.75961471078753
At time: 313.9862651824951 and batch: 900, loss is 4.793587265014648 and perplexity is 120.73369652793085
At time: 314.34538531303406 and batch: 950, loss is 4.86950364112854 and perplexity is 130.2562470042856
At time: 314.70515489578247 and batch: 1000, loss is 4.913536758422851 and perplexity is 136.1199875845153
At time: 315.0663743019104 and batch: 1050, loss is 4.811754007339477 and perplexity is 122.94707858007956
At time: 315.4277968406677 and batch: 1100, loss is 4.923194046020508 and perplexity is 137.44090542809266
At time: 315.79011702537537 and batch: 1150, loss is 4.891957731246948 and perplexity is 133.21411637030064
At time: 316.15164852142334 and batch: 1200, loss is 4.848850965499878 and perplexity is 127.59369602530695
At time: 316.5132806301117 and batch: 1250, loss is 4.8595443439483645 and perplexity is 128.96542484100607
At time: 316.8743894100189 and batch: 1300, loss is 4.922986354827881 and perplexity is 137.41236312662346
At time: 317.2362916469574 and batch: 1350, loss is 4.8532171726226805 and perplexity is 128.15201450981854
At time: 317.5977027416229 and batch: 1400, loss is 4.7429252624511715 and perplexity is 114.76944184714111
At time: 317.9593198299408 and batch: 1450, loss is 4.819282960891724 and perplexity is 123.8762348220792
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.138054741753472 and perplexity of 170.3840048526121
Finished 28 epochs...
Completing Train Step...
At time: 319.17697501182556 and batch: 50, loss is 4.9472835254669185 and perplexity is 140.7919861374808
At time: 319.53794860839844 and batch: 100, loss is 4.942641410827637 and perplexity is 140.13992823225718
At time: 319.9001054763794 and batch: 150, loss is 4.866208848953247 and perplexity is 129.82778597350062
At time: 320.26103377342224 and batch: 200, loss is 4.8831367015838625 and perplexity is 132.04419822557492
At time: 320.62297344207764 and batch: 250, loss is 4.881130962371826 and perplexity is 131.7796174282125
At time: 321.00344014167786 and batch: 300, loss is 4.920640573501587 and perplexity is 137.09040154457054
At time: 321.37693524360657 and batch: 350, loss is 4.947108249664307 and perplexity is 140.76731087166098
At time: 321.7507600784302 and batch: 400, loss is 4.850275716781616 and perplexity is 127.77561487104171
At time: 322.11180210113525 and batch: 450, loss is 4.884341897964478 and perplexity is 132.20343335088194
At time: 322.4730865955353 and batch: 500, loss is 4.885715446472168 and perplexity is 132.38514594643598
At time: 322.83483386039734 and batch: 550, loss is 4.93169093132019 and perplexity is 138.6137005337246
At time: 323.1952452659607 and batch: 600, loss is 4.8251008129119874 and perplexity is 124.59902894098983
At time: 323.5556857585907 and batch: 650, loss is 4.960755729675293 and perplexity is 142.70159898992858
At time: 323.9168300628662 and batch: 700, loss is 4.976032295227051 and perplexity is 144.89832582064184
At time: 324.27760195732117 and batch: 750, loss is 4.9251253795623775 and perplexity is 137.7066061545437
At time: 324.6378209590912 and batch: 800, loss is 4.861856384277344 and perplexity is 129.26394306438993
At time: 324.997501373291 and batch: 850, loss is 4.809804573059082 and perplexity is 122.70763479621107
At time: 325.3577597141266 and batch: 900, loss is 4.7858233070373535 and perplexity is 119.79995463845793
At time: 325.71733808517456 and batch: 950, loss is 4.863259353637695 and perplexity is 129.44542369201983
At time: 326.0789120197296 and batch: 1000, loss is 4.906513509750366 and perplexity is 135.1673323456224
At time: 326.4400849342346 and batch: 1050, loss is 4.803336601257325 and perplexity is 121.91652646565299
At time: 326.8019948005676 and batch: 1100, loss is 4.915093078613281 and perplexity is 136.33199880539266
At time: 327.1636176109314 and batch: 1150, loss is 4.884508762359619 and perplexity is 132.22549523744414
At time: 327.52562403678894 and batch: 1200, loss is 4.840864915847778 and perplexity is 126.57878439488535
At time: 327.88676619529724 and batch: 1250, loss is 4.854931564331054 and perplexity is 128.37190569686194
At time: 328.24958300590515 and batch: 1300, loss is 4.917067003250122 and perplexity is 136.60137367200178
At time: 328.6100833415985 and batch: 1350, loss is 4.846666326522827 and perplexity is 127.31525412200361
At time: 328.9709429740906 and batch: 1400, loss is 4.736545257568359 and perplexity is 114.03954310237944
At time: 329.34302520751953 and batch: 1450, loss is 4.813981771469116 and perplexity is 123.22128098732374
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.1363301073384084 and perplexity of 170.0904079804738
Finished 29 epochs...
Completing Train Step...
At time: 330.5742893218994 and batch: 50, loss is 4.942260866165161 and perplexity is 140.08660887641022
At time: 330.9496455192566 and batch: 100, loss is 4.935951271057129 and perplexity is 139.2055017321501
At time: 331.3121027946472 and batch: 150, loss is 4.858187742233277 and perplexity is 128.79058874276865
At time: 331.67452096939087 and batch: 200, loss is 4.8753077507019045 and perplexity is 131.0144668013503
At time: 332.0372450351715 and batch: 250, loss is 4.872637462615967 and perplexity is 130.6650871113795
At time: 332.3998992443085 and batch: 300, loss is 4.913517208099365 and perplexity is 136.11732642073844
At time: 332.7626733779907 and batch: 350, loss is 4.9395606803894045 and perplexity is 139.70885923436776
At time: 333.12541365623474 and batch: 400, loss is 4.843917665481567 and perplexity is 126.96578814482059
At time: 333.4880254268646 and batch: 450, loss is 4.8780035972595215 and perplexity is 131.3681382084025
At time: 333.8502604961395 and batch: 500, loss is 4.876013116836548 and perplexity is 131.10691256960448
At time: 334.21261167526245 and batch: 550, loss is 4.923607730865479 and perplexity is 137.4977744098543
At time: 334.57559990882874 and batch: 600, loss is 4.817204532623291 and perplexity is 123.61903433281094
At time: 334.9386534690857 and batch: 650, loss is 4.953774137496948 and perplexity is 141.70878436867662
At time: 335.3004946708679 and batch: 700, loss is 4.969857378005981 and perplexity is 144.00634743380866
At time: 335.66300225257874 and batch: 750, loss is 4.919658880233765 and perplexity is 136.9558868571756
At time: 336.0257751941681 and batch: 800, loss is 4.856991453170776 and perplexity is 128.63661008995513
At time: 336.38844442367554 and batch: 850, loss is 4.8045436382293705 and perplexity is 122.06377306876999
At time: 336.75025820732117 and batch: 900, loss is 4.780885553359985 and perplexity is 119.20987001707208
At time: 337.1121051311493 and batch: 950, loss is 4.858995599746704 and perplexity is 128.89467522540588
At time: 337.4752538204193 and batch: 1000, loss is 4.901870288848877 and perplexity is 134.5411753803999
At time: 337.8380687236786 and batch: 1050, loss is 4.798622217178345 and perplexity is 121.34311783060879
At time: 338.2004029750824 and batch: 1100, loss is 4.9120117282867435 and perplexity is 135.912558709167
At time: 338.5630564689636 and batch: 1150, loss is 4.877402601242065 and perplexity is 131.2892102006035
At time: 338.92566657066345 and batch: 1200, loss is 4.835365447998047 and perplexity is 125.88457906921889
At time: 339.2882330417633 and batch: 1250, loss is 4.848567895889282 and perplexity is 127.5575832389159
At time: 339.65039229393005 and batch: 1300, loss is 4.91120602607727 and perplexity is 135.8030977627045
At time: 340.01870369911194 and batch: 1350, loss is 4.840215368270874 and perplexity is 126.4965921489711
At time: 340.3967628479004 and batch: 1400, loss is 4.729304656982422 and perplexity is 113.21681045342147
At time: 340.76826906204224 and batch: 1450, loss is 4.809113521575927 and perplexity is 122.6228667960903
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.13288814186031 and perplexity of 169.5059690543465
Finished 30 epochs...
Completing Train Step...
At time: 341.95951437950134 and batch: 50, loss is 4.936734533309936 and perplexity is 139.31457885946165
At time: 342.33351850509644 and batch: 100, loss is 4.929405813217163 and perplexity is 138.29731348586756
At time: 342.6954143047333 and batch: 150, loss is 4.853784837722778 and perplexity is 128.22478258795812
At time: 343.0569384098053 and batch: 200, loss is 4.869897146224975 and perplexity is 130.30751358749362
At time: 343.41742849349976 and batch: 250, loss is 4.8662902450561525 and perplexity is 129.8383538794151
At time: 343.7785449028015 and batch: 300, loss is 4.907433748245239 and perplexity is 135.29177577813277
At time: 344.13942861557007 and batch: 350, loss is 4.934342298507691 and perplexity is 138.98170399162333
At time: 344.5006983280182 and batch: 400, loss is 4.838275547027588 and perplexity is 126.25144921592266
At time: 344.86168670654297 and batch: 450, loss is 4.873233852386474 and perplexity is 130.74303767484403
At time: 345.22199010849 and batch: 500, loss is 4.872149486541748 and perplexity is 130.60134122963086
At time: 345.5844359397888 and batch: 550, loss is 4.9187120342254635 and perplexity is 136.82627209468524
At time: 345.94589495658875 and batch: 600, loss is 4.809616298675537 and perplexity is 122.68453426660079
At time: 346.3072979450226 and batch: 650, loss is 4.948962306976318 and perplexity is 141.0285436290938
At time: 346.66877150535583 and batch: 700, loss is 4.96300853729248 and perplexity is 143.02344062664721
At time: 347.029981136322 and batch: 750, loss is 4.915565090179443 and perplexity is 136.3963642750949
At time: 347.3919246196747 and batch: 800, loss is 4.850213556289673 and perplexity is 127.7676725228157
At time: 347.75357580184937 and batch: 850, loss is 4.798303680419922 and perplexity is 121.3044717426247
At time: 348.1146593093872 and batch: 900, loss is 4.77674277305603 and perplexity is 118.71703128169847
At time: 348.476443529129 and batch: 950, loss is 4.850992288589477 and perplexity is 127.86720808702938
At time: 348.85641622543335 and batch: 1000, loss is 4.898226680755616 and perplexity is 134.05185205746648
At time: 349.2670271396637 and batch: 1050, loss is 4.79504207611084 and perplexity is 120.90946907624927
At time: 349.6449201107025 and batch: 1100, loss is 4.909348773956299 and perplexity is 135.55111124503065
At time: 350.02539896965027 and batch: 1150, loss is 4.871188116073609 and perplexity is 130.4758452907837
At time: 350.3938193321228 and batch: 1200, loss is 4.829224815368653 and perplexity is 125.11393665300547
At time: 350.7562484741211 and batch: 1250, loss is 4.84498815536499 and perplexity is 127.1017765106691
At time: 351.1171524524689 and batch: 1300, loss is 4.905087394714355 and perplexity is 134.9747055672065
At time: 351.4788863658905 and batch: 1350, loss is 4.83425196647644 and perplexity is 125.74448692605077
At time: 351.8402581214905 and batch: 1400, loss is 4.722156944274903 and perplexity is 112.4104544522012
At time: 352.20174765586853 and batch: 1450, loss is 4.8059999465942385 and perplexity is 122.24166506389771
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.129381489549947 and perplexity of 168.912611513661
Finished 31 epochs...
Completing Train Step...
At time: 353.4031000137329 and batch: 50, loss is 4.93209774017334 and perplexity is 138.67010128565434
At time: 353.76368737220764 and batch: 100, loss is 4.925156497955323 and perplexity is 137.71089142950024
At time: 354.12429642677307 and batch: 150, loss is 4.847872943878174 and perplexity is 127.46896763527434
At time: 354.48412919044495 and batch: 200, loss is 4.86473461151123 and perplexity is 129.63653000339974
At time: 354.84571981430054 and batch: 250, loss is 4.86221757888794 and perplexity is 129.31064093697142
At time: 355.2063970565796 and batch: 300, loss is 4.9037046718597415 and perplexity is 134.7882019281611
At time: 355.56673526763916 and batch: 350, loss is 4.9314992713928225 and perplexity is 138.5871363876706
At time: 355.9279246330261 and batch: 400, loss is 4.832736921310425 and perplexity is 125.55412259067634
At time: 356.28867506980896 and batch: 450, loss is 4.866821489334106 and perplexity is 129.9073480867388
At time: 356.64996814727783 and batch: 500, loss is 4.867307968139649 and perplexity is 129.9705606328025
At time: 357.01215291023254 and batch: 550, loss is 4.915575170516968 and perplexity is 136.3977392034138
At time: 357.3725862503052 and batch: 600, loss is 4.8064103698730465 and perplexity is 122.2918461859261
At time: 357.7327690124512 and batch: 650, loss is 4.945858764648437 and perplexity is 140.59153406411488
At time: 358.0942463874817 and batch: 700, loss is 4.961461906433105 and perplexity is 142.80240713243222
At time: 358.4682767391205 and batch: 750, loss is 4.912065467834473 and perplexity is 135.91986278485984
At time: 358.8297595977783 and batch: 800, loss is 4.843884286880493 and perplexity is 126.9615502751555
At time: 359.19105315208435 and batch: 850, loss is 4.793136062622071 and perplexity is 120.6792334830448
At time: 359.5522437095642 and batch: 900, loss is 4.772035245895386 and perplexity is 118.1594810036942
At time: 359.9133777618408 and batch: 950, loss is 4.8460063552856445 and perplexity is 127.23125743697534
At time: 360.274676322937 and batch: 1000, loss is 4.893372888565064 and perplexity is 133.40276875687707
At time: 360.6359558105469 and batch: 1050, loss is 4.791830425262451 and perplexity is 120.5217729828034
At time: 360.9965364933014 and batch: 1100, loss is 4.902912530899048 and perplexity is 134.68147295017408
At time: 361.35693097114563 and batch: 1150, loss is 4.86725510597229 and perplexity is 129.96369028886681
At time: 361.71805906295776 and batch: 1200, loss is 4.824820098876953 and perplexity is 124.56405715357982
At time: 362.0799810886383 and batch: 1250, loss is 4.83973388671875 and perplexity is 126.43570103359552
At time: 362.4409613609314 and batch: 1300, loss is 4.900493144989014 and perplexity is 134.35602034864613
At time: 362.8019025325775 and batch: 1350, loss is 4.828826265335083 and perplexity is 125.06408242471448
At time: 363.1625711917877 and batch: 1400, loss is 4.717293710708618 and perplexity is 111.86510331672471
At time: 363.5425899028778 and batch: 1450, loss is 4.80172981262207 and perplexity is 121.72078967241796
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.128718971187233 and perplexity of 168.80074086910935
Finished 32 epochs...
Completing Train Step...
At time: 364.7599015235901 and batch: 50, loss is 4.926758575439453 and perplexity is 137.93169177037979
At time: 365.12179732322693 and batch: 100, loss is 4.919369277954101 and perplexity is 136.91622986278355
At time: 365.4846410751343 and batch: 150, loss is 4.843410768508911 and perplexity is 126.90144588000643
At time: 365.8483395576477 and batch: 200, loss is 4.861263284683227 and perplexity is 129.18729940313347
At time: 366.2115240097046 and batch: 250, loss is 4.858323268890381 and perplexity is 128.80804448355977
At time: 366.5994358062744 and batch: 300, loss is 4.897947616577149 and perplexity is 134.01444820678026
At time: 366.98708057403564 and batch: 350, loss is 4.928266019821167 and perplexity is 138.139772920176
At time: 367.3580253124237 and batch: 400, loss is 4.830398788452149 and perplexity is 125.2609032975695
At time: 367.7427349090576 and batch: 450, loss is 4.863185882568359 and perplexity is 129.43591354768503
At time: 368.132120847702 and batch: 500, loss is 4.862076358795166 and perplexity is 129.29238096562946
At time: 368.4948949813843 and batch: 550, loss is 4.911556806564331 and perplexity is 135.85074319553758
At time: 368.85741424560547 and batch: 600, loss is 4.802702083587646 and perplexity is 121.83919281276394
At time: 369.21891951560974 and batch: 650, loss is 4.940915365219116 and perplexity is 139.8982489592789
At time: 369.58134031295776 and batch: 700, loss is 4.956605081558227 and perplexity is 142.11052239084808
At time: 369.94427609443665 and batch: 750, loss is 4.90816635131836 and perplexity is 135.39092726374267
At time: 370.3066945075989 and batch: 800, loss is 4.839893341064453 and perplexity is 126.45586336302017
At time: 370.6690685749054 and batch: 850, loss is 4.791355857849121 and perplexity is 120.4645908462115
At time: 371.0319447517395 and batch: 900, loss is 4.76913444519043 and perplexity is 117.81722055258035
At time: 371.39492630958557 and batch: 950, loss is 4.842768259048462 and perplexity is 126.81993668850126
At time: 371.75781774520874 and batch: 1000, loss is 4.889008045196533 and perplexity is 132.8217555046936
At time: 372.1210067272186 and batch: 1050, loss is 4.787855195999145 and perplexity is 120.0436223129067
At time: 372.48403334617615 and batch: 1100, loss is 4.899823026657105 and perplexity is 134.2660160765326
At time: 372.8467767238617 and batch: 1150, loss is 4.864383506774902 and perplexity is 129.59102199322086
At time: 373.2086441516876 and batch: 1200, loss is 4.82144679069519 and perplexity is 124.1445721243546
At time: 373.5710985660553 and batch: 1250, loss is 4.838458013534546 and perplexity is 126.27448797869685
At time: 373.9334292411804 and batch: 1300, loss is 4.900593280792236 and perplexity is 134.36947487028996
At time: 374.2955973148346 and batch: 1350, loss is 4.825171327590942 and perplexity is 124.60781531129406
At time: 374.6585965156555 and batch: 1400, loss is 4.714348230361939 and perplexity is 111.53609164001126
At time: 375.02187633514404 and batch: 1450, loss is 4.7991707897186275 and perplexity is 121.40970159434542
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.1283877120058765 and perplexity of 168.74483333433002
Finished 33 epochs...
Completing Train Step...
At time: 376.3616671562195 and batch: 50, loss is 4.924290237426757 and perplexity is 137.5916495746141
At time: 376.73609590530396 and batch: 100, loss is 4.914644393920899 and perplexity is 136.27084244543406
At time: 377.0975112915039 and batch: 150, loss is 4.840686159133911 and perplexity is 126.55615960956806
At time: 377.4750027656555 and batch: 200, loss is 4.858785276412964 and perplexity is 128.86756851829753
At time: 377.8362946510315 and batch: 250, loss is 4.853024873733521 and perplexity is 128.12737338909074
At time: 378.19788670539856 and batch: 300, loss is 4.893712215423584 and perplexity is 133.4480435803646
At time: 378.5597403049469 and batch: 350, loss is 4.925937814712524 and perplexity is 137.8185293007839
At time: 378.9219694137573 and batch: 400, loss is 4.827486410140991 and perplexity is 124.89662687243063
At time: 379.283056974411 and batch: 450, loss is 4.85886739730835 and perplexity is 128.8781516729536
At time: 379.6445834636688 and batch: 500, loss is 4.857236576080322 and perplexity is 128.66814573499116
At time: 380.0055329799652 and batch: 550, loss is 4.905253868103028 and perplexity is 134.99717713423442
At time: 380.3670074939728 and batch: 600, loss is 4.799669132232666 and perplexity is 121.4702202885333
At time: 380.7283134460449 and batch: 650, loss is 4.937107048034668 and perplexity is 139.3664852588054
At time: 381.09233117103577 and batch: 700, loss is 4.949533958435058 and perplexity is 141.1091858492087
At time: 381.4536187648773 and batch: 750, loss is 4.903721284866333 and perplexity is 134.79044118404855
At time: 381.81541657447815 and batch: 800, loss is 4.8359888076782225 and perplexity is 125.96307490319367
At time: 382.1763231754303 and batch: 850, loss is 4.7876244640350345 and perplexity is 120.01592760730124
At time: 382.53659224510193 and batch: 900, loss is 4.762858362197876 and perplexity is 117.0801054158577
At time: 382.8980071544647 and batch: 950, loss is 4.838742895126343 and perplexity is 126.31046638038437
At time: 383.2589612007141 and batch: 1000, loss is 4.88490556716919 and perplexity is 132.2779733609995
At time: 383.6193058490753 and batch: 1050, loss is 4.785087985992432 and perplexity is 119.71189559043495
At time: 383.97961139678955 and batch: 1100, loss is 4.896176738739014 and perplexity is 133.77733500168674
At time: 384.34033608436584 and batch: 1150, loss is 4.861552505493164 and perplexity is 129.2246684621947
At time: 384.7017834186554 and batch: 1200, loss is 4.818449430465698 and perplexity is 123.7730232322694
At time: 385.0622465610504 and batch: 1250, loss is 4.831931381225586 and perplexity is 125.45302443688732
At time: 385.4222173690796 and batch: 1300, loss is 4.8944358634948735 and perplexity is 133.54464794928586
At time: 385.78370690345764 and batch: 1350, loss is 4.821103315353394 and perplexity is 124.10193884717091
At time: 386.1466255187988 and batch: 1400, loss is 4.710937242507935 and perplexity is 111.15629150121703
At time: 386.50993156433105 and batch: 1450, loss is 4.7952880859375 and perplexity is 120.93921765284934
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.126697507678953 and perplexity of 168.4598609854731
Finished 34 epochs...
Completing Train Step...
At time: 387.7029266357422 and batch: 50, loss is 4.917576284408569 and perplexity is 136.67095989580318
At time: 388.077351808548 and batch: 100, loss is 4.9112182712554935 and perplexity is 135.8047607060214
At time: 388.4467396736145 and batch: 150, loss is 4.8355695915222165 and perplexity is 125.91028021410057
At time: 388.81960105895996 and batch: 200, loss is 4.851757965087891 and perplexity is 127.96515049449415
At time: 389.18163442611694 and batch: 250, loss is 4.847836723327637 and perplexity is 127.46435072270432
At time: 389.5446014404297 and batch: 300, loss is 4.890453624725342 and perplexity is 133.0138987611505
At time: 389.9071924686432 and batch: 350, loss is 4.919650259017945 and perplexity is 136.9547061360068
At time: 390.269953250885 and batch: 400, loss is 4.821208038330078 and perplexity is 124.11493585214991
At time: 390.63235688209534 and batch: 450, loss is 4.855697202682495 and perplexity is 128.47022978665484
At time: 390.99490308761597 and batch: 500, loss is 4.850915889739991 and perplexity is 127.8574395526016
At time: 391.35739731788635 and batch: 550, loss is 4.899819383621216 and perplexity is 134.2655269415083
At time: 391.73739361763 and batch: 600, loss is 4.793433713912964 and perplexity is 120.71515915907169
At time: 392.11346101760864 and batch: 650, loss is 4.9315520191192626 and perplexity is 138.59444673682933
At time: 392.4768023490906 and batch: 700, loss is 4.945305271148682 and perplexity is 140.51373909538054
At time: 392.83931612968445 and batch: 750, loss is 4.896376295089722 and perplexity is 133.80403378233413
At time: 393.20090222358704 and batch: 800, loss is 4.8329165744781495 and perplexity is 125.57668081278798
At time: 393.5630865097046 and batch: 850, loss is 4.783325147628784 and perplexity is 119.5010487673398
At time: 393.9250569343567 and batch: 900, loss is 4.758603172302246 and perplexity is 116.58296579618323
At time: 394.28769755363464 and batch: 950, loss is 4.834558343887329 and perplexity is 125.78301809862772
At time: 394.65010237693787 and batch: 1000, loss is 4.8807195377349855 and perplexity is 131.72541119862285
At time: 395.0129110813141 and batch: 1050, loss is 4.780696020126343 and perplexity is 119.18727792596938
At time: 395.376588344574 and batch: 1100, loss is 4.891085662841797 and perplexity is 133.09799518846012
At time: 395.75239753723145 and batch: 1150, loss is 4.856000442504882 and perplexity is 128.5091929836153
At time: 396.1148672103882 and batch: 1200, loss is 4.812583246231079 and perplexity is 123.04907336242253
At time: 396.47738313674927 and batch: 1250, loss is 4.828003826141358 and perplexity is 124.96126710707
At time: 396.83924746513367 and batch: 1300, loss is 4.888365068435669 and perplexity is 132.73638165220973
At time: 397.19963479042053 and batch: 1350, loss is 4.815280771255493 and perplexity is 123.3814494118556
At time: 397.5604202747345 and batch: 1400, loss is 4.707841672897339 and perplexity is 110.81273149452576
At time: 397.9203894138336 and batch: 1450, loss is 4.788942308425903 and perplexity is 120.17419418677011
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.1243348732972755 and perplexity of 168.06232173085507
Finished 35 epochs...
Completing Train Step...
At time: 399.1256892681122 and batch: 50, loss is 4.9133998394012455 and perplexity is 136.10135144484434
At time: 399.5032444000244 and batch: 100, loss is 4.906078662872314 and perplexity is 135.1085680308028
At time: 399.8739082813263 and batch: 150, loss is 4.829682550430298 and perplexity is 125.17121879753483
At time: 400.2334768772125 and batch: 200, loss is 4.846864643096924 and perplexity is 127.34050535081718
At time: 400.5948369503021 and batch: 250, loss is 4.843707580566406 and perplexity is 126.93911734965377
At time: 400.9842052459717 and batch: 300, loss is 4.888009510040283 and perplexity is 132.68919450673013
At time: 401.36417269706726 and batch: 350, loss is 4.91505919456482 and perplexity is 136.32737940360076
At time: 401.7467222213745 and batch: 400, loss is 4.817578897476197 and perplexity is 123.6653216180411
At time: 402.1236171722412 and batch: 450, loss is 4.8527381801605225 and perplexity is 128.0906453597115
At time: 402.4921021461487 and batch: 500, loss is 4.846721334457397 and perplexity is 127.32225766379554
At time: 402.8614056110382 and batch: 550, loss is 4.894240798950196 and perplexity is 133.518600663873
At time: 403.2288091182709 and batch: 600, loss is 4.788982467651367 and perplexity is 120.179020386237
At time: 403.5962791442871 and batch: 650, loss is 4.926939182281494 and perplexity is 137.95660542736854
At time: 403.96362686157227 and batch: 700, loss is 4.943163852691651 and perplexity is 140.21316232619816
At time: 404.3320405483246 and batch: 750, loss is 4.891256399154663 and perplexity is 133.12072178948134
At time: 404.70044231414795 and batch: 800, loss is 4.828622903823852 and perplexity is 125.03865178980574
At time: 405.1022469997406 and batch: 850, loss is 4.778931741714477 and perplexity is 118.97718377134258
At time: 405.4872522354126 and batch: 900, loss is 4.754973001480103 and perplexity is 116.16051696003447
At time: 405.8691062927246 and batch: 950, loss is 4.830662260055542 and perplexity is 125.2939103366216
At time: 406.2386214733124 and batch: 1000, loss is 4.87686601638794 and perplexity is 131.2187812961313
At time: 406.5993845462799 and batch: 1050, loss is 4.777622699737549 and perplexity is 118.8215395381324
At time: 406.96027159690857 and batch: 1100, loss is 4.887805862426758 and perplexity is 132.66217542020786
At time: 407.32133531570435 and batch: 1150, loss is 4.851521282196045 and perplexity is 127.93486691656345
At time: 407.68242144584656 and batch: 1200, loss is 4.80824917793274 and perplexity is 122.51692429262609
At time: 408.0437750816345 and batch: 1250, loss is 4.825247783660888 and perplexity is 124.61734269934603
At time: 408.4050860404968 and batch: 1300, loss is 4.8838185119628905 and perplexity is 132.13425802878103
At time: 408.7663559913635 and batch: 1350, loss is 4.8108562469482425 and perplexity is 122.836751093946
At time: 409.12735629081726 and batch: 1400, loss is 4.701966218948364 and perplexity is 110.16356533409544
At time: 409.48781275749207 and batch: 1450, loss is 4.784839019775391 and perplexity is 119.68209508246883
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.124100644364316 and perplexity of 168.02296128242324
Finished 36 epochs...
Completing Train Step...
At time: 410.6986548900604 and batch: 50, loss is 4.910173988342285 and perplexity is 135.66301613848
At time: 411.0613958835602 and batch: 100, loss is 4.9025374698638915 and perplexity is 134.6309686492027
At time: 411.4243857860565 and batch: 150, loss is 4.824542617797851 and perplexity is 124.52949777959152
At time: 411.78636837005615 and batch: 200, loss is 4.843988513946533 and perplexity is 126.97478379467405
At time: 412.1490864753723 and batch: 250, loss is 4.841299419403076 and perplexity is 126.63379527707671
At time: 412.511846780777 and batch: 300, loss is 4.884562034606933 and perplexity is 132.23253937435445
At time: 412.8739593029022 and batch: 350, loss is 4.9132115936279295 and perplexity is 136.07573335201675
At time: 413.23627281188965 and batch: 400, loss is 4.814635219573975 and perplexity is 123.30182601299434
At time: 413.5993232727051 and batch: 450, loss is 4.8494200515747075 and perplexity is 127.66632848605177
At time: 413.9628806114197 and batch: 500, loss is 4.842864656448365 and perplexity is 126.83216238990725
At time: 414.3259611129761 and batch: 550, loss is 4.8884875774383545 and perplexity is 132.75264405007076
At time: 414.7018196582794 and batch: 600, loss is 4.785486793518066 and perplexity is 119.75964711650548
At time: 415.06537413597107 and batch: 650, loss is 4.9196718978881835 and perplexity is 136.95766971318557
At time: 415.4284460544586 and batch: 700, loss is 4.938170804977417 and perplexity is 139.5148162051356
At time: 415.7909767627716 and batch: 750, loss is 4.889012460708618 and perplexity is 132.82234198205498
At time: 416.1535859107971 and batch: 800, loss is 4.825099010467529 and perplexity is 124.59880435836297
At time: 416.51638293266296 and batch: 850, loss is 4.77749529838562 and perplexity is 118.80640247761846
At time: 416.87923550605774 and batch: 900, loss is 4.749282484054565 and perplexity is 115.50138070596135
At time: 417.24219274520874 and batch: 950, loss is 4.828874015808106 and perplexity is 125.07005443639048
At time: 417.6069881916046 and batch: 1000, loss is 4.874845952987671 and perplexity is 130.9539785877842
At time: 417.9699823856354 and batch: 1050, loss is 4.773695363998413 and perplexity is 118.35580261059113
At time: 418.3324942588806 and batch: 1100, loss is 4.885441579818726 and perplexity is 132.3488950337348
At time: 418.6953864097595 and batch: 1150, loss is 4.847932481765747 and perplexity is 127.4765570942665
At time: 419.0578815937042 and batch: 1200, loss is 4.805318279266357 and perplexity is 122.158365309304
At time: 419.4207909107208 and batch: 1250, loss is 4.8230165672302245 and perplexity is 124.3396043991217
At time: 419.7836194038391 and batch: 1300, loss is 4.879270114898682 and perplexity is 131.53462367880508
At time: 420.1457679271698 and batch: 1350, loss is 4.8078748226165775 and perplexity is 122.47106801450359
At time: 420.5085139274597 and batch: 1400, loss is 4.698971004486084 and perplexity is 109.83409549272191
At time: 420.870760679245 and batch: 1450, loss is 4.779539051055909 and perplexity is 119.04946167176466
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.118827624198718 and perplexity of 167.13930463644053
Finished 37 epochs...
Completing Train Step...
At time: 422.0672674179077 and batch: 50, loss is 4.906628742218017 and perplexity is 135.18290890832012
At time: 422.4415445327759 and batch: 100, loss is 4.9013901042938235 and perplexity is 134.47658629454526
At time: 422.80280113220215 and batch: 150, loss is 4.822927589416504 and perplexity is 124.3285414251503
At time: 423.1635277271271 and batch: 200, loss is 4.839481258392334 and perplexity is 126.40376382833544
At time: 423.52474880218506 and batch: 250, loss is 4.837008371353149 and perplexity is 126.09156777094644
At time: 423.89888310432434 and batch: 300, loss is 4.883295335769653 and perplexity is 132.06514661096995
At time: 424.25978231430054 and batch: 350, loss is 4.90751579284668 and perplexity is 135.30287619331304
At time: 424.6211483478546 and batch: 400, loss is 4.8104541301727295 and perplexity is 122.787366305573
At time: 424.9833080768585 and batch: 450, loss is 4.845883474349976 and perplexity is 127.21562410155431
At time: 425.34489822387695 and batch: 500, loss is 4.83904709815979 and perplexity is 126.34889625235894
At time: 425.70634841918945 and batch: 550, loss is 4.88548791885376 and perplexity is 132.35502809591748
At time: 426.06836199760437 and batch: 600, loss is 4.783084154129028 and perplexity is 119.47225326127709
At time: 426.4299030303955 and batch: 650, loss is 4.918201560974121 and perplexity is 136.7564437669631
At time: 426.79157876968384 and batch: 700, loss is 4.935728626251221 and perplexity is 139.1745118002373
At time: 427.1522943973541 and batch: 750, loss is 4.883410139083862 and perplexity is 132.08030899782185
At time: 427.5127305984497 and batch: 800, loss is 4.820549478530884 and perplexity is 124.03322565339731
At time: 427.87297797203064 and batch: 850, loss is 4.773227243423462 and perplexity is 118.30041079026124
At time: 428.2331266403198 and batch: 900, loss is 4.747257051467895 and perplexity is 115.26767720091645
At time: 428.59402346611023 and batch: 950, loss is 4.825226821899414 and perplexity is 124.61473052771078
At time: 428.9549250602722 and batch: 1000, loss is 4.871815252304077 and perplexity is 130.55769708399637
At time: 429.3165442943573 and batch: 1050, loss is 4.770015153884888 and perplexity is 117.92102890882897
At time: 429.67791271209717 and batch: 1100, loss is 4.882540245056152 and perplexity is 131.96546308497548
At time: 430.03890347480774 and batch: 1150, loss is 4.84370719909668 and perplexity is 126.9390689262327
At time: 430.4000506401062 and batch: 1200, loss is 4.801229515075684 and perplexity is 121.65990829067347
At time: 430.7602627277374 and batch: 1250, loss is 4.818840637207031 and perplexity is 123.82145354586795
At time: 431.12036323547363 and batch: 1300, loss is 4.876072607040405 and perplexity is 131.11471237856415
At time: 431.48190903663635 and batch: 1350, loss is 4.803923139572143 and perplexity is 121.98805615503576
At time: 431.8442599773407 and batch: 1400, loss is 4.694560556411743 and perplexity is 109.35074459828358
At time: 432.20735454559326 and batch: 1450, loss is 4.777214107513427 and perplexity is 118.772999898154
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.120724409054487 and perplexity of 167.45663279476113
Annealing...
Finished 38 epochs...
Completing Train Step...
At time: 433.398072719574 and batch: 50, loss is 4.895094499588013 and perplexity is 133.63263424676575
At time: 433.7723834514618 and batch: 100, loss is 4.872877979278565 and perplexity is 130.6965180217269
At time: 434.1329312324524 and batch: 150, loss is 4.791454830169678 and perplexity is 120.4765140963386
At time: 434.49397468566895 and batch: 200, loss is 4.802430467605591 and perplexity is 121.80610383470635
At time: 434.85499691963196 and batch: 250, loss is 4.802744598388672 and perplexity is 121.84437289191771
At time: 435.21673941612244 and batch: 300, loss is 4.837266597747803 and perplexity is 126.12413214619784
At time: 435.57676005363464 and batch: 350, loss is 4.863821792602539 and perplexity is 129.51824932019056
At time: 435.93697595596313 and batch: 400, loss is 4.761861066818238 and perplexity is 116.96340017215199
At time: 436.2989194393158 and batch: 450, loss is 4.805917205810547 and perplexity is 122.23155111115457
At time: 436.65962433815 and batch: 500, loss is 4.786367025375366 and perplexity is 119.86510978210599
At time: 437.01972103118896 and batch: 550, loss is 4.8358181190490725 and perplexity is 125.94157627345295
At time: 437.38121724128723 and batch: 600, loss is 4.736964826583862 and perplexity is 114.0874006002669
At time: 437.74477553367615 and batch: 650, loss is 4.867812690734863 and perplexity is 130.03617626892066
At time: 438.10792326927185 and batch: 700, loss is 4.882331199645996 and perplexity is 131.9378791938619
At time: 438.4725308418274 and batch: 750, loss is 4.826487579345703 and perplexity is 124.77193855691398
At time: 438.83727383613586 and batch: 800, loss is 4.76331262588501 and perplexity is 117.13330273812501
At time: 439.2015800476074 and batch: 850, loss is 4.713659744262696 and perplexity is 111.4593270200724
At time: 439.5595703125 and batch: 900, loss is 4.682955169677735 and perplexity is 108.08902246544207
At time: 439.91877937316895 and batch: 950, loss is 4.76369613647461 and perplexity is 117.1782332152261
At time: 440.2768383026123 and batch: 1000, loss is 4.812204627990723 and perplexity is 123.00249355732694
At time: 440.634978055954 and batch: 1050, loss is 4.710089693069458 and perplexity is 111.0621209615032
At time: 441.0121519565582 and batch: 1100, loss is 4.812890253067017 and perplexity is 123.08685606857833
At time: 441.3845980167389 and batch: 1150, loss is 4.777381057739258 and perplexity is 118.79283073264466
At time: 441.74288511276245 and batch: 1200, loss is 4.740204000473023 and perplexity is 114.45754869275126
At time: 442.11407709121704 and batch: 1250, loss is 4.752099885940551 and perplexity is 115.82725335534678
At time: 442.47235107421875 and batch: 1300, loss is 4.806214475631714 and perplexity is 122.2678922637907
At time: 442.8307092189789 and batch: 1350, loss is 4.730324974060059 and perplexity is 113.33238645065785
At time: 443.1882166862488 and batch: 1400, loss is 4.616755352020264 and perplexity is 101.16525339730727
At time: 443.546151638031 and batch: 1450, loss is 4.7042962837219235 and perplexity is 110.42055285953053
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.058790418836805 and perplexity of 157.40001304114185
Finished 39 epochs...
Completing Train Step...
At time: 444.7402539253235 and batch: 50, loss is 4.857942066192627 and perplexity is 128.75895186722366
At time: 445.1006474494934 and batch: 100, loss is 4.850347318649292 and perplexity is 127.7847641712595
At time: 445.46015334129333 and batch: 150, loss is 4.77145167350769 and perplexity is 118.09054650932612
At time: 445.82014989852905 and batch: 200, loss is 4.787214593887329 and perplexity is 119.96674674089884
At time: 446.18022179603577 and batch: 250, loss is 4.787455587387085 and perplexity is 119.99566143103651
At time: 446.539892911911 and batch: 300, loss is 4.823923244476318 and perplexity is 124.45239141220135
At time: 446.9000446796417 and batch: 350, loss is 4.851892080307007 and perplexity is 127.98231371959106
At time: 447.2600030899048 and batch: 400, loss is 4.751477642059326 and perplexity is 115.75520297444636
At time: 447.62109327316284 and batch: 450, loss is 4.794082670211792 and perplexity is 120.79352344672087
At time: 447.9817087650299 and batch: 500, loss is 4.77422872543335 and perplexity is 118.41894586889718
At time: 448.34459805488586 and batch: 550, loss is 4.8258336162567135 and perplexity is 124.69036898920635
At time: 448.70560216903687 and batch: 600, loss is 4.7262360382080075 and perplexity is 112.8699237270479
At time: 449.06564140319824 and batch: 650, loss is 4.8574848651885985 and perplexity is 128.70009660052105
At time: 449.4262590408325 and batch: 700, loss is 4.872861671447754 and perplexity is 130.69438666240237
At time: 449.8074462413788 and batch: 750, loss is 4.819923467636109 and perplexity is 123.9556038014216
At time: 450.17933988571167 and batch: 800, loss is 4.757589101791382 and perplexity is 116.46480237164836
At time: 450.5400822162628 and batch: 850, loss is 4.708467721939087 and perplexity is 110.8821274192509
At time: 450.90055990219116 and batch: 900, loss is 4.678318395614624 and perplexity is 107.58899823512115
At time: 451.27261328697205 and batch: 950, loss is 4.760517263412476 and perplexity is 116.80632991606028
At time: 451.6324062347412 and batch: 1000, loss is 4.809033155441284 and perplexity is 122.61301246624956
At time: 451.9919171333313 and batch: 1050, loss is 4.708423118591309 and perplexity is 110.87718181545534
At time: 452.3520133495331 and batch: 1100, loss is 4.811717557907104 and perplexity is 122.9425973105238
At time: 452.711674451828 and batch: 1150, loss is 4.778174552917481 and perplexity is 118.88712967897023
At time: 453.07140731811523 and batch: 1200, loss is 4.740690498352051 and perplexity is 114.51324559454281
At time: 453.43125581741333 and batch: 1250, loss is 4.75310245513916 and perplexity is 115.94343642297108
At time: 453.7912447452545 and batch: 1300, loss is 4.808662939071655 and perplexity is 122.56762752354774
At time: 454.1512653827667 and batch: 1350, loss is 4.7334977149963375 and perplexity is 113.69253177435135
At time: 454.51193165779114 and batch: 1400, loss is 4.620934753417969 and perplexity is 101.58894837771466
At time: 454.87137627601624 and batch: 1450, loss is 4.706277675628662 and perplexity is 110.63955614332205
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0566954001402245 and perplexity of 157.0706022523441
Finished 40 epochs...
Completing Train Step...
At time: 456.0747740268707 and batch: 50, loss is 4.850998754501343 and perplexity is 127.8680348678003
At time: 456.43259501457214 and batch: 100, loss is 4.845327072143554 and perplexity is 127.1448607358849
At time: 456.79072427749634 and batch: 150, loss is 4.765844411849976 and perplexity is 117.43023491577773
At time: 457.14869451522827 and batch: 200, loss is 4.7826727104187015 and perplexity is 119.42310726521295
At time: 457.5062518119812 and batch: 250, loss is 4.781759796142578 and perplexity is 119.31413395490515
At time: 457.8644742965698 and batch: 300, loss is 4.818895931243897 and perplexity is 123.82830032317631
At time: 458.2227039337158 and batch: 350, loss is 4.84796259880066 and perplexity is 127.48039636800047
At time: 458.5817639827728 and batch: 400, loss is 4.74735689163208 and perplexity is 115.27918611925
At time: 458.9393780231476 and batch: 450, loss is 4.7895023632049565 and perplexity is 120.24151716906256
At time: 459.29702711105347 and batch: 500, loss is 4.769403324127198 and perplexity is 117.84890338080719
At time: 459.6544964313507 and batch: 550, loss is 4.8217028141021725 and perplexity is 124.17636010972876
At time: 460.0125632286072 and batch: 600, loss is 4.721925678253174 and perplexity is 112.38446073944645
At time: 460.37029457092285 and batch: 650, loss is 4.8533303165435795 and perplexity is 128.16651495151424
At time: 460.7405204772949 and batch: 700, loss is 4.868906650543213 and perplexity is 130.1785084580429
At time: 461.09830045700073 and batch: 750, loss is 4.816930274963379 and perplexity is 123.58513551445212
At time: 461.456748008728 and batch: 800, loss is 4.754770431518555 and perplexity is 116.13698871171911
At time: 461.81417179107666 and batch: 850, loss is 4.7055198669433596 and perplexity is 110.55574428742568
At time: 462.17330861091614 and batch: 900, loss is 4.6761566925048825 and perplexity is 107.3566739615848
At time: 462.53191614151 and batch: 950, loss is 4.758296747207641 and perplexity is 116.54724732265761
At time: 462.89055490493774 and batch: 1000, loss is 4.8071621322631835 and perplexity is 122.38381516158624
At time: 463.24882531166077 and batch: 1050, loss is 4.707843971252442 and perplexity is 110.81298618182532
At time: 463.6075687408447 and batch: 1100, loss is 4.81057578086853 and perplexity is 122.80230438271488
At time: 463.96610045433044 and batch: 1150, loss is 4.778209228515625 and perplexity is 118.89125223277905
At time: 464.3242681026459 and batch: 1200, loss is 4.740011358261109 and perplexity is 114.43550146108275
At time: 464.68330240249634 and batch: 1250, loss is 4.75264570236206 and perplexity is 115.89049102879675
At time: 465.0432984828949 and batch: 1300, loss is 4.809232940673828 and perplexity is 122.63751118261744
At time: 465.4028742313385 and batch: 1350, loss is 4.733880567550659 and perplexity is 113.7360675839146
At time: 465.7636396884918 and batch: 1400, loss is 4.62277289390564 and perplexity is 101.77585486439189
At time: 466.125367641449 and batch: 1450, loss is 4.705681400299072 and perplexity is 110.57360417023831
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.055443396935096 and perplexity of 156.87407240856172
Finished 41 epochs...
Completing Train Step...
At time: 467.3121783733368 and batch: 50, loss is 4.846933355331421 and perplexity is 127.34925550209958
At time: 467.6964647769928 and batch: 100, loss is 4.842399864196778 and perplexity is 126.77322548134664
At time: 468.0698273181915 and batch: 150, loss is 4.7625653934478756 and perplexity is 117.0458096277665
At time: 468.4331135749817 and batch: 200, loss is 4.779594488143921 and perplexity is 119.05606161018821
At time: 468.79410195350647 and batch: 250, loss is 4.777976036071777 and perplexity is 118.8635309234444
At time: 469.16119480133057 and batch: 300, loss is 4.815453310012817 and perplexity is 123.4027393304292
At time: 469.5356638431549 and batch: 350, loss is 4.845086708068847 and perplexity is 127.11430335167617
At time: 469.91207218170166 and batch: 400, loss is 4.74474799156189 and perplexity is 114.9788262173397
At time: 470.3047571182251 and batch: 450, loss is 4.786479482650757 and perplexity is 119.87859024374026
At time: 470.6830418109894 and batch: 500, loss is 4.765742664337158 and perplexity is 117.41828728927639
At time: 471.0508282184601 and batch: 550, loss is 4.818816766738892 and perplexity is 123.81849790508257
At time: 471.41862750053406 and batch: 600, loss is 4.71919774055481 and perplexity is 112.07830071488247
At time: 471.80001163482666 and batch: 650, loss is 4.850216751098633 and perplexity is 127.76808071677267
At time: 472.17093873023987 and batch: 700, loss is 4.866021566390991 and perplexity is 129.8034737697885
At time: 472.5306408405304 and batch: 750, loss is 4.814758996963501 and perplexity is 123.31708893572495
At time: 472.89194989204407 and batch: 800, loss is 4.752545890808105 and perplexity is 115.87892439604992
At time: 473.25215220451355 and batch: 850, loss is 4.70347505569458 and perplexity is 110.32990963120153
At time: 473.61238408088684 and batch: 900, loss is 4.674339942932129 and perplexity is 107.16181083238294
At time: 473.973299741745 and batch: 950, loss is 4.756649780273437 and perplexity is 116.35545584051225
At time: 474.33414483070374 and batch: 1000, loss is 4.805819320678711 and perplexity is 122.2195870452211
At time: 474.6956205368042 and batch: 1050, loss is 4.706627521514893 and perplexity is 110.67826970838904
At time: 475.0556981563568 and batch: 1100, loss is 4.8095216464996335 and perplexity is 122.67292245803291
At time: 475.4157338142395 and batch: 1150, loss is 4.777886524200439 and perplexity is 118.85289170253296
At time: 475.77625799179077 and batch: 1200, loss is 4.738946905136109 and perplexity is 114.3137550421151
At time: 476.13678669929504 and batch: 1250, loss is 4.7518430519104005 and perplexity is 115.79750879493737
At time: 476.495881319046 and batch: 1300, loss is 4.808627309799195 and perplexity is 122.5632606059474
At time: 476.85627341270447 and batch: 1350, loss is 4.733428821563721 and perplexity is 113.68469937537807
At time: 477.2174210548401 and batch: 1400, loss is 4.622688255310059 and perplexity is 101.76724106350726
At time: 477.57909870147705 and batch: 1450, loss is 4.704468793869019 and perplexity is 110.43960316848522
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.054070366753472 and perplexity of 156.6588273752094
Finished 42 epochs...
Completing Train Step...
At time: 478.77688550949097 and batch: 50, loss is 4.843567409515381 and perplexity is 126.92132540714547
At time: 479.1496276855469 and batch: 100, loss is 4.839226732254028 and perplexity is 126.37159486055609
At time: 479.50979924201965 and batch: 150, loss is 4.759600229263306 and perplexity is 116.69926362191514
At time: 479.8708209991455 and batch: 200, loss is 4.776750183105468 and perplexity is 118.71791098402872
At time: 480.2308180332184 and batch: 250, loss is 4.774666528701783 and perplexity is 118.47080142087977
At time: 480.59177684783936 and batch: 300, loss is 4.81259578704834 and perplexity is 123.05061650804186
At time: 480.95279812812805 and batch: 350, loss is 4.843181734085083 and perplexity is 126.87238440863206
At time: 481.3136065006256 and batch: 400, loss is 4.742231588363648 and perplexity is 114.6898568655032
At time: 481.6748671531677 and batch: 450, loss is 4.78376467704773 and perplexity is 119.55358453853057
At time: 482.03532671928406 and batch: 500, loss is 4.762452192306519 and perplexity is 117.032560658439
At time: 482.3960647583008 and batch: 550, loss is 4.8160804271697994 and perplexity is 123.48015157621867
At time: 482.75730085372925 and batch: 600, loss is 4.716323175430298 and perplexity is 111.7565869555393
At time: 483.11854696273804 and batch: 650, loss is 4.847736015319824 and perplexity is 127.45151468823244
At time: 483.4798974990845 and batch: 700, loss is 4.863228120803833 and perplexity is 129.44138080774312
At time: 483.8404948711395 and batch: 750, loss is 4.812477617263794 and perplexity is 123.03607650231243
At time: 484.2015104293823 and batch: 800, loss is 4.749945831298828 and perplexity is 115.57802364619239
At time: 484.5628037452698 and batch: 850, loss is 4.701285991668701 and perplexity is 110.08865455279728
At time: 484.9230935573578 and batch: 900, loss is 4.672159414291382 and perplexity is 106.92839601100515
At time: 485.28348183631897 and batch: 950, loss is 4.754727983474732 and perplexity is 116.13205902836125
At time: 485.6450951099396 and batch: 1000, loss is 4.804121446609497 and perplexity is 122.01224964383469
At time: 486.0065722465515 and batch: 1050, loss is 4.705011920928955 and perplexity is 110.49960219752786
At time: 486.3674840927124 and batch: 1100, loss is 4.807827253341674 and perplexity is 122.46524229316529
At time: 486.72896814346313 and batch: 1150, loss is 4.77671612739563 and perplexity is 118.7138680301428
At time: 487.08830308914185 and batch: 1200, loss is 4.7376344108581545 and perplexity is 114.16381731046238
At time: 487.4487738609314 and batch: 1250, loss is 4.750487241744995 and perplexity is 115.64061573801901
At time: 487.80871629714966 and batch: 1300, loss is 4.807416677474976 and perplexity is 122.41497134089639
At time: 488.16883969306946 and batch: 1350, loss is 4.7325786781311034 and perplexity is 113.58809214563448
At time: 488.52858209609985 and batch: 1400, loss is 4.622041254043579 and perplexity is 101.70141882548491
At time: 488.8893485069275 and batch: 1450, loss is 4.70283447265625 and perplexity is 110.25925679439183
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.053004077357104 and perplexity of 156.4918727555207
Finished 43 epochs...
Completing Train Step...
At time: 490.0881185531616 and batch: 50, loss is 4.8405867767333985 and perplexity is 126.54358277959452
At time: 490.44951915740967 and batch: 100, loss is 4.836842222213745 and perplexity is 126.0706195057915
At time: 490.8115608692169 and batch: 150, loss is 4.757354984283447 and perplexity is 116.43753911388251
At time: 491.17405676841736 and batch: 200, loss is 4.7746905422210695 and perplexity is 118.47364635591292
At time: 491.53692269325256 and batch: 250, loss is 4.771931591033936 and perplexity is 118.14723383381211
At time: 491.89965319633484 and batch: 300, loss is 4.810164308547973 and perplexity is 122.75178502793169
At time: 492.2614150047302 and batch: 350, loss is 4.8412758731842045 and perplexity is 126.63081356512075
At time: 492.6230878829956 and batch: 400, loss is 4.740503292083741 and perplexity is 114.49181000366404
At time: 492.9855487346649 and batch: 450, loss is 4.78127968788147 and perplexity is 119.25686400251514
At time: 493.34835624694824 and batch: 500, loss is 4.759839582443237 and perplexity is 116.72719930487257
At time: 493.71097683906555 and batch: 550, loss is 4.813680906295776 and perplexity is 123.18421357168711
At time: 494.0733916759491 and batch: 600, loss is 4.714464588165283 and perplexity is 111.5490704897087
At time: 494.4361581802368 and batch: 650, loss is 4.845618476867676 and perplexity is 127.18191674783738
At time: 494.7983465194702 and batch: 700, loss is 4.86113956451416 and perplexity is 129.17131731728358
At time: 495.16116762161255 and batch: 750, loss is 4.8105642604827885 and perplexity is 122.80088966094755
At time: 495.52401208877563 and batch: 800, loss is 4.747889413833618 and perplexity is 115.34059119356527
At time: 495.88695669174194 and batch: 850, loss is 4.699429607391357 and perplexity is 109.88447727974689
At time: 496.24964141845703 and batch: 900, loss is 4.669958667755127 and perplexity is 106.69333246637075
At time: 496.61198925971985 and batch: 950, loss is 4.752817068099976 and perplexity is 115.9103523900391
At time: 496.97482466697693 and batch: 1000, loss is 4.802572832107544 and perplexity is 121.82344593443406
At time: 497.3380677700043 and batch: 1050, loss is 4.703186492919922 and perplexity is 110.29807711941051
At time: 497.71408867836 and batch: 1100, loss is 4.80648567199707 and perplexity is 122.30105536842579
At time: 498.0769085884094 and batch: 1150, loss is 4.775890817642212 and perplexity is 118.61593273602728
At time: 498.44005703926086 and batch: 1200, loss is 4.736229705810547 and perplexity is 114.0035634011209
At time: 498.80291223526 and batch: 1250, loss is 4.749320592880249 and perplexity is 115.50578241181627
At time: 499.1661112308502 and batch: 1300, loss is 4.80643892288208 and perplexity is 122.29533803596615
At time: 499.5293731689453 and batch: 1350, loss is 4.731726455688476 and perplexity is 113.491331061133
At time: 499.8928098678589 and batch: 1400, loss is 4.620915069580078 and perplexity is 101.58694873700362
At time: 500.2561228275299 and batch: 1450, loss is 4.701296787261963 and perplexity is 110.08984303154975
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0518939678485575 and perplexity of 156.31824602973472
Finished 44 epochs...
Completing Train Step...
At time: 501.4705617427826 and batch: 50, loss is 4.838075113296509 and perplexity is 126.22614670272546
At time: 501.83188247680664 and batch: 100, loss is 4.83465654373169 and perplexity is 125.7953705779241
At time: 502.19311904907227 and batch: 150, loss is 4.755262002944947 and perplexity is 116.19409237103072
At time: 502.5546290874481 and batch: 200, loss is 4.772711133956909 and perplexity is 118.23937058142499
At time: 502.91594672203064 and batch: 250, loss is 4.769486780166626 and perplexity is 117.85873899394929
At time: 503.2770974636078 and batch: 300, loss is 4.807750959396362 and perplexity is 122.4558992930788
At time: 503.63814306259155 and batch: 350, loss is 4.8397507476806645 and perplexity is 126.43783287910773
At time: 503.99958205223083 and batch: 400, loss is 4.738635892868042 and perplexity is 114.27820759002165
At time: 504.36117696762085 and batch: 450, loss is 4.778882675170898 and perplexity is 118.9713461153881
At time: 504.72274446487427 and batch: 500, loss is 4.757011995315552 and perplexity is 116.39760917067406
At time: 505.0841519832611 and batch: 550, loss is 4.811516485214233 and perplexity is 122.91787939654606
At time: 505.44834423065186 and batch: 600, loss is 4.711833324432373 and perplexity is 111.25594128533606
At time: 505.80893659591675 and batch: 650, loss is 4.843425559997558 and perplexity is 126.90332295518483
At time: 506.17012190818787 and batch: 700, loss is 4.858597393035889 and perplexity is 128.84335871870954
At time: 506.53108763694763 and batch: 750, loss is 4.808454246520996 and perplexity is 122.54205124161419
At time: 506.91299700737 and batch: 800, loss is 4.745838184356689 and perplexity is 115.10424365740931
At time: 507.2740867137909 and batch: 850, loss is 4.697373476028442 and perplexity is 109.65877247859194
At time: 507.6347312927246 and batch: 900, loss is 4.667759895324707 and perplexity is 106.45899582931287
At time: 507.99464440345764 and batch: 950, loss is 4.751193332672119 and perplexity is 115.72229736153163
At time: 508.35692262649536 and batch: 1000, loss is 4.8005766010284425 and perplexity is 121.58050075353358
At time: 508.7172248363495 and batch: 1050, loss is 4.701375427246094 and perplexity is 110.09850083547903
At time: 509.09682178497314 and batch: 1100, loss is 4.8050362014770505 and perplexity is 122.12391200715632
At time: 509.47112584114075 and batch: 1150, loss is 4.774696493148804 and perplexity is 118.47435138611863
At time: 509.83283948898315 and batch: 1200, loss is 4.734284868240357 and perplexity is 113.7820604513298
At time: 510.1948323249817 and batch: 1250, loss is 4.748346242904663 and perplexity is 115.39329416590245
At time: 510.5559928417206 and batch: 1300, loss is 4.805030174255371 and perplexity is 122.12317594148455
At time: 510.91739773750305 and batch: 1350, loss is 4.7305083751678465 and perplexity is 113.35317364201981
At time: 511.2792856693268 and batch: 1400, loss is 4.619703779220581 and perplexity is 101.4639719406879
At time: 511.6414451599121 and batch: 1450, loss is 4.699588222503662 and perplexity is 109.90190800080254
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.050366523938301 and perplexity of 156.07966093583565
Finished 45 epochs...
Completing Train Step...
At time: 512.832367181778 and batch: 50, loss is 4.835443992614746 and perplexity is 125.89446701354747
At time: 513.2055940628052 and batch: 100, loss is 4.8325959587097165 and perplexity is 125.53642540237644
At time: 513.5665280818939 and batch: 150, loss is 4.753535327911377 and perplexity is 115.99363604395646
At time: 513.9293565750122 and batch: 200, loss is 4.7707418441772464 and perplexity is 118.00675211914195
At time: 514.2906239032745 and batch: 250, loss is 4.7671748065948485 and perplexity is 117.58656745213284
At time: 514.6518115997314 and batch: 300, loss is 4.805631456375122 and perplexity is 122.1966285042286
At time: 515.012647151947 and batch: 350, loss is 4.838063077926636 and perplexity is 126.22462753350412
At time: 515.3747367858887 and batch: 400, loss is 4.7367133617401125 and perplexity is 114.05871523673254
At time: 515.7358992099762 and batch: 450, loss is 4.776488523483277 and perplexity is 118.6868513639947
At time: 516.1101038455963 and batch: 500, loss is 4.753967981338501 and perplexity is 116.04383194604708
At time: 516.470956325531 and batch: 550, loss is 4.809697122573852 and perplexity is 122.69445050965254
At time: 516.8319780826569 and batch: 600, loss is 4.710270671844483 and perplexity is 111.08222266704263
At time: 517.192713022232 and batch: 650, loss is 4.840666160583496 and perplexity is 126.55362869513719
At time: 517.5540850162506 and batch: 700, loss is 4.856557817459106 and perplexity is 128.58084075465356
At time: 517.9147372245789 and batch: 750, loss is 4.805910606384277 and perplexity is 122.23074445570684
At time: 518.2912926673889 and batch: 800, loss is 4.7433180999755855 and perplexity is 114.81453644740036
At time: 518.6650931835175 and batch: 850, loss is 4.6953584003448485 and perplexity is 109.43802423957814
At time: 519.0267164707184 and batch: 900, loss is 4.665355014801025 and perplexity is 106.20328226719704
At time: 519.3877937793732 and batch: 950, loss is 4.749138565063476 and perplexity is 115.48475905989471
At time: 519.7484047412872 and batch: 1000, loss is 4.798780918121338 and perplexity is 121.36237662598833
At time: 520.1092984676361 and batch: 1050, loss is 4.699282293319702 and perplexity is 109.86829094225403
At time: 520.4705474376678 and batch: 1100, loss is 4.803440389633178 and perplexity is 121.92918064059135
At time: 520.8319873809814 and batch: 1150, loss is 4.773259763717651 and perplexity is 118.30425801697896
At time: 521.193416595459 and batch: 1200, loss is 4.732620258331298 and perplexity is 113.59281525943898
At time: 521.5545380115509 and batch: 1250, loss is 4.746352663040161 and perplexity is 115.1634775731352
At time: 521.9149854183197 and batch: 1300, loss is 4.80315372467041 and perplexity is 121.89423282595895
At time: 522.275340795517 and batch: 1350, loss is 4.729121694564819 and perplexity is 113.19609792693234
At time: 522.6464560031891 and batch: 1400, loss is 4.618401498794555 and perplexity is 101.33192339686184
At time: 523.0211107730865 and batch: 1450, loss is 4.697462635040283 and perplexity is 109.66854998225563
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.049531855134883 and perplexity of 155.94944046504673
Finished 46 epochs...
Completing Train Step...
At time: 524.2174386978149 and batch: 50, loss is 4.83342077255249 and perplexity is 125.64001229790061
At time: 524.5928158760071 and batch: 100, loss is 4.8302889156341555 and perplexity is 125.24714128518922
At time: 524.9557588100433 and batch: 150, loss is 4.75174955368042 and perplexity is 115.78668243895935
At time: 525.3317523002625 and batch: 200, loss is 4.769177923202514 and perplexity is 117.8223431224781
At time: 525.6943628787994 and batch: 250, loss is 4.76529260635376 and perplexity is 117.36545414156663
At time: 526.0569112300873 and batch: 300, loss is 4.803145751953125 and perplexity is 121.89326100157605
At time: 526.4201767444611 and batch: 350, loss is 4.836150255203247 and perplexity is 125.98341297160249
At time: 526.7839705944061 and batch: 400, loss is 4.734259004592896 and perplexity is 113.77911767028658
At time: 527.1465148925781 and batch: 450, loss is 4.774140625 and perplexity is 118.4085135680012
At time: 527.5092926025391 and batch: 500, loss is 4.750731134414673 and perplexity is 115.66882307615623
At time: 527.8719093799591 and batch: 550, loss is 4.807273244857788 and perplexity is 122.39741430033023
At time: 528.2342143058777 and batch: 600, loss is 4.709070529937744 and perplexity is 110.94898820265023
At time: 528.5969395637512 and batch: 650, loss is 4.838166999816894 and perplexity is 126.237745717016
At time: 528.9594242572784 and batch: 700, loss is 4.854152421951294 and perplexity is 128.27192465955252
At time: 529.3299045562744 and batch: 750, loss is 4.8040321159362795 and perplexity is 122.0013506942457
At time: 529.7094509601593 and batch: 800, loss is 4.740985593795776 and perplexity is 114.5470429180368
At time: 530.072295665741 and batch: 850, loss is 4.693731021881104 and perplexity is 109.26007199291624
At time: 530.4345812797546 and batch: 900, loss is 4.663677396774292 and perplexity is 106.02526309220738
At time: 530.7972686290741 and batch: 950, loss is 4.747326107025146 and perplexity is 115.27563734944168
At time: 531.1601490974426 and batch: 1000, loss is 4.796957635879517 and perplexity is 121.14130036331761
At time: 531.5232560634613 and batch: 1050, loss is 4.697220497131347 and perplexity is 109.64199828360302
At time: 531.886602640152 and batch: 1100, loss is 4.8015830707550045 and perplexity is 121.7029294469342
At time: 532.2497911453247 and batch: 1150, loss is 4.771740159988403 and perplexity is 118.12461894997699
At time: 532.6131820678711 and batch: 1200, loss is 4.730381212234497 and perplexity is 113.33876023639992
At time: 532.97660779953 and batch: 1250, loss is 4.744509983062744 and perplexity is 114.95146353588271
At time: 533.3405435085297 and batch: 1300, loss is 4.801087169647217 and perplexity is 121.64259179139212
At time: 533.7042369842529 and batch: 1350, loss is 4.7269620609283445 and perplexity is 112.95189961069262
At time: 534.0682785511017 and batch: 1400, loss is 4.61648850440979 and perplexity is 101.13826129272466
At time: 534.4332971572876 and batch: 1450, loss is 4.695239810943604 and perplexity is 109.42504681931761
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.047981457832532 and perplexity of 155.70784420673456
Finished 47 epochs...
Completing Train Step...
At time: 535.6530516147614 and batch: 50, loss is 4.8312047004699705 and perplexity is 125.36189325394396
At time: 536.0149924755096 and batch: 100, loss is 4.8280056190490725 and perplexity is 124.96149115129069
At time: 536.3775641918182 and batch: 150, loss is 4.749508543014526 and perplexity is 115.52749377939371
At time: 536.7393682003021 and batch: 200, loss is 4.767360610961914 and perplexity is 117.6084175797354
At time: 537.1011743545532 and batch: 250, loss is 4.76268310546875 and perplexity is 117.05958813748491
At time: 537.4634230136871 and batch: 300, loss is 4.800839061737061 and perplexity is 121.6124150458562
At time: 537.8258333206177 and batch: 350, loss is 4.833844966888428 and perplexity is 125.69331938496744
At time: 538.1884977817535 and batch: 400, loss is 4.731888523101807 and perplexity is 113.50972579814696
At time: 538.550778388977 and batch: 450, loss is 4.771308174133301 and perplexity is 118.07360180558699
At time: 538.9136884212494 and batch: 500, loss is 4.747257070541382 and perplexity is 115.267679399473
At time: 539.276798248291 and batch: 550, loss is 4.804936408996582 and perplexity is 122.11172556712027
At time: 539.6396446228027 and batch: 600, loss is 4.7068289852142335 and perplexity is 110.70056960827587
At time: 540.0032951831818 and batch: 650, loss is 4.835683736801148 and perplexity is 125.92465309843872
At time: 540.3661465644836 and batch: 700, loss is 4.852077655792236 and perplexity is 128.00606630344083
At time: 540.7288846969604 and batch: 750, loss is 4.801702356338501 and perplexity is 121.71744771777948
At time: 541.0919103622437 and batch: 800, loss is 4.738688306808472 and perplexity is 114.28419751816317
At time: 541.4546294212341 and batch: 850, loss is 4.69179443359375 and perplexity is 109.04868496810255
At time: 541.8170201778412 and batch: 900, loss is 4.661438074111938 and perplexity is 105.78810395480261
At time: 542.1791274547577 and batch: 950, loss is 4.745661897659302 and perplexity is 115.08395409888185
At time: 542.541253566742 and batch: 1000, loss is 4.795255060195923 and perplexity is 120.93522361145405
At time: 542.9226245880127 and batch: 1050, loss is 4.6954645156860355 and perplexity is 109.44963790904251
At time: 543.293372631073 and batch: 1100, loss is 4.799740352630615 and perplexity is 121.47887175403794
At time: 543.6558811664581 and batch: 1150, loss is 4.770440282821656 and perplexity is 117.97117120818756
At time: 544.0365173816681 and batch: 1200, loss is 4.728524150848389 and perplexity is 113.12847851468116
At time: 544.3990561962128 and batch: 1250, loss is 4.742464570999146 and perplexity is 114.71658072359718
At time: 544.76083111763 and batch: 1300, loss is 4.7988809394836425 and perplexity is 121.37451606332239
At time: 545.1225910186768 and batch: 1350, loss is 4.724983358383179 and perplexity is 112.72862237192109
At time: 545.4871122837067 and batch: 1400, loss is 4.614818897247314 and perplexity is 100.96954101475583
At time: 545.8496234416962 and batch: 1450, loss is 4.692981882095337 and perplexity is 109.17825157728146
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.046602689302885 and perplexity of 155.49330706383998
Finished 48 epochs...
Completing Train Step...
At time: 547.0711677074432 and batch: 50, loss is 4.828562383651733 and perplexity is 125.03108465806224
At time: 547.4338271617889 and batch: 100, loss is 4.825642175674439 and perplexity is 124.66650047713684
At time: 547.796537399292 and batch: 150, loss is 4.7470315647125245 and perplexity is 115.24168879651592
At time: 548.158929347992 and batch: 200, loss is 4.764890460968018 and perplexity is 117.31826565469018
At time: 548.5215828418732 and batch: 250, loss is 4.759917297363281 and perplexity is 116.73627110233598
At time: 548.8836193084717 and batch: 300, loss is 4.798179750442505 and perplexity is 121.28943941367837
At time: 549.2464361190796 and batch: 350, loss is 4.831805620193482 and perplexity is 125.43724832708422
At time: 549.6093904972076 and batch: 400, loss is 4.729518928527832 and perplexity is 113.24107219357116
At time: 549.9716002941132 and batch: 450, loss is 4.768306255340576 and perplexity is 117.7196859205518
At time: 550.3427085876465 and batch: 500, loss is 4.7441485977172855 and perplexity is 114.90992926691193
At time: 550.7175295352936 and batch: 550, loss is 4.801906805038453 and perplexity is 121.7423352357505
At time: 551.079577922821 and batch: 600, loss is 4.703966722488404 and perplexity is 110.38416852168713
At time: 551.4408757686615 and batch: 650, loss is 4.833139591217041 and perplexity is 125.60468963772595
At time: 551.8037157058716 and batch: 700, loss is 4.8494675350189205 and perplexity is 127.67239066696378
At time: 552.1660258769989 and batch: 750, loss is 4.7987658977508545 and perplexity is 121.36055373181897
At time: 552.528669834137 and batch: 800, loss is 4.736096448898316 and perplexity is 113.98837265043748
At time: 552.8912546634674 and batch: 850, loss is 4.6892028903961185 and perplexity is 108.76644646496098
At time: 553.2671158313751 and batch: 900, loss is 4.659736051559448 and perplexity is 105.60820335695293
At time: 553.6290144920349 and batch: 950, loss is 4.743686246871948 and perplexity is 114.85681284413542
At time: 553.9905705451965 and batch: 1000, loss is 4.793372011184692 and perplexity is 120.70771093419809
At time: 554.3689558506012 and batch: 1050, loss is 4.693155317306519 and perplexity is 109.19718857252366
At time: 554.7432017326355 and batch: 1100, loss is 4.797171106338501 and perplexity is 121.16716321268706
At time: 555.1080873012543 and batch: 1150, loss is 4.768407096862793 and perplexity is 117.73155755144153
At time: 555.4718322753906 and batch: 1200, loss is 4.725404739379883 and perplexity is 112.7761340807358
At time: 555.8342177867889 and batch: 1250, loss is 4.740390634536743 and perplexity is 114.47891236371957
At time: 556.1952877044678 and batch: 1300, loss is 4.796731252670288 and perplexity is 121.11387911094381
At time: 556.558242559433 and batch: 1350, loss is 4.722296714782715 and perplexity is 112.42616721656832
At time: 556.9206516742706 and batch: 1400, loss is 4.612576217651367 and perplexity is 100.7433524143927
At time: 557.2830948829651 and batch: 1450, loss is 4.690608310699463 and perplexity is 108.91941650556693
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.044771112947383 and perplexity of 155.2087698545395
Finished 49 epochs...
Completing Train Step...
At time: 558.4841320514679 and batch: 50, loss is 4.8255982589721675 and perplexity is 124.66102565577111
At time: 558.8596413135529 and batch: 100, loss is 4.822599840164185 and perplexity is 124.28779951558617
At time: 559.2221517562866 and batch: 150, loss is 4.7443006896972655 and perplexity is 114.92740747468743
At time: 559.5853598117828 and batch: 200, loss is 4.762388734817505 and perplexity is 117.02513430163823
At time: 559.9474194049835 and batch: 250, loss is 4.75688588142395 and perplexity is 116.38293074080482
At time: 560.3102285861969 and batch: 300, loss is 4.79502347946167 and perplexity is 120.9072205861788
At time: 560.672102689743 and batch: 350, loss is 4.829180326461792 and perplexity is 125.10837059454558
At time: 561.0576088428497 and batch: 400, loss is 4.727381181716919 and perplexity is 112.99925002200618
At time: 561.418993473053 and batch: 450, loss is 4.766329231262207 and perplexity is 117.48718117645869
At time: 561.7814288139343 and batch: 500, loss is 4.740778875350952 and perplexity is 114.52336637873859
At time: 562.1606516838074 and batch: 550, loss is 4.798703184127808 and perplexity is 121.35294301044995
At time: 562.5472824573517 and batch: 600, loss is 4.7005288028717045 and perplexity is 110.00532820776208
At time: 562.9098193645477 and batch: 650, loss is 4.829954719543457 and perplexity is 125.20529117366183
At time: 563.2724301815033 and batch: 700, loss is 4.846524095535278 and perplexity is 127.29714723539044
At time: 563.6346659660339 and batch: 750, loss is 4.795944547653198 and perplexity is 121.01863568376125
At time: 563.9974431991577 and batch: 800, loss is 4.73389404296875 and perplexity is 113.73760023530383
At time: 564.3599543571472 and batch: 850, loss is 4.687135553359985 and perplexity is 108.54182182931119
At time: 564.7217037677765 and batch: 900, loss is 4.656958742141724 and perplexity is 105.31530362404624
At time: 565.0838901996613 and batch: 950, loss is 4.7418217372894285 and perplexity is 114.64286073582979
At time: 565.4570050239563 and batch: 1000, loss is 4.791136178970337 and perplexity is 120.43813022648729
At time: 565.8324675559998 and batch: 1050, loss is 4.691172800064087 and perplexity is 108.98091771454148
At time: 566.1977171897888 and batch: 1100, loss is 4.795113983154297 and perplexity is 120.91816363129267
At time: 566.5596973896027 and batch: 1150, loss is 4.7661816501617436 and perplexity is 117.46984356835338
At time: 566.9222297668457 and batch: 1200, loss is 4.723431634902954 and perplexity is 112.55383436808982
At time: 567.2835412025452 and batch: 1250, loss is 4.738200235366821 and perplexity is 114.22843227494093
At time: 567.6447432041168 and batch: 1300, loss is 4.794976205825805 and perplexity is 120.9015049973588
At time: 568.0060799121857 and batch: 1350, loss is 4.720052509307862 and perplexity is 112.17414269976022
At time: 568.3685631752014 and batch: 1400, loss is 4.610375690460205 and perplexity is 100.52190766503102
At time: 568.7294020652771 and batch: 1450, loss is 4.688263931274414 and perplexity is 108.6643671495693
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.044654780982906 and perplexity of 155.19071516362752
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f83117ed8d0>
SETTINGS FOR THIS RUN
{'batch_size': 20, 'seq_len': 35, 'anneal': 6.072075262495876, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'dropout': 0.39702696090568435, 'lr': 2.9194512100577086, 'num_layers': 1, 'wordvec_dim': 200, 'data': 'ptb'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.5832338333129883 and batch: 50, loss is 6.8100347900390625 and perplexity is 906.902357567191
At time: 0.9597682952880859 and batch: 100, loss is 6.1020505905151365 and perplexity is 446.77297983646974
At time: 1.3239612579345703 and batch: 150, loss is 5.9083983516693115 and perplexity is 368.1160904754292
At time: 1.687328815460205 and batch: 200, loss is 5.7288973903656 and perplexity is 307.6298856327246
At time: 2.0514109134674072 and batch: 250, loss is 5.6415876770019535 and perplexity is 281.90994529223224
At time: 2.415316343307495 and batch: 300, loss is 5.665341873168945 and perplexity is 288.68665847084776
At time: 2.7787985801696777 and batch: 350, loss is 5.653218050003051 and perplexity is 285.20780359598047
At time: 3.1425929069519043 and batch: 400, loss is 5.498975515365601 and perplexity is 244.4413775061186
At time: 3.5070724487304688 and batch: 450, loss is 5.508453569412231 and perplexity is 246.76922037712797
At time: 3.8918769359588623 and batch: 500, loss is 5.461753835678101 and perplexity is 235.5101084001294
At time: 4.27522611618042 and batch: 550, loss is 5.5038605976104735 and perplexity is 245.63841517250046
At time: 4.6486496925354 and batch: 600, loss is 5.306765794754028 and perplexity is 201.69684337812296
At time: 5.012970447540283 and batch: 650, loss is 5.468030204772949 and perplexity is 236.99290518835988
At time: 5.3763511180877686 and batch: 700, loss is 5.4369503688812255 and perplexity is 229.74049030335306
At time: 5.739622592926025 and batch: 750, loss is 5.359739208221436 and perplexity is 212.66947676575035
At time: 6.102882385253906 and batch: 800, loss is 5.273315076828003 and perplexity is 195.06153576884893
At time: 6.467116594314575 and batch: 850, loss is 5.203568620681763 and perplexity is 181.92028937665148
At time: 6.830795049667358 and batch: 900, loss is 5.181459398269653 and perplexity is 177.94231029063022
At time: 7.194296836853027 and batch: 950, loss is 5.200684890747071 and perplexity is 181.3964360811888
At time: 7.557682514190674 and batch: 1000, loss is 5.237465009689331 and perplexity is 188.19243122586087
At time: 7.921591758728027 and batch: 1050, loss is 5.141207275390625 and perplexity is 170.9219937275897
At time: 8.285062551498413 and batch: 1100, loss is 5.227972345352173 and perplexity is 186.4144359529424
At time: 8.648865461349487 and batch: 1150, loss is 5.186149644851684 and perplexity is 178.77886389103168
At time: 9.013075590133667 and batch: 1200, loss is 5.124805727005005 and perplexity is 168.14147313107446
At time: 9.37682294845581 and batch: 1250, loss is 5.132895221710205 and perplexity is 169.50716913541203
At time: 9.7404465675354 and batch: 1300, loss is 5.208333082199097 and perplexity is 182.78910968153835
At time: 10.103604078292847 and batch: 1350, loss is 5.123629016876221 and perplexity is 167.94373571919647
At time: 10.467067241668701 and batch: 1400, loss is 4.986053600311279 and perplexity is 146.35769633518726
At time: 10.83078646659851 and batch: 1450, loss is 5.0601396656036375 and perplexity is 157.61252783504654
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.985830975393964 and perplexity of 146.32511709175245
Finished 1 epochs...
Completing Train Step...
At time: 12.015652418136597 and batch: 50, loss is 4.964664506912231 and perplexity is 143.26047930949798
At time: 12.38678789138794 and batch: 100, loss is 4.916455631256103 and perplexity is 136.51788494173047
At time: 12.7455735206604 and batch: 150, loss is 4.780711212158203 and perplexity is 119.1890886366471
At time: 13.11696481704712 and batch: 200, loss is 4.816368446350098 and perplexity is 123.51572135040149
At time: 13.475818395614624 and batch: 250, loss is 4.828329181671142 and perplexity is 125.00193056101325
At time: 13.833858966827393 and batch: 300, loss is 4.842401723861695 and perplexity is 126.77346123728572
At time: 14.192658424377441 and batch: 350, loss is 4.847483520507812 and perplexity is 127.41933790439708
At time: 14.553376197814941 and batch: 400, loss is 4.694226903915405 and perplexity is 109.31426553537554
At time: 14.923067808151245 and batch: 450, loss is 4.7419760799407955 and perplexity is 114.66055638447759
At time: 15.286761045455933 and batch: 500, loss is 4.708698205947876 and perplexity is 110.9076869218967
At time: 15.651679277420044 and batch: 550, loss is 4.774777545928955 and perplexity is 118.4839544508473
At time: 16.017318725585938 and batch: 600, loss is 4.6347877788543705 and perplexity is 103.00605561235255
At time: 16.382784843444824 and batch: 650, loss is 4.749299058914184 and perplexity is 115.50329514099806
At time: 16.762144327163696 and batch: 700, loss is 4.768113393783569 and perplexity is 117.69698450782002
At time: 17.136854887008667 and batch: 750, loss is 4.697096195220947 and perplexity is 109.62837042075851
At time: 17.49681830406189 and batch: 800, loss is 4.604803032875061 and perplexity is 99.96329142794261
At time: 17.855541706085205 and batch: 850, loss is 4.554861273765564 and perplexity is 95.09356234867563
At time: 18.21395969390869 and batch: 900, loss is 4.51064661026001 and perplexity is 90.98062850276035
At time: 18.573542594909668 and batch: 950, loss is 4.578324031829834 and perplexity is 97.35110006234709
At time: 18.93307089805603 and batch: 1000, loss is 4.597518644332886 and perplexity is 99.23776568709378
At time: 19.29178261756897 and batch: 1050, loss is 4.546084413528442 and perplexity is 94.26259143463888
At time: 19.651095151901245 and batch: 1100, loss is 4.655255908966065 and perplexity is 105.13612183277684
At time: 20.010283946990967 and batch: 1150, loss is 4.590494651794433 and perplexity is 98.54316266038285
At time: 20.368579149246216 and batch: 1200, loss is 4.517753934860229 and perplexity is 91.62956071612211
At time: 20.72644829750061 and batch: 1250, loss is 4.461784472465515 and perplexity is 86.64198145977136
At time: 21.085780382156372 and batch: 1300, loss is 4.567270154953003 and perplexity is 96.28091871181452
At time: 21.444700479507446 and batch: 1350, loss is 4.5259700202941895 and perplexity is 92.38549818626149
At time: 21.80258798599243 and batch: 1400, loss is 4.364551038742065 and perplexity is 78.6140973335879
At time: 22.16097855567932 and batch: 1450, loss is 4.476895542144775 and perplexity is 87.96117660113393
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.621391100761218 and perplexity of 101.63531880411601
Finished 2 epochs...
Completing Train Step...
At time: 23.362152338027954 and batch: 50, loss is 4.521882514953614 and perplexity is 92.00864269315264
At time: 23.72010111808777 and batch: 100, loss is 4.510896244049072 and perplexity is 91.00334317684188
At time: 24.079187154769897 and batch: 150, loss is 4.363329067230224 and perplexity is 78.51809181616721
At time: 24.437955379486084 and batch: 200, loss is 4.462603769302368 and perplexity is 86.71299604816146
At time: 24.79699969291687 and batch: 250, loss is 4.508401470184326 and perplexity is 90.77659337702259
At time: 25.15613079071045 and batch: 300, loss is 4.511395244598389 and perplexity is 91.04876522694823
At time: 25.514920473098755 and batch: 350, loss is 4.516378269195557 and perplexity is 91.5035957382887
At time: 25.87318205833435 and batch: 400, loss is 4.344192676544189 and perplexity is 77.0298243856128
At time: 26.232686758041382 and batch: 450, loss is 4.422465867996216 and perplexity is 83.30144267048345
At time: 26.591654300689697 and batch: 500, loss is 4.395148143768311 and perplexity is 81.05663790910003
At time: 26.95057702064514 and batch: 550, loss is 4.4717648983001705 and perplexity is 87.51103487771431
At time: 27.308309078216553 and batch: 600, loss is 4.360632839202881 and perplexity is 78.30667427938059
At time: 27.665658950805664 and batch: 650, loss is 4.453983960151672 and perplexity is 85.96875877111897
At time: 28.022900342941284 and batch: 700, loss is 4.489128952026367 and perplexity is 89.0438506233199
At time: 28.379716873168945 and batch: 750, loss is 4.425067887306214 and perplexity is 83.51847687400438
At time: 28.73694157600403 and batch: 800, loss is 4.333748068809509 and perplexity is 76.2294650814318
At time: 29.094269514083862 and batch: 850, loss is 4.298806843757629 and perplexity is 73.61191077014061
At time: 29.45177698135376 and batch: 900, loss is 4.234147801399231 and perplexity is 69.00284953817402
At time: 29.80944037437439 and batch: 950, loss is 4.344572877883911 and perplexity is 77.05911679619675
At time: 30.166923999786377 and batch: 1000, loss is 4.361725287437439 and perplexity is 78.39226701175336
At time: 30.524510383605957 and batch: 1050, loss is 4.308378086090088 and perplexity is 74.31985073471031
At time: 30.88282561302185 and batch: 1100, loss is 4.434548931121826 and perplexity is 84.3140848499294
At time: 31.240626573562622 and batch: 1150, loss is 4.367222785949707 and perplexity is 78.82441516154687
At time: 31.611277103424072 and batch: 1200, loss is 4.301585893630982 and perplexity is 73.81676646169176
At time: 31.969002723693848 and batch: 1250, loss is 4.216422052383423 and perplexity is 67.79049899999633
At time: 32.325634717941284 and batch: 1300, loss is 4.335955491065979 and perplexity is 76.39792155813598
At time: 32.69121956825256 and batch: 1350, loss is 4.313190002441406 and perplexity is 74.67833344238129
At time: 33.06558084487915 and batch: 1400, loss is 4.153704342842102 and perplexity is 63.669417346600376
At time: 33.42903137207031 and batch: 1450, loss is 4.272796840667724 and perplexity is 71.72195023179158
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.49912829276843 and perplexity of 89.9386969070826
Finished 3 epochs...
Completing Train Step...
At time: 34.61407017707825 and batch: 50, loss is 4.313405032157898 and perplexity is 74.6943932298534
At time: 34.97095489501953 and batch: 100, loss is 4.323006625175476 and perplexity is 75.41503250049797
At time: 35.32914924621582 and batch: 150, loss is 4.169250373840332 and perplexity is 64.66695789010643
At time: 35.68739342689514 and batch: 200, loss is 4.288179378509522 and perplexity is 72.83374503525496
At time: 36.0479474067688 and batch: 250, loss is 4.3455411100387575 and perplexity is 77.13376404300358
At time: 36.405444383621216 and batch: 300, loss is 4.3402057552337645 and perplexity is 76.72332393981014
At time: 36.7651891708374 and batch: 350, loss is 4.343872051239014 and perplexity is 77.005130633594
At time: 37.124526023864746 and batch: 400, loss is 4.159657049179077 and perplexity is 64.04955298612707
At time: 37.48445749282837 and batch: 450, loss is 4.246340351104736 and perplexity is 69.84932004162289
At time: 37.84357142448425 and batch: 500, loss is 4.223299231529236 and perplexity is 68.25831318318141
At time: 38.202388286590576 and batch: 550, loss is 4.301675667762757 and perplexity is 73.8233935952794
At time: 38.56225395202637 and batch: 600, loss is 4.204241061210633 and perplexity is 66.96975243170009
At time: 38.92184257507324 and batch: 650, loss is 4.282605304718017 and perplexity is 72.42889374962415
At time: 39.282503604888916 and batch: 700, loss is 4.325898933410644 and perplexity is 75.63347176461741
At time: 39.64267945289612 and batch: 750, loss is 4.269609198570252 and perplexity is 71.4936903226479
At time: 40.001980781555176 and batch: 800, loss is 4.177669219970703 and perplexity is 65.21367720203735
At time: 40.36193251609802 and batch: 850, loss is 4.148289289474487 and perplexity is 63.32557585399912
At time: 40.74296045303345 and batch: 900, loss is 4.070460176467895 and perplexity is 58.58391532914065
At time: 41.10310983657837 and batch: 950, loss is 4.2041346025466915 and perplexity is 66.96262330081734
At time: 41.46311664581299 and batch: 1000, loss is 4.219403476715088 and perplexity is 67.99291283399933
At time: 41.82314348220825 and batch: 1050, loss is 4.1610363626480105 and perplexity is 64.13795835258037
At time: 42.183470726013184 and batch: 1100, loss is 4.300368475914001 and perplexity is 73.72695530233183
At time: 42.54295539855957 and batch: 1150, loss is 4.228796010017395 and perplexity is 68.63454710066502
At time: 42.903080224990845 and batch: 1200, loss is 4.168692936897278 and perplexity is 64.6309201840911
At time: 43.26300072669983 and batch: 1250, loss is 4.061748886108399 and perplexity is 58.075790258147286
At time: 43.62325644493103 and batch: 1300, loss is 4.188223958015442 and perplexity is 65.90563577878262
At time: 43.98360872268677 and batch: 1350, loss is 4.179644441604614 and perplexity is 65.34261596747196
At time: 44.34322237968445 and batch: 1400, loss is 4.023449907302856 and perplexity is 55.893601333470585
At time: 44.702789545059204 and batch: 1450, loss is 4.142510442733765 and perplexity is 62.960682403504045
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.4394776433961 and perplexity of 84.73067048687952
Finished 4 epochs...
Completing Train Step...
At time: 45.90553331375122 and batch: 50, loss is 4.175983972549439 and perplexity is 65.10386857404363
At time: 46.28176307678223 and batch: 100, loss is 4.2001950073242185 and perplexity is 66.69933663195492
At time: 46.6475248336792 and batch: 150, loss is 4.039530272483826 and perplexity is 56.799656176822324
At time: 47.00657796859741 and batch: 200, loss is 4.170549902915955 and perplexity is 64.75104910977491
At time: 47.36507701873779 and batch: 250, loss is 4.2340611505508425 and perplexity is 68.9968706417623
At time: 47.72431230545044 and batch: 300, loss is 4.223488864898681 and perplexity is 68.27125846449287
At time: 48.08311343193054 and batch: 350, loss is 4.225334119796753 and perplexity is 68.39735264074132
At time: 48.441444873809814 and batch: 400, loss is 4.033343997001648 and perplexity is 56.44936248021734
At time: 48.79946708679199 and batch: 450, loss is 4.125652394294739 and perplexity is 61.908184625050815
At time: 49.15727782249451 and batch: 500, loss is 4.10356125831604 and perplexity is 60.55555803766818
At time: 49.51494908332825 and batch: 550, loss is 4.1831751775741575 and perplexity is 65.5737312554505
At time: 49.88470983505249 and batch: 600, loss is 4.09384596824646 and perplexity is 59.9700918181008
At time: 50.24607849121094 and batch: 650, loss is 4.163293485641479 and perplexity is 64.28288911487975
At time: 50.623131275177 and batch: 700, loss is 4.209454641342163 and perplexity is 67.31981635260715
At time: 50.988269090652466 and batch: 750, loss is 4.159429507255554 and perplexity is 64.03498068560735
At time: 51.3465781211853 and batch: 800, loss is 4.069210638999939 and perplexity is 58.510758247693104
At time: 51.70408296585083 and batch: 850, loss is 4.041211376190185 and perplexity is 56.89522259536457
At time: 52.061938762664795 and batch: 900, loss is 3.9571751737594605 and perplexity is 52.30935221668873
At time: 52.419803619384766 and batch: 950, loss is 4.102808718681335 and perplexity is 60.51000472263052
At time: 52.77776741981506 and batch: 1000, loss is 4.115957045555115 and perplexity is 61.310863482664125
At time: 53.137503147125244 and batch: 1050, loss is 4.055091352462768 and perplexity is 57.690432918574494
At time: 53.50910472869873 and batch: 1100, loss is 4.20262291431427 and perplexity is 66.86147316415946
At time: 53.879404067993164 and batch: 1150, loss is 4.12681640625 and perplexity is 61.98028844879804
At time: 54.23870038986206 and batch: 1200, loss is 4.0714657497406 and perplexity is 58.64285537790835
At time: 54.613343715667725 and batch: 1250, loss is 3.951860957145691 and perplexity is 52.03210631294964
At time: 54.985992431640625 and batch: 1300, loss is 4.08070499420166 and perplexity is 59.18718176478236
At time: 55.34663987159729 and batch: 1350, loss is 4.081568932533264 and perplexity is 59.23833793455464
At time: 55.70564889907837 and batch: 1400, loss is 3.925861396789551 and perplexity is 50.69672925546058
At time: 56.064263582229614 and batch: 1450, loss is 4.0461895513534545 and perplexity is 57.17916314590605
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.405809190538195 and perplexity of 81.92540929449785
Finished 5 epochs...
Completing Train Step...
At time: 57.25348377227783 and batch: 50, loss is 4.074062404632568 and perplexity is 58.79532850958367
At time: 57.625006675720215 and batch: 100, loss is 4.110684871673584 and perplexity is 60.988472546852044
At time: 57.98353981971741 and batch: 150, loss is 3.9455633783340454 and perplexity is 51.70545964383196
At time: 58.342323303222656 and batch: 200, loss is 4.082323336601258 and perplexity is 59.28304443893775
At time: 58.700931787490845 and batch: 250, loss is 4.1475028228759765 and perplexity is 63.2757919830004
At time: 59.072579860687256 and batch: 300, loss is 4.135851650238037 and perplexity is 62.542833014114464
At time: 59.43142604827881 and batch: 350, loss is 4.134466905593872 and perplexity is 62.456287096894336
At time: 59.7903208732605 and batch: 400, loss is 3.9409301042556764 and perplexity is 51.466448208274386
At time: 60.14868521690369 and batch: 450, loss is 4.033445715904236 and perplexity is 56.45510473946383
At time: 60.5078284740448 and batch: 500, loss is 4.013896026611328 and perplexity is 55.362143320603344
At time: 60.86605501174927 and batch: 550, loss is 4.093452596664429 and perplexity is 59.946505927521464
At time: 61.22492599487305 and batch: 600, loss is 4.009144897460938 and perplexity is 55.099734490383696
At time: 61.58379006385803 and batch: 650, loss is 4.071947412490845 and perplexity is 58.67110826054623
At time: 61.94269061088562 and batch: 700, loss is 4.121594610214234 and perplexity is 61.65748356840007
At time: 62.30072212219238 and batch: 750, loss is 4.074934301376342 and perplexity is 58.846614319776805
At time: 62.65982460975647 and batch: 800, loss is 3.985588355064392 and perplexity is 53.816943636372955
At time: 63.01911425590515 and batch: 850, loss is 3.956498303413391 and perplexity is 52.2739575475035
At time: 63.378260374069214 and batch: 900, loss is 3.8708797788619993 and perplexity is 47.9845833380927
At time: 63.73716354370117 and batch: 950, loss is 4.024217567443848 and perplexity is 55.93652509667389
At time: 64.09539914131165 and batch: 1000, loss is 4.035101552009582 and perplexity is 56.5486625770689
At time: 64.45353960990906 and batch: 1050, loss is 3.9717329216003416 and perplexity is 53.07642848035797
At time: 64.81158375740051 and batch: 1100, loss is 4.125835275650024 and perplexity is 61.9195075130993
At time: 65.17041277885437 and batch: 1150, loss is 4.047411065101624 and perplexity is 57.249050955567824
At time: 65.52944612503052 and batch: 1200, loss is 3.9946137714385985 and perplexity is 54.30486248398098
At time: 65.88828253746033 and batch: 1250, loss is 3.8696239471435545 and perplexity is 47.92436059906812
At time: 66.24678587913513 and batch: 1300, loss is 3.9964212799072265 and perplexity is 54.403107745631694
At time: 66.60584807395935 and batch: 1350, loss is 4.003810682296753 and perplexity is 54.80660315897837
At time: 66.9640965461731 and batch: 1400, loss is 3.848891968727112 and perplexity is 46.94102228473254
At time: 67.32214045524597 and batch: 1450, loss is 3.9695065355300905 and perplexity is 52.95839130624789
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.388301490718483 and perplexity of 80.50356673567804
Finished 6 epochs...
Completing Train Step...
At time: 68.50655341148376 and batch: 50, loss is 3.9937865686416627 and perplexity is 54.25995992416899
At time: 68.87695384025574 and batch: 100, loss is 4.039318075180054 and perplexity is 56.787604721614805
At time: 69.2352705001831 and batch: 150, loss is 3.8707460832595824 and perplexity is 47.97816843914803
At time: 69.59381699562073 and batch: 200, loss is 4.010023379325867 and perplexity is 55.148159875192825
At time: 69.95178818702698 and batch: 250, loss is 4.07668251991272 and perplexity is 58.94958103967338
At time: 70.30963349342346 and batch: 300, loss is 4.0653705358505245 and perplexity is 58.28650176027441
At time: 70.66704249382019 and batch: 350, loss is 4.0607512044906615 and perplexity is 58.01787800357076
At time: 71.02538394927979 and batch: 400, loss is 3.86753547668457 and perplexity is 47.82437643102374
At time: 71.38496160507202 and batch: 450, loss is 3.9584208154678344 and perplexity is 52.37455152660736
At time: 71.74295997619629 and batch: 500, loss is 3.9441330242156982 and perplexity is 51.63155539391363
At time: 72.10067343711853 and batch: 550, loss is 4.020701909065247 and perplexity is 55.74021666243902
At time: 72.4580385684967 and batch: 600, loss is 3.9407817220687864 and perplexity is 51.45881207068519
At time: 72.81664204597473 and batch: 650, loss is 3.998488130569458 and perplexity is 54.51566712654876
At time: 73.17478203773499 and batch: 700, loss is 4.052046341896057 and perplexity is 57.51503212490199
At time: 73.53384947776794 and batch: 750, loss is 4.003932538032532 and perplexity is 54.813282064855095
At time: 73.8926591873169 and batch: 800, loss is 3.9186663150787355 and perplexity is 50.33327126894495
At time: 74.25152254104614 and batch: 850, loss is 3.8872034215927123 and perplexity is 48.7742944788022
At time: 74.61023187637329 and batch: 900, loss is 3.803864026069641 and perplexity is 44.87424517569463
At time: 74.9806776046753 and batch: 950, loss is 3.960392117500305 and perplexity is 52.47789941796789
At time: 75.33838152885437 and batch: 1000, loss is 3.9677903604507447 and perplexity is 52.867583378285076
At time: 75.7246322631836 and batch: 1050, loss is 3.903067126274109 and perplexity is 49.55420526386983
At time: 76.10435724258423 and batch: 1100, loss is 4.062205319404602 and perplexity is 58.10230403294893
At time: 76.47009825706482 and batch: 1150, loss is 3.9818092346191407 and perplexity is 53.613946740830805
At time: 76.85030174255371 and batch: 1200, loss is 3.9321845960617066 and perplexity is 51.018310416393895
At time: 77.23637771606445 and batch: 1250, loss is 3.803049097061157 and perplexity is 44.83769074822182
At time: 77.59461736679077 and batch: 1300, loss is 3.9275636577606203 and perplexity is 50.783101812492674
At time: 77.95394730567932 and batch: 1350, loss is 3.9389771842956542 and perplexity is 51.36603643428916
At time: 78.31285881996155 and batch: 1400, loss is 3.78499107837677 and perplexity is 44.035277690841035
At time: 78.67053174972534 and batch: 1450, loss is 3.906244535446167 and perplexity is 49.711909663210754
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.377779447115385 and perplexity of 79.66094551897925
Finished 7 epochs...
Completing Train Step...
At time: 79.86113739013672 and batch: 50, loss is 3.9289632987976075 and perplexity is 50.8542296909121
At time: 80.21972107887268 and batch: 100, loss is 3.9799777364730833 and perplexity is 53.51584276282229
At time: 80.57977652549744 and batch: 150, loss is 3.8084932231903075 and perplexity is 45.082458460598694
At time: 80.93944835662842 and batch: 200, loss is 3.9486070346832274 and perplexity is 51.86307303318543
At time: 81.29826259613037 and batch: 250, loss is 4.017252459526062 and perplexity is 55.54827483490447
At time: 81.65665125846863 and batch: 300, loss is 4.005240154266358 and perplexity is 54.88500368426979
At time: 82.01596570014954 and batch: 350, loss is 3.9996154642105104 and perplexity is 54.57715912655265
At time: 82.37497067451477 and batch: 400, loss is 3.806720132827759 and perplexity is 45.002594012347444
At time: 82.73441171646118 and batch: 450, loss is 3.8966117238998415 and perplexity is 49.2353432282321
At time: 83.09370708465576 and batch: 500, loss is 3.8847551584243774 and perplexity is 48.65502822722712
At time: 83.45348644256592 and batch: 550, loss is 3.9612226819992067 and perplexity is 52.52150380382216
At time: 83.81350207328796 and batch: 600, loss is 3.8830310678482056 and perplexity is 48.57121482328833
At time: 84.17382717132568 and batch: 650, loss is 3.9374489784240723 and perplexity is 51.28759850572729
At time: 84.53333902359009 and batch: 700, loss is 3.993515343666077 and perplexity is 54.24524526344522
At time: 84.89268255233765 and batch: 750, loss is 3.9454958391189576 and perplexity is 51.70196761559762
At time: 85.25143623352051 and batch: 800, loss is 3.8614925384521483 and perplexity is 47.53624812582301
At time: 85.60970664024353 and batch: 850, loss is 3.829952850341797 and perplexity is 46.06036645248055
At time: 85.96935367584229 and batch: 900, loss is 3.7478559160232545 and perplexity is 42.43001089640816
At time: 86.34220337867737 and batch: 950, loss is 3.9071282386779784 and perplexity is 49.755859654954364
At time: 86.70170736312866 and batch: 1000, loss is 3.9123568153381347 and perplexity is 50.01669328153583
At time: 87.06161689758301 and batch: 1050, loss is 3.8460284900665282 and perplexity is 46.806799932248396
At time: 87.42237043380737 and batch: 1100, loss is 4.007009210586548 and perplexity is 54.98218428055078
At time: 87.78203988075256 and batch: 1150, loss is 3.92629852771759 and perplexity is 50.71889520812735
At time: 88.14169454574585 and batch: 1200, loss is 3.878167061805725 and perplexity is 48.335537772843956
At time: 88.5024471282959 and batch: 1250, loss is 3.7479595613479613 and perplexity is 42.43440879657179
At time: 88.86253714561462 and batch: 1300, loss is 3.8691433334350585 and perplexity is 47.9013330285196
At time: 89.2224452495575 and batch: 1350, loss is 3.885203185081482 and perplexity is 48.67683186081491
At time: 89.58315968513489 and batch: 1400, loss is 3.7309799194335938 and perplexity is 41.719970349649174
At time: 89.9421763420105 and batch: 1450, loss is 3.852825961112976 and perplexity is 47.12605162235737
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.373860155415331 and perplexity of 79.34934206767278
Finished 8 epochs...
Completing Train Step...
At time: 91.1334023475647 and batch: 50, loss is 3.8740160512924193 and perplexity is 48.13531230390105
At time: 91.49169278144836 and batch: 100, loss is 3.929402470588684 and perplexity is 50.87656833894227
At time: 91.85040330886841 and batch: 150, loss is 3.7560647201538084 and perplexity is 42.77974402661651
At time: 92.20863795280457 and batch: 200, loss is 3.8959553623199463 and perplexity is 49.20303764379616
At time: 92.56853175163269 and batch: 250, loss is 3.9656108522415163 and perplexity is 52.75248352241322
At time: 92.92703032493591 and batch: 300, loss is 3.952651219367981 and perplexity is 52.07324157259499
At time: 93.28491806983948 and batch: 350, loss is 3.947569751739502 and perplexity is 51.80930424366412
At time: 93.66784954071045 and batch: 400, loss is 3.7542611932754517 and perplexity is 42.70265914164083
At time: 94.04169368743896 and batch: 450, loss is 3.8426153469085693 and perplexity is 46.64731395238242
At time: 94.40825176239014 and batch: 500, loss is 3.8349211263656615 and perplexity is 46.28977648105736
At time: 94.76715135574341 and batch: 550, loss is 3.9098199367523194 and perplexity is 49.889967814942324
At time: 95.12698554992676 and batch: 600, loss is 3.833321189880371 and perplexity is 46.21577499339515
At time: 95.4856345653534 and batch: 650, loss is 3.8848122119903565 and perplexity is 48.657804249280524
At time: 95.85766577720642 and batch: 700, loss is 3.9425883960723875 and perplexity is 51.55186540191568
At time: 96.21617531776428 and batch: 750, loss is 3.8951950311660766 and perplexity is 49.16564126002994
At time: 96.57525444030762 and batch: 800, loss is 3.8122998380661013 and perplexity is 45.254397062010746
At time: 96.93299508094788 and batch: 850, loss is 3.7816542959213257 and perplexity is 43.88858642335193
At time: 97.29166221618652 and batch: 900, loss is 3.7003667545318604 and perplexity is 40.46214131283651
At time: 97.64993739128113 and batch: 950, loss is 3.8622551488876344 and perplexity is 47.57251359116118
At time: 98.00859570503235 and batch: 1000, loss is 3.8637006378173826 and perplexity is 47.64132885678773
At time: 98.3704845905304 and batch: 1050, loss is 3.7948849201202393 and perplexity is 44.47311814994099
At time: 98.7295823097229 and batch: 1100, loss is 3.9591136980056763 and perplexity is 52.41085351384163
At time: 99.08805584907532 and batch: 1150, loss is 3.878277735710144 and perplexity is 48.34088755156647
At time: 99.44700789451599 and batch: 1200, loss is 3.831303482055664 and perplexity is 46.12261907488318
At time: 99.80542516708374 and batch: 1250, loss is 3.6985643482208252 and perplexity is 40.389277778549065
At time: 100.16442394256592 and batch: 1300, loss is 3.8172703123092653 and perplexity is 45.479892823183064
At time: 100.52308988571167 and batch: 1350, loss is 3.8396189832687377 and perplexity is 46.50775083230764
At time: 100.88249325752258 and batch: 1400, loss is 3.6846972131729125 and perplexity is 39.83305969797324
At time: 101.24208617210388 and batch: 1450, loss is 3.806287422180176 and perplexity is 44.98312512325103
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.3741452469784985 and perplexity of 79.37196712059178
Annealing...
Finished 9 epochs...
Completing Train Step...
At time: 102.43025326728821 and batch: 50, loss is 3.8554459190368653 and perplexity is 47.249681776910215
At time: 102.80192255973816 and batch: 100, loss is 3.9112943172454835 and perplexity is 49.963578862304786
At time: 103.16005373001099 and batch: 150, loss is 3.727151188850403 and perplexity is 41.560541223585346
At time: 103.51844692230225 and batch: 200, loss is 3.8651473236083986 and perplexity is 47.71030076862311
At time: 103.87662434577942 and batch: 250, loss is 3.9298992443084715 and perplexity is 50.90184875985049
At time: 104.23537802696228 and batch: 300, loss is 3.915704231262207 and perplexity is 50.184400493392374
At time: 104.59369587898254 and batch: 350, loss is 3.8995097255706788 and perplexity is 49.37823428442673
At time: 104.96532583236694 and batch: 400, loss is 3.70259831905365 and perplexity is 40.552536015158296
At time: 105.32248377799988 and batch: 450, loss is 3.7895871877670286 and perplexity is 44.23813446299708
At time: 105.67985677719116 and batch: 500, loss is 3.773047504425049 and perplexity is 43.512467421659174
At time: 106.06039428710938 and batch: 550, loss is 3.836737880706787 and perplexity is 46.373950071645176
At time: 106.42195081710815 and batch: 600, loss is 3.764329295158386 and perplexity is 43.13476545967597
At time: 106.79812431335449 and batch: 650, loss is 3.807657103538513 and perplexity is 45.044779885222326
At time: 107.16388964653015 and batch: 700, loss is 3.870597004890442 and perplexity is 47.97101646515833
At time: 107.52918696403503 and batch: 750, loss is 3.8143248081207277 and perplexity is 45.34612870647255
At time: 107.89462089538574 and batch: 800, loss is 3.723559079170227 and perplexity is 41.41151901344379
At time: 108.25779986381531 and batch: 850, loss is 3.6819334173202516 and perplexity is 39.72312124648034
At time: 108.63411331176758 and batch: 900, loss is 3.5914113235473635 and perplexity is 36.28525003416586
At time: 109.00716233253479 and batch: 950, loss is 3.752157311439514 and perplexity is 42.61291223427465
At time: 109.37111377716064 and batch: 1000, loss is 3.751957688331604 and perplexity is 42.604406561290034
At time: 109.73075532913208 and batch: 1050, loss is 3.6735521268844606 and perplexity is 39.39158153637489
At time: 110.08946204185486 and batch: 1100, loss is 3.833822474479675 and perplexity is 46.23894805730901
At time: 110.44861578941345 and batch: 1150, loss is 3.741656608581543 and perplexity is 42.167787854533216
At time: 110.80694580078125 and batch: 1200, loss is 3.690093746185303 and perplexity is 40.04860118489952
At time: 111.16500425338745 and batch: 1250, loss is 3.549229774475098 and perplexity is 34.78651370567015
At time: 111.52268934249878 and batch: 1300, loss is 3.658937344551086 and perplexity is 38.82006858763341
At time: 111.88048219680786 and batch: 1350, loss is 3.6696968603134157 and perplexity is 39.24000885318278
At time: 112.23852062225342 and batch: 1400, loss is 3.506731963157654 and perplexity is 33.33913603293364
At time: 112.59709644317627 and batch: 1450, loss is 3.6199147272109986 and perplexity is 37.33438407925618
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.307753082014557 and perplexity of 74.27341503786973
Finished 10 epochs...
Completing Train Step...
At time: 113.78694534301758 and batch: 50, loss is 3.7891883563995363 and perplexity is 44.22049442526791
At time: 114.15997648239136 and batch: 100, loss is 3.8478011322021484 and perplexity is 46.889845221085096
At time: 114.52048993110657 and batch: 150, loss is 3.670539560317993 and perplexity is 39.27309034575223
At time: 114.88013815879822 and batch: 200, loss is 3.813988766670227 and perplexity is 45.33089308765053
At time: 115.2400963306427 and batch: 250, loss is 3.8800387287139895 and perplexity is 48.42609051523737
At time: 115.60088014602661 and batch: 300, loss is 3.8673082065582274 and perplexity is 47.813508613961844
At time: 115.96120595932007 and batch: 350, loss is 3.8515402936935423 and perplexity is 47.0655021247785
At time: 116.32148909568787 and batch: 400, loss is 3.6553590726852416 and perplexity is 38.68140805886172
At time: 116.68210482597351 and batch: 450, loss is 3.7442798519134524 and perplexity is 42.27854943661854
At time: 117.04169297218323 and batch: 500, loss is 3.732260437011719 and perplexity is 41.7734277242901
At time: 117.40086007118225 and batch: 550, loss is 3.7969279384613035 and perplexity is 44.56407042295094
At time: 117.75926733016968 and batch: 600, loss is 3.727846412658691 and perplexity is 41.58944514751317
At time: 118.11893153190613 and batch: 650, loss is 3.771547646522522 and perplexity is 43.4472538213305
At time: 118.4786593914032 and batch: 700, loss is 3.8355321502685547 and perplexity is 46.318069283856
At time: 118.8386447429657 and batch: 750, loss is 3.7819891452789305 and perplexity is 43.90328494908058
At time: 119.19912576675415 and batch: 800, loss is 3.6931682348251345 and perplexity is 40.17191962772065
At time: 119.55969905853271 and batch: 850, loss is 3.6539085865020753 and perplexity is 38.62534188236395
At time: 119.91964817047119 and batch: 900, loss is 3.565601124763489 and perplexity is 35.36070321110183
At time: 120.27938437461853 and batch: 950, loss is 3.729642424583435 and perplexity is 41.664207403797036
At time: 120.63934445381165 and batch: 1000, loss is 3.7302004051208497 and perplexity is 41.68746170775633
At time: 120.99972009658813 and batch: 1050, loss is 3.6543732833862306 and perplexity is 38.64329512947204
At time: 121.35926985740662 and batch: 1100, loss is 3.8169705629348756 and perplexity is 45.466262296734946
At time: 121.71920037269592 and batch: 1150, loss is 3.7273075914382936 and perplexity is 41.56704190813554
At time: 122.07910561561584 and batch: 1200, loss is 3.6788635730743406 and perplexity is 39.601364434136194
At time: 122.43973469734192 and batch: 1250, loss is 3.5407888507843017 and perplexity is 34.49411917404708
At time: 122.7979998588562 and batch: 1300, loss is 3.6525728702545166 and perplexity is 38.573783826775994
At time: 123.15771341323853 and batch: 1350, loss is 3.6664568471908567 and perplexity is 39.113076451933345
At time: 123.53569626808167 and batch: 1400, loss is 3.5073044300079346 and perplexity is 33.358227047094495
At time: 123.90862441062927 and batch: 1450, loss is 3.624432797431946 and perplexity is 37.50344507532184
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.3035646096254005 and perplexity of 73.96297348152619
Finished 11 epochs...
Completing Train Step...
At time: 125.10546350479126 and batch: 50, loss is 3.767068204879761 and perplexity is 43.25306962638269
At time: 125.46395015716553 and batch: 100, loss is 3.824718351364136 and perplexity is 45.81989343832711
At time: 125.82272720336914 and batch: 150, loss is 3.6478580904006956 and perplexity is 38.39234498610168
At time: 126.182058095932 and batch: 200, loss is 3.7921770238876342 and perplexity is 44.35285246783367
At time: 126.54071688652039 and batch: 250, loss is 3.858035168647766 and perplexity is 47.37218151983342
At time: 126.89907217025757 and batch: 300, loss is 3.845845675468445 and perplexity is 46.798243748052734
At time: 127.25778913497925 and batch: 350, loss is 3.8299195861816404 and perplexity is 46.05883431855672
At time: 127.63460278511047 and batch: 400, loss is 3.6332523345947267 and perplexity is 37.83567098879902
At time: 128.0079619884491 and batch: 450, loss is 3.722502226829529 and perplexity is 41.367776271523645
At time: 128.36841893196106 and batch: 500, loss is 3.711519651412964 and perplexity is 40.91593726838169
At time: 128.72692966461182 and batch: 550, loss is 3.7765369415283203 and perplexity is 43.66456665595881
At time: 129.10552382469177 and batch: 600, loss is 3.708825101852417 and perplexity is 40.80583565134466
At time: 129.47400641441345 and batch: 650, loss is 3.7530851650238035 and perplexity is 42.65246912629233
At time: 129.832133769989 and batch: 700, loss is 3.8168246698379518 and perplexity is 45.45962956676945
At time: 130.19087600708008 and batch: 750, loss is 3.764784345626831 and perplexity is 43.15439842156011
At time: 130.5500521659851 and batch: 800, loss is 3.6766221427917483 and perplexity is 39.51270014119799
At time: 130.9088487625122 and batch: 850, loss is 3.638350067138672 and perplexity is 38.02903957202685
At time: 131.2674376964569 and batch: 900, loss is 3.550813174247742 and perplexity is 34.841638294176086
At time: 131.62550735473633 and batch: 950, loss is 3.716113176345825 and perplexity is 41.10431798088187
At time: 131.98277306556702 and batch: 1000, loss is 3.7176289176940918 and perplexity is 41.16666873711003
At time: 132.34014081954956 and batch: 1050, loss is 3.642983288764954 and perplexity is 38.205645351528034
At time: 132.7110834121704 and batch: 1100, loss is 3.8068614482879637 and perplexity is 45.00895402400411
At time: 133.069762468338 and batch: 1150, loss is 3.7178363275527953 and perplexity is 41.17520799558867
At time: 133.4283607006073 and batch: 1200, loss is 3.6708445262908938 and perplexity is 39.28506912842605
At time: 133.78679156303406 and batch: 1250, loss is 3.5337666606903078 and perplexity is 34.2527433972521
At time: 134.14685583114624 and batch: 1300, loss is 3.646136088371277 and perplexity is 38.32629017969945
At time: 134.50510621070862 and batch: 1350, loss is 3.6613290023803713 and perplexity is 38.91302402309294
At time: 134.86379551887512 and batch: 1400, loss is 3.5038790702819824 and perplexity is 33.24415859391223
At time: 135.23719096183777 and batch: 1450, loss is 3.6223479557037352 and perplexity is 37.42533777704605
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.302409375834669 and perplexity of 73.8775782904996
Finished 12 epochs...
Completing Train Step...
At time: 136.43394899368286 and batch: 50, loss is 3.7501638603210448 and perplexity is 42.52805008909154
At time: 136.79143953323364 and batch: 100, loss is 3.8073620271682738 and perplexity is 45.03149019590863
At time: 137.14971494674683 and batch: 150, loss is 3.630767612457275 and perplexity is 37.74177655859993
At time: 137.5074908733368 and batch: 200, loss is 3.775490803718567 and perplexity is 43.6189113868489
At time: 137.8658766746521 and batch: 250, loss is 3.8415041875839235 and perplexity is 46.595510140988665
At time: 138.22466683387756 and batch: 300, loss is 3.829977674484253 and perplexity is 46.06150987577113
At time: 138.58335041999817 and batch: 350, loss is 3.814034996032715 and perplexity is 45.33298875437927
At time: 138.9422962665558 and batch: 400, loss is 3.6168349266052244 and perplexity is 37.21957850044414
At time: 139.30065488815308 and batch: 450, loss is 3.7063706970214843 and perplexity is 40.705804419977035
At time: 139.65953755378723 and batch: 500, loss is 3.6959751319885252 and perplexity is 40.284836473822956
At time: 140.01781606674194 and batch: 550, loss is 3.761282262802124 and perplexity is 43.00353247075729
At time: 140.37593841552734 and batch: 600, loss is 3.694449615478516 and perplexity is 40.22342814230003
At time: 140.7347617149353 and batch: 650, loss is 3.7392352962493898 and perplexity is 42.06580997974692
At time: 141.0929787158966 and batch: 700, loss is 3.8027881622314452 and perplexity is 44.825992559320596
At time: 141.4504668712616 and batch: 750, loss is 3.751715350151062 and perplexity is 42.594083137851236
At time: 141.82576751708984 and batch: 800, loss is 3.663859558105469 and perplexity is 39.011620297884086
At time: 142.18369388580322 and batch: 850, loss is 3.6262904977798462 and perplexity is 37.57317999151988
At time: 142.54241228103638 and batch: 900, loss is 3.539097466468811 and perplexity is 34.43582567415222
At time: 142.9007966518402 and batch: 950, loss is 3.705156097412109 and perplexity is 40.65639317934052
At time: 143.2601296901703 and batch: 1000, loss is 3.7075520658493044 and perplexity is 40.75392140478697
At time: 143.61924004554749 and batch: 1050, loss is 3.6334915828704832 and perplexity is 37.84472419078348
At time: 143.97850942611694 and batch: 1100, loss is 3.7982802391052246 and perplexity is 44.62437520999078
At time: 144.33773255348206 and batch: 1150, loss is 3.7094276571273803 and perplexity is 40.83043083209945
At time: 144.6967158317566 and batch: 1200, loss is 3.6632720613479615 and perplexity is 38.98870782861369
At time: 145.07058453559875 and batch: 1250, loss is 3.52669912815094 and perplexity is 34.01151446949249
At time: 145.44399619102478 and batch: 1300, loss is 3.639096693992615 and perplexity is 38.05744367651508
At time: 145.8033812046051 and batch: 1350, loss is 3.655284857749939 and perplexity is 38.67853742718841
At time: 146.16164302825928 and batch: 1400, loss is 3.4989006233215334 and perplexity is 33.079065607929564
At time: 146.5188593864441 and batch: 1450, loss is 3.618003044128418 and perplexity is 37.26308074521704
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.302292261368189 and perplexity of 73.86892666395846
Finished 13 epochs...
Completing Train Step...
At time: 147.70122575759888 and batch: 50, loss is 3.7359345388412475 and perplexity is 41.927189847396654
At time: 148.0729694366455 and batch: 100, loss is 3.792921657562256 and perplexity is 44.38589139476891
At time: 148.43200397491455 and batch: 150, loss is 3.6164985609054567 and perplexity is 37.207061216187334
At time: 148.79090189933777 and batch: 200, loss is 3.7613608169555666 and perplexity is 43.00691070953118
At time: 149.1496284008026 and batch: 250, loss is 3.827638030052185 and perplexity is 45.953868291276486
At time: 149.50927996635437 and batch: 300, loss is 3.8166868829727174 and perplexity is 45.45336625842745
At time: 149.86788868904114 and batch: 350, loss is 3.8008132457733153 and perplexity is 44.737552328641996
At time: 150.22609043121338 and batch: 400, loss is 3.603108344078064 and perplexity is 36.71217133477265
At time: 150.58437943458557 and batch: 450, loss is 3.692881088256836 and perplexity is 40.160386054849766
At time: 150.95686173439026 and batch: 500, loss is 3.682961664199829 and perplexity is 39.76398742861062
At time: 151.31689381599426 and batch: 550, loss is 3.748445415496826 and perplexity is 42.455030739362805
At time: 151.67634224891663 and batch: 600, loss is 3.6822839260101317 and perplexity is 39.73704698607019
At time: 152.03419065475464 and batch: 650, loss is 3.727489876747131 and perplexity is 41.574619659842654
At time: 152.39193487167358 and batch: 700, loss is 3.7909110498428347 and perplexity is 44.296738434745734
At time: 152.7500035762787 and batch: 750, loss is 3.7405031871795655 and perplexity is 42.11917866437695
At time: 153.10878825187683 and batch: 800, loss is 3.6528339624404906 and perplexity is 38.58385645520168
At time: 153.4880599975586 and batch: 850, loss is 3.615870041847229 and perplexity is 37.18368321664104
At time: 153.85547518730164 and batch: 900, loss is 3.528856348991394 and perplexity is 34.08496401227996
At time: 154.21368288993835 and batch: 950, loss is 3.6954446744918825 and perplexity is 40.26347274708984
At time: 154.57249116897583 and batch: 1000, loss is 3.6985628318786623 and perplexity is 40.38921653463067
At time: 154.93133091926575 and batch: 1050, loss is 3.624809398651123 and perplexity is 37.517571578322716
At time: 155.28891444206238 and batch: 1100, loss is 3.7902821826934816 and perplexity is 44.26889042838659
At time: 155.6471996307373 and batch: 1150, loss is 3.701448140144348 and perplexity is 40.5059201569425
At time: 156.00675988197327 and batch: 1200, loss is 3.6558545207977295 and perplexity is 38.700577437797044
At time: 156.3658709526062 and batch: 1250, loss is 3.519605565071106 and perplexity is 33.771105332937516
At time: 156.72469210624695 and batch: 1300, loss is 3.631782917976379 and perplexity is 37.78011545219234
At time: 157.0830466747284 and batch: 1350, loss is 3.6488279628753664 and perplexity is 38.429598727510715
At time: 157.44070267677307 and batch: 1400, loss is 3.493230381011963 and perplexity is 32.892030060121535
At time: 157.79964232444763 and batch: 1450, loss is 3.6126725578308108 and perplexity is 37.06497886265669
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.302685077373798 and perplexity of 73.89794926056629
Annealing...
Finished 14 epochs...
Completing Train Step...
At time: 158.9781551361084 and batch: 50, loss is 3.7371827077865603 and perplexity is 41.979554737044566
At time: 159.34968161582947 and batch: 100, loss is 3.7976471996307373 and perplexity is 44.596135158435295
At time: 159.7092742919922 and batch: 150, loss is 3.625049180984497 and perplexity is 37.52656870781153
At time: 160.08134508132935 and batch: 200, loss is 3.7652680110931396 and perplexity is 43.1752757622133
At time: 160.44094443321228 and batch: 250, loss is 3.838698229789734 and perplexity is 46.46494836721143
At time: 160.80061173439026 and batch: 300, loss is 3.824065160751343 and perplexity is 45.78997408663763
At time: 161.1599040031433 and batch: 350, loss is 3.804064221382141 and perplexity is 44.88322968852945
At time: 161.5194878578186 and batch: 400, loss is 3.598034462928772 and perplexity is 36.52636990647983
At time: 161.87888479232788 and batch: 450, loss is 3.69325288772583 and perplexity is 40.175320441185974
At time: 162.23834609985352 and batch: 500, loss is 3.6779235649108886 and perplexity is 39.564156318990065
At time: 162.5981891155243 and batch: 550, loss is 3.743618788719177 and perplexity is 42.25060987960253
At time: 162.95783162117004 and batch: 600, loss is 3.677349886894226 and perplexity is 39.541465741427125
At time: 163.3177194595337 and batch: 650, loss is 3.719993009567261 and perplexity is 41.26410565364747
At time: 163.67768216133118 and batch: 700, loss is 3.783454656600952 and perplexity is 43.96767287934385
At time: 164.03797125816345 and batch: 750, loss is 3.732619352340698 and perplexity is 41.78842353879722
At time: 164.39773058891296 and batch: 800, loss is 3.642748780250549 and perplexity is 38.19668685285794
At time: 164.75828218460083 and batch: 850, loss is 3.6016536855697634 and perplexity is 36.65880648560841
At time: 165.11768794059753 and batch: 900, loss is 3.510756001472473 and perplexity is 33.473564284532266
At time: 165.47729969024658 and batch: 950, loss is 3.675082926750183 and perplexity is 39.45192834175769
At time: 165.8376910686493 and batch: 1000, loss is 3.6792670059204102 and perplexity is 39.617344148452176
At time: 166.19829511642456 and batch: 1050, loss is 3.606601915359497 and perplexity is 36.84065222011631
At time: 166.5582754611969 and batch: 1100, loss is 3.7688944864273073 and perplexity is 43.33213408432106
At time: 166.91735744476318 and batch: 1150, loss is 3.6765930891036986 and perplexity is 39.51155216821059
At time: 167.27630186080933 and batch: 1200, loss is 3.6281185054779055 and perplexity is 37.641926869552286
At time: 167.63596272468567 and batch: 1250, loss is 3.4876663494110107 and perplexity is 32.70952596555899
At time: 167.99570894241333 and batch: 1300, loss is 3.6012095403671265 and perplexity is 36.6425282677872
At time: 168.3549783229828 and batch: 1350, loss is 3.6173114585876465 and perplexity is 37.23731904660497
At time: 168.71460509300232 and batch: 1400, loss is 3.4554169511795045 and perplexity is 31.671491395334137
At time: 169.07413029670715 and batch: 1450, loss is 3.575632815361023 and perplexity is 35.71721606857144
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.291311410757212 and perplexity of 73.06222028257524
Finished 15 epochs...
Completing Train Step...
At time: 170.2659204006195 and batch: 50, loss is 3.7293815135955812 and perplexity is 41.65333817229778
At time: 170.62477946281433 and batch: 100, loss is 3.783247184753418 and perplexity is 43.958551771239094
At time: 170.98364400863647 and batch: 150, loss is 3.608558011054993 and perplexity is 36.912786589207066
At time: 171.34229040145874 and batch: 200, loss is 3.752056050300598 and perplexity is 42.608597420714425
At time: 171.7007827758789 and batch: 250, loss is 3.8246839094161986 and perplexity is 45.81831533911937
At time: 172.05946516990662 and batch: 300, loss is 3.811188383102417 and perplexity is 45.20412677952017
At time: 172.4171051979065 and batch: 350, loss is 3.7929221630096435 and perplexity is 44.38591382950743
At time: 172.77557396888733 and batch: 400, loss is 3.5876023721694947 and perplexity is 36.14730416238889
At time: 173.1391954421997 and batch: 450, loss is 3.6824242305755615 and perplexity is 39.742622666316585
At time: 173.51640582084656 and batch: 500, loss is 3.6683261728286745 and perplexity is 39.18625990906432
At time: 173.88343691825867 and batch: 550, loss is 3.734537944793701 and perplexity is 41.8686754535634
At time: 174.24186253547668 and batch: 600, loss is 3.6695968103408814 and perplexity is 39.236083087764406
At time: 174.59994769096375 and batch: 650, loss is 3.712240777015686 and perplexity is 40.94545343945952
At time: 174.95858502388 and batch: 700, loss is 3.775808963775635 and perplexity is 43.63279139009922
At time: 175.3176817893982 and batch: 750, loss is 3.7252803468704223 and perplexity is 41.48286070499829
At time: 175.6767635345459 and batch: 800, loss is 3.6363416433334352 and perplexity is 37.952737792463964
At time: 176.03588962554932 and batch: 850, loss is 3.5961098051071168 and perplexity is 36.456136752018125
At time: 176.39385342597961 and batch: 900, loss is 3.5059843635559083 and perplexity is 33.31422102249924
At time: 176.75238728523254 and batch: 950, loss is 3.671157865524292 and perplexity is 39.29738061060521
At time: 177.1105239391327 and batch: 1000, loss is 3.6758678770065307 and perplexity is 39.48290830029548
At time: 177.4687101840973 and batch: 1050, loss is 3.6035479068756104 and perplexity is 36.72831218670769
At time: 177.82727694511414 and batch: 1100, loss is 3.7669807481765747 and perplexity is 43.24928702092
At time: 178.18512511253357 and batch: 1150, loss is 3.6753062915802004 and perplexity is 39.460741499263676
At time: 178.55743765830994 and batch: 1200, loss is 3.6276274633407595 and perplexity is 37.62344763474876
At time: 178.91669416427612 and batch: 1250, loss is 3.488255581855774 and perplexity is 32.72880515891603
At time: 179.27563285827637 and batch: 1300, loss is 3.602117085456848 and perplexity is 36.67579810904863
At time: 179.63408994674683 and batch: 1350, loss is 3.6192482614517214 and perplexity is 37.309510280312
At time: 179.99306106567383 and batch: 1400, loss is 3.4584233379364013 and perplexity is 31.76685142036959
At time: 180.35207533836365 and batch: 1450, loss is 3.579733815193176 and perplexity is 35.863993126307776
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.290369539179354 and perplexity of 72.99343745125772
Finished 16 epochs...
Completing Train Step...
At time: 181.5416624546051 and batch: 50, loss is 3.7257163095474244 and perplexity is 41.500949626761816
At time: 181.89995121955872 and batch: 100, loss is 3.7785458374023437 and perplexity is 43.752372390514395
At time: 182.25837683677673 and batch: 150, loss is 3.6033422422409056 and perplexity is 36.72075924851124
At time: 182.61641573905945 and batch: 200, loss is 3.7471674871444702 and perplexity is 42.40081090379227
At time: 182.97473120689392 and batch: 250, loss is 3.819479913711548 and perplexity is 45.58049636407164
At time: 183.33295607566833 and batch: 300, loss is 3.806067748069763 and perplexity is 44.97324458054544
At time: 183.6901752948761 and batch: 350, loss is 3.7880373859405516 and perplexity is 44.16962722144265
At time: 184.04786491394043 and batch: 400, loss is 3.5826361560821534 and perplexity is 35.96823385789569
At time: 184.40978717803955 and batch: 450, loss is 3.6773226070404053 and perplexity is 39.5403870707349
At time: 184.7931673526764 and batch: 500, loss is 3.6635717153549194 and perplexity is 39.00039270176274
At time: 185.1570053100586 and batch: 550, loss is 3.7299874067306518 and perplexity is 41.67858329109893
At time: 185.51552772521973 and batch: 600, loss is 3.6655020666122438 and perplexity is 39.075749868351366
At time: 185.87373208999634 and batch: 650, loss is 3.7083821058273316 and perplexity is 40.787762831740004
At time: 186.23147559165955 and batch: 700, loss is 3.771962842941284 and perplexity is 43.46529671093453
At time: 186.589702129364 and batch: 750, loss is 3.7215978860855103 and perplexity is 41.33038261680311
At time: 186.94810271263123 and batch: 800, loss is 3.6329520082473756 and perplexity is 37.82430964607205
At time: 187.30588030815125 and batch: 850, loss is 3.5932583236694335 and perplexity is 36.35233082545316
At time: 187.68563103675842 and batch: 900, loss is 3.5033416604995726 and perplexity is 33.22629765762669
At time: 188.04388689994812 and batch: 950, loss is 3.669003119468689 and perplexity is 39.212795896755
At time: 188.4027020931244 and batch: 1000, loss is 3.674054446220398 and perplexity is 39.4113736600208
At time: 188.76146531105042 and batch: 1050, loss is 3.601918158531189 and perplexity is 36.66850303090249
At time: 189.11976981163025 and batch: 1100, loss is 3.7657486820220947 and perplexity is 43.196033850626975
At time: 189.4776062965393 and batch: 1150, loss is 3.674552321434021 and perplexity is 39.431000491552005
At time: 189.83607172966003 and batch: 1200, loss is 3.6272205829620363 and perplexity is 37.608142506015696
At time: 190.19414114952087 and batch: 1250, loss is 3.4883132791519165 and perplexity is 32.730693576957464
At time: 190.55198979377747 and batch: 1300, loss is 3.6023126602172852 and perplexity is 36.682971670938606
At time: 190.9106092453003 and batch: 1350, loss is 3.6197982025146485 and perplexity is 37.33003395494131
At time: 191.26976251602173 and batch: 1400, loss is 3.4593754243850707 and perplexity is 31.79711061152099
At time: 191.6276171207428 and batch: 1450, loss is 3.581063461303711 and perplexity is 35.91171126236312
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.290067754240117 and perplexity of 72.97141245474509
Finished 17 epochs...
Completing Train Step...
At time: 192.80921626091003 and batch: 50, loss is 3.722326674461365 and perplexity is 41.360514697845375
At time: 193.18265652656555 and batch: 100, loss is 3.7747911167144776 and perplexity is 43.588402476007886
At time: 193.54270887374878 and batch: 150, loss is 3.599391231536865 and perplexity is 36.575961373001626
At time: 193.90228986740112 and batch: 200, loss is 3.743386960029602 and perplexity is 42.240816111362484
At time: 194.26855373382568 and batch: 250, loss is 3.8156526136398314 and perplexity is 45.4063795382803
At time: 194.62787461280823 and batch: 300, loss is 3.802263283729553 and perplexity is 44.802470533143186
At time: 194.9874141216278 and batch: 350, loss is 3.784327812194824 and perplexity is 44.00608026423931
At time: 195.34765243530273 and batch: 400, loss is 3.5788938856124877 and perplexity is 35.833882544753656
At time: 195.70708394050598 and batch: 450, loss is 3.673574199676514 and perplexity is 39.39245102815882
At time: 196.06673502922058 and batch: 500, loss is 3.660019750595093 and perplexity is 38.86211041355997
At time: 196.4268181324005 and batch: 550, loss is 3.7265498733520506 and perplexity is 41.53555773825895
At time: 196.80004048347473 and batch: 600, loss is 3.662382960319519 and perplexity is 38.95405833411876
At time: 197.1605749130249 and batch: 650, loss is 3.705422387123108 and perplexity is 40.66722100013514
At time: 197.5214822292328 and batch: 700, loss is 3.7690200424194336 and perplexity is 43.3375750349718
At time: 197.88142609596252 and batch: 750, loss is 3.718831009864807 and perplexity is 41.21618462265987
At time: 198.242041349411 and batch: 800, loss is 3.6303704023361205 and perplexity is 37.72678811993733
At time: 198.60249710083008 and batch: 850, loss is 3.591012897491455 and perplexity is 36.27079592474521
At time: 198.9627547264099 and batch: 900, loss is 3.501206316947937 and perplexity is 33.155423794132695
At time: 199.3226990699768 and batch: 950, loss is 3.66719012260437 and perplexity is 39.14176762722354
At time: 199.6820046901703 and batch: 1000, loss is 3.6725027847290037 and perplexity is 39.35026796912344
At time: 200.0422489643097 and batch: 1050, loss is 3.6005041885375975 and perplexity is 36.61669150650956
At time: 200.4020733833313 and batch: 1100, loss is 3.764573106765747 and perplexity is 43.14528349833367
At time: 200.7634253501892 and batch: 1150, loss is 3.673703017234802 and perplexity is 39.39752579436773
At time: 201.1228928565979 and batch: 1200, loss is 3.6265486240386964 and perplexity is 37.58287986774671
At time: 201.48221349716187 and batch: 1250, loss is 3.4879208183288575 and perplexity is 32.717850582367916
At time: 201.84269833564758 and batch: 1300, loss is 3.6020166206359865 and perplexity is 36.67211366664317
At time: 202.2022569179535 and batch: 1350, loss is 3.619697403907776 and perplexity is 37.32627132916105
At time: 202.5623800754547 and batch: 1400, loss is 3.4595072841644288 and perplexity is 31.8013036479508
At time: 202.9227557182312 and batch: 1450, loss is 3.5814253664016724 and perplexity is 35.92471024580279
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.289962377303686 and perplexity of 72.96372335598753
Finished 18 epochs...
Completing Train Step...
At time: 204.1037790775299 and batch: 50, loss is 3.7192085790634155 and perplexity is 41.23174952268605
At time: 204.49786520004272 and batch: 100, loss is 3.771503782272339 and perplexity is 43.44534808191633
At time: 204.88067746162415 and batch: 150, loss is 3.5959893655776978 and perplexity is 36.451746256463196
At time: 205.24877262115479 and batch: 200, loss is 3.7401296281814576 and perplexity is 42.10344760461635
At time: 205.60790610313416 and batch: 250, loss is 3.8124361133575437 and perplexity is 45.2605645383872
At time: 205.9799337387085 and batch: 300, loss is 3.799041075706482 and perplexity is 44.65833998714315
At time: 206.35034084320068 and batch: 350, loss is 3.781155300140381 and perplexity is 43.866691667044876
At time: 206.74024271965027 and batch: 400, loss is 3.575716757774353 and perplexity is 35.72021438372681
At time: 207.1135437488556 and batch: 450, loss is 3.6704127025604247 and perplexity is 39.2681085655736
At time: 207.4755415916443 and batch: 500, loss is 3.6570078563690185 and perplexity is 38.745237939707664
At time: 207.83448958396912 and batch: 550, loss is 3.7236163902282713 and perplexity is 41.41389241942422
At time: 208.19277572631836 and batch: 600, loss is 3.659707989692688 and perplexity is 38.84999661535052
At time: 208.55230903625488 and batch: 650, loss is 3.7028658771514893 and perplexity is 40.56338762621055
At time: 208.91041135787964 and batch: 700, loss is 3.7664631605148315 and perplexity is 43.22690751575628
At time: 209.26851272583008 and batch: 750, loss is 3.716458029747009 and perplexity is 41.11849538916417
At time: 209.6262722015381 and batch: 800, loss is 3.6281316471099854 and perplexity is 37.642421549156424
At time: 209.9852819442749 and batch: 850, loss is 3.589017963409424 and perplexity is 36.198510204369484
At time: 210.34314918518066 and batch: 900, loss is 3.4992840576171873 and perplexity is 33.09175168813552
At time: 210.70135641098022 and batch: 950, loss is 3.6655025482177734 and perplexity is 39.07576868745311
At time: 211.05993700027466 and batch: 1000, loss is 3.6710191488265993 and perplexity is 39.29192978580789
At time: 211.41945362091064 and batch: 1050, loss is 3.599129729270935 and perplexity is 36.56639792670996
At time: 211.7781126499176 and batch: 1100, loss is 3.763374128341675 and perplexity is 43.09358423366349
At time: 212.13722395896912 and batch: 1150, loss is 3.672745862007141 and perplexity is 39.3598342877856
At time: 212.4959568977356 and batch: 1200, loss is 3.6256946849823 and perplexity is 37.550800077817975
At time: 212.85512971878052 and batch: 1250, loss is 3.487263126373291 and perplexity is 32.696339389881
At time: 213.2128713130951 and batch: 1300, loss is 3.601428914070129 and perplexity is 36.65056755667273
At time: 213.57124209403992 and batch: 1350, loss is 3.61925808429718 and perplexity is 37.3098767676656
At time: 213.92957091331482 and batch: 1400, loss is 3.45922758102417 and perplexity is 31.79240996730933
At time: 214.2884886264801 and batch: 1450, loss is 3.5813194417953493 and perplexity is 35.92090513654364
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.289946727263621 and perplexity of 72.96258147972895
Finished 19 epochs...
Completing Train Step...
At time: 215.4819619655609 and batch: 50, loss is 3.7163024854660036 and perplexity is 41.11210013974796
At time: 215.84064173698425 and batch: 100, loss is 3.768510675430298 and perplexity is 43.31550592597476
At time: 216.19914722442627 and batch: 150, loss is 3.592915267944336 and perplexity is 36.339862089100826
At time: 216.5576367378235 and batch: 200, loss is 3.737187728881836 and perplexity is 41.97976552091771
At time: 216.91636848449707 and batch: 250, loss is 3.8095698833465574 and perplexity is 45.131023086476524
At time: 217.27513766288757 and batch: 300, loss is 3.7961591863632203 and perplexity is 44.5298248651729
At time: 217.6339521408081 and batch: 350, loss is 3.77830361366272 and perplexity is 43.74177581067996
At time: 217.99229264259338 and batch: 400, loss is 3.572870512008667 and perplexity is 35.61869042439551
At time: 218.35087704658508 and batch: 450, loss is 3.667580556869507 and perplexity is 39.15705289825585
At time: 218.71000456809998 and batch: 500, loss is 3.654298868179321 and perplexity is 38.64041958766266
At time: 219.06893658638 and batch: 550, loss is 3.7209715843200684 and perplexity is 41.304505429513725
At time: 219.42784690856934 and batch: 600, loss is 3.6572862529754637 and perplexity is 38.75602598407379
At time: 219.78662371635437 and batch: 650, loss is 3.700542230606079 and perplexity is 40.46924207353715
At time: 220.14482355117798 and batch: 700, loss is 3.764121298789978 and perplexity is 43.12579451810219
At time: 220.50359296798706 and batch: 750, loss is 3.7142999839782713 and perplexity is 41.029855473071514
At time: 220.86197304725647 and batch: 800, loss is 3.626076407432556 and perplexity is 37.56513679738253
At time: 221.2194173336029 and batch: 850, loss is 3.5871573877334595 and perplexity is 36.131222752885826
At time: 221.5780816078186 and batch: 900, loss is 3.4974768590927123 and perplexity is 33.03200232905083
At time: 221.9372193813324 and batch: 950, loss is 3.6638794422149656 and perplexity is 39.01239601692595
At time: 222.29605436325073 and batch: 1000, loss is 3.6695602226257322 and perplexity is 39.23464755539441
At time: 222.6555552482605 and batch: 1050, loss is 3.597759895324707 and perplexity is 36.51634232529689
At time: 223.01469540596008 and batch: 1100, loss is 3.76214581489563 and perplexity is 43.04068430021187
At time: 223.3733479976654 and batch: 1150, loss is 3.6717095232009886 and perplexity is 39.319065293003945
At time: 223.7328495979309 and batch: 1200, loss is 3.6247248363494875 and perplexity is 37.5143991402545
At time: 224.09220218658447 and batch: 1250, loss is 3.4864444589614867 and perplexity is 32.66958291615814
At time: 224.45093154907227 and batch: 1300, loss is 3.600657410621643 and perplexity is 36.62230242214015
At time: 224.80968141555786 and batch: 1350, loss is 3.618619194030762 and perplexity is 37.28604746352326
At time: 225.16766834259033 and batch: 1400, loss is 3.458709707260132 and perplexity is 31.77594977481052
At time: 225.5253462791443 and batch: 1450, loss is 3.5809448051452635 and perplexity is 35.90745036945704
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.28998533069578 and perplexity of 72.96539814015924
Annealing...
Finished 20 epochs...
Completing Train Step...
At time: 226.7929563522339 and batch: 50, loss is 3.717597107887268 and perplexity is 41.16535925415724
At time: 227.15095782279968 and batch: 100, loss is 3.770766816139221 and perplexity is 43.4133421268395
At time: 227.50926232337952 and batch: 150, loss is 3.596786770820618 and perplexity is 36.48082466213745
At time: 227.86739325523376 and batch: 200, loss is 3.7386563301086424 and perplexity is 42.04146234899256
At time: 228.22680020332336 and batch: 250, loss is 3.814842128753662 and perplexity is 45.36959326330249
At time: 228.5907552242279 and batch: 300, loss is 3.7997321319580077 and perplexity is 44.68921207812116
At time: 228.9656364917755 and batch: 350, loss is 3.7789557218551635 and perplexity is 43.7703094835479
At time: 229.33006620407104 and batch: 400, loss is 3.572655553817749 and perplexity is 35.6110347179969
At time: 229.68800139427185 and batch: 450, loss is 3.6703258609771727 and perplexity is 39.26469860891961
At time: 230.04749298095703 and batch: 500, loss is 3.6540895605087282 and perplexity is 38.6323326978016
At time: 230.40581488609314 and batch: 550, loss is 3.722277512550354 and perplexity is 41.35848138588361
At time: 230.78263878822327 and batch: 600, loss is 3.6577047300338745 and perplexity is 38.77224788583342
At time: 231.15148496627808 and batch: 650, loss is 3.7020022296905517 and perplexity is 40.52837028297651
At time: 231.51127672195435 and batch: 700, loss is 3.7653436517715453 and perplexity is 43.178541692879364
At time: 231.8705096244812 and batch: 750, loss is 3.713983654975891 and perplexity is 41.01687859241198
At time: 232.22889590263367 and batch: 800, loss is 3.6265150451660157 and perplexity is 37.58161789819654
At time: 232.58660554885864 and batch: 850, loss is 3.584837236404419 and perplexity is 36.0474900222608
At time: 232.94429326057434 and batch: 900, loss is 3.493819875717163 and perplexity is 32.91142545386455
At time: 233.30251550674438 and batch: 950, loss is 3.6594043588638305 and perplexity is 38.83820234931909
At time: 233.67395305633545 and batch: 1000, loss is 3.663856587409973 and perplexity is 39.01150440641152
At time: 234.0325038433075 and batch: 1050, loss is 3.593705139160156 and perplexity is 36.36857723929424
At time: 234.3923478126526 and batch: 1100, loss is 3.7573931074142455 and perplexity is 42.83660985514513
At time: 234.7507929801941 and batch: 1150, loss is 3.665692439079285 and perplexity is 39.083189523385556
At time: 235.1099157333374 and batch: 1200, loss is 3.617768235206604 and perplexity is 37.25433206857764
At time: 235.46864104270935 and batch: 1250, loss is 3.479460344314575 and perplexity is 32.442209728042286
At time: 235.82710313796997 and batch: 1300, loss is 3.5925501728057863 and perplexity is 36.32659700377295
At time: 236.18596482276917 and batch: 1350, loss is 3.611442093849182 and perplexity is 37.01939978864152
At time: 236.55866813659668 and batch: 1400, loss is 3.4482984495162965 and perplexity is 31.446838376259105
At time: 236.9319121837616 and batch: 1450, loss is 3.5703648710250855 and perplexity is 35.5295544918442
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2886942023904915 and perplexity of 72.87125124025619
Finished 21 epochs...
Completing Train Step...
At time: 238.15324640274048 and batch: 50, loss is 3.7158082723617554 and perplexity is 41.09178702103391
At time: 238.52532482147217 and batch: 100, loss is 3.7682285022735598 and perplexity is 43.303285177196635
At time: 238.88426780700684 and batch: 150, loss is 3.593194661140442 and perplexity is 36.35001661780301
At time: 239.24368286132812 and batch: 200, loss is 3.7361211252212523 and perplexity is 41.93501361985605
At time: 239.6032145023346 and batch: 250, loss is 3.8108590173721315 and perplexity is 45.18924054093451
At time: 239.9622986316681 and batch: 300, loss is 3.7973035097122194 and perplexity is 44.58081054998405
At time: 240.3207938671112 and batch: 350, loss is 3.776962327957153 and perplexity is 43.68314492122593
At time: 240.68027091026306 and batch: 400, loss is 3.5705147981643677 and perplexity is 35.53488173564837
At time: 241.03923392295837 and batch: 450, loss is 3.667370915412903 and perplexity is 39.14884481705704
At time: 241.39870977401733 and batch: 500, loss is 3.6519319868087767 and perplexity is 38.54907044732563
At time: 241.75864148139954 and batch: 550, loss is 3.7200048971176147 and perplexity is 41.264596185696846
At time: 242.11853003501892 and batch: 600, loss is 3.6555122470855714 and perplexity is 38.6873335141475
At time: 242.47794842720032 and batch: 650, loss is 3.699685854911804 and perplexity is 40.434600033677256
At time: 242.85065865516663 and batch: 700, loss is 3.7631143283843995 and perplexity is 43.08238997651747
At time: 243.21119499206543 and batch: 750, loss is 3.7121906423568727 and perplexity is 40.943400704578394
At time: 243.57089805603027 and batch: 800, loss is 3.624916505813599 and perplexity is 37.52159019416488
At time: 243.93053221702576 and batch: 850, loss is 3.583507957458496 and perplexity is 35.99960468625637
At time: 244.29029440879822 and batch: 900, loss is 3.4928196620941163 and perplexity is 32.87852345502845
At time: 244.6487901210785 and batch: 950, loss is 3.6585690355300904 and perplexity is 38.80577343885463
At time: 245.0075445175171 and batch: 1000, loss is 3.663373646736145 and perplexity is 38.99266871281381
At time: 245.36653017997742 and batch: 1050, loss is 3.5934639167785645 and perplexity is 36.3598053825041
At time: 245.75061535835266 and batch: 1100, loss is 3.7575881385803225 and perplexity is 42.84496514386033
At time: 246.13350892066956 and batch: 1150, loss is 3.665559730529785 and perplexity is 39.07800319413681
At time: 246.500013589859 and batch: 1200, loss is 3.6177855587005614 and perplexity is 37.254977449364226
At time: 246.88475131988525 and batch: 1250, loss is 3.479679980278015 and perplexity is 32.44933598659471
At time: 247.25845313072205 and batch: 1300, loss is 3.593287606239319 and perplexity is 36.3533953307067
At time: 247.6182677745819 and batch: 1350, loss is 3.612283787727356 and perplexity is 37.05057190766785
At time: 247.97734928131104 and batch: 1400, loss is 3.449425988197327 and perplexity is 31.482315900306105
At time: 248.33726024627686 and batch: 1450, loss is 3.5718451309204102 and perplexity is 35.58218641130658
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.288458147619525 and perplexity of 72.85405166383552
Finished 22 epochs...
Completing Train Step...
At time: 249.52068328857422 and batch: 50, loss is 3.7151351261138914 and perplexity is 41.06413554656995
At time: 249.89131951332092 and batch: 100, loss is 3.7671016454696655 and perplexity is 43.25451605873083
At time: 250.24947786331177 and batch: 150, loss is 3.591856722831726 and perplexity is 36.30141505824184
At time: 250.6071617603302 and batch: 200, loss is 3.735080919265747 and perplexity is 41.89141524851846
At time: 250.96464109420776 and batch: 250, loss is 3.8095171213150025 and perplexity is 45.12864194482982
At time: 251.32367491722107 and batch: 300, loss is 3.796051664352417 and perplexity is 44.52503718625772
At time: 251.68228769302368 and batch: 350, loss is 3.775837163925171 and perplexity is 43.63402185869071
At time: 252.0408308506012 and batch: 400, loss is 3.5694432735443113 and perplexity is 35.49682562766738
At time: 252.41268610954285 and batch: 450, loss is 3.666055107116699 and perplexity is 39.09736631760558
At time: 252.77097916603088 and batch: 500, loss is 3.6508604669570923 and perplexity is 38.507786475325155
At time: 253.12966227531433 and batch: 550, loss is 3.718976092338562 and perplexity is 41.22216480248283
At time: 253.48793387413025 and batch: 600, loss is 3.6545609521865843 and perplexity is 38.65054795085356
At time: 253.84720730781555 and batch: 650, loss is 3.698644685745239 and perplexity is 40.39252268348073
At time: 254.20613145828247 and batch: 700, loss is 3.7620926475524903 and perplexity is 43.038396002212615
At time: 254.58153700828552 and batch: 750, loss is 3.7113348197937013 and perplexity is 40.90837540829967
At time: 254.93877243995667 and batch: 800, loss is 3.6241189146041872 and perplexity is 37.49167523520289
At time: 255.29744935035706 and batch: 850, loss is 3.582907729148865 and perplexity is 35.9780031879521
At time: 255.6563422679901 and batch: 900, loss is 3.4923360443115232 and perplexity is 32.86262666071624
At time: 256.0152208805084 and batch: 950, loss is 3.65822114944458 and perplexity is 38.7922757981946
At time: 256.3738946914673 and batch: 1000, loss is 3.6631067514419557 and perplexity is 38.982263141687234
At time: 256.73252606391907 and batch: 1050, loss is 3.5932939291000365 and perplexity is 36.353625188888664
At time: 257.0910973548889 and batch: 1100, loss is 3.7576744413375853 and perplexity is 42.84866294204987
At time: 257.450989484787 and batch: 1150, loss is 3.6656257009506223 and perplexity is 39.080581271490495
At time: 257.80952167510986 and batch: 1200, loss is 3.6178651428222657 and perplexity is 37.25794247200645
At time: 258.16847825050354 and batch: 1250, loss is 3.4799313735961914 and perplexity is 32.45749455830324
At time: 258.5266840457916 and batch: 1300, loss is 3.5936874389648437 and perplexity is 36.36793351407091
At time: 258.88462924957275 and batch: 1350, loss is 3.6127461862564085 and perplexity is 37.06770799916494
At time: 259.2424750328064 and batch: 1400, loss is 3.450005235671997 and perplexity is 31.50055723490159
At time: 259.60139632225037 and batch: 1450, loss is 3.5725709342956544 and perplexity is 35.608021456749924
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.288342858991053 and perplexity of 72.84565290429057
Finished 23 epochs...
Completing Train Step...
At time: 260.7980306148529 and batch: 50, loss is 3.7145362186431883 and perplexity is 41.03954929219376
At time: 261.156067609787 and batch: 100, loss is 3.766231460571289 and perplexity is 43.21689300395107
At time: 261.52694439888 and batch: 150, loss is 3.5909128761291504 and perplexity is 36.26716825175037
At time: 261.8846712112427 and batch: 200, loss is 3.7342675018310545 and perplexity is 41.85735389591845
At time: 262.24368143081665 and batch: 250, loss is 3.808590235710144 and perplexity is 45.08683223564642
At time: 262.60212802886963 and batch: 300, loss is 3.7951219844818116 and perplexity is 44.48366239108485
At time: 262.9600598812103 and batch: 350, loss is 3.774982032775879 and perplexity is 43.596724996557526
At time: 263.31868839263916 and batch: 400, loss is 3.5686366319656373 and perplexity is 35.468203957471715
At time: 263.6774935722351 and batch: 450, loss is 3.665125403404236 and perplexity is 39.061034242642016
At time: 264.0354371070862 and batch: 500, loss is 3.650062394142151 and perplexity is 38.47706671770786
At time: 264.393438577652 and batch: 550, loss is 3.718206691741943 and perplexity is 41.1904606424537
At time: 264.75223302841187 and batch: 600, loss is 3.65387779712677 and perplexity is 38.62415265052438
At time: 265.11100912094116 and batch: 650, loss is 3.6979371404647825 and perplexity is 40.363953252965025
At time: 265.46954250335693 and batch: 700, loss is 3.761389956474304 and perplexity is 43.00816392847065
At time: 265.8276798725128 and batch: 750, loss is 3.7107290840148925 and perplexity is 40.88360324511214
At time: 266.1865117549896 and batch: 800, loss is 3.6235486841201783 and perplexity is 37.47030243337792
At time: 266.54518604278564 and batch: 850, loss is 3.5824734687805178 and perplexity is 35.962382758947406
At time: 266.9031009674072 and batch: 900, loss is 3.4919655752182006 and perplexity is 32.85045432808877
At time: 267.2619836330414 and batch: 950, loss is 3.657956805229187 and perplexity is 38.782022639726684
At time: 267.6199645996094 and batch: 1000, loss is 3.6628926897048952 and perplexity is 38.973919423791806
At time: 267.9777362346649 and batch: 1050, loss is 3.59314079284668 and perplexity is 36.34805855716875
At time: 268.3366162776947 and batch: 1100, loss is 3.757673673629761 and perplexity is 42.848630046808694
At time: 268.69431233406067 and batch: 1150, loss is 3.665661268234253 and perplexity is 39.08197128632841
At time: 269.0516378879547 and batch: 1200, loss is 3.6178972911834717 and perplexity is 37.259140273052395
At time: 269.4095149040222 and batch: 1250, loss is 3.480085139274597 and perplexity is 32.462485790703624
At time: 269.7675392627716 and batch: 1300, loss is 3.593896713256836 and perplexity is 36.37554518404393
At time: 270.1251971721649 and batch: 1350, loss is 3.6130048131942747 and perplexity is 37.077295946775806
At time: 270.4828782081604 and batch: 1400, loss is 3.4503254985809324 and perplexity is 31.510647310646984
At time: 270.8408167362213 and batch: 1450, loss is 3.572983355522156 and perplexity is 35.62270998935553
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.288274520482773 and perplexity of 72.84067491113268
Finished 24 epochs...
Completing Train Step...
At time: 272.03381299972534 and batch: 50, loss is 3.713967218399048 and perplexity is 41.01620442087568
At time: 272.3934805393219 and batch: 100, loss is 3.765486283302307 and perplexity is 43.184700753604766
At time: 272.75399351119995 and batch: 150, loss is 3.5901275730133055 and perplexity is 36.238698711591795
At time: 273.11400294303894 and batch: 200, loss is 3.7335552263259886 and perplexity is 41.82755054339052
At time: 273.472531080246 and batch: 250, loss is 3.807824659347534 and perplexity is 45.052328032108434
At time: 273.8315176963806 and batch: 300, loss is 3.7943518447875975 and perplexity is 44.44941694551457
At time: 274.19296979904175 and batch: 350, loss is 3.7742642402648925 and perplexity is 43.5654428222498
At time: 274.5884962081909 and batch: 400, loss is 3.5679487133026124 and perplexity is 35.4438131084474
At time: 274.9658856391907 and batch: 450, loss is 3.6643696880340575 and perplexity is 39.031526369870626
At time: 275.3334741592407 and batch: 500, loss is 3.649389343261719 and perplexity is 38.45117840712945
At time: 275.69495463371277 and batch: 550, loss is 3.717552900314331 and perplexity is 41.16353947375987
At time: 276.05520009994507 and batch: 600, loss is 3.6533000612258912 and perplexity is 38.60184453561708
At time: 276.4157557487488 and batch: 650, loss is 3.6973645544052123 and perplexity is 40.34084803151835
At time: 276.77680468559265 and batch: 700, loss is 3.7608189010620117 and perplexity is 42.98361089492512
At time: 277.1371192932129 and batch: 750, loss is 3.7102256345748903 and perplexity is 40.863025598290136
At time: 277.4972484111786 and batch: 800, loss is 3.6230725908279418 and perplexity is 37.452467319657195
At time: 277.856703042984 and batch: 850, loss is 3.5821007347106932 and perplexity is 35.94898085148999
At time: 278.2173228263855 and batch: 900, loss is 3.4916351079940795 and perplexity is 32.83960012321411
At time: 278.5770351886749 and batch: 950, loss is 3.657709250450134 and perplexity is 38.77242315292933
At time: 278.93678975105286 and batch: 1000, loss is 3.6626917934417724 and perplexity is 38.96609049544787
At time: 279.296151638031 and batch: 1050, loss is 3.592981195449829 and perplexity is 36.342257964534504
At time: 279.6690604686737 and batch: 1100, loss is 3.7576159858703613 and perplexity is 42.846158276644076
At time: 280.02898597717285 and batch: 1150, loss is 3.6656486129760744 and perplexity is 39.08147669702124
At time: 280.39026379585266 and batch: 1200, loss is 3.6178844785690307 and perplexity is 37.258662889111946
At time: 280.75005865097046 and batch: 1250, loss is 3.48016047000885 and perplexity is 32.464931305703985
At time: 281.11011505126953 and batch: 1300, loss is 3.5939969062805175 and perplexity is 36.379189942490626
At time: 281.4706840515137 and batch: 1350, loss is 3.6131447744369507 and perplexity is 37.08248569436487
At time: 281.8310925960541 and batch: 1400, loss is 3.450505771636963 and perplexity is 31.516328343388356
At time: 282.19089818000793 and batch: 1450, loss is 3.5732310152053834 and perplexity is 35.631533390982526
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.288232004540598 and perplexity of 72.83757808704284
Finished 25 epochs...
Completing Train Step...
At time: 283.37177991867065 and batch: 50, loss is 3.71341646194458 and perplexity is 40.99362070118866
At time: 283.74312376976013 and batch: 100, loss is 3.764815230369568 and perplexity is 43.15573125463533
At time: 284.100861787796 and batch: 150, loss is 3.5894272327423096 and perplexity is 36.21332817655624
At time: 284.4588520526886 and batch: 200, loss is 3.7329041957855225 and perplexity is 41.8003283927411
At time: 284.8166437149048 and batch: 250, loss is 3.8071465349197386 and perplexity is 45.02178730431794
At time: 285.1739344596863 and batch: 300, loss is 3.7936755514144895 and perplexity is 44.4193662620802
At time: 285.5310709476471 and batch: 350, loss is 3.7736263704299926 and perplexity is 43.53766260145378
At time: 285.8893699645996 and batch: 400, loss is 3.56732958316803 and perplexity is 35.42187556746456
At time: 286.247998714447 and batch: 450, loss is 3.6637117576599123 and perplexity is 39.00585478910505
At time: 286.60591197013855 and batch: 500, loss is 3.6487869119644163 and perplexity is 38.42802118985541
At time: 286.9636709690094 and batch: 550, loss is 3.716966943740845 and perplexity is 41.13942649248712
At time: 287.3215386867523 and batch: 600, loss is 3.6527790355682375 and perplexity is 38.58173722284907
At time: 287.6792998313904 and batch: 650, loss is 3.6968610954284666 and perplexity is 40.32054318120582
At time: 288.0375466346741 and batch: 700, loss is 3.7603159093856813 and perplexity is 42.96199593295504
At time: 288.39508152008057 and batch: 750, loss is 3.709775280952454 and perplexity is 40.84462692995267
At time: 288.76571822166443 and batch: 800, loss is 3.6226460790634154 and perplexity is 37.436496807782525
At time: 289.1234030723572 and batch: 850, loss is 3.581756796836853 and perplexity is 35.93661876146654
At time: 289.4809374809265 and batch: 900, loss is 3.4913224840164183 and perplexity is 32.82933528140023
At time: 289.838725566864 and batch: 950, loss is 3.6574632501602173 and perplexity is 38.76288629867548
At time: 290.197039604187 and batch: 1000, loss is 3.6624911642074585 and perplexity is 38.9582735427284
At time: 290.5548710823059 and batch: 1050, loss is 3.592809739112854 and perplexity is 36.336027388257655
At time: 290.9131021499634 and batch: 1100, loss is 3.7575204229354857 and perplexity is 42.842063967646226
At time: 291.27260422706604 and batch: 1150, loss is 3.6655968952178957 and perplexity is 39.07945554292538
At time: 291.63162779808044 and batch: 1200, loss is 3.617837080955505 and perplexity is 37.25689695925861
At time: 291.9900755882263 and batch: 1250, loss is 3.4801799964904787 and perplexity is 32.46556523777791
At time: 292.3491587638855 and batch: 1300, loss is 3.5940299892425536 and perplexity is 36.3803934937588
At time: 292.7082636356354 and batch: 1350, loss is 3.613210654258728 and perplexity is 37.08492876238704
At time: 293.06645011901855 and batch: 1400, loss is 3.4506025409698484 and perplexity is 31.51937830502614
At time: 293.4261305332184 and batch: 1450, loss is 3.5733809328079222 and perplexity is 35.63687558547777
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.288209311982506 and perplexity of 72.8359252348246
Finished 26 epochs...
Completing Train Step...
At time: 294.6055703163147 and batch: 50, loss is 3.7128796863555906 and perplexity is 40.97162223094109
At time: 294.97622084617615 and batch: 100, loss is 3.764193558692932 and perplexity is 43.12891089642213
At time: 295.33439087867737 and batch: 150, loss is 3.588780779838562 and perplexity is 36.189925530571365
At time: 295.6933162212372 and batch: 200, loss is 3.732295479774475 and perplexity is 41.77489160625643
At time: 296.05167388916016 and batch: 250, loss is 3.806524815559387 and perplexity is 44.9938050869577
At time: 296.41130089759827 and batch: 300, loss is 3.7930599308013915 and perplexity is 44.39202920008132
At time: 296.7702445983887 and batch: 350, loss is 3.7730401706695558 and perplexity is 43.512148313032334
At time: 297.1288757324219 and batch: 400, loss is 3.5667559909820556 and perplexity is 35.4015636823527
At time: 297.48725056648254 and batch: 450, loss is 3.6631153440475464 and perplexity is 38.98259810233853
At time: 297.84619307518005 and batch: 500, loss is 3.648230347633362 and perplexity is 38.406639474650085
At time: 298.2183380126953 and batch: 550, loss is 3.7164261627197264 and perplexity is 41.11718508582762
At time: 298.57680559158325 and batch: 600, loss is 3.652293848991394 and perplexity is 38.56302242228938
At time: 298.9360980987549 and batch: 650, loss is 3.6963990259170534 and perplexity is 40.30191659123924
At time: 299.3116400241852 and batch: 700, loss is 3.7598531675338744 and perplexity is 42.942120218416854
At time: 299.6787552833557 and batch: 750, loss is 3.7093571853637695 and perplexity is 40.8275535410148
At time: 300.03727674484253 and batch: 800, loss is 3.6222496223449707 and perplexity is 37.42165779881481
At time: 300.3960657119751 and batch: 850, loss is 3.5814288568496706 and perplexity is 35.92483563935459
At time: 300.7543795108795 and batch: 900, loss is 3.491019468307495 and perplexity is 32.819388984114724
At time: 301.11261916160583 and batch: 950, loss is 3.657215700149536 and perplexity is 38.753291733374574
At time: 301.4713695049286 and batch: 1000, loss is 3.6622866868972777 and perplexity is 38.950308274131196
At time: 301.8521490097046 and batch: 1050, loss is 3.592626757621765 and perplexity is 36.32937917605434
At time: 302.22009205818176 and batch: 1100, loss is 3.757399392127991 and perplexity is 42.83687907182187
At time: 302.57873916625977 and batch: 1150, loss is 3.665516424179077 and perplexity is 39.07631090506921
At time: 302.93763852119446 and batch: 1200, loss is 3.6177636861801146 and perplexity is 37.25416259801968
At time: 303.2963635921478 and batch: 1250, loss is 3.480160117149353 and perplexity is 32.46491985014667
At time: 303.6553530693054 and batch: 1300, loss is 3.5940186643600462 and perplexity is 36.379981492409854
At time: 304.01369285583496 and batch: 1350, loss is 3.6132276678085327 and perplexity is 37.08555971403688
At time: 304.3717966079712 and batch: 1400, loss is 3.450645432472229 and perplexity is 31.520730247508958
At time: 304.7292959690094 and batch: 1450, loss is 3.573467607498169 and perplexity is 35.63996453449542
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.288197835286458 and perplexity of 72.83508932384609
Finished 27 epochs...
Completing Train Step...
At time: 305.92089796066284 and batch: 50, loss is 3.7123546266555785 and perplexity is 40.95011532996108
At time: 306.2967441082001 and batch: 100, loss is 3.7636068058013916 and perplexity is 43.103612305981024
At time: 306.66982674598694 and batch: 150, loss is 3.5881723976135254 and perplexity is 36.167914919264405
At time: 307.0310688018799 and batch: 200, loss is 3.7317183017730713 and perplexity is 41.750787014799414
At time: 307.40243220329285 and batch: 250, loss is 3.8059430742263793 and perplexity is 44.96763794280194
At time: 307.7607071399689 and batch: 300, loss is 3.7924865674972534 and perplexity is 44.366583734986826
At time: 308.1186490058899 and batch: 350, loss is 3.7724897956848142 and perplexity is 43.48820690404913
At time: 308.4775846004486 and batch: 400, loss is 3.566214723587036 and perplexity is 35.382407155068236
At time: 308.83632135391235 and batch: 450, loss is 3.662560725212097 and perplexity is 38.960983613631555
At time: 309.194130897522 and batch: 500, loss is 3.6477058935165405 and perplexity is 38.38650223545489
At time: 309.55203652381897 and batch: 550, loss is 3.7159170150756835 and perplexity is 41.09625569643828
At time: 309.9099762439728 and batch: 600, loss is 3.6518336868286134 and perplexity is 38.545281260706886
At time: 310.26820135116577 and batch: 650, loss is 3.695963935852051 and perplexity is 40.28438544182086
At time: 310.62726616859436 and batch: 700, loss is 3.7594167804718017 and perplexity is 42.923384920953595
At time: 310.98736095428467 and batch: 750, loss is 3.7089605712890625 and perplexity is 40.8113639693628
At time: 311.34609818458557 and batch: 800, loss is 3.6218726778030397 and perplexity is 37.40755456739258
At time: 311.70495080947876 and batch: 850, loss is 3.5811109495162965 and perplexity is 35.91341668583529
At time: 312.06251978874207 and batch: 900, loss is 3.4907222414016723 and perplexity is 32.80963562822768
At time: 312.41979360580444 and batch: 950, loss is 3.6569661283493042 and perplexity is 38.74362121138675
At time: 312.77812576293945 and batch: 1000, loss is 3.6620778465270996 and perplexity is 38.94217472666877
At time: 313.1351275444031 and batch: 1050, loss is 3.5924344205856324 and perplexity is 36.322392362872094
At time: 313.49279522895813 and batch: 1100, loss is 3.757260813713074 and perplexity is 42.83094321632032
At time: 313.85127329826355 and batch: 1150, loss is 3.6654147863388062 and perplexity is 39.07233947505028
At time: 314.21041893959045 and batch: 1200, loss is 3.6176705503463746 and perplexity is 37.2506930620974
At time: 314.57467699050903 and batch: 1250, loss is 3.4801112365722657 and perplexity is 32.463332984913066
At time: 314.94082403182983 and batch: 1300, loss is 3.5939763879776 and perplexity is 36.378443510909264
At time: 315.2992353439331 and batch: 1350, loss is 3.6132105445861815 and perplexity is 37.08492469518868
At time: 315.65751600265503 and batch: 1400, loss is 3.45065092086792 and perplexity is 31.520903246223774
At time: 316.01643419265747 and batch: 1450, loss is 3.573511128425598 and perplexity is 35.641515652558304
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.288192879440438 and perplexity of 72.83472836525299
Finished 28 epochs...
Completing Train Step...
At time: 317.2083327770233 and batch: 50, loss is 3.711839828491211 and perplexity is 40.929039711068995
At time: 317.5681836605072 and batch: 100, loss is 3.763046350479126 and perplexity is 43.07946142543219
At time: 317.9283220767975 and batch: 150, loss is 3.5875925731658938 and perplexity is 36.146949956560675
At time: 318.288645029068 and batch: 200, loss is 3.731165533065796 and perplexity is 41.727714863602586
At time: 318.64927554130554 and batch: 250, loss is 3.8053916454315186 and perplexity is 44.94284832788531
At time: 319.0088896751404 and batch: 300, loss is 3.7919440937042235 and perplexity is 44.34252255289474
At time: 319.3676378726959 and batch: 350, loss is 3.771965727806091 and perplexity is 43.46542210262021
At time: 319.72833824157715 and batch: 400, loss is 3.565697503089905 and perplexity is 35.36411138073242
At time: 320.0876476764679 and batch: 450, loss is 3.662035737037659 and perplexity is 38.94053492609914
At time: 320.44725346565247 and batch: 500, loss is 3.647205324172974 and perplexity is 38.36729193767327
At time: 320.80676794052124 and batch: 550, loss is 3.7154316568374632 and perplexity is 41.07631412996926
At time: 321.1666808128357 and batch: 600, loss is 3.651392283439636 and perplexity is 38.528270997399446
At time: 321.5265302658081 and batch: 650, loss is 3.6955483293533327 and perplexity is 40.267646468088444
At time: 321.88594245910645 and batch: 700, loss is 3.758998599052429 and perplexity is 42.90543891152844
At time: 322.24514079093933 and batch: 750, loss is 3.708579111099243 and perplexity is 40.795799027607806
At time: 322.60497188568115 and batch: 800, loss is 3.6215098762512206 and perplexity is 37.393985510132126
At time: 322.9646363258362 and batch: 850, loss is 3.5808000135421754 and perplexity is 35.902251648529884
At time: 323.3243327140808 and batch: 900, loss is 3.4904288053512573 and perplexity is 32.800009510727406
At time: 323.6838312149048 and batch: 950, loss is 3.6567147064208982 and perplexity is 38.73388143987573
At time: 324.0436944961548 and batch: 1000, loss is 3.661864748001099 and perplexity is 38.93387709077364
At time: 324.4033932685852 and batch: 1050, loss is 3.59223436832428 and perplexity is 36.31512671292125
At time: 324.762770652771 and batch: 1100, loss is 3.7571093368530275 and perplexity is 42.8244558108874
At time: 325.1228172779083 and batch: 1150, loss is 3.6652972984313963 and perplexity is 39.06774921730291
At time: 325.4987027645111 and batch: 1200, loss is 3.6175617456436155 and perplexity is 37.24664023199869
At time: 325.8585002422333 and batch: 1250, loss is 3.4800406646728517 and perplexity is 32.46104206668118
At time: 326.21843957901 and batch: 1300, loss is 3.5939112091064453 and perplexity is 36.37607248229819
At time: 326.57781648635864 and batch: 1350, loss is 3.6131688451766966 and perplexity is 37.083378307970044
At time: 326.9379997253418 and batch: 1400, loss is 3.4506296157836913 and perplexity is 31.52023169787887
At time: 327.2973668575287 and batch: 1450, loss is 3.573523359298706 and perplexity is 35.64195158207952
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.288196531116453 and perplexity of 72.83499433456923
Annealing...
Finished 29 epochs...
Completing Train Step...
At time: 328.47999358177185 and batch: 50, loss is 3.7120785331726074 and perplexity is 40.938810830612674
At time: 328.8565299510956 and batch: 100, loss is 3.7635757398605345 and perplexity is 43.10227327250967
At time: 329.21495151519775 and batch: 150, loss is 3.588243727684021 and perplexity is 36.17049487119825
At time: 329.5737624168396 and batch: 200, loss is 3.7316504383087157 and perplexity is 41.747953757891416
At time: 329.93196749687195 and batch: 250, loss is 3.8062972164154054 and perplexity is 44.9835657007174
At time: 330.2909462451935 and batch: 300, loss is 3.7925991201400757 and perplexity is 44.371577592269844
At time: 330.66294717788696 and batch: 350, loss is 3.7720179748535156 and perplexity is 43.46769310191612
At time: 331.03721857070923 and batch: 400, loss is 3.5657989501953127 and perplexity is 35.367699149448605
At time: 331.4022834300995 and batch: 450, loss is 3.662840151786804 and perplexity is 38.971871868993034
At time: 331.7612888813019 and batch: 500, loss is 3.64731116771698 and perplexity is 38.371353082745074
At time: 332.11998653411865 and batch: 550, loss is 3.715626015663147 and perplexity is 41.08429845003339
At time: 332.47942447662354 and batch: 600, loss is 3.6513126850128175 and perplexity is 38.52520432969259
At time: 332.83791995048523 and batch: 650, loss is 3.6952344799041748 and perplexity is 40.25501047242941
At time: 333.19779896736145 and batch: 700, loss is 3.7589216327667234 and perplexity is 42.90213676633741
At time: 333.5763370990753 and batch: 750, loss is 3.7082134962081907 and perplexity is 40.78088620233255
At time: 333.9434220790863 and batch: 800, loss is 3.6209097003936765 and perplexity is 37.371549276328004
At time: 334.3010070323944 and batch: 850, loss is 3.580370855331421 and perplexity is 35.88684720815782
At time: 334.67297291755676 and batch: 900, loss is 3.4896052932739257 and perplexity is 32.77300942573266
At time: 335.0309729576111 and batch: 950, loss is 3.655714249610901 and perplexity is 38.69514924258748
At time: 335.3887140750885 and batch: 1000, loss is 3.6602293109893798 and perplexity is 38.87025522612631
At time: 335.74771785736084 and batch: 1050, loss is 3.590113091468811 and perplexity is 36.238173923063854
At time: 336.10698652267456 and batch: 1100, loss is 3.755430989265442 and perplexity is 42.75264177010604
At time: 336.4654746055603 and batch: 1150, loss is 3.6637374114990235 and perplexity is 39.00685545186357
At time: 336.82406187057495 and batch: 1200, loss is 3.6154349708557127 and perplexity is 37.16750919339505
At time: 337.18276858329773 and batch: 1250, loss is 3.4783719635009764 and perplexity is 32.40691945753386
At time: 337.54179978370667 and batch: 1300, loss is 3.591547508239746 and perplexity is 36.2901918662731
At time: 337.9009370803833 and batch: 1350, loss is 3.6106480836868284 and perplexity is 36.990017675397034
At time: 338.2596652507782 and batch: 1400, loss is 3.4482421398162844 and perplexity is 31.44506766407841
At time: 338.6184322834015 and batch: 1450, loss is 3.5708554649353026 and perplexity is 35.546989351278874
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.288089328342014 and perplexity of 72.82718663961109
Finished 30 epochs...
Completing Train Step...
At time: 339.7977981567383 and batch: 50, loss is 3.7117326164245608 and perplexity is 40.92465185935509
At time: 340.1686849594116 and batch: 100, loss is 3.763317933082581 and perplexity is 43.09116264657368
At time: 340.5267701148987 and batch: 150, loss is 3.587938642501831 and perplexity is 36.15946147232941
At time: 340.8852903842926 and batch: 200, loss is 3.731343297958374 and perplexity is 41.73513324569725
At time: 341.24330472946167 and batch: 250, loss is 3.805681338310242 and perplexity is 44.955869837023606
At time: 341.6021361351013 and batch: 300, loss is 3.7923016119003297 and perplexity is 44.35837864582063
At time: 341.9599666595459 and batch: 350, loss is 3.7718121814727783 and perplexity is 43.458748658784984
At time: 342.3171217441559 and batch: 400, loss is 3.565540132522583 and perplexity is 35.35854654834349
At time: 342.67518067359924 and batch: 450, loss is 3.6624875688552856 and perplexity is 38.958133474266766
At time: 343.0333921909332 and batch: 500, loss is 3.6470449447631834 and perplexity is 38.361139107443876
At time: 343.39241456985474 and batch: 550, loss is 3.715292520523071 and perplexity is 41.07059932059038
At time: 343.75120544433594 and batch: 600, loss is 3.650964255332947 and perplexity is 38.511783343351816
At time: 344.1226119995117 and batch: 650, loss is 3.695024833679199 and perplexity is 40.24657204602054
At time: 344.48138093948364 and batch: 700, loss is 3.7587274265289308 and perplexity is 42.89380571276022
At time: 344.8399910926819 and batch: 750, loss is 3.7079845237731934 and perplexity is 40.77154957247369
At time: 345.19799304008484 and batch: 800, loss is 3.620801854133606 and perplexity is 37.36751911182849
At time: 345.55557680130005 and batch: 850, loss is 3.5801721525192263 and perplexity is 35.87971709910657
At time: 345.9259946346283 and batch: 900, loss is 3.4894364261627198 and perplexity is 32.76747560955834
At time: 346.30773663520813 and batch: 950, loss is 3.655589990615845 and perplexity is 38.690341320948995
At time: 346.6777675151825 and batch: 1000, loss is 3.660227394104004 and perplexity is 38.87018071637393
At time: 347.0365090370178 and batch: 1050, loss is 3.5902524518966676 and perplexity is 36.243224442399615
At time: 347.39463114738464 and batch: 1100, loss is 3.755570330619812 and perplexity is 42.758599396175384
At time: 347.753812789917 and batch: 1150, loss is 3.6638387393951417 and perplexity is 39.01080813471583
At time: 348.11182498931885 and batch: 1200, loss is 3.615534529685974 and perplexity is 37.17120973134162
At time: 348.4876697063446 and batch: 1250, loss is 3.4784011173248293 and perplexity is 32.40786425692753
At time: 348.8518154621124 and batch: 1300, loss is 3.591709027290344 and perplexity is 36.29605389701143
At time: 349.2099258899689 and batch: 1350, loss is 3.610762872695923 and perplexity is 36.99426396658149
At time: 349.56808161735535 and batch: 1400, loss is 3.4484076738357543 and perplexity is 31.450273323366318
At time: 349.9266982078552 and batch: 1450, loss is 3.5710893297195434 and perplexity is 35.555303512430775
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.288039769881811 and perplexity of 72.8235775258121
Finished 31 epochs...
Completing Train Step...
At time: 351.117830991745 and batch: 50, loss is 3.711498432159424 and perplexity is 40.915069071946235
At time: 351.47767400741577 and batch: 100, loss is 3.7631264686584474 and perplexity is 43.08291301171331
At time: 351.8376421928406 and batch: 150, loss is 3.5876983070373534 and perplexity is 36.150772115583315
At time: 352.19752860069275 and batch: 200, loss is 3.7311261510849 and perplexity is 41.72607157589117
At time: 352.5578429698944 and batch: 250, loss is 3.805277523994446 and perplexity is 44.93771967809799
At time: 352.9175159931183 and batch: 300, loss is 3.7920871067047117 and perplexity is 44.34886456357843
At time: 353.29054260253906 and batch: 350, loss is 3.7716477012634275 and perplexity is 43.45160114253606
At time: 353.65028047561646 and batch: 400, loss is 3.565346431732178 and perplexity is 35.35169823321294
At time: 354.0101249217987 and batch: 450, loss is 3.6622270154953003 and perplexity is 38.94798412397237
At time: 354.37028551101685 and batch: 500, loss is 3.6468545532226564 and perplexity is 38.353836166304006
At time: 354.7306938171387 and batch: 550, loss is 3.715057997703552 and perplexity is 41.06096845721114
At time: 355.0906391143799 and batch: 600, loss is 3.650723657608032 and perplexity is 38.50251861047852
At time: 355.4508581161499 and batch: 650, loss is 3.6948596382141115 and perplexity is 40.239924043958226
At time: 355.8107578754425 and batch: 700, loss is 3.7585814952850343 and perplexity is 42.88754662304658
At time: 356.17063760757446 and batch: 750, loss is 3.7078257322311403 and perplexity is 40.76507590924027
At time: 356.5309753417969 and batch: 800, loss is 3.620703573226929 and perplexity is 37.36384677863299
At time: 356.8907992839813 and batch: 850, loss is 3.58004234790802 and perplexity is 35.875060048638176
At time: 357.25064873695374 and batch: 900, loss is 3.4893343544006346 and perplexity is 32.76413114627432
At time: 357.61009907722473 and batch: 950, loss is 3.6555175495147707 and perplexity is 38.687538651538226
At time: 357.96969079971313 and batch: 1000, loss is 3.6602215051651 and perplexity is 38.8699518129285
At time: 358.32828426361084 and batch: 1050, loss is 3.5903534746170043 and perplexity is 36.246886016474534
At time: 358.6894814968109 and batch: 1100, loss is 3.7556728601455687 and perplexity is 42.762983639846865
At time: 359.07777428627014 and batch: 1150, loss is 3.6639057636260985 and perplexity is 39.01342289175513
At time: 359.45915603637695 and batch: 1200, loss is 3.6156060028076173 and perplexity is 37.173866568681476
At time: 359.8251488208771 and batch: 1250, loss is 3.478445134162903 and perplexity is 32.40929078003612
At time: 360.191428899765 and batch: 1300, loss is 3.5918349027633667 and perplexity is 36.3006229675255
At time: 360.56153655052185 and batch: 1350, loss is 3.6108633852005005 and perplexity is 36.9979825395862
At time: 360.9417054653168 and batch: 1400, loss is 3.4485301876068117 and perplexity is 31.45412665098998
At time: 361.3106005191803 and batch: 1450, loss is 3.5712546920776367 and perplexity is 35.56118350741384
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2880126431456995 and perplexity of 72.82160208663558
Finished 32 epochs...
Completing Train Step...
At time: 362.50271821022034 and batch: 50, loss is 3.711318826675415 and perplexity is 40.90772116104461
At time: 362.8600697517395 and batch: 100, loss is 3.762961573600769 and perplexity is 43.07580943797549
At time: 363.21805214881897 and batch: 150, loss is 3.5874940395355224 and perplexity is 36.143388441821976
At time: 363.5770525932312 and batch: 200, loss is 3.7309523582458497 and perplexity is 41.71882051355919
At time: 363.9358878135681 and batch: 250, loss is 3.804986147880554 and perplexity is 44.92462780739286
At time: 364.2946181297302 and batch: 300, loss is 3.7919118499755857 and perplexity is 44.34109280768072
At time: 364.6537539958954 and batch: 350, loss is 3.771503195762634 and perplexity is 43.44532260080552
At time: 365.01231479644775 and batch: 400, loss is 3.565185661315918 and perplexity is 35.34601518281792
At time: 365.37072134017944 and batch: 450, loss is 3.6620181608200073 and perplexity is 38.9398505047966
At time: 365.72965359687805 and batch: 500, loss is 3.646701807975769 and perplexity is 38.347978247525724
At time: 366.08828377723694 and batch: 550, loss is 3.714877181053162 and perplexity is 41.05354462162969
At time: 366.44744324684143 and batch: 600, loss is 3.650541982650757 and perplexity is 38.49552430241951
At time: 366.80593633651733 and batch: 650, loss is 3.6947206020355225 and perplexity is 40.23432962761459
At time: 367.1645185947418 and batch: 700, loss is 3.758460674285889 and perplexity is 42.88236521983015
At time: 367.5235731601715 and batch: 750, loss is 3.707701063156128 and perplexity is 40.759994081713806
At time: 367.88205003738403 and batch: 800, loss is 3.620610752105713 and perplexity is 37.360378785436055
At time: 368.24081897735596 and batch: 850, loss is 3.579946045875549 and perplexity is 35.87160537378926
At time: 368.5998065471649 and batch: 900, loss is 3.489261908531189 and perplexity is 32.76175760628442
At time: 368.9587025642395 and batch: 950, loss is 3.6554674434661867 and perplexity is 38.68560022041092
At time: 369.3171057701111 and batch: 1000, loss is 3.660208559036255 and perplexity is 38.86944860078147
At time: 369.6756272315979 and batch: 1050, loss is 3.59042160987854 and perplexity is 36.24935579167156
At time: 370.0340554714203 and batch: 1100, loss is 3.755745725631714 and perplexity is 42.766099698964005
At time: 370.3930604457855 and batch: 1150, loss is 3.6639493989944456 and perplexity is 39.01512529397569
At time: 370.7527005672455 and batch: 1200, loss is 3.6156546592712404 and perplexity is 37.17567536157228
At time: 371.11153292655945 and batch: 1250, loss is 3.4784882402420045 and perplexity is 32.41068784759896
At time: 371.4707086086273 and batch: 1300, loss is 3.5919310522079466 and perplexity is 36.304113420061576
At time: 371.8292808532715 and batch: 1350, loss is 3.6109449338912962 and perplexity is 37.00099979964951
At time: 372.1881148815155 and batch: 1400, loss is 3.448621516227722 and perplexity is 31.456999444181076
At time: 372.5462989807129 and batch: 1450, loss is 3.571374158859253 and perplexity is 35.565432141338185
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.28799803644164 and perplexity of 72.82053841081317
Finished 33 epochs...
Completing Train Step...
At time: 373.72376799583435 and batch: 50, loss is 3.71116973400116 and perplexity is 40.90162257413763
At time: 374.0956025123596 and batch: 100, loss is 3.7628103494644165 and perplexity is 43.06929582841545
At time: 374.45398592948914 and batch: 150, loss is 3.5873132514953614 and perplexity is 36.136854740086164
At time: 374.82436776161194 and batch: 200, loss is 3.7308027124404908 and perplexity is 41.71257793416437
At time: 375.1830418109894 and batch: 250, loss is 3.8047590255737305 and perplexity is 44.914425580912514
At time: 375.54183292388916 and batch: 300, loss is 3.791758670806885 and perplexity is 44.33430119612513
At time: 375.90047669410706 and batch: 350, loss is 3.771371054649353 and perplexity is 43.43958206679881
At time: 376.25951623916626 and batch: 400, loss is 3.565043816566467 and perplexity is 35.34100189171314
At time: 376.6177234649658 and batch: 450, loss is 3.661841769218445 and perplexity is 38.93298244795304
At time: 376.97695803642273 and batch: 500, loss is 3.646570014953613 and perplexity is 38.34292458460498
At time: 377.33538818359375 and batch: 550, loss is 3.714727396965027 and perplexity is 41.04739591438459
At time: 377.6929361820221 and batch: 600, loss is 3.6503953409194945 and perplexity is 38.489879665969696
At time: 378.05087876319885 and batch: 650, loss is 3.6945987939834595 and perplexity is 40.2294290607669
At time: 378.4091532230377 and batch: 700, loss is 3.7583546686172484 and perplexity is 42.877819686962525
At time: 378.76782512664795 and batch: 750, loss is 3.707595682144165 and perplexity is 40.755698978605004
At time: 379.1267890930176 and batch: 800, loss is 3.620523328781128 and perplexity is 37.357112759680376
At time: 379.4856638908386 and batch: 850, loss is 3.5798674392700196 and perplexity is 35.86878573947832
At time: 379.8442461490631 and batch: 900, loss is 3.489203190803528 and perplexity is 32.759833966800024
At time: 380.202597618103 and batch: 950, loss is 3.6554273080825808 and perplexity is 38.68404759016396
At time: 380.56043696403503 and batch: 1000, loss is 3.660189652442932 and perplexity is 38.86871371887116
At time: 380.9321894645691 and batch: 1050, loss is 3.590464639663696 and perplexity is 36.250915627222774
At time: 381.2901840209961 and batch: 1100, loss is 3.7557964897155762 and perplexity is 42.76827073594047
At time: 381.648962020874 and batch: 1150, loss is 3.6639777421951294 and perplexity is 39.0162311231729
At time: 382.0069799423218 and batch: 1200, loss is 3.6156867027282713 and perplexity is 37.176866617814206
At time: 382.3657808303833 and batch: 1250, loss is 3.47852587223053 and perplexity is 32.41190754918189
At time: 382.7245774269104 and batch: 1300, loss is 3.592004070281982 and perplexity is 36.30676437328565
At time: 383.08353757858276 and batch: 1350, loss is 3.6110093879699705 and perplexity is 37.00338474186043
At time: 383.4417088031769 and batch: 1400, loss is 3.4486910581588743 and perplexity is 31.45918710073673
At time: 383.8006830215454 and batch: 1450, loss is 3.571462950706482 and perplexity is 35.56859020195846
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287985516409589 and perplexity of 72.81962670104562
Finished 34 epochs...
Completing Train Step...
At time: 384.9797101020813 and batch: 50, loss is 3.711038866043091 and perplexity is 40.896270212543605
At time: 385.3507091999054 and batch: 100, loss is 3.762668242454529 and perplexity is 43.06317581442606
At time: 385.7093975543976 and batch: 150, loss is 3.587149729728699 and perplexity is 36.130946060869434
At time: 386.0683283805847 and batch: 200, loss is 3.730667862892151 and perplexity is 41.70695339111193
At time: 386.42627477645874 and batch: 250, loss is 3.8045710802078245 and perplexity is 44.90598491597903
At time: 386.7846829891205 and batch: 300, loss is 3.7916197395324707 and perplexity is 44.32814220300798
At time: 387.1439595222473 and batch: 350, loss is 3.7712474727630614 and perplexity is 43.43421405300875
At time: 387.50313687324524 and batch: 400, loss is 3.5649150705337522 and perplexity is 35.33645217081296
At time: 387.8623559474945 and batch: 450, loss is 3.661687021255493 and perplexity is 38.92695811436628
At time: 388.2216410636902 and batch: 500, loss is 3.6464511346817017 and perplexity is 38.3383666382348
At time: 388.58089113235474 and batch: 550, loss is 3.714596929550171 and perplexity is 41.04204091608705
At time: 388.9403123855591 and batch: 600, loss is 3.6502707862854002 and perplexity is 38.48508587164242
At time: 389.29959750175476 and batch: 650, loss is 3.6944890594482422 and perplexity is 40.22501474527272
At time: 389.658784866333 and batch: 700, loss is 3.758258328437805 and perplexity is 42.87368902909709
At time: 390.03071117401123 and batch: 750, loss is 3.707502088546753 and perplexity is 40.75188468462208
At time: 390.38989996910095 and batch: 800, loss is 3.6204403114318846 and perplexity is 37.354011599930494
At time: 390.7485771179199 and batch: 850, loss is 3.579798994064331 and perplexity is 35.86633077707675
At time: 391.10670614242554 and batch: 900, loss is 3.4891512632369994 and perplexity is 32.75813287250947
At time: 391.4657917022705 and batch: 950, loss is 3.655391926765442 and perplexity is 38.68267892182075
At time: 391.82405710220337 and batch: 1000, loss is 3.6601665210723877 and perplexity is 38.867814642650025
At time: 392.1826505661011 and batch: 1050, loss is 3.5904894828796388 and perplexity is 36.25181622773468
At time: 392.540976524353 and batch: 1100, loss is 3.7558312463760375 and perplexity is 42.769757244037834
At time: 392.8998234272003 and batch: 1150, loss is 3.6639955615997315 and perplexity is 39.0169263753758
At time: 393.2582812309265 and batch: 1200, loss is 3.6157071352005006 and perplexity is 37.17762624086941
At time: 393.6169629096985 and batch: 1250, loss is 3.4785573863983155 and perplexity is 32.412928999569644
At time: 393.9756283760071 and batch: 1300, loss is 3.5920594263076784 and perplexity is 36.30877422709549
At time: 394.3346755504608 and batch: 1350, loss is 3.611059741973877 and perplexity is 37.005248057352574
At time: 394.69269490242004 and batch: 1400, loss is 3.448744788169861 and perplexity is 31.46087744861608
At time: 395.0510952472687 and batch: 1450, loss is 3.5715305519104006 and perplexity is 35.570994762752484
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287978995559562 and perplexity of 72.81915185672906
Finished 35 epochs...
Completing Train Step...
At time: 396.2473313808441 and batch: 50, loss is 3.710919895172119 and perplexity is 40.891405037069745
At time: 396.6066505908966 and batch: 100, loss is 3.7625331497192382 and perplexity is 43.05735868514978
At time: 396.96659684181213 and batch: 150, loss is 3.586999092102051 and perplexity is 36.125503790821895
At time: 397.3256468772888 and batch: 200, loss is 3.73054301738739 and perplexity is 41.70174679048089
At time: 397.6849501132965 and batch: 250, loss is 3.8044084167480468 and perplexity is 44.898680947168394
At time: 398.0443387031555 and batch: 300, loss is 3.791490702629089 and perplexity is 44.32242260583294
At time: 398.40396642684937 and batch: 350, loss is 3.771130223274231 and perplexity is 43.4291217121563
At time: 398.76334953308105 and batch: 400, loss is 3.5647952127456666 and perplexity is 35.33221707562661
At time: 399.1413035392761 and batch: 450, loss is 3.6615476417541504 and perplexity is 38.92153287244805
At time: 399.5016450881958 and batch: 500, loss is 3.646340537071228 and perplexity is 38.33412674096072
At time: 399.8617813587189 and batch: 550, loss is 3.7144791984558108 and perplexity is 41.03720927611794
At time: 400.2218556404114 and batch: 600, loss is 3.6501606607437136 and perplexity is 38.480847914071916
At time: 400.58149313926697 and batch: 650, loss is 3.694388508796692 and perplexity is 40.220970297170815
At time: 400.9414756298065 and batch: 700, loss is 3.758168635368347 and perplexity is 42.86984372878007
At time: 401.30132007598877 and batch: 750, loss is 3.7074163246154783 and perplexity is 40.748389792654656
At time: 401.6610760688782 and batch: 800, loss is 3.6203612518310546 and perplexity is 37.351058523420065
At time: 402.0210883617401 and batch: 850, loss is 3.5797362899780274 and perplexity is 35.86408188208449
At time: 402.3810541629791 and batch: 900, loss is 3.4891028451919555 and perplexity is 32.75654682615344
At time: 402.74190044403076 and batch: 950, loss is 3.6553582239151 and perplexity is 38.68137522725145
At time: 403.10178303718567 and batch: 1000, loss is 3.6601400232315062 and perplexity is 38.866784743127326
At time: 403.46248483657837 and batch: 1050, loss is 3.590501170158386 and perplexity is 36.2522399152919
At time: 403.82268357276917 and batch: 1100, loss is 3.75585382938385 and perplexity is 42.770723124706024
At time: 404.18240094184875 and batch: 1150, loss is 3.6640061044692995 and perplexity is 39.01733772790994
At time: 404.5428168773651 and batch: 1200, loss is 3.6157193422317504 and perplexity is 37.17808007208469
At time: 404.9029052257538 and batch: 1250, loss is 3.478583211898804 and perplexity is 32.413766090492445
At time: 405.26287293434143 and batch: 1300, loss is 3.5921012353897095 and perplexity is 36.310292295349896
At time: 405.62169647216797 and batch: 1350, loss is 3.6110989093780517 and perplexity is 37.0066974852448
At time: 405.9839143753052 and batch: 1400, loss is 3.4487871074676515 and perplexity is 31.462208879029983
At time: 406.34371876716614 and batch: 1450, loss is 3.571583352088928 and perplexity is 35.57287296721069
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287972996377538 and perplexity of 72.81871500269263
Finished 36 epochs...
Completing Train Step...
At time: 407.5366072654724 and batch: 50, loss is 3.710809006690979 and perplexity is 40.886870902669784
At time: 407.8946967124939 and batch: 100, loss is 3.762403950691223 and perplexity is 43.051796075608365
At time: 408.2663607597351 and batch: 150, loss is 3.5868584728240966 and perplexity is 36.12042420571526
At time: 408.62502002716064 and batch: 200, loss is 3.730425329208374 and perplexity is 41.69683927662318
At time: 408.9834899902344 and batch: 250, loss is 3.8042627573013306 and perplexity is 44.892141506420565
At time: 409.3424346446991 and batch: 300, loss is 3.7913691425323486 and perplexity is 44.31703509531298
At time: 409.70115756988525 and batch: 350, loss is 3.7710182428359986 and perplexity is 43.42425877235708
At time: 410.060382604599 and batch: 400, loss is 3.564682307243347 and perplexity is 35.32822809910257
At time: 410.4186840057373 and batch: 450, loss is 3.661419224739075 and perplexity is 38.9165350062868
At time: 410.7778072357178 and batch: 500, loss is 3.6462357330322264 and perplexity is 38.33010938016817
At time: 411.13694763183594 and batch: 550, loss is 3.7143702507019043 and perplexity is 41.03273860787977
At time: 411.49539136886597 and batch: 600, loss is 3.650060410499573 and perplexity is 38.47699039303573
At time: 411.85444951057434 and batch: 650, loss is 3.694294466972351 and perplexity is 40.21718802159615
At time: 412.2132782936096 and batch: 700, loss is 3.758083543777466 and perplexity is 42.86619602077319
At time: 412.572137594223 and batch: 750, loss is 3.7073361825942994 and perplexity is 40.74512426519162
At time: 412.93115425109863 and batch: 800, loss is 3.6202854824066164 and perplexity is 37.3482285624272
At time: 413.29092288017273 and batch: 850, loss is 3.5796775245666503 and perplexity is 35.86197437648386
At time: 413.64952325820923 and batch: 900, loss is 3.489055953025818 and perplexity is 32.75501083673079
At time: 414.0078887939453 and batch: 950, loss is 3.655325016975403 and perplexity is 38.68009075848364
At time: 414.3667254447937 and batch: 1000, loss is 3.6601114082336426 and perplexity is 38.865672586077196
At time: 414.72493743896484 and batch: 1050, loss is 3.590503454208374 and perplexity is 36.252322717314605
At time: 415.08296513557434 and batch: 1100, loss is 3.755867209434509 and perplexity is 42.771295402976705
At time: 415.4407913684845 and batch: 1150, loss is 3.6640112924575807 and perplexity is 39.017540149925914
At time: 415.79865074157715 and batch: 1200, loss is 3.6157255363464356 and perplexity is 37.17831035808963
At time: 416.1570498943329 and batch: 1250, loss is 3.478603930473328 and perplexity is 32.4144376644778
At time: 416.51565957069397 and batch: 1300, loss is 3.5921327543258665 and perplexity is 36.3114367751709
At time: 416.8762695789337 and batch: 1350, loss is 3.611129112243652 and perplexity is 37.00781521043443
At time: 417.2519690990448 and batch: 1400, loss is 3.4488207292556763 and perplexity is 31.463266712530732
At time: 417.6238992214203 and batch: 1450, loss is 3.571625428199768 and perplexity is 35.57436976684609
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287969344701523 and perplexity of 72.81844909282313
Finished 37 epochs...
Completing Train Step...
At time: 418.80388021469116 and batch: 50, loss is 3.710703520774841 and perplexity is 40.8825581411064
At time: 419.17459321022034 and batch: 100, loss is 3.762279987335205 and perplexity is 43.04645956125718
At time: 419.53306102752686 and batch: 150, loss is 3.586725926399231 and perplexity is 36.11563688989997
At time: 419.89455580711365 and batch: 200, loss is 3.730312747955322 and perplexity is 41.69214525844329
At time: 420.27008533477783 and batch: 250, loss is 3.80412917137146 and perplexity is 44.88614494849034
At time: 420.63788294792175 and batch: 300, loss is 3.791253614425659 and perplexity is 44.31191552788698
At time: 420.99627900123596 and batch: 350, loss is 3.770910453796387 and perplexity is 43.419578365460964
At time: 421.35445380210876 and batch: 400, loss is 3.5645745182037354 and perplexity is 35.32442030854731
At time: 421.7113654613495 and batch: 450, loss is 3.661299157142639 and perplexity is 38.911862671970574
At time: 422.06900119781494 and batch: 500, loss is 3.646135187149048 and perplexity is 38.32625563921035
At time: 422.4271183013916 and batch: 550, loss is 3.7142674589157103 and perplexity is 41.028520996157475
At time: 422.78553438186646 and batch: 600, loss is 3.6499667882919313 and perplexity is 38.473388260874145
At time: 423.14460706710815 and batch: 650, loss is 3.6942055559158327 and perplexity is 40.21361242787621
At time: 423.5036072731018 and batch: 700, loss is 3.7580020236968994 and perplexity is 42.862701707450285
At time: 423.86179637908936 and batch: 750, loss is 3.7072601079940797 and perplexity is 40.7420247140523
At time: 424.22029399871826 and batch: 800, loss is 3.6202122449874876 and perplexity is 37.34549337471852
At time: 424.5792148113251 and batch: 850, loss is 3.5796210765838623 and perplexity is 35.859950097505276
At time: 424.93782567977905 and batch: 900, loss is 3.489010047912598 and perplexity is 32.75350724876126
At time: 425.2960636615753 and batch: 950, loss is 3.655291600227356 and perplexity is 38.67879821723271
At time: 425.65509057044983 and batch: 1000, loss is 3.66008131980896 and perplexity is 38.86450319680748
At time: 426.01372599601746 and batch: 1050, loss is 3.590498490333557 and perplexity is 36.25214276576944
At time: 426.3722126483917 and batch: 1100, loss is 3.7558736419677734 and perplexity is 42.77157053164203
At time: 426.74280166625977 and batch: 1150, loss is 3.6640123891830445 and perplexity is 39.0175829414792
At time: 427.100887298584 and batch: 1200, loss is 3.615727162361145 and perplexity is 37.178370810618304
At time: 427.45947098731995 and batch: 1250, loss is 3.4786199522018433 and perplexity is 32.41495700395839
At time: 427.8174715042114 and batch: 1300, loss is 3.592156004905701 and perplexity is 36.3122810469454
At time: 428.17531299591064 and batch: 1350, loss is 3.6111524438858034 and perplexity is 37.008678673608685
At time: 428.5332086086273 and batch: 1400, loss is 3.4488474893569947 and perplexity is 31.46410868400134
At time: 428.9107117652893 and batch: 1450, loss is 3.571659345626831 and perplexity is 35.57557637840043
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287966736361512 and perplexity of 72.81825915779655
Finished 38 epochs...
Completing Train Step...
At time: 430.14246559143066 and batch: 50, loss is 3.7106024074554442 and perplexity is 40.87842457892994
At time: 430.52140831947327 and batch: 100, loss is 3.762160396575928 and perplexity is 43.041311910285934
At time: 430.9066364765167 and batch: 150, loss is 3.586599793434143 and perplexity is 36.11108180481223
At time: 431.2774283885956 and batch: 200, loss is 3.730204315185547 and perplexity is 41.68762470874734
At time: 431.63821840286255 and batch: 250, loss is 3.8040046882629395 and perplexity is 44.88055772940208
At time: 431.99859404563904 and batch: 300, loss is 3.791142530441284 and perplexity is 44.30699345714154
At time: 432.3584225177765 and batch: 350, loss is 3.7708062505722046 and perplexity is 43.41505414112613
At time: 432.7182722091675 and batch: 400, loss is 3.564470958709717 and perplexity is 35.32076231886671
At time: 433.0778021812439 and batch: 450, loss is 3.661185541152954 and perplexity is 38.907441913321804
At time: 433.43782234191895 and batch: 500, loss is 3.6460379934310914 and perplexity is 38.32253074895032
At time: 433.7984926700592 and batch: 550, loss is 3.7141693830490112 and perplexity is 41.024497285719065
At time: 434.1583387851715 and batch: 600, loss is 3.6498783731460573 and perplexity is 38.46998678101218
At time: 434.51923513412476 and batch: 650, loss is 3.6941207027435303 and perplexity is 40.2102003200581
At time: 434.8809850215912 and batch: 700, loss is 3.7579229402542116 and perplexity is 42.85931211146858
At time: 435.2427923679352 and batch: 750, loss is 3.7071868419647216 and perplexity is 40.7390398170206
At time: 435.6027991771698 and batch: 800, loss is 3.620141453742981 and perplexity is 37.342849734340206
At time: 435.97670555114746 and batch: 850, loss is 3.57956636428833 and perplexity is 35.85798817098901
At time: 436.3364505767822 and batch: 900, loss is 3.488964500427246 and perplexity is 32.752015442843884
At time: 436.69699025154114 and batch: 950, loss is 3.6552577924728396 and perplexity is 38.67749059602159
At time: 437.0562870502472 and batch: 1000, loss is 3.660050029754639 and perplexity is 38.86328714341657
At time: 437.4175522327423 and batch: 1050, loss is 3.5904882860183718 and perplexity is 36.25177283936594
At time: 437.7946569919586 and batch: 1100, loss is 3.7558747577667235 and perplexity is 42.77161825614215
At time: 438.16940116882324 and batch: 1150, loss is 3.664010238647461 and perplexity is 39.017499032868926
At time: 438.53005862236023 and batch: 1200, loss is 3.615725393295288 and perplexity is 37.17830503969006
At time: 438.8913233280182 and batch: 1250, loss is 3.478632063865662 and perplexity is 32.415349605397836
At time: 439.2520110607147 and batch: 1300, loss is 3.592172875404358 and perplexity is 36.31289365840156
At time: 439.612530708313 and batch: 1350, loss is 3.6111701107025147 and perplexity is 37.00933250492709
At time: 439.9726483821869 and batch: 1400, loss is 3.4488690662384034 and perplexity is 31.46478758866734
At time: 440.3331825733185 and batch: 1450, loss is 3.571687197685242 and perplexity is 35.57656724523049
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2879641280215015 and perplexity of 72.8180692232654
Finished 39 epochs...
Completing Train Step...
At time: 441.52644968032837 and batch: 50, loss is 3.7105043029785154 and perplexity is 40.87441441917947
At time: 441.8846101760864 and batch: 100, loss is 3.7620449113845824 and perplexity is 43.036341563150486
At time: 442.2427294254303 and batch: 150, loss is 3.586479105949402 and perplexity is 36.10672391215477
At time: 442.60199880599976 and batch: 200, loss is 3.730099153518677 and perplexity is 41.68324099914826
At time: 442.961177110672 and batch: 250, loss is 3.8038867568969725 and perplexity is 44.87526521600649
At time: 443.320720911026 and batch: 300, loss is 3.7910354280471803 and perplexity is 44.30224832617871
At time: 443.67977142333984 and batch: 350, loss is 3.7707050800323487 and perplexity is 43.41066203884022
At time: 444.03855299949646 and batch: 400, loss is 3.564370756149292 and perplexity is 35.31722326536027
At time: 444.39782428741455 and batch: 450, loss is 3.6610768318176268 and perplexity is 38.90321254106241
At time: 444.75721764564514 and batch: 500, loss is 3.645943298339844 and perplexity is 38.31890196522093
At time: 445.1289646625519 and batch: 550, loss is 3.7140746831893923 and perplexity is 41.020612455534504
At time: 445.4875400066376 and batch: 600, loss is 3.6497933673858642 and perplexity is 38.46671674952896
At time: 445.8459565639496 and batch: 650, loss is 3.6940389823913575 and perplexity is 40.20691446258955
At time: 446.20461416244507 and batch: 700, loss is 3.7578462028503417 and perplexity is 42.85602332531357
At time: 446.5626976490021 and batch: 750, loss is 3.7071161317825316 and perplexity is 40.73615925393666
At time: 446.92131090164185 and batch: 800, loss is 3.620072350502014 and perplexity is 37.340269311555446
At time: 447.28095293045044 and batch: 850, loss is 3.5795127820968626 and perplexity is 35.85606687287534
At time: 447.64008498191833 and batch: 900, loss is 3.4889191246032714 and perplexity is 32.75052932687346
At time: 447.9999704360962 and batch: 950, loss is 3.6552232837677003 and perplexity is 38.67615590893238
At time: 448.3581314086914 and batch: 1000, loss is 3.660017991065979 and perplexity is 38.86204203460542
At time: 448.716609954834 and batch: 1050, loss is 3.590473861694336 and perplexity is 36.25124993581891
At time: 449.0756869316101 and batch: 1100, loss is 3.7558714866638185 and perplexity is 42.77147834600625
At time: 449.4354887008667 and batch: 1150, loss is 3.664005546569824 and perplexity is 39.01731596016376
At time: 449.794495344162 and batch: 1200, loss is 3.615720896720886 and perplexity is 37.17813786505116
At time: 450.15405440330505 and batch: 1250, loss is 3.478640661239624 and perplexity is 32.4156282934785
At time: 450.5134437084198 and batch: 1300, loss is 3.592184567451477 and perplexity is 36.31331823294731
At time: 450.8858599662781 and batch: 1350, loss is 3.6111833333969114 and perplexity is 37.00982187125599
At time: 451.2564420700073 and batch: 1400, loss is 3.448886275291443 and perplexity is 31.465329072525027
At time: 451.6147725582123 and batch: 1450, loss is 3.571710023880005 and perplexity is 35.57737933215183
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287962302183494 and perplexity of 72.81793626938833
Finished 40 epochs...
Completing Train Step...
At time: 452.80877137184143 and batch: 50, loss is 3.7104084587097166 and perplexity is 40.87049702854961
At time: 453.16669511795044 and batch: 100, loss is 3.761932735443115 and perplexity is 43.03151419178086
At time: 453.5247001647949 and batch: 150, loss is 3.5863627290725706 and perplexity is 36.102522168890886
At time: 453.8825714588165 and batch: 200, loss is 3.72999671459198 and perplexity is 41.67897123137801
At time: 454.2538011074066 and batch: 250, loss is 3.8037739896774294 and perplexity is 44.87020504243804
At time: 454.63162302970886 and batch: 300, loss is 3.7909313917160032 and perplexity is 44.29763952254563
At time: 455.00777077674866 and batch: 350, loss is 3.7706064701080324 and perplexity is 43.40638152779595
At time: 455.38082456588745 and batch: 400, loss is 3.564273157119751 and perplexity is 35.31377650684637
At time: 455.7440824508667 and batch: 450, loss is 3.6609721899032595 and perplexity is 38.899141847413375
At time: 456.1018717288971 and batch: 500, loss is 3.645850830078125 and perplexity is 38.31535884678077
At time: 456.45993638038635 and batch: 550, loss is 3.7139829492568968 and perplexity is 41.01684964603188
At time: 456.81853199005127 and batch: 600, loss is 3.649711322784424 and perplexity is 38.46356089254682
At time: 457.17699909210205 and batch: 650, loss is 3.693959789276123 and perplexity is 40.20373047785579
At time: 457.5360441207886 and batch: 700, loss is 3.7577708673477175 and perplexity is 42.852794866866184
At time: 457.8944716453552 and batch: 750, loss is 3.7070470333099363 and perplexity is 40.73334454479999
At time: 458.2535798549652 and batch: 800, loss is 3.6200048398971556 and perplexity is 37.33774853247926
At time: 458.61224150657654 and batch: 850, loss is 3.5794599437713623 and perplexity is 35.85417234839494
At time: 458.9712073802948 and batch: 900, loss is 3.488873629570007 and perplexity is 32.74903937434529
At time: 459.32998871803284 and batch: 950, loss is 3.6551881504058836 and perplexity is 38.67479710942289
At time: 459.6886487007141 and batch: 1000, loss is 3.6599853897094725 and perplexity is 38.86077509997049
At time: 460.04777455329895 and batch: 1050, loss is 3.5904563283920288 and perplexity is 36.25061433726685
At time: 460.40648102760315 and batch: 1100, loss is 3.7558647918701173 and perplexity is 42.77119200074094
At time: 460.7643666267395 and batch: 1150, loss is 3.66399866104126 and perplexity is 39.017047306245125
At time: 461.1242141723633 and batch: 1200, loss is 3.615714168548584 and perplexity is 37.177887724975236
At time: 461.48234820365906 and batch: 1250, loss is 3.4786463260650633 and perplexity is 32.415811922874404
At time: 461.840980052948 and batch: 1300, loss is 3.592192087173462 and perplexity is 36.31359130003147
At time: 462.2001414299011 and batch: 1350, loss is 3.611192765235901 and perplexity is 37.0101709435831
At time: 462.55954098701477 and batch: 1400, loss is 3.4488998365402224 and perplexity is 31.465755784573876
At time: 462.918386220932 and batch: 1450, loss is 3.5717287826538087 and perplexity is 35.578046726422976
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2879617805154915 and perplexity of 72.8178982826109
Finished 41 epochs...
Completing Train Step...
At time: 464.1003694534302 and batch: 50, loss is 3.7103146505355835 and perplexity is 40.86666322167147
At time: 464.47125816345215 and batch: 100, loss is 3.761823673248291 and perplexity is 43.026821336307705
At time: 464.82916498184204 and batch: 150, loss is 3.586250123977661 and perplexity is 36.09845706983532
At time: 465.1878981590271 and batch: 200, loss is 3.7298964166641237 and perplexity is 41.67479112655975
At time: 465.5452287197113 and batch: 250, loss is 3.803665509223938 and perplexity is 44.865337766253724
At time: 465.91276144981384 and batch: 300, loss is 3.7908300590515136 and perplexity is 44.29315095212545
At time: 466.2925727367401 and batch: 350, loss is 3.770510129928589 and perplexity is 43.40219995064076
At time: 466.66778779029846 and batch: 400, loss is 3.564177951812744 and perplexity is 35.31041460795031
At time: 467.0406792163849 and batch: 450, loss is 3.660871105194092 and perplexity is 38.89520993770419
At time: 467.40248703956604 and batch: 500, loss is 3.645760350227356 and perplexity is 38.31189223566174
At time: 467.7610011100769 and batch: 550, loss is 3.7138936042785646 and perplexity is 41.013185160193146
At time: 468.1201207637787 and batch: 600, loss is 3.6496310806274415 and perplexity is 38.46047461728192
At time: 468.47852206230164 and batch: 650, loss is 3.6938826656341552 and perplexity is 40.2006299393046
At time: 468.8372678756714 and batch: 700, loss is 3.7576969480514526 and perplexity is 42.84962733549893
At time: 469.19559812545776 and batch: 750, loss is 3.706979432106018 and perplexity is 40.730591014741165
At time: 469.5535891056061 and batch: 800, loss is 3.6199385690689088 and perplexity is 37.335274210947716
At time: 469.9116826057434 and batch: 850, loss is 3.5794078302383423 and perplexity is 35.85230390948625
At time: 470.2848024368286 and batch: 900, loss is 3.4888280916213987 and perplexity is 32.74754808422869
At time: 470.65780091285706 and batch: 950, loss is 3.655152454376221 and perplexity is 38.673416597357615
At time: 471.02237153053284 and batch: 1000, loss is 3.6599522542953493 and perplexity is 38.859487453427874
At time: 471.3815031051636 and batch: 1050, loss is 3.5904361820220947 and perplexity is 36.24988402633666
At time: 471.7400019168854 and batch: 1100, loss is 3.7558552837371826 and perplexity is 42.770785328494966
At time: 472.0991156101227 and batch: 1150, loss is 3.663989896774292 and perplexity is 39.016705351924735
At time: 472.4581525325775 and batch: 1200, loss is 3.6157057094573974 and perplexity is 37.177573235162996
At time: 472.8366665840149 and batch: 1250, loss is 3.478649435043335 and perplexity is 32.41591270308599
At time: 473.19535088539124 and batch: 1300, loss is 3.592196283340454 and perplexity is 36.31374367824435
At time: 473.57186555862427 and batch: 1350, loss is 3.6111991214752197 and perplexity is 37.01040618983449
At time: 473.9426381587982 and batch: 1400, loss is 3.4489105129241944 and perplexity is 31.466091726857922
At time: 474.3014032840729 and batch: 1450, loss is 3.571744523048401 and perplexity is 35.578606743324706
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2879617805154915 and perplexity of 72.8178982826109
Finished 42 epochs...
Completing Train Step...
At time: 475.48210310935974 and batch: 50, loss is 3.710222239494324 and perplexity is 40.86288686526155
At time: 475.855628490448 and batch: 100, loss is 3.761717343330383 and perplexity is 43.02224654115029
At time: 476.2149555683136 and batch: 150, loss is 3.5861407566070556 and perplexity is 36.094509292385624
At time: 476.57517743110657 and batch: 200, loss is 3.729798002243042 and perplexity is 41.670689927929175
At time: 476.9352660179138 and batch: 250, loss is 3.8035605478286745 and perplexity is 44.8606288849325
At time: 477.3158040046692 and batch: 300, loss is 3.790731315612793 and perplexity is 44.28877751001657
At time: 477.6851031780243 and batch: 350, loss is 3.7704157304763792 and perplexity is 43.3981030001187
At time: 478.0448594093323 and batch: 400, loss is 3.5640847635269166 and perplexity is 35.30712424425519
At time: 478.4054081439972 and batch: 450, loss is 3.6607726764678956 and perplexity is 38.89138172014126
At time: 478.7658245563507 and batch: 500, loss is 3.6456712818145753 and perplexity is 38.30848000819278
At time: 479.12572598457336 and batch: 550, loss is 3.7138062047958376 and perplexity is 41.00960078566368
At time: 479.4849443435669 and batch: 600, loss is 3.649552593231201 and perplexity is 38.45745607323142
At time: 479.84501099586487 and batch: 650, loss is 3.6938072061538696 and perplexity is 40.19759653511321
At time: 480.20400381088257 and batch: 700, loss is 3.7576242589950564 and perplexity is 42.8465127497205
At time: 480.5630352497101 and batch: 750, loss is 3.7069130516052247 and perplexity is 40.727887387447055
At time: 480.92205023765564 and batch: 800, loss is 3.619873323440552 and perplexity is 37.332838326988195
At time: 481.28067994117737 and batch: 850, loss is 3.57935610294342 and perplexity is 35.8504494147527
At time: 481.63933992385864 and batch: 900, loss is 3.4887824392318727 and perplexity is 32.74605311453225
At time: 482.01169443130493 and batch: 950, loss is 3.655116333961487 and perplexity is 38.672019722738945
At time: 482.37160754203796 and batch: 1000, loss is 3.659918885231018 and perplexity is 38.85819077032583
At time: 482.732328414917 and batch: 1050, loss is 3.590414161682129 and perplexity is 36.249085800355324
At time: 483.0930755138397 and batch: 1100, loss is 3.7558433294296263 and perplexity is 42.7702740364288
At time: 483.4536244869232 and batch: 1150, loss is 3.6639795207977297 and perplexity is 39.01630051760474
At time: 483.81313943862915 and batch: 1200, loss is 3.6156955337524415 and perplexity is 37.17719492907154
At time: 484.1719434261322 and batch: 1250, loss is 3.4786499977111816 and perplexity is 32.415930942482916
At time: 484.5310356616974 and batch: 1300, loss is 3.5921974563598633 and perplexity is 36.313786274995486
At time: 484.89113998413086 and batch: 1350, loss is 3.6112030029296873 and perplexity is 37.01054984431973
At time: 485.25018525123596 and batch: 1400, loss is 3.448918523788452 and perplexity is 31.46634379845712
At time: 485.6100342273712 and batch: 1450, loss is 3.5717572784423828 and perplexity is 35.579060565365374
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2879594330094815 and perplexity of 72.81772734235768
Finished 43 epochs...
Completing Train Step...
At time: 486.80178928375244 and batch: 50, loss is 3.7101311254501343 and perplexity is 40.85916385199397
At time: 487.16041707992554 and batch: 100, loss is 3.761613268852234 and perplexity is 43.01776925628229
At time: 487.51952147483826 and batch: 150, loss is 3.5860340642929076 and perplexity is 36.09065849109029
At time: 487.87927985191345 and batch: 200, loss is 3.7297012615203857 and perplexity is 41.66665887025882
At time: 488.2385411262512 and batch: 250, loss is 3.803458275794983 and perplexity is 44.85604113178717
At time: 488.59727478027344 and batch: 300, loss is 3.7906344652175905 and perplexity is 44.28448833211934
At time: 488.956015586853 and batch: 350, loss is 3.770322952270508 and perplexity is 43.39407678875936
At time: 489.3139123916626 and batch: 400, loss is 3.563993148803711 and perplexity is 35.30388974000674
At time: 489.6720676422119 and batch: 450, loss is 3.660676589012146 and perplexity is 38.8876449257536
At time: 490.0302412509918 and batch: 500, loss is 3.6455834245681764 and perplexity is 38.305114478470784
At time: 490.38889026641846 and batch: 550, loss is 3.713720450401306 and perplexity is 41.00608418296254
At time: 490.7469277381897 and batch: 600, loss is 3.6494755125045777 and perplexity is 38.45449185881658
At time: 491.1186375617981 and batch: 650, loss is 3.693733296394348 and perplexity is 40.19462565021001
At time: 491.4781632423401 and batch: 700, loss is 3.7575526142120363 and perplexity is 42.843443130573796
At time: 491.83647537231445 and batch: 750, loss is 3.706847348213196 and perplexity is 40.725211515003444
At time: 492.1940658092499 and batch: 800, loss is 3.6198091888427735 and perplexity is 37.33044407719612
At time: 492.5526568889618 and batch: 850, loss is 3.579304757118225 and perplexity is 35.84860869110103
At time: 492.91171193122864 and batch: 900, loss is 3.4887367343902587 and perplexity is 32.7445564955628
At time: 493.27006244659424 and batch: 950, loss is 3.655079345703125 and perplexity is 38.67058933853593
At time: 493.6289405822754 and batch: 1000, loss is 3.659885058403015 and perplexity is 38.85687634322171
At time: 493.9875273704529 and batch: 1050, loss is 3.5903904008865357 and perplexity is 36.248224503469764
At time: 494.36066699028015 and batch: 1100, loss is 3.7558295917510987 and perplexity is 42.76968647618942
At time: 494.73311591148376 and batch: 1150, loss is 3.6639678716659545 and perplexity is 39.01584601422592
At time: 495.1054148674011 and batch: 1200, loss is 3.6156840753555297 and perplexity is 37.176768940456554
At time: 495.46460247039795 and batch: 1250, loss is 3.478648681640625 and perplexity is 32.41588828085872
At time: 495.82357263565063 and batch: 1300, loss is 3.5921963024139405 and perplexity is 36.31374437087405
At time: 496.1978123188019 and batch: 1350, loss is 3.6112045812606812 and perplexity is 37.010608259263755
At time: 496.57257533073425 and batch: 1400, loss is 3.44892436504364 and perplexity is 31.4665276019379
At time: 496.93244886398315 and batch: 1450, loss is 3.571767797470093 and perplexity is 35.579434824457785
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287960476345486 and perplexity of 72.817803315754
Annealing...
Finished 44 epochs...
Completing Train Step...
At time: 498.123113155365 and batch: 50, loss is 3.71016131401062 and perplexity is 40.86039734995198
At time: 498.4816472530365 and batch: 100, loss is 3.761692533493042 and perplexity is 43.02117917945213
At time: 498.84054684638977 and batch: 150, loss is 3.5861310863494875 and perplexity is 36.09416025087164
At time: 499.1993987560272 and batch: 200, loss is 3.729785752296448 and perplexity is 41.67017946732959
At time: 499.55747961997986 and batch: 250, loss is 3.8035620212554933 and perplexity is 44.860694983834904
At time: 499.916216135025 and batch: 300, loss is 3.7907214641571043 and perplexity is 44.28834120323656
At time: 500.2748613357544 and batch: 350, loss is 3.770339093208313 and perplexity is 43.394777215506664
At time: 500.6573100090027 and batch: 400, loss is 3.563994960784912 and perplexity is 35.30395371004923
At time: 501.02979493141174 and batch: 450, loss is 3.6607800674438478 and perplexity is 38.89166916647055
At time: 501.3937027454376 and batch: 500, loss is 3.6455924463272096 and perplexity is 38.30546005954222
At time: 501.7505130767822 and batch: 550, loss is 3.713662738800049 and perplexity is 41.00371772446977
At time: 502.1088168621063 and batch: 600, loss is 3.6493891048431397 and perplexity is 38.451169239655215
At time: 502.46712923049927 and batch: 650, loss is 3.693588962554932 and perplexity is 40.188824624218256
At time: 502.825971364975 and batch: 700, loss is 3.7574567222595214 and perplexity is 42.83933498613169
At time: 503.18443870544434 and batch: 750, loss is 3.7067153692245483 and perplexity is 40.71983699744473
At time: 503.5431218147278 and batch: 800, loss is 3.6195716714859008 and perplexity is 37.32157850169373
At time: 503.9018249511719 and batch: 850, loss is 3.579167866706848 and perplexity is 35.84370169617795
At time: 504.2602279186249 and batch: 900, loss is 3.4885311985015868 and perplexity is 32.73782700564385
At time: 504.6413495540619 and batch: 950, loss is 3.6548784828186034 and perplexity is 38.66282263246285
At time: 505.0123989582062 and batch: 1000, loss is 3.6595801305770874 and perplexity is 38.84502960668763
At time: 505.3711242675781 and batch: 1050, loss is 3.589922938346863 and perplexity is 36.231283776270914
At time: 505.72961711883545 and batch: 1100, loss is 3.7554373264312746 and perplexity is 42.752912701545185
At time: 506.08844804763794 and batch: 1150, loss is 3.663624114990234 and perplexity is 39.0024363616605
At time: 506.44708919525146 and batch: 1200, loss is 3.615254826545715 and perplexity is 37.160814281140354
At time: 506.8056571483612 and batch: 1250, loss is 3.4783250522613525 and perplexity is 32.405399244427535
At time: 507.1635901927948 and batch: 1300, loss is 3.5917491912841797 and perplexity is 36.29751172077223
At time: 507.522173166275 and batch: 1350, loss is 3.6107372188568116 and perplexity is 36.993314933858876
At time: 507.88036274909973 and batch: 1400, loss is 3.4484770345687865 and perplexity is 31.452454813032077
At time: 508.2386713027954 and batch: 1450, loss is 3.5712728786468504 and perplexity is 35.56183024922
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287959172175481 and perplexity of 72.81770834902102
Finished 45 epochs...
Completing Train Step...
At time: 509.4168155193329 and batch: 50, loss is 3.710134434700012 and perplexity is 40.85929906540068
At time: 509.788405418396 and batch: 100, loss is 3.7616635751724243 and perplexity is 43.019933376390384
At time: 510.14863562583923 and batch: 150, loss is 3.586100640296936 and perplexity is 36.093061342900626
At time: 510.50850796699524 and batch: 200, loss is 3.7297603273391724 and perplexity is 41.66912001826525
At time: 510.8682086467743 and batch: 250, loss is 3.803525514602661 and perplexity is 44.859057299910674
At time: 511.22829270362854 and batch: 300, loss is 3.790696716308594 and perplexity is 44.2872451756399
At time: 511.58842873573303 and batch: 350, loss is 3.7703177309036255 and perplexity is 43.393850212955435
At time: 511.94866132736206 and batch: 400, loss is 3.5639729833602907 and perplexity is 35.3031778285937
At time: 512.3087832927704 and batch: 450, loss is 3.660754141807556 and perplexity is 38.89066088827116
At time: 512.6681394577026 and batch: 500, loss is 3.645570044517517 and perplexity is 38.30460195752733
At time: 513.0277943611145 and batch: 550, loss is 3.7136426877975466 and perplexity is 41.00289556706564
At time: 513.3879475593567 and batch: 600, loss is 3.649368577003479 and perplexity is 38.45037992831976
At time: 513.7469308376312 and batch: 650, loss is 3.693573303222656 and perplexity is 40.18819529898712
At time: 514.1084895133972 and batch: 700, loss is 3.757442412376404 and perplexity is 42.838721964641344
At time: 514.468593120575 and batch: 750, loss is 3.7067005014419556 and perplexity is 40.7192315882616
At time: 514.8284170627594 and batch: 800, loss is 3.6195636940002442 and perplexity is 37.321280770524126
At time: 515.1879694461823 and batch: 850, loss is 3.579155292510986 and perplexity is 35.84325099328603
At time: 515.5482938289642 and batch: 900, loss is 3.488522810935974 and perplexity is 32.73755241612339
At time: 515.9077150821686 and batch: 950, loss is 3.6548695039749144 and perplexity is 38.66247548658034
At time: 516.267237663269 and batch: 1000, loss is 3.659578037261963 and perplexity is 38.84494829188476
At time: 516.6279418468475 and batch: 1050, loss is 3.5899291229248047 and perplexity is 36.23150785216227
At time: 516.9879610538483 and batch: 1100, loss is 3.755445990562439 and perplexity is 42.75328311999317
At time: 517.348007440567 and batch: 1150, loss is 3.6636317491531374 and perplexity is 39.002734113749845
At time: 517.7085001468658 and batch: 1200, loss is 3.6152574157714845 and perplexity is 37.16091049900287
At time: 518.0685725212097 and batch: 1250, loss is 3.4783256959915163 and perplexity is 32.40542010476722
At time: 518.427717924118 and batch: 1300, loss is 3.5917548036575315 and perplexity is 36.29771543653141
At time: 518.7877762317657 and batch: 1350, loss is 3.6107356929779053 and perplexity is 36.99325848658301
At time: 519.1479613780975 and batch: 1400, loss is 3.4484844160079957 and perplexity is 31.452686978272116
At time: 519.5079617500305 and batch: 1450, loss is 3.571283655166626 and perplexity is 35.56221348405191
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2879594330094815 and perplexity of 72.81772734235768
Annealing...
Finished 46 epochs...
Completing Train Step...
At time: 520.688069820404 and batch: 50, loss is 3.710128607749939 and perplexity is 40.859060980998656
At time: 521.0594682693481 and batch: 100, loss is 3.7616662693023684 and perplexity is 43.02004927783721
At time: 521.4177906513214 and batch: 150, loss is 3.586105589866638 and perplexity is 36.09323998846562
At time: 521.7766418457031 and batch: 200, loss is 3.729766960144043 and perplexity is 41.66939640232406
At time: 522.1552784442902 and batch: 250, loss is 3.803526339530945 and perplexity is 44.85909430543109
At time: 522.5404858589172 and batch: 300, loss is 3.790704622268677 and perplexity is 44.287595310216524
At time: 522.9202566146851 and batch: 350, loss is 3.7703177404403685 and perplexity is 43.39385062679143
At time: 523.2832205295563 and batch: 400, loss is 3.5639685916900636 and perplexity is 35.303022789019145
At time: 523.641946554184 and batch: 450, loss is 3.6607644748687744 and perplexity is 38.89106274992716
At time: 523.9995355606079 and batch: 500, loss is 3.645567440986633 and perplexity is 38.304502230442964
At time: 524.3571343421936 and batch: 550, loss is 3.7136280298233033 and perplexity is 41.00229455208336
At time: 524.71404504776 and batch: 600, loss is 3.6493489122390748 and perplexity is 38.449623818091595
At time: 525.0718913078308 and batch: 650, loss is 3.693547372817993 and perplexity is 40.187153216331204
At time: 525.429919719696 and batch: 700, loss is 3.7574245595932005 and perplexity is 42.83795718105218
At time: 525.787534236908 and batch: 750, loss is 3.706676301956177 and perplexity is 40.718246215718665
At time: 526.1487395763397 and batch: 800, loss is 3.6195243787765503 and perplexity is 37.319813504865216
At time: 526.508444070816 and batch: 850, loss is 3.5791302251815797 and perplexity is 35.84235250996772
At time: 526.8666515350342 and batch: 900, loss is 3.4884869289398193 and perplexity is 32.736377748468314
At time: 527.2250049114227 and batch: 950, loss is 3.654835681915283 and perplexity is 38.661167864142314
At time: 527.58465051651 and batch: 1000, loss is 3.659529299736023 and perplexity is 38.8430551313441
At time: 527.956151008606 and batch: 1050, loss is 3.589853572845459 and perplexity is 36.228770662267976
At time: 528.3146967887878 and batch: 1100, loss is 3.7553820419311523 and perplexity is 42.75054919347099
At time: 528.6733551025391 and batch: 1150, loss is 3.6635753440856935 and perplexity is 39.00053422394472
At time: 529.031861782074 and batch: 1200, loss is 3.615187544822693 and perplexity is 37.158314121635065
At time: 529.3904588222504 and batch: 1250, loss is 3.478272247314453 and perplexity is 32.40368812421938
At time: 529.7482409477234 and batch: 1300, loss is 3.5916816711425783 and perplexity is 36.29506099037882
At time: 530.1064777374268 and batch: 1350, loss is 3.6106589603424073 and perplexity is 36.99042000526714
At time: 530.4651391506195 and batch: 1400, loss is 3.448410596847534 and perplexity is 31.450365253020074
At time: 530.8246383666992 and batch: 1450, loss is 3.5712022018432616 and perplexity is 35.559316941545546
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2879594330094815 and perplexity of 72.81772734235768
Annealing...
Finished 47 epochs...
Completing Train Step...
At time: 532.0210781097412 and batch: 50, loss is 3.710127468109131 and perplexity is 40.85901441637192
At time: 532.3797056674957 and batch: 100, loss is 3.7616668367385864 and perplexity is 43.020073688978194
At time: 532.7383337020874 and batch: 150, loss is 3.5861065864562987 and perplexity is 36.09327595863333
At time: 533.0975041389465 and batch: 200, loss is 3.7297684001922606 and perplexity is 41.66945640830728
At time: 533.4560959339142 and batch: 250, loss is 3.8035265970230103 and perplexity is 44.859105856293425
At time: 533.8132586479187 and batch: 300, loss is 3.7907062864303587 and perplexity is 44.28766901199695
At time: 534.1719591617584 and batch: 350, loss is 3.7703180170059203 and perplexity is 43.39386262803733
At time: 534.5303840637207 and batch: 400, loss is 3.5639680337905886 and perplexity is 35.30300309348676
At time: 534.8887100219727 and batch: 450, loss is 3.6607662343978884 and perplexity is 38.891131179944544
At time: 535.247298002243 and batch: 500, loss is 3.6455670022964477 and perplexity is 38.30448542663746
At time: 535.6059801578522 and batch: 550, loss is 3.7136257171630858 and perplexity is 41.00219972781757
At time: 535.9645073413849 and batch: 600, loss is 3.6493460083007814 and perplexity is 38.449512162918744
At time: 536.3231370449066 and batch: 650, loss is 3.6935431718826295 and perplexity is 40.186984393052704
At time: 536.6821122169495 and batch: 700, loss is 3.757421836853027 and perplexity is 42.837840544584004
At time: 537.0537621974945 and batch: 750, loss is 3.7066723203659055 and perplexity is 40.71808409266842
At time: 537.4125032424927 and batch: 800, loss is 3.619517741203308 and perplexity is 37.3195657926918
At time: 537.7705366611481 and batch: 850, loss is 3.5791261196136475 and perplexity is 35.842205357056706
At time: 538.1280560493469 and batch: 900, loss is 3.4884810972213747 and perplexity is 32.73618683968706
At time: 538.4867055416107 and batch: 950, loss is 3.654830265045166 and perplexity is 38.660958442184615
At time: 538.8435258865356 and batch: 1000, loss is 3.6595210599899293 and perplexity is 38.8427350757509
At time: 539.2010869979858 and batch: 1050, loss is 3.5898409509658813 and perplexity is 36.22831338997326
At time: 539.5598747730255 and batch: 1100, loss is 3.7553710651397707 and perplexity is 42.75007993218654
At time: 539.9184997081757 and batch: 1150, loss is 3.663565731048584 and perplexity is 39.00015931216396
At time: 540.2769525051117 and batch: 1200, loss is 3.615175790786743 and perplexity is 37.15787736404188
At time: 540.6364707946777 and batch: 1250, loss is 3.4782632064819334 and perplexity is 32.403395169226314
At time: 540.9953801631927 and batch: 1300, loss is 3.591669282913208 and perplexity is 36.294611361623325
At time: 541.3549816608429 and batch: 1350, loss is 3.6106458282470704 and perplexity is 36.9899342467346
At time: 541.7137944698334 and batch: 1400, loss is 3.448397855758667 and perplexity is 31.449964543674223
At time: 542.0723886489868 and batch: 1450, loss is 3.5711883115768432 and perplexity is 35.558823016589955
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287959693843483 and perplexity of 72.81774633569937
Annealing...
Finished 48 epochs...
Completing Train Step...
At time: 543.2705457210541 and batch: 50, loss is 3.7101273775100707 and perplexity is 40.859010714583775
At time: 543.6292817592621 and batch: 100, loss is 3.7616671180725096 and perplexity is 43.020085791986006
At time: 543.9882893562317 and batch: 150, loss is 3.5861068964004517 and perplexity is 36.09328714553491
At time: 544.3460681438446 and batch: 200, loss is 3.7297687005996703 and perplexity is 41.669468926122626
At time: 544.7045726776123 and batch: 250, loss is 3.803526768684387 and perplexity is 44.85911355686996
At time: 545.0627210140228 and batch: 300, loss is 3.790706558227539 and perplexity is 44.28768104926214
At time: 545.4216251373291 and batch: 350, loss is 3.7703181409835818 and perplexity is 43.39386800790728
At time: 545.780641078949 and batch: 400, loss is 3.5639682960510255 and perplexity is 35.30301235206899
At time: 546.139680147171 and batch: 450, loss is 3.660766673088074 and perplexity is 38.89114824110584
At time: 546.5113401412964 and batch: 500, loss is 3.6455671787261963 and perplexity is 38.30449218468879
At time: 546.8701059818268 and batch: 550, loss is 3.713625612258911 and perplexity is 41.002195426515875
At time: 547.2282874584198 and batch: 600, loss is 3.649345736503601 and perplexity is 38.44950171245117
At time: 547.5867886543274 and batch: 650, loss is 3.693542785644531 and perplexity is 40.18696887131127
At time: 547.9448301792145 and batch: 700, loss is 3.757421684265137 and perplexity is 42.83783400804879
At time: 548.3033800125122 and batch: 750, loss is 3.7066720056533815 and perplexity is 40.718071278179416
At time: 548.6629807949066 and batch: 800, loss is 3.6195170974731443 and perplexity is 37.31954176896933
At time: 549.0219712257385 and batch: 850, loss is 3.579125761985779 and perplexity is 35.84219253888749
At time: 549.3816587924957 and batch: 900, loss is 3.4884804630279542 and perplexity is 32.736166078619334
At time: 549.7392976284027 and batch: 950, loss is 3.6548296928405763 and perplexity is 38.66093632021309
At time: 550.0971817970276 and batch: 1000, loss is 3.6595200586318968 and perplexity is 38.84269618028561
At time: 550.4564490318298 and batch: 1050, loss is 3.5898394632339476 and perplexity is 36.22825949199462
At time: 550.8148903846741 and batch: 1100, loss is 3.75536979675293 and perplexity is 42.75002570858209
At time: 551.1730968952179 and batch: 1150, loss is 3.663564672470093 and perplexity is 39.00011802745601
At time: 551.5325765609741 and batch: 1200, loss is 3.6151745080947877 and perplexity is 37.15782970196208
At time: 551.8917787075043 and batch: 1250, loss is 3.4782622194290163 and perplexity is 32.40336318537637
At time: 552.2507994174957 and batch: 1300, loss is 3.5916679096221924 and perplexity is 36.29456151859385
At time: 552.6095788478851 and batch: 1350, loss is 3.6106444120407106 and perplexity is 36.98988186139157
At time: 552.9681792259216 and batch: 1400, loss is 3.4483964681625365 and perplexity is 31.4499209038554
At time: 553.3259520530701 and batch: 1450, loss is 3.571186652183533 and perplexity is 35.55876401056587
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287959693843483 and perplexity of 72.81774633569937
Annealing...
Finished 49 epochs...
Completing Train Step...
At time: 554.5360593795776 and batch: 50, loss is 3.710127425193787 and perplexity is 40.85901266289329
At time: 554.9272084236145 and batch: 100, loss is 3.7616670751571655 and perplexity is 43.020083945764256
At time: 555.2899396419525 and batch: 150, loss is 3.5861069679260256 and perplexity is 36.09328972712808
At time: 555.670371055603 and batch: 200, loss is 3.729768738746643 and perplexity is 41.66947051568675
At time: 556.0446434020996 and batch: 250, loss is 3.803526773452759 and perplexity is 44.85911377077489
At time: 556.4058456420898 and batch: 300, loss is 3.790706534385681 and perplexity is 44.28767999336156
At time: 556.7644574642181 and batch: 350, loss is 3.7703182172775267 and perplexity is 43.39387131859678
At time: 557.1242833137512 and batch: 400, loss is 3.5639682531356813 and perplexity is 35.3030108370281
At time: 557.4833962917328 and batch: 450, loss is 3.6607667207717896 and perplexity is 38.891150095580336
At time: 557.8428692817688 and batch: 500, loss is 3.6455671119689943 and perplexity is 38.304489627588154
At time: 558.2034811973572 and batch: 550, loss is 3.7136255741119384 and perplexity is 41.00219386240627
At time: 558.5632214546204 and batch: 600, loss is 3.6493456506729127 and perplexity is 38.449498412304116
At time: 558.9221084117889 and batch: 650, loss is 3.6935428524017335 and perplexity is 40.186971554080976
At time: 559.2816772460938 and batch: 700, loss is 3.757421684265137 and perplexity is 42.83783400804879
At time: 559.6411345005035 and batch: 750, loss is 3.7066719484329225 and perplexity is 40.71806894827275
At time: 560.0002062320709 and batch: 800, loss is 3.619516959190369 and perplexity is 37.31953660831987
At time: 560.3592190742493 and batch: 850, loss is 3.579125747680664 and perplexity is 35.84219202616081
At time: 560.718489408493 and batch: 900, loss is 3.4884804105758667 and perplexity is 32.73616436153913
At time: 561.0783355236053 and batch: 950, loss is 3.6548295640945434 and perplexity is 38.66093134277123
At time: 561.4380950927734 and batch: 1000, loss is 3.659520025253296 and perplexity is 38.842694883770776
At time: 561.7975461483002 and batch: 1050, loss is 3.58983943939209 and perplexity is 36.22825862824562
At time: 562.1559956073761 and batch: 1100, loss is 3.7553696775436403 and perplexity is 42.75002061238221
At time: 562.5159549713135 and batch: 1150, loss is 3.6635646295547484 and perplexity is 39.000116353752546
At time: 562.875726222992 and batch: 1200, loss is 3.6151743602752684 and perplexity is 37.157824209309965
At time: 563.2354419231415 and batch: 1250, loss is 3.4782621812820436 and perplexity is 32.403361949286186
At time: 563.5953457355499 and batch: 1300, loss is 3.5916677808761595 and perplexity is 36.29455684581334
At time: 563.9558773040771 and batch: 1350, loss is 3.610644383430481 and perplexity is 36.989880803102565
At time: 564.3157007694244 and batch: 1400, loss is 3.4483963680267333 and perplexity is 31.449917754592466
At time: 564.6757786273956 and batch: 1450, loss is 3.5711866092681883 and perplexity is 35.55876248454929
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2879594330094815 and perplexity of 72.81772734235768
Annealing...
Model not improving. Stopping early with 72.81770834902102loss at 49 epochs.
Finished Training.
Improved accuracyfrom -139.73909556442666 to -72.81770834902102
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f830fadb9e8>
SETTINGS FOR THIS RUN
{'batch_size': 20, 'seq_len': 35, 'anneal': 3.7530622630505643, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'dropout': 0.35219484179540284, 'lr': 25.109332104928228, 'num_layers': 1, 'wordvec_dim': 200, 'data': 'ptb'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.6088850498199463 and batch: 50, loss is 6.749370307922363 and perplexity is 853.5211377763399
At time: 0.9781525135040283 and batch: 100, loss is 6.004494342803955 and perplexity is 405.24602135128663
At time: 1.3440821170806885 and batch: 150, loss is 5.950429887771606 and perplexity is 383.91834539344836
At time: 1.7091171741485596 and batch: 200, loss is 5.973456373214722 and perplexity is 392.8612017246673
At time: 2.0743954181671143 and batch: 250, loss is 6.00929274559021 and perplexity is 407.19522778807135
At time: 2.4392306804656982 and batch: 300, loss is 6.136498622894287 and perplexity is 462.43158555862345
At time: 2.802562952041626 and batch: 350, loss is 6.247757358551025 and perplexity is 516.8524093207719
At time: 3.1675007343292236 and batch: 400, loss is 6.14279483795166 and perplexity is 465.3523394692151
At time: 3.532977819442749 and batch: 450, loss is 6.2166324234008785 and perplexity is 501.0131876538869
At time: 3.8973803520202637 and batch: 500, loss is 6.250744981765747 and perplexity is 518.3988785608434
At time: 4.273770570755005 and batch: 550, loss is 6.312680959701538 and perplexity is 551.5215756579295
At time: 4.63780403137207 and batch: 600, loss is 6.296693277359009 and perplexity is 542.7741358696201
At time: 5.000380277633667 and batch: 650, loss is 6.671038608551026 and perplexity is 789.214864250484
At time: 5.363654375076294 and batch: 700, loss is 6.662376899719238 and perplexity is 782.4084350987977
At time: 5.72672438621521 and batch: 750, loss is 6.433234930038452 and perplexity is 622.1834158377341
At time: 6.089890480041504 and batch: 800, loss is 6.349740362167358 and perplexity is 572.3440875422127
At time: 6.45233941078186 and batch: 850, loss is 6.243961410522461 and perplexity is 514.8941834497446
At time: 6.836860656738281 and batch: 900, loss is 6.205448760986328 and perplexity is 495.4412407599491
At time: 7.216656923294067 and batch: 950, loss is 6.22277042388916 and perplexity is 504.097864032295
At time: 7.580494403839111 and batch: 1000, loss is 6.404922790527344 and perplexity is 604.8150994208729
At time: 7.9433534145355225 and batch: 1050, loss is 6.405689430236817 and perplexity is 605.278952474344
At time: 8.306015253067017 and batch: 1100, loss is 6.481143569946289 and perplexity is 652.716947121959
At time: 8.66911792755127 and batch: 1150, loss is 6.544732608795166 and perplexity is 695.5706646033357
At time: 9.032659530639648 and batch: 1200, loss is 6.546117935180664 and perplexity is 696.5349247512903
At time: 9.396259784698486 and batch: 1250, loss is 6.4808511066436765 and perplexity is 652.5260792802129
At time: 9.759378671646118 and batch: 1300, loss is 6.610793790817261 and perplexity is 743.0726289014677
At time: 10.122406721115112 and batch: 1350, loss is 6.475774726867676 and perplexity is 649.2220025575687
At time: 10.484429121017456 and batch: 1400, loss is 6.317571220397949 and perplexity is 554.2252654283544
At time: 10.847472429275513 and batch: 1450, loss is 6.373692674636841 and perplexity is 586.218551389801
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 6.527675530849359 and perplexity of 683.806874716433
Finished 1 epochs...
Completing Train Step...
At time: 12.082171440124512 and batch: 50, loss is 6.247148561477661 and perplexity is 516.5378468486879
At time: 12.457866430282593 and batch: 100, loss is 6.4086104679107665 and perplexity is 607.0495798734562
At time: 12.821867942810059 and batch: 150, loss is 6.215743341445923 and perplexity is 500.5679438280038
At time: 13.187241315841675 and batch: 200, loss is 6.4253356075286865 and perplexity is 617.2879492665575
At time: 13.565565586090088 and batch: 250, loss is 6.209296169281006 and perplexity is 497.3510771033991
At time: 13.941455125808716 and batch: 300, loss is 6.339211378097534 and perplexity is 566.3494996021383
At time: 14.303204536437988 and batch: 350, loss is 6.399903011322022 and perplexity is 601.7866685481386
At time: 14.662989854812622 and batch: 400, loss is 6.335914630889892 and perplexity is 564.485462788136
At time: 15.042573690414429 and batch: 450, loss is 6.305206098556519 and perplexity is 547.4143978767423
At time: 15.412984132766724 and batch: 500, loss is 6.267473020553589 and perplexity is 527.1436123147231
At time: 15.772155046463013 and batch: 550, loss is 6.316428813934326 and perplexity is 553.5924764227719
At time: 16.130433082580566 and batch: 600, loss is 6.1716584300994874 and perplexity is 478.9798022836708
At time: 16.490132570266724 and batch: 650, loss is 6.385830984115601 and perplexity is 593.3776151542418
At time: 16.849499940872192 and batch: 700, loss is 6.386907682418824 and perplexity is 594.0168478942978
At time: 17.230818510055542 and batch: 750, loss is 6.323303289413452 and perplexity is 557.411245304821
At time: 17.60619878768921 and batch: 800, loss is 6.307286281585693 and perplexity is 548.5543052140333
At time: 17.97187852859497 and batch: 850, loss is 6.327228393554687 and perplexity is 559.6034419777624
At time: 18.330020427703857 and batch: 900, loss is 6.31632553100586 and perplexity is 553.5353027232143
At time: 18.689268350601196 and batch: 950, loss is 6.368077154159546 and perplexity is 582.9358547617635
At time: 19.047593355178833 and batch: 1000, loss is 6.478109636306763 and perplexity is 650.7396482325172
At time: 19.40461802482605 and batch: 1050, loss is 6.238489074707031 and perplexity is 512.0842051533369
At time: 19.761231422424316 and batch: 1100, loss is 6.202376651763916 and perplexity is 493.92152671405165
At time: 20.11800193786621 and batch: 1150, loss is 6.4303672504425045 and perplexity is 620.4017489969962
At time: 20.476000785827637 and batch: 1200, loss is 6.241489734649658 and perplexity is 513.6231034154966
At time: 20.835922718048096 and batch: 1250, loss is 6.365726718902588 and perplexity is 581.5673107432908
At time: 21.194262981414795 and batch: 1300, loss is 6.435580310821533 and perplexity is 623.6443854601201
At time: 21.55209517478943 and batch: 1350, loss is 6.261933221817016 and perplexity is 524.2314167337133
At time: 21.91039729118347 and batch: 1400, loss is 6.2205213451385495 and perplexity is 502.96538223581837
At time: 22.26855707168579 and batch: 1450, loss is 6.347900657653809 and perplexity is 571.2921115002965
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 6.441541883680555 and perplexity of 627.3733912277742
Finished 2 epochs...
Completing Train Step...
At time: 23.48892569541931 and batch: 50, loss is 6.406371021270752 and perplexity is 605.6916458094421
At time: 23.870438814163208 and batch: 100, loss is 6.330865669250488 and perplexity is 561.6425801823594
At time: 24.230944871902466 and batch: 150, loss is 6.331117153167725 and perplexity is 561.7838420203062
At time: 24.590612649917603 and batch: 200, loss is 6.299129772186279 and perplexity is 544.098214644552
At time: 24.950369119644165 and batch: 250, loss is 6.386160278320313 and perplexity is 593.5730431390034
At time: 25.309266805648804 and batch: 300, loss is 6.312180547714234 and perplexity is 551.2456566925499
At time: 25.66878366470337 and batch: 350, loss is 6.439486684799195 and perplexity is 626.0853381918844
At time: 26.04196786880493 and batch: 400, loss is 6.285032720565796 and perplexity is 536.4818443397994
At time: 26.402092456817627 and batch: 450, loss is 6.372295236587524 and perplexity is 585.3999194078345
At time: 26.761852979660034 and batch: 500, loss is 6.398474245071411 and perplexity is 600.9274700091494
At time: 27.120968341827393 and batch: 550, loss is 6.438152942657471 and perplexity is 625.2508584061532
At time: 27.480119943618774 and batch: 600, loss is 6.3206582736969 and perplexity is 555.9388319370862
At time: 27.83861494064331 and batch: 650, loss is 6.409203624725341 and perplexity is 607.4097622803072
At time: 28.198375701904297 and batch: 700, loss is 6.572950849533081 and perplexity is 715.4779990971793
At time: 28.558090686798096 and batch: 750, loss is 6.402266664505005 and perplexity is 603.2107658958247
At time: 28.916821241378784 and batch: 800, loss is 6.2507587337493895 and perplexity is 518.4060076227609
At time: 29.275691747665405 and batch: 850, loss is 6.153172388076782 and perplexity is 470.2067013244296
At time: 29.635786294937134 and batch: 900, loss is 6.17323504447937 and perplexity is 479.73556434373995
At time: 29.996278285980225 and batch: 950, loss is 6.288345041275025 and perplexity is 538.2617905118301
At time: 30.357234477996826 and batch: 1000, loss is 6.3677066135406495 and perplexity is 582.7198933630692
At time: 30.734278440475464 and batch: 1050, loss is 6.296393775939942 and perplexity is 542.6115985869825
At time: 31.10466241836548 and batch: 1100, loss is 6.4711271667480466 and perplexity is 646.2117049577203
At time: 31.465211868286133 and batch: 1150, loss is 6.65511305809021 and perplexity is 776.7457355121026
At time: 31.837796449661255 and batch: 1200, loss is 6.275680875778198 and perplexity is 531.4881359873925
At time: 32.21097421646118 and batch: 1250, loss is 6.28031216621399 and perplexity is 533.9553206227755
At time: 32.5731155872345 and batch: 1300, loss is 6.405010595321655 and perplexity is 604.868207417808
At time: 32.93254494667053 and batch: 1350, loss is 6.333707180023193 and perplexity is 563.2407631761191
At time: 33.29165053367615 and batch: 1400, loss is 6.264059734344483 and perplexity is 525.3473875511106
At time: 33.65103530883789 and batch: 1450, loss is 6.281002254486084 and perplexity is 534.3239240971989
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 6.491714347122062 and perplexity of 659.6532690964755
Annealing...
Finished 3 epochs...
Completing Train Step...
At time: 34.86651921272278 and batch: 50, loss is 5.899879608154297 and perplexity is 364.993522976178
At time: 35.22548508644104 and batch: 100, loss is 5.815715551376343 and perplexity is 335.5314025801642
At time: 35.599058628082275 and batch: 150, loss is 5.823128509521484 and perplexity is 338.0279246984715
At time: 35.95940446853638 and batch: 200, loss is 5.746003122329712 and perplexity is 312.9373849139848
At time: 36.31993317604065 and batch: 250, loss is 5.728037042617798 and perplexity is 307.36533077437065
At time: 36.68092346191406 and batch: 300, loss is 5.803349008560181 and perplexity is 331.40759032926434
At time: 37.04100060462952 and batch: 350, loss is 5.824662113189698 and perplexity is 338.54672327776785
At time: 37.40049624443054 and batch: 400, loss is 5.735198583602905 and perplexity is 309.57444106338164
At time: 37.76046824455261 and batch: 450, loss is 5.735699281692505 and perplexity is 309.7294832060243
At time: 38.12179756164551 and batch: 500, loss is 5.733361721038818 and perplexity is 309.0063173041672
At time: 38.48253631591797 and batch: 550, loss is 5.7932118225097655 and perplexity is 328.0650206769994
At time: 38.84201192855835 and batch: 600, loss is 5.642763214111328 and perplexity is 282.2415357546868
At time: 39.201359033584595 and batch: 650, loss is 5.81698320388794 and perplexity is 335.9570095092171
At time: 39.561150550842285 and batch: 700, loss is 5.804051332473755 and perplexity is 331.6404275590989
At time: 39.92144441604614 and batch: 750, loss is 5.749996747970581 and perplexity is 314.1896385300851
At time: 40.28238916397095 and batch: 800, loss is 5.724940366744995 and perplexity is 306.4149921751627
At time: 40.64323043823242 and batch: 850, loss is 5.705563135147095 and perplexity is 300.5346740424631
At time: 41.00296688079834 and batch: 900, loss is 5.612661457061767 and perplexity is 273.87216791329126
At time: 41.36350107192993 and batch: 950, loss is 5.677850561141968 and perplexity is 292.32042927582233
At time: 41.724153995513916 and batch: 1000, loss is 5.723567934036255 and perplexity is 305.99474666275995
At time: 42.08551788330078 and batch: 1050, loss is 5.58711874961853 and perplexity is 266.9653166081683
At time: 42.4458384513855 and batch: 1100, loss is 5.706208419799805 and perplexity is 300.72866703885006
At time: 42.80603289604187 and batch: 1150, loss is 5.697365980148316 and perplexity is 298.0812141702576
At time: 43.16647672653198 and batch: 1200, loss is 5.645314054489136 and perplexity is 282.96240788437206
At time: 43.538655281066895 and batch: 1250, loss is 5.656470985412597 and perplexity is 286.13707677275556
At time: 43.90123963356018 and batch: 1300, loss is 5.741056108474732 and perplexity is 311.393102278299
At time: 44.26137590408325 and batch: 1350, loss is 5.641728191375733 and perplexity is 281.94956047484317
At time: 44.62153911590576 and batch: 1400, loss is 5.55354718208313 and perplexity is 258.15164461628007
At time: 44.982757329940796 and batch: 1450, loss is 5.614003763198853 and perplexity is 274.2400350449777
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.775008764022436 and perplexity of 322.14725801190167
Finished 4 epochs...
Completing Train Step...
At time: 46.19912624359131 and batch: 50, loss is 5.712767219543457 and perplexity is 302.70756865884886
At time: 46.55982542037964 and batch: 100, loss is 5.707106294631958 and perplexity is 300.99880499718006
At time: 46.920788049697876 and batch: 150, loss is 5.653951215744018 and perplexity is 285.4169848595314
At time: 47.281869649887085 and batch: 200, loss is 5.6366658115386965 and perplexity is 280.52583147390044
At time: 47.64210343360901 and batch: 250, loss is 5.633463163375854 and perplexity is 279.6288430709285
At time: 48.002403259277344 and batch: 300, loss is 5.687413759231568 and perplexity is 295.1293572062804
At time: 48.362263441085815 and batch: 350, loss is 5.712660608291626 and perplexity is 302.6752983462352
At time: 48.72145986557007 and batch: 400, loss is 5.61891842842102 and perplexity is 275.59115042806985
At time: 49.07994747161865 and batch: 450, loss is 5.626950120925903 and perplexity is 277.81352657955824
At time: 49.44020938873291 and batch: 500, loss is 5.632616491317749 and perplexity is 279.39218934104747
At time: 49.80019521713257 and batch: 550, loss is 5.690293912887573 and perplexity is 295.98060037054654
At time: 50.16010665893555 and batch: 600, loss is 5.5457604885101315 and perplexity is 256.1493027926472
At time: 50.52019214630127 and batch: 650, loss is 5.698071603775024 and perplexity is 298.29162154313065
At time: 50.88192391395569 and batch: 700, loss is 5.673968744277954 and perplexity is 291.1878944722468
At time: 51.24165749549866 and batch: 750, loss is 5.6105376243591305 and perplexity is 273.29112648253806
At time: 51.602386474609375 and batch: 800, loss is 5.562996311187744 and perplexity is 260.60251388924314
At time: 51.963675022125244 and batch: 850, loss is 5.526410341262817 and perplexity is 251.24042300727447
At time: 52.32521986961365 and batch: 900, loss is 5.474823598861694 and perplexity is 238.60837242950387
At time: 52.68704867362976 and batch: 950, loss is 5.541484603881836 and perplexity is 255.05637620546588
At time: 53.04887104034424 and batch: 1000, loss is 5.601228227615357 and perplexity is 270.7587566661521
At time: 53.40995812416077 and batch: 1050, loss is 5.476056747436523 and perplexity is 238.9027934990593
At time: 53.78483486175537 and batch: 1100, loss is 5.589304990768433 and perplexity is 267.5496056345656
At time: 54.14574861526489 and batch: 1150, loss is 5.570819368362427 and perplexity is 262.6492175569546
At time: 54.50717639923096 and batch: 1200, loss is 5.5258328819274904 and perplexity is 251.09538376076128
At time: 54.868274450302124 and batch: 1250, loss is 5.537066202163697 and perplexity is 253.9319206521186
At time: 55.229774475097656 and batch: 1300, loss is 5.61121563911438 and perplexity is 273.4764847294843
At time: 55.58941030502319 and batch: 1350, loss is 5.548113813400269 and perplexity is 256.75281517432717
At time: 55.949331760406494 and batch: 1400, loss is 5.452017459869385 and perplexity is 233.22822016502033
At time: 56.33580565452576 and batch: 1450, loss is 5.512713222503662 and perplexity is 247.8226136016434
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.678262824686165 and perplexity of 292.4409671770207
Finished 5 epochs...
Completing Train Step...
At time: 57.551039934158325 and batch: 50, loss is 5.606204681396484 and perplexity is 272.1095333557443
At time: 57.9251070022583 and batch: 100, loss is 5.604244441986084 and perplexity is 271.57665597876587
At time: 58.286502838134766 and batch: 150, loss is 5.543596534729004 and perplexity is 255.595606842624
At time: 58.647789478302 and batch: 200, loss is 5.523351564407348 and perplexity is 250.4731087360451
At time: 59.00858807563782 and batch: 250, loss is 5.518927736282349 and perplexity is 249.36750605425848
At time: 59.36992335319519 and batch: 300, loss is 5.572529344558716 and perplexity is 263.09872568151667
At time: 59.73043894767761 and batch: 350, loss is 5.593082895278931 and perplexity is 268.56229421237583
At time: 60.09121036529541 and batch: 400, loss is 5.499025192260742 and perplexity is 244.45352089641767
At time: 60.45111131668091 and batch: 450, loss is 5.507482233047486 and perplexity is 246.52964083467347
At time: 60.81172847747803 and batch: 500, loss is 5.501061305999756 and perplexity is 244.9517631356669
At time: 61.17256236076355 and batch: 550, loss is 5.570497875213623 and perplexity is 262.5647912049454
At time: 61.53278875350952 and batch: 600, loss is 5.429599618911743 and perplexity is 228.05791706512997
At time: 61.89386296272278 and batch: 650, loss is 5.572847099304199 and perplexity is 263.1823398338258
At time: 62.25492477416992 and batch: 700, loss is 5.576855773925781 and perplexity is 264.2394696294319
At time: 62.616153717041016 and batch: 750, loss is 5.511033840179444 and perplexity is 247.40677395942512
At time: 62.98962640762329 and batch: 800, loss is 5.4572906589508055 and perplexity is 234.4613273538254
At time: 63.34916353225708 and batch: 850, loss is 5.425515613555908 and perplexity is 227.1284266242864
At time: 63.709686279296875 and batch: 900, loss is 5.381785678863525 and perplexity is 217.41015372506172
At time: 64.06953382492065 and batch: 950, loss is 5.451792020797729 and perplexity is 233.17564733778974
At time: 64.42955017089844 and batch: 1000, loss is 5.509758558273315 and perplexity is 247.0914616758999
At time: 64.78967666625977 and batch: 1050, loss is 5.380220375061035 and perplexity is 217.07010699238896
At time: 65.1493182182312 and batch: 1100, loss is 5.4920923709869385 and perplexity is 242.76462948202342
At time: 65.50932788848877 and batch: 1150, loss is 5.475322246551514 and perplexity is 238.72738361304727
At time: 65.86878776550293 and batch: 1200, loss is 5.426821527481079 and perplexity is 227.42523055743075
At time: 66.22886681556702 and batch: 1250, loss is 5.436438188552857 and perplexity is 229.6228518722067
At time: 66.58960962295532 and batch: 1300, loss is 5.501426639556885 and perplexity is 245.04126858329454
At time: 66.94951844215393 and batch: 1350, loss is 5.4437266540527345 and perplexity is 231.3025639319987
At time: 67.3082172870636 and batch: 1400, loss is 5.3512644195556645 and perplexity is 210.87476354378765
At time: 67.66837882995605 and batch: 1450, loss is 5.415364055633545 and perplexity is 224.8343830047896
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.587669959435096 and perplexity of 267.11251107515596
Finished 6 epochs...
Completing Train Step...
At time: 68.86271786689758 and batch: 50, loss is 5.5002234935760494 and perplexity is 244.74662545075284
At time: 69.23708534240723 and batch: 100, loss is 5.509379739761353 and perplexity is 246.9978765830711
At time: 69.59924721717834 and batch: 150, loss is 5.449559850692749 and perplexity is 232.65574010515738
At time: 69.9609603881836 and batch: 200, loss is 5.431110639572143 and perplexity is 228.40277776979306
At time: 70.32317471504211 and batch: 250, loss is 5.430187301635742 and perplexity is 228.19198215306994
At time: 70.6858446598053 and batch: 300, loss is 5.487780418395996 and perplexity is 241.7200935221238
At time: 71.04874801635742 and batch: 350, loss is 5.510685834884644 and perplexity is 247.320690071811
At time: 71.41116094589233 and batch: 400, loss is 5.428728094100952 and perplexity is 227.85924551827682
At time: 71.7742829322815 and batch: 450, loss is 5.437456312179566 and perplexity is 229.856755374066
At time: 72.13632535934448 and batch: 500, loss is 5.43610239982605 and perplexity is 229.54576005113728
At time: 72.5204164981842 and batch: 550, loss is 5.5048951816558835 and perplexity is 245.89268026440175
At time: 72.8825089931488 and batch: 600, loss is 5.3606375885009765 and perplexity is 212.86062067684125
At time: 73.24482679367065 and batch: 650, loss is 5.5135994815826415 and perplexity is 248.0423459984575
At time: 73.60825848579407 and batch: 700, loss is 5.513378772735596 and perplexity is 247.98760689917765
At time: 73.97112464904785 and batch: 750, loss is 5.446021423339844 and perplexity is 231.8339594335852
At time: 74.33400774002075 and batch: 800, loss is 5.397749338150025 and perplexity is 220.9086655741855
At time: 74.69655871391296 and batch: 850, loss is 5.366207857131958 and perplexity is 214.04961996333896
At time: 75.06202363967896 and batch: 900, loss is 5.324680652618408 and perplexity is 205.3427743156515
At time: 75.42497897148132 and batch: 950, loss is 5.396719083786011 and perplexity is 220.68119065606345
At time: 75.78750324249268 and batch: 1000, loss is 5.446132583618164 and perplexity is 231.85973159343354
At time: 76.1503894329071 and batch: 1050, loss is 5.329522953033448 and perplexity is 206.3395170331589
At time: 76.5124306678772 and batch: 1100, loss is 5.444112491607666 and perplexity is 231.39182636700812
At time: 76.87477803230286 and batch: 1150, loss is 5.418301954269409 and perplexity is 225.49589488353166
At time: 77.23648977279663 and batch: 1200, loss is 5.383187170028687 and perplexity is 217.71506575057026
At time: 77.5987663269043 and batch: 1250, loss is 5.389469738006592 and perplexity is 219.08718114188332
At time: 77.96096587181091 and batch: 1300, loss is 5.452418994903565 and perplexity is 233.32188827063047
At time: 78.32293748855591 and batch: 1350, loss is 5.393037567138672 and perplexity is 219.87024285376157
At time: 78.68413305282593 and batch: 1400, loss is 5.301305685043335 and perplexity is 200.59855759399508
At time: 79.07468628883362 and batch: 1450, loss is 5.371944875717163 and perplexity is 215.28115590568697
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.563958062065972 and perplexity of 260.8532691485617
Finished 7 epochs...
Completing Train Step...
At time: 80.408935546875 and batch: 50, loss is 5.450224475860596 and perplexity is 232.81042036197724
At time: 80.76907849311829 and batch: 100, loss is 5.461507835388184 and perplexity is 235.45217997068193
At time: 81.12958812713623 and batch: 150, loss is 5.403331327438354 and perplexity is 222.14522339459077
At time: 81.4909040927887 and batch: 200, loss is 5.388558015823365 and perplexity is 218.8875255278318
At time: 81.86517333984375 and batch: 250, loss is 5.385295190811157 and perplexity is 218.17449770975503
At time: 82.24207496643066 and batch: 300, loss is 5.4447528266906735 and perplexity is 231.54004212016096
At time: 82.6151385307312 and batch: 350, loss is 5.471613883972168 and perplexity is 237.84373537368083
At time: 82.9798674583435 and batch: 400, loss is 5.387325477600098 and perplexity is 218.61790447927945
At time: 83.34085774421692 and batch: 450, loss is 5.397348613739013 and perplexity is 220.82015981367977
At time: 83.7272675037384 and batch: 500, loss is 5.399120655059814 and perplexity is 221.2118091682694
At time: 84.10373067855835 and batch: 550, loss is 5.466864452362061 and perplexity is 236.71679110936913
At time: 84.47013783454895 and batch: 600, loss is 5.324065389633179 and perplexity is 205.21647336546494
At time: 84.83107042312622 and batch: 650, loss is 5.473182640075684 and perplexity is 238.2171470045384
At time: 85.19280219078064 and batch: 700, loss is 5.4822941017150875 and perplexity is 240.39757174485385
At time: 85.55387091636658 and batch: 750, loss is 5.413766374588013 and perplexity is 224.47545617432505
At time: 85.91497945785522 and batch: 800, loss is 5.368695287704468 and perplexity is 214.58271627723528
At time: 86.27711606025696 and batch: 850, loss is 5.3363606643676755 and perplexity is 207.7552417299483
At time: 86.63823628425598 and batch: 900, loss is 5.2981398487091065 and perplexity is 199.96449958328583
At time: 86.99994158744812 and batch: 950, loss is 5.37219799041748 and perplexity is 215.33565362774436
At time: 87.36150932312012 and batch: 1000, loss is 5.424489250183106 and perplexity is 226.89542991637413
At time: 87.72339344024658 and batch: 1050, loss is 5.302868795394898 and perplexity is 200.9123604662445
At time: 88.08425855636597 and batch: 1100, loss is 5.417454833984375 and perplexity is 225.30495362330987
At time: 88.4450454711914 and batch: 1150, loss is 5.395741014480591 and perplexity is 220.46545467676705
At time: 88.8057873249054 and batch: 1200, loss is 5.353543710708618 and perplexity is 211.35595670805208
At time: 89.16722750663757 and batch: 1250, loss is 5.359989910125733 and perplexity is 212.7228000924118
At time: 89.52889108657837 and batch: 1300, loss is 5.425424280166626 and perplexity is 227.10768316258032
At time: 89.88956785202026 and batch: 1350, loss is 5.364704093933105 and perplexity is 213.72798191644904
At time: 90.25007486343384 and batch: 1400, loss is 5.270790901184082 and perplexity is 194.5697870823206
At time: 90.61211466789246 and batch: 1450, loss is 5.335020875930786 and perplexity is 207.47708003989237
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.535624707865919 and perplexity of 253.56614293306063
Finished 8 epochs...
Completing Train Step...
At time: 91.81829786300659 and batch: 50, loss is 5.41766131401062 and perplexity is 225.35147939920353
At time: 92.17950510978699 and batch: 100, loss is 5.429342298507691 and perplexity is 227.99924065940544
At time: 92.5408251285553 and batch: 150, loss is 5.372831869125366 and perplexity is 215.4721935839413
At time: 92.90103244781494 and batch: 200, loss is 5.3539886474609375 and perplexity is 211.45001766504967
At time: 93.26169347763062 and batch: 250, loss is 5.356222991943359 and perplexity is 211.92299804911178
At time: 93.62331295013428 and batch: 300, loss is 5.415805416107178 and perplexity is 224.9336379165477
At time: 93.98432755470276 and batch: 350, loss is 5.436588735580444 and perplexity is 229.6574235122857
At time: 94.3457670211792 and batch: 400, loss is 5.357065153121948 and perplexity is 212.10154654367156
At time: 94.70618915557861 and batch: 450, loss is 5.359786376953125 and perplexity is 212.67950835182518
At time: 95.0669846534729 and batch: 500, loss is 5.366592025756836 and perplexity is 214.13186690883236
At time: 95.42836833000183 and batch: 550, loss is 5.433663330078125 and perplexity is 228.98656416813708
At time: 95.78931522369385 and batch: 600, loss is 5.2899695491790775 and perplexity is 198.33738578120915
At time: 96.15121626853943 and batch: 650, loss is 5.437852554321289 and perplexity is 229.94785235414426
At time: 96.51237916946411 and batch: 700, loss is 5.449195261001587 and perplexity is 232.57093168180324
At time: 96.87336492538452 and batch: 750, loss is 5.381947622299195 and perplexity is 217.44536472332342
At time: 97.23364090919495 and batch: 800, loss is 5.330058488845825 and perplexity is 206.45004882826453
At time: 97.59497427940369 and batch: 850, loss is 5.299867219924927 and perplexity is 200.3102110040691
At time: 97.95605063438416 and batch: 900, loss is 5.258484230041504 and perplexity is 192.1899546422411
At time: 98.31709480285645 and batch: 950, loss is 5.328290185928345 and perplexity is 206.08530518827178
At time: 98.67832922935486 and batch: 1000, loss is 5.38407380104065 and perplexity is 217.90818427942352
At time: 99.05519223213196 and batch: 1050, loss is 5.263812637329101 and perplexity is 193.21675417080513
At time: 99.42821860313416 and batch: 1100, loss is 5.379511852264404 and perplexity is 216.916362345343
At time: 99.78924703598022 and batch: 1150, loss is 5.358888463973999 and perplexity is 212.4886263714106
At time: 100.16510391235352 and batch: 1200, loss is 5.320662221908569 and perplexity is 204.51927430231106
At time: 100.52586793899536 and batch: 1250, loss is 5.319696283340454 and perplexity is 204.32181662868368
At time: 100.88786911964417 and batch: 1300, loss is 5.383819828033447 and perplexity is 217.85284850976137
At time: 101.24891710281372 and batch: 1350, loss is 5.32269471168518 and perplexity is 204.93538035885837
At time: 101.60974907875061 and batch: 1400, loss is 5.2274430561065675 and perplexity is 186.31579490389296
At time: 101.97041249275208 and batch: 1450, loss is 5.291217975616455 and perplexity is 198.58515004268605
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.4889828934628735 and perplexity of 242.01093073495136
Finished 9 epochs...
Completing Train Step...
At time: 103.16725420951843 and batch: 50, loss is 5.376405067443848 and perplexity is 216.24349565071014
At time: 103.55196499824524 and batch: 100, loss is 5.386587686538697 and perplexity is 218.45666962962162
At time: 103.93595862388611 and batch: 150, loss is 5.328773183822632 and perplexity is 206.18486799909965
At time: 104.30526828765869 and batch: 200, loss is 5.310361490249634 and perplexity is 202.4233892453927
At time: 104.67455768585205 and batch: 250, loss is 5.312883014678955 and perplexity is 202.93444882026236
At time: 105.04322528839111 and batch: 300, loss is 5.366759824752807 and perplexity is 214.16780103587615
At time: 105.41259503364563 and batch: 350, loss is 5.3884858131408695 and perplexity is 218.87172183186547
At time: 105.79571533203125 and batch: 400, loss is 5.312281084060669 and perplexity is 202.8123331182895
At time: 106.16543793678284 and batch: 450, loss is 5.321156644821167 and perplexity is 204.6204183194934
At time: 106.52751731872559 and batch: 500, loss is 5.32838059425354 and perplexity is 206.1039378578227
At time: 106.88987135887146 and batch: 550, loss is 5.387512998580933 and perplexity is 218.65890376714864
At time: 107.25271797180176 and batch: 600, loss is 5.248693208694458 and perplexity is 190.31740076036695
At time: 107.6162543296814 and batch: 650, loss is 5.396946401596069 and perplexity is 220.7313611231487
At time: 107.97932147979736 and batch: 700, loss is 5.4090729999542235 and perplexity is 223.424377245409
At time: 108.3686695098877 and batch: 750, loss is 5.33949764251709 and perplexity is 208.4079886748463
At time: 108.73980927467346 and batch: 800, loss is 5.284539823532104 and perplexity is 197.26338658998466
At time: 109.10932779312134 and batch: 850, loss is 5.254064350128174 and perplexity is 191.34237260739576
At time: 109.51473426818848 and batch: 900, loss is 5.213211297988892 and perplexity is 183.68297285871807
At time: 109.89432454109192 and batch: 950, loss is 5.290219526290894 and perplexity is 198.38697178549685
At time: 110.26409125328064 and batch: 1000, loss is 5.346036472320557 and perplexity is 209.77519814609553
At time: 110.62676048278809 and batch: 1050, loss is 5.223576354980469 and perplexity is 185.59675845533263
At time: 110.98829293251038 and batch: 1100, loss is 5.335554475784302 and perplexity is 207.5878193220144
At time: 111.35113716125488 and batch: 1150, loss is 5.315877752304077 and perplexity is 203.54309516274427
At time: 111.71304440498352 and batch: 1200, loss is 5.276461143493652 and perplexity is 195.67617871115328
At time: 112.0754759311676 and batch: 1250, loss is 5.281987390518188 and perplexity is 196.76052704028075
At time: 112.43776655197144 and batch: 1300, loss is 5.349446630477905 and perplexity is 210.4917858935953
At time: 112.79978680610657 and batch: 1350, loss is 5.289429636001587 and perplexity is 198.23032971612756
At time: 113.16107726097107 and batch: 1400, loss is 5.198882303237915 and perplexity is 181.06974766199505
At time: 113.52241897583008 and batch: 1450, loss is 5.2585945892333985 and perplexity is 192.2111657407239
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.4711893195779915 and perplexity of 237.74277682548217
Finished 10 epochs...
Completing Train Step...
At time: 114.71535992622375 and batch: 50, loss is 5.347806243896485 and perplexity is 210.14678104054553
At time: 115.08879446983337 and batch: 100, loss is 5.356807584762573 and perplexity is 212.04692293126647
At time: 115.44975566864014 and batch: 150, loss is 5.301214056015015 and perplexity is 200.58017778515517
At time: 115.8113431930542 and batch: 200, loss is 5.28311149597168 and perplexity is 196.98183098293939
At time: 116.1723849773407 and batch: 250, loss is 5.291515598297119 and perplexity is 198.6442622835173
At time: 116.55617499351501 and batch: 300, loss is 5.340750370025635 and perplexity is 208.669230693627
At time: 116.9269208908081 and batch: 350, loss is 5.359293460845947 and perplexity is 212.57470102922264
At time: 117.28749299049377 and batch: 400, loss is 5.282566413879395 and perplexity is 196.87448897212678
At time: 117.648681640625 and batch: 450, loss is 5.295804662704468 and perplexity is 199.49809007086512
At time: 118.00874161720276 and batch: 500, loss is 5.303325939178467 and perplexity is 201.00422729944984
At time: 118.36956477165222 and batch: 550, loss is 5.361675586700439 and perplexity is 213.08168432982865
At time: 118.73076558113098 and batch: 600, loss is 5.2195766830444335 and perplexity is 184.85591486241273
At time: 119.10573673248291 and batch: 650, loss is 5.375913028717041 and perplexity is 216.13712164864026
At time: 119.46775460243225 and batch: 700, loss is 5.382740287780762 and perplexity is 217.6177944885995
At time: 119.82935309410095 and batch: 750, loss is 5.316457071304321 and perplexity is 203.66104570733754
At time: 120.19133639335632 and batch: 800, loss is 5.2631204891204835 and perplexity is 193.0830658119471
At time: 120.55403351783752 and batch: 850, loss is 5.2348488998413085 and perplexity is 187.7007425893772
At time: 120.91571998596191 and batch: 900, loss is 5.1922792720794675 and perplexity is 179.87807712490934
At time: 121.27750706672668 and batch: 950, loss is 5.268505964279175 and perplexity is 194.1257149268706
At time: 121.63984751701355 and batch: 1000, loss is 5.327760038375854 and perplexity is 205.9760785238046
At time: 122.00247406959534 and batch: 1050, loss is 5.201661338806153 and perplexity is 181.5736467835677
At time: 122.36377334594727 and batch: 1100, loss is 5.320486869812012 and perplexity is 204.48341456290783
At time: 122.72623419761658 and batch: 1150, loss is 5.297625370025635 and perplexity is 199.86164857039466
At time: 123.08760452270508 and batch: 1200, loss is 5.25757848739624 and perplexity is 192.01595881394624
At time: 123.45153760910034 and batch: 1250, loss is 5.266270771026611 and perplexity is 193.6922910122736
At time: 123.8128936290741 and batch: 1300, loss is 5.331515474319458 and perplexity is 206.75106278366871
At time: 124.17496514320374 and batch: 1350, loss is 5.270940656661987 and perplexity is 194.59892715565945
At time: 124.53576231002808 and batch: 1400, loss is 5.182409868240357 and perplexity is 178.11151951448358
At time: 124.89767074584961 and batch: 1450, loss is 5.24429986000061 and perplexity is 189.48310407637513
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.461765387119391 and perplexity of 235.51282889703276
Finished 11 epochs...
Completing Train Step...
At time: 126.10466384887695 and batch: 50, loss is 5.33337142944336 and perplexity is 207.13513978260292
At time: 126.46673965454102 and batch: 100, loss is 5.337414636611938 and perplexity is 207.9743254221162
At time: 126.82839751243591 and batch: 150, loss is 5.2845492172241215 and perplexity is 197.26523963018798
At time: 127.18996024131775 and batch: 200, loss is 5.266531934738159 and perplexity is 193.74288301600285
At time: 127.55152750015259 and batch: 250, loss is 5.2696694564819335 and perplexity is 194.35171012887622
At time: 127.91214179992676 and batch: 300, loss is 5.324205541610718 and perplexity is 205.245236875615
At time: 128.2846119403839 and batch: 350, loss is 5.339099798202515 and perplexity is 208.3250912326714
At time: 128.64394903182983 and batch: 400, loss is 5.26619366645813 and perplexity is 193.6773570275036
At time: 129.00325918197632 and batch: 450, loss is 5.276336278915405 and perplexity is 195.65174721297169
At time: 129.3636336326599 and batch: 500, loss is 5.285063991546631 and perplexity is 197.36681285167333
At time: 129.72392964363098 and batch: 550, loss is 5.3419113445281985 and perplexity is 208.9116310330117
At time: 130.08483004570007 and batch: 600, loss is 5.198624362945557 and perplexity is 181.0230485014024
At time: 130.44572925567627 and batch: 650, loss is 5.357336816787719 and perplexity is 212.1591746546988
At time: 130.8069326877594 and batch: 700, loss is 5.366025905609131 and perplexity is 214.01067685201286
At time: 131.16821765899658 and batch: 750, loss is 5.303766918182373 and perplexity is 201.09288549014894
At time: 131.5301411151886 and batch: 800, loss is 5.24465087890625 and perplexity is 189.54962790308264
At time: 131.8918743133545 and batch: 850, loss is 5.21762866973877 and perplexity is 184.49616359452241
At time: 132.253338098526 and batch: 900, loss is 5.173636302947998 and perplexity is 176.55568157168722
At time: 132.61492156982422 and batch: 950, loss is 5.2531367111206055 and perplexity is 191.16495825972143
At time: 132.9765133857727 and batch: 1000, loss is 5.306960573196411 and perplexity is 201.73613340141029
At time: 133.33820390701294 and batch: 1050, loss is 5.181896362304688 and perplexity is 178.0200816709488
At time: 133.7027690410614 and batch: 1100, loss is 5.301544408798218 and perplexity is 200.64645095130166
At time: 134.06425833702087 and batch: 1150, loss is 5.280592555999756 and perplexity is 196.4862699813717
At time: 134.42468976974487 and batch: 1200, loss is 5.235515699386597 and perplexity is 187.82594309636778
At time: 134.79396510124207 and batch: 1250, loss is 5.239730243682861 and perplexity is 188.61921431768698
At time: 135.1694839000702 and batch: 1300, loss is 5.3099010181427 and perplexity is 202.33020037793776
At time: 135.5378098487854 and batch: 1350, loss is 5.246786155700684 and perplexity is 189.95480124961406
At time: 135.89858531951904 and batch: 1400, loss is 5.156382455825805 and perplexity is 173.5355462329607
At time: 136.25973749160767 and batch: 1450, loss is 5.225755243301392 and perplexity is 186.0015939502332
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.432987050113515 and perplexity of 228.83175749485116
Finished 12 epochs...
Completing Train Step...
At time: 137.45864725112915 and batch: 50, loss is 5.305934534072876 and perplexity is 201.52925038909186
At time: 137.81865048408508 and batch: 100, loss is 5.31937801361084 and perplexity is 204.2567975267059
At time: 138.17944812774658 and batch: 150, loss is 5.25955117225647 and perplexity is 192.39511964828145
At time: 138.54041361808777 and batch: 200, loss is 5.242766542434692 and perplexity is 189.19278893398302
At time: 138.9014048576355 and batch: 250, loss is 5.249191226959229 and perplexity is 190.41220590743717
At time: 139.26114463806152 and batch: 300, loss is 5.299546556472778 and perplexity is 200.2459891376609
At time: 139.63825464248657 and batch: 350, loss is 5.320104131698608 and perplexity is 204.40516594191573
At time: 140.01092505455017 and batch: 400, loss is 5.242633819580078 and perplexity is 189.16768039323875
At time: 140.37168145179749 and batch: 450, loss is 5.2545411586761475 and perplexity is 191.4336280402008
At time: 140.7311496734619 and batch: 500, loss is 5.262676219940186 and perplexity is 192.99730400864314
At time: 141.0907428264618 and batch: 550, loss is 5.325375785827637 and perplexity is 205.48556452071043
At time: 141.45917630195618 and batch: 600, loss is 5.1788228988647464 and perplexity is 177.47378340227164
At time: 141.8320071697235 and batch: 650, loss is 5.332501211166382 and perplexity is 206.95496540504817
At time: 142.19543743133545 and batch: 700, loss is 5.345484123229981 and perplexity is 209.65936100039025
At time: 142.55712890625 and batch: 750, loss is 5.281298389434815 and perplexity is 196.62500551658437
At time: 142.91873216629028 and batch: 800, loss is 5.220912199020386 and perplexity is 185.10295781814904
At time: 143.28006434440613 and batch: 850, loss is 5.189507598876953 and perplexity is 179.3802041681175
At time: 143.67000818252563 and batch: 900, loss is 5.148769512176513 and perplexity is 172.2194459533921
At time: 144.04084849357605 and batch: 950, loss is 5.231229581832886 and perplexity is 187.0226218191383
At time: 144.40294241905212 and batch: 1000, loss is 5.288870639801026 and perplexity is 198.119550680395
At time: 144.76431369781494 and batch: 1050, loss is 5.161027688980102 and perplexity is 174.34353449980387
At time: 145.12623262405396 and batch: 1100, loss is 5.281174907684326 and perplexity is 196.6007274156954
At time: 145.48803973197937 and batch: 1150, loss is 5.261218843460083 and perplexity is 192.71623913547256
At time: 145.84917378425598 and batch: 1200, loss is 5.212358875274658 and perplexity is 183.52646403575014
At time: 146.21065187454224 and batch: 1250, loss is 5.223006973266601 and perplexity is 185.49111313402634
At time: 146.57239961624146 and batch: 1300, loss is 5.288591794967651 and perplexity is 198.06431376891888
At time: 146.93412256240845 and batch: 1350, loss is 5.225675745010376 and perplexity is 185.98680772913534
At time: 147.29621291160583 and batch: 1400, loss is 5.129642629623413 and perplexity is 168.95672712536748
At time: 147.65776920318604 and batch: 1450, loss is 5.2042201900482175 and perplexity is 182.03886168919425
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.425940358740652 and perplexity of 227.22491882066075
Finished 13 epochs...
Completing Train Step...
At time: 148.86311268806458 and batch: 50, loss is 5.291336078643798 and perplexity is 198.60860493511123
At time: 149.2392861843109 and batch: 100, loss is 5.298998641967773 and perplexity is 200.13630150810903
At time: 149.60310006141663 and batch: 150, loss is 5.237192258834839 and perplexity is 188.14110857890114
At time: 149.96649169921875 and batch: 200, loss is 5.226486415863037 and perplexity is 186.13764294373624
At time: 150.3302502632141 and batch: 250, loss is 5.233187665939331 and perplexity is 187.38918660769104
At time: 150.71154832839966 and batch: 300, loss is 5.278266258239746 and perplexity is 196.02971565818416
At time: 151.08676624298096 and batch: 350, loss is 5.301251430511474 and perplexity is 200.58767450839187
At time: 151.4511320590973 and batch: 400, loss is 5.218226528167724 and perplexity is 184.6064991602747
At time: 151.81550312042236 and batch: 450, loss is 5.233212461471558 and perplexity is 187.39383307991213
At time: 152.17814087867737 and batch: 500, loss is 5.237306118011475 and perplexity is 188.1625313901839
At time: 152.54128432273865 and batch: 550, loss is 5.298757944107056 and perplexity is 200.08813492551334
At time: 152.9057002067566 and batch: 600, loss is 5.162181539535522 and perplexity is 174.54481698654314
At time: 153.27027654647827 and batch: 650, loss is 5.315062255859375 and perplexity is 203.37717415548636
At time: 153.63844394683838 and batch: 700, loss is 5.324318323135376 and perplexity is 205.26838605173378
At time: 154.00317692756653 and batch: 750, loss is 5.258970203399659 and perplexity is 192.28337653833978
At time: 154.3685896396637 and batch: 800, loss is 5.2001106071472165 and perplexity is 181.29229298957236
At time: 154.73326349258423 and batch: 850, loss is 5.168378591537476 and perplexity is 175.62983878996988
At time: 155.09786939620972 and batch: 900, loss is 5.1228201293945315 and perplexity is 167.80794306163958
At time: 155.4625961780548 and batch: 950, loss is 5.213356924057007 and perplexity is 183.70972383560778
At time: 155.83958864212036 and batch: 1000, loss is 5.265748691558838 and perplexity is 193.59119463653752
At time: 156.21987867355347 and batch: 1050, loss is 5.136536998748779 and perplexity is 170.12560186540213
At time: 156.58442997932434 and batch: 1100, loss is 5.262985916137695 and perplexity is 193.05708379613276
At time: 156.9487693309784 and batch: 1150, loss is 5.241196250915527 and perplexity is 188.89593423723818
At time: 157.31224608421326 and batch: 1200, loss is 5.1928255748748775 and perplexity is 179.97637186817752
At time: 157.6777970790863 and batch: 1250, loss is 5.19827865600586 and perplexity is 180.96047839337373
At time: 158.04279708862305 and batch: 1300, loss is 5.26625150680542 and perplexity is 193.68855971707697
At time: 158.40814924240112 and batch: 1350, loss is 5.204057102203369 and perplexity is 182.00917578433362
At time: 158.77285265922546 and batch: 1400, loss is 5.106576042175293 and perplexity is 165.10407657557235
At time: 159.13678336143494 and batch: 1450, loss is 5.183136377334595 and perplexity is 178.24096616959184
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.4103294437767095 and perplexity of 223.705273852442
Finished 14 epochs...
Completing Train Step...
At time: 160.34077215194702 and batch: 50, loss is 5.2699093246459965 and perplexity is 194.39833450839592
At time: 160.71622514724731 and batch: 100, loss is 5.27543363571167 and perplexity is 195.47522317414834
At time: 161.07827377319336 and batch: 150, loss is 5.210659580230713 and perplexity is 183.21486325079783
At time: 161.44059538841248 and batch: 200, loss is 5.202517576217652 and perplexity is 181.72918351156625
At time: 161.80242776870728 and batch: 250, loss is 5.216098785400391 and perplexity is 184.21412160417105
At time: 162.1646273136139 and batch: 300, loss is 5.260081796646118 and perplexity is 192.4972362816083
At time: 162.5265190601349 and batch: 350, loss is 5.287166557312012 and perplexity is 197.7822261194176
At time: 162.88792181015015 and batch: 400, loss is 5.19884087562561 and perplexity is 181.0622465300668
At time: 163.2480273246765 and batch: 450, loss is 5.214678592681885 and perplexity is 183.95268773720156
At time: 163.61030316352844 and batch: 500, loss is 5.221348466873169 and perplexity is 185.1837299059517
At time: 163.99295663833618 and batch: 550, loss is 5.283028001785278 and perplexity is 196.9653848318142
At time: 164.36343598365784 and batch: 600, loss is 5.1456093502044675 and perplexity is 171.67606364970237
At time: 164.72564363479614 and batch: 650, loss is 5.300348129272461 and perplexity is 200.4065652239129
At time: 165.08762860298157 and batch: 700, loss is 5.3111896991729735 and perplexity is 202.591107545968
At time: 165.47213101387024 and batch: 750, loss is 5.24267014503479 and perplexity is 189.17455212005436
At time: 165.83481121063232 and batch: 800, loss is 5.182415571212768 and perplexity is 178.112535282462
At time: 166.19682574272156 and batch: 850, loss is 5.154342966079712 and perplexity is 173.18198293275296
At time: 166.5588457584381 and batch: 900, loss is 5.109117136001587 and perplexity is 165.52415502859358
At time: 166.9204444885254 and batch: 950, loss is 5.196075820922852 and perplexity is 180.56229103448928
At time: 167.28234791755676 and batch: 1000, loss is 5.253030261993408 and perplexity is 191.14460999981043
At time: 167.64414286613464 and batch: 1050, loss is 5.1233868980407715 and perplexity is 167.90307829964533
At time: 168.005220413208 and batch: 1100, loss is 5.2490839004516605 and perplexity is 190.39177072701662
At time: 168.36697626113892 and batch: 1150, loss is 5.224876146316529 and perplexity is 185.83815236084183
At time: 168.72885751724243 and batch: 1200, loss is 5.177661647796631 and perplexity is 177.26781139748473
At time: 169.0904564857483 and batch: 1250, loss is 5.185950841903686 and perplexity is 178.74332565852015
At time: 169.4527235031128 and batch: 1300, loss is 5.254369649887085 and perplexity is 191.40079830584426
At time: 169.81514644622803 and batch: 1350, loss is 5.189351654052734 and perplexity is 179.35223293475133
At time: 170.17762899398804 and batch: 1400, loss is 5.093254680633545 and perplexity is 162.91925021999035
At time: 170.54020404815674 and batch: 1450, loss is 5.173457469940185 and perplexity is 176.52411041117224
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.411148462540064 and perplexity of 223.88856771950063
Annealing...
Finished 15 epochs...
Completing Train Step...
At time: 171.75796389579773 and batch: 50, loss is 5.227398195266724 and perplexity is 186.30743680833442
At time: 172.11933636665344 and batch: 100, loss is 5.1782620239257815 and perplexity is 177.37427071453308
At time: 172.48128700256348 and batch: 150, loss is 5.106863059997559 and perplexity is 165.1514711893023
At time: 172.84274792671204 and batch: 200, loss is 5.079479808807373 and perplexity is 160.69044442957846
At time: 173.20536041259766 and batch: 250, loss is 5.101929845809937 and perplexity is 164.33874992080965
At time: 173.56793308258057 and batch: 300, loss is 5.130205059051514 and perplexity is 169.05178008856456
At time: 173.9296464920044 and batch: 350, loss is 5.151374444961548 and perplexity is 172.66865085465068
At time: 174.29055333137512 and batch: 400, loss is 5.057258710861206 and perplexity is 157.15910673196467
At time: 174.66496229171753 and batch: 450, loss is 5.0799846172332765 and perplexity is 160.7715827978316
At time: 175.02683901786804 and batch: 500, loss is 5.082099685668945 and perplexity is 161.11198555862745
At time: 175.3889684677124 and batch: 550, loss is 5.128534412384033 and perplexity is 168.76959008105976
At time: 175.75157618522644 and batch: 600, loss is 5.01039677619934 and perplexity is 149.9642265819325
At time: 176.1121747493744 and batch: 650, loss is 5.153123931884766 and perplexity is 172.97099679939285
At time: 176.47423839569092 and batch: 700, loss is 5.166214542388916 and perplexity is 175.250178137197
At time: 176.8356215953827 and batch: 750, loss is 5.088638362884521 and perplexity is 162.16889646175534
At time: 177.20211124420166 and batch: 800, loss is 5.037783975601196 and perplexity is 154.1280847066033
At time: 177.57097792625427 and batch: 850, loss is 4.9912739276885985 and perplexity is 147.1237291556514
At time: 177.93263602256775 and batch: 900, loss is 4.951992511749268 and perplexity is 141.45653712159137
At time: 178.29443979263306 and batch: 950, loss is 5.034899692535401 and perplexity is 153.68417616860282
At time: 178.6561143398285 and batch: 1000, loss is 5.087076768875122 and perplexity is 161.91585211222235
At time: 179.01801919937134 and batch: 1050, loss is 4.9687314701080325 and perplexity is 143.84430079179367
At time: 179.37999272346497 and batch: 1100, loss is 5.086300468444824 and perplexity is 161.7902055426085
At time: 179.74175143241882 and batch: 1150, loss is 5.0595794200897215 and perplexity is 157.52425085409027
At time: 180.1042001247406 and batch: 1200, loss is 5.0049254417419435 and perplexity is 149.14596268065768
At time: 180.46613812446594 and batch: 1250, loss is 5.013802337646484 and perplexity is 150.47580958967635
At time: 180.8290195465088 and batch: 1300, loss is 5.0815690326690675 and perplexity is 161.02651368013457
At time: 181.191143989563 and batch: 1350, loss is 5.000044860839844 and perplexity is 148.41981719088042
At time: 181.5532467365265 and batch: 1400, loss is 4.902680673599243 and perplexity is 134.6502496873327
At time: 181.9152810573578 and batch: 1450, loss is 4.990923347473145 and perplexity is 147.0721595271596
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.2330504849425745 and perplexity of 187.36348213541362
Finished 16 epochs...
Completing Train Step...
At time: 183.1156096458435 and batch: 50, loss is 5.1160261344909665 and perplexity is 166.671720866114
At time: 183.49414086341858 and batch: 100, loss is 5.117412223815918 and perplexity is 166.90290294166817
At time: 183.88599634170532 and batch: 150, loss is 5.0572731399536135 and perplexity is 157.1613744115986
At time: 184.25213956832886 and batch: 200, loss is 5.039097394943237 and perplexity is 154.33065251332604
At time: 184.61421537399292 and batch: 250, loss is 5.066207437515259 and perplexity is 158.57179205945286
At time: 184.9754295349121 and batch: 300, loss is 5.099245138168335 and perplexity is 163.898140141953
At time: 185.33701920509338 and batch: 350, loss is 5.121436758041382 and perplexity is 167.57596285475884
At time: 185.6997525691986 and batch: 400, loss is 5.031912250518799 and perplexity is 153.22573872203031
At time: 186.06078672409058 and batch: 450, loss is 5.0557069492340085 and perplexity is 156.91542237968542
At time: 186.42147779464722 and batch: 500, loss is 5.058063678741455 and perplexity is 157.28566569608907
At time: 186.7835521697998 and batch: 550, loss is 5.103370685577392 and perplexity is 164.57570639419058
At time: 187.1453719139099 and batch: 600, loss is 4.988545122146607 and perplexity is 146.72280437983457
At time: 187.50715470314026 and batch: 650, loss is 5.134333257675171 and perplexity is 169.75110189094931
At time: 187.86858320236206 and batch: 700, loss is 5.147011470794678 and perplexity is 171.91694302489483
At time: 188.2297751903534 and batch: 750, loss is 5.072178602218628 and perplexity is 159.52148290562604
At time: 188.59249806404114 and batch: 800, loss is 5.023099946975708 and perplexity is 151.88139906609052
At time: 188.95519280433655 and batch: 850, loss is 4.976193256378174 and perplexity is 144.92165069911107
At time: 189.31695413589478 and batch: 900, loss is 4.9389968109130855 and perplexity is 139.6301038790313
At time: 189.67947459220886 and batch: 950, loss is 5.023947353363037 and perplexity is 152.0101588820157
At time: 190.04148411750793 and batch: 1000, loss is 5.078478450775147 and perplexity is 160.52961629905576
At time: 190.4029769897461 and batch: 1050, loss is 4.958494377136231 and perplexity is 142.37926495952382
At time: 190.76521944999695 and batch: 1100, loss is 5.075406084060669 and perplexity is 160.03716732853349
At time: 191.12779760360718 and batch: 1150, loss is 5.049037427902221 and perplexity is 155.87235387318802
At time: 191.49503660202026 and batch: 1200, loss is 4.998846282958985 and perplexity is 148.24203104746758
At time: 191.8731653690338 and batch: 1250, loss is 5.008810768127441 and perplexity is 149.72657062003148
At time: 192.24286723136902 and batch: 1300, loss is 5.075951757431031 and perplexity is 160.12451917963483
At time: 192.60537195205688 and batch: 1350, loss is 5.001213645935058 and perplexity is 148.5933894756381
At time: 192.96822237968445 and batch: 1400, loss is 4.906264562606811 and perplexity is 135.13368701246162
At time: 193.33042931556702 and batch: 1450, loss is 4.993332185745239 and perplexity is 147.42685960984304
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.230204264322917 and perplexity of 186.83096252283363
Finished 17 epochs...
Completing Train Step...
At time: 194.51913213729858 and batch: 50, loss is 5.1028502082824705 and perplexity is 164.49007076335064
At time: 194.90752387046814 and batch: 100, loss is 5.1050104236602785 and perplexity is 164.8457888191868
At time: 195.28455567359924 and batch: 150, loss is 5.045838003158569 and perplexity is 155.3744489367677
At time: 195.65200638771057 and batch: 200, loss is 5.028255186080933 and perplexity is 152.66640570381125
At time: 196.0123131275177 and batch: 250, loss is 5.054099273681641 and perplexity is 156.66335596613283
At time: 196.37432670593262 and batch: 300, loss is 5.087320632934571 and perplexity is 161.95534238414075
At time: 196.73540496826172 and batch: 350, loss is 5.108969564437866 and perplexity is 165.49973017245387
At time: 197.0963795185089 and batch: 400, loss is 5.021178274154663 and perplexity is 151.5898129657564
At time: 197.45783710479736 and batch: 450, loss is 5.046938705444336 and perplexity is 155.5455641040138
At time: 197.8186731338501 and batch: 500, loss is 5.047994327545166 and perplexity is 155.70984813483935
At time: 198.17961311340332 and batch: 550, loss is 5.091859436035156 and perplexity is 162.69209652048357
At time: 198.5407750606537 and batch: 600, loss is 4.979294519424439 and perplexity is 145.37178849610657
At time: 198.90134239196777 and batch: 650, loss is 5.125248403549194 and perplexity is 168.2159218944799
At time: 199.26282358169556 and batch: 700, loss is 5.137191228866577 and perplexity is 170.23693957422088
At time: 199.62383580207825 and batch: 750, loss is 5.063384609222412 and perplexity is 158.1248023028603
At time: 199.98413825035095 and batch: 800, loss is 5.014474077224731 and perplexity is 150.57692410405494
At time: 200.34493970870972 and batch: 850, loss is 4.967246246337891 and perplexity is 143.63081839086968
At time: 200.70497727394104 and batch: 900, loss is 4.931760292053223 and perplexity is 138.62331521503882
At time: 201.06425309181213 and batch: 950, loss is 5.018378705978393 and perplexity is 151.16602044435123
At time: 201.4247670173645 and batch: 1000, loss is 5.072357797622681 and perplexity is 159.55007098356006
At time: 201.78554844856262 and batch: 1050, loss is 4.953728475570679 and perplexity is 141.70231382034302
At time: 202.1445450782776 and batch: 1100, loss is 5.06987811088562 and perplexity is 159.15492690788014
At time: 202.51705121994019 and batch: 1150, loss is 5.04292477607727 and perplexity is 154.92246656768253
At time: 202.87529873847961 and batch: 1200, loss is 4.991631441116333 and perplexity is 147.1763372678558
At time: 203.23408961296082 and batch: 1250, loss is 5.0053177833557125 and perplexity is 149.20449032900817
At time: 203.59326171875 and batch: 1300, loss is 5.072012853622437 and perplexity is 159.49504463488574
At time: 203.95138549804688 and batch: 1350, loss is 4.997830629348755 and perplexity is 148.09154492726825
At time: 204.3098566532135 and batch: 1400, loss is 4.903330411911011 and perplexity is 134.73776554136643
At time: 204.66844630241394 and batch: 1450, loss is 4.9909486484527585 and perplexity is 147.0758806439433
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.228253747662928 and perplexity of 186.4669007874942
Finished 18 epochs...
Completing Train Step...
At time: 205.8482391834259 and batch: 50, loss is 5.094517965316772 and perplexity is 163.12519366860965
At time: 206.21935558319092 and batch: 100, loss is 5.09703914642334 and perplexity is 163.53698070161394
At time: 206.5781979560852 and batch: 150, loss is 5.036899490356445 and perplexity is 153.9918209603984
At time: 206.9376130104065 and batch: 200, loss is 5.018376331329346 and perplexity is 151.165661478531
At time: 207.29633212089539 and batch: 250, loss is 5.046201782226563 and perplexity is 155.43098119099383
At time: 207.65460753440857 and batch: 300, loss is 5.080367984771729 and perplexity is 160.83322921964537
At time: 208.01200675964355 and batch: 350, loss is 5.100643844604492 and perplexity is 164.127545923715
At time: 208.36984944343567 and batch: 400, loss is 5.0131384372711185 and perplexity is 150.37594179800666
At time: 208.7285761833191 and batch: 450, loss is 5.039260683059692 and perplexity is 154.35585493245796
At time: 209.08660626411438 and batch: 500, loss is 5.040707321166992 and perplexity is 154.57931358722033
At time: 209.44512486457825 and batch: 550, loss is 5.084350376129151 and perplexity is 161.4750071389091
At time: 209.8035774230957 and batch: 600, loss is 4.971388740539551 and perplexity is 144.22704229765912
At time: 210.16255044937134 and batch: 650, loss is 5.118065519332886 and perplexity is 167.0119754843512
At time: 210.52150464057922 and batch: 700, loss is 5.129583206176758 and perplexity is 168.94668743260553
At time: 210.88002705574036 and batch: 750, loss is 5.056794376373291 and perplexity is 157.08614927826082
At time: 211.23810076713562 and batch: 800, loss is 5.007887687683105 and perplexity is 149.5884247203931
At time: 211.61728429794312 and batch: 850, loss is 4.961605520248413 and perplexity is 142.82291700367077
At time: 211.9746434688568 and batch: 900, loss is 4.925019292831421 and perplexity is 137.6919980857405
At time: 212.33329391479492 and batch: 950, loss is 5.0131215000152585 and perplexity is 150.37339486377434
At time: 212.69210267066956 and batch: 1000, loss is 5.069024333953857 and perplexity is 159.0191020930073
At time: 213.05059599876404 and batch: 1050, loss is 4.9498903274536135 and perplexity is 141.1594817526975
At time: 213.40903735160828 and batch: 1100, loss is 5.065297832489014 and perplexity is 158.42761994015748
At time: 213.77034878730774 and batch: 1150, loss is 5.037352638244629 and perplexity is 154.06161784182453
At time: 214.1281235218048 and batch: 1200, loss is 4.987780427932739 and perplexity is 146.61064918796126
At time: 214.48678016662598 and batch: 1250, loss is 5.000444984436035 and perplexity is 148.4792153443898
At time: 214.84482049942017 and batch: 1300, loss is 5.067554063796997 and perplexity is 158.78547284397186
At time: 215.20324158668518 and batch: 1350, loss is 4.9949257183074955 and perplexity is 147.66197639455513
At time: 215.56138396263123 and batch: 1400, loss is 4.899138507843017 and perplexity is 134.1741399115049
At time: 215.91903567314148 and batch: 1450, loss is 4.986549806594849 and perplexity is 146.43033796488365
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.223049587673611 and perplexity of 185.49901789624525
Finished 19 epochs...
Completing Train Step...
At time: 217.1129081249237 and batch: 50, loss is 5.0871281337738035 and perplexity is 161.92416911716018
At time: 217.4714376926422 and batch: 100, loss is 5.08884976387024 and perplexity is 162.20318275027014
At time: 217.82948207855225 and batch: 150, loss is 5.02786699295044 and perplexity is 152.60715315532022
At time: 218.18689846992493 and batch: 200, loss is 5.009781455993652 and perplexity is 149.87197894701362
At time: 218.54572677612305 and batch: 250, loss is 5.0392653465271 and perplexity is 154.3565747676351
At time: 218.90318632125854 and batch: 300, loss is 5.073314828872681 and perplexity is 159.70283847740367
At time: 219.2608404159546 and batch: 350, loss is 5.09412166595459 and perplexity is 163.06056006637647
At time: 219.61847805976868 and batch: 400, loss is 5.005647773742676 and perplexity is 149.25373450111334
At time: 219.97901248931885 and batch: 450, loss is 5.032114868164062 and perplexity is 153.25678810587425
At time: 220.339910030365 and batch: 500, loss is 5.032275285720825 and perplexity is 153.28137515742415
At time: 220.71377110481262 and batch: 550, loss is 5.075434913635254 and perplexity is 160.04178119849306
At time: 221.07477188110352 and batch: 600, loss is 4.962921285629273 and perplexity is 143.01096213796728
At time: 221.436017036438 and batch: 650, loss is 5.110235691070557 and perplexity is 165.70940649890827
At time: 221.7943069934845 and batch: 700, loss is 5.1201193904876705 and perplexity is 167.35534906514172
At time: 222.1517894268036 and batch: 750, loss is 5.049044876098633 and perplexity is 155.87351484541838
At time: 222.51005172729492 and batch: 800, loss is 4.998687047958374 and perplexity is 148.21842760685996
At time: 222.86844897270203 and batch: 850, loss is 4.952066774368286 and perplexity is 141.4670424445869
At time: 223.2256200313568 and batch: 900, loss is 4.9139952468872075 and perplexity is 136.18241133778295
At time: 223.58365178108215 and batch: 950, loss is 5.001935415267944 and perplexity is 148.70067834148006
At time: 223.95351910591125 and batch: 1000, loss is 5.05912691116333 and perplexity is 157.45298584969697
At time: 224.32704615592957 and batch: 1050, loss is 4.9414066696167 and perplexity is 139.96699847129278
At time: 224.68813157081604 and batch: 1100, loss is 5.054665298461914 and perplexity is 156.75205640872645
At time: 225.04889678955078 and batch: 1150, loss is 5.026423616409302 and perplexity is 152.38704245996675
At time: 225.40983605384827 and batch: 1200, loss is 4.973854675292968 and perplexity is 144.58313564467815
At time: 225.76823329925537 and batch: 1250, loss is 4.991896524429321 and perplexity is 147.2153564303682
At time: 226.1257541179657 and batch: 1300, loss is 5.057890853881836 and perplexity is 157.2584851717979
At time: 226.48459386825562 and batch: 1350, loss is 4.983170709609985 and perplexity is 145.93637070303848
At time: 226.84276676177979 and batch: 1400, loss is 4.8865259075164795 and perplexity is 132.4924824402192
At time: 227.2000231742859 and batch: 1450, loss is 4.974961919784546 and perplexity is 144.74331318668155
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.2131895407652245 and perplexity of 183.67897647066906
Finished 20 epochs...
Completing Train Step...
At time: 228.39613246917725 and batch: 50, loss is 5.073332462310791 and perplexity is 159.70565461235105
At time: 228.7555501461029 and batch: 100, loss is 5.073545265197754 and perplexity is 159.7396440531141
At time: 229.11573958396912 and batch: 150, loss is 5.011803483963012 and perplexity is 150.17533086994726
At time: 229.47604417800903 and batch: 200, loss is 4.992440690994263 and perplexity is 147.29548790564107
At time: 229.84876799583435 and batch: 250, loss is 5.023575258255005 and perplexity is 151.95360716748516
At time: 230.20782709121704 and batch: 300, loss is 5.0557207679748535 and perplexity is 156.91759076822404
At time: 230.56571316719055 and batch: 350, loss is 5.075355195999146 and perplexity is 160.02902355452872
At time: 230.92453980445862 and batch: 400, loss is 4.985699682235718 and perplexity is 146.30590686611197
At time: 231.28390407562256 and batch: 450, loss is 5.016856346130371 and perplexity is 150.93606644522043
At time: 231.64347863197327 and batch: 500, loss is 5.0147007465362545 and perplexity is 150.61105914030932
At time: 232.00294423103333 and batch: 550, loss is 5.058111724853515 and perplexity is 157.29322284235292
At time: 232.36175203323364 and batch: 600, loss is 4.9464139652252195 and perplexity is 140.66961223743579
At time: 232.72132468223572 and batch: 650, loss is 5.091050271987915 and perplexity is 162.56050517188297
At time: 233.08181500434875 and batch: 700, loss is 5.1058876323699955 and perplexity is 164.99045642346366
At time: 233.44115614891052 and batch: 750, loss is 5.031383399963379 and perplexity is 153.144726628536
At time: 233.80140566825867 and batch: 800, loss is 4.982127265930176 and perplexity is 145.78417373766388
At time: 234.1602966785431 and batch: 850, loss is 4.93705117225647 and perplexity is 139.358698265541
At time: 234.519273519516 and batch: 900, loss is 4.898329887390137 and perplexity is 134.0656878119272
At time: 234.87837982177734 and batch: 950, loss is 4.984979677200317 and perplexity is 146.20060379038102
At time: 235.23885869979858 and batch: 1000, loss is 5.042828378677368 and perplexity is 154.90753316450113
At time: 235.59829807281494 and batch: 1050, loss is 4.924891681671142 and perplexity is 137.6744281711861
At time: 235.9576292037964 and batch: 1100, loss is 5.0392524528503415 and perplexity is 154.35458455668513
At time: 236.3169560432434 and batch: 1150, loss is 5.010310306549072 and perplexity is 149.95125978833232
At time: 236.67672538757324 and batch: 1200, loss is 4.957957143783569 and perplexity is 142.30279461270982
At time: 237.05429649353027 and batch: 1250, loss is 4.974658193588257 and perplexity is 144.69935752630983
At time: 237.4259057044983 and batch: 1300, loss is 5.043250102996826 and perplexity is 154.97287521570144
At time: 237.7856240272522 and batch: 1350, loss is 4.9672871017456055 and perplexity is 143.63668660638876
At time: 238.14507055282593 and batch: 1400, loss is 4.871037864685059 and perplexity is 130.45624258656022
At time: 238.50371026992798 and batch: 1450, loss is 4.9565838432312015 and perplexity is 142.10750423315014
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.204539241953793 and perplexity of 182.0969508011331
Finished 21 epochs...
Completing Train Step...
At time: 239.71985507011414 and batch: 50, loss is 5.0593288707733155 and perplexity is 157.48478820459778
At time: 240.10594749450684 and batch: 100, loss is 5.057442483901977 and perplexity is 157.18799099288657
At time: 240.46745920181274 and batch: 150, loss is 4.9950557136535645 and perplexity is 147.68117301198617
At time: 240.82890629768372 and batch: 200, loss is 4.976725177764893 and perplexity is 144.99875813024425
At time: 241.18986439704895 and batch: 250, loss is 5.010847749710083 and perplexity is 150.03187172761798
At time: 241.5516722202301 and batch: 300, loss is 5.044570283889771 and perplexity is 155.17760255331106
At time: 241.91263151168823 and batch: 350, loss is 5.063930959701538 and perplexity is 158.21121746869417
At time: 242.27320051193237 and batch: 400, loss is 4.9765873050689695 and perplexity is 144.97876813862402
At time: 242.63409900665283 and batch: 450, loss is 5.004446563720703 and perplexity is 149.07455705582987
At time: 242.99512100219727 and batch: 500, loss is 5.003413324356079 and perplexity is 148.9206069025914
At time: 243.35666155815125 and batch: 550, loss is 5.046101741790771 and perplexity is 155.41543258565758
At time: 243.71863985061646 and batch: 600, loss is 4.934356851577759 and perplexity is 138.9837266168174
At time: 244.07939100265503 and batch: 650, loss is 5.0783082866668705 and perplexity is 160.50230224404817
At time: 244.44023871421814 and batch: 700, loss is 5.0963071346282955 and perplexity is 163.41731350705692
At time: 244.80129718780518 and batch: 750, loss is 5.020224437713623 and perplexity is 151.4452900146452
At time: 245.16263341903687 and batch: 800, loss is 4.973563499450684 and perplexity is 144.54104265690464
At time: 245.522141456604 and batch: 850, loss is 4.926978235244751 and perplexity is 137.96199314681388
At time: 245.88156843185425 and batch: 900, loss is 4.886961374282837 and perplexity is 132.55019107729893
At time: 246.2424237728119 and batch: 950, loss is 4.974168405532837 and perplexity is 144.62850286266692
At time: 246.6030764579773 and batch: 1000, loss is 5.032221841812134 and perplexity is 153.2731834205073
At time: 246.96323204040527 and batch: 1050, loss is 4.915189752578735 and perplexity is 136.34517919742558
At time: 247.32441782951355 and batch: 1100, loss is 5.0297933864593505 and perplexity is 152.90141792844523
At time: 247.6858344078064 and batch: 1150, loss is 5.001040821075439 and perplexity is 148.56771106295963
At time: 248.04592084884644 and batch: 1200, loss is 4.947593040466309 and perplexity is 140.83557011358354
At time: 248.4189419746399 and batch: 1250, loss is 4.964879732131958 and perplexity is 143.2913158959221
At time: 248.77967810630798 and batch: 1300, loss is 5.034323053359985 and perplexity is 153.59558139804517
At time: 249.14161896705627 and batch: 1350, loss is 4.957599477767944 and perplexity is 142.2519068401043
At time: 249.50266981124878 and batch: 1400, loss is 4.859440517425537 and perplexity is 128.95203550447604
At time: 249.86321330070496 and batch: 1450, loss is 4.94788164138794 and perplexity is 140.87622125461297
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.1953427567441235 and perplexity of 180.42997579061088
Finished 22 epochs...
Completing Train Step...
At time: 251.06504130363464 and batch: 50, loss is 5.046538314819336 and perplexity is 155.48329758468338
At time: 251.4451401233673 and batch: 100, loss is 5.047106161117553 and perplexity is 155.5716132721465
At time: 251.80544590950012 and batch: 150, loss is 4.9812735748291015 and perplexity is 145.6597721936673
At time: 252.16648173332214 and batch: 200, loss is 4.965794792175293 and perplexity is 143.4224960633667
At time: 252.5273027420044 and batch: 250, loss is 5.000742988586426 and perplexity is 148.52346936042193
At time: 252.88892531394958 and batch: 300, loss is 5.034237632751465 and perplexity is 153.58246173036903
At time: 253.24910640716553 and batch: 350, loss is 5.0540257263183594 and perplexity is 156.65183421308117
At time: 253.61773538589478 and batch: 400, loss is 4.964390354156494 and perplexity is 143.22120943752486
At time: 253.99378275871277 and batch: 450, loss is 4.99464822769165 and perplexity is 147.62100726632565
At time: 254.36088132858276 and batch: 500, loss is 4.992010116577148 and perplexity is 147.2320798887071
At time: 254.72175335884094 and batch: 550, loss is 5.033473062515259 and perplexity is 153.46508202955755
At time: 255.09295439720154 and batch: 600, loss is 4.923488712310791 and perplexity is 137.48141059728917
At time: 255.4639413356781 and batch: 650, loss is 5.069286155700683 and perplexity is 159.0607422030013
At time: 255.82490873336792 and batch: 700, loss is 5.085385503768921 and perplexity is 161.64224092115344
At time: 256.184654712677 and batch: 750, loss is 5.01016583442688 and perplexity is 149.92959757643592
At time: 256.5454795360565 and batch: 800, loss is 4.964520530700684 and perplexity is 143.2398546931852
At time: 256.90684247016907 and batch: 850, loss is 4.916540699005127 and perplexity is 136.52949870487527
At time: 257.2668299674988 and batch: 900, loss is 4.877630043029785 and perplexity is 131.31907424931742
At time: 257.648827791214 and batch: 950, loss is 4.9643037891387936 and perplexity is 143.20881202759352
At time: 258.0092122554779 and batch: 1000, loss is 5.022003259658813 and perplexity is 151.71492396431418
At time: 258.36956810951233 and batch: 1050, loss is 4.9075500011444095 and perplexity is 135.30750475355265
At time: 258.73021268844604 and batch: 1100, loss is 5.022108678817749 and perplexity is 151.73091846704517
At time: 259.09155654907227 and batch: 1150, loss is 4.992587537765503 and perplexity is 147.317119360674
At time: 259.45208716392517 and batch: 1200, loss is 4.940599336624145 and perplexity is 139.85404409758954
At time: 259.8122503757477 and batch: 1250, loss is 4.955888433456421 and perplexity is 142.0087156388949
At time: 260.17107367515564 and batch: 1300, loss is 5.025670900344848 and perplexity is 152.27238144410063
At time: 260.53091835975647 and batch: 1350, loss is 4.947884998321533 and perplexity is 140.87669416752635
At time: 260.8909533023834 and batch: 1400, loss is 4.851482582092285 and perplexity is 127.92991591974194
At time: 261.2509310245514 and batch: 1450, loss is 4.939641284942627 and perplexity is 139.72012085841052
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.186833308293269 and perplexity of 178.9011302541611
Finished 23 epochs...
Completing Train Step...
At time: 262.4754321575165 and batch: 50, loss is 5.038555402755737 and perplexity is 154.2470291690187
At time: 262.84951615333557 and batch: 100, loss is 5.0403730583190915 and perplexity is 154.52765210037305
At time: 263.21299839019775 and batch: 150, loss is 4.97343243598938 and perplexity is 144.5220998489356
At time: 263.5847496986389 and batch: 200, loss is 4.9563166046142575 and perplexity is 142.06953269421825
At time: 263.9600386619568 and batch: 250, loss is 4.991751117706299 and perplexity is 147.1939518840313
At time: 264.3239493370056 and batch: 300, loss is 5.02395809173584 and perplexity is 152.01179123253593
At time: 264.6864080429077 and batch: 350, loss is 5.045391025543213 and perplexity is 155.30501555483443
At time: 265.04835200309753 and batch: 400, loss is 4.9570770168304445 and perplexity is 142.17760518704128
At time: 265.41042494773865 and batch: 450, loss is 4.986234111785889 and perplexity is 146.38411796340498
At time: 265.7731354236603 and batch: 500, loss is 4.9851229763031 and perplexity is 146.2215557068901
At time: 266.13477659225464 and batch: 550, loss is 5.025424242019653 and perplexity is 152.23482682529027
At time: 266.4960849285126 and batch: 600, loss is 4.916285285949707 and perplexity is 136.49463174138447
At time: 266.8707752227783 and batch: 650, loss is 5.059616651535034 and perplexity is 157.53011581880122
At time: 267.2321455478668 and batch: 700, loss is 5.076739244461059 and perplexity is 160.2506648241889
At time: 267.59474301338196 and batch: 750, loss is 5.001203489303589 and perplexity is 148.59188027500664
At time: 267.9585783481598 and batch: 800, loss is 4.955354347229004 and perplexity is 141.9328909899517
At time: 268.32084560394287 and batch: 850, loss is 4.908685131072998 and perplexity is 135.46118355796466
At time: 268.6824109554291 and batch: 900, loss is 4.868732995986939 and perplexity is 130.15590432963194
At time: 269.0449962615967 and batch: 950, loss is 4.955602922439575 and perplexity is 141.9681763735707
At time: 269.4074969291687 and batch: 1000, loss is 5.011489477157593 and perplexity is 150.12818219693744
At time: 269.77040910720825 and batch: 1050, loss is 4.898480615615845 and perplexity is 134.08589681817497
At time: 270.1328537464142 and batch: 1100, loss is 5.016887550354004 and perplexity is 150.94077636147625
At time: 270.50225496292114 and batch: 1150, loss is 4.985425825119019 and perplexity is 146.2658454381055
At time: 270.8789701461792 and batch: 1200, loss is 4.932695407867431 and perplexity is 138.7530046972067
At time: 271.24781799316406 and batch: 1250, loss is 4.94842495918274 and perplexity is 140.95278260917453
At time: 271.6103003025055 and batch: 1300, loss is 5.016568918228149 and perplexity is 150.89268944245148
At time: 271.97183632850647 and batch: 1350, loss is 4.940330152511597 and perplexity is 139.81640267730623
At time: 272.3332188129425 and batch: 1400, loss is 4.842195949554443 and perplexity is 126.74737719992615
At time: 272.6941132545471 and batch: 1450, loss is 4.92875485420227 and perplexity is 138.20731689814153
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.181235288962339 and perplexity of 177.90243623097004
Finished 24 epochs...
Completing Train Step...
At time: 273.89624094963074 and batch: 50, loss is 5.030902233123779 and perplexity is 153.07105618973026
At time: 274.25653553009033 and batch: 100, loss is 5.026442031860352 and perplexity is 152.38984876192745
At time: 274.61692476272583 and batch: 150, loss is 4.959069004058838 and perplexity is 142.4611034294328
At time: 274.9767920970917 and batch: 200, loss is 4.943217830657959 and perplexity is 140.22073095181784
At time: 275.33783888816833 and batch: 250, loss is 4.976565628051758 and perplexity is 144.97562546543378
At time: 275.6982171535492 and batch: 300, loss is 5.011941967010498 and perplexity is 150.19612904748752
At time: 276.0581307411194 and batch: 350, loss is 5.034629383087158 and perplexity is 153.64263949786925
At time: 276.431764125824 and batch: 400, loss is 4.943049468994141 and perplexity is 140.1971251434653
At time: 276.79277753829956 and batch: 450, loss is 4.971291255950928 and perplexity is 144.21298306906266
At time: 277.15267038345337 and batch: 500, loss is 4.9686065101623536 and perplexity is 143.82632713879724
At time: 277.5135314464569 and batch: 550, loss is 5.00877311706543 and perplexity is 149.72093336176138
At time: 277.87378454208374 and batch: 600, loss is 4.898597211837768 and perplexity is 134.10153163862
At time: 278.233918428421 and batch: 650, loss is 5.041331005096436 and perplexity is 154.67575229143804
At time: 278.59467029571533 and batch: 700, loss is 5.063428707122803 and perplexity is 158.13177542839054
At time: 278.95548844337463 and batch: 750, loss is 4.985364189147949 and perplexity is 146.2568304785134
At time: 279.3164587020874 and batch: 800, loss is 4.941729621887207 and perplexity is 140.01220843118185
At time: 279.676718711853 and batch: 850, loss is 4.890146312713623 and perplexity is 132.97302827265332
At time: 280.036119222641 and batch: 900, loss is 4.853626041412354 and perplexity is 128.20442258216784
At time: 280.3964066505432 and batch: 950, loss is 4.93512433052063 and perplexity is 139.09043464324137
At time: 280.75796818733215 and batch: 1000, loss is 4.991780118942261 and perplexity is 147.19822075246302
At time: 281.11815071105957 and batch: 1050, loss is 4.8795740509033205 and perplexity is 131.57460786280646
At time: 281.4790680408478 and batch: 1100, loss is 5.000357179641724 and perplexity is 148.46617872977401
At time: 281.8403010368347 and batch: 1150, loss is 4.964629878997803 and perplexity is 143.2555185837698
At time: 282.20118379592896 and batch: 1200, loss is 4.913582677841187 and perplexity is 136.126238278682
At time: 282.56243872642517 and batch: 1250, loss is 4.928814344406128 and perplexity is 138.2155391241669
At time: 282.92376255989075 and batch: 1300, loss is 4.995441446304321 and perplexity is 147.73814945044882
At time: 283.30366349220276 and batch: 1350, loss is 4.923318519592285 and perplexity is 137.45801425327576
At time: 283.66373014450073 and batch: 1400, loss is 4.821780376434326 and perplexity is 124.18599189134409
At time: 284.0232000350952 and batch: 1450, loss is 4.910783710479737 and perplexity is 135.7457581048941
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.16790771484375 and perplexity of 175.54715825985593
Finished 25 epochs...
Completing Train Step...
At time: 285.2107422351837 and batch: 50, loss is 5.014563446044922 and perplexity is 150.59038158744076
At time: 285.5848476886749 and batch: 100, loss is 5.005361528396606 and perplexity is 149.2110174283022
At time: 285.9455337524414 and batch: 150, loss is 4.940443611145019 and perplexity is 139.8322669552367
At time: 286.3062243461609 and batch: 200, loss is 4.92617280960083 and perplexity is 137.8509197563301
At time: 286.66704869270325 and batch: 250, loss is 4.958007717132569 and perplexity is 142.30999152358973
At time: 287.02747869491577 and batch: 300, loss is 4.993332681655883 and perplexity is 147.4269327204101
At time: 287.38814783096313 and batch: 350, loss is 5.020435695648193 and perplexity is 151.47728741354723
At time: 287.74941873550415 and batch: 400, loss is 4.925941858291626 and perplexity is 137.8190865820355
At time: 288.12076687812805 and batch: 450, loss is 4.956425266265869 and perplexity is 142.08497104304757
At time: 288.4928877353668 and batch: 500, loss is 4.953251304626465 and perplexity is 141.6347137231439
At time: 288.85426473617554 and batch: 550, loss is 4.991194944381714 and perplexity is 147.1121092958951
At time: 289.21507716178894 and batch: 600, loss is 4.879772434234619 and perplexity is 131.60071266112138
At time: 289.6012976169586 and batch: 650, loss is 5.024841556549072 and perplexity is 152.14614764212754
At time: 289.973121881485 and batch: 700, loss is 5.046170969009399 and perplexity is 155.426191936203
At time: 290.3377342224121 and batch: 750, loss is 4.970547037124634 and perplexity is 144.10569697918237
At time: 290.6979603767395 and batch: 800, loss is 4.928236722946167 and perplexity is 138.13572591579884
At time: 291.0586223602295 and batch: 850, loss is 4.874833221435547 and perplexity is 130.95231135099328
At time: 291.41927576065063 and batch: 900, loss is 4.839120359420776 and perplexity is 126.3581530709015
At time: 291.78004121780396 and batch: 950, loss is 4.920832281112671 and perplexity is 137.1166853372742
At time: 292.14053177833557 and batch: 1000, loss is 4.977661247253418 and perplexity is 145.13455058927747
At time: 292.5012183189392 and batch: 1050, loss is 4.867835683822632 and perplexity is 130.0391662365089
At time: 292.8622443675995 and batch: 1100, loss is 4.988231744766235 and perplexity is 146.67683197548928
At time: 293.2229313850403 and batch: 1150, loss is 4.949299650192261 and perplexity is 141.07612667699934
At time: 293.58368134498596 and batch: 1200, loss is 4.901836748123169 and perplexity is 134.53666284741726
At time: 293.94455432891846 and batch: 1250, loss is 4.91433934211731 and perplexity is 136.22927911897563
At time: 294.30424284935 and batch: 1300, loss is 4.983231258392334 and perplexity is 145.94520724010303
At time: 294.66492533683777 and batch: 1350, loss is 4.910475749969482 and perplexity is 135.7039602083443
At time: 295.0303180217743 and batch: 1400, loss is 4.811958360671997 and perplexity is 122.97220579263835
At time: 295.4071595668793 and batch: 1450, loss is 4.899249773025513 and perplexity is 134.18906965223314
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.152371398404113 and perplexity of 172.840879298148
Finished 26 epochs...
Completing Train Step...
At time: 296.62381410598755 and batch: 50, loss is 5.000787572860718 and perplexity is 148.5300913191352
At time: 296.9984276294708 and batch: 100, loss is 4.991682939529419 and perplexity is 147.18391681083446
At time: 297.36113691329956 and batch: 150, loss is 4.928213882446289 and perplexity is 138.13257086279953
At time: 297.7234034538269 and batch: 200, loss is 4.912851676940918 and perplexity is 136.0267662374555
At time: 298.08442878723145 and batch: 250, loss is 4.9426905536651615 and perplexity is 140.14681527520403
At time: 298.4467647075653 and batch: 300, loss is 4.978474397659301 and perplexity is 145.2526148034732
At time: 298.8090217113495 and batch: 350, loss is 5.008122301101684 and perplexity is 149.62352428935054
At time: 299.1708753108978 and batch: 400, loss is 4.913816261291504 and perplexity is 136.15803882899436
At time: 299.5332555770874 and batch: 450, loss is 4.945813674926757 and perplexity is 140.58519497388835
At time: 299.89509677886963 and batch: 500, loss is 4.941078987121582 and perplexity is 139.92114124971428
At time: 300.25752544403076 and batch: 550, loss is 4.980355749130249 and perplexity is 145.52614324488138
At time: 300.61966705322266 and batch: 600, loss is 4.868458528518676 and perplexity is 130.12018567012043
At time: 300.9825620651245 and batch: 650, loss is 5.012326250076294 and perplexity is 150.2538579678414
At time: 301.345253944397 and batch: 700, loss is 5.034586820602417 and perplexity is 153.63610022453489
At time: 301.70746779441833 and batch: 750, loss is 4.957844161987305 and perplexity is 142.2867178955663
At time: 302.0695044994354 and batch: 800, loss is 4.914135761260987 and perplexity is 136.20154826850725
At time: 302.4318585395813 and batch: 850, loss is 4.864824113845825 and perplexity is 129.64813329473685
At time: 302.7938804626465 and batch: 900, loss is 4.827804841995239 and perplexity is 124.93640426977407
At time: 303.1557517051697 and batch: 950, loss is 4.913204364776611 and perplexity is 136.07474968432768
At time: 303.5174481868744 and batch: 1000, loss is 4.967397432327271 and perplexity is 143.65253499983572
At time: 303.89249539375305 and batch: 1050, loss is 4.859716548919677 and perplexity is 128.9876352406069
At time: 304.2540211677551 and batch: 1100, loss is 4.97976170539856 and perplexity is 145.43972002381773
At time: 304.61696600914 and batch: 1150, loss is 4.93969955444336 and perplexity is 139.7282625172982
At time: 304.979722738266 and batch: 1200, loss is 4.890426912307739 and perplexity is 133.01034568579573
At time: 305.3418219089508 and batch: 1250, loss is 4.903949089050293 and perplexity is 134.82115050823157
At time: 305.7043077945709 and batch: 1300, loss is 4.972127132415771 and perplexity is 144.33357770162098
At time: 306.0669996738434 and batch: 1350, loss is 4.899698534011841 and perplexity is 134.2493019854345
At time: 306.4347150325775 and batch: 1400, loss is 4.8043566417694095 and perplexity is 122.04094970932687
At time: 306.81219506263733 and batch: 1450, loss is 4.889711580276489 and perplexity is 132.91523314761736
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.1454446906717415 and perplexity of 171.64779787645995
Finished 27 epochs...
Completing Train Step...
At time: 308.03588461875916 and batch: 50, loss is 4.990222015380859 and perplexity is 146.9690492632964
At time: 308.3973505496979 and batch: 100, loss is 4.982538757324218 and perplexity is 145.84417501470244
At time: 308.7593603134155 and batch: 150, loss is 4.915318145751953 and perplexity is 136.36268611149575
At time: 309.1210341453552 and batch: 200, loss is 4.9052856826782225 and perplexity is 135.001472080398
At time: 309.48326539993286 and batch: 250, loss is 4.933468904495239 and perplexity is 138.86037119689786
At time: 309.84547185897827 and batch: 300, loss is 4.966404047012329 and perplexity is 143.5099035368423
At time: 310.2080738544464 and batch: 350, loss is 4.996495304107666 and perplexity is 147.8939265211222
At time: 310.570992231369 and batch: 400, loss is 4.901692876815796 and perplexity is 134.51730827416102
At time: 310.9335114955902 and batch: 450, loss is 4.936422681808471 and perplexity is 139.2711401724303
At time: 311.29574513435364 and batch: 500, loss is 4.931259479522705 and perplexity is 138.55390830313343
At time: 311.65827322006226 and batch: 550, loss is 4.967794570922852 and perplexity is 143.70959629570865
At time: 312.02084589004517 and batch: 600, loss is 4.858580989837646 and perplexity is 128.8412452928878
At time: 312.39766359329224 and batch: 650, loss is 5.000056591033935 and perplexity is 148.42155819435425
At time: 312.76572608947754 and batch: 700, loss is 5.024163360595703 and perplexity is 152.04299772235873
At time: 313.14093947410583 and batch: 750, loss is 4.947545213699341 and perplexity is 140.82883456466195
At time: 313.5022699832916 and batch: 800, loss is 4.905405187606812 and perplexity is 135.01760638572372
At time: 313.8649277687073 and batch: 850, loss is 4.852306880950928 and perplexity is 128.03541187754618
At time: 314.22704005241394 and batch: 900, loss is 4.81476902961731 and perplexity is 123.31832613959308
At time: 314.58974289894104 and batch: 950, loss is 4.900170316696167 and perplexity is 134.31265342437501
At time: 314.9707901477814 and batch: 1000, loss is 4.954491987228393 and perplexity is 141.81054650206923
At time: 315.3567705154419 and batch: 1050, loss is 4.850628871917724 and perplexity is 127.82074745463557
At time: 315.7438247203827 and batch: 1100, loss is 4.966764478683472 and perplexity is 143.5616383740765
At time: 316.1165511608124 and batch: 1150, loss is 4.9273014163970945 and perplexity is 138.00658706830802
At time: 316.4788599014282 and batch: 1200, loss is 4.878471479415894 and perplexity is 131.42961739757234
At time: 316.8402714729309 and batch: 1250, loss is 4.891118421554565 and perplexity is 133.10235537887124
At time: 317.20214676856995 and batch: 1300, loss is 4.95978196144104 and perplexity is 142.56270834048127
At time: 317.564820766449 and batch: 1350, loss is 4.8872593402862545 and perplexity is 132.58969241272175
At time: 317.92820739746094 and batch: 1400, loss is 4.790298414230347 and perplexity is 120.3372736605694
At time: 318.2898380756378 and batch: 1450, loss is 4.8769151306152345 and perplexity is 131.2252261634473
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.132252750233707 and perplexity of 169.39830059039286
Finished 28 epochs...
Completing Train Step...
At time: 319.48825573921204 and batch: 50, loss is 4.971850738525391 and perplexity is 144.29369029513919
At time: 319.84796357154846 and batch: 100, loss is 4.964995260238648 and perplexity is 143.3078710266256
At time: 320.210768699646 and batch: 150, loss is 4.8975355052948 and perplexity is 133.95923071933282
At time: 320.5716826915741 and batch: 200, loss is 4.890231704711914 and perplexity is 132.98438359007605
At time: 320.9338126182556 and batch: 250, loss is 4.918053550720215 and perplexity is 136.736203908888
At time: 321.2953152656555 and batch: 300, loss is 4.948636150360107 and perplexity is 140.9825537368761
At time: 321.6564223766327 and batch: 350, loss is 4.979252548217773 and perplexity is 145.36568719476864
At time: 322.01766419410706 and batch: 400, loss is 4.88297441482544 and perplexity is 132.0227709394058
At time: 322.3789322376251 and batch: 450, loss is 4.917025632858277 and perplexity is 136.59572253654196
At time: 322.7529444694519 and batch: 500, loss is 4.910484867095947 and perplexity is 135.7051974441514
At time: 323.11357283592224 and batch: 550, loss is 4.949361524581909 and perplexity is 141.08485594628775
At time: 323.4737751483917 and batch: 600, loss is 4.843674755096435 and perplexity is 126.93495058185755
At time: 323.83324337005615 and batch: 650, loss is 4.980138797760009 and perplexity is 145.49457457325585
At time: 324.19441175460815 and batch: 700, loss is 5.005056352615356 and perplexity is 149.1654887869601
At time: 324.55543279647827 and batch: 750, loss is 4.927981805801392 and perplexity is 138.1005172387953
At time: 324.9161026477814 and batch: 800, loss is 4.885555534362793 and perplexity is 132.36397765107628
At time: 325.27704071998596 and batch: 850, loss is 4.830930089950561 and perplexity is 125.32747228571965
At time: 325.6381719112396 and batch: 900, loss is 4.792189159393311 and perplexity is 120.56501601219557
At time: 326.01258158683777 and batch: 950, loss is 4.87929741859436 and perplexity is 131.53821510917064
At time: 326.3849675655365 and batch: 1000, loss is 4.933642978668213 and perplexity is 138.8845453051557
At time: 326.7483925819397 and batch: 1050, loss is 4.833568086624146 and perplexity is 125.65852220302638
At time: 327.1093804836273 and batch: 1100, loss is 4.946540145874024 and perplexity is 140.6873631402616
At time: 327.4696056842804 and batch: 1150, loss is 4.90761471748352 and perplexity is 135.31626164326838
At time: 327.8300426006317 and batch: 1200, loss is 4.858197250366211 and perplexity is 128.79181330662874
At time: 328.1905701160431 and batch: 1250, loss is 4.870264930725098 and perplexity is 130.3554474853726
At time: 328.55159425735474 and batch: 1300, loss is 4.941343946456909 and perplexity is 139.95821957420523
At time: 328.91280722618103 and batch: 1350, loss is 4.868890943527222 and perplexity is 130.176463758187
At time: 329.27443861961365 and batch: 1400, loss is 4.771138172149659 and perplexity is 118.05353076517093
At time: 329.63541865348816 and batch: 1450, loss is 4.859556398391724 and perplexity is 128.96697945678508
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.1151185647035255 and perplexity of 166.5205232693987
Finished 29 epochs...
Completing Train Step...
At time: 330.8326025009155 and batch: 50, loss is 4.953160839080811 and perplexity is 141.62190124103614
At time: 331.20713210105896 and batch: 100, loss is 4.9480570030212405 and perplexity is 140.90092770508383
At time: 331.56701707839966 and batch: 150, loss is 4.879188232421875 and perplexity is 131.5238537389731
At time: 331.9408121109009 and batch: 200, loss is 4.873768634796143 and perplexity is 130.8129754506585
At time: 332.30118703842163 and batch: 250, loss is 4.905611848831176 and perplexity is 135.04551217299294
At time: 332.6748802661896 and batch: 300, loss is 4.932846488952637 and perplexity is 138.77396923536466
At time: 333.03748655319214 and batch: 350, loss is 4.963754167556763 and perplexity is 143.13012300034092
At time: 333.3971438407898 and batch: 400, loss is 4.866445808410645 and perplexity is 129.85855354040913
At time: 333.75895285606384 and batch: 450, loss is 4.900483255386352 and perplexity is 134.35469162756
At time: 334.1201193332672 and batch: 500, loss is 4.893276128768921 and perplexity is 133.38986135663606
At time: 334.4808530807495 and batch: 550, loss is 4.933441286087036 and perplexity is 138.85653614744214
At time: 334.8421964645386 and batch: 600, loss is 4.827691888809204 and perplexity is 124.92229310182567
At time: 335.20300221443176 and batch: 650, loss is 4.964116344451904 and perplexity is 143.18197081236337
At time: 335.56359100341797 and batch: 700, loss is 4.988504705429077 and perplexity is 146.71687444552975
At time: 335.9237742424011 and batch: 750, loss is 4.913672466278076 and perplexity is 136.13846138957544
At time: 336.2840394973755 and batch: 800, loss is 4.8723636245727535 and perplexity is 130.62931093827078
At time: 336.6444163322449 and batch: 850, loss is 4.814988098144531 and perplexity is 123.34534426298212
At time: 337.00551295280457 and batch: 900, loss is 4.7764112091064455 and perplexity is 118.67767551876037
At time: 337.3660011291504 and batch: 950, loss is 4.864072046279907 and perplexity is 129.550665794371
At time: 337.72617650032043 and batch: 1000, loss is 4.919224395751953 and perplexity is 136.89639457481596
At time: 338.0865480899811 and batch: 1050, loss is 4.822301368713379 and perplexity is 124.25070869129877
At time: 338.44678115844727 and batch: 1100, loss is 4.9301448154449465 and perplexity is 138.39955328169557
At time: 338.80745935440063 and batch: 1150, loss is 4.8923562717437745 and perplexity is 133.26721817132938
At time: 339.167448759079 and batch: 1200, loss is 4.8437265777587895 and perplexity is 126.94152885939296
At time: 339.52848267555237 and batch: 1250, loss is 4.855948257446289 and perplexity is 128.5024868988299
At time: 339.88975191116333 and batch: 1300, loss is 4.926616077423096 and perplexity is 137.91203817824191
At time: 340.2505478858948 and batch: 1350, loss is 4.854593057632446 and perplexity is 128.32845830090258
At time: 340.6115605831146 and batch: 1400, loss is 4.756695890426636 and perplexity is 116.36082113210283
At time: 340.9724268913269 and batch: 1450, loss is 4.84546667098999 and perplexity is 127.1626112507207
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.1089540139222755 and perplexity of 165.4971565863299
Finished 30 epochs...
Completing Train Step...
At time: 342.1606459617615 and batch: 50, loss is 4.938540573120117 and perplexity is 139.56641387860302
At time: 342.53568601608276 and batch: 100, loss is 4.936590051651001 and perplexity is 139.2944519120165
At time: 342.8974390029907 and batch: 150, loss is 4.863126182556153 and perplexity is 129.4281864527224
At time: 343.2687602043152 and batch: 200, loss is 4.86256775856018 and perplexity is 129.35593082416807
At time: 343.6371614933014 and batch: 250, loss is 4.893132982254028 and perplexity is 133.3707684294364
At time: 344.01525831222534 and batch: 300, loss is 4.9203287124633786 and perplexity is 137.0476550554451
At time: 344.3902530670166 and batch: 350, loss is 4.951158990859986 and perplexity is 141.33867926828992
At time: 344.7519006729126 and batch: 400, loss is 4.851844463348389 and perplexity is 127.97621973614449
At time: 345.11322689056396 and batch: 450, loss is 4.887717895507812 and perplexity is 132.6505060506423
At time: 345.4748237133026 and batch: 500, loss is 4.879927787780762 and perplexity is 131.62115888666392
At time: 345.8377892971039 and batch: 550, loss is 4.922535915374755 and perplexity is 137.3504811150201
At time: 346.2002418041229 and batch: 600, loss is 4.816702871322632 and perplexity is 123.55703499989464
At time: 346.5621213912964 and batch: 650, loss is 4.952666206359863 and perplexity is 141.55186773653887
At time: 346.9242422580719 and batch: 700, loss is 4.9766066360473635 and perplexity is 144.98157074714698
At time: 347.2868449687958 and batch: 750, loss is 4.903025064468384 and perplexity is 134.69662998987047
At time: 347.6486430168152 and batch: 800, loss is 4.857847108840942 and perplexity is 128.74672583863347
At time: 348.0101521015167 and batch: 850, loss is 4.804178695678711 and perplexity is 122.01923493150822
At time: 348.3718252182007 and batch: 900, loss is 4.765021171569824 and perplexity is 117.33360139804705
At time: 348.73447823524475 and batch: 950, loss is 4.852644786834717 and perplexity is 128.07868310694278
At time: 349.0970072746277 and batch: 1000, loss is 4.908549947738647 and perplexity is 135.44287270118545
At time: 349.45947265625 and batch: 1050, loss is 4.81135329246521 and perplexity is 122.89782172658086
At time: 349.8222346305847 and batch: 1100, loss is 4.918361825942993 and perplexity is 136.77836279054534
At time: 350.1979331970215 and batch: 1150, loss is 4.881728343963623 and perplexity is 131.8583636642722
At time: 350.5603919029236 and batch: 1200, loss is 4.834207239151001 and perplexity is 125.73886283723805
At time: 350.92275881767273 and batch: 1250, loss is 4.846705894470215 and perplexity is 127.32029182494551
At time: 351.28521633148193 and batch: 1300, loss is 4.915043878555298 and perplexity is 136.32529142814948
At time: 351.64776253700256 and batch: 1350, loss is 4.843928508758545 and perplexity is 126.96716487749227
At time: 352.0097930431366 and batch: 1400, loss is 4.744952697753906 and perplexity is 115.00236550425382
At time: 352.3712351322174 and batch: 1450, loss is 4.833263778686524 and perplexity is 125.62028913489826
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.100479517227564 and perplexity of 164.10057749049835
Finished 31 epochs...
Completing Train Step...
At time: 353.57528614997864 and batch: 50, loss is 4.927919893264771 and perplexity is 138.09196735013975
At time: 353.9358253479004 and batch: 100, loss is 4.9273591899871825 and perplexity is 138.01456043462153
At time: 354.2969779968262 and batch: 150, loss is 4.851025094985962 and perplexity is 127.8714030181652
At time: 354.6583790779114 and batch: 200, loss is 4.853909540176391 and perplexity is 128.24077352999495
At time: 355.01984763145447 and batch: 250, loss is 4.884394989013672 and perplexity is 132.21045235618715
At time: 355.3804180622101 and batch: 300, loss is 4.911314353942871 and perplexity is 135.81780981927562
At time: 355.74035358428955 and batch: 350, loss is 4.9421317005157475 and perplexity is 140.0685156671363
At time: 356.10112953186035 and batch: 400, loss is 4.839505615234375 and perplexity is 126.4068426623396
At time: 356.4628412723541 and batch: 450, loss is 4.878692779541016 and perplexity is 131.45870600688488
At time: 356.82463240623474 and batch: 500, loss is 4.8697210311889645 and perplexity is 130.28456649576893
At time: 357.18601417541504 and batch: 550, loss is 4.912939157485962 and perplexity is 136.03866645361757
At time: 357.5476667881012 and batch: 600, loss is 4.803899574279785 and perplexity is 121.98518150469936
At time: 357.9094195365906 and batch: 650, loss is 4.943253793716431 and perplexity is 140.22577380884172
At time: 358.2701954841614 and batch: 700, loss is 4.967997007369995 and perplexity is 143.73869130064847
At time: 358.6312425136566 and batch: 750, loss is 4.894612379074097 and perplexity is 133.5682227407686
At time: 358.99241614341736 and batch: 800, loss is 4.849135847091675 and perplexity is 127.63005029861962
At time: 359.3671221733093 and batch: 850, loss is 4.794928026199341 and perplexity is 120.89568014832969
At time: 359.74296736717224 and batch: 900, loss is 4.754151515960693 and perplexity is 116.06513196148632
At time: 360.1158220767975 and batch: 950, loss is 4.842608327865601 and perplexity is 126.79965584782889
At time: 360.4767987728119 and batch: 1000, loss is 4.899877967834473 and perplexity is 134.2733930121833
At time: 360.8379545211792 and batch: 1050, loss is 4.802498064041138 and perplexity is 121.81433777144267
At time: 361.1991295814514 and batch: 1100, loss is 4.909201545715332 and perplexity is 135.5311557624023
At time: 361.5604553222656 and batch: 1150, loss is 4.873675699234009 and perplexity is 130.80081883815015
At time: 361.92135787010193 and batch: 1200, loss is 4.82627345085144 and perplexity is 124.74522418984019
At time: 362.2810711860657 and batch: 1250, loss is 4.8359180927276615 and perplexity is 125.9541677455177
At time: 362.6406650543213 and batch: 1300, loss is 4.9067800426483155 and perplexity is 135.20336368797638
At time: 363.00096893310547 and batch: 1350, loss is 4.8385331916809085 and perplexity is 126.28398141748104
At time: 363.36141896247864 and batch: 1400, loss is 4.736375503540039 and perplexity is 114.0201860735633
At time: 363.72112107276917 and batch: 1450, loss is 4.824409685134888 and perplexity is 124.51294484207158
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.096203926282051 and perplexity of 163.40044834670977
Finished 32 epochs...
Completing Train Step...
At time: 364.9184584617615 and batch: 50, loss is 4.919349870681763 and perplexity is 136.9135727180071
At time: 365.2803466320038 and batch: 100, loss is 4.919650259017945 and perplexity is 136.9547061360068
At time: 365.64142990112305 and batch: 150, loss is 4.840694332122803 and perplexity is 126.55719395588159
At time: 366.00157713890076 and batch: 200, loss is 4.846140279769897 and perplexity is 127.24829795855446
At time: 366.36266016960144 and batch: 250, loss is 4.877756052017212 and perplexity is 131.3356226754967
At time: 366.7231454849243 and batch: 300, loss is 4.904204702377319 and perplexity is 134.85561699592554
At time: 367.0835690498352 and batch: 350, loss is 4.933124761581421 and perplexity is 138.8125916061157
At time: 367.44313979148865 and batch: 400, loss is 4.830814733505249 and perplexity is 125.3130157878579
At time: 367.8034210205078 and batch: 450, loss is 4.869603252410888 and perplexity is 130.26922264233278
At time: 368.16320848464966 and batch: 500, loss is 4.8622050380706785 and perplexity is 129.30901928602194
At time: 368.5236692428589 and batch: 550, loss is 4.903288869857788 and perplexity is 134.73216837419898
At time: 368.8969328403473 and batch: 600, loss is 4.794707822799682 and perplexity is 120.86906143942966
At time: 369.2566361427307 and batch: 650, loss is 4.934553699493408 and perplexity is 139.0110879666351
At time: 369.6169624328613 and batch: 700, loss is 4.960384140014648 and perplexity is 142.64858240200442
At time: 369.9783251285553 and batch: 750, loss is 4.886582679748535 and perplexity is 132.50000454769935
At time: 370.3390884399414 and batch: 800, loss is 4.841606101989746 and perplexity is 126.67263761280168
At time: 370.69964051246643 and batch: 850, loss is 4.7874382209777835 and perplexity is 119.99357755536045
At time: 371.0596435070038 and batch: 900, loss is 4.742755937576294 and perplexity is 114.75001017094006
At time: 371.4205062389374 and batch: 950, loss is 4.835596895217895 and perplexity is 125.9137180770073
At time: 371.7809410095215 and batch: 1000, loss is 4.893154067993164 and perplexity is 133.37358068031696
At time: 372.14160227775574 and batch: 1050, loss is 4.7958063220977785 and perplexity is 121.00190897168393
At time: 372.5021495819092 and batch: 1100, loss is 4.9026945781707765 and perplexity is 134.65212195437795
At time: 372.86165857315063 and batch: 1150, loss is 4.86860746383667 and perplexity is 130.13956660456762
At time: 373.22201657295227 and batch: 1200, loss is 4.819115295410156 and perplexity is 123.85546679460225
At time: 373.5826344490051 and batch: 1250, loss is 4.826890096664429 and perplexity is 124.82217153221717
At time: 373.94332337379456 and batch: 1300, loss is 4.89788332939148 and perplexity is 134.0058330719904
At time: 374.30355072021484 and batch: 1350, loss is 4.831724271774292 and perplexity is 125.42704462025868
At time: 374.66473031044006 and batch: 1400, loss is 4.72819001197815 and perplexity is 113.0906842073036
At time: 375.0408136844635 and batch: 1450, loss is 4.817295484542846 and perplexity is 123.63027823259652
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0969911232972755 and perplexity of 163.5291273331467
Annealing...
Finished 33 epochs...
Completing Train Step...
At time: 376.24002265930176 and batch: 50, loss is 4.90660590171814 and perplexity is 135.1798212983672
At time: 376.61337900161743 and batch: 100, loss is 4.89719373703003 and perplexity is 133.91345552819925
At time: 376.9733028411865 and batch: 150, loss is 4.814916944503784 and perplexity is 123.33656810490007
At time: 377.33397936820984 and batch: 200, loss is 4.817986326217651 and perplexity is 123.71571668989277
At time: 377.6944389343262 and batch: 250, loss is 4.8520556640625 and perplexity is 128.00325125958008
At time: 378.06830048561096 and batch: 300, loss is 4.872168884277344 and perplexity is 130.60387462448756
At time: 378.42875838279724 and batch: 350, loss is 4.901279067993164 and perplexity is 134.46165534083204
At time: 378.7894239425659 and batch: 400, loss is 4.79742880821228 and perplexity is 121.19839224140424
At time: 379.15072441101074 and batch: 450, loss is 4.840003175735474 and perplexity is 126.46975336395913
At time: 379.5101230144501 and batch: 500, loss is 4.817719421386719 and perplexity is 123.6827007736957
At time: 379.8699760437012 and batch: 550, loss is 4.864927539825439 and perplexity is 129.66154297337067
At time: 380.2303719520569 and batch: 600, loss is 4.757340335845948 and perplexity is 116.43583349836054
At time: 380.5909194946289 and batch: 650, loss is 4.891949920654297 and perplexity is 133.21307589316572
At time: 380.9519293308258 and batch: 700, loss is 4.917977142333984 and perplexity is 136.72575651534737
At time: 381.3126537799835 and batch: 750, loss is 4.840897464752198 and perplexity is 126.58290446269166
At time: 381.6734092235565 and batch: 800, loss is 4.796091613769531 and perplexity is 121.03643473330165
At time: 382.0339434146881 and batch: 850, loss is 4.737164258956909 and perplexity is 114.11015559026879
At time: 382.39442682266235 and batch: 900, loss is 4.689802227020263 and perplexity is 108.8316537184012
At time: 382.75709223747253 and batch: 950, loss is 4.7809906101226805 and perplexity is 119.22239447797556
At time: 383.1177911758423 and batch: 1000, loss is 4.842285985946655 and perplexity is 126.75878959024908
At time: 383.47889399528503 and batch: 1050, loss is 4.740597677230835 and perplexity is 114.50261683998674
At time: 383.8395645618439 and batch: 1100, loss is 4.846842174530029 and perplexity is 127.3376442242971
At time: 384.20620822906494 and batch: 1150, loss is 4.811215114593506 and perplexity is 122.88084114033529
At time: 384.5787637233734 and batch: 1200, loss is 4.763311672210693 and perplexity is 117.13319103115586
At time: 384.9409568309784 and batch: 1250, loss is 4.765853319168091 and perplexity is 117.43128090889495
At time: 385.30182790756226 and batch: 1300, loss is 4.837879686355591 and perplexity is 126.20148112324935
At time: 385.66238236427307 and batch: 1350, loss is 4.764960403442383 and perplexity is 117.3264714714425
At time: 386.02306604385376 and batch: 1400, loss is 4.658518886566162 and perplexity is 105.47973894587493
At time: 386.3830394744873 and batch: 1450, loss is 4.747433938980103 and perplexity is 115.28806841699702
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.051964914696848 and perplexity of 156.3293367100406
Finished 34 epochs...
Completing Train Step...
At time: 387.58110094070435 and batch: 50, loss is 4.87644434928894 and perplexity is 131.16346231720428
At time: 387.95596504211426 and batch: 100, loss is 4.878435897827148 and perplexity is 131.42494100617432
At time: 388.3184280395508 and batch: 150, loss is 4.792934226989746 and perplexity is 120.65487857157343
At time: 388.68125581741333 and batch: 200, loss is 4.802233018875122 and perplexity is 121.78205574835103
At time: 389.0440137386322 and batch: 250, loss is 4.835933847427368 and perplexity is 125.95615213123898
At time: 389.4062523841858 and batch: 300, loss is 4.858252630233765 and perplexity is 128.79894597769308
At time: 389.76867747306824 and batch: 350, loss is 4.891309928894043 and perplexity is 133.12784789775245
At time: 390.1301996707916 and batch: 400, loss is 4.787394161224365 and perplexity is 119.98829078438936
At time: 390.4921143054962 and batch: 450, loss is 4.827919874191284 and perplexity is 124.95077680535951
At time: 390.8542511463165 and batch: 500, loss is 4.806585540771485 and perplexity is 122.3132700348568
At time: 391.215811252594 and batch: 550, loss is 4.854458589553833 and perplexity is 128.3112033798275
At time: 391.57657766342163 and batch: 600, loss is 4.749270992279053 and perplexity is 115.50005339764947
At time: 391.9377918243408 and batch: 650, loss is 4.882859373092652 and perplexity is 132.00758368467024
At time: 392.2992331981659 and batch: 700, loss is 4.910786991119385 and perplexity is 135.74620343854068
At time: 392.66023087501526 and batch: 750, loss is 4.832908630371094 and perplexity is 125.5756832221544
At time: 393.0213692188263 and batch: 800, loss is 4.788250322341919 and perplexity is 120.09106408249373
At time: 393.38349199295044 and batch: 850, loss is 4.732004528045654 and perplexity is 113.52289425130238
At time: 393.74602222442627 and batch: 900, loss is 4.684466361999512 and perplexity is 108.25248925002596
At time: 394.10833048820496 and batch: 950, loss is 4.777479524612427 and perplexity is 118.80452846715201
At time: 394.4705283641815 and batch: 1000, loss is 4.838681230545044 and perplexity is 126.30267773850548
At time: 394.83241510391235 and batch: 1050, loss is 4.736516590118408 and perplexity is 114.03627392634485
At time: 395.19335436820984 and batch: 1100, loss is 4.844585828781128 and perplexity is 127.05065037251461
At time: 395.55462408065796 and batch: 1150, loss is 4.8096060371398925 and perplexity is 122.68327534133867
At time: 395.93685722351074 and batch: 1200, loss is 4.761900968551636 and perplexity is 116.9680673076758
At time: 396.3374843597412 and batch: 1250, loss is 4.7650353050231935 and perplexity is 117.3352597387501
At time: 396.70607590675354 and batch: 1300, loss is 4.837676076889038 and perplexity is 126.17578792277787
At time: 397.07493805885315 and batch: 1350, loss is 4.765323753356934 and perplexity is 117.3691097806701
At time: 397.44354796409607 and batch: 1400, loss is 4.657539033889771 and perplexity is 105.37643496097212
At time: 397.8270752429962 and batch: 1450, loss is 4.747468299865723 and perplexity is 115.29202988518868
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.048628847823184 and perplexity of 155.80868054323565
Finished 35 epochs...
Completing Train Step...
At time: 399.0393466949463 and batch: 50, loss is 4.868968944549561 and perplexity is 130.18661805146206
At time: 399.3990421295166 and batch: 100, loss is 4.872240343093872 and perplexity is 130.6132077562655
At time: 399.7599575519562 and batch: 150, loss is 4.785974740982056 and perplexity is 119.81809779187394
At time: 400.127788066864 and batch: 200, loss is 4.79638014793396 and perplexity is 121.07136291860799
At time: 400.50378227233887 and batch: 250, loss is 4.829670839309692 and perplexity is 125.16975291087874
At time: 400.8711533546448 and batch: 300, loss is 4.852731704711914 and perplexity is 128.08981591800574
At time: 401.2310035228729 and batch: 350, loss is 4.887279281616211 and perplexity is 132.5923364538897
At time: 401.5921561717987 and batch: 400, loss is 4.782668504714966 and perplexity is 119.4226050080608
At time: 401.95242166519165 and batch: 450, loss is 4.821727409362793 and perplexity is 124.17941429722764
At time: 402.312566280365 and batch: 500, loss is 4.80095703125 and perplexity is 121.62676244948804
At time: 402.6724178791046 and batch: 550, loss is 4.849892444610596 and perplexity is 127.7266514174906
At time: 403.0317962169647 and batch: 600, loss is 4.7452350616455075 and perplexity is 115.03484260468545
At time: 403.39385867118835 and batch: 650, loss is 4.878396959304809 and perplexity is 131.41982361280557
At time: 403.76593375205994 and batch: 700, loss is 4.906623659133911 and perplexity is 135.18222176397077
At time: 404.12642121315 and batch: 750, loss is 4.829172410964966 and perplexity is 125.10738030355456
At time: 404.4869713783264 and batch: 800, loss is 4.784555397033691 and perplexity is 119.64815533179929
At time: 404.84729266166687 and batch: 850, loss is 4.728802375793457 and perplexity is 113.15995805839559
At time: 405.20793056488037 and batch: 900, loss is 4.681076860427856 and perplexity is 107.88618840691304
At time: 405.5821018218994 and batch: 950, loss is 4.775190019607544 and perplexity is 118.5328360438857
At time: 405.94323468208313 and batch: 1000, loss is 4.836169767379761 and perplexity is 125.98587120617685
At time: 406.30349254608154 and batch: 1050, loss is 4.733077154159546 and perplexity is 113.64472720112167
At time: 406.6634862422943 and batch: 1100, loss is 4.842642192840576 and perplexity is 126.80394998771112
At time: 407.0235345363617 and batch: 1150, loss is 4.807825994491577 and perplexity is 122.46508812788018
At time: 407.3840844631195 and batch: 1200, loss is 4.760651502609253 and perplexity is 116.82201095644828
At time: 407.7448365688324 and batch: 1250, loss is 4.764717035293579 and perplexity is 117.29792141950234
At time: 408.1059651374817 and batch: 1300, loss is 4.836694669723511 and perplexity is 126.05201884425877
At time: 408.4669325351715 and batch: 1350, loss is 4.764303941726684 and perplexity is 117.24947640960372
At time: 408.8278818130493 and batch: 1400, loss is 4.655960731506347 and perplexity is 105.21025026186759
At time: 409.1900851726532 and batch: 1450, loss is 4.745935430526734 and perplexity is 115.11543764853843
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.046337681957799 and perplexity of 155.45210565493545
Finished 36 epochs...
Completing Train Step...
At time: 410.39293384552 and batch: 50, loss is 4.86426326751709 and perplexity is 129.5754410016594
At time: 410.75392293930054 and batch: 100, loss is 4.867896203994751 and perplexity is 130.0470364673832
At time: 411.1151292324066 and batch: 150, loss is 4.781347599029541 and perplexity is 119.26496314807295
At time: 411.47633361816406 and batch: 200, loss is 4.792259092330933 and perplexity is 120.57344777276522
At time: 411.8373918533325 and batch: 250, loss is 4.82530481338501 and perplexity is 124.62444979467688
At time: 412.19824266433716 and batch: 300, loss is 4.8489263725280765 and perplexity is 127.60331784951312
At time: 412.55879378318787 and batch: 350, loss is 4.884537954330444 and perplexity is 132.2293552165833
At time: 412.9191482067108 and batch: 400, loss is 4.7793930149078365 and perplexity is 119.0320774163478
At time: 413.2797591686249 and batch: 450, loss is 4.81733362197876 and perplexity is 123.63499326431861
At time: 413.64034628868103 and batch: 500, loss is 4.79692572593689 and perplexity is 121.13743481304833
At time: 414.0006191730499 and batch: 550, loss is 4.846559162139893 and perplexity is 127.30161119238858
At time: 414.36155366897583 and batch: 600, loss is 4.742508172988892 and perplexity is 114.72158270382091
At time: 414.72197675704956 and batch: 650, loss is 4.874783229827881 and perplexity is 130.94576499805402
At time: 415.09491086006165 and batch: 700, loss is 4.903479900360107 and perplexity is 134.7579087865257
At time: 415.45491099357605 and batch: 750, loss is 4.826544971466064 and perplexity is 124.77909968852362
At time: 415.815233707428 and batch: 800, loss is 4.78187424659729 and perplexity is 119.32779029326208
At time: 416.1762607097626 and batch: 850, loss is 4.726586904525757 and perplexity is 112.90953292993188
At time: 416.53734493255615 and batch: 900, loss is 4.678681154251098 and perplexity is 107.62803415330073
At time: 416.8984019756317 and batch: 950, loss is 4.773466758728027 and perplexity is 118.32874894275696
At time: 417.26039600372314 and batch: 1000, loss is 4.834081439971924 and perplexity is 125.72304598640929
At time: 417.6221525669098 and batch: 1050, loss is 4.730180711746216 and perplexity is 113.3160380376134
At time: 417.98492431640625 and batch: 1100, loss is 4.841026849746704 and perplexity is 126.599283450665
At time: 418.3471086025238 and batch: 1150, loss is 4.806303644180298 and perplexity is 122.27879520037457
At time: 418.71015524864197 and batch: 1200, loss is 4.759508543014526 and perplexity is 116.68856439469177
At time: 419.0716087818146 and batch: 1250, loss is 4.764103689193726 and perplexity is 117.22599925572284
At time: 419.4338901042938 and batch: 1300, loss is 4.835796365737915 and perplexity is 125.93883665695455
At time: 419.82005500793457 and batch: 1350, loss is 4.763218584060669 and perplexity is 117.12228782658381
At time: 420.1901912689209 and batch: 1400, loss is 4.653897800445557 and perplexity is 104.99343248564371
At time: 420.55181217193604 and batch: 1450, loss is 4.743990087509156 and perplexity is 114.89171631361529
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.044467502170139 and perplexity of 155.16165395209876
Finished 37 epochs...
Completing Train Step...
At time: 421.75446939468384 and batch: 50, loss is 4.860765962600708 and perplexity is 129.12306767961041
At time: 422.1314079761505 and batch: 100, loss is 4.864443311691284 and perplexity is 129.59877240520905
At time: 422.4947407245636 and batch: 150, loss is 4.77781497001648 and perplexity is 118.8443875851122
At time: 422.85776257514954 and batch: 200, loss is 4.7888595008850094 and perplexity is 120.16424326928181
At time: 423.22072649002075 and batch: 250, loss is 4.8220234203338626 and perplexity is 124.21617820723256
At time: 423.59885597229004 and batch: 300, loss is 4.845684509277344 and perplexity is 127.19031515354688
At time: 423.97373032569885 and batch: 350, loss is 4.8822986602783205 and perplexity is 131.93358608854828
At time: 424.3544533252716 and batch: 400, loss is 4.777208576202392 and perplexity is 118.77234292956595
At time: 424.7173433303833 and batch: 450, loss is 4.8137634754180905 and perplexity is 123.19438520401032
At time: 425.08084750175476 and batch: 500, loss is 4.79379225730896 and perplexity is 120.75844854228227
At time: 425.4441771507263 and batch: 550, loss is 4.843776502609253 and perplexity is 126.9478665544418
At time: 425.8078582286835 and batch: 600, loss is 4.740291814804078 and perplexity is 114.46760014714829
At time: 426.1710858345032 and batch: 650, loss is 4.87165714263916 and perplexity is 130.53705628205623
At time: 426.53424310684204 and batch: 700, loss is 4.900777435302734 and perplexity is 134.39422189372857
At time: 426.8958463668823 and batch: 750, loss is 4.8240492630004885 and perplexity is 124.46807570713169
At time: 427.2587628364563 and batch: 800, loss is 4.779397706985474 and perplexity is 119.03263592540668
At time: 427.63712882995605 and batch: 850, loss is 4.72465612411499 and perplexity is 112.6917397386351
At time: 428.0124886035919 and batch: 900, loss is 4.676498556137085 and perplexity is 107.3933815782286
At time: 428.3759677410126 and batch: 950, loss is 4.771958341598511 and perplexity is 118.15039438129315
At time: 428.74534821510315 and batch: 1000, loss is 4.832006940841675 and perplexity is 125.46250397738162
At time: 429.1214487552643 and batch: 1050, loss is 4.727898473739624 and perplexity is 113.05771875401473
At time: 429.4896082878113 and batch: 1100, loss is 4.8395181655883786 and perplexity is 126.40842912291873
At time: 429.85149455070496 and batch: 1150, loss is 4.805093870162964 and perplexity is 122.13095493575668
At time: 430.2133631706238 and batch: 1200, loss is 4.758383665084839 and perplexity is 116.55737780224166
At time: 430.57591485977173 and batch: 1250, loss is 4.763363485336304 and perplexity is 117.1392602251265
At time: 430.9376223087311 and batch: 1300, loss is 4.834621248245239 and perplexity is 125.7909306474815
At time: 431.2999653816223 and batch: 1350, loss is 4.761911487579345 and perplexity is 116.9692977044882
At time: 431.66246342658997 and batch: 1400, loss is 4.651847877502441 and perplexity is 104.77842448971879
At time: 432.02496790885925 and batch: 1450, loss is 4.741991901397705 and perplexity is 114.66237049588061
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.043050130208333 and perplexity of 154.94188795611146
Finished 38 epochs...
Completing Train Step...
At time: 433.21150279045105 and batch: 50, loss is 4.857797117233276 and perplexity is 128.74028974370378
At time: 433.58561086654663 and batch: 100, loss is 4.861379871368408 and perplexity is 129.20236180015874
At time: 433.9464313983917 and batch: 150, loss is 4.774613676071167 and perplexity is 118.46454009283876
At time: 434.3077230453491 and batch: 200, loss is 4.785900192260742 and perplexity is 119.80916583883034
At time: 434.6688230037689 and batch: 250, loss is 4.818978538513184 and perplexity is 123.83852986343786
At time: 435.0320794582367 and batch: 300, loss is 4.8428271484375 and perplexity is 126.82740525699825
At time: 435.3915328979492 and batch: 350, loss is 4.880331115722656 and perplexity is 131.67425608485948
At time: 435.7508590221405 and batch: 400, loss is 4.775203695297241 and perplexity is 118.53445707325467
At time: 436.1108615398407 and batch: 450, loss is 4.810562744140625 and perplexity is 122.80070345292198
At time: 436.47141766548157 and batch: 500, loss is 4.791029233932495 and perplexity is 120.42525065480797
At time: 436.832510471344 and batch: 550, loss is 4.841158065795899 and perplexity is 126.61589639838905
At time: 437.20966696739197 and batch: 600, loss is 4.738306636810303 and perplexity is 114.24058699164986
At time: 437.5761926174164 and batch: 650, loss is 4.868779439926147 and perplexity is 130.1619494229181
At time: 437.93764638900757 and batch: 700, loss is 4.898284273147583 and perplexity is 134.0595726465956
At time: 438.2989468574524 and batch: 750, loss is 4.821504964828491 and perplexity is 124.15179433731288
At time: 438.6602563858032 and batch: 800, loss is 4.776743364334107 and perplexity is 118.7171014764971
At time: 439.0202577114105 and batch: 850, loss is 4.722809572219848 and perplexity is 112.48384060040152
At time: 439.38066029548645 and batch: 900, loss is 4.674498023986817 and perplexity is 107.17875242349862
At time: 439.7411479949951 and batch: 950, loss is 4.770406103134155 and perplexity is 117.96713905933075
At time: 440.10176062583923 and batch: 1000, loss is 4.829717350006104 and perplexity is 125.1755747786448
At time: 440.4625551700592 and batch: 1050, loss is 4.725652465820312 and perplexity is 112.80407517172763
At time: 440.82304072380066 and batch: 1100, loss is 4.837765331268311 and perplexity is 126.18705016700295
At time: 441.1831691265106 and batch: 1150, loss is 4.802983875274658 and perplexity is 121.87353092232054
At time: 441.54387164115906 and batch: 1200, loss is 4.7563733386993405 and perplexity is 116.323294800674
At time: 441.90484595298767 and batch: 1250, loss is 4.761385641098022 and perplexity is 116.90780597988793
At time: 442.26704001426697 and batch: 1300, loss is 4.832077751159668 and perplexity is 125.47138833173274
At time: 442.6274628639221 and batch: 1350, loss is 4.758589677810669 and perplexity is 116.58139257894813
At time: 442.9882764816284 and batch: 1400, loss is 4.646035137176514 and perplexity is 104.17114141571025
At time: 443.3494441509247 and batch: 1450, loss is 4.736114549636841 and perplexity is 113.99043594283921
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.038043682391827 and perplexity of 154.16811801506444
Finished 39 epochs...
Completing Train Step...
At time: 444.56003427505493 and batch: 50, loss is 4.851762676239014 and perplexity is 127.96575335907676
At time: 444.92106890678406 and batch: 100, loss is 4.854645404815674 and perplexity is 128.3351761100503
At time: 445.2818009853363 and batch: 150, loss is 4.763224115371704 and perplexity is 117.12293566817863
At time: 445.6425247192383 and batch: 200, loss is 4.7779294300079345 and perplexity is 118.85799129122482
At time: 446.0036232471466 and batch: 250, loss is 4.812949151992798 and perplexity is 123.09410596568202
At time: 446.3646275997162 and batch: 300, loss is 4.836440601348877 and perplexity is 126.01999708074264
At time: 446.72572135925293 and batch: 350, loss is 4.871682977676391 and perplexity is 130.54042875532915
At time: 447.0868058204651 and batch: 400, loss is 4.764662790298462 and perplexity is 117.29155876690028
At time: 447.44761419296265 and batch: 450, loss is 4.799917936325073 and perplexity is 121.50044633647293
At time: 447.8084216117859 and batch: 500, loss is 4.781691255569458 and perplexity is 119.3059563760338
At time: 448.16927194595337 and batch: 550, loss is 4.830465831756592 and perplexity is 125.26930148396204
At time: 448.5304865837097 and batch: 600, loss is 4.730153007507324 and perplexity is 113.31289874651141
At time: 448.8914837837219 and batch: 650, loss is 4.858778114318848 and perplexity is 128.86664555994847
At time: 449.26514506340027 and batch: 700, loss is 4.891638650894165 and perplexity is 133.17161714374816
At time: 449.63962507247925 and batch: 750, loss is 4.814300165176392 and perplexity is 123.26052011420661
At time: 450.00272130966187 and batch: 800, loss is 4.766333675384521 and perplexity is 117.48770330502234
At time: 450.36243057250977 and batch: 850, loss is 4.713583698272705 and perplexity is 111.45085130748154
At time: 450.7227611541748 and batch: 900, loss is 4.66709186553955 and perplexity is 106.38790179831004
At time: 451.0828757286072 and batch: 950, loss is 4.761770915985108 and perplexity is 116.95285629945734
At time: 451.4939169883728 and batch: 1000, loss is 4.8237926959991455 and perplexity is 124.436145402491
At time: 451.86943197250366 and batch: 1050, loss is 4.716730394363403 and perplexity is 111.80210562104902
At time: 452.26179695129395 and batch: 1100, loss is 4.831619968414307 and perplexity is 125.41396284032041
At time: 452.6337568759918 and batch: 1150, loss is 4.794186534881592 and perplexity is 120.80607027772258
At time: 452.9981436729431 and batch: 1200, loss is 4.748180923461914 and perplexity is 115.37421898760627
At time: 453.3609359264374 and batch: 1250, loss is 4.753613491058349 and perplexity is 116.00270282591794
At time: 453.72168803215027 and batch: 1300, loss is 4.823338766098022 and perplexity is 124.37967293355307
At time: 454.081684589386 and batch: 1350, loss is 4.752410945892334 and perplexity is 115.86328817939531
At time: 454.4419128894806 and batch: 1400, loss is 4.63784044265747 and perplexity is 103.32097890272738
At time: 454.8019452095032 and batch: 1450, loss is 4.729975852966309 and perplexity is 113.29282662992864
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.034064398871528 and perplexity of 153.55585834900322
Finished 40 epochs...
Completing Train Step...
At time: 455.999299287796 and batch: 50, loss is 4.8465571975708 and perplexity is 127.30136109982348
At time: 456.3583824634552 and batch: 100, loss is 4.850373096466065 and perplexity is 127.78805822595324
At time: 456.7177791595459 and batch: 150, loss is 4.757717752456665 and perplexity is 116.47978660980104
At time: 457.07712054252625 and batch: 200, loss is 4.7734409523010255 and perplexity is 118.32569533993664
At time: 457.43676948547363 and batch: 250, loss is 4.809603061676025 and perplexity is 122.68291030222885
At time: 457.7966001033783 and batch: 300, loss is 4.832982759475708 and perplexity is 125.58499238014855
At time: 458.1570494174957 and batch: 350, loss is 4.867880210876465 and perplexity is 130.0449566263779
At time: 458.51994729042053 and batch: 400, loss is 4.760829105377197 and perplexity is 116.84276071150333
At time: 458.8794946670532 and batch: 450, loss is 4.796187858581543 and perplexity is 121.04808442281131
At time: 459.239040851593 and batch: 500, loss is 4.7782438945770265 and perplexity is 118.89537379566788
At time: 459.5980200767517 and batch: 550, loss is 4.827571611404419 and perplexity is 124.90726867617924
At time: 459.9577569961548 and batch: 600, loss is 4.727352523803711 and perplexity is 112.99601174570785
At time: 460.3176567554474 and batch: 650, loss is 4.85582670211792 and perplexity is 128.48686768615715
At time: 460.67745757102966 and batch: 700, loss is 4.888628368377685 and perplexity is 132.77133573530432
At time: 461.03675651550293 and batch: 750, loss is 4.811548919677734 and perplexity is 122.92186623667409
At time: 461.452675819397 and batch: 800, loss is 4.762956609725952 and perplexity is 117.09160881188261
At time: 461.81545519828796 and batch: 850, loss is 4.711199235916138 and perplexity is 111.18541753211808
At time: 462.1780650615692 and batch: 900, loss is 4.664805126190186 and perplexity is 106.14489834564246
At time: 462.5398280620575 and batch: 950, loss is 4.759283676147461 and perplexity is 116.66232795275778
At time: 462.90110087394714 and batch: 1000, loss is 4.821727476119995 and perplexity is 124.17942258709822
At time: 463.26265716552734 and batch: 1050, loss is 4.713975400924682 and perplexity is 111.49451545262623
At time: 463.62619376182556 and batch: 1100, loss is 4.829968061447143 and perplexity is 125.20696166174147
At time: 464.0049479007721 and batch: 1150, loss is 4.792040758132934 and perplexity is 120.5471253393941
At time: 464.38384318351746 and batch: 1200, loss is 4.746178760528564 and perplexity is 115.14345209643177
At time: 464.7536895275116 and batch: 1250, loss is 4.751840620040894 and perplexity is 115.7972271908492
At time: 465.1232190132141 and batch: 1300, loss is 4.821320419311523 and perplexity is 124.1288847942362
At time: 465.4946620464325 and batch: 1350, loss is 4.750177936553955 and perplexity is 115.60485302635746
At time: 465.8788709640503 and batch: 1400, loss is 4.635158061981201 and perplexity is 103.0442040791381
At time: 466.2482256889343 and batch: 1450, loss is 4.727276029586792 and perplexity is 112.98736853485643
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.03241697132078 and perplexity of 153.30309445964505
Finished 41 epochs...
Completing Train Step...
At time: 467.4580297470093 and batch: 50, loss is 4.8437832164764405 and perplexity is 126.94871886841874
At time: 467.8542094230652 and batch: 100, loss is 4.847588987350464 and perplexity is 127.43277712834238
At time: 468.22307562828064 and batch: 150, loss is 4.755118064880371 and perplexity is 116.17736882186622
At time: 468.5856113433838 and batch: 200, loss is 4.770443592071533 and perplexity is 117.9715616049174
At time: 468.94748544692993 and batch: 250, loss is 4.806734895706176 and perplexity is 122.33153948959745
At time: 469.31043314933777 and batch: 300, loss is 4.829767971038819 and perplexity is 125.181911455894
At time: 469.67266726493835 and batch: 350, loss is 4.86516845703125 and perplexity is 129.6927844331564
At time: 470.03567361831665 and batch: 400, loss is 4.758093557357788 and perplexity is 116.5235685107019
At time: 470.39777660369873 and batch: 450, loss is 4.79329044342041 and perplexity is 120.69786547762703
At time: 470.7732105255127 and batch: 500, loss is 4.775618858337403 and perplexity is 118.58367841555113
At time: 471.1354875564575 and batch: 550, loss is 4.82563250541687 and perplexity is 124.665294925796
At time: 471.49780225753784 and batch: 600, loss is 4.724665536880493 and perplexity is 112.69280048454767
At time: 471.8602373600006 and batch: 650, loss is 4.853220615386963 and perplexity is 128.1524557077563
At time: 472.2220072746277 and batch: 700, loss is 4.88579029083252 and perplexity is 132.3950545988032
At time: 472.5868754386902 and batch: 750, loss is 4.809197559356689 and perplexity is 122.63317218270136
At time: 472.9506571292877 and batch: 800, loss is 4.760442733764648 and perplexity is 116.79762470582976
At time: 473.3255388736725 and batch: 850, loss is 4.7091628932952885 and perplexity is 110.95923629698369
At time: 473.6929614543915 and batch: 900, loss is 4.66256462097168 and perplexity is 105.9073463645811
At time: 474.0579209327698 and batch: 950, loss is 4.756947441101074 and perplexity is 116.3900954569705
At time: 474.4211275577545 and batch: 1000, loss is 4.819519729614258 and perplexity is 123.9055683124398
At time: 474.7832295894623 and batch: 1050, loss is 4.711731986999512 and perplexity is 111.2446674650953
At time: 475.1461458206177 and batch: 1100, loss is 4.828400382995605 and perplexity is 125.01083118089383
At time: 475.5094747543335 and batch: 1150, loss is 4.790270395278931 and perplexity is 120.33390198358083
At time: 475.87303256988525 and batch: 1200, loss is 4.744275484085083 and perplexity is 114.92451069553319
At time: 476.25117087364197 and batch: 1250, loss is 4.750234985351563 and perplexity is 115.61144833234557
At time: 476.6136043071747 and batch: 1300, loss is 4.8195903110504155 and perplexity is 123.91431405403911
At time: 476.9766592979431 and batch: 1350, loss is 4.748175048828125 and perplexity is 115.37354120831196
At time: 477.3403878211975 and batch: 1400, loss is 4.632992925643921 and perplexity is 102.82134068042353
At time: 477.7034652233124 and batch: 1450, loss is 4.724589710235596 and perplexity is 112.68425569154844
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.031827486478365 and perplexity of 153.2127512397613
Finished 42 epochs...
Completing Train Step...
At time: 478.91530776023865 and batch: 50, loss is 4.841514625549316 and perplexity is 126.66105058079134
At time: 479.2922487258911 and batch: 100, loss is 4.845091543197632 and perplexity is 127.1149179671891
At time: 479.6543929576874 and batch: 150, loss is 4.753024864196777 and perplexity is 115.93444061147714
At time: 480.02944779396057 and batch: 200, loss is 4.767719440460205 and perplexity is 117.65062652166414
At time: 480.39173102378845 and batch: 250, loss is 4.80417293548584 and perplexity is 122.01853207920531
At time: 480.7539587020874 and batch: 300, loss is 4.827415866851807 and perplexity is 124.88781656432073
At time: 481.11601090431213 and batch: 350, loss is 4.86289496421814 and perplexity is 129.3982637420318
At time: 481.47714281082153 and batch: 400, loss is 4.755785150527954 and perplexity is 116.25489493258421
At time: 481.86215710639954 and batch: 450, loss is 4.790608634948731 and perplexity is 120.37461056709428
At time: 482.23344111442566 and batch: 500, loss is 4.7728551006317135 and perplexity is 118.25639433583585
At time: 482.60654282569885 and batch: 550, loss is 4.8232384872436525 and perplexity is 124.3672009077951
At time: 482.99087166786194 and batch: 600, loss is 4.722393674850464 and perplexity is 112.43706859384898
At time: 483.3828580379486 and batch: 650, loss is 4.850681209564209 and perplexity is 127.82743746679753
At time: 483.7626233100891 and batch: 700, loss is 4.8832730865478515 and perplexity is 132.0622082969184
At time: 484.1342475414276 and batch: 750, loss is 4.807067279815674 and perplexity is 122.37220730770797
At time: 484.50968050956726 and batch: 800, loss is 4.758636341094971 and perplexity is 116.58683277654215
At time: 484.8805592060089 and batch: 850, loss is 4.707452812194824 and perplexity is 110.76964915496653
At time: 485.2537748813629 and batch: 900, loss is 4.660685300827026 and perplexity is 105.70849946211078
At time: 485.63986253738403 and batch: 950, loss is 4.75482684135437 and perplexity is 116.14354016496584
At time: 486.0055477619171 and batch: 1000, loss is 4.817672910690308 and perplexity is 123.67694833892467
At time: 486.38442277908325 and batch: 1050, loss is 4.70995005607605 and perplexity is 111.04661366357203
At time: 486.75509548187256 and batch: 1100, loss is 4.826910314559936 and perplexity is 124.8246951993497
At time: 487.1460189819336 and batch: 1150, loss is 4.788490943908691 and perplexity is 120.119964059328
At time: 487.5154674053192 and batch: 1200, loss is 4.742636814117431 and perplexity is 114.73634156696585
At time: 487.889839887619 and batch: 1250, loss is 4.748641357421875 and perplexity is 115.42735342764384
At time: 488.26683592796326 and batch: 1300, loss is 4.817958793640137 and perplexity is 123.71231052422368
At time: 488.6312153339386 and batch: 1350, loss is 4.746444482803344 and perplexity is 115.17405234185223
At time: 489.00306129455566 and batch: 1400, loss is 4.6307363605499265 and perplexity is 102.58957922287972
At time: 489.3676884174347 and batch: 1450, loss is 4.722388610839844 and perplexity is 112.43649921278126
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.031544742421207 and perplexity of 153.1694373685259
Finished 43 epochs...
Completing Train Step...
At time: 490.68249320983887 and batch: 50, loss is 4.839325170516968 and perplexity is 126.38403527313538
At time: 491.04965376853943 and batch: 100, loss is 4.842790365219116 and perplexity is 126.8227402226516
At time: 491.4322421550751 and batch: 150, loss is 4.750926866531372 and perplexity is 115.69146539557522
At time: 491.82901787757874 and batch: 200, loss is 4.765245122909546 and perplexity is 117.3598813578808
At time: 492.22061467170715 and batch: 250, loss is 4.801918458938599 and perplexity is 121.74375401703605
At time: 492.60827684402466 and batch: 300, loss is 4.825505132675171 and perplexity is 124.64941697661703
At time: 492.99420642852783 and batch: 350, loss is 4.860862617492676 and perplexity is 129.1355486589316
At time: 493.3722336292267 and batch: 400, loss is 4.753462762832641 and perplexity is 115.98521926201006
At time: 493.7541997432709 and batch: 450, loss is 4.788048152923584 and perplexity is 120.06678779596497
At time: 494.1259651184082 and batch: 500, loss is 4.770614519119262 and perplexity is 117.99172785908856
At time: 494.506192445755 and batch: 550, loss is 4.82096342086792 and perplexity is 124.08457888459938
At time: 494.8839259147644 and batch: 600, loss is 4.7202013492584225 and perplexity is 112.19083993619097
At time: 495.25064277648926 and batch: 650, loss is 4.84821930885315 and perplexity is 127.51312606808531
At time: 495.6213524341583 and batch: 700, loss is 4.880658912658691 and perplexity is 131.71742557758594
At time: 495.99016213417053 and batch: 750, loss is 4.804987115859985 and perplexity is 122.11791762669716
At time: 496.35263562202454 and batch: 800, loss is 4.75645341873169 and perplexity is 116.33261034687426
At time: 496.7269184589386 and batch: 850, loss is 4.705833921432495 and perplexity is 110.59047026785845
At time: 497.109032869339 and batch: 900, loss is 4.658996667861938 and perplexity is 105.5301472333362
At time: 497.4882183074951 and batch: 950, loss is 4.752774038314819 and perplexity is 115.90536489978443
At time: 497.8520576953888 and batch: 1000, loss is 4.816007280349732 and perplexity is 123.47111972611899
At time: 498.2178235054016 and batch: 1050, loss is 4.708068771362305 and perplexity is 110.83789975347516
At time: 498.60093569755554 and batch: 1100, loss is 4.825531806945801 and perplexity is 124.65274195324477
At time: 498.965945482254 and batch: 1150, loss is 4.786804027557373 and perplexity is 119.91750254366909
At time: 499.3658013343811 and batch: 1200, loss is 4.741222114562988 and perplexity is 114.57413887676175
At time: 499.73908042907715 and batch: 1250, loss is 4.747134981155395 and perplexity is 115.25360729831556
At time: 500.1053626537323 and batch: 1300, loss is 4.816429576873779 and perplexity is 123.5232721619207
At time: 500.4724209308624 and batch: 1350, loss is 4.744894056320191 and perplexity is 114.99562179839224
At time: 500.8464193344116 and batch: 1400, loss is 4.628415908813476 and perplexity is 102.35180103872344
At time: 501.2253110408783 and batch: 1450, loss is 4.7203821849823 and perplexity is 112.21112988246148
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.030962560930822 and perplexity of 153.08029090942438
Finished 44 epochs...
Completing Train Step...
At time: 502.55435395240784 and batch: 50, loss is 4.837146005630493 and perplexity is 126.1089234870991
At time: 502.9261567592621 and batch: 100, loss is 4.8406907081604 and perplexity is 126.5567353181999
At time: 503.3114595413208 and batch: 150, loss is 4.748702669143677 and perplexity is 115.434430694383
At time: 503.685599565506 and batch: 200, loss is 4.762877950668335 and perplexity is 117.08239885850642
At time: 504.0691874027252 and batch: 250, loss is 4.7998996925354005 and perplexity is 121.49822972810456
At time: 504.45629024505615 and batch: 300, loss is 4.823569173812866 and perplexity is 124.40833427153666
At time: 504.8323862552643 and batch: 350, loss is 4.858830966949463 and perplexity is 128.8734566811561
At time: 505.2053122520447 and batch: 400, loss is 4.751135568618775 and perplexity is 115.71561296563449
At time: 505.5908567905426 and batch: 450, loss is 4.785713806152343 and perplexity is 119.78683715560194
At time: 505.965567111969 and batch: 500, loss is 4.768707752227783 and perplexity is 117.76695949747383
At time: 506.3304913043976 and batch: 550, loss is 4.8187228965759275 and perplexity is 123.80687558800912
At time: 506.7083160877228 and batch: 600, loss is 4.718255243301392 and perplexity is 111.97271698829292
At time: 507.08686876296997 and batch: 650, loss is 4.845707674026489 and perplexity is 127.19326151941682
At time: 507.4643545150757 and batch: 700, loss is 4.878446474075317 and perplexity is 131.4263309963164
At time: 507.8381311893463 and batch: 750, loss is 4.80304217338562 and perplexity is 121.88063612605752
At time: 508.21504044532776 and batch: 800, loss is 4.754666967391968 and perplexity is 116.12497332120927
At time: 508.5902421474457 and batch: 850, loss is 4.704250764846802 and perplexity is 110.41552675456624
At time: 508.98335123062134 and batch: 900, loss is 4.65730637550354 and perplexity is 105.35192110145546
At time: 509.3628737926483 and batch: 950, loss is 4.750592622756958 and perplexity is 115.65280270525568
At time: 509.7420508861542 and batch: 1000, loss is 4.813991479873657 and perplexity is 123.22247727517461
At time: 510.11771607398987 and batch: 1050, loss is 4.706420850753784 and perplexity is 110.65539810967701
At time: 510.4970428943634 and batch: 1100, loss is 4.824203252792358 and perplexity is 124.4872439960268
At time: 510.86956691741943 and batch: 1150, loss is 4.785186891555786 and perplexity is 119.72373634845732
At time: 511.2459375858307 and batch: 1200, loss is 4.740037860870362 and perplexity is 114.43853434065207
At time: 511.62543845176697 and batch: 1250, loss is 4.745687551498413 and perplexity is 115.08690648199446
At time: 511.99615120887756 and batch: 1300, loss is 4.81492618560791 and perplexity is 123.33770787623489
At time: 512.3703157901764 and batch: 1350, loss is 4.743691129684448 and perplexity is 114.8573736697861
At time: 512.7451872825623 and batch: 1400, loss is 4.626337203979492 and perplexity is 102.139262833766
At time: 513.1192100048065 and batch: 1450, loss is 4.718914318084717 and perplexity is 112.04653970715425
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.028390216012286 and perplexity of 152.68702162994566
Finished 45 epochs...
Completing Train Step...
At time: 514.3741314411163 and batch: 50, loss is 4.83522813796997 and perplexity is 125.86729504079484
At time: 514.7562298774719 and batch: 100, loss is 4.838823823928833 and perplexity is 126.32068894881509
At time: 515.1194503307343 and batch: 150, loss is 4.74671688079834 and perplexity is 115.20542979616951
At time: 515.4814891815186 and batch: 200, loss is 4.760864906311035 and perplexity is 116.84694386632898
At time: 515.8607907295227 and batch: 250, loss is 4.797975149154663 and perplexity is 121.26462597668986
At time: 516.2238743305206 and batch: 300, loss is 4.821964597702026 and perplexity is 124.20887169960984
At time: 516.588618516922 and batch: 350, loss is 4.857093229293823 and perplexity is 128.64970289166794
At time: 516.9621782302856 and batch: 400, loss is 4.748954515457154 and perplexity is 115.46350609131373
At time: 517.3389558792114 and batch: 450, loss is 4.783448534011841 and perplexity is 119.51579447920997
At time: 517.7298085689545 and batch: 500, loss is 4.767171306610107 and perplexity is 117.58615590166121
At time: 518.0974540710449 and batch: 550, loss is 4.816890649795532 and perplexity is 123.58023852973648
At time: 518.4945385456085 and batch: 600, loss is 4.716505556106568 and perplexity is 111.77697105622238
At time: 518.8786129951477 and batch: 650, loss is 4.843411989212036 and perplexity is 126.90160078909257
At time: 519.2520701885223 and batch: 700, loss is 4.876458311080933 and perplexity is 131.1652936069662
At time: 519.622810125351 and batch: 750, loss is 4.801261491775513 and perplexity is 121.663798635242
At time: 519.9868271350861 and batch: 800, loss is 4.7534824562072755 and perplexity is 115.98750342487638
At time: 520.3560070991516 and batch: 850, loss is 4.7025042915344235 and perplexity is 110.22285727883879
At time: 520.7238233089447 and batch: 900, loss is 4.655451440811158 and perplexity is 105.15668130261476
At time: 521.0911295413971 and batch: 950, loss is 4.748817682266235 and perplexity is 115.44770793222155
At time: 521.4647362232208 and batch: 1000, loss is 4.812326326370239 and perplexity is 123.0174636723702
At time: 521.8455889225006 and batch: 1050, loss is 4.704763793945313 and perplexity is 110.4721876658241
At time: 522.2202506065369 and batch: 1100, loss is 4.823203716278076 and perplexity is 124.36287661531388
At time: 522.6013572216034 and batch: 1150, loss is 4.783716602325439 and perplexity is 119.54783717130773
At time: 522.9652874469757 and batch: 1200, loss is 4.7388325214385985 and perplexity is 114.30068015992806
At time: 523.3397450447083 and batch: 1250, loss is 4.744246282577515 and perplexity is 114.92115477556351
At time: 523.7148339748383 and batch: 1300, loss is 4.813284673690796 and perplexity is 123.13541363855197
At time: 524.0930051803589 and batch: 1350, loss is 4.742481079101562 and perplexity is 114.71847449229186
At time: 524.4734213352203 and batch: 1400, loss is 4.624540815353393 and perplexity is 101.9559457274129
At time: 524.8405787944794 and batch: 1450, loss is 4.717404956817627 and perplexity is 111.87754856643257
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.029591095753205 and perplexity of 152.87049052091092
Annealing...
Finished 46 epochs...
Completing Train Step...
At time: 526.1046652793884 and batch: 50, loss is 4.834963855743408 and perplexity is 125.83403494702947
At time: 526.4944944381714 and batch: 100, loss is 4.836757583618164 and perplexity is 126.0599495171653
At time: 526.8674952983856 and batch: 150, loss is 4.740889015197754 and perplexity is 114.53598065942151
At time: 527.2337439060211 and batch: 200, loss is 4.755967521667481 and perplexity is 116.27609840364046
At time: 527.6081855297089 and batch: 250, loss is 4.793815450668335 and perplexity is 120.76124936885708
At time: 528.0062990188599 and batch: 300, loss is 4.817371501922607 and perplexity is 123.63967663962347
At time: 528.3761713504791 and batch: 350, loss is 4.849465417861938 and perplexity is 127.6721203647566
At time: 528.7450957298279 and batch: 400, loss is 4.74125678062439 and perplexity is 114.57811077973984
At time: 529.1125147342682 and batch: 450, loss is 4.778520717620849 and perplexity is 118.92829133089438
At time: 529.5058350563049 and batch: 500, loss is 4.756838741302491 and perplexity is 116.37744456462438
At time: 529.877904176712 and batch: 550, loss is 4.806560220718384 and perplexity is 122.31017309557213
At time: 530.2430994510651 and batch: 600, loss is 4.709821329116822 and perplexity is 111.03231989067925
At time: 530.615644454956 and batch: 650, loss is 4.833189888000488 and perplexity is 125.61100730847858
At time: 530.9855151176453 and batch: 700, loss is 4.867652053833008 and perplexity is 130.0152893380866
At time: 531.3666596412659 and batch: 750, loss is 4.791630249023438 and perplexity is 120.49764980209285
At time: 531.7390975952148 and batch: 800, loss is 4.740753078460694 and perplexity is 114.52041207013022
At time: 532.1102979183197 and batch: 850, loss is 4.687976627349854 and perplexity is 108.63315193476895
At time: 532.4837512969971 and batch: 900, loss is 4.641891565322876 and perplexity is 103.74039383924433
At time: 532.861186504364 and batch: 950, loss is 4.732409238815308 and perplexity is 113.56884748746566
At time: 533.2336494922638 and batch: 1000, loss is 4.797066345214843 and perplexity is 121.15447026939358
At time: 533.5979781150818 and batch: 1050, loss is 4.687612047195435 and perplexity is 108.59355366227231
At time: 533.9778792858124 and batch: 1100, loss is 4.809780702590943 and perplexity is 122.70470574248333
At time: 534.3489952087402 and batch: 1150, loss is 4.764260454177856 and perplexity is 117.24437762814087
At time: 534.7346684932709 and batch: 1200, loss is 4.722930917739868 and perplexity is 112.49749083871387
At time: 535.1152675151825 and batch: 1250, loss is 4.726784038543701 and perplexity is 112.93179343390177
At time: 535.4855885505676 and batch: 1300, loss is 4.791882934570313 and perplexity is 120.52810166384087
At time: 535.8692445755005 and batch: 1350, loss is 4.721901588439941 and perplexity is 112.3817534513861
At time: 536.2440338134766 and batch: 1400, loss is 4.6015904712677 and perplexity is 99.6426684819895
At time: 536.6193027496338 and batch: 1450, loss is 4.695257186889648 and perplexity is 109.42694819954617
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.018375755375267 and perplexity of 151.16557441407676
Finished 47 epochs...
Completing Train Step...
At time: 537.9481942653656 and batch: 50, loss is 4.82798812866211 and perplexity is 124.95930554556861
At time: 538.3465945720673 and batch: 100, loss is 4.831582098007202 and perplexity is 125.40921345242226
At time: 538.7288796901703 and batch: 150, loss is 4.736133432388305 and perplexity is 113.99258841623272
At time: 539.0948913097382 and batch: 200, loss is 4.751728210449219 and perplexity is 115.78421120339821
At time: 539.4824175834656 and batch: 250, loss is 4.788583402633667 and perplexity is 120.13107071149459
At time: 539.8635258674622 and batch: 300, loss is 4.814200744628907 and perplexity is 123.24826609497427
At time: 540.2261183261871 and batch: 350, loss is 4.846523056030273 and perplexity is 127.29701490943758
At time: 540.6013782024384 and batch: 400, loss is 4.738347387313842 and perplexity is 114.24524244794989
At time: 540.9796421527863 and batch: 450, loss is 4.775314617156982 and perplexity is 118.54760586490734
At time: 541.3493118286133 and batch: 500, loss is 4.753825979232788 and perplexity is 116.02735464748893
At time: 541.7203543186188 and batch: 550, loss is 4.804013509750366 and perplexity is 121.99908073555065
At time: 542.1000511646271 and batch: 600, loss is 4.707354402542114 and perplexity is 110.75874888861685
At time: 542.4710648059845 and batch: 650, loss is 4.830736236572266 and perplexity is 125.30317948652049
At time: 542.8554494380951 and batch: 700, loss is 4.865794162750245 and perplexity is 129.77395934324292
At time: 543.2276055812836 and batch: 750, loss is 4.789323015213013 and perplexity is 120.21995402812082
At time: 543.6117000579834 and batch: 800, loss is 4.738903789520264 and perplexity is 114.30882644041756
At time: 543.9800868034363 and batch: 850, loss is 4.686571083068848 and perplexity is 108.48057048445122
At time: 544.3491492271423 and batch: 900, loss is 4.641006517410278 and perplexity is 103.64861923867485
At time: 544.7264549732208 and batch: 950, loss is 4.7315112972259525 and perplexity is 113.4669150675801
At time: 545.1005899906158 and batch: 1000, loss is 4.796426362991333 and perplexity is 121.07695836788751
At time: 545.4716851711273 and batch: 1050, loss is 4.687677555084228 and perplexity is 108.60066762971725
At time: 545.8379559516907 and batch: 1100, loss is 4.809233350753784 and perplexity is 122.63756147381292
At time: 546.2029566764832 and batch: 1150, loss is 4.764533605575561 and perplexity is 117.27640746806168
At time: 546.5711028575897 and batch: 1200, loss is 4.7233638668060305 and perplexity is 112.54620706738001
At time: 546.9346776008606 and batch: 1250, loss is 4.727352142333984 and perplexity is 112.99596864115831
At time: 547.3114693164825 and batch: 1300, loss is 4.79235728263855 and perplexity is 120.5852874979561
At time: 547.702666759491 and batch: 1350, loss is 4.723209352493286 and perplexity is 112.52881841097573
At time: 548.0812346935272 and batch: 1400, loss is 4.602905101776123 and perplexity is 99.77374791554959
At time: 548.4469044208527 and batch: 1450, loss is 4.696954402923584 and perplexity is 109.61282706425054
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.0178363506610575 and perplexity of 151.08405697803275
Finished 48 epochs...
Completing Train Step...
At time: 549.7760565280914 and batch: 50, loss is 4.826470012664795 and perplexity is 124.76974674733452
At time: 550.163360118866 and batch: 100, loss is 4.829921636581421 and perplexity is 125.20114908028401
At time: 550.5387222766876 and batch: 150, loss is 4.7341637134552 and perplexity is 113.76827604528141
At time: 550.9081587791443 and batch: 200, loss is 4.749983043670654 and perplexity is 115.58232465860813
At time: 551.2707901000977 and batch: 250, loss is 4.786560573577881 and perplexity is 119.88831170392126
At time: 551.6464011669159 and batch: 300, loss is 4.812913799285889 and perplexity is 123.0897543327531
At time: 552.0207681655884 and batch: 350, loss is 4.84526104927063 and perplexity is 127.13646654400894
At time: 552.3957893848419 and batch: 400, loss is 4.7372488594055175 and perplexity is 114.11980976899066
At time: 552.780993938446 and batch: 450, loss is 4.77402063369751 and perplexity is 118.39430642861583
At time: 553.1550931930542 and batch: 500, loss is 4.752352895736695 and perplexity is 115.85656249269914
At time: 553.5180954933167 and batch: 550, loss is 4.8028613948822025 and perplexity is 121.85860471852551
At time: 553.9185829162598 and batch: 600, loss is 4.706170578002929 and perplexity is 110.6277075440367
At time: 554.2870826721191 and batch: 650, loss is 4.8293705177307125 and perplexity is 125.13216737719996
At time: 554.660213470459 and batch: 700, loss is 4.864975786209106 and perplexity is 129.66779882482967
At time: 555.0386176109314 and batch: 750, loss is 4.78829909324646 and perplexity is 120.09692117514298
At time: 555.4143970012665 and batch: 800, loss is 4.737861967086792 and perplexity is 114.18979895420668
At time: 555.781608581543 and batch: 850, loss is 4.685900926589966 and perplexity is 108.40789588170611
At time: 556.1504290103912 and batch: 900, loss is 4.640564136505127 and perplexity is 103.60277720924519
At time: 556.5160789489746 and batch: 950, loss is 4.730933504104614 and perplexity is 113.40137360108223
At time: 556.9254937171936 and batch: 1000, loss is 4.7961630153656 and perplexity is 121.04507723646475
At time: 557.2897572517395 and batch: 1050, loss is 4.687665739059448 and perplexity is 108.59938440911871
At time: 557.6517570018768 and batch: 1100, loss is 4.80897665977478 and perplexity is 122.60608555806019
At time: 558.0245521068573 and batch: 1150, loss is 4.764558753967285 and perplexity is 117.27935681818218
At time: 558.3995063304901 and batch: 1200, loss is 4.723515758514404 and perplexity is 112.56330320139008
At time: 558.7625441551208 and batch: 1250, loss is 4.727405519485473 and perplexity is 113.00200020506655
At time: 559.1312716007233 and batch: 1300, loss is 4.792443552017212 and perplexity is 120.59569076451956
At time: 559.4993877410889 and batch: 1350, loss is 4.723872566223145 and perplexity is 112.603473821861
At time: 559.8899042606354 and batch: 1400, loss is 4.603278608322143 and perplexity is 99.81102102395867
At time: 560.2636592388153 and batch: 1450, loss is 4.697553606033325 and perplexity is 109.67852709295991
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.017516568175748 and perplexity of 151.03575066696942
Finished 49 epochs...
Completing Train Step...
At time: 561.5145347118378 and batch: 50, loss is 4.825430660247803 and perplexity is 124.64013437761791
At time: 561.890456199646 and batch: 100, loss is 4.828734245300293 and perplexity is 125.05257455298425
At time: 562.2704651355743 and batch: 150, loss is 4.732804021835327 and perplexity is 113.61369139128035
At time: 562.6531572341919 and batch: 200, loss is 4.748740491867065 and perplexity is 115.43879682149348
At time: 563.0226027965546 and batch: 250, loss is 4.785188636779785 and perplexity is 119.7239452933776
At time: 563.3932304382324 and batch: 300, loss is 4.811991004943848 and perplexity is 122.97622019627764
At time: 563.7694275379181 and batch: 350, loss is 4.844347991943359 and perplexity is 127.02043664070526
At time: 564.1336088180542 and batch: 400, loss is 4.736496562957764 and perplexity is 114.0339901264367
At time: 564.5126464366913 and batch: 450, loss is 4.773227100372314 and perplexity is 118.30039386725291
At time: 564.8907852172852 and batch: 500, loss is 4.751316823959351 and perplexity is 115.73658893941872
At time: 565.2684218883514 and batch: 550, loss is 4.802075843811036 and perplexity is 121.76291615010739
At time: 565.6558992862701 and batch: 600, loss is 4.705332288742065 and perplexity is 110.53500838463196
At time: 566.0255768299103 and batch: 650, loss is 4.828327083587647 and perplexity is 125.00166829680097
At time: 566.4252953529358 and batch: 700, loss is 4.864411888122558 and perplexity is 129.59470001326247
At time: 566.7960846424103 and batch: 750, loss is 4.787654638290405 and perplexity is 120.01954905318637
At time: 567.1631486415863 and batch: 800, loss is 4.737066869735718 and perplexity is 114.09904303221629
At time: 567.5327575206757 and batch: 850, loss is 4.685378465652466 and perplexity is 108.35127178401899
At time: 567.9122252464294 and batch: 900, loss is 4.640185317993164 and perplexity is 103.56353799208776
At time: 568.3031742572784 and batch: 950, loss is 4.730400352478028 and perplexity is 113.34092958863319
At time: 568.6946475505829 and batch: 1000, loss is 4.795914907455444 and perplexity is 121.01504872062708
At time: 569.0741083621979 and batch: 1050, loss is 4.687532205581665 and perplexity is 108.58488372381842
At time: 569.4456615447998 and batch: 1100, loss is 4.808704805374146 and perplexity is 122.57275908433618
At time: 569.813464641571 and batch: 1150, loss is 4.764453439712525 and perplexity is 117.26700628047534
At time: 570.182204246521 and batch: 1200, loss is 4.723512115478516 and perplexity is 112.56289312998379
At time: 570.5476751327515 and batch: 1250, loss is 4.7272904586791995 and perplexity is 112.98899885179982
At time: 570.9240834712982 and batch: 1300, loss is 4.792411727905273 and perplexity is 120.5918529748248
At time: 571.3045258522034 and batch: 1350, loss is 4.724249620437622 and perplexity is 112.6459394416476
At time: 571.6967906951904 and batch: 1400, loss is 4.603302154541016 and perplexity is 99.81337122377464
At time: 572.0639770030975 and batch: 1450, loss is 4.697729806900025 and perplexity is 109.69785424717271
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.01722912910657 and perplexity of 150.99234333016628
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f830fadb9e8>
SETTINGS FOR THIS RUN
{'batch_size': 20, 'seq_len': 35, 'anneal': 4.412380902650271, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'dropout': 0.0606127314504219, 'lr': 11.306292291322702, 'num_layers': 1, 'wordvec_dim': 200, 'data': 'ptb'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.604128360748291 and batch: 50, loss is 6.728251276016235 and perplexity is 835.6846057194807
At time: 1.0105392932891846 and batch: 100, loss is 5.791714687347412 and perplexity is 327.5742304803079
At time: 1.384150505065918 and batch: 150, loss is 5.469174814224243 and perplexity is 237.26432481262876
At time: 1.7660353183746338 and batch: 200, loss is 5.375517063140869 and perplexity is 216.05155573043152
At time: 2.152324676513672 and batch: 250, loss is 5.329480810165405 and perplexity is 206.33082147734976
At time: 2.530704975128174 and batch: 300, loss is 5.317603092193604 and perplexity is 203.89457931168621
At time: 2.9077792167663574 and batch: 350, loss is 5.325661525726319 and perplexity is 205.5442883345659
At time: 3.289804220199585 and batch: 400, loss is 5.204124364852905 and perplexity is 182.02141861547483
At time: 3.6782212257385254 and batch: 450, loss is 5.203272180557251 and perplexity is 181.86636889590935
At time: 4.063833713531494 and batch: 500, loss is 5.174340991973877 and perplexity is 176.68014227084132
At time: 4.465522289276123 and batch: 550, loss is 5.219685974121094 and perplexity is 184.87611906842474
At time: 4.850452899932861 and batch: 600, loss is 5.063982667922974 and perplexity is 158.21939850087224
At time: 5.234305143356323 and batch: 650, loss is 5.209675712585449 and perplexity is 183.03469272122496
At time: 5.6107470989227295 and batch: 700, loss is 5.20533597946167 and perplexity is 182.24209208398057
At time: 5.987577676773071 and batch: 750, loss is 5.1404321670532225 and perplexity is 170.7895619963059
At time: 6.367784023284912 and batch: 800, loss is 5.046245603561402 and perplexity is 155.43779253330493
At time: 6.7488367557525635 and batch: 850, loss is 4.995807790756226 and perplexity is 147.7922824168852
At time: 7.130185127258301 and batch: 900, loss is 4.979762468338013 and perplexity is 145.4398309855605
At time: 7.500865936279297 and batch: 950, loss is 5.022408647537231 and perplexity is 151.77643982351378
At time: 7.881162405014038 and batch: 1000, loss is 5.046367492675781 and perplexity is 155.45673986289106
At time: 8.269137382507324 and batch: 1050, loss is 4.976442308425903 and perplexity is 144.95774822787308
At time: 8.64707326889038 and batch: 1100, loss is 5.085679798126221 and perplexity is 161.6898183210946
At time: 9.008795261383057 and batch: 1150, loss is 5.037350835800171 and perplexity is 154.06134015456556
At time: 9.391655206680298 and batch: 1200, loss is 4.967376089096069 and perplexity is 143.6494690232875
At time: 9.783368110656738 and batch: 1250, loss is 4.945369167327881 and perplexity is 140.5227176732791
At time: 10.16397213935852 and batch: 1300, loss is 5.037006521224976 and perplexity is 154.00830372080878
At time: 10.538011074066162 and batch: 1350, loss is 4.9834168338775635 and perplexity is 145.97229360595853
At time: 10.912934303283691 and batch: 1400, loss is 4.829780883789063 and perplexity is 125.18352790908813
At time: 11.299718856811523 and batch: 1450, loss is 4.929395208358764 and perplexity is 138.2958468702178
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.004558856670673 and perplexity of 149.09129801753562
Finished 1 epochs...
Completing Train Step...
At time: 12.568580627441406 and batch: 50, loss is 4.961815242767334 and perplexity is 142.8528733267324
At time: 12.961140632629395 and batch: 100, loss is 4.94362003326416 and perplexity is 140.27713943830983
At time: 13.352400064468384 and batch: 150, loss is 4.801747741699219 and perplexity is 121.72297203341046
At time: 13.711824178695679 and batch: 200, loss is 4.86694564819336 and perplexity is 129.92347823621563
At time: 14.085520505905151 and batch: 250, loss is 4.887146816253662 and perplexity is 132.57477372522249
At time: 14.48049283027649 and batch: 300, loss is 4.895885410308838 and perplexity is 133.7383675371284
At time: 14.852001190185547 and batch: 350, loss is 4.918134489059448 and perplexity is 136.74727155803802
At time: 15.234074115753174 and batch: 400, loss is 4.781416673660278 and perplexity is 119.27320161589356
At time: 15.599452257156372 and batch: 450, loss is 4.815675382614136 and perplexity is 123.43014674086699
At time: 15.961198806762695 and batch: 500, loss is 4.808859539031983 and perplexity is 122.5917266831256
At time: 16.339938163757324 and batch: 550, loss is 4.851497030258178 and perplexity is 127.93176428574255
At time: 16.725929975509644 and batch: 600, loss is 4.737560338973999 and perplexity is 114.15536129459223
At time: 17.102821588516235 and batch: 650, loss is 4.855253019332886 and perplexity is 128.41317812130106
At time: 17.479217767715454 and batch: 700, loss is 4.872444524765014 and perplexity is 130.63987930212616
At time: 17.868295431137085 and batch: 750, loss is 4.826036233901977 and perplexity is 124.71563601784447
At time: 18.258479833602905 and batch: 800, loss is 4.7242939662933345 and perplexity is 112.65093493298858
At time: 18.637375593185425 and batch: 850, loss is 4.705066394805908 and perplexity is 110.50562170321277
At time: 19.00666117668152 and batch: 900, loss is 4.653682079315185 and perplexity is 104.97078562649719
At time: 19.37211585044861 and batch: 950, loss is 4.742521209716797 and perplexity is 114.72307830762834
At time: 19.73180890083313 and batch: 1000, loss is 4.771247882843017 and perplexity is 118.06648321038247
At time: 20.119740962982178 and batch: 1050, loss is 4.685060997009277 and perplexity is 108.31687911236416
At time: 20.507595777511597 and batch: 1100, loss is 4.823820495605469 and perplexity is 124.43960472642931
At time: 20.869248867034912 and batch: 1150, loss is 4.747466421127319 and perplexity is 115.29181328182794
At time: 21.2438805103302 and batch: 1200, loss is 4.690057725906372 and perplexity is 108.85946363724996
At time: 21.62466025352478 and batch: 1250, loss is 4.67116039276123 and perplexity is 106.82162558306382
At time: 21.995750665664673 and batch: 1300, loss is 4.7539225196838375 and perplexity is 116.03855652134894
At time: 22.360711574554443 and batch: 1350, loss is 4.726287260055542 and perplexity is 112.87570528114192
At time: 22.73969578742981 and batch: 1400, loss is 4.570022134780884 and perplexity is 96.54624677921112
At time: 23.106882095336914 and batch: 1450, loss is 4.664356784820557 and perplexity is 106.09731986303704
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.894175994090545 and perplexity of 133.50994829005714
Finished 2 epochs...
Completing Train Step...
At time: 24.368294715881348 and batch: 50, loss is 4.753971548080444 and perplexity is 116.0442458451878
At time: 24.74557900428772 and batch: 100, loss is 4.755456600189209 and perplexity is 116.21670562137245
At time: 25.104941606521606 and batch: 150, loss is 4.5958846950531 and perplexity is 99.07574861121005
At time: 25.490410089492798 and batch: 200, loss is 4.695220823287964 and perplexity is 109.42296911393568
At time: 25.857893705368042 and batch: 250, loss is 4.721924848556519 and perplexity is 112.38436749447395
At time: 26.235564708709717 and batch: 300, loss is 4.7426964282989506 and perplexity is 114.74318168394083
At time: 26.594274759292603 and batch: 350, loss is 4.751525583267212 and perplexity is 115.76075255172172
At time: 26.956071376800537 and batch: 400, loss is 4.598196315765381 and perplexity is 99.30503907797761
At time: 27.31564474105835 and batch: 450, loss is 4.644259834289551 and perplexity is 103.9863701486273
At time: 27.67275357246399 and batch: 500, loss is 4.656390056610108 and perplexity is 105.25542936104469
At time: 28.048999309539795 and batch: 550, loss is 4.686804027557373 and perplexity is 108.50584337893409
At time: 28.428405284881592 and batch: 600, loss is 4.588014612197876 and perplexity is 98.29907451425612
At time: 28.806041955947876 and batch: 650, loss is 4.692258234024048 and perplexity is 109.09927352570472
At time: 29.185168981552124 and batch: 700, loss is 4.7286827182769775 and perplexity is 113.1464184289248
At time: 29.562217235565186 and batch: 750, loss is 4.678467321395874 and perplexity is 107.60502220389866
At time: 29.93361806869507 and batch: 800, loss is 4.59502387046814 and perplexity is 98.9904984690056
At time: 30.30381989479065 and batch: 850, loss is 4.57689661026001 and perplexity is 97.21223813310648
At time: 30.677436590194702 and batch: 900, loss is 4.508110084533691 and perplexity is 90.75014623364518
At time: 31.059632301330566 and batch: 950, loss is 4.610714387893677 and perplexity is 100.55595994354903
At time: 31.44589328765869 and batch: 1000, loss is 4.640764684677124 and perplexity is 103.62355664039715
At time: 31.830281257629395 and batch: 1050, loss is 4.5606350994110105 and perplexity is 95.64420412274885
At time: 32.195443868637085 and batch: 1100, loss is 4.701686677932739 and perplexity is 110.13277440302164
At time: 32.56596922874451 and batch: 1150, loss is 4.630851631164551 and perplexity is 102.60140546832697
At time: 32.93766474723816 and batch: 1200, loss is 4.575661821365356 and perplexity is 97.09227562046675
At time: 33.302550315856934 and batch: 1250, loss is 4.5416833114624025 and perplexity is 93.84864372994481
At time: 33.66282391548157 and batch: 1300, loss is 4.629851894378662 and perplexity is 102.49888232561412
At time: 34.03490614891052 and batch: 1350, loss is 4.593880090713501 and perplexity is 98.87733986755036
At time: 34.40421104431152 and batch: 1400, loss is 4.450423545837403 and perplexity is 85.66321861934148
At time: 34.78583741188049 and batch: 1450, loss is 4.547324352264404 and perplexity is 94.37954376498915
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8324934478498935 and perplexity of 125.52355721504509
Finished 3 epochs...
Completing Train Step...
At time: 36.06674122810364 and batch: 50, loss is 4.637650594711304 and perplexity is 103.30136548892887
At time: 36.44150185585022 and batch: 100, loss is 4.651539707183838 and perplexity is 104.74613986409824
At time: 36.824201345443726 and batch: 150, loss is 4.47945930480957 and perplexity is 88.18697750794244
At time: 37.19662642478943 and batch: 200, loss is 4.588966856002807 and perplexity is 98.39272378038306
At time: 37.562516927719116 and batch: 250, loss is 4.638524255752563 and perplexity is 103.39165530306889
At time: 37.92335772514343 and batch: 300, loss is 4.631996221542359 and perplexity is 102.71890928381553
At time: 38.294983863830566 and batch: 350, loss is 4.630050706863403 and perplexity is 102.51926240893282
At time: 38.67741537094116 and batch: 400, loss is 4.494215326309204 and perplexity is 89.4979147663333
At time: 39.037333965301514 and batch: 450, loss is 4.547119064331055 and perplexity is 94.36017077208805
At time: 39.40243220329285 and batch: 500, loss is 4.555432739257813 and perplexity is 95.14792056853705
At time: 39.79285526275635 and batch: 550, loss is 4.584604749679565 and perplexity is 97.96445900514563
At time: 40.15724158287048 and batch: 600, loss is 4.496464462280273 and perplexity is 89.69943428321632
At time: 40.54165530204773 and batch: 650, loss is 4.591792602539062 and perplexity is 98.6711498743177
At time: 40.920735359191895 and batch: 700, loss is 4.631075468063354 and perplexity is 102.6243740192486
At time: 41.299344301223755 and batch: 750, loss is 4.582105617523194 and perplexity is 97.7199385472
At time: 41.674442529678345 and batch: 800, loss is 4.494407153129577 and perplexity is 89.51508451350931
At time: 42.05561876296997 and batch: 850, loss is 4.4855859661102295 and perplexity is 88.72892772776358
At time: 42.414655923843384 and batch: 900, loss is 4.413800921440124 and perplexity is 82.58275829917314
At time: 42.79074192047119 and batch: 950, loss is 4.523954038619995 and perplexity is 92.19943832460746
At time: 43.207544803619385 and batch: 1000, loss is 4.546493816375732 and perplexity is 94.30119070875239
At time: 43.57876706123352 and batch: 1050, loss is 4.463256893157959 and perplexity is 86.7696488731121
At time: 43.94038796424866 and batch: 1100, loss is 4.618930110931396 and perplexity is 101.38550284154358
At time: 44.3239266872406 and batch: 1150, loss is 4.542774868011475 and perplexity is 93.95114076210608
At time: 44.69734191894531 and batch: 1200, loss is 4.488853197097779 and perplexity is 89.01929972782082
At time: 45.07412266731262 and batch: 1250, loss is 4.448207068443298 and perplexity is 85.47355829831902
At time: 45.43090319633484 and batch: 1300, loss is 4.541890182495117 and perplexity is 93.86806030408623
At time: 45.80968189239502 and batch: 1350, loss is 4.5191560649871825 and perplexity is 91.75812739626629
At time: 46.19698667526245 and batch: 1400, loss is 4.376059875488282 and perplexity is 79.52408052558125
At time: 46.57703876495361 and batch: 1450, loss is 4.472431583404541 and perplexity is 87.56939663343026
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.827536558493589 and perplexity of 124.90289038956462
Finished 4 epochs...
Completing Train Step...
At time: 47.86354875564575 and batch: 50, loss is 4.5585581398010255 and perplexity is 95.44576112423944
At time: 48.224762201309204 and batch: 100, loss is 4.5806489849090575 and perplexity is 97.57770011737855
At time: 48.59567880630493 and batch: 150, loss is 4.402849941253662 and perplexity is 81.68332994888378
At time: 48.959120750427246 and batch: 200, loss is 4.511596212387085 and perplexity is 91.0670649347237
At time: 49.31768226623535 and batch: 250, loss is 4.559929127693176 and perplexity is 95.57670584840318
At time: 49.687891721725464 and batch: 300, loss is 4.563877325057984 and perplexity is 95.95480746531244
At time: 50.0569851398468 and batch: 350, loss is 4.561584005355835 and perplexity is 95.73500455034845
At time: 50.43340992927551 and batch: 400, loss is 4.4201344394683835 and perplexity is 83.10745752974555
At time: 50.79353618621826 and batch: 450, loss is 4.485606002807617 and perplexity is 88.73070558024905
At time: 51.16261577606201 and batch: 500, loss is 4.48908618927002 and perplexity is 89.04004294424546
At time: 51.52573037147522 and batch: 550, loss is 4.508195543289185 and perplexity is 90.75790195959578
At time: 51.896591663360596 and batch: 600, loss is 4.417669973373413 and perplexity is 82.90289419166598
At time: 52.27828335762024 and batch: 650, loss is 4.51415638923645 and perplexity is 91.30051143075606
At time: 52.66484189033508 and batch: 700, loss is 4.570524444580078 and perplexity is 96.594755087123
At time: 53.02341651916504 and batch: 750, loss is 4.51393424987793 and perplexity is 91.28023224620019
At time: 53.4005823135376 and batch: 800, loss is 4.439626455307007 and perplexity is 84.74328035809333
At time: 53.77935791015625 and batch: 850, loss is 4.431102857589722 and perplexity is 84.02403237186951
At time: 54.162102937698364 and batch: 900, loss is 4.344386215209961 and perplexity is 77.04473407780345
At time: 54.544599294662476 and batch: 950, loss is 4.459817857742309 and perplexity is 86.47175750071969
At time: 54.935460567474365 and batch: 1000, loss is 4.486844186782837 and perplexity is 88.84063856259216
At time: 55.3102343082428 and batch: 1050, loss is 4.39525475025177 and perplexity is 81.06527953284689
At time: 55.67048740386963 and batch: 1100, loss is 4.561887683868409 and perplexity is 95.76408162895008
At time: 56.054906129837036 and batch: 1150, loss is 4.485433416366577 and perplexity is 88.71539318495591
At time: 56.42521572113037 and batch: 1200, loss is 4.423013658523559 and perplexity is 83.34708691229262
At time: 56.79355549812317 and batch: 1250, loss is 4.378716711997986 and perplexity is 79.73564392635764
At time: 57.186481952667236 and batch: 1300, loss is 4.472598571777343 and perplexity is 87.58402092549075
At time: 57.56545877456665 and batch: 1350, loss is 4.453739318847656 and perplexity is 85.94772983424676
At time: 57.934720277786255 and batch: 1400, loss is 4.313528985977173 and perplexity is 74.7036524590192
At time: 58.31403732299805 and batch: 1450, loss is 4.41476879119873 and perplexity is 82.66272634659788
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.8231018588074255 and perplexity of 124.35020997236605
Finished 5 epochs...
Completing Train Step...
At time: 59.57879662513733 and batch: 50, loss is 4.487906050682068 and perplexity is 88.93502533354989
At time: 59.967135190963745 and batch: 100, loss is 4.519500799179077 and perplexity is 91.78976501313485
At time: 60.340984582901 and batch: 150, loss is 4.349568719863892 and perplexity is 77.44505520778529
At time: 60.71561360359192 and batch: 200, loss is 4.452612495422363 and perplexity is 85.8509364636792
At time: 61.07776856422424 and batch: 250, loss is 4.508925247192383 and perplexity is 90.82415252360963
At time: 61.440088510513306 and batch: 300, loss is 4.511126461029053 and perplexity is 91.02429610344342
At time: 61.81954550743103 and batch: 350, loss is 4.507325677871704 and perplexity is 90.67898912606637
At time: 62.20919895172119 and batch: 400, loss is 4.343624777793885 and perplexity is 76.98609166366245
At time: 62.59910035133362 and batch: 450, loss is 4.429967679977417 and perplexity is 83.9287042888151
At time: 62.97710037231445 and batch: 500, loss is 4.4365624332427975 and perplexity is 84.48402246606446
At time: 63.34661102294922 and batch: 550, loss is 4.456999959945679 and perplexity is 86.22843192010791
At time: 63.71937704086304 and batch: 600, loss is 4.3844694232940675 and perplexity is 80.19566197273865
At time: 64.1069107055664 and batch: 650, loss is 4.464811005592346 and perplexity is 86.90460350352525
At time: 64.50001502037048 and batch: 700, loss is 4.504408540725708 and perplexity is 90.41485152863463
At time: 64.86053276062012 and batch: 750, loss is 4.456521110534668 and perplexity is 86.18715137064275
At time: 65.24609065055847 and batch: 800, loss is 4.387684850692749 and perplexity is 80.45394031660518
At time: 65.61217403411865 and batch: 850, loss is 4.360723466873169 and perplexity is 78.31377135242921
At time: 65.99018478393555 and batch: 900, loss is 4.2824112939834595 and perplexity is 72.4148431297742
At time: 66.36912488937378 and batch: 950, loss is 4.4150830078125 and perplexity is 82.68870442971442
At time: 66.74007177352905 and batch: 1000, loss is 4.441557369232178 and perplexity is 84.90707041956672
At time: 67.12932705879211 and batch: 1050, loss is 4.33439576625824 and perplexity is 76.27885470452294
At time: 67.49143815040588 and batch: 1100, loss is 4.49876672744751 and perplexity is 89.90618407138344
At time: 67.88345646858215 and batch: 1150, loss is 4.42598708152771 and perplexity is 83.59528186928124
At time: 68.24957156181335 and batch: 1200, loss is 4.365911440849304 and perplexity is 78.721116895573
At time: 68.61339926719666 and batch: 1250, loss is 4.330276560783386 and perplexity is 75.96529268517467
At time: 68.98622035980225 and batch: 1300, loss is 4.4199259567260745 and perplexity is 83.09013286510297
At time: 69.35270738601685 and batch: 1350, loss is 4.399436550140381 and perplexity is 81.40498811136257
At time: 69.73475337028503 and batch: 1400, loss is 4.257494220733642 and perplexity is 70.63277138577439
At time: 70.12110710144043 and batch: 1450, loss is 4.3612931537628175 and perplexity is 78.35839839176032
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.837272448417468 and perplexity of 126.12487005899047
Annealing...
Finished 6 epochs...
Completing Train Step...
At time: 71.42983794212341 and batch: 50, loss is 4.415243482589721 and perplexity is 82.70197494589958
At time: 71.80442523956299 and batch: 100, loss is 4.375896000862122 and perplexity is 79.51104961436144
At time: 72.16782021522522 and batch: 150, loss is 4.180709099769592 and perplexity is 65.41222056305854
At time: 72.54578852653503 and batch: 200, loss is 4.263819899559021 and perplexity is 71.08098775391733
At time: 72.90642404556274 and batch: 250, loss is 4.317053956985474 and perplexity is 74.96744532611106
At time: 73.2854654788971 and batch: 300, loss is 4.309294357299804 and perplexity is 74.38797908150386
At time: 73.65764617919922 and batch: 350, loss is 4.291947193145752 and perplexity is 73.1086867252063
At time: 74.03390502929688 and batch: 400, loss is 4.122585806846619 and perplexity is 61.718628556821606
At time: 74.42269277572632 and batch: 450, loss is 4.190513281822205 and perplexity is 66.05668795747313
At time: 74.80381536483765 and batch: 500, loss is 4.178748717308045 and perplexity is 65.2841132038334
At time: 75.18323421478271 and batch: 550, loss is 4.204726405143738 and perplexity is 67.00226368367564
At time: 75.55740141868591 and batch: 600, loss is 4.1213296604156495 and perplexity is 61.64114959448451
At time: 75.93531656265259 and batch: 650, loss is 4.196326379776001 and perplexity is 66.44180021824182
At time: 76.31955981254578 and batch: 700, loss is 4.254665851593018 and perplexity is 70.43327808820342
At time: 76.68774008750916 and batch: 750, loss is 4.18516704082489 and perplexity is 65.70447532988273
At time: 77.06746697425842 and batch: 800, loss is 4.114401202201844 and perplexity is 61.215547550788024
At time: 77.45476174354553 and batch: 850, loss is 4.072976684570312 and perplexity is 58.731527882931346
At time: 77.81664228439331 and batch: 900, loss is 3.9819487380981444 and perplexity is 53.62142659464496
At time: 78.18433022499084 and batch: 950, loss is 4.10909170627594 and perplexity is 60.891385181386255
At time: 78.56812167167664 and batch: 1000, loss is 4.117814955711364 and perplexity is 61.42487944152398
At time: 78.94783020019531 and batch: 1050, loss is 4.021400933265686 and perplexity is 55.77919404430323
At time: 79.31817603111267 and batch: 1100, loss is 4.182068667411804 and perplexity is 65.50121338371295
At time: 79.69127750396729 and batch: 1150, loss is 4.088646502494812 and perplexity is 59.659088605495285
At time: 80.05975079536438 and batch: 1200, loss is 4.028678908348083 and perplexity is 56.186634500947505
At time: 80.43118858337402 and batch: 1250, loss is 3.9715815591812134 and perplexity is 53.06839531171975
At time: 80.80230903625488 and batch: 1300, loss is 4.053515682220459 and perplexity is 57.59960339763752
At time: 81.16563272476196 and batch: 1350, loss is 4.015054097175598 and perplexity is 55.42629372733722
At time: 81.53320288658142 and batch: 1400, loss is 3.8737256717681885 and perplexity is 48.12133682401034
At time: 81.90167093276978 and batch: 1450, loss is 3.965475182533264 and perplexity is 52.745327093830426
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.6115785256410255 and perplexity of 100.64289169935336
Finished 7 epochs...
Completing Train Step...
At time: 83.2060604095459 and batch: 50, loss is 4.216861305236816 and perplexity is 67.82028271092616
At time: 83.5958001613617 and batch: 100, loss is 4.226748905181885 and perplexity is 68.49418870060786
At time: 83.97219157218933 and batch: 150, loss is 4.0473299312591555 and perplexity is 57.244406308507706
At time: 84.3385558128357 and batch: 200, loss is 4.157702956199646 and perplexity is 63.924516410635825
At time: 84.70300579071045 and batch: 250, loss is 4.211339282989502 and perplexity is 67.4468097130958
At time: 85.08072900772095 and batch: 300, loss is 4.2169701290130615 and perplexity is 67.8276635717961
At time: 85.4575629234314 and batch: 350, loss is 4.199631824493408 and perplexity is 66.66178328642965
At time: 85.83085250854492 and batch: 400, loss is 4.031268944740296 and perplexity is 56.33234854994814
At time: 86.218186378479 and batch: 450, loss is 4.108489961624145 and perplexity is 60.8547551380846
At time: 86.59141898155212 and batch: 500, loss is 4.097738747596741 and perplexity is 60.203997128668085
At time: 86.96966075897217 and batch: 550, loss is 4.128277454376221 and perplexity is 62.07091081880007
At time: 87.34696292877197 and batch: 600, loss is 4.04990074634552 and perplexity is 57.391760420786646
At time: 87.72176361083984 and batch: 650, loss is 4.123105564117432 and perplexity is 61.75071560077346
At time: 88.1016275882721 and batch: 700, loss is 4.184342555999756 and perplexity is 65.65032531303089
At time: 88.46680402755737 and batch: 750, loss is 4.121446704864502 and perplexity is 61.648364771105356
At time: 88.85103130340576 and batch: 800, loss is 4.054390630722046 and perplexity is 57.65002213800652
At time: 89.22125315666199 and batch: 850, loss is 4.016939506530762 and perplexity is 55.53089355581469
At time: 89.58207941055298 and batch: 900, loss is 3.9337482929229735 and perplexity is 51.09814999443965
At time: 89.9470567703247 and batch: 950, loss is 4.0628300428390505 and perplexity is 58.13861324430048
At time: 90.31327366828918 and batch: 1000, loss is 4.075150218009949 and perplexity is 58.85932165445295
At time: 90.68455791473389 and batch: 1050, loss is 3.9841408109664918 and perplexity is 53.73909759362806
At time: 91.08070611953735 and batch: 1100, loss is 4.146648845672607 and perplexity is 63.22177896534721
At time: 91.44302201271057 and batch: 1150, loss is 4.054352502822876 and perplexity is 57.64782410567877
At time: 91.81897735595703 and batch: 1200, loss is 3.997974123954773 and perplexity is 54.487652913403956
At time: 92.20155692100525 and batch: 1250, loss is 3.943243465423584 and perplexity is 51.58564651221448
At time: 92.58062839508057 and batch: 1300, loss is 4.028441281318664 and perplexity is 56.173284624106614
At time: 92.97335982322693 and batch: 1350, loss is 3.9966466522216795 and perplexity is 54.41537008168138
At time: 93.34270358085632 and batch: 1400, loss is 3.8635491561889648 and perplexity is 47.634112617290164
At time: 93.72134828567505 and batch: 1450, loss is 3.958039402961731 and perplexity is 52.354579026776285
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.6006161942441235 and perplexity of 99.54563619535871
Finished 8 epochs...
Completing Train Step...
At time: 95.05672097206116 and batch: 50, loss is 4.164034242630005 and perplexity is 64.33052475527275
At time: 95.43968749046326 and batch: 100, loss is 4.178065371513367 and perplexity is 65.23951681872781
At time: 95.83786964416504 and batch: 150, loss is 4.001442260742188 and perplexity is 54.676951614086725
At time: 96.20414209365845 and batch: 200, loss is 4.109463958740235 and perplexity is 60.914056369015256
At time: 96.5714602470398 and batch: 250, loss is 4.167972826957703 and perplexity is 64.58439556949183
At time: 96.93616485595703 and batch: 300, loss is 4.175350131988526 and perplexity is 65.06261617657154
At time: 97.30346894264221 and batch: 350, loss is 4.157756495475769 and perplexity is 63.92793897459093
At time: 97.6859803199768 and batch: 400, loss is 3.9868091678619386 and perplexity is 53.882684170166684
At time: 98.06689500808716 and batch: 450, loss is 4.066155624389649 and perplexity is 58.33227979234488
At time: 98.45129799842834 and batch: 500, loss is 4.05713369846344 and perplexity is 57.80837714398413
At time: 98.82536172866821 and batch: 550, loss is 4.08838942527771 and perplexity is 59.64375358424852
At time: 99.20039629936218 and batch: 600, loss is 4.013522634506225 and perplexity is 55.341475392226634
At time: 99.59181118011475 and batch: 650, loss is 4.084211549758911 and perplexity is 59.39508921239096
At time: 99.95425701141357 and batch: 700, loss is 4.147642674446106 and perplexity is 63.28464182067786
At time: 100.3266270160675 and batch: 750, loss is 4.08688099861145 and perplexity is 59.55385317699825
At time: 100.72493290901184 and batch: 800, loss is 4.021672148704528 and perplexity is 55.79432427457751
At time: 101.12402844429016 and batch: 850, loss is 3.9875803136825563 and perplexity is 53.92425160208397
At time: 101.50907158851624 and batch: 900, loss is 3.9037572526931763 and perplexity is 49.58841573351497
At time: 101.88250875473022 and batch: 950, loss is 4.034441118240356 and perplexity is 56.511328260477185
At time: 102.26725101470947 and batch: 1000, loss is 4.048398537635803 and perplexity is 57.305610742016135
At time: 102.63603448867798 and batch: 1050, loss is 3.960894455909729 and perplexity is 52.50426770483858
At time: 103.02029824256897 and batch: 1100, loss is 4.123910398483276 and perplexity is 61.80043470394205
At time: 103.39402723312378 and batch: 1150, loss is 4.033043866157532 and perplexity is 56.43242282758961
At time: 103.75648736953735 and batch: 1200, loss is 3.9760902738571167 and perplexity is 53.30820577672088
At time: 104.1312108039856 and batch: 1250, loss is 3.921926746368408 and perplexity is 50.49764726420554
At time: 104.50525259971619 and batch: 1300, loss is 4.008158264160156 and perplexity is 55.04539806694145
At time: 104.87488150596619 and batch: 1350, loss is 3.978086819648743 and perplexity is 53.4147443698231
At time: 105.23601698875427 and batch: 1400, loss is 3.850698390007019 and perplexity is 47.02589418040829
At time: 105.61194634437561 and batch: 1450, loss is 3.9445731115341185 and perplexity is 51.6542827873248
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.596912351428953 and perplexity of 99.17761676972898
Finished 9 epochs...
Completing Train Step...
At time: 106.91210651397705 and batch: 50, loss is 4.127878794670105 and perplexity is 62.04617057953062
At time: 107.30298495292664 and batch: 100, loss is 4.144073004722595 and perplexity is 63.05913927506842
At time: 107.6842086315155 and batch: 150, loss is 3.9680083799362182 and perplexity is 52.879110798166856
At time: 108.0476086139679 and batch: 200, loss is 4.077524390220642 and perplexity is 58.99922983760717
At time: 108.42879295349121 and batch: 250, loss is 4.13518536567688 and perplexity is 62.50117556946332
At time: 108.78870558738708 and batch: 300, loss is 4.142754225730896 and perplexity is 62.976033018395235
At time: 109.16588497161865 and batch: 350, loss is 4.126031470298767 and perplexity is 61.931656980917495
At time: 109.52826738357544 and batch: 400, loss is 3.955998592376709 and perplexity is 52.247842199593194
At time: 109.91411423683167 and batch: 450, loss is 4.03386281490326 and perplexity is 56.47865701861502
At time: 110.31025075912476 and batch: 500, loss is 4.027737703323364 and perplexity is 56.13377623736692
At time: 110.69366097450256 and batch: 550, loss is 4.056872568130493 and perplexity is 57.79328359399102
At time: 111.07006740570068 and batch: 600, loss is 3.9865226268768312 and perplexity is 53.86724678459179
At time: 111.44490313529968 and batch: 650, loss is 4.055854940414429 and perplexity is 57.734501461040004
At time: 111.81101298332214 and batch: 700, loss is 4.118871397972107 and perplexity is 61.48980556934115
At time: 112.18257784843445 and batch: 750, loss is 4.061299924850464 and perplexity is 58.04972233048009
At time: 112.55790519714355 and batch: 800, loss is 3.9952854776382445 and perplexity is 54.34135165041009
At time: 112.93652749061584 and batch: 850, loss is 3.9638982725143435 and perplexity is 52.66221800408496
At time: 113.31157755851746 and batch: 900, loss is 3.8794615268707275 and perplexity is 48.39814695184396
At time: 113.69299864768982 and batch: 950, loss is 4.013666429519653 and perplexity is 55.349433792599214
At time: 114.07527112960815 and batch: 1000, loss is 4.027015142440796 and perplexity is 56.09323081649853
At time: 114.44822239875793 and batch: 1050, loss is 3.9404575300216673 and perplexity is 51.44213223693849
At time: 114.81923699378967 and batch: 1100, loss is 4.1055417108535766 and perplexity is 60.675604279951386
At time: 115.1869478225708 and batch: 1150, loss is 4.013038635253906 and perplexity is 55.314696640485224
At time: 115.55842566490173 and batch: 1200, loss is 3.956286907196045 and perplexity is 52.26290819854867
At time: 115.93458962440491 and batch: 1250, loss is 3.9023280334472656 and perplexity is 49.517593637581186
At time: 116.29620337486267 and batch: 1300, loss is 3.9878836727142333 and perplexity is 53.94061249232033
At time: 116.65710878372192 and batch: 1350, loss is 3.960138649940491 and perplexity is 52.46459965845824
At time: 117.02012348175049 and batch: 1400, loss is 3.836503310203552 and perplexity is 46.36307338656451
At time: 117.39316701889038 and batch: 1450, loss is 3.929399847984314 and perplexity is 50.87643491000677
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.5943864349626065 and perplexity of 98.92741851740736
Finished 10 epochs...
Completing Train Step...
At time: 118.65589785575867 and batch: 50, loss is 4.096957693099975 and perplexity is 60.156992884815075
At time: 119.04076385498047 and batch: 100, loss is 4.115703387260437 and perplexity is 61.295313445869155
At time: 119.40873074531555 and batch: 150, loss is 3.941514210700989 and perplexity is 51.49651887376998
At time: 119.78609681129456 and batch: 200, loss is 4.051885485649109 and perplexity is 57.50578121674441
At time: 120.15081596374512 and batch: 250, loss is 4.108443007469178 and perplexity is 60.85189782156329
At time: 120.52945518493652 and batch: 300, loss is 4.117094869613648 and perplexity is 61.38066416109913
At time: 120.8987340927124 and batch: 350, loss is 4.100933156013489 and perplexity is 60.396620779325026
At time: 121.28089833259583 and batch: 400, loss is 3.92907329082489 and perplexity is 50.85982355836647
At time: 121.64955115318298 and batch: 450, loss is 4.008637919425964 and perplexity is 55.07180721511993
At time: 122.01009917259216 and batch: 500, loss is 4.001967282295227 and perplexity is 54.70566572924368
At time: 122.38287234306335 and batch: 550, loss is 4.030811634063721 and perplexity is 56.306593055099945
At time: 122.75364708900452 and batch: 600, loss is 3.9641364145278932 and perplexity is 52.674760584116804
At time: 123.11371755599976 and batch: 650, loss is 4.032032361030579 and perplexity is 56.37537000205034
At time: 123.47950172424316 and batch: 700, loss is 4.0956153345108035 and perplexity is 60.0762948037162
At time: 123.85113859176636 and batch: 750, loss is 4.039670491218567 and perplexity is 56.80762111114865
At time: 124.2347731590271 and batch: 800, loss is 3.974164538383484 and perplexity is 53.20564705599881
At time: 124.60509419441223 and batch: 850, loss is 3.9426238489151 and perplexity is 51.553693094489574
At time: 124.97069501876831 and batch: 900, loss is 3.8582568407058715 and perplexity is 47.38268377279287
At time: 125.331866979599 and batch: 950, loss is 3.993423647880554 and perplexity is 54.24027143111312
At time: 125.70762705802917 and batch: 1000, loss is 4.006646823883057 and perplexity is 54.962263077846096
At time: 126.087566614151 and batch: 1050, loss is 3.9212494230270387 and perplexity is 50.463455609739256
At time: 126.46434664726257 and batch: 1100, loss is 4.08735426902771 and perplexity is 59.58204492451502
At time: 126.8240385055542 and batch: 1150, loss is 3.9953384971618653 and perplexity is 54.344232879367524
At time: 127.20976376533508 and batch: 1200, loss is 3.9378358364105224 and perplexity is 51.307443361137985
At time: 127.59486484527588 and batch: 1250, loss is 3.8867146301269533 and perplexity is 48.75045984546977
At time: 127.96596693992615 and batch: 1300, loss is 3.9709200191497804 and perplexity is 53.03330005355614
At time: 128.36102437973022 and batch: 1350, loss is 3.942346839904785 and perplexity is 51.53941423476508
At time: 128.73231649398804 and batch: 1400, loss is 3.822058973312378 and perplexity is 45.69820290167372
At time: 129.1232852935791 and batch: 1450, loss is 3.912533140182495 and perplexity is 50.02551324476059
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.59294193626469 and perplexity of 98.78462115030598
Finished 11 epochs...
Completing Train Step...
At time: 130.38444256782532 and batch: 50, loss is 4.070936117172241 and perplexity is 58.61180443531973
At time: 130.75346684455872 and batch: 100, loss is 4.091108894348144 and perplexity is 59.80617367547442
At time: 131.12322235107422 and batch: 150, loss is 3.91936975479126 and perplexity is 50.36869014687892
At time: 131.50358653068542 and batch: 200, loss is 4.027959213256836 and perplexity is 56.14621180365668
At time: 131.8754367828369 and batch: 250, loss is 4.084881119728088 and perplexity is 59.43487169753655
At time: 132.2465009689331 and batch: 300, loss is 4.09448926448822 and perplexity is 60.008682764159836
At time: 132.61933541297913 and batch: 350, loss is 4.079198522567749 and perplexity is 59.098085082025264
At time: 132.99204230308533 and batch: 400, loss is 3.9059551191329955 and perplexity is 49.69752430737405
At time: 133.37519097328186 and batch: 450, loss is 3.986208128929138 and perplexity is 53.85030830972756
At time: 133.74621057510376 and batch: 500, loss is 3.9791496419906616 and perplexity is 53.471544932634025
At time: 134.12082886695862 and batch: 550, loss is 4.008093528747558 and perplexity is 55.04183479572215
At time: 134.5254602432251 and batch: 600, loss is 3.944469485282898 and perplexity is 51.64893032497267
At time: 134.89191937446594 and batch: 650, loss is 4.010605440139771 and perplexity is 55.18026880178252
At time: 135.25743794441223 and batch: 700, loss is 4.074459509849548 and perplexity is 58.818681077675336
At time: 135.63567185401917 and batch: 750, loss is 4.018899145126343 and perplexity is 55.63982073216486
At time: 136.01630067825317 and batch: 800, loss is 3.95529851436615 and perplexity is 52.211277434757406
At time: 136.38604426383972 and batch: 850, loss is 3.924249839782715 and perplexity is 50.61509438349818
At time: 136.763245344162 and batch: 900, loss is 3.8390214347839358 and perplexity is 46.47996849773889
At time: 137.15350341796875 and batch: 950, loss is 3.976147575378418 and perplexity is 53.3112605055292
At time: 137.52547025680542 and batch: 1000, loss is 3.9893591833114623 and perplexity is 54.020261184467955
At time: 137.9000744819641 and batch: 1050, loss is 3.9040017986297606 and perplexity is 49.60054386196608
At time: 138.27627801895142 and batch: 1100, loss is 4.071901021003723 and perplexity is 58.66838648371704
At time: 138.64126348495483 and batch: 1150, loss is 3.979345736503601 and perplexity is 53.482031437333134
At time: 139.02794814109802 and batch: 1200, loss is 3.920495324134827 and perplexity is 50.42541551856475
At time: 139.40667247772217 and batch: 1250, loss is 3.8707373094558717 and perplexity is 47.97774748996241
At time: 139.7755148410797 and batch: 1300, loss is 3.9530906438827516 and perplexity is 52.0961288597548
At time: 140.16061782836914 and batch: 1350, loss is 3.92542818069458 and perplexity is 50.6747713729822
At time: 140.54360103607178 and batch: 1400, loss is 3.8087479305267333 and perplexity is 45.09394275601778
At time: 140.91853713989258 and batch: 1450, loss is 3.89630961894989 and perplexity is 49.220471233894955
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.593511076055021 and perplexity of 98.8408594110733
Annealing...
Finished 12 epochs...
Completing Train Step...
At time: 142.18312287330627 and batch: 50, loss is 4.057336630821228 and perplexity is 57.82010952465743
At time: 142.5453474521637 and batch: 100, loss is 4.077318129539489 and perplexity is 58.98706187120304
At time: 142.9224133491516 and batch: 150, loss is 3.898340301513672 and perplexity is 49.32052393987146
At time: 143.30127716064453 and batch: 200, loss is 4.006127643585205 and perplexity is 54.93373515993798
At time: 143.68834471702576 and batch: 250, loss is 4.05972499370575 and perplexity is 57.958369970560796
At time: 144.0600779056549 and batch: 300, loss is 4.059547762870789 and perplexity is 57.94809887046266
At time: 144.4434049129486 and batch: 350, loss is 4.037682738304138 and perplexity is 56.694813750446514
At time: 144.8236541748047 and batch: 400, loss is 3.8603741359710693 and perplexity is 47.48311318664034
At time: 145.2069022655487 and batch: 450, loss is 3.9457164287567137 and perplexity is 51.71337379190111
At time: 145.57992386817932 and batch: 500, loss is 3.927164454460144 and perplexity is 50.762833076583014
At time: 145.96049213409424 and batch: 550, loss is 3.9594779920578005 and perplexity is 52.429949954192104
At time: 146.33301043510437 and batch: 600, loss is 3.8996792364120485 and perplexity is 49.38660513992097
At time: 146.69197297096252 and batch: 650, loss is 3.953827910423279 and perplexity is 52.13455175467107
At time: 147.0772397518158 and batch: 700, loss is 4.014280877113342 and perplexity is 55.38345356961985
At time: 147.45700478553772 and batch: 750, loss is 3.95678174495697 and perplexity is 52.28877625873973
At time: 147.8172585964203 and batch: 800, loss is 3.895904264450073 and perplexity is 49.20052353761456
At time: 148.1905071735382 and batch: 850, loss is 3.8496820402145384 and perplexity is 46.978123702486585
At time: 148.59588599205017 and batch: 900, loss is 3.7637131786346436 and perplexity is 43.10819760321661
At time: 148.9650309085846 and batch: 950, loss is 3.900024824142456 and perplexity is 49.403675494186416
At time: 149.3247447013855 and batch: 1000, loss is 3.9101863718032837 and perplexity is 49.90825259772925
At time: 149.6963140964508 and batch: 1050, loss is 3.820812602043152 and perplexity is 45.64128145451865
At time: 150.06978130340576 and batch: 1100, loss is 3.9848226070404054 and perplexity is 53.77574919242136
At time: 150.42857909202576 and batch: 1150, loss is 3.88555184841156 and perplexity is 48.69380664617979
At time: 150.80211973190308 and batch: 1200, loss is 3.8292401885986327 and perplexity is 46.027552685380776
At time: 151.18656420707703 and batch: 1250, loss is 3.7714236783981323 and perplexity is 43.44186808060136
At time: 151.55723524093628 and batch: 1300, loss is 3.849507842063904 and perplexity is 46.96994091295142
At time: 151.9450557231903 and batch: 1350, loss is 3.8143915700912476 and perplexity is 45.34915620444018
At time: 152.3290090560913 and batch: 1400, loss is 3.69688419342041 and perplexity is 40.321474515543315
At time: 152.72095847129822 and batch: 1450, loss is 3.7854608488082886 and perplexity is 44.05596902195115
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.546206743289263 and perplexity of 94.27412326023176
Finished 13 epochs...
Completing Train Step...
At time: 153.9769470691681 and batch: 50, loss is 4.018574132919311 and perplexity is 55.62174004961026
At time: 154.3670244216919 and batch: 100, loss is 4.039837894439697 and perplexity is 56.81713168593558
At time: 154.73736095428467 and batch: 150, loss is 3.8616318130493164 and perplexity is 47.542869178693145
At time: 155.1074023246765 and batch: 200, loss is 3.9741101980209352 and perplexity is 53.20275592040153
At time: 155.46770119667053 and batch: 250, loss is 4.030493488311768 and perplexity is 56.28868220099468
At time: 155.83605885505676 and batch: 300, loss is 4.03369246006012 and perplexity is 56.46903642533847
At time: 156.20525288581848 and batch: 350, loss is 4.01369204044342 and perplexity is 55.350851360881144
At time: 156.57288718223572 and batch: 400, loss is 3.8361382341384886 and perplexity is 46.346150427439916
At time: 156.93399167060852 and batch: 450, loss is 3.9222094869613646 and perplexity is 50.511927017573775
At time: 157.31320095062256 and batch: 500, loss is 3.9061953020095825 and perplexity is 49.709462235306994
At time: 157.68180084228516 and batch: 550, loss is 3.9404712200164793 and perplexity is 51.44283648428249
At time: 158.06384015083313 and batch: 600, loss is 3.881416473388672 and perplexity is 48.49285528540275
At time: 158.43641328811646 and batch: 650, loss is 3.9348740577697754 and perplexity is 51.15570688712453
At time: 158.8108105659485 and batch: 700, loss is 3.997719030380249 and perplexity is 54.47375523593434
At time: 159.1999146938324 and batch: 750, loss is 3.9432688999176024 and perplexity is 51.586958583718
At time: 159.58135342597961 and batch: 800, loss is 3.8826882791519166 and perplexity is 48.554568013214045
At time: 159.9660885334015 and batch: 850, loss is 3.838296904563904 and perplexity is 46.446304552681546
At time: 160.33941435813904 and batch: 900, loss is 3.752332706451416 and perplexity is 42.620386982020726
At time: 160.72623682022095 and batch: 950, loss is 3.8912593078613282 and perplexity is 48.97251918673923
At time: 161.1041977405548 and batch: 1000, loss is 3.9031864500045774 and perplexity is 49.56011860929652
At time: 161.4800455570221 and batch: 1050, loss is 3.8152773332595826 and perplexity is 45.389342611913506
At time: 161.8587634563446 and batch: 1100, loss is 3.9801021671295165 and perplexity is 53.52250218857661
At time: 162.23136353492737 and batch: 1150, loss is 3.8824741220474244 and perplexity is 48.544170820874506
At time: 162.60366535186768 and batch: 1200, loss is 3.826672005653381 and perplexity is 45.909497168531885
At time: 162.98827958106995 and batch: 1250, loss is 3.7697798585891724 and perplexity is 43.370516138247304
At time: 163.35861539840698 and batch: 1300, loss is 3.8506655740737914 and perplexity is 47.02435100712536
At time: 163.73183012008667 and batch: 1350, loss is 3.816805601119995 and perplexity is 45.4587627181797
At time: 164.10520386695862 and batch: 1400, loss is 3.7014644527435303 and perplexity is 40.50658091917188
At time: 164.46836113929749 and batch: 1450, loss is 3.791553621292114 and perplexity is 44.32521140113804
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.543967222556089 and perplexity of 94.06323064392556
Finished 14 epochs...
Completing Train Step...
At time: 165.6892113685608 and batch: 50, loss is 4.004705080986023 and perplexity is 54.85564404078811
At time: 166.08193588256836 and batch: 100, loss is 4.026839141845703 and perplexity is 56.08335924322103
At time: 166.45694375038147 and batch: 150, loss is 3.848936524391174 and perplexity is 46.94311381974671
At time: 166.83399200439453 and batch: 200, loss is 3.962155804634094 and perplexity is 52.57053568065914
At time: 167.21241998672485 and batch: 250, loss is 4.018896145820618 and perplexity is 55.639653851582224
At time: 167.58350491523743 and batch: 300, loss is 4.021949238777161 and perplexity is 55.80978647005474
At time: 167.95869541168213 and batch: 350, loss is 4.002595109939575 and perplexity is 54.740022242346804
At time: 168.3573455810547 and batch: 400, loss is 3.8248855781555178 and perplexity is 45.82755639279605
At time: 168.7280716896057 and batch: 450, loss is 3.910883374214172 and perplexity is 49.94305089595319
At time: 169.11007404327393 and batch: 500, loss is 3.895535526275635 and perplexity is 49.182384770817286
At time: 169.485018491745 and batch: 550, loss is 3.931400113105774 and perplexity is 50.978303116006146
At time: 169.8601746559143 and batch: 600, loss is 3.8731777811050416 and perplexity is 48.09497881417942
At time: 170.25093579292297 and batch: 650, loss is 3.925235514640808 and perplexity is 50.665009005224604
At time: 170.63502955436707 and batch: 700, loss is 3.9888072490692137 and perplexity is 53.990453779165556
At time: 170.99947118759155 and batch: 750, loss is 3.935808458328247 and perplexity is 51.203529147302696
At time: 171.36284184455872 and batch: 800, loss is 3.8755152559280397 and perplexity is 48.20753110910119
At time: 171.73072862625122 and batch: 850, loss is 3.832006769180298 and perplexity is 46.155067928125824
At time: 172.10275602340698 and batch: 900, loss is 3.7455910444259644 and perplexity is 42.334021113155806
At time: 172.47829461097717 and batch: 950, loss is 3.8856465339660646 and perplexity is 48.69841746454852
At time: 172.85151839256287 and batch: 1000, loss is 3.8987437152862547 and perplexity is 49.34042453231645
At time: 173.2333903312683 and batch: 1050, loss is 3.8113490104675294 and perplexity is 45.211388382487435
At time: 173.60015177726746 and batch: 1100, loss is 3.9768128299713137 and perplexity is 53.3467378658636
At time: 173.97289633750916 and batch: 1150, loss is 3.879683156013489 and perplexity is 48.408874580397786
At time: 174.34406757354736 and batch: 1200, loss is 3.824092721939087 and perplexity is 45.79123613010186
At time: 174.7257797718048 and batch: 1250, loss is 3.7674767637252806 and perplexity is 43.27074466097444
At time: 175.09741258621216 and batch: 1300, loss is 3.849785957336426 and perplexity is 46.98300578755514
At time: 175.46885228157043 and batch: 1350, loss is 3.8162292003631593 and perplexity is 45.432567803053814
At time: 175.8464117050171 and batch: 1400, loss is 3.701809468269348 and perplexity is 40.52055872962895
At time: 176.21949195861816 and batch: 1450, loss is 3.792331266403198 and perplexity is 44.35969409099176
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.543232192341079 and perplexity of 93.99411673079966
Finished 15 epochs...
Completing Train Step...
At time: 177.48249220848083 and batch: 50, loss is 3.9942897081375124 and perplexity is 54.2872671221389
At time: 177.8641321659088 and batch: 100, loss is 4.017070698738098 and perplexity is 55.53817925421859
At time: 178.24940943717957 and batch: 150, loss is 3.8393574285507204 and perplexity is 46.49558810133225
At time: 178.62567234039307 and batch: 200, loss is 3.953143434524536 and perplexity is 52.098879120425174
At time: 178.99854063987732 and batch: 250, loss is 4.010209665298462 and perplexity is 55.15843416073994
At time: 179.3845353126526 and batch: 300, loss is 4.0129375171661374 and perplexity is 55.309103606918626
At time: 179.76252222061157 and batch: 350, loss is 3.99420392036438 and perplexity is 54.28261013814205
At time: 180.13789057731628 and batch: 400, loss is 3.816496753692627 and perplexity is 45.4447250641211
At time: 180.50032687187195 and batch: 450, loss is 3.9023971366882324 and perplexity is 49.52101558201878
At time: 180.87903594970703 and batch: 500, loss is 3.8873505544662477 and perplexity is 48.7814713088644
At time: 181.25957083702087 and batch: 550, loss is 3.9243918085098266 and perplexity is 50.62228065412121
At time: 181.6188097000122 and batch: 600, loss is 3.866960482597351 and perplexity is 47.79688560164055
At time: 182.00262093544006 and batch: 650, loss is 3.917728247642517 and perplexity is 50.28607740518336
At time: 182.39753031730652 and batch: 700, loss is 3.9818623161315916 and perplexity is 53.616792725746194
At time: 182.76494932174683 and batch: 750, loss is 3.9298649835586548 and perplexity is 50.900104854218846
At time: 183.1460177898407 and batch: 800, loss is 3.869753861427307 and perplexity is 47.930587062494155
At time: 183.52732491493225 and batch: 850, loss is 3.8266915607452394 and perplexity is 45.91039494174417
At time: 183.90834784507751 and batch: 900, loss is 3.739925513267517 and perplexity is 42.09485454004808
At time: 184.28208780288696 and batch: 950, loss is 3.8806641197204588 and perplexity is 48.45638522875737
At time: 184.6549026966095 and batch: 1000, loss is 3.8947760915756224 and perplexity is 49.14504814035381
At time: 185.0303065776825 and batch: 1050, loss is 3.8076260757446287 and perplexity is 45.0433822667591
At time: 185.3983952999115 and batch: 1100, loss is 3.97355703830719 and perplexity is 53.17333443730593
At time: 185.7712378501892 and batch: 1150, loss is 3.8765889549255372 and perplexity is 48.25931928440558
At time: 186.141921043396 and batch: 1200, loss is 3.821032347679138 and perplexity is 45.65131202898622
At time: 186.50623869895935 and batch: 1250, loss is 3.764614815711975 and perplexity is 43.14708308017218
At time: 186.89581418037415 and batch: 1300, loss is 3.8477445316314696 and perplexity is 46.887191304193856
At time: 187.26646900177002 and batch: 1350, loss is 3.8143069696426393 and perplexity is 45.345319807764
At time: 187.63976454734802 and batch: 1400, loss is 3.7006469345092774 and perplexity is 40.47347958297974
At time: 188.0131824016571 and batch: 1450, loss is 3.791287035942078 and perplexity is 44.31339652404778
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.542913453191773 and perplexity of 93.96416190013541
Finished 16 epochs...
Completing Train Step...
At time: 189.2710521221161 and batch: 50, loss is 3.9855005025863646 and perplexity is 53.8122158921897
At time: 189.6429407596588 and batch: 100, loss is 4.0088728380203245 and perplexity is 55.08474612639572
At time: 190.02686405181885 and batch: 150, loss is 3.8312470626831057 and perplexity is 46.12001693906036
At time: 190.40544962882996 and batch: 200, loss is 3.945558958053589 and perplexity is 51.70523109170434
At time: 190.7764208316803 and batch: 250, loss is 4.0028599262237545 and perplexity is 54.75452021119732
At time: 191.1408233642578 and batch: 300, loss is 4.00528881072998 and perplexity is 54.88767425942482
At time: 191.50738668441772 and batch: 350, loss is 3.987059545516968 and perplexity is 53.89617687934185
At time: 191.87975430488586 and batch: 400, loss is 3.8092755317687987 and perplexity is 45.1177406535736
At time: 192.24170327186584 and batch: 450, loss is 3.8951477336883547 and perplexity is 49.16331590419993
At time: 192.60693430900574 and batch: 500, loss is 3.8803196144104004 and perplexity is 48.43969462190625
At time: 192.96695804595947 and batch: 550, loss is 3.918267960548401 and perplexity is 50.31322477537926
At time: 193.35330533981323 and batch: 600, loss is 3.861582679748535 and perplexity is 47.54053329798702
At time: 193.7438542842865 and batch: 650, loss is 3.9111376762390138 and perplexity is 49.955753129956264
At time: 194.12697339057922 and batch: 700, loss is 3.9757639741897584 and perplexity is 53.29081416450143
At time: 194.51054406166077 and batch: 750, loss is 3.9244698524475097 and perplexity is 50.626231570408486
At time: 194.88151502609253 and batch: 800, loss is 3.8645345067977903 and perplexity is 47.68107205111236
At time: 195.25937914848328 and batch: 850, loss is 3.8219692754745482 and perplexity is 45.6941040555123
At time: 195.6270887851715 and batch: 900, loss is 3.734698781967163 and perplexity is 41.87541003455091
At time: 196.00331282615662 and batch: 950, loss is 3.8759376430511474 and perplexity is 48.2278976504581
At time: 196.412531375885 and batch: 1000, loss is 3.890914435386658 and perplexity is 48.95563282484453
At time: 196.7731659412384 and batch: 1050, loss is 3.804006018638611 and perplexity is 44.88061743744392
At time: 197.1467342376709 and batch: 1100, loss is 3.970245485305786 and perplexity is 52.99753936006624
At time: 197.51402807235718 and batch: 1150, loss is 3.873311176300049 and perplexity is 48.10139488118395
At time: 197.89584684371948 and batch: 1200, loss is 3.8178103876113894 and perplexity is 45.5044620240522
At time: 198.25586128234863 and batch: 1250, loss is 3.7614920711517335 and perplexity is 43.01255591749649
At time: 198.61808156967163 and batch: 1300, loss is 3.845155563354492 and perplexity is 46.76595885450987
At time: 198.98688530921936 and batch: 1350, loss is 3.811773643493652 and perplexity is 45.230590707833734
At time: 199.36880207061768 and batch: 1400, loss is 3.698715329170227 and perplexity is 40.39537625041867
At time: 199.74201941490173 and batch: 1450, loss is 3.7894043827056887 and perplexity is 44.23004824723611
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.542757996127137 and perplexity of 93.94955564269777
Finished 17 epochs...
Completing Train Step...
At time: 200.9899444580078 and batch: 50, loss is 3.9776464891433716 and perplexity is 53.39122940599835
At time: 201.37870979309082 and batch: 100, loss is 4.001603088378906 and perplexity is 54.68574588615983
At time: 201.75641679763794 and batch: 150, loss is 3.8240962171554567 and perplexity is 45.79139618065967
At time: 202.13192987442017 and batch: 200, loss is 3.9386223220825194 and perplexity is 51.34781180272791
At time: 202.5109498500824 and batch: 250, loss is 3.9963571310043333 and perplexity is 54.39961795789005
At time: 202.89281296730042 and batch: 300, loss is 3.99843599319458 and perplexity is 54.512824896868906
At time: 203.2807376384735 and batch: 350, loss is 3.980619568824768 and perplexity is 53.55020198728654
At time: 203.65157270431519 and batch: 400, loss is 3.802824492454529 and perplexity is 44.82762112721316
At time: 204.03448843955994 and batch: 450, loss is 3.888668637275696 and perplexity is 48.845811721296876
At time: 204.40212774276733 and batch: 500, loss is 3.87403902053833 and perplexity is 48.1364179484242
At time: 204.77594423294067 and batch: 550, loss is 3.9126728773117065 and perplexity is 50.03250415480221
At time: 205.15246629714966 and batch: 600, loss is 3.8567517709732058 and perplexity is 47.311423169134656
At time: 205.54196619987488 and batch: 650, loss is 3.9051448774337767 and perplexity is 49.65727360943124
At time: 205.9433889389038 and batch: 700, loss is 3.9702500772476195 and perplexity is 52.99778272224305
At time: 206.30926656723022 and batch: 750, loss is 3.9194611167907714 and perplexity is 50.373292141344024
At time: 206.66980457305908 and batch: 800, loss is 3.859719214439392 and perplexity is 47.452025654481616
At time: 207.033917427063 and batch: 850, loss is 3.817526330947876 and perplexity is 45.49153801405717
At time: 207.39167761802673 and batch: 900, loss is 3.7297456884384155 and perplexity is 41.66851003261744
At time: 207.76348876953125 and batch: 950, loss is 3.8715564966201783 and perplexity is 48.01706634743141
At time: 208.13413166999817 and batch: 1000, loss is 3.8871744155883787 and perplexity is 48.77287975192307
At time: 208.49509358406067 and batch: 1050, loss is 3.8004550409317015 and perplexity is 44.721529990606776
At time: 208.85576152801514 and batch: 1100, loss is 3.9668811988830566 and perplexity is 52.819540046185836
At time: 209.23141264915466 and batch: 1150, loss is 3.869964189529419 and perplexity is 47.94066927215296
At time: 209.6044783592224 and batch: 1200, loss is 3.8144446325302126 and perplexity is 45.35156260511757
At time: 209.98483395576477 and batch: 1250, loss is 3.758191914558411 and perplexity is 42.870841715636345
At time: 210.3628809452057 and batch: 1300, loss is 3.8422232484817505 and perplexity is 46.629027199304204
At time: 210.74641823768616 and batch: 1350, loss is 3.808826694488525 and perplexity is 45.09749467348177
At time: 211.11179208755493 and batch: 1400, loss is 3.6964936447143555 and perplexity is 40.30573009052758
At time: 211.48309087753296 and batch: 1450, loss is 3.786972007751465 and perplexity is 44.122594922022415
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.542735042735043 and perplexity of 93.94739920645885
Finished 18 epochs...
Completing Train Step...
At time: 212.73403525352478 and batch: 50, loss is 3.970334448814392 and perplexity is 53.00225441684609
At time: 213.12975335121155 and batch: 100, loss is 3.994939284324646 and perplexity is 54.322542293841416
At time: 213.49949312210083 and batch: 150, loss is 3.8176024961471557 and perplexity is 45.49500301807023
At time: 213.8624403476715 and batch: 200, loss is 3.9324206161499022 and perplexity is 51.03035318362955
At time: 214.2327218055725 and batch: 250, loss is 3.990454535484314 and perplexity is 54.07946481342683
At time: 214.60703468322754 and batch: 300, loss is 3.9922607374191283 and perplexity is 54.17723151402924
At time: 214.99191403388977 and batch: 350, loss is 3.9746365547180176 and perplexity is 53.23076691852499
At time: 215.36984539031982 and batch: 400, loss is 3.7968592071533203 and perplexity is 44.561007581359476
At time: 215.78175568580627 and batch: 450, loss is 3.882717533111572 and perplexity is 48.555988447364356
At time: 216.14240193367004 and batch: 500, loss is 3.8682080507278442 and perplexity is 47.85655268449053
At time: 216.51298642158508 and batch: 550, loss is 3.907513437271118 and perplexity is 49.775029233904306
At time: 216.88450050354004 and batch: 600, loss is 3.852242684364319 and perplexity is 47.09857210705028
At time: 217.24462795257568 and batch: 650, loss is 3.89958354473114 and perplexity is 49.3818794787676
At time: 217.61511993408203 and batch: 700, loss is 3.9650298404693602 and perplexity is 52.721842610703405
At time: 217.99231004714966 and batch: 750, loss is 3.914666938781738 and perplexity is 50.13237158138848
At time: 218.3656280040741 and batch: 800, loss is 3.8550523710250855 and perplexity is 47.231090417125976
At time: 218.75046062469482 and batch: 850, loss is 3.81320698261261 and perplexity is 45.2954679673185
At time: 219.13615155220032 and batch: 900, loss is 3.7249726486206054 and perplexity is 41.47009846492212
At time: 219.50579524040222 and batch: 950, loss is 3.8673946475982666 and perplexity is 47.81764184201205
At time: 219.87559032440186 and batch: 1000, loss is 3.8834205532073973 and perplexity is 48.590136284917094
At time: 220.24164009094238 and batch: 1050, loss is 3.796933903694153 and perplexity is 44.564336258800616
At time: 220.60805821418762 and batch: 1100, loss is 3.9634487199783326 and perplexity is 52.63854889108278
At time: 220.97878670692444 and batch: 1150, loss is 3.8665813302993772 and perplexity is 47.77876673775019
At time: 221.3677294254303 and batch: 1200, loss is 3.8110034132003783 and perplexity is 45.19576614987428
At time: 221.73492121696472 and batch: 1250, loss is 3.7548428058624266 and perplexity is 42.72750276967796
At time: 222.10061192512512 and batch: 1300, loss is 3.838980989456177 and perplexity is 46.4780886381948
At time: 222.46794533729553 and batch: 1350, loss is 3.8056313514709474 and perplexity is 44.95362269134704
At time: 222.83442616462708 and batch: 1400, loss is 3.693961892127991 and perplexity is 40.20381502043441
At time: 223.2110435962677 and batch: 1450, loss is 3.784266929626465 and perplexity is 44.00340114260613
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.542813292935363 and perplexity of 93.95475089689819
Annealing...
Finished 19 epochs...
Completing Train Step...
At time: 224.4955632686615 and batch: 50, loss is 3.9667974138259887 and perplexity is 52.81511474339848
At time: 224.88361978530884 and batch: 100, loss is 3.99671302318573 and perplexity is 54.41898180210823
At time: 225.27693629264832 and batch: 150, loss is 3.8174020051956177 and perplexity is 45.485882595936516
At time: 225.64032745361328 and batch: 200, loss is 3.931683201789856 and perplexity is 50.99273653962504
At time: 226.00631976127625 and batch: 250, loss is 3.993253035545349 and perplexity is 54.231018161125554
At time: 226.37239384651184 and batch: 300, loss is 3.9919700479507445 and perplexity is 54.16148505217811
At time: 226.7468285560608 and batch: 350, loss is 3.9706164836883544 and perplexity is 53.017205009185375
At time: 227.13721466064453 and batch: 400, loss is 3.790779366493225 and perplexity is 44.29090567589891
At time: 227.51501655578613 and batch: 450, loss is 3.8768312406539915 and perplexity is 48.27101324531582
At time: 227.87955975532532 and batch: 500, loss is 3.856956934928894 and perplexity is 47.321130763651475
At time: 228.2566065788269 and batch: 550, loss is 3.898680124282837 and perplexity is 49.33728702497106
At time: 228.62815380096436 and batch: 600, loss is 3.843789744377136 and perplexity is 46.70212862060726
At time: 228.99242639541626 and batch: 650, loss is 3.889742512702942 and perplexity is 48.89829421301377
At time: 229.38513445854187 and batch: 700, loss is 3.954520525932312 and perplexity is 52.17067346155603
At time: 229.7519371509552 and batch: 750, loss is 3.9032938289642334 and perplexity is 49.56544060900349
At time: 230.13014674186707 and batch: 800, loss is 3.842607464790344 and perplexity is 46.646946274188004
At time: 230.5051589012146 and batch: 850, loss is 3.7977913188934327 and perplexity is 44.60256278371458
At time: 230.87183904647827 and batch: 900, loss is 3.7073714542388916 and perplexity is 40.74656143807914
At time: 231.2374038696289 and batch: 950, loss is 3.8459887599945066 and perplexity is 46.804940331657264
At time: 231.59859037399292 and batch: 1000, loss is 3.8639149188995363 and perplexity is 47.65153858612726
At time: 231.96935033798218 and batch: 1050, loss is 3.775333523750305 and perplexity is 43.61205154532234
At time: 232.37180352210999 and batch: 1100, loss is 3.94333261013031 and perplexity is 51.59024530452004
At time: 232.74998807907104 and batch: 1150, loss is 3.8390575313568114 and perplexity is 46.48164629559022
At time: 233.11561226844788 and batch: 1200, loss is 3.7864757776260376 and perplexity is 44.10070539278119
At time: 233.48782062530518 and batch: 1250, loss is 3.728945755958557 and perplexity is 41.63519136617348
At time: 233.84978604316711 and batch: 1300, loss is 3.810411901473999 and perplexity is 45.169040229340894
At time: 234.23040533065796 and batch: 1350, loss is 3.775957775115967 and perplexity is 43.63928492741242
At time: 234.59646153450012 and batch: 1400, loss is 3.660464506149292 and perplexity is 38.87939839719269
At time: 234.96546697616577 and batch: 1450, loss is 3.752461552619934 and perplexity is 42.62587880937698
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.533915723490919 and perplexity of 93.1224900162563
Finished 20 epochs...
Completing Train Step...
At time: 236.24963188171387 and batch: 50, loss is 3.960197229385376 and perplexity is 52.46767309560159
At time: 236.6240999698639 and batch: 100, loss is 3.988042187690735 and perplexity is 53.94916356496067
At time: 236.9960241317749 and batch: 150, loss is 3.806180658340454 and perplexity is 44.97832280845153
At time: 237.3667221069336 and batch: 200, loss is 3.921657657623291 and perplexity is 50.48406074374372
At time: 237.72853088378906 and batch: 250, loss is 3.9822580814361572 and perplexity is 53.63801659160698
At time: 238.11412143707275 and batch: 300, loss is 3.9831851434707644 and perplexity is 53.68776541696128
At time: 238.49622511863708 and batch: 350, loss is 3.962857575416565 and perplexity is 52.60744109467471
At time: 238.87643146514893 and batch: 400, loss is 3.782884831428528 and perplexity is 43.94262612937632
At time: 239.24054598808289 and batch: 450, loss is 3.8693432903289793 and perplexity is 47.910912187964215
At time: 239.60148310661316 and batch: 500, loss is 3.8511674928665163 and perplexity is 47.04795933684809
At time: 239.9720640182495 and batch: 550, loss is 3.8935048627853392 and perplexity is 49.08261323319171
At time: 240.3426673412323 and batch: 600, loss is 3.8403551387786865 and perplexity is 46.54200037428597
At time: 240.70186161994934 and batch: 650, loss is 3.885244917869568 and perplexity is 48.67886332311266
At time: 241.082594871521 and batch: 700, loss is 3.9502804279327393 and perplexity is 51.94993300467397
At time: 241.4586956501007 and batch: 750, loss is 3.898727993965149 and perplexity is 49.339648841756336
At time: 241.83149695396423 and batch: 800, loss is 3.8386883115768433 and perplexity is 46.46448752024696
At time: 242.21173214912415 and batch: 850, loss is 3.7947405576705933 and perplexity is 44.46669836506055
At time: 242.58264207839966 and batch: 900, loss is 3.7044454193115235 and perplexity is 40.627509835654735
At time: 242.94284439086914 and batch: 950, loss is 3.8444978189468384 and perplexity is 46.73520892051192
At time: 243.3299698829651 and batch: 1000, loss is 3.8618993663787844 and perplexity is 47.55559113345915
At time: 243.71020030975342 and batch: 1050, loss is 3.774459652900696 and perplexity is 43.57395689211296
At time: 244.11986327171326 and batch: 1100, loss is 3.942498664855957 and perplexity is 51.54723979785754
At time: 244.49128890037537 and batch: 1150, loss is 3.838822503089905 and perplexity is 46.470723078501074
At time: 244.87205386161804 and batch: 1200, loss is 3.786771173477173 and perplexity is 44.11373448246113
At time: 245.24481511116028 and batch: 1250, loss is 3.7299930906295775 and perplexity is 41.67882018862697
At time: 245.6096441745758 and batch: 1300, loss is 3.811830816268921 and perplexity is 45.23317674015616
At time: 245.98306035995483 and batch: 1350, loss is 3.7777870988845823 and perplexity is 43.71918837092714
At time: 246.3577527999878 and batch: 1400, loss is 3.6625891304016114 and perplexity is 38.96209032347284
At time: 246.7156994342804 and batch: 1450, loss is 3.7555247926712036 and perplexity is 42.7566523016072
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.533403967180822 and perplexity of 93.07484618643363
Finished 21 epochs...
Completing Train Step...
At time: 248.05680656433105 and batch: 50, loss is 3.956556181907654 and perplexity is 52.27698317301398
At time: 248.45897126197815 and batch: 100, loss is 3.9847140455245973 and perplexity is 53.769911532453655
At time: 248.83089184761047 and batch: 150, loss is 3.8021579790115356 and perplexity is 44.79775287001766
At time: 249.1923589706421 and batch: 200, loss is 3.918249020576477 and perplexity is 50.31227185333879
At time: 249.55731225013733 and batch: 250, loss is 3.9786390018463136 and perplexity is 53.44424718546706
At time: 249.9496455192566 and batch: 300, loss is 3.980082893371582 and perplexity is 53.52147061876652
At time: 250.32370257377625 and batch: 350, loss is 3.9597453927993773 and perplexity is 52.44397163631124
At time: 250.69130897521973 and batch: 400, loss is 3.779918828010559 and perplexity is 43.812485244642545
At time: 251.07793354988098 and batch: 450, loss is 3.8660726499557496 and perplexity is 47.754468798733846
At time: 251.4525671005249 and batch: 500, loss is 3.8483539962768556 and perplexity is 46.91577609944145
At time: 251.82244539260864 and batch: 550, loss is 3.89110137462616 and perplexity is 48.96478540907606
At time: 252.218759059906 and batch: 600, loss is 3.8382956838607787 and perplexity is 46.44624785556703
At time: 252.5847201347351 and batch: 650, loss is 3.8829943418502806 and perplexity is 48.56943102970951
At time: 252.95210242271423 and batch: 700, loss is 3.9483416080474854 and perplexity is 51.84930901893979
At time: 253.31693863868713 and batch: 750, loss is 3.8966832971572876 and perplexity is 49.238867288241146
At time: 253.70811891555786 and batch: 800, loss is 3.836547055244446 and perplexity is 46.36510158546726
At time: 254.07173800468445 and batch: 850, loss is 3.7933457326889037 and perplexity is 44.404718339020754
At time: 254.452538728714 and batch: 900, loss is 3.7030234718322754 and perplexity is 40.569780704079406
At time: 254.8287148475647 and batch: 950, loss is 3.843562293052673 and perplexity is 46.69150736755209
At time: 255.1894073486328 and batch: 1000, loss is 3.8608628559112548 and perplexity is 47.50632480240447
At time: 255.56645226478577 and batch: 1050, loss is 3.773895583152771 and perplexity is 43.549385071994436
At time: 255.95144510269165 and batch: 1100, loss is 3.942038254737854 and perplexity is 51.52351238968287
At time: 256.31310200691223 and batch: 1150, loss is 3.8385601472854614 and perplexity is 46.45853281372803
At time: 256.67261958122253 and batch: 1200, loss is 3.786758232116699 and perplexity is 44.11316359441539
At time: 257.0318281650543 and batch: 1250, loss is 3.7302617025375366 and perplexity is 41.690017119786525
At time: 257.39312720298767 and batch: 1300, loss is 3.8124391269683837 and perplexity is 45.26070093632064
At time: 257.76091599464417 and batch: 1350, loss is 3.778340845108032 and perplexity is 43.743404410531284
At time: 258.1372106075287 and batch: 1400, loss is 3.663185954093933 and perplexity is 38.9853507625804
At time: 258.50816226005554 and batch: 1450, loss is 3.756593065261841 and perplexity is 42.80235246709939
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.533215645032051 and perplexity of 93.05731978176014
Finished 22 epochs...
Completing Train Step...
At time: 259.8220076560974 and batch: 50, loss is 3.9535165786743165 and perplexity is 52.118323139864515
At time: 260.2098925113678 and batch: 100, loss is 3.98209361076355 and perplexity is 53.62919543637138
At time: 260.59106278419495 and batch: 150, loss is 3.7991501760482786 and perplexity is 44.663212493091024
At time: 260.96264147758484 and batch: 200, loss is 3.9156715774536135 and perplexity is 50.18276180833908
At time: 261.34533429145813 and batch: 250, loss is 3.97605598449707 and perplexity is 53.30637790379805
At time: 261.72374153137207 and batch: 300, loss is 3.9777916049957276 and perplexity is 53.398977881961684
At time: 262.09040689468384 and batch: 350, loss is 3.9573799562454224 and perplexity is 52.3200653527686
At time: 262.4552471637726 and batch: 400, loss is 3.7777097988128663 and perplexity is 43.715809005145
At time: 262.8315875530243 and batch: 450, loss is 3.8635920667648316 and perplexity is 47.63615666834887
At time: 263.21787667274475 and batch: 500, loss is 3.8461777782440185 and perplexity is 46.81378815572103
At time: 263.6248745918274 and batch: 550, loss is 3.8893240594863894 and perplexity is 48.87783684504063
At time: 263.997362613678 and batch: 600, loss is 3.836734137535095 and perplexity is 46.37377648631292
At time: 264.38876843452454 and batch: 650, loss is 3.881257314682007 and perplexity is 48.48513783943867
At time: 264.77283930778503 and batch: 700, loss is 3.946877541542053 and perplexity is 51.77345372442293
At time: 265.15171098709106 and batch: 750, loss is 3.8951711320877074 and perplexity is 49.164466260557155
At time: 265.51634645462036 and batch: 800, loss is 3.8348341512680055 and perplexity is 46.285750598305754
At time: 265.8940284252167 and batch: 850, loss is 3.79225302696228 and perplexity is 44.35622354909518
At time: 266.27291440963745 and batch: 900, loss is 3.7018492364883424 and perplexity is 40.52217019212457
At time: 266.64422059059143 and batch: 950, loss is 3.8426463413238525 and perplexity is 46.6487597810091
At time: 267.0380074977875 and batch: 1000, loss is 3.859969253540039 and perplexity is 47.46389199976347
At time: 267.4202058315277 and batch: 1050, loss is 3.773304748535156 and perplexity is 43.52366218745168
At time: 267.7902235984802 and batch: 1100, loss is 3.9415787172317507 and perplexity is 51.49984084269204
At time: 268.158447265625 and batch: 1150, loss is 3.8381193017959596 and perplexity is 46.43805629291077
At time: 268.52734756469727 and batch: 1200, loss is 3.7864869117736815 and perplexity is 44.10119641927981
At time: 268.8936381340027 and batch: 1250, loss is 3.73015691280365 and perplexity is 41.68564866287553
At time: 269.28157091140747 and batch: 1300, loss is 3.8126103115081786 and perplexity is 45.268449531782174
At time: 269.6622107028961 and batch: 1350, loss is 3.778410301208496 and perplexity is 43.746442762337466
At time: 270.04061627388 and batch: 1400, loss is 3.663216247558594 and perplexity is 38.986531781814506
At time: 270.4031343460083 and batch: 1450, loss is 3.7569576501846313 and perplexity is 42.8179604045053
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.533129569811699 and perplexity of 93.04931019717286
Finished 23 epochs...
Completing Train Step...
At time: 271.72583627700806 and batch: 50, loss is 3.9508567905426024 and perplexity is 51.97988363402509
At time: 272.0954375267029 and batch: 100, loss is 3.979832353591919 and perplexity is 53.50806304094638
At time: 272.4648611545563 and batch: 150, loss is 3.796628866195679 and perplexity is 44.550744538244686
At time: 272.8397560119629 and batch: 200, loss is 3.9134903383255004 and perplexity is 50.07342049785037
At time: 273.2164855003357 and batch: 250, loss is 3.9739300537109377 and perplexity is 53.193172609861634
At time: 273.5890145301819 and batch: 300, loss is 3.9758474159240724 and perplexity is 53.29526102798274
At time: 273.9633905887604 and batch: 350, loss is 3.9553557014465333 and perplexity is 52.214263330653495
At time: 274.33302664756775 and batch: 400, loss is 3.7758263635635374 and perplexity is 43.63355059802001
At time: 274.716121673584 and batch: 450, loss is 3.8614455604553224 and perplexity is 47.53401502056325
At time: 275.1084270477295 and batch: 500, loss is 3.8442809343338014 and perplexity is 46.725073871917765
At time: 275.49238681793213 and batch: 550, loss is 3.887812099456787 and perplexity is 48.803991349184265
At time: 275.88130378723145 and batch: 600, loss is 3.8354012060165403 and perplexity is 46.31200459599555
At time: 276.2428216934204 and batch: 650, loss is 3.8797343730926515 and perplexity is 48.41135400505325
At time: 276.6131341457367 and batch: 700, loss is 3.9455937194824218 and perplexity is 51.70702847065477
At time: 276.9850854873657 and batch: 750, loss is 3.8938600397109986 and perplexity is 49.1000493411315
At time: 277.34494614601135 and batch: 800, loss is 3.833307538032532 and perplexity is 46.21514406697383
At time: 277.7129020690918 and batch: 850, loss is 3.791256890296936 and perplexity is 44.31206068825605
At time: 278.0843164920807 and batch: 900, loss is 3.7007471036911013 and perplexity is 40.477533981374634
At time: 278.45284485816956 and batch: 950, loss is 3.8417167806625367 and perplexity is 46.60541707697479
At time: 278.8321933746338 and batch: 1000, loss is 3.8591060733795164 and perplexity is 47.42293978695961
At time: 279.20065903663635 and batch: 1050, loss is 3.7726572132110596 and perplexity is 43.49548820156125
At time: 279.57114577293396 and batch: 1100, loss is 3.941049032211304 and perplexity is 51.47256937172472
At time: 279.9473006725311 and batch: 1150, loss is 3.837536344528198 and perplexity is 46.41099277969639
At time: 280.31923174858093 and batch: 1200, loss is 3.7860576915740967 and perplexity is 44.0822713567509
At time: 280.6938543319702 and batch: 1250, loss is 3.7298691368103025 and perplexity is 41.67365425985663
At time: 281.06754422187805 and batch: 1300, loss is 3.812534055709839 and perplexity is 45.264997681636984
At time: 281.4407329559326 and batch: 1350, loss is 3.7782268428802492 and perplexity is 43.73841784922263
At time: 281.81321358680725 and batch: 1400, loss is 3.6629915285110473 and perplexity is 38.977771749835235
At time: 282.1731209754944 and batch: 1450, loss is 3.7569813680648805 and perplexity is 42.81897596780614
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.533092531383547 and perplexity of 93.04586386080636
Finished 24 epochs...
Completing Train Step...
At time: 283.42687463760376 and batch: 50, loss is 3.9484298753738405 and perplexity is 51.853885820808316
At time: 283.79217076301575 and batch: 100, loss is 3.977777462005615 and perplexity is 53.398222666086006
At time: 284.16519951820374 and batch: 150, loss is 3.7943840503692625 and perplexity is 44.45084848789368
At time: 284.54065108299255 and batch: 200, loss is 3.911537094116211 and perplexity is 49.975710336192364
At time: 284.9030647277832 and batch: 250, loss is 3.9720557641983034 and perplexity is 53.09356657872434
At time: 285.27821946144104 and batch: 300, loss is 3.9741049909591677 and perplexity is 53.20247889108651
At time: 285.6552515029907 and batch: 350, loss is 3.953530468940735 and perplexity is 52.11904708228607
At time: 286.04154777526855 and batch: 400, loss is 3.7741206884384155 and perplexity is 43.55918937221921
At time: 286.43411207199097 and batch: 450, loss is 3.8594923973083497 and perplexity is 47.44126394267695
At time: 286.8003635406494 and batch: 500, loss is 3.8425467681884764 and perplexity is 46.6441150489854
At time: 287.1600933074951 and batch: 550, loss is 3.886441497802734 and perplexity is 48.737146337322905
At time: 287.53456687927246 and batch: 600, loss is 3.8341979932785035 and perplexity is 46.25631491212873
At time: 287.91057562828064 and batch: 650, loss is 3.87832754611969 and perplexity is 48.34329549094295
At time: 288.28802514076233 and batch: 700, loss is 3.9444000053405763 and perplexity is 51.64534188493645
At time: 288.6669919490814 and batch: 750, loss is 3.8926494026184084 and perplexity is 49.04064296718675
At time: 289.03912568092346 and batch: 800, loss is 3.831876068115234 and perplexity is 46.14903580580052
At time: 289.4232921600342 and batch: 850, loss is 3.790302586555481 and perplexity is 44.26979369393278
At time: 289.7944223880768 and batch: 900, loss is 3.6996778631210328 and perplexity is 40.43427689010512
At time: 290.16636848449707 and batch: 950, loss is 3.840782461166382 and perplexity is 46.56189306300694
At time: 290.53147554397583 and batch: 1000, loss is 3.8582482528686524 and perplexity is 47.382276859764886
At time: 290.8977973461151 and batch: 1050, loss is 3.7719781017303466 and perplexity is 43.46595994378863
At time: 291.26553201675415 and batch: 1100, loss is 3.9405022048950196 and perplexity is 51.44443045901715
At time: 291.62555480003357 and batch: 1150, loss is 3.8368804359436037 and perplexity is 46.38056139230777
At time: 292.04543447494507 and batch: 1200, loss is 3.7855398941040037 and perplexity is 44.059451576688474
At time: 292.4217720031738 and batch: 1250, loss is 3.729458065032959 and perplexity is 41.65652691725641
At time: 292.7912130355835 and batch: 1300, loss is 3.812302284240723 and perplexity is 45.254507762303746
At time: 293.1522288322449 and batch: 1350, loss is 3.7779035568237305 and perplexity is 43.72428011398725
At time: 293.5215654373169 and batch: 1400, loss is 3.662602858543396 and perplexity is 38.96262520424448
At time: 293.8915228843689 and batch: 1450, loss is 3.7568029832839964 and perplexity is 42.81133839539404
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.533087836371528 and perplexity of 93.04542701038271
Finished 25 epochs...
Completing Train Step...
At time: 295.1468801498413 and batch: 50, loss is 3.9461832857131958 and perplexity is 51.737522176681125
At time: 295.5479757785797 and batch: 100, loss is 3.975875015258789 and perplexity is 53.29673196202897
At time: 295.90630197525024 and batch: 150, loss is 3.7923309659957884 and perplexity is 44.35968076501297
At time: 296.2694208621979 and batch: 200, loss is 3.909739375114441 and perplexity is 49.885948759314466
At time: 296.6347391605377 and batch: 250, loss is 3.9703483152389527 and perplexity is 53.002989373704104
At time: 297.00752544403076 and batch: 300, loss is 3.9724928903579713 and perplexity is 53.11678023886539
At time: 297.36784267425537 and batch: 350, loss is 3.9518399953842165 and perplexity is 52.03101563977934
At time: 297.73457884788513 and batch: 400, loss is 3.772535562515259 and perplexity is 43.4901972669868
At time: 298.1080298423767 and batch: 450, loss is 3.8576744604110718 and perplexity is 47.35509706520603
At time: 298.46771693229675 and batch: 500, loss is 3.840919017791748 and perplexity is 46.56825183215043
At time: 298.8311092853546 and batch: 550, loss is 3.8851623582839965 and perplexity is 48.67484458222568
At time: 299.1978921890259 and batch: 600, loss is 3.8330703353881836 and perplexity is 46.20418301263914
At time: 299.5747609138489 and batch: 650, loss is 3.8769899797439575 and perplexity is 48.27867635023117
At time: 299.9467976093292 and batch: 700, loss is 3.9432557725906374 and perplexity is 51.58628138929043
At time: 300.30564308166504 and batch: 750, loss is 3.8914970111846925 and perplexity is 48.98416150095701
At time: 300.6684126853943 and batch: 800, loss is 3.830513663291931 and perplexity is 46.086204947079004
At time: 301.0402376651764 and batch: 850, loss is 3.789369044303894 and perplexity is 44.228485255636734
At time: 301.43781781196594 and batch: 900, loss is 3.6986236715316774 and perplexity is 40.39167387530131
At time: 301.80695128440857 and batch: 950, loss is 3.8398386335372923 and perplexity is 46.517967394262044
At time: 302.1809079647064 and batch: 1000, loss is 3.857390670776367 and perplexity is 47.341660086236345
At time: 302.5617756843567 and batch: 1050, loss is 3.7712662506103514 and perplexity is 43.435029661705066
At time: 302.9324486255646 and batch: 1100, loss is 3.9399002313613893 and perplexity is 51.413471592572144
At time: 303.2977430820465 and batch: 1150, loss is 3.8361560535430907 and perplexity is 46.34697629560435
At time: 303.6738636493683 and batch: 1200, loss is 3.784956760406494 and perplexity is 44.033766515420524
At time: 304.0431468486786 and batch: 1250, loss is 3.7289772844314575 and perplexity is 41.636504080870004
At time: 304.42952585220337 and batch: 1300, loss is 3.8119657754898073 and perplexity is 45.239281786404106
At time: 304.7997488975525 and batch: 1350, loss is 3.7774808549880983 and perplexity is 43.70580168622918
At time: 305.16841411590576 and batch: 1400, loss is 3.662131218910217 and perplexity is 38.944253218804256
At time: 305.531156539917 and batch: 1450, loss is 3.756502432823181 and perplexity is 42.798473361303984
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.5330993130675745 and perplexity of 93.0464948705948
Annealing...
Finished 26 epochs...
Completing Train Step...
At time: 306.8238070011139 and batch: 50, loss is 3.9452110624313352 and perplexity is 51.68724619677442
At time: 307.22414803504944 and batch: 100, loss is 3.976967873573303 and perplexity is 53.35500957747813
At time: 307.59504747390747 and batch: 150, loss is 3.792595329284668 and perplexity is 44.3714093863538
At time: 307.9758758544922 and batch: 200, loss is 3.9093808364868163 and perplexity is 49.86806592574343
At time: 308.34674286842346 and batch: 250, loss is 3.9714668560028077 and perplexity is 53.06230854719689
At time: 308.72966051101685 and batch: 300, loss is 3.973611660003662 and perplexity is 53.17623893436353
At time: 309.10417103767395 and batch: 350, loss is 3.9520221042633055 and perplexity is 52.04049181253677
At time: 309.481764793396 and batch: 400, loss is 3.771927485466003 and perplexity is 43.46375991494927
At time: 309.8481674194336 and batch: 450, loss is 3.8575629234313964 and perplexity is 47.34981551525668
At time: 310.21507024765015 and batch: 500, loss is 3.837811379432678 and perplexity is 46.4237591781845
At time: 310.5779941082001 and batch: 550, loss is 3.882672142982483 and perplexity is 48.553784534799
At time: 310.94782185554504 and batch: 600, loss is 3.830158066749573 and perplexity is 46.06981976537906
At time: 311.3601396083832 and batch: 650, loss is 3.8758615970611574 and perplexity is 48.22423025168338
At time: 311.7363352775574 and batch: 700, loss is 3.942280201911926 and perplexity is 51.53597986607834
At time: 312.10223627090454 and batch: 750, loss is 3.8896168279647827 and perplexity is 48.8921488299077
At time: 312.4763436317444 and batch: 800, loss is 3.8262472677230837 and perplexity is 45.89000180422695
At time: 312.8532483577728 and batch: 850, loss is 3.785244698524475 and perplexity is 44.04644734083749
At time: 313.21609473228455 and batch: 900, loss is 3.694074230194092 and perplexity is 40.208331692956065
At time: 313.59835052490234 and batch: 950, loss is 3.8340129375457765 and perplexity is 46.24775570786875
At time: 313.9681911468506 and batch: 1000, loss is 3.853134341239929 and perplexity is 47.14058660117359
At time: 314.3368492126465 and batch: 1050, loss is 3.765682873725891 and perplexity is 43.19319128676968
At time: 314.72077107429504 and batch: 1100, loss is 3.9343853330612184 and perplexity is 51.130711937507336
At time: 315.10537219047546 and batch: 1150, loss is 3.8275688171386717 and perplexity is 45.950687800231634
At time: 315.4808633327484 and batch: 1200, loss is 3.777192211151123 and perplexity is 43.693188096437446
At time: 315.84142303466797 and batch: 1250, loss is 3.719696102142334 and perplexity is 41.251855852914325
At time: 316.22266030311584 and batch: 1300, loss is 3.802949810028076 and perplexity is 44.83323916793298
At time: 316.59178376197815 and batch: 1350, loss is 3.7679479789733885 and perplexity is 43.29113930041084
At time: 316.95181345939636 and batch: 1400, loss is 3.6516948318481446 and perplexity is 38.53992942800318
At time: 317.32230138778687 and batch: 1450, loss is 3.74623272895813 and perplexity is 42.36119491726095
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.531126886351496 and perplexity of 92.86314835649787
Finished 27 epochs...
Completing Train Step...
At time: 318.5943911075592 and batch: 50, loss is 3.94350510597229 and perplexity is 51.59914517489504
At time: 318.98164463043213 and batch: 100, loss is 3.9748408794403076 and perplexity is 53.24164439142338
At time: 319.3527662754059 and batch: 150, loss is 3.7902482748031616 and perplexity is 44.26738938915404
At time: 319.7157554626465 and batch: 200, loss is 3.907311215400696 and perplexity is 49.76496465206588
At time: 320.0781321525574 and batch: 250, loss is 3.968788533210754 and perplexity is 52.92038070594423
At time: 320.4389445781708 and batch: 300, loss is 3.9716738796234132 and perplexity is 53.07329483560139
At time: 320.8213424682617 and batch: 350, loss is 3.950255994796753 and perplexity is 51.94866372040274
At time: 321.18242621421814 and batch: 400, loss is 3.7701299810409545 and perplexity is 43.385703788306174
At time: 321.5496356487274 and batch: 450, loss is 3.8554255533218384 and perplexity is 47.24871951315467
At time: 321.9227194786072 and batch: 500, loss is 3.8364155292510986 and perplexity is 46.35900377044397
At time: 322.28465485572815 and batch: 550, loss is 3.880907235145569 and perplexity is 48.468167155577596
At time: 322.6568467617035 and batch: 600, loss is 3.829037237167358 and perplexity is 46.018212275542055
At time: 323.0234887599945 and batch: 650, loss is 3.8744306325912476 and perplexity is 48.155272441459495
At time: 323.3831284046173 and batch: 700, loss is 3.9409861516952516 and perplexity is 51.469332851758175
At time: 323.75040769577026 and batch: 750, loss is 3.888204894065857 and perplexity is 48.82316505930578
At time: 324.14280462265015 and batch: 800, loss is 3.8253075456619263 and perplexity is 45.84689821301474
At time: 324.50346970558167 and batch: 850, loss is 3.7843918228149414 and perplexity is 44.008897210882246
At time: 324.8752450942993 and batch: 900, loss is 3.693311862945557 and perplexity is 40.17768985940438
At time: 325.2521507740021 and batch: 950, loss is 3.8333693504333497 and perplexity is 46.21800082427335
At time: 325.6162917613983 and batch: 1000, loss is 3.852313780784607 and perplexity is 47.10192076596518
At time: 325.9905815124512 and batch: 1050, loss is 3.765640597343445 and perplexity is 43.191365273494654
At time: 326.36928510665894 and batch: 1100, loss is 3.934489197731018 and perplexity is 51.136022887824616
At time: 326.73965549468994 and batch: 1150, loss is 3.8275080585479735 and perplexity is 45.947895986013485
At time: 327.1163504123688 and batch: 1200, loss is 3.7775780868530275 and perplexity is 43.710051489440154
At time: 327.4896252155304 and batch: 1250, loss is 3.720438313484192 and perplexity is 41.2824848133759
At time: 327.8645613193512 and batch: 1300, loss is 3.803719367980957 and perplexity is 44.867754222652124
At time: 328.22435569763184 and batch: 1350, loss is 3.76890567779541 and perplexity is 43.3326190328979
At time: 328.60338139533997 and batch: 1400, loss is 3.652781939506531 and perplexity is 38.58184926199589
At time: 328.9931354522705 and batch: 1450, loss is 3.7473414278030397 and perplexity is 42.408186770227694
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.53077893379407 and perplexity of 92.83084200740099
Finished 28 epochs...
Completing Train Step...
At time: 330.35943937301636 and batch: 50, loss is 3.942589144706726 and perplexity is 51.55190399542678
At time: 330.7346589565277 and batch: 100, loss is 3.973801293373108 and perplexity is 53.186323879918
At time: 331.10298705101013 and batch: 150, loss is 3.78913733959198 and perplexity is 44.21823849435946
At time: 331.47098445892334 and batch: 200, loss is 3.9062869787216186 and perplexity is 49.71401964426275
At time: 331.8348059654236 and batch: 250, loss is 3.9676465129852296 and perplexity is 52.85997905735246
At time: 332.2031214237213 and batch: 300, loss is 3.97079448223114 and perplexity is 53.02664283435422
At time: 332.5794451236725 and batch: 350, loss is 3.94932626247406 and perplexity is 51.90038781393399
At time: 332.95813822746277 and batch: 400, loss is 3.769190077781677 and perplexity is 43.34494458176565
At time: 333.34443855285645 and batch: 450, loss is 3.854324960708618 and perplexity is 47.1967465272628
At time: 333.71984243392944 and batch: 500, loss is 3.835636992454529 and perplexity is 46.32292562606014
At time: 334.1257927417755 and batch: 550, loss is 3.8800097465515138 and perplexity is 48.42468704275193
At time: 334.5009014606476 and batch: 600, loss is 3.8283273506164552 and perplexity is 45.985556157991766
At time: 334.8662860393524 and batch: 650, loss is 3.8737152719497683 and perplexity is 48.12083637344754
At time: 335.24202156066895 and batch: 700, loss is 3.9402834367752075 and perplexity is 51.43317728865318
At time: 335.61061334609985 and batch: 750, loss is 3.88749249458313 and perplexity is 48.78839584802699
At time: 335.98727893829346 and batch: 800, loss is 3.8248227977752687 and perplexity is 45.82467941168975
At time: 336.3696184158325 and batch: 850, loss is 3.783970875740051 and perplexity is 43.990375692895086
At time: 336.74133491516113 and batch: 900, loss is 3.6929464817047117 and perplexity is 40.16301236683278
At time: 337.11387515068054 and batch: 950, loss is 3.8331343269348146 and perplexity is 46.20713978437413
At time: 337.48900961875916 and batch: 1000, loss is 3.8520115995407105 and perplexity is 47.08768959926233
At time: 337.85207653045654 and batch: 1050, loss is 3.7656865072250367 and perplexity is 43.19334822947844
At time: 338.21400117874146 and batch: 1100, loss is 3.9345884037017824 and perplexity is 51.141096138260444
At time: 338.57528424263 and batch: 1150, loss is 3.8275147676467896 and perplexity is 45.94820425602215
At time: 338.96256279945374 and batch: 1200, loss is 3.7778359603881837 and perplexity is 43.72132460839664
At time: 339.3397605419159 and batch: 1250, loss is 3.720800166130066 and perplexity is 41.29742569276921
At time: 339.70608711242676 and batch: 1300, loss is 3.8041332292556764 and perplexity is 44.88632709163903
At time: 340.07934951782227 and batch: 1350, loss is 3.769380249977112 and perplexity is 43.35318836888247
At time: 340.45880126953125 and batch: 1400, loss is 3.653268222808838 and perplexity is 38.60061553355657
At time: 340.83559942245483 and batch: 1450, loss is 3.7478394746780395 and perplexity is 42.4293132956863
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.530652690137553 and perplexity of 92.81912344218124
Finished 29 epochs...
Completing Train Step...
At time: 342.1119306087494 and batch: 50, loss is 3.941809344291687 and perplexity is 51.511719469286476
At time: 342.49962520599365 and batch: 100, loss is 3.9730227518081667 and perplexity is 53.14493223074144
At time: 342.8783311843872 and batch: 150, loss is 3.7883124589920043 and perplexity is 44.18177876678869
At time: 343.2809853553772 and batch: 200, loss is 3.905549683570862 and perplexity is 49.677379247707584
At time: 343.65573620796204 and batch: 250, loss is 3.9668635177612304 and perplexity is 52.818606145719706
At time: 344.03054785728455 and batch: 300, loss is 3.9701510143280028 and perplexity is 52.992532867190654
At time: 344.4033393859863 and batch: 350, loss is 3.9486441564559938 and perplexity is 51.86499831813231
At time: 344.8017678260803 and batch: 400, loss is 3.7685028553009032 and perplexity is 43.31516719443809
At time: 345.1890833377838 and batch: 450, loss is 3.853524112701416 and perplexity is 47.158964237814956
At time: 345.56180238723755 and batch: 500, loss is 3.835034337043762 and perplexity is 46.29501727469321
At time: 345.93138098716736 and batch: 550, loss is 3.879386487007141 and perplexity is 48.39451529775998
At time: 346.2972364425659 and batch: 600, loss is 3.8278129577636717 and perplexity is 45.96190759941902
At time: 346.65897727012634 and batch: 650, loss is 3.8732435655593873 and perplexity is 48.09814282018754
At time: 347.0429530143738 and batch: 700, loss is 3.939815797805786 and perplexity is 51.40913075361849
At time: 347.40861201286316 and batch: 750, loss is 3.887002635002136 and perplexity is 48.7645022376143
At time: 347.76835441589355 and batch: 800, loss is 3.8244472551345825 and perplexity is 45.80747352154981
At time: 348.1288158893585 and batch: 850, loss is 3.783659930229187 and perplexity is 43.97669920948291
At time: 348.49808406829834 and batch: 900, loss is 3.692668471336365 and perplexity is 40.15184818492183
At time: 348.8597273826599 and batch: 950, loss is 3.8329665756225584 and perplexity is 46.19938912614941
At time: 349.2472720146179 and batch: 1000, loss is 3.8518274450302123 and perplexity is 47.07901898722436
At time: 349.6467661857605 and batch: 1050, loss is 3.7657122468948363 and perplexity is 43.194460026307986
At time: 350.0201053619385 and batch: 1100, loss is 3.934621324539185 and perplexity is 51.14277977368418
At time: 350.38191628456116 and batch: 1150, loss is 3.827472615242004 and perplexity is 45.94626746953758
At time: 350.75323510169983 and batch: 1200, loss is 3.777966194152832 and perplexity is 43.72701897188696
At time: 351.1233711242676 and batch: 1250, loss is 3.720962471961975 and perplexity is 41.30412904978423
At time: 351.4828202724457 and batch: 1300, loss is 3.8043497037887573 and perplexity is 44.896044890127904
At time: 351.84272599220276 and batch: 1350, loss is 3.769620351791382 and perplexity is 43.36359879779565
At time: 352.21551179885864 and batch: 1400, loss is 3.6535008573532104 and perplexity is 38.60959641475482
At time: 352.58963108062744 and batch: 1450, loss is 3.748095393180847 and perplexity is 42.44017313157729
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.530597914997329 and perplexity of 92.81403940092
Finished 30 epochs...
Completing Train Step...
At time: 353.87697410583496 and batch: 50, loss is 3.941105675697327 and perplexity is 51.47548504006452
At time: 354.28663873672485 and batch: 100, loss is 3.972376012802124 and perplexity is 53.110572442199704
At time: 354.6570417881012 and batch: 150, loss is 3.7876197624206545 and perplexity is 44.15118479751293
At time: 355.02043199539185 and batch: 200, loss is 3.9049377155303957 and perplexity is 49.64698757958715
At time: 355.38708209991455 and batch: 250, loss is 3.9662254095077514 and perplexity is 52.78491290831058
At time: 355.75716948509216 and batch: 300, loss is 3.9696059131622317 and perplexity is 52.963654447292825
At time: 356.129691362381 and batch: 350, loss is 3.94807514667511 and perplexity is 51.835495021431996
At time: 356.5091881752014 and batch: 400, loss is 3.7679295539855957 and perplexity is 43.29034166904589
At time: 356.87533354759216 and batch: 450, loss is 3.852859363555908 and perplexity is 47.12762577389741
At time: 357.2411119937897 and batch: 500, loss is 3.8345137214660645 and perplexity is 46.27092164035576
At time: 357.60810446739197 and batch: 550, loss is 3.8788851499557495 and perplexity is 48.370259414851525
At time: 357.9659221172333 and batch: 600, loss is 3.8273994874954225 and perplexity is 45.94290764538337
At time: 358.3359520435333 and batch: 650, loss is 3.872872314453125 and perplexity is 48.08028964566683
At time: 358.6990051269531 and batch: 700, loss is 3.9394526958465574 and perplexity is 51.39046738607732
At time: 359.0713777542114 and batch: 750, loss is 3.8866069316864014 and perplexity is 48.74520977968525
At time: 359.45991492271423 and batch: 800, loss is 3.8241109085083007 and perplexity is 45.79206892315992
At time: 359.8266589641571 and batch: 850, loss is 3.783387093544006 and perplexity is 43.96470238930614
At time: 360.2092628479004 and batch: 900, loss is 3.692416672706604 and perplexity is 40.14173927732445
At time: 360.5655908584595 and batch: 950, loss is 3.8328059101104737 and perplexity is 46.191967073887334
At time: 360.933634519577 and batch: 1000, loss is 3.8516730260849 and perplexity is 47.071749656041675
At time: 361.293559551239 and batch: 1050, loss is 3.765706114768982 and perplexity is 43.194195153255016
At time: 361.6604483127594 and batch: 1100, loss is 3.934604425430298 and perplexity is 51.14191551358264
At time: 362.02456641197205 and batch: 1150, loss is 3.827389397621155 and perplexity is 45.942444089560354
At time: 362.3856678009033 and batch: 1200, loss is 3.778016834259033 and perplexity is 43.72923336883972
At time: 362.7575831413269 and batch: 1250, loss is 3.721021337509155 and perplexity is 41.30656051150551
At time: 363.1224031448364 and batch: 1300, loss is 3.804459810256958 and perplexity is 44.90098850722405
At time: 363.48993277549744 and batch: 1350, loss is 3.7697403955459596 and perplexity is 43.36880463946548
At time: 363.8606584072113 and batch: 1400, loss is 3.6536081552505495 and perplexity is 38.61373936552822
At time: 364.24071741104126 and batch: 1450, loss is 3.7482320404052736 and perplexity is 42.44597285968924
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.530573918269231 and perplexity of 92.81181219437576
Finished 31 epochs...
Completing Train Step...
At time: 365.51914954185486 and batch: 50, loss is 3.9404544591903687 and perplexity is 51.4419742670713
At time: 365.8922076225281 and batch: 100, loss is 3.9718052768707275 and perplexity is 53.08026897863025
At time: 366.2635509967804 and batch: 150, loss is 3.787002148628235 and perplexity is 44.12392483576102
At time: 366.6222734451294 and batch: 200, loss is 3.904393963813782 and perplexity is 49.619999282997306
At time: 366.981205701828 and batch: 250, loss is 3.9656656646728514 and perplexity is 52.75537509354035
At time: 367.35301518440247 and batch: 300, loss is 3.9691166067123413 and perplexity is 52.93774532882832
At time: 367.7295813560486 and batch: 350, loss is 3.9475685262680056 and perplexity is 51.80924075287743
At time: 368.0884256362915 and batch: 400, loss is 3.7674201250076296 and perplexity is 43.268293930888795
At time: 368.4834372997284 and batch: 450, loss is 3.8522705173492433 and perplexity is 47.099883019140904
At time: 368.8488085269928 and batch: 500, loss is 3.834040141105652 and perplexity is 46.24901382857285
At time: 369.22538590431213 and batch: 550, loss is 3.878447699546814 and perplexity is 48.34910445255098
At time: 369.5997042655945 and batch: 600, loss is 3.82703980922699 and perplexity is 45.926385951339995
At time: 369.9797852039337 and batch: 650, loss is 3.872547302246094 and perplexity is 48.06466550377036
At time: 370.3675289154053 and batch: 700, loss is 3.939139404296875 and perplexity is 51.37436970867585
At time: 370.7420196533203 and batch: 750, loss is 3.8862581634521485 and perplexity is 48.72821196326361
At time: 371.11586236953735 and batch: 800, loss is 3.8237926530838013 and perplexity is 45.777497667639615
At time: 371.49044728279114 and batch: 850, loss is 3.7831314516067507 and perplexity is 43.95346460410227
At time: 371.8697757720947 and batch: 900, loss is 3.6921749210357664 and perplexity is 40.13203611770861
At time: 372.24030566215515 and batch: 950, loss is 3.832639384269714 and perplexity is 46.18427555816986
At time: 372.6054883003235 and batch: 1000, loss is 3.851524772644043 and perplexity is 47.06477162445939
At time: 372.9766671657562 and batch: 1050, loss is 3.7656737089157106 and perplexity is 43.19279543118442
At time: 373.34327244758606 and batch: 1100, loss is 3.9345544290542604 and perplexity is 51.139358667060414
At time: 373.71398067474365 and batch: 1150, loss is 3.827277684211731 and perplexity is 45.937311989161394
At time: 374.0971210002899 and batch: 1200, loss is 3.778017520904541 and perplexity is 43.72926339533169
At time: 374.4671185016632 and batch: 1250, loss is 3.7210210847854612 and perplexity is 41.306550072360274
At time: 374.8311839103699 and batch: 1300, loss is 3.804507875442505 and perplexity is 44.90314673343524
At time: 375.19043159484863 and batch: 1350, loss is 3.769793152809143 and perplexity is 43.371092719261675
At time: 375.55312037467957 and batch: 1400, loss is 3.6536448764801026 and perplexity is 38.61515733555
At time: 375.92778491973877 and batch: 1450, loss is 3.7483003902435303 and perplexity is 42.44887413421855
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.530560876569178 and perplexity of 92.81060177845268
Finished 32 epochs...
Completing Train Step...
At time: 377.16668343544006 and batch: 50, loss is 3.939840703010559 and perplexity is 51.410411124490984
At time: 377.53606939315796 and batch: 100, loss is 3.971281886100769 and perplexity is 53.052494524860336
At time: 377.9114816188812 and batch: 150, loss is 3.7864334344863892 and perplexity is 44.09883806998859
At time: 378.2902693748474 and batch: 200, loss is 3.9038929986953734 and perplexity is 49.59514761960906
At time: 378.6668667793274 and batch: 250, loss is 3.96515531539917 and perplexity is 52.72845829524703
At time: 379.04688334465027 and batch: 300, loss is 3.9686638879776 and perplexity is 52.91378484383247
At time: 379.41931676864624 and batch: 350, loss is 3.9471004676818846 and perplexity is 51.78499666717149
At time: 379.7930428981781 and batch: 400, loss is 3.7669514989852906 and perplexity is 43.24802203275106
At time: 380.1660120487213 and batch: 450, loss is 3.8517292404174803 and perplexity is 47.07439583740795
At time: 380.5264708995819 and batch: 500, loss is 3.8335970497131346 and perplexity is 46.22852582799655
At time: 380.8956265449524 and batch: 550, loss is 3.878047981262207 and perplexity is 48.32978229342435
At time: 381.26824855804443 and batch: 600, loss is 3.8267114782333373 and perplexity is 45.911309370595525
At time: 381.62936639785767 and batch: 650, loss is 3.8722457027435304 and perplexity is 48.050171410379086
At time: 382.0081195831299 and batch: 700, loss is 3.9388516044616697 and perplexity is 51.359586300973106
At time: 382.3892660140991 and batch: 750, loss is 3.885934815406799 and perplexity is 48.71245833826111
At time: 382.7534079551697 and batch: 800, loss is 3.8234851694107057 and perplexity is 45.7634239983343
At time: 383.1172797679901 and batch: 850, loss is 3.7828848934173585 and perplexity is 43.94262885332841
At time: 383.4839196205139 and batch: 900, loss is 3.6919380235671997 and perplexity is 40.12253006596815
At time: 383.8461585044861 and batch: 950, loss is 3.832465481758118 and perplexity is 46.17624469496791
At time: 384.2111096382141 and batch: 1000, loss is 3.851376132965088 and perplexity is 47.057776451808024
At time: 384.5943036079407 and batch: 1050, loss is 3.765622320175171 and perplexity is 43.190575864857664
At time: 384.96321153640747 and batch: 1100, loss is 3.9344824934005738 and perplexity is 51.135680056178806
At time: 385.34530544281006 and batch: 1150, loss is 3.8271462297439576 and perplexity is 45.93127372115027
At time: 385.7138056755066 and batch: 1200, loss is 3.777985110282898 and perplexity is 43.72784612568848
At time: 386.0810980796814 and batch: 1250, loss is 3.7209840774536134 and perplexity is 41.305021455439444
At time: 386.44126868247986 and batch: 1300, loss is 3.804516887664795 and perplexity is 44.90355141239866
At time: 386.8192684650421 and batch: 1350, loss is 3.7698042154312135 and perplexity is 43.371572519923134
At time: 387.20339584350586 and batch: 1400, loss is 3.6536376905441283 and perplexity is 38.61487985049875
At time: 387.57085490226746 and batch: 1450, loss is 3.7483253145217894 and perplexity is 42.4499321549544
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.5305561815571584 and perplexity of 92.81016603258475
Finished 33 epochs...
Completing Train Step...
At time: 388.9435143470764 and batch: 50, loss is 3.939255509376526 and perplexity is 51.380334880249556
At time: 389.3218686580658 and batch: 100, loss is 3.97079053401947 and perplexity is 53.02643347435746
At time: 389.6986458301544 and batch: 150, loss is 3.785898976325989 and perplexity is 44.07527538331388
At time: 390.0816185474396 and batch: 200, loss is 3.903421640396118 and perplexity is 49.5717760438016
At time: 390.4674882888794 and batch: 250, loss is 3.9646794033050536 and perplexity is 52.703370154588505
At time: 390.8391716480255 and batch: 300, loss is 3.9682371616363525 and perplexity is 52.89120995501691
At time: 391.2133717536926 and batch: 350, loss is 3.9466592979431154 and perplexity is 51.76215573245474
At time: 391.58411407470703 and batch: 400, loss is 3.7665107011795045 and perplexity is 43.228962600520994
At time: 391.9729528427124 and batch: 450, loss is 3.851220407485962 and perplexity is 47.05044892757938
At time: 392.33368134498596 and batch: 500, loss is 3.8331748056411743 and perplexity is 46.209010227473485
At time: 392.6947045326233 and batch: 550, loss is 3.8776724624633787 and perplexity is 48.31163695880025
At time: 393.06417202949524 and batch: 600, loss is 3.8264028930664065 and perplexity is 45.8971440072523
At time: 393.42682933807373 and batch: 650, loss is 3.8719576454162596 and perplexity is 48.03633219976641
At time: 393.78893518447876 and batch: 700, loss is 3.938578515052795 and perplexity is 51.34556245687894
At time: 394.1542088985443 and batch: 750, loss is 3.8856276226043702 and perplexity is 48.69749651987009
At time: 394.52379179000854 and batch: 800, loss is 3.8231850385665895 and perplexity is 45.749691044204674
At time: 394.90951228141785 and batch: 850, loss is 3.782644257545471 and perplexity is 43.932055952681864
At time: 395.29273676872253 and batch: 900, loss is 3.6917035293579104 and perplexity is 40.113122668038926
At time: 395.65583181381226 and batch: 950, loss is 3.8322850275039673 and perplexity is 46.16791274696235
At time: 396.04102849960327 and batch: 1000, loss is 3.8512250185012817 and perplexity is 47.05066587842037
At time: 396.41965794563293 and batch: 1050, loss is 3.765556468963623 and perplexity is 43.187731806752886
At time: 396.8073160648346 and batch: 1100, loss is 3.934395179748535 and perplexity is 51.13121540811881
At time: 397.1758906841278 and batch: 1150, loss is 3.8270007610321044 and perplexity is 45.92459264388391
At time: 397.5434150695801 and batch: 1200, loss is 3.777929310798645 and perplexity is 43.72540620250103
At time: 397.91583037376404 and batch: 1250, loss is 3.7209221267700197 and perplexity is 41.3024626603848
At time: 398.29032588005066 and batch: 1300, loss is 3.8044997167587282 and perplexity is 44.902780384354934
At time: 398.6722252368927 and batch: 1350, loss is 3.7697877359390257 and perplexity is 43.37085778432188
At time: 399.05417251586914 and batch: 1400, loss is 3.653601384162903 and perplexity is 38.61347790939978
At time: 399.42469549179077 and batch: 1450, loss is 3.7483200454711914 and perplexity is 42.44970848470326
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.53055409488515 and perplexity of 92.80997236841124
Finished 34 epochs...
Completing Train Step...
At time: 400.68370032310486 and batch: 50, loss is 3.9386926651000977 and perplexity is 51.351423889797225
At time: 401.06310653686523 and batch: 100, loss is 3.9703228855133057 and perplexity is 53.00164153936346
At time: 401.45549631118774 and batch: 150, loss is 3.785390419960022 and perplexity is 44.052866320054804
At time: 401.82995319366455 and batch: 200, loss is 3.9029721641540527 and perplexity is 49.54949971490826
At time: 402.2092592716217 and batch: 250, loss is 3.964229145050049 and perplexity is 52.679645368651
At time: 402.58409309387207 and batch: 300, loss is 3.967830104827881 and perplexity is 52.86968460921292
At time: 402.96326065063477 and batch: 350, loss is 3.94623779296875 and perplexity is 51.74034232388271
At time: 403.3513820171356 and batch: 400, loss is 3.7660899114608766 and perplexity is 43.21077612412123
At time: 403.7211093902588 and batch: 450, loss is 3.8507348489761353 and perplexity is 47.02760872728699
At time: 404.09771728515625 and batch: 500, loss is 3.832767858505249 and perplexity is 46.19020942883252
At time: 404.49682903289795 and batch: 550, loss is 3.8773141956329344 and perplexity is 48.29433160190623
At time: 404.8550980091095 and batch: 600, loss is 3.8261081171035767 and perplexity is 45.88361662630775
At time: 405.23708868026733 and batch: 650, loss is 3.8716779708862306 and perplexity is 48.02289953960814
At time: 405.6129848957062 and batch: 700, loss is 3.9383144092559816 and perplexity is 51.33200358676034
At time: 405.9954833984375 and batch: 750, loss is 3.8853308629989622 and perplexity is 48.68304721410968
At time: 406.36696124076843 and batch: 800, loss is 3.8228904485702513 and perplexity is 45.73621562784636
At time: 406.73652052879333 and batch: 850, loss is 3.782407808303833 and perplexity is 43.921669479353504
At time: 407.10749220848083 and batch: 900, loss is 3.691470575332642 and perplexity is 40.103779242983805
At time: 407.469664812088 and batch: 950, loss is 3.832099270820618 and perplexity is 46.1593375450885
At time: 407.83352541923523 and batch: 1000, loss is 3.85107120513916 and perplexity is 47.043429413858284
At time: 408.19703221321106 and batch: 1050, loss is 3.765479803085327 and perplexity is 43.1844209082804
At time: 408.55822920799255 and batch: 1100, loss is 3.934296865463257 and perplexity is 51.12618872632192
At time: 408.9237027168274 and batch: 1150, loss is 3.8268450021743776 and perplexity is 45.91744003884739
At time: 409.293657541275 and batch: 1200, loss is 3.777856497764587 and perplexity is 43.72222253891752
At time: 409.67864441871643 and batch: 1250, loss is 3.7208422899246214 and perplexity is 41.29916533368465
At time: 410.0530984401703 and batch: 1300, loss is 3.8044641733169557 and perplexity is 44.901184413358244
At time: 410.4244010448456 and batch: 1350, loss is 3.769751477241516 and perplexity is 43.36928524201807
At time: 410.78589630126953 and batch: 1400, loss is 3.6535440778732298 and perplexity is 38.611265177651745
At time: 411.1482846736908 and batch: 1450, loss is 3.748292636871338 and perplexity is 42.44854501357414
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.5305561815571584 and perplexity of 92.81016603258475
Annealing...
Finished 35 epochs...
Completing Train Step...
At time: 412.3936200141907 and batch: 50, loss is 3.938453960418701 and perplexity is 51.339167527402076
At time: 412.76518034935 and batch: 100, loss is 3.9707256507873536 and perplexity is 53.02299305957986
At time: 413.1392526626587 and batch: 150, loss is 3.7857485723495485 and perplexity is 44.06864678512978
At time: 413.50695180892944 and batch: 200, loss is 3.902662506103516 and perplexity is 49.534158688780174
At time: 413.9125952720642 and batch: 250, loss is 3.964306607246399 and perplexity is 52.68372620773755
At time: 414.2732436656952 and batch: 300, loss is 3.9680426216125486 and perplexity is 52.88092149856397
At time: 414.6337261199951 and batch: 350, loss is 3.946334481239319 and perplexity is 51.74534524995887
At time: 415.00960969924927 and batch: 400, loss is 3.765820026397705 and perplexity is 43.19911575462784
At time: 415.3773729801178 and batch: 450, loss is 3.8510016012191772 and perplexity is 47.040155120714786
At time: 415.7516098022461 and batch: 500, loss is 3.8319104862213136 and perplexity is 46.15062419554488
At time: 416.13641476631165 and batch: 550, loss is 3.876086263656616 and perplexity is 48.23506584246471
At time: 416.51685214042664 and batch: 600, loss is 3.824547600746155 and perplexity is 45.812070331125895
At time: 416.8983807563782 and batch: 650, loss is 3.870714325904846 and perplexity is 47.97664480362676
At time: 417.2765815258026 and batch: 700, loss is 3.937162685394287 and perplexity is 51.27291732542074
At time: 417.65269660949707 and batch: 750, loss is 3.8845253372192383 and perplexity is 48.64384755483088
At time: 418.02750277519226 and batch: 800, loss is 3.821620135307312 and perplexity is 45.678153193086054
At time: 418.3891351222992 and batch: 850, loss is 3.7811957216262817 and perplexity is 43.868464859740904
At time: 418.75868010520935 and batch: 900, loss is 3.6900275802612303 and perplexity is 40.045951419857346
At time: 419.1192412376404 and batch: 950, loss is 3.8301617431640627 and perplexity is 46.06998913744332
At time: 419.48774814605713 and batch: 1000, loss is 3.8497747659683226 and perplexity is 46.982479986384995
At time: 419.8525047302246 and batch: 1050, loss is 3.763511371612549 and perplexity is 43.09949894398522
At time: 420.24188208580017 and batch: 1100, loss is 3.9323189878463745 and perplexity is 51.025167318926854
At time: 420.62941122055054 and batch: 1150, loss is 3.8246342945098877 and perplexity is 45.81604212408964
At time: 421.0090868473053 and batch: 1200, loss is 3.7755887031555178 and perplexity is 43.62318186274927
At time: 421.38216161727905 and batch: 1250, loss is 3.7178577518463136 and perplexity is 41.17609015478024
At time: 421.74123191833496 and batch: 1300, loss is 3.80172954082489 and perplexity is 44.778563912946744
At time: 422.11663031578064 and batch: 1350, loss is 3.7668202781677245 and perplexity is 43.24234736426727
At time: 422.49317359924316 and batch: 1400, loss is 3.650523533821106 and perplexity is 38.494814111600455
At time: 422.86867213249207 and batch: 1450, loss is 3.7452214527130128 and perplexity is 42.318377700792325
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.530368381076389 and perplexity of 92.79273787534294
Finished 36 epochs...
Completing Train Step...
At time: 424.12616443634033 and batch: 50, loss is 3.938196053504944 and perplexity is 51.32592850844088
At time: 424.51007103919983 and batch: 100, loss is 3.97040301322937 and perplexity is 53.00588860999944
At time: 424.882963180542 and batch: 150, loss is 3.7855466842651366 and perplexity is 44.05975074847982
At time: 425.2488441467285 and batch: 200, loss is 3.902302794456482 and perplexity is 49.516343879263125
At time: 425.61504769325256 and batch: 250, loss is 3.963880581855774 and perplexity is 52.66128638300725
At time: 425.97483229637146 and batch: 300, loss is 3.9677434968948364 and perplexity is 52.86510587338849
At time: 426.3406398296356 and batch: 350, loss is 3.946017084121704 and perplexity is 51.72892403268793
At time: 426.71608328819275 and batch: 400, loss is 3.7655623531341553 and perplexity is 43.18798593147939
At time: 427.09696316719055 and batch: 450, loss is 3.85068088054657 and perplexity is 47.025070789582635
At time: 427.46395659446716 and batch: 500, loss is 3.831733937263489 and perplexity is 46.14247707014461
At time: 427.8292226791382 and batch: 550, loss is 3.8759065008163454 and perplexity is 48.22639574933186
At time: 428.22093057632446 and batch: 600, loss is 3.824427285194397 and perplexity is 45.80655875817745
At time: 428.5954713821411 and batch: 650, loss is 3.870580472946167 and perplexity is 47.97022341754264
At time: 428.9763786792755 and batch: 700, loss is 3.937077898979187 and perplexity is 51.26857026285754
At time: 429.3461711406708 and batch: 750, loss is 3.8843264150619508 and perplexity is 48.634172178091816
At time: 429.714364528656 and batch: 800, loss is 3.8214999532699583 and perplexity is 45.67266382944082
At time: 430.0803818702698 and batch: 850, loss is 3.7810980224609376 and perplexity is 43.86417915669739
At time: 430.44383692741394 and batch: 900, loss is 3.6899417209625245 and perplexity is 40.04251325015396
At time: 430.8049554824829 and batch: 950, loss is 3.830101728439331 and perplexity is 46.06722434269188
At time: 431.17845702171326 and batch: 1000, loss is 3.8496599912643434 and perplexity is 46.97708789559608
At time: 431.556720495224 and batch: 1050, loss is 3.7636043405532837 and perplexity is 43.103506045013326
At time: 431.9310736656189 and batch: 1100, loss is 3.9324027347564696 and perplexity is 51.029440697965555
At time: 432.3120050430298 and batch: 1150, loss is 3.8246220111846925 and perplexity is 45.81547935420142
At time: 432.7092046737671 and batch: 1200, loss is 3.775654606819153 and perplexity is 43.62605688498966
At time: 433.0738093852997 and batch: 1250, loss is 3.7180182933807373 and perplexity is 41.182701158131366
At time: 433.4439570903778 and batch: 1300, loss is 3.8018566036224364 and perplexity is 44.78425396403688
At time: 433.80643796920776 and batch: 1350, loss is 3.7669286918640137 and perplexity is 43.247035681115534
At time: 434.1830050945282 and batch: 1400, loss is 3.650713677406311 and perplexity is 38.50213434949352
At time: 434.5593626499176 and batch: 1450, loss is 3.7453762245178224 and perplexity is 42.32492789936565
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.530292217548077 and perplexity of 92.78567072215763
Finished 37 epochs...
Completing Train Step...
At time: 435.79829597473145 and batch: 50, loss is 3.9379833459854128 and perplexity is 51.31501225852559
At time: 436.16778898239136 and batch: 100, loss is 3.9701663494110107 and perplexity is 52.99334551831199
At time: 436.5367901325226 and batch: 150, loss is 3.785363302230835 and perplexity is 44.05167172255348
At time: 436.9064838886261 and batch: 200, loss is 3.902062487602234 and perplexity is 49.50444619203679
At time: 437.27616786956787 and batch: 250, loss is 3.9635772609710695 and perplexity is 52.645315537299865
At time: 437.6397726535797 and batch: 300, loss is 3.9675212907791138 and perplexity is 52.85336022858048
At time: 438.0127010345459 and batch: 350, loss is 3.9457924270629885 and perplexity is 51.717304070066405
At time: 438.39071583747864 and batch: 400, loss is 3.7653690433502196 and perplexity is 43.179638078137216
At time: 438.7755582332611 and batch: 450, loss is 3.8504420471191407 and perplexity is 47.01384097183217
At time: 439.16147661209106 and batch: 500, loss is 3.83158887386322 and perplexity is 46.13578397099758
At time: 439.53740525245667 and batch: 550, loss is 3.875759177207947 and perplexity is 48.21929138602308
At time: 439.9148442745209 and batch: 600, loss is 3.824330687522888 and perplexity is 45.80213416496772
At time: 440.29221510887146 and batch: 650, loss is 3.870461163520813 and perplexity is 47.964500459160824
At time: 440.6576392650604 and batch: 700, loss is 3.9369921922683715 and perplexity is 51.26417639062695
At time: 441.0173478126526 and batch: 750, loss is 3.884193229675293 and perplexity is 48.627695248391255
At time: 441.3885130882263 and batch: 800, loss is 3.8214176177978514 and perplexity is 45.66890350390826
At time: 441.7776930332184 and batch: 850, loss is 3.7810223054885865 and perplexity is 43.86085801959179
At time: 442.15372610092163 and batch: 900, loss is 3.6898861646652223 and perplexity is 40.04028869817762
At time: 442.5498480796814 and batch: 950, loss is 3.830056037902832 and perplexity is 46.06511955458145
At time: 442.91895389556885 and batch: 1000, loss is 3.8495839071273803 and perplexity is 46.97351382037344
At time: 443.2958436012268 and batch: 1050, loss is 3.7636767292022704 and perplexity is 43.10662636251893
At time: 443.6551797389984 and batch: 1100, loss is 3.932460641860962 and perplexity is 51.03239575067869
At time: 444.0177757740021 and batch: 1150, loss is 3.8246132946014404 and perplexity is 45.8150800015019
At time: 444.3813853263855 and batch: 1200, loss is 3.775714979171753 and perplexity is 43.62869077218464
At time: 444.76272225379944 and batch: 1250, loss is 3.7181259965896607 and perplexity is 41.18713690606609
At time: 445.1240601539612 and batch: 1300, loss is 3.8019487047195435 and perplexity is 44.78837883290965
At time: 445.48835706710815 and batch: 1350, loss is 3.767009263038635 and perplexity is 43.250520285956725
At time: 445.8469760417938 and batch: 1400, loss is 3.650844235420227 and perplexity is 38.50716143984204
At time: 446.2168982028961 and batch: 1450, loss is 3.745476927757263 and perplexity is 42.32919037133297
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.5302426590878735 and perplexity of 92.78107252112855
Finished 38 epochs...
Completing Train Step...
At time: 447.45128440856934 and batch: 50, loss is 3.937793855667114 and perplexity is 51.30528948173435
At time: 447.8428497314453 and batch: 100, loss is 3.969970669746399 and perplexity is 52.98297681273981
At time: 448.2324845790863 and batch: 150, loss is 3.785199556350708 and perplexity is 44.0444590333364
At time: 448.5981614589691 and batch: 200, loss is 3.9018583726882934 and perplexity is 49.49434262744181
At time: 448.97181606292725 and batch: 250, loss is 3.9633379364013672 and perplexity is 52.63271772735491
At time: 449.3359854221344 and batch: 300, loss is 3.9673401641845705 and perplexity is 52.84378794635572
At time: 449.69571709632874 and batch: 350, loss is 3.945607552528381 and perplexity is 51.7077437413032
At time: 450.0580916404724 and batch: 400, loss is 3.76520076751709 and perplexity is 43.17237259988473
At time: 450.4352025985718 and batch: 450, loss is 3.850247411727905 and perplexity is 47.004691304954505
At time: 450.80723309516907 and batch: 500, loss is 3.831461162567139 and perplexity is 46.12989228645627
At time: 451.1771013736725 and batch: 550, loss is 3.875627031326294 and perplexity is 48.212919826247166
At time: 451.563844203949 and batch: 600, loss is 3.824235200881958 and perplexity is 45.79776088182725
At time: 451.9459037780762 and batch: 650, loss is 3.870352854728699 and perplexity is 47.95930576337243
At time: 452.3155405521393 and batch: 700, loss is 3.9369073867797852 and perplexity is 51.25982909144119
At time: 452.6904630661011 and batch: 750, loss is 3.884082221984863 and perplexity is 48.62229749985216
At time: 453.06712675094604 and batch: 800, loss is 3.8213476657867433 and perplexity is 45.66570898399591
At time: 453.44282603263855 and batch: 850, loss is 3.78095956325531 and perplexity is 43.85810617773548
At time: 453.81538677215576 and batch: 900, loss is 3.6898408222198484 and perplexity is 40.038473214734104
At time: 454.1827185153961 and batch: 950, loss is 3.830012640953064 and perplexity is 46.063120512278566
At time: 454.55553102493286 and batch: 1000, loss is 3.8495247173309326 and perplexity is 46.970733549934614
At time: 454.93048453330994 and batch: 1050, loss is 3.7637323474884035 and perplexity is 43.109023945872316
At time: 455.30426836013794 and batch: 1100, loss is 3.932499928474426 and perplexity is 51.03440068006788
At time: 455.66676235198975 and batch: 1150, loss is 3.8246027612686158 and perplexity is 45.81459741855746
At time: 456.03824043273926 and batch: 1200, loss is 3.7757620429992675 and perplexity is 43.630744153681455
At time: 456.44001030921936 and batch: 1250, loss is 3.7182011795043945 and perplexity is 41.19023359147568
At time: 456.8134796619415 and batch: 1300, loss is 3.802019839286804 and perplexity is 44.79156494817635
At time: 457.18057918548584 and batch: 1350, loss is 3.767070565223694 and perplexity is 43.25317171862366
At time: 457.55678272247314 and batch: 1400, loss is 3.650937705039978 and perplexity is 38.51076085779499
At time: 457.92634630203247 and batch: 1450, loss is 3.7455473852157595 and perplexity is 42.33217288357563
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.530208750667735 and perplexity of 92.77792651487897
Finished 39 epochs...
Completing Train Step...
At time: 459.19985604286194 and batch: 50, loss is 3.937619342803955 and perplexity is 51.29633682997086
At time: 459.57922649383545 and batch: 100, loss is 3.9697998332977296 and perplexity is 52.9739261622537
At time: 459.9425599575043 and batch: 150, loss is 3.785050392150879 and perplexity is 44.037889666817115
At time: 460.3010058403015 and batch: 200, loss is 3.9016765546798706 and perplexity is 49.48534448267426
At time: 460.67064785957336 and batch: 250, loss is 3.963136763572693 and perplexity is 52.622130519613854
At time: 461.0309820175171 and batch: 300, loss is 3.9671842432022095 and perplexity is 52.83554913334605
At time: 461.4041018486023 and batch: 350, loss is 3.9454461097717286 and perplexity is 51.69939657442627
At time: 461.77577447891235 and batch: 400, loss is 3.7650485324859617 and perplexity is 43.165800752643484
At time: 462.1565001010895 and batch: 450, loss is 3.850079131126404 and perplexity is 46.99678199273891
At time: 462.5264735221863 and batch: 500, loss is 3.831342854499817 and perplexity is 46.124435070876764
At time: 462.89403653144836 and batch: 550, loss is 3.875505256652832 and perplexity is 48.20704907114056
At time: 463.270792722702 and batch: 600, loss is 3.824140009880066 and perplexity is 45.793401554572156
At time: 463.6468472480774 and batch: 650, loss is 3.8702522325515747 and perplexity is 47.95448023639474
At time: 464.0150189399719 and batch: 700, loss is 3.936824016571045 and perplexity is 51.25555572692797
At time: 464.3843755722046 and batch: 750, loss is 3.8839826250076293 and perplexity is 48.617455107142845
At time: 464.7616093158722 and batch: 800, loss is 3.821283106803894 and perplexity is 45.662760947434954
At time: 465.1398844718933 and batch: 850, loss is 3.7809041023254393 and perplexity is 43.855673833835134
At time: 465.5073871612549 and batch: 900, loss is 3.6897994232177735 and perplexity is 40.03681569620846
At time: 465.89066195487976 and batch: 950, loss is 3.8299700355529787 and perplexity is 46.06115801640672
At time: 466.25796151161194 and batch: 1000, loss is 3.8494736337661744 and perplexity is 46.968334178710315
At time: 466.6303234100342 and batch: 1050, loss is 3.763774247169495 and perplexity is 43.11083023806908
At time: 467.0032477378845 and batch: 1100, loss is 3.9325256729125977 and perplexity is 51.035714548953145
At time: 467.3736000061035 and batch: 1150, loss is 3.8245895433425905 and perplexity is 45.813991848600104
At time: 467.7570514678955 and batch: 1200, loss is 3.7757976484298705 and perplexity is 43.63229767277127
At time: 468.1404047012329 and batch: 1250, loss is 3.7182546138763426 and perplexity is 41.192434624542926
At time: 468.5128881931305 and batch: 1300, loss is 3.8020760679244994 and perplexity is 44.7940835876628
At time: 468.8931360244751 and batch: 1350, loss is 3.7671179819107055 and perplexity is 43.255222689354035
At time: 469.283882856369 and batch: 1400, loss is 3.651006360054016 and perplexity is 38.51340490538483
At time: 469.6521346569061 and batch: 1450, loss is 3.745598359107971 and perplexity is 42.33433077419085
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.530183188935631 and perplexity of 92.7755549806866
Finished 40 epochs...
Completing Train Step...
At time: 470.8964536190033 and batch: 50, loss is 3.9374554347991944 and perplexity is 51.28792963877131
At time: 471.25625586509705 and batch: 100, loss is 3.9696460008621215 and perplexity is 52.96577768093487
At time: 471.6169493198395 and batch: 150, loss is 3.784912075996399 and perplexity is 44.03179893649989
At time: 471.9894244670868 and batch: 200, loss is 3.901510467529297 and perplexity is 49.47712628530137
At time: 472.3664755821228 and batch: 250, loss is 3.9629604530334475 and perplexity is 52.61285350124778
At time: 472.7294178009033 and batch: 300, loss is 3.967044734954834 and perplexity is 52.82817865262071
At time: 473.1003108024597 and batch: 350, loss is 3.9453000116348265 and perplexity is 51.69184394063407
At time: 473.4733238220215 and batch: 400, loss is 3.764908318519592 and perplexity is 43.159748728807486
At time: 473.8334627151489 and batch: 450, loss is 3.8499284648895262 and perplexity is 46.98970169784479
At time: 474.21122121810913 and batch: 500, loss is 3.8312306118011477 and perplexity is 46.119258230346524
At time: 474.58837938308716 and batch: 550, loss is 3.875391249656677 and perplexity is 48.201553443558424
At time: 474.9609613418579 and batch: 600, loss is 3.8240458011627196 and perplexity is 45.78908762015708
At time: 475.3566598892212 and batch: 650, loss is 3.870157504081726 and perplexity is 47.94993779701211
At time: 475.74005007743835 and batch: 700, loss is 3.9367424201965333 and perplexity is 51.25137363003137
At time: 476.1235957145691 and batch: 750, loss is 3.8838898801803587 and perplexity is 48.61294629875416
At time: 476.4969735145569 and batch: 800, loss is 3.821220965385437 and perplexity is 45.65992348686186
At time: 476.8778443336487 and batch: 850, loss is 3.780852861404419 and perplexity is 43.85342668628936
At time: 477.2591242790222 and batch: 900, loss is 3.689759011268616 and perplexity is 40.03519776314024
At time: 477.6343836784363 and batch: 950, loss is 3.8299270820617677 and perplexity is 46.059179571351564
At time: 478.0127754211426 and batch: 1000, loss is 3.849426999092102 and perplexity is 46.96614387682658
At time: 478.3939588069916 and batch: 1050, loss is 3.7638053417205812 and perplexity is 43.112170770823816
At time: 478.78079104423523 and batch: 1100, loss is 3.93254150390625 and perplexity is 51.036522501421544
At time: 479.1547043323517 and batch: 1150, loss is 3.824573040008545 and perplexity is 45.81323577122758
At time: 479.5384154319763 and batch: 1200, loss is 3.775823879241943 and perplexity is 43.633442198382674
At time: 479.91595339775085 and batch: 1250, loss is 3.7182927322387695 and perplexity is 41.19400484262207
At time: 480.2811686992645 and batch: 1300, loss is 3.802121777534485 and perplexity is 44.796131154549634
At time: 480.6681852340698 and batch: 1350, loss is 3.767154493331909 and perplexity is 43.25680202784068
At time: 481.04553747177124 and batch: 1400, loss is 3.651057314872742 and perplexity is 38.515367398949124
At time: 481.4237895011902 and batch: 1450, loss is 3.745635952949524 and perplexity is 42.33592231423008
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.5301654522235575 and perplexity of 92.77390946197355
Finished 41 epochs...
Completing Train Step...
At time: 482.69881224632263 and batch: 50, loss is 3.9372995853424073 and perplexity is 51.279937065632645
At time: 483.0768210887909 and batch: 100, loss is 3.9695045614242552 and perplexity is 52.958286760881776
At time: 483.4434063434601 and batch: 150, loss is 3.784782176017761 and perplexity is 44.026079578238964
At time: 483.82287192344666 and batch: 200, loss is 3.901356258392334 and perplexity is 49.46949704862162
At time: 484.19834876060486 and batch: 250, loss is 3.9628011703491213 and perplexity is 52.60447385209626
At time: 484.5676209926605 and batch: 300, loss is 3.9669166898727415 and perplexity is 52.821414697203195
At time: 484.94881939888 and batch: 350, loss is 3.9451648378372193 and perplexity is 51.68485703001756
At time: 485.3195061683655 and batch: 400, loss is 3.7647769594192506 and perplexity is 43.15407967539253
At time: 485.678927898407 and batch: 450, loss is 3.849790163040161 and perplexity is 46.983203384573585
At time: 486.0506408214569 and batch: 500, loss is 3.8311227226257323 and perplexity is 46.114282730011425
At time: 486.4187488555908 and batch: 550, loss is 3.8752832984924317 and perplexity is 48.19635031059294
At time: 486.7869281768799 and batch: 600, loss is 3.8239534425735475 and perplexity is 45.784858799911945
At time: 487.1615996360779 and batch: 650, loss is 3.8700677824020384 and perplexity is 47.94563584104429
At time: 487.52929067611694 and batch: 700, loss is 3.9366629552841186 and perplexity is 51.247301105928244
At time: 487.8876495361328 and batch: 750, loss is 3.883802447319031 and perplexity is 48.60869611556723
At time: 488.26566648483276 and batch: 800, loss is 3.821160011291504 and perplexity is 45.65714041241741
At time: 488.6403510570526 and batch: 850, loss is 3.7808039712905885 and perplexity is 43.85128273967615
At time: 488.99882674217224 and batch: 900, loss is 3.6897183990478517 and perplexity is 40.033571877865974
At time: 489.3578085899353 and batch: 950, loss is 3.8298834705352784 and perplexity is 46.057170904022456
At time: 489.7260801792145 and batch: 1000, loss is 3.8493828105926515 and perplexity is 46.9640685592566
At time: 490.13241243362427 and batch: 1050, loss is 3.7638280391693115 and perplexity is 43.11314931821476
At time: 490.4948329925537 and batch: 1100, loss is 3.932549958229065 and perplexity is 51.036953982482046
At time: 490.8595881462097 and batch: 1150, loss is 3.824553899765015 and perplexity is 45.81235890312978
At time: 491.22526836395264 and batch: 1200, loss is 3.775842671394348 and perplexity is 43.63426217238293
At time: 491.60344195365906 and batch: 1250, loss is 3.7183193826675414 and perplexity is 41.195102695143014
At time: 491.9871573448181 and batch: 1300, loss is 3.802159061431885 and perplexity is 44.797801360043216
At time: 492.3670151233673 and batch: 1350, loss is 3.7671827363967894 and perplexity is 43.25802374975936
At time: 492.7281668186188 and batch: 1400, loss is 3.6510953664779664 and perplexity is 38.5168329983885
At time: 493.105345249176 and batch: 1450, loss is 3.7456633758544924 and perplexity is 42.33708330412325
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.530150845519498 and perplexity of 92.77255435083046
Finished 42 epochs...
Completing Train Step...
At time: 494.35894298553467 and batch: 50, loss is 3.9371499109268187 and perplexity is 51.27226234538988
At time: 494.7509882450104 and batch: 100, loss is 3.9693727540969848 and perplexity is 52.951306930653494
At time: 495.13377499580383 and batch: 150, loss is 3.784659023284912 and perplexity is 44.02065798007145
At time: 495.50634837150574 and batch: 200, loss is 3.9012113285064696 and perplexity is 49.46232795958077
At time: 495.89932775497437 and batch: 250, loss is 3.9626541709899903 and perplexity is 52.59674159648481
At time: 496.2738981246948 and batch: 300, loss is 3.9667970943450928 and perplexity is 52.815097869981
At time: 496.65026211738586 and batch: 350, loss is 3.945037841796875 and perplexity is 51.67829367459788
At time: 497.01611399650574 and batch: 400, loss is 3.7646524477005006 and perplexity is 43.148706821259665
At time: 497.3839182853699 and batch: 450, loss is 3.8496606492996217 and perplexity is 46.977118808187356
At time: 497.7497799396515 and batch: 500, loss is 3.831018123626709 and perplexity is 46.10945947445544
At time: 498.1191849708557 and batch: 550, loss is 3.8751801109313964 and perplexity is 48.19137730333424
At time: 498.50725769996643 and batch: 600, loss is 3.8238631200790407 and perplexity is 45.78072358400882
At time: 498.89306902885437 and batch: 650, loss is 3.8699820756912233 and perplexity is 47.94152675438909
At time: 499.27241945266724 and batch: 700, loss is 3.936585464477539 and perplexity is 51.243330065092096
At time: 499.67143654823303 and batch: 750, loss is 3.8837187242507936 and perplexity is 48.60462661674325
At time: 500.04647159576416 and batch: 800, loss is 3.8210994815826416 and perplexity is 45.65437688263942
At time: 500.4212908744812 and batch: 850, loss is 3.780756196975708 and perplexity is 43.84918782472859
At time: 500.78337121009827 and batch: 900, loss is 3.6896770715713503 and perplexity is 40.03191742555233
At time: 501.17012310028076 and batch: 950, loss is 3.8298389434814455 and perplexity is 46.055120159551365
At time: 501.5422520637512 and batch: 1000, loss is 3.8493403720855714 and perplexity is 46.96207551659172
At time: 501.90019130706787 and batch: 1050, loss is 3.763844165802002 and perplexity is 43.11384459374416
At time: 502.28083539009094 and batch: 1100, loss is 3.932552342414856 and perplexity is 51.037075664207606
At time: 502.65240931510925 and batch: 1150, loss is 3.824531898498535 and perplexity is 45.81135098430127
At time: 503.0311315059662 and batch: 1200, loss is 3.7758554077148436 and perplexity is 43.634817915869604
At time: 503.4043457508087 and batch: 1250, loss is 3.7183373832702635 and perplexity is 41.19584423849482
At time: 503.7662467956543 and batch: 1300, loss is 3.8021897077560425 and perplexity is 44.79917426902244
At time: 504.1469783782959 and batch: 1350, loss is 3.7672042512893675 and perplexity is 43.25895445150542
At time: 504.5185492038727 and batch: 1400, loss is 3.6511236667633056 and perplexity is 38.51792305117704
At time: 504.89174795150757 and batch: 1450, loss is 3.7456830024719237 and perplexity is 42.33791424601468
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.530140412159455 and perplexity of 92.77158642641821
Finished 43 epochs...
Completing Train Step...
At time: 506.1777980327606 and batch: 50, loss is 3.9370055294036863 and perplexity is 51.264860112443706
At time: 506.56664514541626 and batch: 100, loss is 3.9692483806610106 and perplexity is 52.94472160419953
At time: 506.95022797584534 and batch: 150, loss is 3.7845414972305296 and perplexity is 44.015484709830694
At time: 507.3258171081543 and batch: 200, loss is 3.9010734081268312 and perplexity is 49.45550656694613
At time: 507.6969065666199 and batch: 250, loss is 3.9625162649154664 and perplexity is 52.58948868644016
At time: 508.07024669647217 and batch: 300, loss is 3.9666837882995605 and perplexity is 52.80911393911113
At time: 508.43589448928833 and batch: 350, loss is 3.9449168825149536 and perplexity is 51.67204308334522
At time: 508.79683208465576 and batch: 400, loss is 3.7645333766937257 and perplexity is 43.14356936716441
At time: 509.200364112854 and batch: 450, loss is 3.849537935256958 and perplexity is 46.97135440971926
At time: 509.5857090950012 and batch: 500, loss is 3.830915970802307 and perplexity is 46.10474950351099
At time: 509.95907735824585 and batch: 550, loss is 3.875080704689026 and perplexity is 48.18658701769795
At time: 510.3359811306 and batch: 600, loss is 3.823775300979614 and perplexity is 45.77670333862231
At time: 510.71110558509827 and batch: 650, loss is 3.869899621009827 and perplexity is 47.937573914042225
At time: 511.09080815315247 and batch: 700, loss is 3.9365101051330567 and perplexity is 51.23946854683186
At time: 511.4637770652771 and batch: 750, loss is 3.8836379766464235 and perplexity is 48.60070206803374
At time: 511.8451187610626 and batch: 800, loss is 3.8210391330718996 and perplexity is 45.65162179211934
At time: 512.2202243804932 and batch: 850, loss is 3.7807091951370237 and perplexity is 43.847126880710476
At time: 512.5784244537354 and batch: 900, loss is 3.6896349668502806 and perplexity is 40.03023192831918
At time: 512.9610755443573 and batch: 950, loss is 3.8297935914993286 and perplexity is 46.05303151592792
At time: 513.3388311862946 and batch: 1000, loss is 3.8492988204956053 and perplexity is 46.960124208226155
At time: 513.7335073947906 and batch: 1050, loss is 3.763854970932007 and perplexity is 43.11431044695681
At time: 514.10209608078 and batch: 1100, loss is 3.9325500774383544 and perplexity is 51.036960066561434
At time: 514.465934753418 and batch: 1150, loss is 3.824507460594177 and perplexity is 45.81023146456682
At time: 514.8413789272308 and batch: 1200, loss is 3.775863037109375 and perplexity is 43.63515082438072
At time: 515.2011291980743 and batch: 1250, loss is 3.7183486795425416 and perplexity is 41.196309600596486
At time: 515.5741512775421 and batch: 1300, loss is 3.802214756011963 and perplexity is 44.80029642425851
At time: 515.9484198093414 and batch: 1350, loss is 3.767220125198364 and perplexity is 43.25964114566192
At time: 516.308274269104 and batch: 1400, loss is 3.651144108772278 and perplexity is 38.518710442953555
At time: 516.6935896873474 and batch: 1450, loss is 3.745696544647217 and perplexity is 42.338487597353144
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.530132065471421 and perplexity of 92.77081209415944
Finished 44 epochs...
Completing Train Step...
At time: 517.9591262340546 and batch: 50, loss is 3.9368652725219726 and perplexity is 51.25767036724026
At time: 518.3415699005127 and batch: 100, loss is 3.96913037776947 and perplexity is 52.938474342563154
At time: 518.728481054306 and batch: 150, loss is 3.7844285345077515 and perplexity is 44.010512881654385
At time: 519.0917603969574 and batch: 200, loss is 3.9009413957595824 and perplexity is 49.448978259368886
At time: 519.4603130817413 and batch: 250, loss is 3.9623853969573974 and perplexity is 52.58260685775514
At time: 519.8335223197937 and batch: 300, loss is 3.966575388908386 and perplexity is 52.80338977356531
At time: 520.2038607597351 and batch: 350, loss is 3.9448009014129637 and perplexity is 51.66605045036915
At time: 520.5785253047943 and batch: 400, loss is 3.76441867351532 and perplexity is 43.138620946435445
At time: 520.960125207901 and batch: 450, loss is 3.8494202518463134 and perplexity is 46.96582698577917
At time: 521.3450629711151 and batch: 500, loss is 3.8308161640167238 and perplexity is 46.10014816628908
At time: 521.7101275920868 and batch: 550, loss is 3.87498468875885 and perplexity is 48.181960559833826
At time: 522.0819773674011 and batch: 600, loss is 3.823689603805542 and perplexity is 45.77278057259524
At time: 522.4509289264679 and batch: 650, loss is 3.8698198556900025 and perplexity is 47.93375031062487
At time: 522.8118207454681 and batch: 700, loss is 3.9364363956451416 and perplexity is 51.2356918510351
At time: 523.1790587902069 and batch: 750, loss is 3.8835596656799316 and perplexity is 48.59689624910323
At time: 523.5559186935425 and batch: 800, loss is 3.8209786653518676 and perplexity is 45.64886142609117
At time: 523.9150636196136 and batch: 850, loss is 3.780662527084351 and perplexity is 43.84508066843039
At time: 524.2907266616821 and batch: 900, loss is 3.689591827392578 and perplexity is 40.028505083069945
At time: 524.6740713119507 and batch: 950, loss is 3.829747447967529 and perplexity is 46.05090651543159
At time: 525.0548949241638 and batch: 1000, loss is 3.8492578411102296 and perplexity is 46.9581998506287
At time: 525.4255366325378 and batch: 1050, loss is 3.7638614845275877 and perplexity is 43.1145912770534
At time: 525.8011376857758 and batch: 1100, loss is 3.9325440073013307 and perplexity is 51.03665026616083
At time: 526.1728358268738 and batch: 1150, loss is 3.8244810056686402 and perplexity is 45.809019574334904
At time: 526.5332570075989 and batch: 1200, loss is 3.7758665323257445 and perplexity is 43.635303338940716
At time: 526.9075541496277 and batch: 1250, loss is 3.7183546304702757 and perplexity is 41.196554757587286
At time: 527.2852492332458 and batch: 1300, loss is 3.80223527431488 and perplexity is 44.80121565974187
At time: 527.6567983627319 and batch: 1350, loss is 3.7672316026687622 and perplexity is 43.26013765976196
At time: 528.0331637859344 and batch: 1400, loss is 3.6511584377288817 and perplexity is 38.51926237983826
At time: 528.3944923877716 and batch: 1450, loss is 3.745705361366272 and perplexity is 42.3388608855491
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.530127370459402 and perplexity of 92.7703765351041
Finished 45 epochs...
Completing Train Step...
At time: 529.6038224697113 and batch: 50, loss is 3.9367284297943117 and perplexity is 51.2506566077156
At time: 529.9822671413422 and batch: 100, loss is 3.969017200469971 and perplexity is 52.932483248031794
At time: 530.3587613105774 and batch: 150, loss is 3.784319128990173 and perplexity is 44.00569815209747
At time: 530.7442967891693 and batch: 200, loss is 3.9008141946792603 and perplexity is 49.442688695941584
At time: 531.1200275421143 and batch: 250, loss is 3.9622598695755005 and perplexity is 52.57600671504095
At time: 531.4824540615082 and batch: 300, loss is 3.9664707517623903 and perplexity is 52.79786486662078
At time: 531.8543236255646 and batch: 350, loss is 3.944688849449158 and perplexity is 51.66026149229221
At time: 532.2353637218475 and batch: 400, loss is 3.7643073701858523 and perplexity is 43.133819741495465
At time: 532.6215295791626 and batch: 450, loss is 3.8493066596984864 and perplexity is 46.96049233961007
At time: 532.9933848381042 and batch: 500, loss is 3.830718035697937 and perplexity is 46.095624658199455
At time: 533.372894525528 and batch: 550, loss is 3.8748912477493285 and perplexity is 48.17745859913554
At time: 533.7550249099731 and batch: 600, loss is 3.82360595703125 and perplexity is 45.76895198727661
At time: 534.1382269859314 and batch: 650, loss is 3.8697424936294555 and perplexity is 47.93004220036647
At time: 534.5241887569427 and batch: 700, loss is 3.9363643074035646 and perplexity is 51.231998493229014
At time: 534.9142644405365 and batch: 750, loss is 3.8834832906723022 and perplexity is 48.59318480251413
At time: 535.2981696128845 and batch: 800, loss is 3.8209182596206666 and perplexity is 45.64610405651953
At time: 535.6698491573334 and batch: 850, loss is 3.7806158113479613 and perplexity is 43.843032461042036
At time: 536.0433382987976 and batch: 900, loss is 3.6895482206344603 and perplexity is 40.026759607788506
At time: 536.427259683609 and batch: 950, loss is 3.829700722694397 and perplexity is 46.048754824516244
At time: 536.797735452652 and batch: 1000, loss is 3.8492173767089843 and perplexity is 46.95629975363159
At time: 537.1726524829865 and batch: 1050, loss is 3.7638646173477173 and perplexity is 43.11472634752441
At time: 537.532333612442 and batch: 1100, loss is 3.9325349283218385 and perplexity is 51.03618690756312
At time: 537.9347064495087 and batch: 1150, loss is 3.824452691078186 and perplexity is 45.807722529069295
At time: 538.303619146347 and batch: 1200, loss is 3.7758666181564333 and perplexity is 43.635307084189016
At time: 538.6743686199188 and batch: 1250, loss is 3.71835590839386 and perplexity is 41.19660740366984
At time: 539.0401055812836 and batch: 1300, loss is 3.8022519016265868 and perplexity is 44.80196058971255
At time: 539.4118051528931 and batch: 1350, loss is 3.767238998413086 and perplexity is 43.2604576018626
At time: 539.7856798171997 and batch: 1400, loss is 3.651167769432068 and perplexity is 38.51962183183889
At time: 540.159548997879 and batch: 1450, loss is 3.745710186958313 and perplexity is 42.33906519611218
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.5301205887753735 and perplexity of 92.76974739785655
Finished 46 epochs...
Completing Train Step...
At time: 541.3837170600891 and batch: 50, loss is 3.936594705581665 and perplexity is 51.24380361222903
At time: 541.774346113205 and batch: 100, loss is 3.9689082098007202 and perplexity is 52.926714415637655
At time: 542.1408061981201 and batch: 150, loss is 3.784212908744812 and perplexity is 44.00102410428612
At time: 542.5217597484589 and batch: 200, loss is 3.900690779685974 and perplexity is 49.43658710336987
At time: 542.8955917358398 and batch: 250, loss is 3.962139005661011 and perplexity is 52.56965255706307
At time: 543.2539479732513 and batch: 300, loss is 3.9663693475723267 and perplexity is 52.79251121334292
At time: 543.6299493312836 and batch: 350, loss is 3.9445800733566285 and perplexity is 51.65464239652521
At time: 544.0165555477142 and batch: 400, loss is 3.7641989517211916 and perplexity is 43.129143492484594
At time: 544.3950691223145 and batch: 450, loss is 3.849196367263794 and perplexity is 46.95531323818869
At time: 544.7765655517578 and batch: 500, loss is 3.830621461868286 and perplexity is 46.09117324214467
At time: 545.1532826423645 and batch: 550, loss is 3.874800052642822 and perplexity is 48.17306525099636
At time: 545.5455420017242 and batch: 600, loss is 3.823524236679077 and perplexity is 45.765211885224936
At time: 545.9159519672394 and batch: 650, loss is 3.8696671295166016 and perplexity is 47.92643013136889
At time: 546.280962228775 and batch: 700, loss is 3.936293935775757 and perplexity is 51.22839334095091
At time: 546.6468126773834 and batch: 750, loss is 3.8834086656570435 and perplexity is 48.58955867065852
At time: 547.0059719085693 and batch: 800, loss is 3.8208576822280884 and perplexity is 45.64333901830469
At time: 547.4025022983551 and batch: 850, loss is 3.7805690717697145 and perplexity is 43.84098330408449
At time: 547.768795967102 and batch: 900, loss is 3.6895037698745727 and perplexity is 40.024980427451354
At time: 548.1285307407379 and batch: 950, loss is 3.8296531295776366 and perplexity is 46.04656327290301
At time: 548.5060827732086 and batch: 1000, loss is 3.849177083969116 and perplexity is 46.954407793776824
At time: 548.8958125114441 and batch: 1050, loss is 3.763864903450012 and perplexity is 43.11473868274832
At time: 549.2847199440002 and batch: 1100, loss is 3.932523021697998 and perplexity is 51.03557924250098
At time: 549.6557350158691 and batch: 1150, loss is 3.824422626495361 and perplexity is 45.80634535970341
At time: 550.0290002822876 and batch: 1200, loss is 3.775863666534424 and perplexity is 43.635178289446316
At time: 550.404620885849 and batch: 1250, loss is 3.7183536005020144 and perplexity is 41.19651232646526
At time: 550.7796640396118 and batch: 1300, loss is 3.8022652864456177 and perplexity is 44.802560259860506
At time: 551.1528527736664 and batch: 1350, loss is 3.767243056297302 and perplexity is 43.26063314814686
At time: 551.5308086872101 and batch: 1400, loss is 3.6511728811264037 and perplexity is 38.519818732874874
At time: 551.8997464179993 and batch: 1450, loss is 3.745711631774902 and perplexity is 42.33912636834013
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.530117458767361 and perplexity of 92.76945702825827
Finished 47 epochs...
Completing Train Step...
At time: 553.1591787338257 and batch: 50, loss is 3.9364636659622194 and perplexity is 51.23708908364898
At time: 553.5389575958252 and batch: 100, loss is 3.9688027191162107 and perplexity is 52.921131434786524
At time: 553.9187760353088 and batch: 150, loss is 3.784109330177307 and perplexity is 43.996466777265425
At time: 554.2961626052856 and batch: 200, loss is 3.900570721626282 and perplexity is 49.430652198918125
At time: 554.6872527599335 and batch: 250, loss is 3.962021884918213 and perplexity is 52.56349592084891
At time: 555.0627646446228 and batch: 300, loss is 3.9662705516815184 and perplexity is 52.78729578780514
At time: 555.4347383975983 and batch: 350, loss is 3.9444738483428954 and perplexity is 51.64915567284607
At time: 555.8022844791412 and batch: 400, loss is 3.7640929555892946 and perplexity is 43.12457221237564
At time: 556.1703584194183 and batch: 450, loss is 3.849088959693909 and perplexity is 46.95027015293819
At time: 556.5394871234894 and batch: 500, loss is 3.830526256561279 and perplexity is 46.086785326725575
At time: 556.9271245002747 and batch: 550, loss is 3.8747110319137574 and perplexity is 48.16877704047908
At time: 557.299654006958 and batch: 600, loss is 3.8234441566467283 and perplexity is 45.76154715231464
At time: 557.6639082431793 and batch: 650, loss is 3.8695933628082275 and perplexity is 47.92289488676726
At time: 558.0388617515564 and batch: 700, loss is 3.9362246417999267 and perplexity is 51.224843644888615
At time: 558.4298324584961 and batch: 750, loss is 3.8833353614807127 and perplexity is 48.58599698362676
At time: 558.7915427684784 and batch: 800, loss is 3.8207972764968874 and perplexity is 45.640581982308056
At time: 559.1621251106262 and batch: 850, loss is 3.780522360801697 and perplexity is 43.8389354971434
At time: 559.5344922542572 and batch: 900, loss is 3.6894588088989257 and perplexity is 40.023180905735515
At time: 559.8978476524353 and batch: 950, loss is 3.82960506439209 and perplexity is 46.04435008948446
At time: 560.2712457180023 and batch: 1000, loss is 3.8491369009017946 and perplexity is 46.952521059555046
At time: 560.6447610855103 and batch: 1050, loss is 3.7638628101348877 and perplexity is 43.11464843010821
At time: 561.0220038890839 and batch: 1100, loss is 3.932509140968323 and perplexity is 51.034870836338314
At time: 561.3978481292725 and batch: 1150, loss is 3.824391107559204 and perplexity is 45.804901615181194
At time: 561.7700238227844 and batch: 1200, loss is 3.7758582830429077 and perplexity is 43.6349433804665
At time: 562.1319243907928 and batch: 1250, loss is 3.718348274230957 and perplexity is 41.19629290325834
At time: 562.5137915611267 and batch: 1300, loss is 3.8022756814956664 and perplexity is 44.80302598713734
At time: 562.8809411525726 and batch: 1350, loss is 3.767244415283203 and perplexity is 43.26069193877733
At time: 563.2490701675415 and batch: 1400, loss is 3.6511745405197145 and perplexity is 38.51988265245744
At time: 563.6246602535248 and batch: 1450, loss is 3.7457103157043456 and perplexity is 42.33907064709919
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.530113807091346 and perplexity of 92.76911826487566
Finished 48 epochs...
Completing Train Step...
At time: 564.8798367977142 and batch: 50, loss is 3.936334843635559 and perplexity is 51.230489027748334
At time: 565.2417352199554 and batch: 100, loss is 3.9687002086639405 and perplexity is 52.915706743717
At time: 565.6158318519592 and batch: 150, loss is 3.784008183479309 and perplexity is 43.99201690497606
At time: 566.0091888904572 and batch: 200, loss is 3.9004533910751342 and perplexity is 49.42485281348123
At time: 566.3805546760559 and batch: 250, loss is 3.9619075298309325 and perplexity is 52.55748536136069
At time: 566.7433414459229 and batch: 300, loss is 3.966173939704895 and perplexity is 52.782196149165536
At time: 567.1192500591278 and batch: 350, loss is 3.9443698358535766 and perplexity is 51.643783794969366
At time: 567.477486371994 and batch: 400, loss is 3.763989052772522 and perplexity is 43.120091680624625
At time: 567.8409802913666 and batch: 450, loss is 3.8489837551116945 and perplexity is 46.94533102919568
At time: 568.2084279060364 and batch: 500, loss is 3.8304323625564574 and perplexity is 46.08245825702801
At time: 568.5811161994934 and batch: 550, loss is 3.8746235513687135 and perplexity is 48.164563393918215
At time: 568.940762758255 and batch: 600, loss is 3.8233657550811766 and perplexity is 45.757959516015816
At time: 569.3144047260284 and batch: 650, loss is 3.86952100276947 and perplexity is 47.919427309694406
At time: 569.6917679309845 and batch: 700, loss is 3.9361564779281615 and perplexity is 51.221352080215844
At time: 570.0490901470184 and batch: 750, loss is 3.883263278007507 and perplexity is 48.58249486243907
At time: 570.4264488220215 and batch: 800, loss is 3.820736746788025 and perplexity is 45.63781945477669
At time: 570.8023359775543 and batch: 850, loss is 3.780475640296936 and perplexity is 43.836887367793985
At time: 571.1747877597809 and batch: 900, loss is 3.689413514137268 and perplexity is 40.02136810635107
At time: 571.5711436271667 and batch: 950, loss is 3.8295563316345214 and perplexity is 46.042106276008205
At time: 571.9453883171082 and batch: 1000, loss is 3.8490966844558714 and perplexity is 46.95063283400001
At time: 572.3234193325043 and batch: 1050, loss is 3.763858642578125 and perplexity is 43.114468747737995
At time: 572.6909840106964 and batch: 1100, loss is 3.932493257522583 and perplexity is 51.034060233174145
At time: 573.0595517158508 and batch: 1150, loss is 3.8243583726882933 and perplexity is 45.803402222181084
At time: 573.4235420227051 and batch: 1200, loss is 3.7758507919311524 and perplexity is 43.63461650745352
At time: 573.7867538928986 and batch: 1250, loss is 3.718340268135071 and perplexity is 41.1959630831075
At time: 574.1492667198181 and batch: 1300, loss is 3.802283606529236 and perplexity is 44.80338105402926
At time: 574.513815164566 and batch: 1350, loss is 3.767243227958679 and perplexity is 43.260640574327354
At time: 574.8888781070709 and batch: 1400, loss is 3.6511733102798463 and perplexity is 38.51983526379124
At time: 575.2630875110626 and batch: 1450, loss is 3.7457067489624025 and perplexity is 42.338919634829395
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.530111720419337 and perplexity of 92.76892468635529
Finished 49 epochs...
Completing Train Step...
At time: 576.4935789108276 and batch: 50, loss is 3.936208086013794 and perplexity is 51.22399558435272
At time: 576.8828580379486 and batch: 100, loss is 3.968600130081177 and perplexity is 52.910411279765846
At time: 577.2592685222626 and batch: 150, loss is 3.7839088249206543 and perplexity is 43.98764613872417
At time: 577.6194672584534 and batch: 200, loss is 3.9003385877609253 and perplexity is 49.419179002266354
At time: 577.979113817215 and batch: 250, loss is 3.9617961645126343 and perplexity is 52.551632606177485
At time: 578.3391296863556 and batch: 300, loss is 3.966079149246216 and perplexity is 52.77719313770508
At time: 578.7162761688232 and batch: 350, loss is 3.9442679834365846 and perplexity is 51.638524018632246
At time: 579.0981497764587 and batch: 400, loss is 3.7638869190216067 and perplexity is 43.11568788881319
At time: 579.4686563014984 and batch: 450, loss is 3.8488804960250853 and perplexity is 46.940483747460284
At time: 579.8282442092896 and batch: 500, loss is 3.830339403152466 and perplexity is 46.07817465827746
At time: 580.2042820453644 and batch: 550, loss is 3.874537634849548 and perplexity is 48.16042544004613
At time: 580.5853204727173 and batch: 600, loss is 3.8232887172698975 and perplexity is 45.754434558745345
At time: 580.9604527950287 and batch: 650, loss is 3.8694497680664064 and perplexity is 47.91601390509689
At time: 581.3207447528839 and batch: 700, loss is 3.9360895013809203 and perplexity is 51.21792156579178
At time: 581.6996252536774 and batch: 750, loss is 3.883192195892334 and perplexity is 48.57904163867654
At time: 582.0726654529572 and batch: 800, loss is 3.820676159858704 and perplexity is 45.63505448319643
At time: 582.4500703811646 and batch: 850, loss is 3.7804288148880003 and perplexity is 43.83483473567457
At time: 582.8217160701752 and batch: 900, loss is 3.6893679094314575 and perplexity is 40.01954298524982
At time: 583.2052097320557 and batch: 950, loss is 3.829507327079773 and perplexity is 46.039850058373396
At time: 583.594658613205 and batch: 1000, loss is 3.849056625366211 and perplexity is 46.94875207206075
At time: 583.9652097225189 and batch: 1050, loss is 3.763852806091309 and perplexity is 43.1142171114439
At time: 584.3323514461517 and batch: 1100, loss is 3.9324760246276855 and perplexity is 51.03318077615578
At time: 584.7113406658173 and batch: 1150, loss is 3.8243242406845095 and perplexity is 45.80183888696316
At time: 585.0727646350861 and batch: 1200, loss is 3.775841236114502 and perplexity is 43.63419954505078
At time: 585.4674551486969 and batch: 1250, loss is 3.7183299255371094 and perplexity is 41.19553701202704
At time: 585.8712673187256 and batch: 1300, loss is 3.802289309501648 and perplexity is 44.80363656720397
At time: 586.2414829730988 and batch: 1350, loss is 3.7672400522232055 and perplexity is 43.26050319019462
At time: 586.6042461395264 and batch: 1400, loss is 3.6511694049835204 and perplexity is 38.51968483271384
At time: 586.9793698787689 and batch: 1450, loss is 3.745701036453247 and perplexity is 42.33867777405416
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.530109112079327 and perplexity of 92.76868271377285
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f830fadb9e8>
SETTINGS FOR THIS RUN
{'batch_size': 20, 'seq_len': 35, 'anneal': 8.0, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'dropout': 0.0, 'lr': 6.250041585959168, 'num_layers': 1, 'wordvec_dim': 200, 'data': 'ptb'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.6729438304901123 and batch: 50, loss is 6.731028089523315 and perplexity is 838.0083708583609
At time: 1.0627825260162354 and batch: 100, loss is 5.943975191116333 and perplexity is 381.44824936979444
At time: 1.445573329925537 and batch: 150, loss is 5.540611743927002 and perplexity is 254.83384484193766
At time: 1.819366216659546 and batch: 200, loss is 5.3448409080505375 and perplexity is 209.524548278325
At time: 2.189330816268921 and batch: 250, loss is 5.248376712799073 and perplexity is 190.25717561521412
At time: 2.5634944438934326 and batch: 300, loss is 5.2059837818145756 and perplexity is 182.36018718704398
At time: 2.9353790283203125 and batch: 350, loss is 5.1903919506072995 and perplexity is 179.53890952739968
At time: 3.2937707901000977 and batch: 400, loss is 5.012072458267212 and perplexity is 150.21572960794356
At time: 3.6604232788085938 and batch: 450, loss is 4.993261671066284 and perplexity is 147.41646421868637
At time: 4.024536848068237 and batch: 500, loss is 4.947503986358643 and perplexity is 140.82302868600055
At time: 4.412381649017334 and batch: 550, loss is 4.991040735244751 and perplexity is 147.0894250135905
At time: 4.784692049026489 and batch: 600, loss is 4.812959594726562 and perplexity is 123.09539141137041
At time: 5.150586128234863 and batch: 650, loss is 4.927039051055909 and perplexity is 137.97038367247174
At time: 5.522089004516602 and batch: 700, loss is 4.9264563465118405 and perplexity is 137.89001112195837
At time: 5.894376039505005 and batch: 750, loss is 4.8418239307403566 and perplexity is 126.70023356067571
At time: 6.275787830352783 and batch: 800, loss is 4.73437915802002 and perplexity is 113.79278944254854
At time: 6.6508965492248535 and batch: 850, loss is 4.686606941223144 and perplexity is 108.4844604672292
At time: 7.049274921417236 and batch: 900, loss is 4.63848768234253 and perplexity is 103.38787398681366
At time: 7.433127403259277 and batch: 950, loss is 4.6898789215087895 and perplexity is 108.8400008265031
At time: 7.811281442642212 and batch: 1000, loss is 4.705718832015991 and perplexity is 110.57774320755348
At time: 8.177053213119507 and batch: 1050, loss is 4.644862470626831 and perplexity is 104.04905500004818
At time: 8.568091869354248 and batch: 1100, loss is 4.7479031467437744 and perplexity is 115.3421751664178
At time: 8.950275897979736 and batch: 1150, loss is 4.6821799659729 and perplexity is 108.00526392393527
At time: 9.309922218322754 and batch: 1200, loss is 4.601727857589721 and perplexity is 99.65635896214943
At time: 9.677739381790161 and batch: 1250, loss is 4.534540891647339 and perplexity is 93.1807254332284
At time: 10.044692754745483 and batch: 1300, loss is 4.638321151733399 and perplexity is 103.3706581747015
At time: 10.43828272819519 and batch: 1350, loss is 4.5944272232055665 and perplexity is 98.9314536752822
At time: 10.802305936813354 and batch: 1400, loss is 4.423851737976074 and perplexity is 83.41696767198496
At time: 11.169744491577148 and batch: 1450, loss is 4.537250690460205 and perplexity is 93.43356887509937
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.676585662059295 and perplexity of 107.40273658520249
Finished 1 epochs...
Completing Train Step...
At time: 12.451005697250366 and batch: 50, loss is 4.601224422454834 and perplexity is 99.60620107631331
At time: 12.834684371948242 and batch: 100, loss is 4.58464262008667 and perplexity is 97.96816902933953
At time: 13.207631587982178 and batch: 150, loss is 4.398708009719849 and perplexity is 81.34570288555443
At time: 13.596707105636597 and batch: 200, loss is 4.509057331085205 and perplexity is 90.83614972353821
At time: 13.968865156173706 and batch: 250, loss is 4.552097635269165 and perplexity is 94.83112093264667
At time: 14.342106103897095 and batch: 300, loss is 4.5300649070739745 and perplexity is 92.76458196429446
At time: 14.72091794013977 and batch: 350, loss is 4.532266139984131 and perplexity is 92.96900332197883
At time: 15.103764295578003 and batch: 400, loss is 4.356243028640747 and perplexity is 77.9636762126215
At time: 15.473564624786377 and batch: 450, loss is 4.4103062725067135 and perplexity is 82.29466423796404
At time: 15.832718133926392 and batch: 500, loss is 4.391172037124634 and perplexity is 80.7349879536163
At time: 16.206318616867065 and batch: 550, loss is 4.467341938018799 and perplexity is 87.12483175639535
At time: 16.574247121810913 and batch: 600, loss is 4.356246681213379 and perplexity is 77.96396098113158
At time: 16.953001737594604 and batch: 650, loss is 4.436019682884217 and perplexity is 84.43818117389085
At time: 17.31121850013733 and batch: 700, loss is 4.472070302963257 and perplexity is 87.53776523741794
At time: 17.680623531341553 and batch: 750, loss is 4.403505892753601 and perplexity is 81.73692782856669
At time: 18.05301547050476 and batch: 800, loss is 4.314576592445373 and perplexity is 74.78195349570859
At time: 18.41156244277954 and batch: 850, loss is 4.27858256816864 and perplexity is 72.13811664347566
At time: 18.79306674003601 and batch: 900, loss is 4.20111584186554 and perplexity is 66.76078397208352
At time: 19.168663501739502 and batch: 950, loss is 4.321845378875732 and perplexity is 75.32750790170547
At time: 19.544499397277832 and batch: 1000, loss is 4.334622020721436 and perplexity is 76.29611508839312
At time: 19.9244647026062 and batch: 1050, loss is 4.271337265968323 and perplexity is 71.61734304741228
At time: 20.308034658432007 and batch: 1100, loss is 4.418906364440918 and perplexity is 83.00545798092587
At time: 20.674612760543823 and batch: 1150, loss is 4.335771822929383 and perplexity is 76.38389098276781
At time: 21.03411340713501 and batch: 1200, loss is 4.27651159286499 and perplexity is 71.98887497669897
At time: 21.401904821395874 and batch: 1250, loss is 4.177671747207642 and perplexity is 65.21384201265955
At time: 21.771827220916748 and batch: 1300, loss is 4.298720216751098 and perplexity is 73.60553426685827
At time: 22.13065791130066 and batch: 1350, loss is 4.280177793502808 and perplexity is 72.25328503004557
At time: 22.503060817718506 and batch: 1400, loss is 4.116047644615174 and perplexity is 61.316418440900236
At time: 22.86802363395691 and batch: 1450, loss is 4.236594176292419 and perplexity is 69.17186302772944
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.519473866519765 and perplexity of 91.78729290395576
Finished 2 epochs...
Completing Train Step...
At time: 24.114381790161133 and batch: 50, loss is 4.290240182876587 and perplexity is 72.98399590073795
At time: 24.477349758148193 and batch: 100, loss is 4.303287334442139 and perplexity is 73.94246822742996
At time: 24.853020668029785 and batch: 150, loss is 4.120254282951355 and perplexity is 61.57489772060813
At time: 25.22523593902588 and batch: 200, loss is 4.261984162330627 and perplexity is 70.95062143423011
At time: 25.605613470077515 and batch: 250, loss is 4.319342608451843 and perplexity is 75.13921616660275
At time: 25.98076319694519 and batch: 300, loss is 4.291394095420838 and perplexity is 73.06826165744417
At time: 26.37615942955017 and batch: 350, loss is 4.293758935928345 and perplexity is 73.24126091963188
At time: 26.761889696121216 and batch: 400, loss is 4.105722260475159 and perplexity is 60.68656022635963
At time: 27.141971111297607 and batch: 450, loss is 4.1788851833343506 and perplexity is 65.29302287526313
At time: 27.506959199905396 and batch: 500, loss is 4.16713360786438 and perplexity is 64.53021784826795
At time: 27.88516330718994 and batch: 550, loss is 4.238722629547119 and perplexity is 69.31924890105338
At time: 28.25801181793213 and batch: 600, loss is 4.144430074691773 and perplexity is 63.081659820451655
At time: 28.61713457107544 and batch: 650, loss is 4.219195499420166 and perplexity is 67.97877332231391
At time: 28.976680755615234 and batch: 700, loss is 4.266082344055175 and perplexity is 71.24198660024449
At time: 29.335468292236328 and batch: 750, loss is 4.205335116386413 and perplexity is 67.04306113053714
At time: 29.692227602005005 and batch: 800, loss is 4.114602198600769 and perplexity is 61.2278528920272
At time: 30.07132577896118 and batch: 850, loss is 4.090496339797974 and perplexity is 59.769550349698804
At time: 30.441134929656982 and batch: 900, loss is 4.00187361240387 and perplexity is 54.70054169546579
At time: 30.805578231811523 and batch: 950, loss is 4.14304856300354 and perplexity is 62.99457194040983
At time: 31.18297290802002 and batch: 1000, loss is 4.154975485801697 and perplexity is 63.75040173866737
At time: 31.554478645324707 and batch: 1050, loss is 4.090745005607605 and perplexity is 59.78441484139666
At time: 31.9220073223114 and batch: 1100, loss is 4.252584285736084 and perplexity is 70.28681906627575
At time: 32.29682683944702 and batch: 1150, loss is 4.161250333786011 and perplexity is 64.15168349285769
At time: 32.67083287239075 and batch: 1200, loss is 4.10448929309845 and perplexity is 60.611781786557444
At time: 33.04225778579712 and batch: 1250, loss is 3.992799286842346 and perplexity is 54.20641648888295
At time: 33.41393971443176 and batch: 1300, loss is 4.113653521537781 and perplexity is 61.169794975833526
At time: 33.79814410209656 and batch: 1350, loss is 4.1137300395965575 and perplexity is 61.17447574888037
At time: 34.17319941520691 and batch: 1400, loss is 3.9492345523834227 and perplexity is 51.89562824291715
At time: 34.54694128036499 and batch: 1450, loss is 4.074981627464294 and perplexity is 58.849399365723905
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.464600131043002 and perplexity of 86.88627946652994
Finished 3 epochs...
Completing Train Step...
At time: 35.812910079956055 and batch: 50, loss is 4.117663125991822 and perplexity is 61.41555402726086
At time: 36.182798862457275 and batch: 100, loss is 4.148727684020996 and perplexity is 63.35334352726161
At time: 36.555185317993164 and batch: 150, loss is 3.9641796016693114 and perplexity is 52.67703550557464
At time: 36.92548131942749 and batch: 200, loss is 4.111826958656311 and perplexity is 61.05816647813457
At time: 37.28283905982971 and batch: 250, loss is 4.180722994804382 and perplexity is 65.41312947445364
At time: 37.65920376777649 and batch: 300, loss is 4.146164174079895 and perplexity is 63.19114458944754
At time: 38.04325771331787 and batch: 350, loss is 4.143602437973023 and perplexity is 63.029472721463186
At time: 38.4143807888031 and batch: 400, loss is 3.9495368576049805 and perplexity is 51.911318933880416
At time: 38.793407917022705 and batch: 450, loss is 4.033780403137207 and perplexity is 56.4740027045336
At time: 39.170265913009644 and batch: 500, loss is 4.030122394561768 and perplexity is 56.26779769812806
At time: 39.55054044723511 and batch: 550, loss is 4.096250295639038 and perplexity is 60.11445302885773
At time: 39.90923881530762 and batch: 600, loss is 4.007069358825683 and perplexity is 54.98549146157862
At time: 40.28788161277771 and batch: 650, loss is 4.08098424911499 and perplexity is 59.20371238411721
At time: 40.66304850578308 and batch: 700, loss is 4.137150416374206 and perplexity is 62.624114298958
At time: 41.03462314605713 and batch: 750, loss is 4.070409774780273 and perplexity is 58.58096267535057
At time: 41.40571904182434 and batch: 800, loss is 3.987818078994751 and perplexity is 53.937074442953985
At time: 41.77322435379028 and batch: 850, loss is 3.967408456802368 and perplexity is 52.84739691020032
At time: 42.14237713813782 and batch: 900, loss is 3.8747629737854004 and perplexity is 48.17127908189311
At time: 42.51727271080017 and batch: 950, loss is 4.023669624328614 and perplexity is 55.90588345856103
At time: 42.89068794250488 and batch: 1000, loss is 4.036082043647766 and perplexity is 56.604135258682305
At time: 43.2714421749115 and batch: 1050, loss is 3.970540752410889 and perplexity is 53.01319010055138
At time: 43.628559827804565 and batch: 1100, loss is 4.133713517189026 and perplexity is 62.409250974845094
At time: 44.004995584487915 and batch: 1150, loss is 4.041687836647034 and perplexity is 56.92233737816281
At time: 44.38483715057373 and batch: 1200, loss is 3.9835015678405763 and perplexity is 53.70475622231063
At time: 44.75429844856262 and batch: 1250, loss is 3.876901502609253 and perplexity is 48.27440498024246
At time: 45.12750458717346 and batch: 1300, loss is 3.9902276515960695 and perplexity is 54.06719644597586
At time: 45.49827814102173 and batch: 1350, loss is 4.005458707809448 and perplexity is 54.897000307192
At time: 45.85624670982361 and batch: 1400, loss is 3.8388903903961182 and perplexity is 46.47387795779558
At time: 46.2140953540802 and batch: 1450, loss is 3.9612881422042845 and perplexity is 52.52494198476294
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.445139827891293 and perplexity of 85.21179198952493
Finished 4 epochs...
Completing Train Step...
At time: 47.42526340484619 and batch: 50, loss is 4.000781245231629 and perplexity is 54.64082124368292
At time: 47.82574963569641 and batch: 100, loss is 4.041435809135437 and perplexity is 56.90799319075995
At time: 48.2013041973114 and batch: 150, loss is 3.859035363197327 and perplexity is 47.4195866208002
At time: 48.56086564064026 and batch: 200, loss is 4.003788805007934 and perplexity is 54.80540415220744
At time: 48.93133234977722 and batch: 250, loss is 4.076608386039734 and perplexity is 58.94521104090447
At time: 49.302058696746826 and batch: 300, loss is 4.0436007690429685 and perplexity is 57.0313301760763
At time: 49.66374945640564 and batch: 350, loss is 4.039751968383789 and perplexity is 56.8122498236444
At time: 50.03728795051575 and batch: 400, loss is 3.8442177248001097 and perplexity is 46.72212049512838
At time: 50.41627216339111 and batch: 450, loss is 3.929638137817383 and perplexity is 50.88855969173736
At time: 50.81085515022278 and batch: 500, loss is 3.9334523677825928 and perplexity is 51.08303100438431
At time: 51.18644857406616 and batch: 550, loss is 3.9940089797973632 and perplexity is 54.27202928669467
At time: 51.59317588806152 and batch: 600, loss is 3.9078695726394654 and perplexity is 49.79275903919299
At time: 51.97975254058838 and batch: 650, loss is 3.976344428062439 and perplexity is 53.32175600324781
At time: 52.34218120574951 and batch: 700, loss is 4.040197825431823 and perplexity is 56.83758561329345
At time: 52.70807719230652 and batch: 750, loss is 3.9756030225753785 and perplexity is 53.282237612153516
At time: 53.08516240119934 and batch: 800, loss is 3.8955356216430665 and perplexity is 49.18238946121523
At time: 53.469473361968994 and batch: 850, loss is 3.8760046052932737 and perplexity is 48.23112720674577
At time: 53.8310604095459 and batch: 900, loss is 3.780237579345703 and perplexity is 43.826452758773875
At time: 54.20849323272705 and batch: 950, loss is 3.937962236404419 and perplexity is 51.31392903155139
At time: 54.5746374130249 and batch: 1000, loss is 3.947483539581299 and perplexity is 51.80483784426201
At time: 54.963584423065186 and batch: 1050, loss is 3.882231550216675 and perplexity is 48.53239680056683
At time: 55.36020302772522 and batch: 1100, loss is 4.046768174171448 and perplexity is 57.21225788817921
At time: 55.744373083114624 and batch: 1150, loss is 3.952997741699219 and perplexity is 52.09128924043921
At time: 56.131473779678345 and batch: 1200, loss is 3.894307198524475 and perplexity is 49.12200977047036
At time: 56.507845878601074 and batch: 1250, loss is 3.7891765451431274 and perplexity is 44.21997212875422
At time: 56.89583921432495 and batch: 1300, loss is 3.898320074081421 and perplexity is 49.31952632240454
At time: 57.27724099159241 and batch: 1350, loss is 3.91483642578125 and perplexity is 50.14086908671423
At time: 57.662009716033936 and batch: 1400, loss is 3.760774612426758 and perplexity is 42.9817072516155
At time: 58.07188892364502 and batch: 1450, loss is 3.874991188049316 and perplexity is 48.18227370940836
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.442815275273771 and perplexity of 85.01394273999803
Finished 5 epochs...
Completing Train Step...
At time: 59.377723932266235 and batch: 50, loss is 3.910889701843262 and perplexity is 49.9433669180547
At time: 59.76959466934204 and batch: 100, loss is 3.9585225200653076 and perplexity is 52.379878530174
At time: 60.138184547424316 and batch: 150, loss is 3.781173439025879 and perplexity is 43.86748736715874
At time: 60.50584268569946 and batch: 200, loss is 3.9222335243225097 and perplexity is 50.513141205598515
At time: 60.87005591392517 and batch: 250, loss is 3.994525880813599 and perplexity is 54.30008980541667
At time: 61.24554419517517 and batch: 300, loss is 3.9636058139801027 and perplexity is 52.64681874093034
At time: 61.60682988166809 and batch: 350, loss is 3.9621704149246217 and perplexity is 52.57130375706953
At time: 61.989577531814575 and batch: 400, loss is 3.7618758344650267 and perplexity is 43.02906572619542
At time: 62.37224268913269 and batch: 450, loss is 3.853958306312561 and perplexity is 47.17944480473914
At time: 62.77371144294739 and batch: 500, loss is 3.853030791282654 and perplexity is 47.135705448171066
At time: 63.16197085380554 and batch: 550, loss is 3.9166584539413454 and perplexity is 50.23231044122619
At time: 63.53238034248352 and batch: 600, loss is 3.833001527786255 and perplexity is 46.20100392298099
At time: 63.900336503982544 and batch: 650, loss is 3.8978757095336913 and perplexity is 49.297615341988035
At time: 64.2702522277832 and batch: 700, loss is 3.9639232397079467 and perplexity is 52.66353284829136
At time: 64.64303469657898 and batch: 750, loss is 3.907958674430847 and perplexity is 49.79719586088266
At time: 65.01301193237305 and batch: 800, loss is 3.825230565071106 and perplexity is 45.84336902754415
At time: 65.39442539215088 and batch: 850, loss is 3.806325831413269 and perplexity is 44.98485292377068
At time: 65.77646350860596 and batch: 900, loss is 3.708388857841492 and perplexity is 40.78803823222196
At time: 66.14699745178223 and batch: 950, loss is 3.869842777252197 and perplexity is 47.93484903965608
At time: 66.51688194274902 and batch: 1000, loss is 3.8770992040634153 and perplexity is 48.28394984379148
At time: 66.8805570602417 and batch: 1050, loss is 3.812810845375061 and perplexity is 45.27752829928429
At time: 67.24057054519653 and batch: 1100, loss is 3.9795820331573486 and perplexity is 53.49467055562926
At time: 67.60895681381226 and batch: 1150, loss is 3.8823947143554687 and perplexity is 48.54031619335728
At time: 67.98836064338684 and batch: 1200, loss is 3.821968660354614 and perplexity is 45.69407594816666
At time: 68.37456917762756 and batch: 1250, loss is 3.7190805149078368 and perplexity is 41.22646955159513
At time: 68.74958062171936 and batch: 1300, loss is 3.824084587097168 and perplexity is 45.79086362714978
At time: 69.11502385139465 and batch: 1350, loss is 3.8526784944534302 and perplexity is 47.119102613333204
At time: 69.48532223701477 and batch: 1400, loss is 3.6965030241012573 and perplexity is 40.306108135337375
At time: 69.86887335777283 and batch: 1450, loss is 3.8135853099822996 and perplexity is 45.31260772458864
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.449215619991987 and perplexity of 85.55980627336638
Annealing...
Finished 6 epochs...
Completing Train Step...
At time: 71.2661063671112 and batch: 50, loss is 3.8841673374176025 and perplexity is 48.62643618387507
At time: 71.6382565498352 and batch: 100, loss is 3.92044385433197 and perplexity is 50.42282019915991
At time: 72.03065419197083 and batch: 150, loss is 3.7312477922439573 and perplexity is 41.73114749231449
At time: 72.4166829586029 and batch: 200, loss is 3.854921669960022 and perplexity is 47.22491766670567
At time: 72.81086874008179 and batch: 250, loss is 3.9147295713424684 and perplexity is 50.13551159852874
At time: 73.1813371181488 and batch: 300, loss is 3.8920805168151857 and perplexity is 49.01275237565478
At time: 73.5549488067627 and batch: 350, loss is 3.8691726207733153 and perplexity is 47.9027359516068
At time: 73.93799304962158 and batch: 400, loss is 3.6606300926208495 and perplexity is 38.88583683263376
At time: 74.31579041481018 and batch: 450, loss is 3.745907530784607 and perplexity is 42.347421373732594
At time: 74.67719078063965 and batch: 500, loss is 3.7358684968948364 and perplexity is 41.9244209856031
At time: 75.04022550582886 and batch: 550, loss is 3.79483811378479 and perplexity is 44.47103657497021
At time: 75.40019965171814 and batch: 600, loss is 3.7115893602371215 and perplexity is 40.91878956967209
At time: 75.77237510681152 and batch: 650, loss is 3.7633541440963745 and perplexity is 43.092723049510376
At time: 76.14212799072266 and batch: 700, loss is 3.8332825756072997 and perplexity is 46.21399043929419
At time: 76.5061731338501 and batch: 750, loss is 3.7520986080169676 and perplexity is 42.61041078390439
At time: 76.86638903617859 and batch: 800, loss is 3.6737499380111696 and perplexity is 39.39937440023363
At time: 77.2369487285614 and batch: 850, loss is 3.630712447166443 and perplexity is 37.73969457994655
At time: 77.60639977455139 and batch: 900, loss is 3.5164023447036743 and perplexity is 33.66310211191137
At time: 77.96502017974854 and batch: 950, loss is 3.6766656112670897 and perplexity is 39.51441773536008
At time: 78.33523678779602 and batch: 1000, loss is 3.6739991760253905 and perplexity is 39.409195445908814
At time: 78.72093987464905 and batch: 1050, loss is 3.5936446046829222 and perplexity is 36.3663757531169
At time: 79.08149313926697 and batch: 1100, loss is 3.746798939704895 and perplexity is 42.385187072736066
At time: 79.46554517745972 and batch: 1150, loss is 3.645201425552368 and perplexity is 38.29048475688711
At time: 79.82656168937683 and batch: 1200, loss is 3.5641164779663086 and perplexity is 35.30824400766338
At time: 80.19433283805847 and batch: 1250, loss is 3.4504378986358644 and perplexity is 31.51418930819227
At time: 80.57397866249084 and batch: 1300, loss is 3.5356859254837034 and perplexity is 34.31854660842564
At time: 80.95475482940674 and batch: 1350, loss is 3.5374170446395876 and perplexity is 34.378007554003304
At time: 81.32797265052795 and batch: 1400, loss is 3.3700968170166017 and perplexity is 29.08134249032267
At time: 81.70755815505981 and batch: 1450, loss is 3.46924560546875 and perplexity is 32.11250780439008
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.325549003405449 and perplexity of 75.60700997360722
Finished 7 epochs...
Completing Train Step...
At time: 82.98499131202698 and batch: 50, loss is 3.7599300384521483 and perplexity is 42.94542134550938
At time: 83.36475706100464 and batch: 100, loss is 3.804806957244873 and perplexity is 44.916578455984045
At time: 83.76004314422607 and batch: 150, loss is 3.6213571500778197 and perplexity is 37.388274905907416
At time: 84.14451479911804 and batch: 200, loss is 3.760936236381531 and perplexity is 42.98865468654523
At time: 84.5237045288086 and batch: 250, loss is 3.829646153450012 and perplexity is 46.0462420473214
At time: 84.89770889282227 and batch: 300, loss is 3.8059576320648194 and perplexity is 44.968292579175184
At time: 85.27606987953186 and batch: 350, loss is 3.784174027442932 and perplexity is 43.99931332044386
At time: 85.65168690681458 and batch: 400, loss is 3.574097957611084 and perplexity is 35.6624372722663
At time: 86.0219669342041 and batch: 450, loss is 3.6659281778335573 and perplexity is 39.09240403186249
At time: 86.39328813552856 and batch: 500, loss is 3.664260835647583 and perplexity is 39.02727792630834
At time: 86.76311731338501 and batch: 550, loss is 3.7202874755859376 and perplexity is 41.27625831973935
At time: 87.13285803794861 and batch: 600, loss is 3.645312438011169 and perplexity is 38.29473571369887
At time: 87.4953179359436 and batch: 650, loss is 3.6965525770187377 and perplexity is 40.30810547007424
At time: 87.87245273590088 and batch: 700, loss is 3.7660911798477175 and perplexity is 43.21083093213581
At time: 88.24239087104797 and batch: 750, loss is 3.692340168952942 and perplexity is 40.13866840105949
At time: 88.60597920417786 and batch: 800, loss is 3.6158247804641723 and perplexity is 37.18200026979805
At time: 88.98500299453735 and batch: 850, loss is 3.577544913291931 and perplexity is 35.785576218336686
At time: 89.35873770713806 and batch: 900, loss is 3.46450562953949 and perplexity is 31.960655462900956
At time: 89.73116135597229 and batch: 950, loss is 3.6306661796569824 and perplexity is 37.73794849866427
At time: 90.12394070625305 and batch: 1000, loss is 3.6283861875534056 and perplexity is 37.65200428737444
At time: 90.50230407714844 and batch: 1050, loss is 3.553069715499878 and perplexity is 34.920348661475
At time: 90.86754536628723 and batch: 1100, loss is 3.7111643743515015 and perplexity is 40.90140335635764
At time: 91.23613095283508 and batch: 1150, loss is 3.6153042316436768 and perplexity is 37.16265026016323
At time: 91.60742282867432 and batch: 1200, loss is 3.5351981353759765 and perplexity is 34.30181044307828
At time: 91.97230291366577 and batch: 1250, loss is 3.4262634038925173 and perplexity is 30.761484490505993
At time: 92.34400010108948 and batch: 1300, loss is 3.5182865476608276 and perplexity is 33.72659002172829
At time: 92.70496845245361 and batch: 1350, loss is 3.529435977935791 and perplexity is 34.10472637085442
At time: 93.07650232315063 and batch: 1400, loss is 3.3672911882400514 and perplexity is 28.999865389666155
At time: 93.44728660583496 and batch: 1450, loss is 3.475707755088806 and perplexity is 32.320695580293574
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.318553435496795 and perplexity of 75.0799417213114
Finished 8 epochs...
Completing Train Step...
At time: 94.6875171661377 and batch: 50, loss is 3.7176297092437744 and perplexity is 41.166701322586505
At time: 95.06342124938965 and batch: 100, loss is 3.765679988861084 and perplexity is 43.19306668043197
At time: 95.42380785942078 and batch: 150, loss is 3.5807099294662477 and perplexity is 35.899017573037945
At time: 95.78810000419617 and batch: 200, loss is 3.7216699504852295 and perplexity is 41.333361173339206
At time: 96.1498954296112 and batch: 250, loss is 3.790995635986328 and perplexity is 44.30048548349124
At time: 96.51763129234314 and batch: 300, loss is 3.766741313934326 and perplexity is 43.23893290026935
At time: 96.88669967651367 and batch: 350, loss is 3.7443342638015746 and perplexity is 42.280849954907666
At time: 97.25774455070496 and batch: 400, loss is 3.5335281133651733 and perplexity is 34.244573471431885
At time: 97.62539744377136 and batch: 450, loss is 3.6267696380615235 and perplexity is 37.591187129192534
At time: 98.00776886940002 and batch: 500, loss is 3.627705192565918 and perplexity is 37.626372189841426
At time: 98.37165403366089 and batch: 550, loss is 3.682592897415161 and perplexity is 39.74932649421995
At time: 98.72906160354614 and batch: 600, loss is 3.610816626548767 and perplexity is 36.99625260425081
At time: 99.08626222610474 and batch: 650, loss is 3.662447896003723 and perplexity is 38.956587924678665
At time: 99.46398138999939 and batch: 700, loss is 3.731176047325134 and perplexity is 41.72815360192475
At time: 99.82932639122009 and batch: 750, loss is 3.6604158735275267 and perplexity is 38.87750763609269
At time: 100.21300840377808 and batch: 800, loss is 3.5858028745651245 and perplexity is 36.08231566600311
At time: 100.58373141288757 and batch: 850, loss is 3.54959445476532 and perplexity is 34.79920197502442
At time: 100.94754767417908 and batch: 900, loss is 3.4358044147491453 and perplexity is 31.05638473412638
At time: 101.31282329559326 and batch: 950, loss is 3.605359320640564 and perplexity is 36.79490265019913
At time: 101.69781684875488 and batch: 1000, loss is 3.603853931427002 and perplexity is 36.73955367196551
At time: 102.07078766822815 and batch: 1050, loss is 3.5304864645004272 and perplexity is 34.14057175194688
At time: 102.43966102600098 and batch: 1100, loss is 3.6906143045425415 and perplexity is 40.06945424608877
At time: 102.8130612373352 and batch: 1150, loss is 3.597813439369202 and perplexity is 36.51829761030161
At time: 103.188969373703 and batch: 1200, loss is 3.5179598999023436 and perplexity is 33.71557510579312
At time: 103.58532810211182 and batch: 1250, loss is 3.410786967277527 and perplexity is 30.289071390635172
At time: 103.95581102371216 and batch: 1300, loss is 3.506311450004578 and perplexity is 33.32511943500804
At time: 104.31354069709778 and batch: 1350, loss is 3.5220698308944702 and perplexity is 33.854428937215914
At time: 104.67393612861633 and batch: 1400, loss is 3.361653823852539 and perplexity is 28.83684252266519
At time: 105.03727221488953 and batch: 1450, loss is 3.4735681056976317 and perplexity is 32.25161455461512
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.317291259765625 and perplexity of 74.98523742028101
Finished 9 epochs...
Completing Train Step...
At time: 106.28594708442688 and batch: 50, loss is 3.6872863721847535 and perplexity is 39.93632745409009
At time: 106.67076539993286 and batch: 100, loss is 3.737463827133179 and perplexity is 41.99135766098099
At time: 107.063880443573 and batch: 150, loss is 3.5521666383743287 and perplexity is 34.8888271287125
At time: 107.4471447467804 and batch: 200, loss is 3.693333873748779 and perplexity is 40.17857421236243
At time: 107.81964945793152 and batch: 250, loss is 3.7628987216949463 and perplexity is 43.0731021263382
At time: 108.18928527832031 and batch: 300, loss is 3.738733525276184 and perplexity is 42.04470787199003
At time: 108.56964945793152 and batch: 350, loss is 3.716006360054016 and perplexity is 41.09992760454386
At time: 108.93462920188904 and batch: 400, loss is 3.505176887512207 and perplexity is 33.287331444914905
At time: 109.2943708896637 and batch: 450, loss is 3.5992274570465086 and perplexity is 36.56997165406344
At time: 109.65156722068787 and batch: 500, loss is 3.6015337228775026 and perplexity is 36.65440906025609
At time: 110.02073049545288 and batch: 550, loss is 3.6553964757919313 and perplexity is 38.68285489075209
At time: 110.38388466835022 and batch: 600, loss is 3.5857750034332274 and perplexity is 36.08131002503827
At time: 110.7537612915039 and batch: 650, loss is 3.6376239013671876 and perplexity is 38.00143420941501
At time: 111.1249589920044 and batch: 700, loss is 3.7061470699310304 and perplexity is 40.69670251712397
At time: 111.50028419494629 and batch: 750, loss is 3.637028260231018 and perplexity is 37.978805731861506
At time: 111.86970496177673 and batch: 800, loss is 3.563982834815979 and perplexity is 35.30352561799885
At time: 112.26122975349426 and batch: 850, loss is 3.5292964696884157 and perplexity is 34.09996881211827
At time: 112.64795279502869 and batch: 900, loss is 3.4144796657562257 and perplexity is 30.40112656413272
At time: 113.0305438041687 and batch: 950, loss is 3.5865820932388304 and perplexity is 36.11044263726805
At time: 113.395263671875 and batch: 1000, loss is 3.585996141433716 and perplexity is 36.08928985608164
At time: 113.76538610458374 and batch: 1050, loss is 3.512907109260559 and perplexity is 33.54564703044228
At time: 114.13663172721863 and batch: 1100, loss is 3.674657769203186 and perplexity is 39.43515862181871
At time: 114.4945638179779 and batch: 1150, loss is 3.5838471269607544 and perplexity is 36.01181672511781
At time: 114.85473966598511 and batch: 1200, loss is 3.503856210708618 and perplexity is 33.24339865531588
At time: 115.21359205245972 and batch: 1250, loss is 3.3974699926376344 and perplexity is 29.888386472008502
At time: 115.58928918838501 and batch: 1300, loss is 3.495310640335083 and perplexity is 32.9605252314689
At time: 115.9643063545227 and batch: 1350, loss is 3.5141422653198244 and perplexity is 33.58710673896807
At time: 116.3389184474945 and batch: 1400, loss is 3.3547884321212766 and perplexity is 28.639544342050502
At time: 116.70868253707886 and batch: 1450, loss is 3.468006339073181 and perplexity is 32.072736501300355
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.3180826301248665 and perplexity of 75.04460200114276
Annealing...
Finished 10 epochs...
Completing Train Step...
At time: 117.95512056350708 and batch: 50, loss is 3.680665316581726 and perplexity is 39.67278025256295
At time: 118.31698727607727 and batch: 100, loss is 3.743980131149292 and perplexity is 42.26587957627876
At time: 118.69625568389893 and batch: 150, loss is 3.554433069229126 and perplexity is 34.967989917612016
At time: 119.07272124290466 and batch: 200, loss is 3.697494888305664 and perplexity is 40.34610615423821
At time: 119.44205808639526 and batch: 250, loss is 3.7687890100479127 and perplexity is 43.32756380873871
At time: 119.81632781028748 and batch: 300, loss is 3.7399618339538576 and perplexity is 42.09638348182233
At time: 120.19202613830566 and batch: 350, loss is 3.7101896715164187 and perplexity is 40.861556065335826
At time: 120.56328821182251 and batch: 400, loss is 3.5009936475753785 and perplexity is 33.14837340068543
At time: 120.96189188957214 and batch: 450, loss is 3.5918717575073242 and perplexity is 36.30196084234383
At time: 121.33965039253235 and batch: 500, loss is 3.5880325984954835 and perplexity is 36.16285903006994
At time: 121.73027610778809 and batch: 550, loss is 3.6443558597564696 and perplexity is 38.25812131730535
At time: 122.09206557273865 and batch: 600, loss is 3.5757330083847045 and perplexity is 35.720794863729004
At time: 122.47169303894043 and batch: 650, loss is 3.623301272392273 and perplexity is 37.461032987839786
At time: 122.84282088279724 and batch: 700, loss is 3.687744793891907 and perplexity is 39.95463933045915
At time: 123.20197868347168 and batch: 750, loss is 3.6216109371185303 and perplexity is 37.39776476970436
At time: 123.57675623893738 and batch: 800, loss is 3.545744366645813 and perplexity is 34.66547956764059
At time: 123.95165944099426 and batch: 850, loss is 3.5108006763458253 and perplexity is 33.47505974518184
At time: 124.32515478134155 and batch: 900, loss is 3.384781503677368 and perplexity is 29.5115438478442
At time: 124.68921446800232 and batch: 950, loss is 3.554885778427124 and perplexity is 34.98382383209216
At time: 125.05210518836975 and batch: 1000, loss is 3.5536197233200073 and perplexity is 34.939560409141876
At time: 125.41071319580078 and batch: 1050, loss is 3.4807408666610717 and perplexity is 32.48377931227928
At time: 125.78443908691406 and batch: 1100, loss is 3.640870547294617 and perplexity is 38.125011908995305
At time: 126.16146063804626 and batch: 1150, loss is 3.545585103034973 and perplexity is 34.65995905781298
At time: 126.54424738883972 and batch: 1200, loss is 3.460717897415161 and perplexity is 31.839826040692305
At time: 126.92458987236023 and batch: 1250, loss is 3.3498700714111327 and perplexity is 28.499030564379233
At time: 127.30478549003601 and batch: 1300, loss is 3.453285269737244 and perplexity is 31.60404977244422
At time: 127.67126679420471 and batch: 1350, loss is 3.461228995323181 and perplexity is 31.856103468498734
At time: 128.0282063484192 and batch: 1400, loss is 3.293194975852966 and perplexity is 26.928763107369377
At time: 128.3968539237976 and batch: 1450, loss is 3.407367525100708 and perplexity is 30.1856765395288
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.304360935830663 and perplexity of 74.02189559302566
Finished 11 epochs...
Completing Train Step...
At time: 129.73967576026917 and batch: 50, loss is 3.6685333776474 and perplexity is 39.194380332211665
At time: 130.10341811180115 and batch: 100, loss is 3.725182867050171 and perplexity is 41.47881716027846
At time: 130.47699999809265 and batch: 150, loss is 3.5339950275421144 and perplexity is 34.26056648166005
At time: 130.86681246757507 and batch: 200, loss is 3.679750208854675 and perplexity is 39.63649199116682
At time: 131.26300382614136 and batch: 250, loss is 3.751446204185486 and perplexity is 42.582620654827004
At time: 131.65521502494812 and batch: 300, loss is 3.723421187400818 and perplexity is 41.405809099497226
At time: 132.01891493797302 and batch: 350, loss is 3.694220542907715 and perplexity is 40.214215113475426
At time: 132.37609577178955 and batch: 400, loss is 3.4840971851348876 and perplexity is 32.59298838858575
At time: 132.7476372718811 and batch: 450, loss is 3.5772088766098022 and perplexity is 35.773552972275205
At time: 133.12470126152039 and batch: 500, loss is 3.576322245597839 and perplexity is 35.74184908770242
At time: 133.49418997764587 and batch: 550, loss is 3.6314791440963745 and perplexity is 37.76864058290543
At time: 133.87809896469116 and batch: 600, loss is 3.5632117652893065 and perplexity is 35.27631463733788
At time: 134.25881624221802 and batch: 650, loss is 3.611531572341919 and perplexity is 37.022712376937136
At time: 134.64048719406128 and batch: 700, loss is 3.6775269174575804 and perplexity is 39.54846640903097
At time: 135.01105570793152 and batch: 750, loss is 3.6112219715118408 and perplexity is 37.011251888633375
At time: 135.39041805267334 and batch: 800, loss is 3.5365305852890017 and perplexity is 34.34754635105636
At time: 135.76018381118774 and batch: 850, loss is 3.5020292234420776 and perplexity is 33.1827188367825
At time: 136.1185622215271 and batch: 900, loss is 3.376874952316284 and perplexity is 29.27912932012018
At time: 136.48258209228516 and batch: 950, loss is 3.5488461542129515 and perplexity is 34.773171453505995
At time: 136.8574070930481 and batch: 1000, loss is 3.548117747306824 and perplexity is 34.747851657947784
At time: 137.22983980178833 and batch: 1050, loss is 3.476445474624634 and perplexity is 32.344547985945745
At time: 137.609379529953 and batch: 1100, loss is 3.637024064064026 and perplexity is 37.97864636678485
At time: 137.9837396144867 and batch: 1150, loss is 3.543337788581848 and perplexity is 34.58215468906425
At time: 138.34461092948914 and batch: 1200, loss is 3.4592574882507323 and perplexity is 31.793360804335563
At time: 138.71291327476501 and batch: 1250, loss is 3.3491704273223877 and perplexity is 28.47909835964758
At time: 139.11423563957214 and batch: 1300, loss is 3.4535555696487426 and perplexity is 31.612593498932952
At time: 139.50268816947937 and batch: 1350, loss is 3.4627725887298584 and perplexity is 31.905314310769835
At time: 139.8735146522522 and batch: 1400, loss is 3.2969492149353026 and perplexity is 27.03005013115345
At time: 140.25101733207703 and batch: 1450, loss is 3.412935481071472 and perplexity is 30.354217837283098
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.303236480452057 and perplexity of 73.9387080534948
Finished 12 epochs...
Completing Train Step...
At time: 141.50414276123047 and batch: 50, loss is 3.663088908195496 and perplexity is 38.981567577764004
At time: 141.89391684532166 and batch: 100, loss is 3.718827586174011 and perplexity is 41.2160435114295
At time: 142.2778480052948 and batch: 150, loss is 3.5271217823028564 and perplexity is 34.025892615573525
At time: 142.63707089424133 and batch: 200, loss is 3.6731744480133055 and perplexity is 39.37670697740735
At time: 143.00566411018372 and batch: 250, loss is 3.744540991783142 and perplexity is 42.28959149320695
At time: 143.3816432952881 and batch: 300, loss is 3.716722640991211 and perplexity is 41.12937724505603
At time: 143.7617564201355 and batch: 350, loss is 3.687366232872009 and perplexity is 39.93951692400198
At time: 144.12517261505127 and batch: 400, loss is 3.4771507787704468 and perplexity is 32.36736877658778
At time: 144.4869167804718 and batch: 450, loss is 3.570285429954529 and perplexity is 35.52673209810745
At time: 144.8573043346405 and batch: 500, loss is 3.5702192735672 and perplexity is 35.52438185560086
At time: 145.22824788093567 and batch: 550, loss is 3.625044598579407 and perplexity is 37.526396746266066
At time: 145.61037015914917 and batch: 600, loss is 3.5572392892837525 and perplexity is 35.066255605274705
At time: 145.9808588027954 and batch: 650, loss is 3.6057292366027833 and perplexity is 36.80851618979531
At time: 146.3395471572876 and batch: 700, loss is 3.672175588607788 and perplexity is 39.33739482021219
At time: 146.70725226402283 and batch: 750, loss is 3.6057518339157104 and perplexity is 36.80934797275203
At time: 147.071031332016 and batch: 800, loss is 3.5315732908248902 and perplexity is 34.17769679464165
At time: 147.42926740646362 and batch: 850, loss is 3.4976658773422242 and perplexity is 33.03824657042814
At time: 147.81130075454712 and batch: 900, loss is 3.372748017311096 and perplexity is 29.158545248864773
At time: 148.18904447555542 and batch: 950, loss is 3.545534539222717 and perplexity is 34.65820656245718
At time: 148.5605344772339 and batch: 1000, loss is 3.545178060531616 and perplexity is 34.64585385221569
At time: 148.9243860244751 and batch: 1050, loss is 3.474100737571716 and perplexity is 32.26879736816846
At time: 149.29598093032837 and batch: 1100, loss is 3.634998908042908 and perplexity is 37.901811509967665
At time: 149.67850995063782 and batch: 1150, loss is 3.5420684814453125 and perplexity is 34.53828715989429
At time: 150.04739570617676 and batch: 1200, loss is 3.4583198404312134 and perplexity is 31.76356380063306
At time: 150.43575286865234 and batch: 1250, loss is 3.3487372827529907 and perplexity is 28.466765464007977
At time: 150.81019139289856 and batch: 1300, loss is 3.4538098049163817 and perplexity is 31.620631556837527
At time: 151.18460154533386 and batch: 1350, loss is 3.4635642862319944 and perplexity is 31.930583669938933
At time: 151.56170105934143 and batch: 1400, loss is 3.2986357021331787 and perplexity is 27.075674426238507
At time: 151.93456268310547 and batch: 1450, loss is 3.4151712751388548 and perplexity is 30.42215954097065
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.302885137052617 and perplexity of 73.91273473950051
Finished 13 epochs...
Completing Train Step...
At time: 153.192218542099 and batch: 50, loss is 3.658173861503601 and perplexity is 38.79044143471819
At time: 153.58252573013306 and batch: 100, loss is 3.7136740636825563 and perplexity is 41.0041820893848
At time: 153.96479892730713 and batch: 150, loss is 3.521686396598816 and perplexity is 33.841450476454085
At time: 154.32748651504517 and batch: 200, loss is 3.6680120849609374 and perplexity is 39.173953912928106
At time: 154.69201946258545 and batch: 250, loss is 3.739194197654724 and perplexity is 42.06408116959936
At time: 155.05206322669983 and batch: 300, loss is 3.7114681577682496 and perplexity is 40.91383041189015
At time: 155.41426825523376 and batch: 350, loss is 3.6820810079574584 and perplexity is 39.72898443992254
At time: 155.7742691040039 and batch: 400, loss is 3.4718574047088624 and perplexity is 32.19648885094878
At time: 156.1593840122223 and batch: 450, loss is 3.5649342203140257 and perplexity is 35.3371288625869
At time: 156.54219388961792 and batch: 500, loss is 3.565420527458191 and perplexity is 35.35431774000526
At time: 156.92325353622437 and batch: 550, loss is 3.620109214782715 and perplexity is 37.341645859097355
At time: 157.30235719680786 and batch: 600, loss is 3.552742848396301 and perplexity is 34.908936213530644
At time: 157.67840218544006 and batch: 650, loss is 3.601244888305664 and perplexity is 36.643823528516535
At time: 158.06149530410767 and batch: 700, loss is 3.6680154943466188 and perplexity is 39.174087472273335
At time: 158.43722438812256 and batch: 750, loss is 3.6016233491897585 and perplexity is 36.65769440699264
At time: 158.8162751197815 and batch: 800, loss is 3.527748727798462 and perplexity is 34.04723168420033
At time: 159.17725944519043 and batch: 850, loss is 3.4943039560317994 and perplexity is 32.927361083804584
At time: 159.5460765361786 and batch: 900, loss is 3.3694675588607788 and perplexity is 29.06304857477978
At time: 159.92083358764648 and batch: 950, loss is 3.5427747440338133 and perplexity is 34.56268887598149
At time: 160.27817273139954 and batch: 1000, loss is 3.5427854824066163 and perplexity is 34.56306002501248
At time: 160.6523609161377 and batch: 1050, loss is 3.472039065361023 and perplexity is 32.202338217394505
At time: 161.02363920211792 and batch: 1100, loss is 3.633267207145691 and perplexity is 37.83623370592857
At time: 161.3938262462616 and batch: 1150, loss is 3.5408280992507937 and perplexity is 34.4954730418961
At time: 161.76003575325012 and batch: 1200, loss is 3.4572506046295164 and perplexity is 31.729619211646817
At time: 162.131587266922 and batch: 1250, loss is 3.3480180644989015 and perplexity is 28.446299007458194
At time: 162.48857164382935 and batch: 1300, loss is 3.4536232280731203 and perplexity is 31.614732429557105
At time: 162.85918879508972 and batch: 1350, loss is 3.463745126724243 and perplexity is 31.93635853455653
At time: 163.26113414764404 and batch: 1400, loss is 3.299355330467224 and perplexity is 27.09516586117228
At time: 163.65684127807617 and batch: 1450, loss is 3.41618679523468 and perplexity is 30.45306954755292
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.302803235176282 and perplexity of 73.90668139573377
Finished 14 epochs...
Completing Train Step...
At time: 164.92453908920288 and batch: 50, loss is 3.653661274909973 and perplexity is 38.61579056869151
At time: 165.29679012298584 and batch: 100, loss is 3.7091640520095823 and perplexity is 40.81966914005108
At time: 165.6724808216095 and batch: 150, loss is 3.5169890117645264 and perplexity is 33.68285693927318
At time: 166.04207730293274 and batch: 200, loss is 3.66355092048645 and perplexity is 38.9995817021586
At time: 166.41068124771118 and batch: 250, loss is 3.7346335506439208 and perplexity is 41.872678535233675
At time: 166.78775215148926 and batch: 300, loss is 3.7069269609451294 and perplexity is 40.72845388941616
At time: 167.17082977294922 and batch: 350, loss is 3.6775342655181884 and perplexity is 39.548757014626794
At time: 167.54271984100342 and batch: 400, loss is 3.467347640991211 and perplexity is 32.05161720766613
At time: 167.90254640579224 and batch: 450, loss is 3.5603598451614378 and perplexity is 35.175852728348595
At time: 168.2728569507599 and batch: 500, loss is 3.5612542724609373 and perplexity is 35.20732904585241
At time: 168.6412661075592 and batch: 550, loss is 3.615865612030029 and perplexity is 37.18351850008641
At time: 169.01931023597717 and batch: 600, loss is 3.5488884115219115 and perplexity is 34.77464090520294
At time: 169.42519450187683 and batch: 650, loss is 3.597362241744995 and perplexity is 36.501824357805425
At time: 169.80005884170532 and batch: 700, loss is 3.664401106834412 and perplexity is 39.03275271287018
At time: 170.17224502563477 and batch: 750, loss is 3.5981064224243164 and perplexity is 36.5289984202045
At time: 170.54630136489868 and batch: 800, loss is 3.524432325363159 and perplexity is 33.93450438998354
At time: 170.92802381515503 and batch: 850, loss is 3.4913620281219484 and perplexity is 32.83063351376763
At time: 171.30747723579407 and batch: 900, loss is 3.3665588808059694 and perplexity is 28.978636346695637
At time: 171.6773705482483 and batch: 950, loss is 3.5402609872817994 and perplexity is 34.47591579235723
At time: 172.03924775123596 and batch: 1000, loss is 3.54061571598053 and perplexity is 34.48814755845476
At time: 172.40926504135132 and batch: 1050, loss is 3.470068864822388 and perplexity is 32.13895561201755
At time: 172.7884922027588 and batch: 1100, loss is 3.6316041946411133 and perplexity is 37.77336386730285
At time: 173.14941000938416 and batch: 1150, loss is 3.539524345397949 and perplexity is 34.450528740531325
At time: 173.51799488067627 and batch: 1200, loss is 3.456048860549927 and perplexity is 31.691511232217184
At time: 173.88559675216675 and batch: 1250, loss is 3.3470759344100953 and perplexity is 28.419511513881346
At time: 174.25679755210876 and batch: 1300, loss is 3.453123779296875 and perplexity is 31.598946432610425
At time: 174.6296455860138 and batch: 1350, loss is 3.4635464668273928 and perplexity is 31.930014691018798
At time: 175.00077843666077 and batch: 1400, loss is 3.2995403242111205 and perplexity is 27.100178761009694
At time: 175.3684060573578 and batch: 1450, loss is 3.4165792655944824 and perplexity is 30.465023820410778
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.302851228632479 and perplexity of 73.91022851792863
Annealing...
Finished 15 epochs...
Completing Train Step...
At time: 176.6326003074646 and batch: 50, loss is 3.652903757095337 and perplexity is 38.58654949612445
At time: 176.99107146263123 and batch: 100, loss is 3.7117085361480715 and perplexity is 40.92366639428827
At time: 177.35018134117126 and batch: 150, loss is 3.5196797895431517 and perplexity is 33.773612068430666
At time: 177.71189856529236 and batch: 200, loss is 3.6661575174331666 and perplexity is 39.10137049629431
At time: 178.0810146331787 and batch: 250, loss is 3.740426502227783 and perplexity is 42.115948881031436
At time: 178.45220518112183 and batch: 300, loss is 3.710861854553223 and perplexity is 40.88903174348823
At time: 178.82307410240173 and batch: 350, loss is 3.678817448616028 and perplexity is 39.59953788477785
At time: 179.2220344543457 and batch: 400, loss is 3.4686941432952882 and perplexity is 32.094803853019364
At time: 179.57927179336548 and batch: 450, loss is 3.562885036468506 and perplexity is 35.26479073135286
At time: 179.94789934158325 and batch: 500, loss is 3.561354093551636 and perplexity is 35.21084365525151
At time: 180.30585598945618 and batch: 550, loss is 3.6156348466873167 and perplexity is 37.17493882268065
At time: 180.66526913642883 and batch: 600, loss is 3.5492387199401856 and perplexity is 34.78682488860587
At time: 181.02933812141418 and batch: 650, loss is 3.596147618293762 and perplexity is 36.457515300785
At time: 181.39536309242249 and batch: 700, loss is 3.662675213813782 and perplexity is 38.965444457518764
At time: 181.76211071014404 and batch: 750, loss is 3.595824556350708 and perplexity is 36.445739167365694
At time: 182.13796639442444 and batch: 800, loss is 3.521175284385681 and perplexity is 33.82415811734979
At time: 182.51341772079468 and batch: 850, loss is 3.488540267944336 and perplexity is 32.73812392083804
At time: 182.88370561599731 and batch: 900, loss is 3.3629316473007203 and perplexity is 28.873714469113892
At time: 183.27365636825562 and batch: 950, loss is 3.5354134464263915 and perplexity is 34.309196797069205
At time: 183.64843678474426 and batch: 1000, loss is 3.5357844638824463 and perplexity is 34.321928469674475
At time: 184.03077340126038 and batch: 1050, loss is 3.463024311065674 and perplexity is 31.913346601924204
At time: 184.3989613056183 and batch: 1100, loss is 3.6261159706115724 and perplexity is 37.56662302301413
At time: 184.76639866828918 and batch: 1150, loss is 3.5303102684020997 and perplexity is 34.134556846326525
At time: 185.14031410217285 and batch: 1200, loss is 3.44540048122406 and perplexity is 31.355838357025295
At time: 185.49874114990234 and batch: 1250, loss is 3.3366254425048827 and perplexity is 28.124060133900215
At time: 185.86744666099548 and batch: 1300, loss is 3.4432729959487913 and perplexity is 31.289200183628125
At time: 186.2480182647705 and batch: 1350, loss is 3.4522820520401 and perplexity is 31.57235992897483
At time: 186.61730360984802 and batch: 1400, loss is 3.2866440296173094 and perplexity is 26.752930790904447
At time: 187.00088930130005 and batch: 1450, loss is 3.403353762626648 and perplexity is 30.064761228780412
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.300755949101896 and perplexity of 73.7555280559671
Finished 16 epochs...
Completing Train Step...
At time: 188.28942203521729 and batch: 50, loss is 3.6501866149902344 and perplexity is 38.48184666844591
At time: 188.67087411880493 and batch: 100, loss is 3.708144359588623 and perplexity is 40.778066847179026
At time: 189.0397093296051 and batch: 150, loss is 3.5165178537368775 and perplexity is 33.66699072887181
At time: 189.40399527549744 and batch: 200, loss is 3.663072395324707 and perplexity is 38.980923885490064
At time: 189.77476453781128 and batch: 250, loss is 3.7369567728042603 and perplexity is 41.97007115846451
At time: 190.14957213401794 and batch: 300, loss is 3.7075379371643065 and perplexity is 40.75334560953664
At time: 190.5327787399292 and batch: 350, loss is 3.6759073734283447 and perplexity is 39.48446776469258
At time: 190.913827419281 and batch: 400, loss is 3.4656748723983766 and perplexity is 31.998047086750947
At time: 191.2868092060089 and batch: 450, loss is 3.560049066543579 and perplexity is 35.16492252398055
At time: 191.65293288230896 and batch: 500, loss is 3.5588436794281004 and perplexity is 35.12256071577141
At time: 192.02662682533264 and batch: 550, loss is 3.6131067657470703 and perplexity is 37.08107626445158
At time: 192.40753984451294 and batch: 600, loss is 3.5466337108612063 and perplexity is 34.69632282447102
At time: 192.7710256576538 and batch: 650, loss is 3.594097728729248 and perplexity is 36.38285796640994
At time: 193.13064193725586 and batch: 700, loss is 3.660872707366943 and perplexity is 38.89527225460351
At time: 193.51323914527893 and batch: 750, loss is 3.594211959838867 and perplexity is 36.38701425803093
At time: 193.89371800422668 and batch: 800, loss is 3.5197846698760986 and perplexity is 33.77715444186863
At time: 194.2710554599762 and batch: 850, loss is 3.487092127799988 and perplexity is 32.690748840494706
At time: 194.6385543346405 and batch: 900, loss is 3.361789574623108 and perplexity is 28.840757411977027
At time: 195.0022327899933 and batch: 950, loss is 3.534297490119934 and perplexity is 34.27093058821383
At time: 195.37222957611084 and batch: 1000, loss is 3.5347491550445556 and perplexity is 34.28641306167657
At time: 195.73326587677002 and batch: 1050, loss is 3.4629061031341553 and perplexity is 31.9095744141902
At time: 196.0956690311432 and batch: 1100, loss is 3.6258158588409426 and perplexity is 37.55535052885081
At time: 196.4751262664795 and batch: 1150, loss is 3.530299983024597 and perplexity is 34.13420576132901
At time: 196.8453447818756 and batch: 1200, loss is 3.4456999588012693 and perplexity is 31.365230133770904
At time: 197.21659231185913 and batch: 1250, loss is 3.3372898292541504 and perplexity is 28.14275159528087
At time: 197.5869209766388 and batch: 1300, loss is 3.4441196870803834 and perplexity is 31.315703690496992
At time: 197.9623143672943 and batch: 1350, loss is 3.4533127307891847 and perplexity is 31.604917664813126
At time: 198.35080671310425 and batch: 1400, loss is 3.288092966079712 and perplexity is 26.791722184148963
At time: 198.72330164909363 and batch: 1450, loss is 3.405387239456177 and perplexity is 30.125959425594043
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.300082214877137 and perplexity of 73.70585316816566
Finished 17 epochs...
Completing Train Step...
At time: 200.02064752578735 and batch: 50, loss is 3.6488078022003174 and perplexity is 38.42882396866837
At time: 200.41528701782227 and batch: 100, loss is 3.706316933631897 and perplexity is 40.703615996784585
At time: 200.79441857337952 and batch: 150, loss is 3.514893021583557 and perplexity is 33.6123319375361
At time: 201.16056156158447 and batch: 200, loss is 3.661490087509155 and perplexity is 38.9192928374719
At time: 201.53592681884766 and batch: 250, loss is 3.7350915336608885 and perplexity is 41.891859902912806
At time: 201.90346312522888 and batch: 300, loss is 3.70571976184845 and perplexity is 40.67931620212504
At time: 202.28078651428223 and batch: 350, loss is 3.674275403022766 and perplexity is 39.42008283326175
At time: 202.6517014503479 and batch: 400, loss is 3.4639995002746584 and perplexity is 31.94448333278738
At time: 203.02137660980225 and batch: 450, loss is 3.558402681350708 and perplexity is 35.10707514882624
At time: 203.39083671569824 and batch: 500, loss is 3.5574181413650514 and perplexity is 35.07252783895737
At time: 203.75604605674744 and batch: 550, loss is 3.611701316833496 and perplexity is 37.0289973118278
At time: 204.13540720939636 and batch: 600, loss is 3.5452578973770144 and perplexity is 34.6486199783113
At time: 204.51484489440918 and batch: 650, loss is 3.592887215614319 and perplexity is 36.33884268559512
At time: 204.88336539268494 and batch: 700, loss is 3.6598013639450073 and perplexity is 38.853624374104086
At time: 205.25973391532898 and batch: 750, loss is 3.5932663822174074 and perplexity is 36.35262377363544
At time: 205.63521242141724 and batch: 800, loss is 3.5189987564086915 and perplexity is 33.75061894996813
At time: 206.0011179447174 and batch: 850, loss is 3.4862654066085814 and perplexity is 32.663733874126564
At time: 206.37327980995178 and batch: 900, loss is 3.361116676330566 and perplexity is 28.821357043528323
At time: 206.7442364692688 and batch: 950, loss is 3.533686013221741 and perplexity is 34.24998111159281
At time: 207.12738943099976 and batch: 1000, loss is 3.5342298126220704 and perplexity is 34.268611295865
At time: 207.50905394554138 and batch: 1050, loss is 3.4628873825073243 and perplexity is 31.908977052546764
At time: 207.8851912021637 and batch: 1100, loss is 3.6258143997192382 and perplexity is 37.555295731063715
At time: 208.25414085388184 and batch: 1150, loss is 3.530452880859375 and perplexity is 34.13942520649254
At time: 208.61192965507507 and batch: 1200, loss is 3.4459996795654297 and perplexity is 31.374632353464516
At time: 208.9848928451538 and batch: 1250, loss is 3.337750015258789 and perplexity is 28.15570547606576
At time: 209.37627530097961 and batch: 1300, loss is 3.444697790145874 and perplexity is 31.33381262871048
At time: 209.74616932868958 and batch: 1350, loss is 3.454027466773987 and perplexity is 31.627514911335528
At time: 210.12882947921753 and batch: 1400, loss is 3.2890059566497802 and perplexity is 26.81619394340182
At time: 210.49644899368286 and batch: 1450, loss is 3.40661358833313 and perplexity is 30.162927025056735
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.299765562399839 and perplexity of 73.68251772197702
Finished 18 epochs...
Completing Train Step...
At time: 211.74488615989685 and batch: 50, loss is 3.6478016805648803 and perplexity is 38.39017934130686
At time: 212.12852835655212 and batch: 100, loss is 3.705068383216858 and perplexity is 40.652827192927084
At time: 212.4929895401001 and batch: 150, loss is 3.5137484645843506 and perplexity is 33.573882715617785
At time: 212.8634648323059 and batch: 200, loss is 3.6603825855255128 and perplexity is 38.87621350307987
At time: 213.2425880432129 and batch: 250, loss is 3.73381507396698 and perplexity is 41.83842074596476
At time: 213.60813403129578 and batch: 300, loss is 3.7044596815109254 and perplexity is 40.62808927743326
At time: 213.9784152507782 and batch: 350, loss is 3.6731030130386353 and perplexity is 39.37389420380823
At time: 214.35231375694275 and batch: 400, loss is 3.462815408706665 and perplexity is 31.906680524839047
At time: 214.73155069351196 and batch: 450, loss is 3.557210021018982 and perplexity is 35.06522929184042
At time: 215.11246538162231 and batch: 500, loss is 3.5564020538330077 and perplexity is 35.03690917960528
At time: 215.48981928825378 and batch: 550, loss is 3.6107014751434328 and perplexity is 36.99199267904424
At time: 215.86268711090088 and batch: 600, loss is 3.5443035316467286 and perplexity is 34.61556829700695
At time: 216.23930430412292 and batch: 650, loss is 3.592010040283203 and perplexity is 36.306981125360295
At time: 216.62264704704285 and batch: 700, loss is 3.6590035009384154 and perplexity is 38.82263686808018
At time: 217.01417756080627 and batch: 750, loss is 3.592539486885071 and perplexity is 36.32620882271155
At time: 217.38373851776123 and batch: 800, loss is 3.5183962202072143 and perplexity is 33.73028910557718
At time: 217.7421908378601 and batch: 850, loss is 3.4856636714935303 and perplexity is 32.64408487080634
At time: 218.1065709590912 and batch: 900, loss is 3.3605994033813475 and perplexity is 28.806452390389214
At time: 218.48281359672546 and batch: 950, loss is 3.5332483959198 and perplexity is 34.23499600637703
At time: 218.85442638397217 and batch: 1000, loss is 3.533878793716431 and perplexity is 34.25658447637414
At time: 219.2374849319458 and batch: 1050, loss is 3.462837243080139 and perplexity is 31.907377194823592
At time: 219.6150360107422 and batch: 1100, loss is 3.6258276987075804 and perplexity is 37.55579518182491
At time: 219.97717237472534 and batch: 1150, loss is 3.5305676317214965 and perplexity is 34.143342959745794
At time: 220.3500895500183 and batch: 1200, loss is 3.4462005949020384 and perplexity is 31.38093663157666
At time: 220.72666597366333 and batch: 1250, loss is 3.3380369424819945 and perplexity is 28.16378527355689
At time: 221.12124609947205 and batch: 1300, loss is 3.4450802993774414 and perplexity is 31.345800393870412
At time: 221.5080235004425 and batch: 1350, loss is 3.4545109844207764 and perplexity is 31.642811070602715
At time: 221.91711354255676 and batch: 1400, loss is 3.2896032619476316 and perplexity is 26.83221618272028
At time: 222.30919218063354 and batch: 1450, loss is 3.40739089012146 and perplexity is 30.186381836727165
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.299586108607104 and perplexity of 73.6692963010661
Finished 19 epochs...
Completing Train Step...
At time: 223.55965542793274 and batch: 50, loss is 3.6469594478607177 and perplexity is 38.357859489075736
At time: 223.9397430419922 and batch: 100, loss is 3.7040942239761354 and perplexity is 40.61324414887997
At time: 224.29974961280823 and batch: 150, loss is 3.5128207874298094 and perplexity is 33.542751433755335
At time: 224.66010403633118 and batch: 200, loss is 3.6594929933547973 and perplexity is 38.84164490617677
At time: 225.02465867996216 and batch: 250, loss is 3.732819437980652 and perplexity is 41.796785638803804
At time: 225.39593315124512 and batch: 300, loss is 3.7034674882888794 and perplexity is 40.58779835412338
At time: 225.7659637928009 and batch: 350, loss is 3.6721571016311647 and perplexity is 39.33666759743582
At time: 226.14912915229797 and batch: 400, loss is 3.4618720960617066 and perplexity is 31.876596741078945
At time: 226.52507400512695 and batch: 450, loss is 3.5562483167648313 and perplexity is 35.03152312193901
At time: 226.9034128189087 and batch: 500, loss is 3.5555847883224487 and perplexity is 35.008286419926506
At time: 227.26497220993042 and batch: 550, loss is 3.6098940992355346 and perplexity is 36.96213828884945
At time: 227.64469361305237 and batch: 600, loss is 3.5435391092300415 and perplexity is 34.58911749171663
At time: 228.0042269229889 and batch: 650, loss is 3.591296491622925 and perplexity is 36.28108356830193
At time: 228.3804624080658 and batch: 700, loss is 3.6583419609069825 and perplexity is 38.79696263286967
At time: 228.7524971961975 and batch: 750, loss is 3.591917748451233 and perplexity is 36.30363044218165
At time: 229.12076210975647 and batch: 800, loss is 3.517871284484863 and perplexity is 33.71258751840464
At time: 229.5073459148407 and batch: 850, loss is 3.4851668787002565 and perplexity is 32.62787155236284
At time: 229.8802855014801 and batch: 900, loss is 3.3601534795761108 and perplexity is 28.79360977115155
At time: 230.2469892501831 and batch: 950, loss is 3.532884678840637 and perplexity is 34.22254641782568
At time: 230.62991762161255 and batch: 1000, loss is 3.5335926008224487 and perplexity is 34.246781888107364
At time: 231.0078067779541 and batch: 1050, loss is 3.462746653556824 and perplexity is 31.904486851652656
At time: 231.38221740722656 and batch: 1100, loss is 3.625805239677429 and perplexity is 37.554951724560226
At time: 231.75087904930115 and batch: 1150, loss is 3.530621633529663 and perplexity is 34.145186811787696
At time: 232.1653082370758 and batch: 1200, loss is 3.4463145446777346 and perplexity is 31.384512686008392
At time: 232.5366086959839 and batch: 1250, loss is 3.338207492828369 and perplexity is 28.168589026519733
At time: 232.9114785194397 and batch: 1300, loss is 3.4453332662582397 and perplexity is 31.353730846250784
At time: 233.28527522087097 and batch: 1350, loss is 3.454840512275696 and perplexity is 31.653239976471554
At time: 233.65440821647644 and batch: 1400, loss is 3.290010747909546 and perplexity is 26.84315216211951
At time: 234.02278685569763 and batch: 1450, loss is 3.407909355163574 and perplexity is 30.202036478298947
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.299480992504674 and perplexity of 73.66155287875645
Finished 20 epochs...
Completing Train Step...
At time: 235.24727129936218 and batch: 50, loss is 3.6462089824676513 and perplexity is 38.32908404181628
At time: 235.63048839569092 and batch: 100, loss is 3.703270812034607 and perplexity is 40.57981648292192
At time: 236.00122475624084 and batch: 150, loss is 3.5120129108428957 and perplexity is 33.515663973347124
At time: 236.38320064544678 and batch: 200, loss is 3.65872266292572 and perplexity is 38.811735526721726
At time: 236.77699279785156 and batch: 250, loss is 3.7319779109954836 and perplexity is 41.761627311211
At time: 237.14824962615967 and batch: 300, loss is 3.7026254510879517 and perplexity is 40.55363630288294
At time: 237.53678488731384 and batch: 350, loss is 3.6713410663604735 and perplexity is 39.30458058309318
At time: 237.91002249717712 and batch: 400, loss is 3.4610663557052614 and perplexity is 31.85092282530255
At time: 238.27986931800842 and batch: 450, loss is 3.5554214000701903 and perplexity is 35.00256694445406
At time: 238.663321018219 and batch: 500, loss is 3.5548779916763307 and perplexity is 34.98355142283477
At time: 239.0580072402954 and batch: 550, loss is 3.6091931438446045 and perplexity is 36.93623855709434
At time: 239.43604707717896 and batch: 600, loss is 3.5428766632080078 and perplexity is 34.56621165620605
At time: 239.80666971206665 and batch: 650, loss is 3.590673861503601 and perplexity is 36.25850090396365
At time: 240.18191742897034 and batch: 700, loss is 3.6577590036392214 and perplexity is 38.774352252618854
At time: 240.5552577972412 and batch: 750, loss is 3.5913581609725953 and perplexity is 36.283321068122795
At time: 240.920991897583 and batch: 800, loss is 3.5173886108398436 and perplexity is 33.696319267347945
At time: 241.30199599266052 and batch: 850, loss is 3.4847266483306885 and perplexity is 32.6135109336333
At time: 241.67780923843384 and batch: 900, loss is 3.35974732875824 and perplexity is 28.781917597547203
At time: 242.04689192771912 and batch: 950, loss is 3.5325563764572143 and perplexity is 34.211312918363134
At time: 242.44032311439514 and batch: 1000, loss is 3.5333331346511843 and perplexity is 34.237897159425835
At time: 242.8213815689087 and batch: 1050, loss is 3.462623271942139 and perplexity is 31.900550667380582
At time: 243.1896209716797 and batch: 1100, loss is 3.6257448053359984 and perplexity is 37.55268218436506
At time: 243.55438995361328 and batch: 1150, loss is 3.530623741149902 and perplexity is 34.14525877695033
At time: 243.92155003547668 and batch: 1200, loss is 3.446362853050232 and perplexity is 31.386028857359467
At time: 244.28986310958862 and batch: 1250, loss is 3.33830011844635 and perplexity is 28.171198280325974
At time: 244.65833711624146 and batch: 1300, loss is 3.4454989528656004 and perplexity is 31.358926169928694
At time: 245.0321307182312 and batch: 1350, loss is 3.4550671434402465 and perplexity is 31.660414400052495
At time: 245.40825533866882 and batch: 1400, loss is 3.2902981853485107 and perplexity is 26.850868998031377
At time: 245.77801489830017 and batch: 1450, loss is 3.408270363807678 and perplexity is 30.212941642848055
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.299417088174413 and perplexity of 73.6568457369587
Finished 21 epochs...
Completing Train Step...
At time: 247.04617404937744 and batch: 50, loss is 3.6455165767669677 and perplexity is 38.30255395137661
At time: 247.43009972572327 and batch: 100, loss is 3.7025382041931154 and perplexity is 40.55009827838427
At time: 247.8109803199768 and batch: 150, loss is 3.5112797021865845 and perplexity is 33.49109900512402
At time: 248.17999839782715 and batch: 200, loss is 3.658025584220886 and perplexity is 38.784690119872145
At time: 248.5490915775299 and batch: 250, loss is 3.7312300157547 and perplexity is 41.73040566561295
At time: 248.9251253604889 and batch: 300, loss is 3.7018772077560427 and perplexity is 40.52330366444706
At time: 249.3095223903656 and batch: 350, loss is 3.6706075525283812 and perplexity is 39.27576070075425
At time: 249.6818563938141 and batch: 400, loss is 3.460346817970276 and perplexity is 31.82801312762005
At time: 250.05718970298767 and batch: 450, loss is 3.55468044757843 and perplexity is 34.97664131127594
At time: 250.43595504760742 and batch: 500, loss is 3.5542387056350706 and perplexity is 34.961194073868434
At time: 250.81595826148987 and batch: 550, loss is 3.608557381629944 and perplexity is 36.91276335538188
At time: 251.1755886077881 and batch: 600, loss is 3.5422764253616332 and perplexity is 34.54546993337047
At time: 251.55740690231323 and batch: 650, loss is 3.590106372833252 and perplexity is 36.23793045279784
At time: 251.94254612922668 and batch: 700, loss is 3.6572255516052246 and perplexity is 38.7536735115914
At time: 252.33048558235168 and batch: 750, loss is 3.5908403253555297 and perplexity is 36.26453713608256
At time: 252.70755982398987 and batch: 800, loss is 3.5169331789016725 and perplexity is 33.68097638144012
At time: 253.0913565158844 and batch: 850, loss is 3.484320254325867 and perplexity is 32.600259691108825
At time: 253.49555611610413 and batch: 900, loss is 3.3593659591674805 and perplexity is 28.77094314220654
At time: 253.86817860603333 and batch: 950, loss is 3.5322464752197265 and perplexity is 34.20071243279028
At time: 254.2608082294464 and batch: 1000, loss is 3.5330849790573122 and perplexity is 34.22940188784149
At time: 254.643483877182 and batch: 1050, loss is 3.462474570274353 and perplexity is 31.895807354971026
At time: 255.01518034934998 and batch: 1100, loss is 3.6256529760360716 and perplexity is 37.54923390617861
At time: 255.43949031829834 and batch: 1150, loss is 3.5305863189697266 and perplexity is 34.14398101083278
At time: 255.8318030834198 and batch: 1200, loss is 3.4463632774353026 and perplexity is 31.386042177124367
At time: 256.21867847442627 and batch: 1250, loss is 3.3383390378952025 and perplexity is 28.172294709172625
At time: 256.6121861934662 and batch: 1300, loss is 3.445603566169739 and perplexity is 31.362206902410705
At time: 256.992858171463 and batch: 1350, loss is 3.455223250389099 and perplexity is 31.665357196536295
At time: 257.4033317565918 and batch: 1400, loss is 3.2905057096481323 and perplexity is 26.85644178403868
At time: 257.7979416847229 and batch: 1450, loss is 3.408530583381653 and perplexity is 30.22080466466261
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2993795280782585 and perplexity of 73.65407923070586
Finished 22 epochs...
Completing Train Step...
At time: 259.0952959060669 and batch: 50, loss is 3.6448641538619997 and perplexity is 38.277572637936615
At time: 259.4833710193634 and batch: 100, loss is 3.701864314079285 and perplexity is 40.522781173436876
At time: 259.8624746799469 and batch: 150, loss is 3.5105971908569336 and perplexity is 33.468248749276825
At time: 260.2334198951721 and batch: 200, loss is 3.657376971244812 and perplexity is 38.75954202315995
At time: 260.6216585636139 and batch: 250, loss is 3.730543222427368 and perplexity is 41.701755341007
At time: 260.9958553314209 and batch: 300, loss is 3.7011914157867434 and perplexity is 40.495522635316654
At time: 261.37375688552856 and batch: 350, loss is 3.6699300718307497 and perplexity is 39.249161142355774
At time: 261.74771881103516 and batch: 400, loss is 3.4596850872039795 and perplexity is 31.806958519112825
At time: 262.13492798805237 and batch: 450, loss is 3.5539975118637086 and perplexity is 34.95276266846055
At time: 262.5227632522583 and batch: 500, loss is 3.553643503189087 and perplexity is 34.94039127719304
At time: 262.9197483062744 and batch: 550, loss is 3.607964792251587 and perplexity is 36.8908957237947
At time: 263.31961607933044 and batch: 600, loss is 3.541717233657837 and perplexity is 34.52615779327748
At time: 263.69026160240173 and batch: 650, loss is 3.5895747900009156 and perplexity is 36.21867211024538
At time: 264.0533151626587 and batch: 700, loss is 3.656725583076477 and perplexity is 38.73430273725453
At time: 264.43073534965515 and batch: 750, loss is 3.5903521251678465 and perplexity is 36.246837103177725
At time: 264.81353306770325 and batch: 800, loss is 3.516497502326965 and perplexity is 33.66630556511501
At time: 265.21817445755005 and batch: 850, loss is 3.483935537338257 and perplexity is 32.587720229631735
At time: 265.6096966266632 and batch: 900, loss is 3.3590014696121218 and perplexity is 28.760458344849027
At time: 265.99765133857727 and batch: 950, loss is 3.531946716308594 and perplexity is 34.190462000877375
At time: 266.37735748291016 and batch: 1000, loss is 3.5328416872024535 and perplexity is 34.22107516611835
At time: 266.754846572876 and batch: 1050, loss is 3.4623069858551023 and perplexity is 31.890462562483396
At time: 267.13042664527893 and batch: 1100, loss is 3.6255368852615355 and perplexity is 37.544875039548195
At time: 267.5006728172302 and batch: 1150, loss is 3.5305193519592284 and perplexity is 34.14169456705699
At time: 267.8762321472168 and batch: 1200, loss is 3.446328649520874 and perplexity is 31.384955362758767
At time: 268.2859697341919 and batch: 1250, loss is 3.3383395051956177 and perplexity is 28.172307874100717
At time: 268.67443799972534 and batch: 1300, loss is 3.4456642150878904 and perplexity is 31.364109044011016
At time: 269.0630166530609 and batch: 1350, loss is 3.4553293991088867 and perplexity is 31.66871861206615
At time: 269.4510169029236 and batch: 1400, loss is 3.2906577014923095 and perplexity is 26.860524054381514
At time: 269.8294870853424 and batch: 1450, loss is 3.408723306655884 and perplexity is 30.22662947835803
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.299359704694178 and perplexity of 73.65261917207584
Finished 23 epochs...
Completing Train Step...
At time: 271.18293261528015 and batch: 50, loss is 3.644240503311157 and perplexity is 38.25370825096857
At time: 271.56781220436096 and batch: 100, loss is 3.701230387687683 and perplexity is 40.49710085356618
At time: 271.92621970176697 and batch: 150, loss is 3.50995099067688 and perplexity is 33.44662854715055
At time: 272.3092038631439 and batch: 200, loss is 3.656762776374817 and perplexity is 38.73574342052394
At time: 272.68207716941833 and batch: 250, loss is 3.729899525642395 and perplexity is 41.67492069278123
At time: 273.0684862136841 and batch: 300, loss is 3.700549955368042 and perplexity is 40.46955469000643
At time: 273.45582389831543 and batch: 350, loss is 3.6692927980422976 and perplexity is 39.22415664894137
At time: 273.83434081077576 and batch: 400, loss is 3.4590641498565673 and perplexity is 31.787214521187945
At time: 274.22570729255676 and batch: 450, loss is 3.553356032371521 and perplexity is 34.9303483779359
At time: 274.60676622390747 and batch: 500, loss is 3.5530795097351073 and perplexity is 34.920690681258996
At time: 275.0020971298218 and batch: 550, loss is 3.6074026346206667 and perplexity is 36.870163053312545
At time: 275.3984122276306 and batch: 600, loss is 3.541187539100647 and perplexity is 34.507874318169826
At time: 275.77931213378906 and batch: 650, loss is 3.589068126678467 and perplexity is 36.20032608552071
At time: 276.1795482635498 and batch: 700, loss is 3.656249318122864 and perplexity is 38.71585933867894
At time: 276.565550327301 and batch: 750, loss is 3.589886441230774 and perplexity is 36.229961463031344
At time: 276.9518156051636 and batch: 800, loss is 3.5160770320892336 and perplexity is 33.652152861214404
At time: 277.3123474121094 and batch: 850, loss is 3.483565845489502 and perplexity is 32.57567504173442
At time: 277.69474029541016 and batch: 900, loss is 3.358648738861084 and perplexity is 28.750315435739996
At time: 278.073445558548 and batch: 950, loss is 3.531653070449829 and perplexity is 34.18042358724299
At time: 278.4465596675873 and batch: 1000, loss is 3.5326001167297365 and perplexity is 34.21280936324074
At time: 278.8311598300934 and batch: 1050, loss is 3.4621252536773683 and perplexity is 31.8846675658576
At time: 279.2090392112732 and batch: 1100, loss is 3.62540265083313 and perplexity is 37.5398355629509
At time: 279.57870388031006 and batch: 1150, loss is 3.5304306650161745 and perplexity is 34.13866677879978
At time: 279.94992852211 and batch: 1200, loss is 3.4462680196762085 and perplexity is 31.383052555474332
At time: 280.3145842552185 and batch: 1250, loss is 3.338311696052551 and perplexity is 28.171524437253936
At time: 280.69074630737305 and batch: 1300, loss is 3.4456923961639405 and perplexity is 31.36499293080761
At time: 281.08118963241577 and batch: 1350, loss is 3.45539927482605 and perplexity is 31.6709315638057
At time: 281.47184801101685 and batch: 1400, loss is 3.2907690620422363 and perplexity is 26.863515423668705
At time: 281.85325837135315 and batch: 1450, loss is 3.4088687467575074 and perplexity is 30.23102596212587
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.299355270516159 and perplexity of 73.65229258397497
Finished 24 epochs...
Completing Train Step...
At time: 283.1036250591278 and batch: 50, loss is 3.643638501167297 and perplexity is 38.230686366897956
At time: 283.5014798641205 and batch: 100, loss is 3.700625457763672 and perplexity is 40.47261035368911
At time: 283.88896346092224 and batch: 150, loss is 3.50933228969574 and perplexity is 33.42594148546519
At time: 284.2601065635681 and batch: 200, loss is 3.656174216270447 and perplexity is 38.71295181510626
At time: 284.62606024742126 and batch: 250, loss is 3.7292874908447264 and perplexity is 41.6494219949683
At time: 285.0162637233734 and batch: 300, loss is 3.6999416017532347 and perplexity is 40.44494237737488
At time: 285.3944728374481 and batch: 350, loss is 3.6686856889724733 and perplexity is 39.20035053486868
At time: 285.77916979789734 and batch: 400, loss is 3.4584736680984496 and perplexity is 31.76845029138472
At time: 286.15562629699707 and batch: 450, loss is 3.552745485305786 and perplexity is 34.90902826535702
At time: 286.5345914363861 and batch: 500, loss is 3.5525380897521974 and perplexity is 34.901789038832334
At time: 286.9131724834442 and batch: 550, loss is 3.6068630838394165 and perplexity is 36.850275093796824
At time: 287.30196928977966 and batch: 600, loss is 3.5406798267364503 and perplexity is 34.49035869054295
At time: 287.67750358581543 and batch: 650, loss is 3.588579535484314 and perplexity is 36.18264324516167
At time: 288.06733894348145 and batch: 700, loss is 3.6557906436920167 and perplexity is 38.6981054358739
At time: 288.4488079547882 and batch: 750, loss is 3.5894377517700193 and perplexity is 36.2137091075623
At time: 288.82581424713135 and batch: 800, loss is 3.515668692588806 and perplexity is 33.6384141631442
At time: 289.2104368209839 and batch: 850, loss is 3.483207116127014 and perplexity is 32.56399128637243
At time: 289.596467256546 and batch: 900, loss is 3.35830445766449 and perplexity is 28.740418946424665
At time: 289.9737346172333 and batch: 950, loss is 3.5313629627227785 and perplexity is 34.17050902046223
At time: 290.3600399494171 and batch: 1000, loss is 3.5323591661453246 and perplexity is 34.20456675990022
At time: 290.75301003456116 and batch: 1050, loss is 3.4619327926635743 and perplexity is 31.87853160089935
At time: 291.1257040500641 and batch: 1100, loss is 3.625254874229431 and perplexity is 37.534288463423856
At time: 291.49620628356934 and batch: 1150, loss is 3.530325355529785 and perplexity is 34.13507184262905
At time: 291.8818860054016 and batch: 1200, loss is 3.446187539100647 and perplexity is 31.380526930975005
At time: 292.27037358283997 and batch: 1250, loss is 3.33826229095459 and perplexity is 28.170132654710258
At time: 292.6580698490143 and batch: 1300, loss is 3.445695662498474 and perplexity is 31.365095379534477
At time: 293.0400860309601 and batch: 1350, loss is 3.4554419326782226 and perplexity is 31.67228260653861
At time: 293.415194272995 and batch: 1400, loss is 3.2908501529693606 and perplexity is 26.865693899366338
At time: 293.80527424812317 and batch: 1450, loss is 3.4089799451828005 and perplexity is 30.234387791519453
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.29935787885617 and perplexity of 73.65248469444714
Annealing...
Finished 25 epochs...
Completing Train Step...
At time: 295.06387543678284 and batch: 50, loss is 3.643462176322937 and perplexity is 38.22394594134424
At time: 295.4666087627411 and batch: 100, loss is 3.7008404207229613 and perplexity is 40.48131140094884
At time: 295.82739448547363 and batch: 150, loss is 3.509624924659729 and perplexity is 33.435724516006665
At time: 296.2221643924713 and batch: 200, loss is 3.656376323699951 and perplexity is 38.72077678100137
At time: 296.6156816482544 and batch: 250, loss is 3.7299859523773193 and perplexity is 41.678522675756504
At time: 296.98965287208557 and batch: 300, loss is 3.7003030490875246 and perplexity is 40.459563736249095
At time: 297.36944222450256 and batch: 350, loss is 3.668790965080261 and perplexity is 39.20447761243443
At time: 297.7614243030548 and batch: 400, loss is 3.4583803367614747 and perplexity is 31.765485437804433
At time: 298.1427643299103 and batch: 450, loss is 3.5529199504852294 and perplexity is 34.915119206550656
At time: 298.5158178806305 and batch: 500, loss is 3.5524838972091675 and perplexity is 34.89989767337744
At time: 298.9086289405823 and batch: 550, loss is 3.6065757036209107 and perplexity is 36.83968657522664
At time: 299.29555797576904 and batch: 600, loss is 3.540409860610962 and perplexity is 34.48104871878561
At time: 299.670871257782 and batch: 650, loss is 3.588192729949951 and perplexity is 36.16865030495438
At time: 300.05963134765625 and batch: 700, loss is 3.6553084659576416 and perplexity is 38.6794505689124
At time: 300.44922494888306 and batch: 750, loss is 3.588876905441284 and perplexity is 36.19340447618065
At time: 300.8221855163574 and batch: 800, loss is 3.514766225814819 and perplexity is 33.608070306253126
At time: 301.2007772922516 and batch: 850, loss is 3.4822323369979857 and perplexity is 32.53226405334316
At time: 301.5846767425537 and batch: 900, loss is 3.3572736835479735 and perplexity is 28.710809329511886
At time: 301.97651767730713 and batch: 950, loss is 3.5302013635635374 and perplexity is 34.13083963033886
At time: 302.39289808273315 and batch: 1000, loss is 3.53124810218811 and perplexity is 34.166584402922396
At time: 302.78290915489197 and batch: 1050, loss is 3.460012741088867 and perplexity is 31.817381900175466
At time: 303.16716051101685 and batch: 1100, loss is 3.6238120079040526 and perplexity is 37.48017055439605
At time: 303.54646277427673 and batch: 1150, loss is 3.5285979557037352 and perplexity is 34.07615782414804
At time: 303.9353897571564 and batch: 1200, loss is 3.444181957244873 and perplexity is 31.31765378523264
At time: 304.33947134017944 and batch: 1250, loss is 3.3360553073883055 and perplexity is 28.10803018964843
At time: 304.7137520313263 and batch: 1300, loss is 3.4435612249374388 and perplexity is 31.298219937967534
At time: 305.084668636322 and batch: 1350, loss is 3.4533967542648316 and perplexity is 31.607573331410467
At time: 305.46201610565186 and batch: 1400, loss is 3.2887147426605225 and perplexity is 26.808385829558027
At time: 305.8390612602234 and batch: 1450, loss is 3.406777219772339 and perplexity is 30.167863032048555
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.299272846971822 and perplexity of 73.64622215114836
Finished 26 epochs...
Completing Train Step...
At time: 307.16560888290405 and batch: 50, loss is 3.6433000946044922 and perplexity is 38.21775104055396
At time: 307.55318236351013 and batch: 100, loss is 3.700654916763306 and perplexity is 40.47380265386461
At time: 307.93701457977295 and batch: 150, loss is 3.509455418586731 and perplexity is 33.43005743796176
At time: 308.31863951683044 and batch: 200, loss is 3.6562226533889772 and perplexity is 38.714827004356
At time: 308.69672441482544 and batch: 250, loss is 3.7297897386550902 and perplexity is 41.67034557994072
At time: 309.0926339626312 and batch: 300, loss is 3.700127205848694 and perplexity is 40.45244982100532
At time: 309.47793555259705 and batch: 350, loss is 3.668654408454895 and perplexity is 39.19912434679269
At time: 309.85010290145874 and batch: 400, loss is 3.4582387256622313 and perplexity is 31.760987410986363
At time: 310.2372121810913 and batch: 450, loss is 3.5527662372589113 and perplexity is 34.90975270339196
At time: 310.64456963539124 and batch: 500, loss is 3.5523479175567627 and perplexity is 34.89515232006591
At time: 311.02101397514343 and batch: 550, loss is 3.60643470287323 and perplexity is 36.83449251806678
At time: 311.4146513938904 and batch: 600, loss is 3.540280475616455 and perplexity is 34.47658767708869
At time: 311.79243659973145 and batch: 650, loss is 3.5881006860733033 and perplexity is 36.16532135537427
At time: 312.18106341362 and batch: 700, loss is 3.6552194356918335 and perplexity is 38.676007080436555
At time: 312.58698415756226 and batch: 750, loss is 3.588781452178955 and perplexity is 36.18994986252831
At time: 312.99058866500854 and batch: 800, loss is 3.5147037363052367 and perplexity is 33.60597022003903
At time: 313.38121366500854 and batch: 850, loss is 3.4821885299682616 and perplexity is 32.530838942699944
At time: 313.74976110458374 and batch: 900, loss is 3.357233791351318 and perplexity is 28.709664015104686
At time: 314.15244483947754 and batch: 950, loss is 3.5301696109771727 and perplexity is 34.12975590511143
At time: 314.5262246131897 and batch: 1000, loss is 3.531222867965698 and perplexity is 34.16572224661048
At time: 314.8920187950134 and batch: 1050, loss is 3.4600465393066404 and perplexity is 31.81845728915092
At time: 315.2525465488434 and batch: 1100, loss is 3.6238204050064087 and perplexity is 37.480485280545906
At time: 315.64065313339233 and batch: 1150, loss is 3.5286151361465454 and perplexity is 34.07674327265785
At time: 316.0152201652527 and batch: 1200, loss is 3.444204545021057 and perplexity is 31.318361189376265
At time: 316.41427063941956 and batch: 1250, loss is 3.3361169576644896 and perplexity is 28.109763110889602
At time: 316.8039872646332 and batch: 1300, loss is 3.4436221170425414 and perplexity is 31.300125810491227
At time: 317.1634111404419 and batch: 1350, loss is 3.45347375869751 and perplexity is 31.610007348377035
At time: 317.5567011833191 and batch: 1400, loss is 3.288806843757629 and perplexity is 26.810855025010646
At time: 317.94229912757874 and batch: 1450, loss is 3.4068696212768557 and perplexity is 30.170650716771917
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2992042476295405 and perplexity of 73.6411702420281
Finished 27 epochs...
Completing Train Step...
At time: 319.2721984386444 and batch: 50, loss is 3.6431539726257323 and perplexity is 38.212166995133984
At time: 319.6454222202301 and batch: 100, loss is 3.7004844999313353 and perplexity is 40.46690582432315
At time: 320.0451798439026 and batch: 150, loss is 3.509301533699036 and perplexity is 33.42491345312819
At time: 320.4168703556061 and batch: 200, loss is 3.6560781526565553 and perplexity is 38.70923308767055
At time: 320.8067800998688 and batch: 250, loss is 3.7296117305755616 and perplexity is 41.66292858191312
At time: 321.1944167613983 and batch: 300, loss is 3.6999687004089354 and perplexity is 40.446038395793444
At time: 321.56257462501526 and batch: 350, loss is 3.6685271072387695 and perplexity is 39.19413456820148
At time: 321.95677495002747 and batch: 400, loss is 3.4581085634231568 and perplexity is 31.75685359878869
At time: 322.3433184623718 and batch: 450, loss is 3.5526259326934815 and perplexity is 34.9048550492993
At time: 322.7135326862335 and batch: 500, loss is 3.5522236251831054 and perplexity is 34.890815388284274
At time: 323.1032853126526 and batch: 550, loss is 3.6063094091415406 and perplexity is 36.82987767615573
At time: 323.47650027275085 and batch: 600, loss is 3.540161590576172 and perplexity is 34.47248917020427
At time: 323.8632504940033 and batch: 650, loss is 3.5880141401290895 and perplexity is 36.162191528928616
At time: 324.2693793773651 and batch: 700, loss is 3.6551365852355957 and perplexity is 38.67280288834071
At time: 324.6784999370575 and batch: 750, loss is 3.58869508266449 and perplexity is 36.186824289109225
At time: 325.0525870323181 and batch: 800, loss is 3.5146439361572264 and perplexity is 33.603960638133096
At time: 325.42304849624634 and batch: 850, loss is 3.482144355773926 and perplexity is 32.529401950837794
At time: 325.8072214126587 and batch: 900, loss is 3.3571952247619627 and perplexity is 28.708556802632923
At time: 326.17050552368164 and batch: 950, loss is 3.530139527320862 and perplexity is 34.128729172708816
At time: 326.5628590583801 and batch: 1000, loss is 3.531199722290039 and perplexity is 34.1649314670363
At time: 326.96627926826477 and batch: 1050, loss is 3.460073752403259 and perplexity is 31.819323179685117
At time: 327.37705850601196 and batch: 1100, loss is 3.62382915019989 and perplexity is 37.480813056074695
At time: 327.7443914413452 and batch: 1150, loss is 3.5286304807662963 and perplexity is 34.07726617133755
At time: 328.1210820674896 and batch: 1200, loss is 3.4442254209518435 and perplexity is 31.31901499614118
At time: 328.50007915496826 and batch: 1250, loss is 3.3361717891693115 and perplexity is 28.111304453757846
At time: 328.8572974205017 and batch: 1300, loss is 3.4436787271499636 and perplexity is 31.30189776413046
At time: 329.2361195087433 and batch: 1350, loss is 3.453541483879089 and perplexity is 31.612148214358875
At time: 329.6158835887909 and batch: 1400, loss is 3.2888884496688844 and perplexity is 26.8130430385427
At time: 329.9937083721161 and batch: 1450, loss is 3.4069547605514527 and perplexity is 30.173219533440108
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.299146081647303 and perplexity of 73.63688695559982
Finished 28 epochs...
Completing Train Step...
At time: 331.32067584991455 and batch: 50, loss is 3.643019618988037 and perplexity is 38.20703339636053
At time: 331.70350313186646 and batch: 100, loss is 3.70032630443573 and perplexity is 40.4605046484326
At time: 332.0891959667206 and batch: 150, loss is 3.5091594362258913 and perplexity is 33.42016419482322
At time: 332.47374081611633 and batch: 200, loss is 3.6559417963027956 and perplexity is 38.703955197634976
At time: 332.8302733898163 and batch: 250, loss is 3.729447865486145 and perplexity is 41.65610204172677
At time: 333.2157361507416 and batch: 300, loss is 3.699823079109192 and perplexity is 40.44014901993246
At time: 333.61041712760925 and batch: 350, loss is 3.6684072732925417 and perplexity is 39.189438061793254
At time: 334.0179536342621 and batch: 400, loss is 3.457986946105957 and perplexity is 31.752991650295975
At time: 334.3905658721924 and batch: 450, loss is 3.5524957752227784 and perplexity is 34.900312217299
At time: 334.77082920074463 and batch: 500, loss is 3.552107639312744 and perplexity is 34.88676878137299
At time: 335.14585971832275 and batch: 550, loss is 3.606195101737976 and perplexity is 36.82566798906874
At time: 335.5502121448517 and batch: 600, loss is 3.54005126953125 and perplexity is 34.46868633894797
At time: 335.9574680328369 and batch: 650, loss is 3.5879310464859007 and perplexity is 36.15918680552722
At time: 336.3412215709686 and batch: 700, loss is 3.655058116912842 and perplexity is 38.669768417418354
At time: 336.7211720943451 and batch: 750, loss is 3.5886154699325563 and perplexity is 36.18394347184396
At time: 337.09971475601196 and batch: 800, loss is 3.5145861291885376 and perplexity is 33.60201815117785
At time: 337.4928867816925 and batch: 850, loss is 3.4820998430252077 and perplexity is 32.52795400996896
At time: 337.87017798423767 and batch: 900, loss is 3.357157201766968 and perplexity is 28.707465238073716
At time: 338.2637212276459 and batch: 950, loss is 3.5301100969314576 and perplexity is 34.12772476569951
At time: 338.63479566574097 and batch: 1000, loss is 3.531177644729614 and perplexity is 34.164177197023676
At time: 339.01251220703125 and batch: 1050, loss is 3.4600954055786133 and perplexity is 31.820012176529033
At time: 339.39328837394714 and batch: 1100, loss is 3.6238373708724976 and perplexity is 37.48112117483436
At time: 339.7844469547272 and batch: 1150, loss is 3.528643751144409 and perplexity is 34.07771839254526
At time: 340.16909170150757 and batch: 1200, loss is 3.4442442083358764 and perplexity is 31.319603404030754
At time: 340.56619358062744 and batch: 1250, loss is 3.3362202405929566 and perplexity is 28.1126665194759
At time: 340.9740960597992 and batch: 1300, loss is 3.443730616569519 and perplexity is 31.303522043577512
At time: 341.3602328300476 and batch: 1350, loss is 3.4536011266708373 and perplexity is 31.61403370735901
At time: 341.73974561691284 and batch: 1400, loss is 3.2889611673355104 and perplexity is 26.81499289136112
At time: 342.13826179504395 and batch: 1450, loss is 3.4070327138900756 and perplexity is 30.17557172831927
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.299099914029113 and perplexity of 73.6334873943936
Finished 29 epochs...
Completing Train Step...
At time: 343.4072439670563 and batch: 50, loss is 3.6428943729400634 and perplexity is 38.20224841607902
At time: 343.83053183555603 and batch: 100, loss is 3.7001781272888183 and perplexity is 40.454509770454116
At time: 344.1994061470032 and batch: 150, loss is 3.5090264320373534 and perplexity is 33.41571946859384
At time: 344.5964181423187 and batch: 200, loss is 3.6558128881454466 and perplexity is 38.69896626365238
At time: 344.99300241470337 and batch: 250, loss is 3.72929536819458 and perplexity is 41.6497500833288
At time: 345.36788535118103 and batch: 300, loss is 3.6996871280670165 and perplexity is 40.43465151323182
At time: 345.75429010391235 and batch: 350, loss is 3.66829309463501 and perplexity is 39.184963719807975
At time: 346.1459918022156 and batch: 400, loss is 3.45787211894989 and perplexity is 31.749345753896108
At time: 346.5308313369751 and batch: 450, loss is 3.552373332977295 and perplexity is 34.89603920630691
At time: 346.90045070648193 and batch: 500, loss is 3.551998190879822 and perplexity is 34.88295068814613
At time: 347.3009729385376 and batch: 550, loss is 3.606089253425598 and perplexity is 36.82177026054755
At time: 347.6865203380585 and batch: 600, loss is 3.5399479389190676 and perplexity is 34.465124852495904
At time: 348.0579216480255 and batch: 650, loss is 3.587850661277771 and perplexity is 36.15628025859332
At time: 348.4432256221771 and batch: 700, loss is 3.654982886314392 and perplexity is 38.66685937702419
At time: 348.8536274433136 and batch: 750, loss is 3.588540711402893 and perplexity is 36.18123851454316
At time: 349.21542596817017 and batch: 800, loss is 3.514529824256897 and perplexity is 33.60012624510518
At time: 349.6007134914398 and batch: 850, loss is 3.482055187225342 and perplexity is 32.526501480596814
At time: 349.9842298030853 and batch: 900, loss is 3.3571191740036013 and perplexity is 28.70637357813561
At time: 350.35394525527954 and batch: 950, loss is 3.530081009864807 and perplexity is 34.12673210473149
At time: 350.75554847717285 and batch: 1000, loss is 3.531155586242676 and perplexity is 34.16342359527891
At time: 351.1417999267578 and batch: 1050, loss is 3.4601121616363524 and perplexity is 31.82054535895733
At time: 351.5020864009857 and batch: 1100, loss is 3.6238446474075316 and perplexity is 37.48139390851798
At time: 351.88455390930176 and batch: 1150, loss is 3.5286547803878783 and perplexity is 34.07809424607097
At time: 352.2779264450073 and batch: 1200, loss is 3.4442608642578123 and perplexity is 31.320125065244476
At time: 352.6539034843445 and batch: 1250, loss is 3.3362629508972166 and perplexity is 28.113867245658014
At time: 353.0309143066406 and batch: 1300, loss is 3.4437774419784546 and perplexity is 31.304987878117213
At time: 353.40714287757874 and batch: 1350, loss is 3.4536541223526003 and perplexity is 31.615709159024068
At time: 353.77572870254517 and batch: 1400, loss is 3.28902624130249 and perplexity is 26.816737906099995
At time: 354.1634340286255 and batch: 1450, loss is 3.4071038913726808 and perplexity is 30.17771962599113
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.29906261476696 and perplexity of 73.63074097086415
Finished 30 epochs...
Completing Train Step...
At time: 355.4497003555298 and batch: 50, loss is 3.642775912284851 and perplexity is 38.19772322073517
At time: 355.8449065685272 and batch: 100, loss is 3.7000382375717162 and perplexity is 40.44885099633821
At time: 356.2152450084686 and batch: 150, loss is 3.5089010286331175 and perplexity is 33.411529286354536
At time: 356.58320808410645 and batch: 200, loss is 3.655690336227417 and perplexity is 38.69422392170849
At time: 356.9928936958313 and batch: 250, loss is 3.7291520547866823 and perplexity is 41.64378154340237
At time: 357.3720066547394 and batch: 300, loss is 3.6995590591430663 and perplexity is 40.42947342250555
At time: 357.75892877578735 and batch: 350, loss is 3.6681838464736938 and perplexity is 39.18068306840125
At time: 358.13034081459045 and batch: 400, loss is 3.4577627849578856 and perplexity is 31.74587466093899
At time: 358.50209498405457 and batch: 450, loss is 3.5522571277618407 and perplexity is 34.8919843401553
At time: 358.8901252746582 and batch: 500, loss is 3.5518940114974975 and perplexity is 34.87931679318154
At time: 359.2635431289673 and batch: 550, loss is 3.605989999771118 and perplexity is 36.818115746649696
At time: 359.6507234573364 and batch: 600, loss is 3.539850449562073 and perplexity is 34.461765033411254
At time: 360.04575848579407 and batch: 650, loss is 3.5877723836898805 and perplexity is 36.15345014295634
At time: 360.40474367141724 and batch: 700, loss is 3.6549103450775147 and perplexity is 38.66405453695333
At time: 360.77332615852356 and batch: 750, loss is 3.588469634056091 and perplexity is 36.178666939496985
At time: 361.16694927215576 and batch: 800, loss is 3.5144748306274414 and perplexity is 33.59827850302028
At time: 361.5450792312622 and batch: 850, loss is 3.4820101165771487 and perplexity is 32.525035523127706
At time: 361.92110109329224 and batch: 900, loss is 3.3570813655853273 and perplexity is 28.705288256073526
At time: 362.3092164993286 and batch: 950, loss is 3.5300516414642336 and perplexity is 34.125729871909826
At time: 362.6854634284973 and batch: 1000, loss is 3.531133117675781 and perplexity is 34.16265600073392
At time: 363.0798020362854 and batch: 1050, loss is 3.460124750137329 and perplexity is 31.82094593444498
At time: 363.480051279068 and batch: 1100, loss is 3.6238504886627196 and perplexity is 37.48161284754404
At time: 363.8486912250519 and batch: 1150, loss is 3.5286638832092283 and perplexity is 34.078404454286726
At time: 364.24783277511597 and batch: 1200, loss is 3.44427544593811 and perplexity is 31.320581768624812
At time: 364.6326320171356 and batch: 1250, loss is 3.3363005924224853 and perplexity is 28.114925514419642
At time: 365.00496315956116 and batch: 1300, loss is 3.4438197135925295 and perplexity is 31.306311218453086
At time: 365.39036297798157 and batch: 1350, loss is 3.4537016105651857 and perplexity is 31.617210568190988
At time: 365.77765345573425 and batch: 1400, loss is 3.289084620475769 and perplexity is 26.818303490787308
At time: 366.1454794406891 and batch: 1450, loss is 3.4071691942214968 and perplexity is 30.17969038140075
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.299029749682826 and perplexity of 73.62832113013164
Finished 31 epochs...
Completing Train Step...
At time: 367.38505506515503 and batch: 50, loss is 3.6426629781723023 and perplexity is 38.193409638341734
At time: 367.75264072418213 and batch: 100, loss is 3.699905767440796 and perplexity is 40.44349308664049
At time: 368.1439347267151 and batch: 150, loss is 3.508781461715698 and perplexity is 33.40753461161173
At time: 368.5371091365814 and batch: 200, loss is 3.6555734157562254 and perplexity is 38.689700039287565
At time: 368.9057219028473 and batch: 250, loss is 3.729016752243042 and perplexity is 41.638147414997306
At time: 369.27919149398804 and batch: 300, loss is 3.6994372987747193 and perplexity is 40.42455101461273
At time: 369.67424511909485 and batch: 350, loss is 3.6680786180496217 and perplexity is 39.17656036378455
At time: 370.04465556144714 and batch: 400, loss is 3.4576579999923704 and perplexity is 31.7425483448344
At time: 370.4402325153351 and batch: 450, loss is 3.5521459674835203 and perplexity is 34.88810595303019
At time: 370.8196883201599 and batch: 500, loss is 3.5517942190170286 and perplexity is 34.87583627330943
At time: 371.1999890804291 and batch: 550, loss is 3.605895576477051 and perplexity is 36.8146394230051
At time: 371.5901117324829 and batch: 600, loss is 3.5397577142715453 and perplexity is 34.45856935979694
At time: 371.97182512283325 and batch: 650, loss is 3.5876957511901857 and perplexity is 36.15067971985287
At time: 372.3505368232727 and batch: 700, loss is 3.6548396825790403 and perplexity is 38.66132253478479
At time: 372.7561180591583 and batch: 750, loss is 3.588401265144348 and perplexity is 36.17619352796321
At time: 373.1696209907532 and batch: 800, loss is 3.5144204807281496 and perplexity is 33.59645248958954
At time: 373.54505729675293 and batch: 850, loss is 3.481965193748474 and perplexity is 32.52357443934751
At time: 373.92783546447754 and batch: 900, loss is 3.357043447494507 and perplexity is 28.70419982698211
At time: 374.31168961524963 and batch: 950, loss is 3.5300220394134523 and perplexity is 34.12471969527294
At time: 374.7023551464081 and batch: 1000, loss is 3.5311102533340453 and perplexity is 34.16187490302218
At time: 375.08135986328125 and batch: 1050, loss is 3.4601335096359254 and perplexity is 31.821224671197015
At time: 375.4736704826355 and batch: 1100, loss is 3.62385507106781 and perplexity is 37.481784603871084
At time: 375.8949339389801 and batch: 1150, loss is 3.528670907020569 and perplexity is 34.078643815411006
At time: 376.2644407749176 and batch: 1200, loss is 3.444288077354431 and perplexity is 31.320977394431196
At time: 376.6437449455261 and batch: 1250, loss is 3.3363334560394287 and perplexity is 28.115849487744608
At time: 377.0160024166107 and batch: 1300, loss is 3.4438575220108034 and perplexity is 31.307494882938347
At time: 377.3910131454468 and batch: 1350, loss is 3.45374406337738 and perplexity is 31.618552836184676
At time: 377.8011305332184 and batch: 1400, loss is 3.289137325286865 and perplexity is 26.819716981655272
At time: 378.2105128765106 and batch: 1450, loss is 3.4072289657592774 and perplexity is 30.1814943218162
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.299001840444712 and perplexity of 73.62626624846048
Finished 32 epochs...
Completing Train Step...
At time: 379.5138759613037 and batch: 50, loss is 3.642554874420166 and perplexity is 38.18928101061705
At time: 379.9184732437134 and batch: 100, loss is 3.6997795486450196 and perplexity is 40.438388679788915
At time: 380.3075358867645 and batch: 150, loss is 3.5086671257019044 and perplexity is 33.40371514562898
At time: 380.6697130203247 and batch: 200, loss is 3.655461144447327 and perplexity is 38.685356539853004
At time: 381.05890440940857 and batch: 250, loss is 3.7288880157470703 and perplexity is 41.63278741082182
At time: 381.4630537033081 and batch: 300, loss is 3.6993208074569703 and perplexity is 40.41984217967015
At time: 381.84911131858826 and batch: 350, loss is 3.667976713180542 and perplexity is 39.17256828493929
At time: 382.22989153862 and batch: 400, loss is 3.4575568056106567 and perplexity is 31.7393363398018
At time: 382.6060702800751 and batch: 450, loss is 3.5520391845703125 and perplexity is 34.884380698340536
At time: 382.99373054504395 and batch: 500, loss is 3.5516980028152467 and perplexity is 34.872480814236596
At time: 383.39388966560364 and batch: 550, loss is 3.6058053731918336 and perplexity is 36.81131877135415
At time: 383.78364658355713 and batch: 600, loss is 3.539669132232666 and perplexity is 34.455517084656556
At time: 384.1676228046417 and batch: 650, loss is 3.587620749473572 and perplexity is 36.147968458493025
At time: 384.5402388572693 and batch: 700, loss is 3.6547708702087403 and perplexity is 38.658662249073565
At time: 384.91952252388 and batch: 750, loss is 3.5883351707458497 and perplexity is 36.17380256322758
At time: 385.2927393913269 and batch: 800, loss is 3.514367113113403 and perplexity is 33.594659574898444
At time: 385.6680202484131 and batch: 850, loss is 3.481919918060303 and perplexity is 32.52210194546733
At time: 386.05760312080383 and batch: 900, loss is 3.357005319595337 and perplexity is 28.70310541700926
At time: 386.42836356163025 and batch: 950, loss is 3.529992094039917 and perplexity is 34.12369783309498
At time: 386.80298137664795 and batch: 1000, loss is 3.5310868978500367 and perplexity is 34.161077045216395
At time: 387.2018778324127 and batch: 1050, loss is 3.4601392269134523 and perplexity is 31.821406602489784
At time: 387.578626871109 and batch: 1100, loss is 3.623858189582825 and perplexity is 37.4819014915614
At time: 387.9469566345215 and batch: 1150, loss is 3.528676247596741 and perplexity is 34.078825815490134
At time: 388.324912071228 and batch: 1200, loss is 3.444298620223999 and perplexity is 31.32130760915131
At time: 388.7061302661896 and batch: 1250, loss is 3.3363623428344726 and perplexity is 28.116661676256953
At time: 389.0871994495392 and batch: 1300, loss is 3.4438915395736696 and perplexity is 31.308559905728345
At time: 389.4814019203186 and batch: 1350, loss is 3.453782329559326 and perplexity is 31.619762780630197
At time: 389.8594460487366 and batch: 1400, loss is 3.289185004234314 and perplexity is 26.820995748016706
At time: 390.26185941696167 and batch: 1450, loss is 3.407284002304077 and perplexity is 30.183155452691597
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.298979408720619 and perplexity of 73.62461470289362
Finished 33 epochs...
Completing Train Step...
At time: 391.6165075302124 and batch: 50, loss is 3.642450566291809 and perplexity is 38.18529776593755
At time: 392.0066328048706 and batch: 100, loss is 3.6996587133407592 and perplexity is 40.43350259000101
At time: 392.37472105026245 and batch: 150, loss is 3.508556776046753 and perplexity is 33.4000292605537
At time: 392.78507256507874 and batch: 200, loss is 3.6553532695770263 and perplexity is 38.68118358711615
At time: 393.1674838066101 and batch: 250, loss is 3.7287649297714234 and perplexity is 41.62766331392316
At time: 393.5483367443085 and batch: 300, loss is 3.699208722114563 and perplexity is 40.41531196170964
At time: 393.9475393295288 and batch: 350, loss is 3.667877917289734 and perplexity is 39.16869838732847
At time: 394.32394790649414 and batch: 400, loss is 3.4574590301513672 and perplexity is 31.736233163323355
At time: 394.69366908073425 and batch: 450, loss is 3.551935920715332 and perplexity is 34.88077858869808
At time: 395.0990538597107 and batch: 500, loss is 3.551605086326599 and perplexity is 34.869240736299574
At time: 395.492901802063 and batch: 550, loss is 3.605718379020691 and perplexity is 36.80811654047869
At time: 395.87796092033386 and batch: 600, loss is 3.5395840072631835 and perplexity is 34.4525841846495
At time: 396.25310802459717 and batch: 650, loss is 3.5875470876693725 and perplexity is 36.14530583198637
At time: 396.6285982131958 and batch: 700, loss is 3.654703392982483 and perplexity is 38.656053757782054
At time: 397.03134393692017 and batch: 750, loss is 3.5882709884643553 and perplexity is 36.171480920553705
At time: 397.4117362499237 and batch: 800, loss is 3.5143142127990723 and perplexity is 33.59288245385264
At time: 397.80306100845337 and batch: 850, loss is 3.4818747568130495 and perplexity is 32.5206332399447
At time: 398.17129731178284 and batch: 900, loss is 3.356967124938965 and perplexity is 28.702009132697288
At time: 398.5580184459686 and batch: 950, loss is 3.529961724281311 and perplexity is 34.122661520365405
At time: 398.95285725593567 and batch: 1000, loss is 3.531062893867493 and perplexity is 34.1602570531609
At time: 399.34850120544434 and batch: 1050, loss is 3.4601417446136473 and perplexity is 31.821486719352247
At time: 399.7284183502197 and batch: 1100, loss is 3.6238597774505616 and perplexity is 37.48196100791075
At time: 400.11435055732727 and batch: 1150, loss is 3.5286797714233398 and perplexity is 34.07894590357459
At time: 400.51710510253906 and batch: 1200, loss is 3.44430748462677 and perplexity is 31.321585255067852
At time: 400.89948320388794 and batch: 1250, loss is 3.336387495994568 and perplexity is 28.11736890804396
At time: 401.26437616348267 and batch: 1300, loss is 3.44392183303833 and perplexity is 31.3095083648474
At time: 401.66113662719727 and batch: 1350, loss is 3.4538170528411865 and perplexity is 31.620860741627887
At time: 402.0371241569519 and batch: 1400, loss is 3.2892282724380495 and perplexity is 26.822156269431776
At time: 402.41512656211853 and batch: 1450, loss is 3.407334580421448 and perplexity is 30.18468209847781
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.298959585336538 and perplexity of 73.62315522834446
Finished 34 epochs...
Completing Train Step...
At time: 403.71996426582336 and batch: 50, loss is 3.6423495769500733 and perplexity is 38.18144165256863
At time: 404.08480191230774 and batch: 100, loss is 3.6995425987243653 and perplexity is 40.428807941922216
At time: 404.47319889068604 and batch: 150, loss is 3.508450274467468 and perplexity is 33.39647229410392
At time: 404.8460781574249 and batch: 200, loss is 3.655248985290527 and perplexity is 38.67714995781056
At time: 405.2136929035187 and batch: 250, loss is 3.7286470985412596 and perplexity is 41.622758564118065
At time: 405.5867569446564 and batch: 300, loss is 3.699100737571716 and perplexity is 40.41094796834961
At time: 405.9697754383087 and batch: 350, loss is 3.667781548500061 and perplexity is 39.16492392914473
At time: 406.3375566005707 and batch: 400, loss is 3.457364001274109 and perplexity is 31.733217448009725
At time: 406.7180247306824 and batch: 450, loss is 3.5518356800079345 and perplexity is 34.87728229001643
At time: 407.09269738197327 and batch: 500, loss is 3.5515148496627806 and perplexity is 34.866094394305485
At time: 407.44687151908875 and batch: 550, loss is 3.6056340074539186 and perplexity is 36.80501111302297
At time: 407.8336727619171 and batch: 600, loss is 3.5395016288757324 and perplexity is 34.449746153218676
At time: 408.22692608833313 and batch: 650, loss is 3.5874746513366698 and perplexity is 36.1426876934128
At time: 408.6067798137665 and batch: 700, loss is 3.654637088775635 and perplexity is 38.653490783766685
At time: 408.98424649238586 and batch: 750, loss is 3.588208222389221 and perplexity is 36.16921064991326
At time: 409.36406683921814 and batch: 800, loss is 3.5142618942260744 and perplexity is 33.59112496815474
At time: 409.74264574050903 and batch: 850, loss is 3.4818297243118286 and perplexity is 32.519168787462846
At time: 410.1243185997009 and batch: 900, loss is 3.3569286918640135 and perplexity is 28.70090604742665
At time: 410.50582242012024 and batch: 950, loss is 3.529931058883667 and perplexity is 34.121615151424955
At time: 410.88089179992676 and batch: 1000, loss is 3.5310383653640747 and perplexity is 34.15941916345514
At time: 411.25223088264465 and batch: 1050, loss is 3.4601418447494505 and perplexity is 31.82148990582254
At time: 411.65047430992126 and batch: 1100, loss is 3.6238600254058837 and perplexity is 37.48197030176362
At time: 412.02089405059814 and batch: 1150, loss is 3.5286818838119505 and perplexity is 34.079017891627814
At time: 412.42321038246155 and batch: 1200, loss is 3.4443146324157716 and perplexity is 31.321809135950573
At time: 412.82030034065247 and batch: 1250, loss is 3.336409468650818 and perplexity is 28.11798672811318
At time: 413.2226152420044 and batch: 1300, loss is 3.4439489603042603 and perplexity is 31.31035771772722
At time: 413.59966588020325 and batch: 1350, loss is 3.453848443031311 and perplexity is 31.621853342037344
At time: 413.9936361312866 and batch: 1400, loss is 3.289267864227295 and perplexity is 26.823218227612173
At time: 414.3666105270386 and batch: 1450, loss is 3.4073812580108642 and perplexity is 30.186091079559134
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2989439352964745 and perplexity of 73.6220030320315
Finished 35 epochs...
Completing Train Step...
At time: 415.646427154541 and batch: 50, loss is 3.6422514724731445 and perplexity is 38.17769606593933
At time: 416.0183279514313 and batch: 100, loss is 3.6994306659698486 and perplexity is 40.42428288734309
At time: 416.39095163345337 and batch: 150, loss is 3.508346829414368 and perplexity is 33.39301777293374
At time: 416.79501605033875 and batch: 200, loss is 3.6551480674743653 and perplexity is 38.67324694124672
At time: 417.1924583911896 and batch: 250, loss is 3.7285334920883177 and perplexity is 41.61803021874629
At time: 417.5508258342743 and batch: 300, loss is 3.698996114730835 and perplexity is 40.40672028133062
At time: 417.93300461769104 and batch: 350, loss is 3.6676874446868895 and perplexity is 39.161238533868016
At time: 418.3175928592682 and batch: 400, loss is 3.4572713565826416 and perplexity is 31.730277670049503
At time: 418.7059254646301 and batch: 450, loss is 3.5517380619049073 and perplexity is 34.873877802053066
At time: 419.0803596973419 and batch: 500, loss is 3.551427001953125 and perplexity is 34.86303162229903
At time: 419.4701826572418 and batch: 550, loss is 3.60555193901062 and perplexity is 36.801990706997046
At time: 419.8463463783264 and batch: 600, loss is 3.53942183971405 and perplexity is 34.446997546508925
At time: 420.2160966396332 and batch: 650, loss is 3.5874032831192015 and perplexity is 36.14010834626041
At time: 420.60383129119873 and batch: 700, loss is 3.6545719623565676 and perplexity is 38.65097350229914
At time: 420.9999816417694 and batch: 750, loss is 3.5881464529037475 and perplexity is 36.16697656538126
At time: 421.3776624202728 and batch: 800, loss is 3.5142098093032836 and perplexity is 33.58937542256719
At time: 421.78404474258423 and batch: 850, loss is 3.4817845726013186 and perplexity is 32.51770052451527
At time: 422.20409202575684 and batch: 900, loss is 3.356890058517456 and perplexity is 28.69979725679509
At time: 422.573570728302 and batch: 950, loss is 3.5298998403549193 and perplexity is 34.120549941428656
At time: 422.97333002090454 and batch: 1000, loss is 3.5310133695602417 and perplexity is 34.15856533198583
At time: 423.3498766422272 and batch: 1050, loss is 3.4601396703720093 and perplexity is 31.821420713967967
At time: 423.73061442375183 and batch: 1100, loss is 3.623858971595764 and perplexity is 37.48193080290482
At time: 424.1153769493103 and batch: 1150, loss is 3.5286827278137207 and perplexity is 34.079046654391384
At time: 424.5053436756134 and batch: 1200, loss is 3.444320011138916 and perplexity is 31.321977607743374
At time: 424.8741457462311 and batch: 1250, loss is 3.336428527832031 and perplexity is 28.11852263902458
At time: 425.26819372177124 and batch: 1300, loss is 3.443973240852356 and perplexity is 31.311117959603187
At time: 425.6550130844116 and batch: 1350, loss is 3.4538769721984863 and perplexity is 31.62275550004658
At time: 426.0421829223633 and batch: 1400, loss is 3.289303951263428 and perplexity is 26.824186215523362
At time: 426.42166543006897 and batch: 1450, loss is 3.407424430847168 and perplexity is 30.187394326860197
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.298929328592415 and perplexity of 73.62092766507473
Finished 36 epochs...
Completing Train Step...
At time: 427.7948269844055 and batch: 50, loss is 3.6421557331085204 and perplexity is 38.174041132538456
At time: 428.17894101142883 and batch: 100, loss is 3.699322385787964 and perplexity is 40.419905975610156
At time: 428.5745084285736 and batch: 150, loss is 3.508246216773987 and perplexity is 33.3896581822568
At time: 428.9676637649536 and batch: 200, loss is 3.655050024986267 and perplexity is 38.66945550575768
At time: 429.3467962741852 and batch: 250, loss is 3.7284238052368166 and perplexity is 41.6134655183943
At time: 429.7445387840271 and batch: 300, loss is 3.6988947200775146 and perplexity is 40.402623463637106
At time: 430.12526988983154 and batch: 350, loss is 3.6675953578948977 and perplexity is 39.15763246707911
At time: 430.49090695381165 and batch: 400, loss is 3.4571807527542116 and perplexity is 31.727402915649293
At time: 430.8639199733734 and batch: 450, loss is 3.5516427087783815 and perplexity is 34.87055262730598
At time: 431.24401664733887 and batch: 500, loss is 3.5513412618637084 and perplexity is 34.86004259099214
At time: 431.62456703186035 and batch: 550, loss is 3.605471844673157 and perplexity is 36.799043193975166
At time: 432.0101282596588 and batch: 600, loss is 3.5393442249298097 and perplexity is 34.44432405397923
At time: 432.39300537109375 and batch: 650, loss is 3.587333116531372 and perplexity is 36.137572607137095
At time: 432.80056285858154 and batch: 700, loss is 3.6545077896118165 and perplexity is 38.64849324282557
At time: 433.1690020561218 and batch: 750, loss is 3.5880856943130492 and perplexity is 36.1647791776111
At time: 433.5379526615143 and batch: 800, loss is 3.51415810585022 and perplexity is 33.58763878076716
At time: 433.90678191185 and batch: 850, loss is 3.481739492416382 and perplexity is 32.51623465360303
At time: 434.29650139808655 and batch: 900, loss is 3.3568511724472048 and perplexity is 28.698681256161343
At time: 434.68190574645996 and batch: 950, loss is 3.529868245124817 and perplexity is 34.11947191183242
At time: 435.0587418079376 and batch: 1000, loss is 3.5309880065917967 and perplexity is 34.15769898035786
At time: 435.42725348472595 and batch: 1050, loss is 3.4601351976394654 and perplexity is 31.821278385582247
At time: 435.8132817745209 and batch: 1100, loss is 3.6238565015792847 and perplexity is 37.481838222032394
At time: 436.2137951850891 and batch: 1150, loss is 3.5286821842193605 and perplexity is 34.079028129218855
At time: 436.58173847198486 and batch: 1200, loss is 3.44432421207428 and perplexity is 31.32210918962316
At time: 436.9645404815674 and batch: 1250, loss is 3.3364447736740113 and perplexity is 28.11897945181073
At time: 437.36932373046875 and batch: 1300, loss is 3.4439949798583984 and perplexity is 31.31179863958433
At time: 437.74584007263184 and batch: 1350, loss is 3.4539029121398928 and perplexity is 31.623575803110622
At time: 438.13443994522095 and batch: 1400, loss is 3.2893370676040647 and perplexity is 26.82507454912048
At time: 438.5155918598175 and batch: 1450, loss is 3.4074643802642823 and perplexity is 30.188600319756954
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.298917069394364 and perplexity of 73.62002513707397
Finished 37 epochs...
Completing Train Step...
At time: 439.8497610092163 and batch: 50, loss is 3.6420621728897093 and perplexity is 38.1704697279705
At time: 440.2512619495392 and batch: 100, loss is 3.6992175340652467 and perplexity is 40.41566810101466
At time: 440.6147315502167 and batch: 150, loss is 3.5081481075286867 and perplexity is 33.38638250878126
At time: 440.9904537200928 and batch: 200, loss is 3.654954447746277 and perplexity is 38.665759762545804
At time: 441.3537075519562 and batch: 250, loss is 3.728317642211914 and perplexity is 41.609047941514
At time: 441.724901676178 and batch: 300, loss is 3.6987957620620726 and perplexity is 40.39862549801912
At time: 442.1173450946808 and batch: 350, loss is 3.667505121231079 and perplexity is 39.15409917238102
At time: 442.5078344345093 and batch: 400, loss is 3.4570920276641846 and perplexity is 31.724588023846888
At time: 442.87950110435486 and batch: 450, loss is 3.5515495204925536 and perplexity is 34.867303251684994
At time: 443.27985191345215 and batch: 500, loss is 3.5512574529647827 and perplexity is 34.85712113162994
At time: 443.6888303756714 and batch: 550, loss is 3.6053932809829714 and perplexity is 36.79615223891009
At time: 444.0673713684082 and batch: 600, loss is 3.539268522262573 and perplexity is 34.44171662547307
At time: 444.44796919822693 and batch: 650, loss is 3.5872637271881103 and perplexity is 36.13506513170385
At time: 444.8266952037811 and batch: 700, loss is 3.654444499015808 and perplexity is 38.6460472340589
At time: 445.2122416496277 and batch: 750, loss is 3.588025908470154 and perplexity is 36.16261710043629
At time: 445.5818817615509 and batch: 800, loss is 3.514106731414795 and perplexity is 33.58591327911126
At time: 445.9667890071869 and batch: 850, loss is 3.4816946315765382 and perplexity is 32.5147759807268
At time: 446.3636312484741 and batch: 900, loss is 3.3568121719360353 and perplexity is 28.6975620147481
At time: 446.7418956756592 and batch: 950, loss is 3.5298361730575563 and perplexity is 34.118377647382125
At time: 447.11996483802795 and batch: 1000, loss is 3.530962038040161 and perplexity is 34.15681196590542
At time: 447.52007937431335 and batch: 1050, loss is 3.4601290464401244 and perplexity is 31.821082647157624
At time: 447.8878102302551 and batch: 1100, loss is 3.623852949142456 and perplexity is 37.4817050704064
At time: 448.30257058143616 and batch: 1150, loss is 3.528680458068848 and perplexity is 34.07896930373774
At time: 448.68607664108276 and batch: 1200, loss is 3.444326820373535 and perplexity is 31.322190887163778
At time: 449.06256914138794 and batch: 1250, loss is 3.336458821296692 and perplexity is 28.11937445939869
At time: 449.447030544281 and batch: 1300, loss is 3.444014105796814 and perplexity is 31.312397512843784
At time: 449.84798669815063 and batch: 1350, loss is 3.453926544189453 and perplexity is 31.624323141851814
At time: 450.2353296279907 and batch: 1400, loss is 3.2893674516677858 and perplexity is 26.825889616277365
At time: 450.61110186576843 and batch: 1450, loss is 3.4075014448165892 and perplexity is 30.1897192674491
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.29890872270633 and perplexity of 73.61941065625554
Finished 38 epochs...
Completing Train Step...
At time: 451.9217097759247 and batch: 50, loss is 3.6419704294204713 and perplexity is 38.166967997288126
At time: 452.2912368774414 and batch: 100, loss is 3.699115653038025 and perplexity is 40.411550720977694
At time: 452.67817735671997 and batch: 150, loss is 3.5080522155761718 and perplexity is 33.38318117686852
At time: 453.0819947719574 and batch: 200, loss is 3.6548611688613892 and perplexity is 38.662153231801014
At time: 453.451744556427 and batch: 250, loss is 3.7282144021987915 and perplexity is 41.604752444595896
At time: 453.82799339294434 and batch: 300, loss is 3.6986992931365967 and perplexity is 40.39472847400051
At time: 454.2093777656555 and batch: 350, loss is 3.667416296005249 and perplexity is 39.150621455136644
At time: 454.5823905467987 and batch: 400, loss is 3.4570049953460695 and perplexity is 31.721827079557364
At time: 454.9743711948395 and batch: 450, loss is 3.551458134651184 and perplexity is 34.86411701943154
At time: 455.35676646232605 and batch: 500, loss is 3.551175479888916 and perplexity is 34.854263903304414
At time: 455.727906703949 and batch: 550, loss is 3.6053163623809814 and perplexity is 36.793322039170164
At time: 456.10410618782043 and batch: 600, loss is 3.539194450378418 and perplexity is 34.43916555711147
At time: 456.4871907234192 and batch: 650, loss is 3.587195258140564 and perplexity is 36.1325910829101
At time: 456.8612198829651 and batch: 700, loss is 3.6543819189071653 and perplexity is 38.64362883589698
At time: 457.23928022384644 and batch: 750, loss is 3.5879666805267334 and perplexity is 36.16047532642379
At time: 457.62078499794006 and batch: 800, loss is 3.5140556716918945 and perplexity is 33.584198435465964
At time: 457.99063754081726 and batch: 850, loss is 3.481649708747864 and perplexity is 32.513315357823934
At time: 458.3841712474823 and batch: 900, loss is 3.356772880554199 and perplexity is 28.696434470032752
At time: 458.76570868492126 and batch: 950, loss is 3.529803876876831 and perplexity is 34.11727577188485
At time: 459.1597480773926 and batch: 1000, loss is 3.530935735702515 and perplexity is 34.15591357371913
At time: 459.5441789627075 and batch: 1050, loss is 3.460121064186096 and perplexity is 31.820828644206234
At time: 459.9516427516937 and batch: 1100, loss is 3.6238481044769286 and perplexity is 37.481523484521794
At time: 460.32759046554565 and batch: 1150, loss is 3.528677611351013 and perplexity is 34.07887229066612
At time: 460.7075824737549 and batch: 1200, loss is 3.444328169822693 and perplexity is 31.32223315489641
At time: 461.0892367362976 and batch: 1250, loss is 3.3364707326889036 and perplexity is 28.119709402291434
At time: 461.5059268474579 and batch: 1300, loss is 3.444031262397766 and perplexity is 31.312934731761175
At time: 461.88586950302124 and batch: 1350, loss is 3.4539483165740967 and perplexity is 31.625011686274952
At time: 462.30127573013306 and batch: 1400, loss is 3.289395642280579 and perplexity is 26.826645865203876
At time: 462.6795811653137 and batch: 1450, loss is 3.407536087036133 and perplexity is 30.19076512444722
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.298900636852297 and perplexity of 73.6188153828536
Finished 39 epochs...
Completing Train Step...
At time: 463.9641273021698 and batch: 50, loss is 3.6418806076049806 and perplexity is 38.163539924890976
At time: 464.3392028808594 and batch: 100, loss is 3.699016456604004 and perplexity is 40.407542238069794
At time: 464.72299313545227 and batch: 150, loss is 3.50795823097229 and perplexity is 33.38004381924326
At time: 465.1086223125458 and batch: 200, loss is 3.6547699403762817 and perplexity is 38.65862630301131
At time: 465.51534247398376 and batch: 250, loss is 3.728114085197449 and perplexity is 41.60057898992678
At time: 465.911203622818 and batch: 300, loss is 3.698605055809021 and perplexity is 40.39092196210155
At time: 466.27981901168823 and batch: 350, loss is 3.6673290586471556 and perplexity is 39.147206207323954
At time: 466.66470646858215 and batch: 400, loss is 3.456919455528259 and perplexity is 31.71911371630032
At time: 467.0605709552765 and batch: 450, loss is 3.5513683271408083 and perplexity is 34.86098610047269
At time: 467.43028378486633 and batch: 500, loss is 3.551094899177551 and perplexity is 34.85145543508069
At time: 467.7964024543762 and batch: 550, loss is 3.6052404928207396 and perplexity is 36.79053065189922
At time: 468.1713352203369 and batch: 600, loss is 3.5391217994689943 and perplexity is 34.43666361129938
At time: 468.5564785003662 and batch: 650, loss is 3.5871276569366457 and perplexity is 36.13014855881193
At time: 468.9463391304016 and batch: 700, loss is 3.6543201446533202 and perplexity is 38.641241728291426
At time: 469.33406257629395 and batch: 750, loss is 3.587908024787903 and perplexity is 36.15835436923083
At time: 469.7113001346588 and batch: 800, loss is 3.514004707336426 and perplexity is 33.582486882053246
At time: 470.1068260669708 and batch: 850, loss is 3.48160493850708 and perplexity is 32.51185976145062
At time: 470.49844574928284 and batch: 900, loss is 3.356733298301697 and perplexity is 28.695298622997484
At time: 470.8677861690521 and batch: 950, loss is 3.5297712421417238 and perplexity is 34.11616238179515
At time: 471.2912714481354 and batch: 1000, loss is 3.5309091138839723 and perplexity is 34.155004293289224
At time: 471.6886188983917 and batch: 1050, loss is 3.46011155128479 and perplexity is 31.820525937243687
At time: 472.08275842666626 and batch: 1100, loss is 3.6238421964645386 and perplexity is 37.48130204387079
At time: 472.4651999473572 and batch: 1150, loss is 3.52867386341095 and perplexity is 34.07874456533471
At time: 472.8606526851654 and batch: 1200, loss is 3.4443283796310427 and perplexity is 31.322239726563147
At time: 473.25140929222107 and batch: 1250, loss is 3.3364807891845705 and perplexity is 28.119992189449114
At time: 473.6206238269806 and batch: 1300, loss is 3.4440464544296265 and perplexity is 31.313410442476762
At time: 474.02820229530334 and batch: 1350, loss is 3.453967976570129 and perplexity is 31.62563343999105
At time: 474.41991114616394 and batch: 1400, loss is 3.2894216632843016 and perplexity is 26.827343930537946
At time: 474.79023241996765 and batch: 1450, loss is 3.4075683689117433 and perplexity is 30.191739754702915
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.298892290164263 and perplexity of 73.61820091213255
Finished 40 epochs...
Completing Train Step...
At time: 476.05727529525757 and batch: 50, loss is 3.641792211532593 and perplexity is 38.1601665669512
At time: 476.42712926864624 and batch: 100, loss is 3.6989196872711183 and perplexity is 40.40363221635202
At time: 476.8159484863281 and batch: 150, loss is 3.5078661584854127 and perplexity is 33.37697057707945
At time: 477.1910741329193 and batch: 200, loss is 3.6546806859970093 and perplexity is 38.6551760052965
At time: 477.57266879081726 and batch: 250, loss is 3.728016247749329 and perplexity is 41.59650909453543
At time: 477.9476001262665 and batch: 300, loss is 3.698512649536133 and perplexity is 40.38718975998661
At time: 478.3258364200592 and batch: 350, loss is 3.667243070602417 and perplexity is 39.14384016032717
At time: 478.7090880870819 and batch: 400, loss is 3.4568353605270388 and perplexity is 31.71644640954879
At time: 479.08549547195435 and batch: 450, loss is 3.551280198097229 and perplexity is 34.85791397048335
At time: 479.47554993629456 and batch: 500, loss is 3.551015729904175 and perplexity is 34.84869637989543
At time: 479.8626539707184 and batch: 550, loss is 3.605165791511536 and perplexity is 36.7877824537415
At time: 480.24604868888855 and batch: 600, loss is 3.5390504598617554 and perplexity is 34.43420700087058
At time: 480.6360123157501 and batch: 650, loss is 3.5870607471466065 and perplexity is 36.12773117903186
At time: 481.0305805206299 and batch: 700, loss is 3.654259023666382 and perplexity is 38.638880009636495
At time: 481.407767534256 and batch: 750, loss is 3.5878498554229736 and perplexity is 36.15625112189315
At time: 481.7966613769531 and batch: 800, loss is 3.513954029083252 and perplexity is 33.5807850234048
At time: 482.1656930446625 and batch: 850, loss is 3.48156033039093 and perplexity is 32.510409500981076
At time: 482.54234051704407 and batch: 900, loss is 3.3566937255859375 and perplexity is 28.694163094569564
At time: 482.9309878349304 and batch: 950, loss is 3.5297383069992065 and perplexity is 34.115038779628065
At time: 483.3090617656708 and batch: 1000, loss is 3.5308822441101073 and perplexity is 34.15408656837709
At time: 483.71295189857483 and batch: 1050, loss is 3.460100598335266 and perplexity is 31.820177410537962
At time: 484.0839595794678 and batch: 1100, loss is 3.6238352489471435 and perplexity is 37.48104164277742
At time: 484.4670262336731 and batch: 1150, loss is 3.5286691665649412 and perplexity is 34.078584503095215
At time: 484.8527867794037 and batch: 1200, loss is 3.4443275547027588 and perplexity is 31.322213887972342
At time: 485.22128653526306 and batch: 1250, loss is 3.336488904953003 and perplexity is 28.12022040572012
At time: 485.60620760917664 and batch: 1300, loss is 3.444059977531433 and perplexity is 31.3138338997773
At time: 485.99609112739563 and batch: 1350, loss is 3.4539861249923707 and perplexity is 31.626207400548594
At time: 486.3679893016815 and batch: 1400, loss is 3.2894456148147584 and perplexity is 26.827986494178333
At time: 486.74066257476807 and batch: 1450, loss is 3.4075983142852784 and perplexity is 30.192643871164528
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2988870734842415 and perplexity of 73.61781687053636
Finished 41 epochs...
Completing Train Step...
At time: 487.9777114391327 and batch: 50, loss is 3.6417052125930787 and perplexity is 38.15684681733763
At time: 488.3769209384918 and batch: 100, loss is 3.6988251066207884 and perplexity is 40.39981099525095
At time: 488.77361822128296 and batch: 150, loss is 3.5077756118774412 and perplexity is 33.373948542428884
At time: 489.1430413722992 and batch: 200, loss is 3.65459303855896 and perplexity is 38.65178812662389
At time: 489.51212096214294 and batch: 250, loss is 3.7279205417633055 and perplexity is 41.59252825011576
At time: 489.903400182724 and batch: 300, loss is 3.6984222078323366 and perplexity is 40.383537238905774
At time: 490.2853252887726 and batch: 350, loss is 3.66715838432312 and perplexity is 39.14052535450787
At time: 490.6652572154999 and batch: 400, loss is 3.456752371788025 and perplexity is 31.713814410869904
At time: 491.0519711971283 and batch: 450, loss is 3.551193313598633 and perplexity is 34.854885489671844
At time: 491.4165461063385 and batch: 500, loss is 3.550937991142273 and perplexity is 34.84598739068306
At time: 491.8151128292084 and batch: 550, loss is 3.6050920200347902 and perplexity is 36.785068664805024
At time: 492.18917775154114 and batch: 600, loss is 3.538980259895325 and perplexity is 34.431789805539566
At time: 492.58155369758606 and batch: 650, loss is 3.5869948387146 and perplexity is 36.12535013538418
At time: 492.95772314071655 and batch: 700, loss is 3.654198522567749 and perplexity is 38.636542385661095
At time: 493.33839440345764 and batch: 750, loss is 3.5877922201156616 and perplexity is 36.15416730529977
At time: 493.7298300266266 and batch: 800, loss is 3.513903546333313 and perplexity is 33.57908981582144
At time: 494.0992851257324 and batch: 850, loss is 3.4815157413482667 and perplexity is 32.508959925262666
At time: 494.51049160957336 and batch: 900, loss is 3.3566538190841673 and perplexity is 28.693018033747073
At time: 494.920658826828 and batch: 950, loss is 3.529705119132996 and perplexity is 34.113906593072805
At time: 495.277667760849 and batch: 1000, loss is 3.5308551025390624 and perplexity is 34.153159585389965
At time: 495.68271565437317 and batch: 1050, loss is 3.46008837223053 and perplexity is 31.819788376094408
At time: 496.08031368255615 and batch: 1100, loss is 3.62382728099823 and perplexity is 37.48074299694218
At time: 496.46405959129333 and batch: 1150, loss is 3.528663501739502 and perplexity is 34.07839145440958
At time: 496.84553575515747 and batch: 1200, loss is 3.4443256950378416 and perplexity is 31.322155639204208
At time: 497.23372077941895 and batch: 1250, loss is 3.336495518684387 and perplexity is 28.12040638591936
At time: 497.6263153553009 and batch: 1300, loss is 3.444071807861328 and perplexity is 31.31420435495392
At time: 498.0096299648285 and batch: 1350, loss is 3.454002704620361 and perplexity is 31.62673175564884
At time: 498.3893575668335 and batch: 1400, loss is 3.2894679498672486 and perplexity is 26.82858570535657
At time: 498.78133177757263 and batch: 1450, loss is 3.4076265621185304 and perplexity is 30.193496759980114
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2988810743022166 and perplexity of 73.61737522517744
Finished 42 epochs...
Completing Train Step...
At time: 500.05913400650024 and batch: 50, loss is 3.6416194009780884 and perplexity is 38.15357265717179
At time: 500.4585530757904 and batch: 100, loss is 3.698732557296753 and perplexity is 40.39607219306665
At time: 500.84658670425415 and batch: 150, loss is 3.5076866292953492 and perplexity is 33.37097897443485
At time: 501.22132658958435 and batch: 200, loss is 3.6545068979263307 and perplexity is 38.648458780540466
At time: 501.5986018180847 and batch: 250, loss is 3.7278271389007567 and perplexity is 41.58864357033949
At time: 501.9630846977234 and batch: 300, loss is 3.6983333683013915 and perplexity is 40.37994974375762
At time: 502.33230662345886 and batch: 350, loss is 3.6670748090744016 and perplexity is 39.137254312057394
At time: 502.7024927139282 and batch: 400, loss is 3.45667058467865 and perplexity is 31.71122073572802
At time: 503.0860152244568 and batch: 450, loss is 3.5511077451705932 and perplexity is 34.85190313951032
At time: 503.4525718688965 and batch: 500, loss is 3.5508612537384034 and perplexity is 34.843313502670355
At time: 503.8310420513153 and batch: 550, loss is 3.605019268989563 and perplexity is 36.78239260995498
At time: 504.21594524383545 and batch: 600, loss is 3.5389109897613524 and perplexity is 34.42940479345283
At time: 504.57354736328125 and batch: 650, loss is 3.586929383277893 and perplexity is 36.12298561220118
At time: 504.9342908859253 and batch: 700, loss is 3.654138431549072 and perplexity is 38.634220746226525
At time: 505.3243238925934 and batch: 750, loss is 3.587735013961792 and perplexity is 36.1520991235988
At time: 505.69264221191406 and batch: 800, loss is 3.513853178024292 and perplexity is 33.57739853644275
At time: 506.0872588157654 and batch: 850, loss is 3.4814712142944337 and perplexity is 32.507512429280624
At time: 506.45672821998596 and batch: 900, loss is 3.3566138124465943 and perplexity is 28.69187014553545
At time: 506.81901597976685 and batch: 950, loss is 3.5296717500686645 and perplexity is 34.11276826292172
At time: 507.20982122421265 and batch: 1000, loss is 3.5308277368545533 and perplexity is 34.15222497358797
At time: 507.5890018939972 and batch: 1050, loss is 3.460074992179871 and perplexity is 31.819362628562246
At time: 507.9501314163208 and batch: 1100, loss is 3.6238183784484863 and perplexity is 37.48040932424849
At time: 508.33177280426025 and batch: 1150, loss is 3.528657159805298 and perplexity is 34.07817533217851
At time: 508.7123420238495 and batch: 1200, loss is 3.4443228530883787 and perplexity is 31.3220666233473
At time: 509.1178195476532 and batch: 1250, loss is 3.336500768661499 and perplexity is 28.120554017796792
At time: 509.4916889667511 and batch: 1300, loss is 3.444082250595093 and perplexity is 31.31453136256048
At time: 509.8667941093445 and batch: 1350, loss is 3.4540178871154783 and perplexity is 31.62721193199442
At time: 510.27046632766724 and batch: 1400, loss is 3.289488682746887 and perplexity is 26.829141944961073
At time: 510.63452100753784 and batch: 1450, loss is 3.4076527404785155 and perplexity is 30.194287186553495
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.298876118456197 and perplexity of 73.61701038970547
Finished 43 epochs...
Completing Train Step...
At time: 511.97270917892456 and batch: 50, loss is 3.641534838676453 and perplexity is 38.15034643966239
At time: 512.3450241088867 and batch: 100, loss is 3.6986418962478638 and perplexity is 40.39241000880187
At time: 512.7320578098297 and batch: 150, loss is 3.507599024772644 and perplexity is 33.36805565379951
At time: 513.1099548339844 and batch: 200, loss is 3.6544221305847167 and perplexity is 38.645182792282526
At time: 513.492208480835 and batch: 250, loss is 3.7277352571487428 and perplexity is 41.58482250844999
At time: 513.8776366710663 and batch: 300, loss is 3.6982459449768066 and perplexity is 40.376419748608654
At time: 514.253271818161 and batch: 350, loss is 3.6669922351837156 and perplexity is 39.13402273012206
At time: 514.6205787658691 and batch: 400, loss is 3.4565897369384766 and perplexity is 31.70865705882854
At time: 515.0000903606415 and batch: 450, loss is 3.5510232210159303 and perplexity is 34.84895743635234
At time: 515.389125585556 and batch: 500, loss is 3.5507856750488282 and perplexity is 34.84068019020777
At time: 515.7668957710266 and batch: 550, loss is 3.6049472808837892 and perplexity is 36.779744810491344
At time: 516.147055387497 and batch: 600, loss is 3.538842601776123 and perplexity is 34.42705031633625
At time: 516.5205779075623 and batch: 650, loss is 3.586864490509033 and perplexity is 36.12064156770191
At time: 516.8894896507263 and batch: 700, loss is 3.6540789365768434 and perplexity is 38.63192227271063
At time: 517.2728726863861 and batch: 750, loss is 3.587678098678589 and perplexity is 36.150041575192326
At time: 517.6479375362396 and batch: 800, loss is 3.5138028478622436 and perplexity is 33.57570862306042
At time: 518.0260694026947 and batch: 850, loss is 3.481426854133606 and perplexity is 32.50607042278521
At time: 518.4196829795837 and batch: 900, loss is 3.3565736293792723 and perplexity is 28.690717241349567
At time: 518.7908635139465 and batch: 950, loss is 3.52963800907135 and perplexity is 34.111617283517084
At time: 519.16090965271 and batch: 1000, loss is 3.530799913406372 and perplexity is 34.15127475414538
At time: 519.5349671840668 and batch: 1050, loss is 3.460060467720032 and perplexity is 31.81890047286394
At time: 519.92928647995 and batch: 1100, loss is 3.6238086891174315 and perplexity is 37.48004616591386
At time: 520.2996370792389 and batch: 1150, loss is 3.528649997711182 and perplexity is 34.07793126195351
At time: 520.6791751384735 and batch: 1200, loss is 3.444319124221802 and perplexity is 31.32194982775771
At time: 521.0536170005798 and batch: 1250, loss is 3.336504602432251 and perplexity is 28.12066182576097
At time: 521.4455676078796 and batch: 1300, loss is 3.4440913915634157 and perplexity is 31.31481760900799
At time: 521.8225395679474 and batch: 1350, loss is 3.4540317964553835 and perplexity is 31.627651848694903
At time: 522.2213912010193 and batch: 1400, loss is 3.289508008956909 and perplexity is 26.82966045560342
At time: 522.6212134361267 and batch: 1450, loss is 3.4076774740219116 and perplexity is 30.19503400750166
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.298873510116186 and perplexity of 73.61681837176224
Finished 44 epochs...
Completing Train Step...
At time: 523.9352457523346 and batch: 50, loss is 3.6414512014389038 and perplexity is 38.14715578350533
At time: 524.3487544059753 and batch: 100, loss is 3.6985528230667115 and perplexity is 40.38881228858055
At time: 524.7060570716858 and batch: 150, loss is 3.507512664794922 and perplexity is 33.36517411368328
At time: 525.0899493694305 and batch: 200, loss is 3.654338583946228 and perplexity is 38.64195425203517
At time: 525.453164100647 and batch: 250, loss is 3.72764545917511 and perplexity is 41.58108844331309
At time: 525.8373057842255 and batch: 300, loss is 3.698160033226013 and perplexity is 40.37295108869874
At time: 526.2393138408661 and batch: 350, loss is 3.6669106769561766 and perplexity is 39.13083115874294
At time: 526.619353055954 and batch: 400, loss is 3.456509895324707 and perplexity is 31.706125489542124
At time: 526.990040063858 and batch: 450, loss is 3.5509398698806764 and perplexity is 34.84605285723928
At time: 527.3832759857178 and batch: 500, loss is 3.5507110500335695 and perplexity is 34.83808030092654
At time: 527.7737023830414 and batch: 550, loss is 3.60487606048584 and perplexity is 36.77712543570703
At time: 528.142648935318 and batch: 600, loss is 3.5387749767303465 and perplexity is 34.42472226420086
At time: 528.511442899704 and batch: 650, loss is 3.5868002367019653 and perplexity is 36.11832075352882
At time: 528.8690178394318 and batch: 700, loss is 3.654019832611084 and perplexity is 38.629639040374116
At time: 529.2340817451477 and batch: 750, loss is 3.587621555328369 and perplexity is 36.14799758851855
At time: 529.6442289352417 and batch: 800, loss is 3.5137528371810913 and perplexity is 33.57402952098888
At time: 530.042599439621 and batch: 850, loss is 3.4813824319839477 and perplexity is 32.504626465332166
At time: 530.4329373836517 and batch: 900, loss is 3.3565332221984865 and perplexity is 28.68955795377305
At time: 530.8092272281647 and batch: 950, loss is 3.5296041631698607 and perplexity is 34.110462764616834
At time: 531.1854932308197 and batch: 1000, loss is 3.5307719993591307 and perplexity is 34.15032146715366
At time: 531.5819296836853 and batch: 1050, loss is 3.4600451374053955 and perplexity is 31.818412682847303
At time: 531.9510128498077 and batch: 1100, loss is 3.6237980222702024 and perplexity is 37.47964637411954
At time: 532.3299479484558 and batch: 1150, loss is 3.5286421585083008 and perplexity is 34.07766411918367
At time: 532.7086279392242 and batch: 1200, loss is 3.4443145418167114 and perplexity is 31.32180629822423
At time: 533.0755732059479 and batch: 1250, loss is 3.3365071487426756 and perplexity is 28.12073342978649
At time: 533.4683933258057 and batch: 1300, loss is 3.44409939289093 and perplexity is 31.31506817012214
At time: 533.8618788719177 and batch: 1350, loss is 3.454044499397278 and perplexity is 31.6280536154704
At time: 534.2391338348389 and batch: 1400, loss is 3.289525713920593 and perplexity is 26.830135477972554
At time: 534.6273469924927 and batch: 1450, loss is 3.4077006673812864 and perplexity is 30.195734339898234
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2988709017761755 and perplexity of 73.61662635431985
Finished 45 epochs...
Completing Train Step...
At time: 535.9014716148376 and batch: 50, loss is 3.641368522644043 and perplexity is 38.14400195301704
At time: 536.2974891662598 and batch: 100, loss is 3.6984652423858644 and perplexity is 40.38527516379587
At time: 536.6907546520233 and batch: 150, loss is 3.5074274206161498 and perplexity is 33.36233004803811
At time: 537.0720241069794 and batch: 200, loss is 3.654256234169006 and perplexity is 38.638772226732435
At time: 537.4694213867188 and batch: 250, loss is 3.72755699634552 and perplexity is 41.577410225267165
At time: 537.8582448959351 and batch: 300, loss is 3.6980753183364867 and perplexity is 40.36953104347383
At time: 538.2406837940216 and batch: 350, loss is 3.6668299055099487 and perplexity is 39.127670632560005
At time: 538.6383810043335 and batch: 400, loss is 3.456430869102478 and perplexity is 31.703619973225223
At time: 539.023627281189 and batch: 450, loss is 3.55085741519928 and perplexity is 34.84317975550498
At time: 539.3980751037598 and batch: 500, loss is 3.550637307167053 and perplexity is 34.835511335743824
At time: 539.7885792255402 and batch: 550, loss is 3.6048053455352784 and perplexity is 36.77452483505181
At time: 540.1639833450317 and batch: 600, loss is 3.53870819568634 and perplexity is 34.422423422068825
At time: 540.5526947975159 and batch: 650, loss is 3.586736626625061 and perplexity is 36.116023337438214
At time: 540.9102194309235 and batch: 700, loss is 3.653961238861084 and perplexity is 38.62737565127247
At time: 541.2889187335968 and batch: 750, loss is 3.5875651693344115 and perplexity is 36.14595940520798
At time: 541.6732666492462 and batch: 800, loss is 3.5137029457092286 and perplexity is 33.57235450502456
At time: 542.0422909259796 and batch: 850, loss is 3.4813383054733276 and perplexity is 32.50319218123245
At time: 542.4350986480713 and batch: 900, loss is 3.3564928483963015 and perplexity is 28.688399670617756
At time: 542.8095586299896 and batch: 950, loss is 3.529570255279541 and perplexity is 34.10930617039561
At time: 543.1856558322906 and batch: 1000, loss is 3.530743889808655 and perplexity is 34.149361530460375
At time: 543.555225610733 and batch: 1050, loss is 3.460028748512268 and perplexity is 31.81789121855548
At time: 543.9473078250885 and batch: 1100, loss is 3.623786630630493 and perplexity is 37.47921942192346
At time: 544.3304326534271 and batch: 1150, loss is 3.5286334705352784 and perplexity is 34.077368054643244
At time: 544.7054266929626 and batch: 1200, loss is 3.444309277534485 and perplexity is 31.321641411830033
At time: 545.1010911464691 and batch: 1250, loss is 3.336508688926697 and perplexity is 28.120776740924136
At time: 545.4753415584564 and batch: 1300, loss is 3.4441060876846312 and perplexity is 31.315277818745052
At time: 545.8686830997467 and batch: 1350, loss is 3.4540562057495117 and perplexity is 31.628423866773634
At time: 546.2608873844147 and batch: 1400, loss is 3.2895424938201905 and perplexity is 26.830585688729293
At time: 546.6506216526031 and batch: 1450, loss is 3.40772243976593 and perplexity is 30.196391780197875
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.298867250100161 and perplexity of 73.61635753074192
Finished 46 epochs...
Completing Train Step...
At time: 547.9780490398407 and batch: 50, loss is 3.641286883354187 and perplexity is 38.14088803089626
At time: 548.3735003471375 and batch: 100, loss is 3.698379192352295 and perplexity is 40.381800159026604
At time: 548.745885848999 and batch: 150, loss is 3.507343349456787 and perplexity is 33.35952535617044
At time: 549.1271834373474 and batch: 200, loss is 3.654175000190735 and perplexity is 38.63563357303333
At time: 549.5116200447083 and batch: 250, loss is 3.7274700689315794 and perplexity is 41.57379616560063
At time: 549.8755719661713 and batch: 300, loss is 3.6979919147491453 and perplexity is 40.366164220170035
At time: 550.2794728279114 and batch: 350, loss is 3.6667499637603758 and perplexity is 39.12454282313587
At time: 550.6734530925751 and batch: 400, loss is 3.456352710723877 and perplexity is 31.701142166524267
At time: 551.0351357460022 and batch: 450, loss is 3.5507758378982546 and perplexity is 34.840337458876405
At time: 551.416268825531 and batch: 500, loss is 3.5505643701553344 and perplexity is 34.83297063030216
At time: 551.7995669841766 and batch: 550, loss is 3.6047353887557985 and perplexity is 36.7719522977117
At time: 552.2040753364563 and batch: 600, loss is 3.5386419534683227 and perplexity is 34.42014327991348
At time: 552.5838279724121 and batch: 650, loss is 3.5866734075546263 and perplexity is 36.11374018818507
At time: 552.9718980789185 and batch: 700, loss is 3.6539029979705813 and perplexity is 38.62512602402754
At time: 553.3461902141571 and batch: 750, loss is 3.5875092124938965 and perplexity is 36.14393684811076
At time: 553.7154765129089 and batch: 800, loss is 3.5136529397964478 and perplexity is 33.57067573076801
At time: 554.1057069301605 and batch: 850, loss is 3.481294116973877 and perplexity is 32.50175594567539
At time: 554.5007379055023 and batch: 900, loss is 3.356452383995056 and perplexity is 28.68723883518881
At time: 554.8704466819763 and batch: 950, loss is 3.5295360469818116 and perplexity is 34.10813936905204
At time: 555.2754037380219 and batch: 1000, loss is 3.5307156324386595 and perplexity is 34.14839657295015
At time: 555.6558353900909 and batch: 1050, loss is 3.4600115060806274 and perplexity is 31.81734260547092
At time: 556.0307288169861 and batch: 1100, loss is 3.623774709701538 and perplexity is 37.478772637474485
At time: 556.4289283752441 and batch: 1150, loss is 3.528624277114868 and perplexity is 34.07705476851233
At time: 556.8062658309937 and batch: 1200, loss is 3.4443033361434936 and perplexity is 31.32145531826475
At time: 557.1770560741425 and batch: 1250, loss is 3.336509099006653 and perplexity is 28.120788272693396
At time: 557.5487785339355 and batch: 1300, loss is 3.4441119241714477 and perplexity is 31.31546059048457
At time: 557.940484046936 and batch: 1350, loss is 3.4540667295455934 and perplexity is 31.628756719608226
At time: 558.3125019073486 and batch: 1400, loss is 3.2895579719543457 and perplexity is 26.831000979348
At time: 558.6901051998138 and batch: 1450, loss is 3.40774290561676 and perplexity is 30.19700978137159
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.298865685096154 and perplexity of 73.6162423209376
Finished 47 epochs...
Completing Train Step...
At time: 559.983325958252 and batch: 50, loss is 3.641205863952637 and perplexity is 38.13779800415114
At time: 560.3637096881866 and batch: 100, loss is 3.698294520378113 and perplexity is 40.37838109703751
At time: 560.7399141788483 and batch: 150, loss is 3.507260322570801 and perplexity is 33.35675573364029
At time: 561.1198372840881 and batch: 200, loss is 3.654094724655151 and perplexity is 38.632532201339444
At time: 561.5223100185394 and batch: 250, loss is 3.727384424209595 and perplexity is 41.57023574185411
At time: 561.9115443229675 and batch: 300, loss is 3.6979094696044923 and perplexity is 40.362836363106524
At time: 562.2934956550598 and batch: 350, loss is 3.6666710424423217 and perplexity is 39.12145518448987
At time: 562.6660721302032 and batch: 400, loss is 3.456275234222412 and perplexity is 31.69868616807907
At time: 563.0593020915985 and batch: 450, loss is 3.5506952810287475 and perplexity is 34.83753094340172
At time: 563.4578287601471 and batch: 500, loss is 3.550492329597473 and perplexity is 34.830461334052615
At time: 563.8143794536591 and batch: 550, loss is 3.6046660280227663 and perplexity is 36.76940185659656
At time: 564.1948764324188 and batch: 600, loss is 3.538576436042786 and perplexity is 34.41788823461236
At time: 564.5748851299286 and batch: 650, loss is 3.5866106271743776 and perplexity is 36.111473025011286
At time: 564.9438188076019 and batch: 700, loss is 3.6538451051712038 and perplexity is 38.62288997208198
At time: 565.3270831108093 and batch: 750, loss is 3.5874534606933595 and perplexity is 36.14192181472438
At time: 565.7257807254791 and batch: 800, loss is 3.513603172302246 and perplexity is 33.569005043931526
At time: 566.1132800579071 and batch: 850, loss is 3.481250114440918 and perplexity is 32.50032581755302
At time: 566.5215909481049 and batch: 900, loss is 3.356411690711975 and perplexity is 28.686071481009975
At time: 566.927885055542 and batch: 950, loss is 3.529501600265503 and perplexity is 34.1069644758871
At time: 567.3064112663269 and batch: 1000, loss is 3.5306871700286866 and perplexity is 34.147424641118796
At time: 567.6952602863312 and batch: 1050, loss is 3.4599935388565064 and perplexity is 31.816770941281018
At time: 568.0885767936707 and batch: 1100, loss is 3.6237618064880373 and perplexity is 37.478289043989356
At time: 568.4902756214142 and batch: 1150, loss is 3.5286146640777587 and perplexity is 34.07672718609479
At time: 568.8809394836426 and batch: 1200, loss is 3.4442964935302736 and perplexity is 31.321240998393773
At time: 569.2684042453766 and batch: 1250, loss is 3.3365085983276366 and perplexity is 28.120774193208305
At time: 569.664537191391 and batch: 1300, loss is 3.444116668701172 and perplexity is 31.315609167970635
At time: 570.0482745170593 and batch: 1350, loss is 3.4540764188766477 and perplexity is 31.62906318258763
At time: 570.4105799198151 and batch: 1400, loss is 3.2895724296569826 and perplexity is 26.831388896785803
At time: 570.7784602642059 and batch: 1450, loss is 3.4077621841430665 and perplexity is 30.197591940830605
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.298865163428152 and perplexity of 73.61620391770956
Finished 48 epochs...
Completing Train Step...
At time: 572.0394620895386 and batch: 50, loss is 3.6411256790161133 and perplexity is 38.13474004984161
At time: 572.4372115135193 and batch: 100, loss is 3.698210816383362 and perplexity is 40.37500140668688
At time: 572.8152713775635 and batch: 150, loss is 3.5071780490875244 and perplexity is 33.35401147004689
At time: 573.2126185894012 and batch: 200, loss is 3.6540153932571413 and perplexity is 38.62946755011439
At time: 573.5937969684601 and batch: 250, loss is 3.7273000860214234 and perplexity is 41.566729931328716
At time: 573.9743626117706 and batch: 300, loss is 3.6978279829025267 and perplexity is 40.359547462691964
At time: 574.3620581626892 and batch: 350, loss is 3.66659264087677 and perplexity is 39.118388121389586
At time: 574.7617881298065 and batch: 400, loss is 3.4561985826492307 and perplexity is 31.696256507036374
At time: 575.1211085319519 and batch: 450, loss is 3.5506154441833497 and perplexity is 34.83474973585264
At time: 575.50976729393 and batch: 500, loss is 3.5504208612442016 and perplexity is 34.82797214728749
At time: 575.9009592533112 and batch: 550, loss is 3.6045971584320067 and perplexity is 36.766869650135234
At time: 576.2926058769226 and batch: 600, loss is 3.5385114479064943 and perplexity is 34.415651552880576
At time: 576.6839170455933 and batch: 650, loss is 3.5865483331680297 and perplexity is 36.109223566746046
At time: 577.0728397369385 and batch: 700, loss is 3.6537874841690066 and perplexity is 38.620664546570275
At time: 577.4452276229858 and batch: 750, loss is 3.587397885322571 and perplexity is 36.139913269831844
At time: 577.8099842071533 and batch: 800, loss is 3.513553490638733 and perplexity is 33.56733732134643
At time: 578.1797993183136 and batch: 850, loss is 3.4812061166763306 and perplexity is 32.49889590732535
At time: 578.5884807109833 and batch: 900, loss is 3.356370978355408 and perplexity is 28.684903627212528
At time: 578.9526541233063 and batch: 950, loss is 3.5294671154022215 and perplexity is 34.10578832216007
At time: 579.3409411907196 and batch: 1000, loss is 3.530658540725708 and perplexity is 34.146447038146924
At time: 579.7364559173584 and batch: 1050, loss is 3.4599749422073365 and perplexity is 31.81617926145575
At time: 580.1069123744965 and batch: 1100, loss is 3.6237483978271485 and perplexity is 37.47778651369001
At time: 580.4749186038971 and batch: 1150, loss is 3.5286041641235353 and perplexity is 34.07636938389771
At time: 580.8516654968262 and batch: 1200, loss is 3.444289140701294 and perplexity is 31.321010699511962
At time: 581.2150304317474 and batch: 1250, loss is 3.336507210731506 and perplexity is 28.12073517295792
At time: 581.6066086292267 and batch: 1300, loss is 3.4441205739974974 and perplexity is 31.31573146494285
At time: 581.9880154132843 and batch: 1350, loss is 3.454085102081299 and perplexity is 31.629337825408562
At time: 582.3492512702942 and batch: 1400, loss is 3.2895860481262207 and perplexity is 26.83175430171823
At time: 582.743682384491 and batch: 1450, loss is 3.4077802753448485 and perplexity is 30.198138256501476
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.298863337590144 and perplexity of 73.61606950656916
Finished 49 epochs...
Completing Train Step...
At time: 584.0503158569336 and batch: 50, loss is 3.6410462188720705 and perplexity is 38.13170997829077
At time: 584.4351434707642 and batch: 100, loss is 3.6981284189224244 and perplexity is 40.37167474614169
At time: 584.8426444530487 and batch: 150, loss is 3.5070967197418215 and perplexity is 33.35129892042391
At time: 585.2309045791626 and batch: 200, loss is 3.653936882019043 and perplexity is 38.626434821843134
At time: 585.611142873764 and batch: 250, loss is 3.7272168827056884 and perplexity is 41.56327158544909
At time: 585.9816279411316 and batch: 300, loss is 3.6977475690841675 and perplexity is 40.35630212785987
At time: 586.3722801208496 and batch: 350, loss is 3.6665148878097535 and perplexity is 39.11534666497922
At time: 586.7635450363159 and batch: 400, loss is 3.4561226320266725 and perplexity is 31.693849248039463
At time: 587.141672372818 and batch: 450, loss is 3.5505363607406615 and perplexity is 34.831994992847065
At time: 587.5271775722504 and batch: 500, loss is 3.5503502750396727 and perplexity is 34.82551385968379
At time: 587.9212772846222 and batch: 550, loss is 3.604528851509094 and perplexity is 36.76435830417644
At time: 588.3083560466766 and batch: 600, loss is 3.5384470319747923 and perplexity is 34.4134347080215
At time: 588.7299919128418 and batch: 650, loss is 3.5864864683151243 and perplexity is 36.10698974403983
At time: 589.1096444129944 and batch: 700, loss is 3.653730244636536 and perplexity is 38.61845398105439
At time: 589.5176184177399 and batch: 750, loss is 3.5873424911499026 and perplexity is 36.13791138468285
At time: 589.899564743042 and batch: 800, loss is 3.513503980636597 and perplexity is 33.565675443544066
At time: 590.2902891635895 and batch: 850, loss is 3.4811622428894045 and perplexity is 32.49747008896923
At time: 590.6592991352081 and batch: 900, loss is 3.356330213546753 and perplexity is 28.683734316438407
At time: 591.058287858963 and batch: 950, loss is 3.529432468414307 and perplexity is 34.10460667979454
At time: 591.4386491775513 and batch: 1000, loss is 3.5306298446655275 and perplexity is 34.14546718370681
At time: 591.8158059120178 and batch: 1050, loss is 3.459955720901489 and perplexity is 31.815567718820613
At time: 592.2030222415924 and batch: 1100, loss is 3.6237344408035277 and perplexity is 37.47726343898868
At time: 592.5994400978088 and batch: 1150, loss is 3.528593373298645 and perplexity is 34.07600167374675
At time: 592.974632024765 and batch: 1200, loss is 3.4442810678482054 and perplexity is 31.3207578506146
At time: 593.3620059490204 and batch: 1250, loss is 3.33650502204895 and perplexity is 28.12067362566274
At time: 593.7496259212494 and batch: 1300, loss is 3.444123649597168 and perplexity is 31.315827779744335
At time: 594.1616880893707 and batch: 1350, loss is 3.4540930509567263 and perplexity is 31.629589244074026
At time: 594.5390422344208 and batch: 1400, loss is 3.2895987176895143 and perplexity is 26.83209425048113
At time: 594.9415600299835 and batch: 1450, loss is 3.407797441482544 and perplexity is 30.198656646350294
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.29886229425414 and perplexity of 73.61599270031341
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f830fadb9e8>
Saving Model Parameters and Results...
/home-nfs/siddsach/Interpreting-Attention/interpreting_language/trained_models/langmodel/



RESULTS:
[{'params': {'batch_size': 20, 'seq_len': 35, 'anneal': 5.135761720632871, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'dropout': 0.25248092910318143, 'lr': 24.94667119673739, 'num_layers': 1, 'wordvec_dim': 200, 'data': 'ptb'}, 'best_accuracy': -139.73909556442666}, {'params': {'batch_size': 20, 'seq_len': 35, 'anneal': 2.7017793990391183, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'dropout': 0.40085188316593423, 'lr': 20.161345644570805, 'num_layers': 1, 'wordvec_dim': 200, 'data': 'ptb'}, 'best_accuracy': -155.19071516362752}, {'params': {'batch_size': 20, 'seq_len': 35, 'anneal': 6.072075262495876, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'dropout': 0.39702696090568435, 'lr': 2.9194512100577086, 'num_layers': 1, 'wordvec_dim': 200, 'data': 'ptb'}, 'best_accuracy': -72.81770834902102}, {'params': {'batch_size': 20, 'seq_len': 35, 'anneal': 3.7530622630505643, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'dropout': 0.35219484179540284, 'lr': 25.109332104928228, 'num_layers': 1, 'wordvec_dim': 200, 'data': 'ptb'}, 'best_accuracy': -150.99234333016628}, {'params': {'batch_size': 20, 'seq_len': 35, 'anneal': 4.412380902650271, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'dropout': 0.0606127314504219, 'lr': 11.306292291322702, 'num_layers': 1, 'wordvec_dim': 200, 'data': 'ptb'}, 'best_accuracy': -92.76868271377285}, {'params': {'batch_size': 20, 'seq_len': 35, 'anneal': 8.0, 'tune_wordvecs': True, 'wordvec_source': 'glove', 'dropout': 0.0, 'lr': 6.250041585959168, 'num_layers': 1, 'wordvec_dim': 200, 'data': 'ptb'}, 'best_accuracy': -73.61599270031341}]
