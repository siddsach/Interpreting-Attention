Building Bayesian Optimizer for 
 data:ptb 
 choices:[{'type': 'continuous', 'domain': [0, 30], 'name': 'lr'}, {'type': 'continuous', 'domain': [0, 1], 'name': 'dropout'}, {'type': 'continuous', 'domain': [2, 8], 'name': 'anneal'}]
SETTINGS FOR THIS RUN
{'lr': 25.145396342418447, 'batch_size': 20, 'dropout': 0.500916955390465, 'wordvec_source': 'glove', 'anneal': 6.743474951113646, 'num_layers': 1, 'seq_len': 35, 'wordvec_dim': 200, 'tune_wordvecs': True, 'data': 'ptb'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.9356908798217773 and batch: 50, loss is 6.794302263259888 and perplexity is 892.7461404584461
At time: 1.3107333183288574 and batch: 100, loss is 6.067127876281738 and perplexity is 431.4397520311248
At time: 1.6554741859436035 and batch: 150, loss is 6.028197984695435 and perplexity is 414.9665790986689
At time: 2.00683856010437 and batch: 200, loss is 6.013785018920898 and perplexity is 409.0285749152927
At time: 2.358006238937378 and batch: 250, loss is 6.036485347747803 and perplexity is 418.4198472735063
At time: 2.7118935585021973 and batch: 300, loss is 6.11807110786438 and perplexity is 453.98815521417356
At time: 3.06423020362854 and batch: 350, loss is 6.223430242538452 and perplexity is 504.4305869603771
At time: 3.421851396560669 and batch: 400, loss is 6.133621196746827 and perplexity is 461.10288535803187
At time: 3.772426128387451 and batch: 450, loss is 6.248859090805054 and perplexity is 517.4221560872569
At time: 4.123228311538696 and batch: 500, loss is 6.205284862518311 and perplexity is 495.3600453536792
At time: 4.472646236419678 and batch: 550, loss is 6.315736579895019 and perplexity is 553.209393473514
At time: 4.8292317390441895 and batch: 600, loss is 6.189254970550537 and perplexity is 487.4827818589828
At time: 5.17385721206665 and batch: 650, loss is 6.437956037521363 and perplexity is 625.1277554209797
At time: 5.527509450912476 and batch: 700, loss is 6.354270229339599 and perplexity is 574.9426112758669
At time: 5.880059719085693 and batch: 750, loss is 6.308069467544556 and perplexity is 548.9840935236667
At time: 6.23457932472229 and batch: 800, loss is 6.358307685852051 and perplexity is 577.2686094646315
At time: 6.584007263183594 and batch: 850, loss is 6.302659940719605 and perplexity is 546.0223673343215
At time: 6.93094277381897 and batch: 900, loss is 6.339938163757324 and perplexity is 566.7612639109507
At time: 7.276672124862671 and batch: 950, loss is 6.390591630935669 and perplexity is 596.2092111773449
At time: 7.624776363372803 and batch: 1000, loss is 6.615516529083252 and perplexity is 746.5902663426781
At time: 7.971624374389648 and batch: 1050, loss is 6.361895723342895 and perplexity is 579.3435912077105
At time: 8.317854642868042 and batch: 1100, loss is 6.439954509735108 and perplexity is 626.3783050483572
At time: 8.665974378585815 and batch: 1150, loss is 6.61634485244751 and perplexity is 747.2089406996556
At time: 9.013293743133545 and batch: 1200, loss is 6.371957139968872 and perplexity is 585.2020311290876
At time: 9.36035680770874 and batch: 1250, loss is 6.359132537841797 and perplexity is 577.7449670610132
At time: 9.705339670181274 and batch: 1300, loss is 6.485440683364868 and perplexity is 655.527780784283
At time: 10.051172733306885 and batch: 1350, loss is 6.576372900009155 and perplexity is 717.9305949846606
At time: 10.398214101791382 and batch: 1400, loss is 6.570708646774292 and perplexity is 713.8755495335229
At time: 10.744010210037231 and batch: 1450, loss is 6.7710726451873775 and perplexity is 872.2470039314965
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 7.4016661032652245 and perplexity of 1638.712420922842
Finished 1 epochs...
Completing Train Step...
At time: 12.013826847076416 and batch: 50, loss is 6.774955978393555 and perplexity is 875.6408150706319
At time: 12.352737426757812 and batch: 100, loss is 6.772734756469727 and perplexity is 873.6979810263854
At time: 12.691686630249023 and batch: 150, loss is 6.806058683395386 and perplexity is 903.3035763881996
At time: 13.04580044746399 and batch: 200, loss is 6.645348796844482 and perplexity is 769.1982947853766
At time: 13.38526439666748 and batch: 250, loss is 6.627544021606445 and perplexity is 755.62409342992
At time: 13.724756717681885 and batch: 300, loss is 6.677990942001343 and perplexity is 794.7208667557234
At time: 14.065062284469604 and batch: 350, loss is 6.673632974624634 and perplexity is 791.2650348156327
At time: 14.403144598007202 and batch: 400, loss is 6.479818792343139 and perplexity is 651.8528148471397
At time: 14.743117570877075 and batch: 450, loss is 6.729240064620972 and perplexity is 836.511329795085
At time: 15.079202890396118 and batch: 500, loss is 6.87798963546753 and perplexity is 970.6729904049691
At time: 15.424293041229248 and batch: 550, loss is 6.708790349960327 and perplexity is 819.5786362533785
At time: 15.76220154762268 and batch: 600, loss is 6.664228868484497 and perplexity is 783.8587736586026
At time: 16.100759983062744 and batch: 650, loss is 6.710489053726196 and perplexity is 820.9720407248526
At time: 16.441110849380493 and batch: 700, loss is 6.63676498413086 and perplexity is 762.6238977474969
At time: 16.781357288360596 and batch: 750, loss is 6.646255722045899 and perplexity is 769.8962165373792
At time: 17.12016487121582 and batch: 800, loss is 6.640392694473267 and perplexity is 765.3955005952912
At time: 17.458146810531616 and batch: 850, loss is 6.3529211616516115 and perplexity is 574.1674977344217
At time: 17.79776930809021 and batch: 900, loss is 6.402627801895141 and perplexity is 603.4286471976968
At time: 18.137883186340332 and batch: 950, loss is 6.521740894317627 and perplexity is 679.7607474796938
At time: 18.477200984954834 and batch: 1000, loss is 6.611844511032104 and perplexity is 743.8538006583609
At time: 18.817607402801514 and batch: 1050, loss is 6.477661285400391 and perplexity is 650.4479539170117
At time: 19.158538579940796 and batch: 1100, loss is 6.697000799179077 and perplexity is 809.9729071783092
At time: 19.497830629348755 and batch: 1150, loss is 6.5437542343139645 and perplexity is 694.8904688125753
At time: 19.83735942840576 and batch: 1200, loss is 6.871871576309204 and perplexity is 964.7524850945024
At time: 20.177082061767578 and batch: 1250, loss is 6.604694051742554 and perplexity is 738.5538753710456
At time: 20.51641345024109 and batch: 1300, loss is 6.703084182739258 and perplexity is 814.915301042671
At time: 20.85899019241333 and batch: 1350, loss is 6.479715976715088 and perplexity is 651.7857976358515
At time: 21.200845956802368 and batch: 1400, loss is 6.37255443572998 and perplexity is 585.5516742314493
At time: 21.539640188217163 and batch: 1450, loss is 6.438963165283203 and perplexity is 625.7576560801392
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 6.510007157284989 and perplexity of 671.8312260614359
Finished 2 epochs...
Completing Train Step...
At time: 22.821534872055054 and batch: 50, loss is 6.674003200531006 and perplexity is 791.5580358652708
At time: 23.161169052124023 and batch: 100, loss is 6.7968715476989745 and perplexity is 895.042808358328
At time: 23.499993085861206 and batch: 150, loss is 6.717153091430664 and perplexity is 826.4612993572638
At time: 23.842471837997437 and batch: 200, loss is 6.653275184631347 and perplexity is 775.3194861748842
At time: 24.182090759277344 and batch: 250, loss is 6.598051347732544 and perplexity is 733.6641390970527
At time: 24.519782066345215 and batch: 300, loss is 6.664538497924805 and perplexity is 784.1015169902722
At time: 24.858118772506714 and batch: 350, loss is 6.709771671295166 and perplexity is 820.3833010074837
At time: 25.196778297424316 and batch: 400, loss is 6.66097583770752 and perplexity is 781.3129999282276
At time: 25.536474227905273 and batch: 450, loss is 6.671625814437866 and perplexity is 789.6784319562763
At time: 25.877497673034668 and batch: 500, loss is 6.716212739944458 and perplexity is 825.6845005353263
At time: 26.2158145904541 and batch: 550, loss is 6.826130285263061 and perplexity is 921.6175062545019
At time: 26.556108474731445 and batch: 600, loss is 6.683797225952149 and perplexity is 799.348663920563
At time: 26.898935794830322 and batch: 650, loss is 6.765906858444214 and perplexity is 867.7527800171397
At time: 27.238414525985718 and batch: 700, loss is 6.594775590896607 and perplexity is 731.2647658054103
At time: 27.578453063964844 and batch: 750, loss is 6.628730726242066 and perplexity is 756.5213283154833
At time: 27.920313358306885 and batch: 800, loss is 6.627030372619629 and perplexity is 755.2360675429991
At time: 28.260042190551758 and batch: 850, loss is 6.530396928787232 and perplexity is 685.6703197728996
At time: 28.599571704864502 and batch: 900, loss is 6.354765214920044 and perplexity is 575.2272700232072
At time: 28.93862748146057 and batch: 950, loss is 6.519727163314819 and perplexity is 678.3932695164933
At time: 29.278467178344727 and batch: 1000, loss is 6.645976076126098 and perplexity is 769.6809483025995
At time: 29.61909794807434 and batch: 1050, loss is 6.524535217285156 and perplexity is 681.6628748902673
At time: 29.9862539768219 and batch: 1100, loss is 6.60461277961731 and perplexity is 738.4938539670536
At time: 30.32403039932251 and batch: 1150, loss is 6.546728563308716 and perplexity is 696.9603784522926
At time: 30.661818742752075 and batch: 1200, loss is 6.526885070800781 and perplexity is 683.2665662752787
At time: 31.002042055130005 and batch: 1250, loss is 6.80847936630249 and perplexity is 905.4928365988392
At time: 31.34069061279297 and batch: 1300, loss is 6.588277521133423 and perplexity is 726.5283617500129
At time: 31.67857313156128 and batch: 1350, loss is 6.560786113739014 and perplexity is 706.8271227642181
At time: 32.01920509338379 and batch: 1400, loss is 6.486831684112548 and perplexity is 656.4402548964375
At time: 32.35804891586304 and batch: 1450, loss is 6.491922750473022 and perplexity is 659.7907573742384
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 6.732617500500801 and perplexity of 839.3413696230416
Annealing...
Finished 3 epochs...
Completing Train Step...
At time: 33.593339920043945 and batch: 50, loss is 6.114192876815796 and perplexity is 452.2308939899851
At time: 33.95201230049133 and batch: 100, loss is 5.9817068481445315 and perplexity is 396.1159011661114
At time: 34.29542422294617 and batch: 150, loss is 5.9493044662475585 and perplexity is 383.4865184633051
At time: 34.63757395744324 and batch: 200, loss is 5.86882984161377 and perplexity is 353.83469528948467
At time: 34.97946739196777 and batch: 250, loss is 5.865229473114014 and perplexity is 352.563050566902
At time: 35.321985960006714 and batch: 300, loss is 5.942559185028077 and perplexity is 380.9084985617337
At time: 35.66587686538696 and batch: 350, loss is 5.958881025314331 and perplexity is 387.1766408945267
At time: 36.00709128379822 and batch: 400, loss is 5.865624370574952 and perplexity is 352.7023043140572
At time: 36.34798574447632 and batch: 450, loss is 5.8964040660858155 and perplexity is 363.72717453072516
At time: 36.69111895561218 and batch: 500, loss is 5.897606115341187 and perplexity is 364.16465539412405
At time: 37.04129362106323 and batch: 550, loss is 5.946638040542602 and perplexity is 382.4653422033169
At time: 37.38269019126892 and batch: 600, loss is 5.787473545074463 and perplexity is 326.1878834893547
At time: 37.72471475601196 and batch: 650, loss is 5.980648307800293 and perplexity is 395.6968183508987
At time: 38.06602215766907 and batch: 700, loss is 5.9360568141937256 and perplexity is 378.43972538794515
At time: 38.407447814941406 and batch: 750, loss is 5.88990966796875 and perplexity is 361.3726393733109
At time: 38.748472452163696 and batch: 800, loss is 5.867530088424683 and perplexity is 353.37509626322503
At time: 39.10391116142273 and batch: 850, loss is 5.81872896194458 and perplexity is 336.5440214065422
At time: 39.44318771362305 and batch: 900, loss is 5.801104164123535 and perplexity is 330.66446625489385
At time: 39.78485679626465 and batch: 950, loss is 5.8395031070709225 and perplexity is 343.60856157440224
At time: 40.127586364746094 and batch: 1000, loss is 5.907529850006103 and perplexity is 367.7965198325025
At time: 40.46876406669617 and batch: 1050, loss is 5.751618604660035 and perplexity is 314.6996225457966
At time: 40.8093056678772 and batch: 1100, loss is 5.843262510299683 and perplexity is 344.9027558851007
At time: 41.15129494667053 and batch: 1150, loss is 5.860726194381714 and perplexity is 350.9789304238627
At time: 41.49181795120239 and batch: 1200, loss is 5.838856000900268 and perplexity is 343.3862822808256
At time: 41.83284115791321 and batch: 1250, loss is 5.846028785705567 and perplexity is 345.8581727599693
At time: 42.174988746643066 and batch: 1300, loss is 5.916272287368774 and perplexity is 371.02605430127466
At time: 42.51575183868408 and batch: 1350, loss is 5.8463122749328615 and perplexity is 345.9562337250755
At time: 42.85721969604492 and batch: 1400, loss is 5.758403491973877 and perplexity is 316.84208398323517
At time: 43.19915270805359 and batch: 1450, loss is 5.790849990844727 and perplexity is 327.2911006171845
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.874885754707532 and perplexity of 355.98398885262105
Finished 4 epochs...
Completing Train Step...
At time: 44.434868574142456 and batch: 50, loss is 5.889477272033691 and perplexity is 361.21641709037846
At time: 44.792214155197144 and batch: 100, loss is 5.885583419799804 and perplexity is 359.8126285839766
At time: 45.132483959198 and batch: 150, loss is 5.857959432601929 and perplexity is 350.0091974623097
At time: 45.47427845001221 and batch: 200, loss is 5.7998551177978515 and perplexity is 330.2517088485075
At time: 45.81712579727173 and batch: 250, loss is 5.806391410827636 and perplexity is 332.4174008795698
At time: 46.15961503982544 and batch: 300, loss is 5.88524941444397 and perplexity is 359.6924693069708
At time: 46.50320029258728 and batch: 350, loss is 5.90107292175293 and perplexity is 365.4293346888638
At time: 46.845372915267944 and batch: 400, loss is 5.797750616073609 and perplexity is 329.5574243754816
At time: 47.186607122421265 and batch: 450, loss is 5.82868821144104 and perplexity is 339.912493165366
At time: 47.52682280540466 and batch: 500, loss is 5.830109882354736 and perplexity is 340.39608053970306
At time: 47.894519567489624 and batch: 550, loss is 5.884846754074097 and perplexity is 359.5476645597622
At time: 48.236412048339844 and batch: 600, loss is 5.7250230884552 and perplexity is 306.44034039575735
At time: 48.578365087509155 and batch: 650, loss is 5.911886129379273 and perplexity is 369.4022391670472
At time: 48.91887903213501 and batch: 700, loss is 5.8709037971496585 and perplexity is 354.5692942140126
At time: 49.26137852668762 and batch: 750, loss is 5.82606053352356 and perplexity is 339.0204850814251
At time: 49.6055269241333 and batch: 800, loss is 5.796016025543213 and perplexity is 328.9862726882992
At time: 49.94636392593384 and batch: 850, loss is 5.741220378875733 and perplexity is 311.444259149744
At time: 50.28577375411987 and batch: 900, loss is 5.72781195640564 and perplexity is 307.29615486188214
At time: 50.6278190612793 and batch: 950, loss is 5.76972357749939 and perplexity is 320.4491410506775
At time: 50.969470500946045 and batch: 1000, loss is 5.842874002456665 and perplexity is 344.7687844855159
At time: 51.311569929122925 and batch: 1050, loss is 5.686708326339722 and perplexity is 294.92123666652554
At time: 51.65097641944885 and batch: 1100, loss is 5.7871365737915035 and perplexity is 326.07798605694865
At time: 51.99144124984741 and batch: 1150, loss is 5.79255781173706 and perplexity is 327.8505327656764
At time: 52.331857204437256 and batch: 1200, loss is 5.768040933609009 and perplexity is 319.9103926492766
At time: 52.67321419715881 and batch: 1250, loss is 5.778065404891968 and perplexity is 323.13345294077163
At time: 53.01514911651611 and batch: 1300, loss is 5.8541614818573 and perplexity is 348.68240091899736
At time: 53.35642337799072 and batch: 1350, loss is 5.782645854949951 and perplexity is 324.61694451987387
At time: 53.69764757156372 and batch: 1400, loss is 5.688487968444824 and perplexity is 295.44655822051766
At time: 54.03843927383423 and batch: 1450, loss is 5.739082584381103 and perplexity is 310.77916649615497
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.826166658319979 and perplexity of 339.0564654705582
Finished 5 epochs...
Completing Train Step...
At time: 55.285502672195435 and batch: 50, loss is 5.837018346786499 and perplexity is 342.7558365146246
At time: 55.629894733428955 and batch: 100, loss is 5.841092119216919 and perplexity is 344.1549937809423
At time: 55.971187114715576 and batch: 150, loss is 5.811279878616333 and perplexity is 334.0463910250864
At time: 56.31131148338318 and batch: 200, loss is 5.754025917053223 and perplexity is 315.45811544566334
At time: 56.667800426483154 and batch: 250, loss is 5.765866498947144 and perplexity is 319.2155241496725
At time: 57.009392499923706 and batch: 300, loss is 5.841531133651733 and perplexity is 344.30611596100755
At time: 57.35039472579956 and batch: 350, loss is 5.855898418426514 and perplexity is 349.288566415306
At time: 57.69034481048584 and batch: 400, loss is 5.757127084732056 and perplexity is 316.4379224449545
At time: 58.030707120895386 and batch: 450, loss is 5.784801664352417 and perplexity is 325.3175116543528
At time: 58.37348008155823 and batch: 500, loss is 5.7936790084838865 and perplexity is 328.2183238610197
At time: 58.715699195861816 and batch: 550, loss is 5.849188318252564 and perplexity is 346.95265102281377
At time: 59.056894063949585 and batch: 600, loss is 5.682167339324951 and perplexity is 293.5850392840187
At time: 59.39862656593323 and batch: 650, loss is 5.877433347702026 and perplexity is 356.8920473593937
At time: 59.740559816360474 and batch: 700, loss is 5.837461671829224 and perplexity is 342.90782244758753
At time: 60.0849187374115 and batch: 750, loss is 5.786386041641236 and perplexity is 325.83334586156803
At time: 60.42554306983948 and batch: 800, loss is 5.751372079849244 and perplexity is 314.62205084296005
At time: 60.76592302322388 and batch: 850, loss is 5.708757486343384 and perplexity is 301.4962222817744
At time: 61.107608795166016 and batch: 900, loss is 5.690993413925171 and perplexity is 296.18771153640733
At time: 61.449527978897095 and batch: 950, loss is 5.734116916656494 and perplexity is 309.2397656593218
At time: 61.79152727127075 and batch: 1000, loss is 5.805317182540893 and perplexity is 332.0605004351367
At time: 62.13384652137756 and batch: 1050, loss is 5.654664382934571 and perplexity is 285.6206074886184
At time: 62.47622060775757 and batch: 1100, loss is 5.751852235794067 and perplexity is 314.773154764865
At time: 62.81581664085388 and batch: 1150, loss is 5.764372653961182 and perplexity is 318.7390216385363
At time: 63.15484833717346 and batch: 1200, loss is 5.742748441696167 and perplexity is 311.92052933549695
At time: 63.4984827041626 and batch: 1250, loss is 5.753153715133667 and perplexity is 315.1830922271567
At time: 63.84078121185303 and batch: 1300, loss is 5.827856130599976 and perplexity is 339.62977613019063
At time: 64.18304920196533 and batch: 1350, loss is 5.7583730506896975 and perplexity is 316.8324390501194
At time: 64.52394080162048 and batch: 1400, loss is 5.668603086471558 and perplexity is 289.6296640771749
At time: 64.86697030067444 and batch: 1450, loss is 5.715893831253052 and perplexity is 303.6554988201484
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.8094096387553416 and perplexity of 333.42222799839
Finished 6 epochs...
Completing Train Step...
At time: 66.11049222946167 and batch: 50, loss is 5.81566987991333 and perplexity is 335.516078720056
At time: 66.45340609550476 and batch: 100, loss is 5.816492872238159 and perplexity is 335.7923195341423
At time: 66.79627776145935 and batch: 150, loss is 5.788187494277954 and perplexity is 326.4208482215572
At time: 67.13830733299255 and batch: 200, loss is 5.730390138626099 and perplexity is 308.08944252542057
At time: 67.48152732849121 and batch: 250, loss is 5.744644365310669 and perplexity is 312.51246779064815
At time: 67.8252022266388 and batch: 300, loss is 5.824141178131104 and perplexity is 338.3704083489415
At time: 68.1684582233429 and batch: 350, loss is 5.834027805328369 and perplexity is 341.73234213948024
At time: 68.51125359535217 and batch: 400, loss is 5.741779670715332 and perplexity is 311.61849610248765
At time: 68.85310506820679 and batch: 450, loss is 5.766401586532592 and perplexity is 319.3863781205702
At time: 69.19595098495483 and batch: 500, loss is 5.772937498092651 and perplexity is 321.48069592398326
At time: 69.53842616081238 and batch: 550, loss is 5.836135339736939 and perplexity is 342.4533142789941
At time: 69.8807315826416 and batch: 600, loss is 5.663291635513306 and perplexity is 288.0953885420223
At time: 70.22295045852661 and batch: 650, loss is 5.864364442825317 and perplexity is 352.2582047189413
At time: 70.5664930343628 and batch: 700, loss is 5.825463399887085 and perplexity is 338.8181049763267
At time: 70.90856385231018 and batch: 750, loss is 5.771747159957886 and perplexity is 321.09825285547544
At time: 71.25152444839478 and batch: 800, loss is 5.7377450656890865 and perplexity is 310.363771413148
At time: 71.59195017814636 and batch: 850, loss is 5.69798789024353 and perplexity is 298.26665154325406
At time: 71.9362781047821 and batch: 900, loss is 5.68009732246399 and perplexity is 292.97794187029893
At time: 72.27879691123962 and batch: 950, loss is 5.724421863555908 and perplexity is 306.25615620657237
At time: 72.62109875679016 and batch: 1000, loss is 5.792404289245606 and perplexity is 327.80020419844385
At time: 72.96235775947571 and batch: 1050, loss is 5.64302209854126 and perplexity is 282.3146131526658
At time: 73.3057701587677 and batch: 1100, loss is 5.739241304397583 and perplexity is 310.8284972853712
At time: 73.64769268035889 and batch: 1150, loss is 5.754794063568116 and perplexity is 315.70052658935555
At time: 74.0180721282959 and batch: 1200, loss is 5.734563903808594 and perplexity is 309.37802275876146
At time: 74.36016941070557 and batch: 1250, loss is 5.741396532058716 and perplexity is 311.49912587964786
At time: 74.70243430137634 and batch: 1300, loss is 5.815324239730835 and perplexity is 335.4001309206405
At time: 75.04555940628052 and batch: 1350, loss is 5.74873517036438 and perplexity is 313.79351384157206
At time: 75.38672852516174 and batch: 1400, loss is 5.6565474510192875 and perplexity is 286.158957254469
At time: 75.72828102111816 and batch: 1450, loss is 5.700951671600341 and perplexity is 299.15195996671116
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.798236553485577 and perplexity of 329.71760757372977
Finished 7 epochs...
Completing Train Step...
At time: 76.98225951194763 and batch: 50, loss is 5.800564365386963 and perplexity is 330.4860221600617
At time: 77.33783555030823 and batch: 100, loss is 5.800896816253662 and perplexity is 330.5959107898336
At time: 77.68366718292236 and batch: 150, loss is 5.775653123855591 and perplexity is 322.35490365739764
At time: 78.02721738815308 and batch: 200, loss is 5.719632711410522 and perplexity is 304.79295542128875
At time: 78.36964917182922 and batch: 250, loss is 5.728451366424561 and perplexity is 307.4927059337423
At time: 78.71229243278503 and batch: 300, loss is 5.808867292404175 and perplexity is 333.24144669710796
At time: 79.05630445480347 and batch: 350, loss is 5.81944354057312 and perplexity is 336.7845945157666
At time: 79.39911556243896 and batch: 400, loss is 5.726092271804809 and perplexity is 306.7681565219004
At time: 79.7400016784668 and batch: 450, loss is 5.7489893436431885 and perplexity is 313.8732819048796
At time: 80.08224701881409 and batch: 500, loss is 5.757412557601929 and perplexity is 316.52826978205474
At time: 80.4243094921112 and batch: 550, loss is 5.820608186721802 and perplexity is 337.1770578928234
At time: 80.76840567588806 and batch: 600, loss is 5.645619039535522 and perplexity is 283.04872034880276
At time: 81.11025047302246 and batch: 650, loss is 5.843220176696778 and perplexity is 344.88815521784386
At time: 81.452791929245 and batch: 700, loss is 5.808597888946533 and perplexity is 333.15168239108834
At time: 81.79516768455505 and batch: 750, loss is 5.754339876174927 and perplexity is 315.55717194755556
At time: 82.13890957832336 and batch: 800, loss is 5.722574453353882 and perplexity is 305.69089775204634
At time: 82.48007726669312 and batch: 850, loss is 5.679149360656738 and perplexity is 292.7003415690687
At time: 82.83625626564026 and batch: 900, loss is 5.667956314086914 and perplexity is 289.44240017376467
At time: 83.17806196212769 and batch: 950, loss is 5.7099169158935545 and perplexity is 301.84598863669464
At time: 83.52033352851868 and batch: 1000, loss is 5.772877006530762 and perplexity is 321.46124964274344
At time: 83.86445116996765 and batch: 1050, loss is 5.62544132232666 and perplexity is 277.39467797835374
At time: 84.2076187133789 and batch: 1100, loss is 5.721145238876343 and perplexity is 305.25431195701265
At time: 84.54874682426453 and batch: 1150, loss is 5.7367853260040285 and perplexity is 310.0660458772775
At time: 84.89113688468933 and batch: 1200, loss is 5.719074220657348 and perplexity is 304.62277889948365
At time: 85.2361650466919 and batch: 1250, loss is 5.723174171447754 and perplexity is 305.87428109821917
At time: 85.57901334762573 and batch: 1300, loss is 5.800319738388062 and perplexity is 330.40518624400875
At time: 85.92060136795044 and batch: 1350, loss is 5.7358633518219 and perplexity is 309.78030473144435
At time: 86.26269245147705 and batch: 1400, loss is 5.639538421630859 and perplexity is 281.33283135156177
At time: 86.60681700706482 and batch: 1450, loss is 5.691705846786499 and perplexity is 296.39880057968463
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.784874549278846 and perplexity of 325.34122326135446
Finished 8 epochs...
Completing Train Step...
At time: 87.84218382835388 and batch: 50, loss is 5.7871255207061765 and perplexity is 326.074381909064
At time: 88.20037484169006 and batch: 100, loss is 5.786759119033814 and perplexity is 325.9549295953181
At time: 88.54353666305542 and batch: 150, loss is 5.766242628097534 and perplexity is 319.3356129966045
At time: 88.88729333877563 and batch: 200, loss is 5.7084337425231935 and perplexity is 301.39863054121383
At time: 89.22906756401062 and batch: 250, loss is 5.7173202610015865 and perplexity is 304.0889511281095
At time: 89.57372212409973 and batch: 300, loss is 5.800123872756958 and perplexity is 330.3404775609956
At time: 89.9174690246582 and batch: 350, loss is 5.809143962860108 and perplexity is 333.3336575155178
At time: 90.25972509384155 and batch: 400, loss is 5.716294689178467 and perplexity is 303.7772459334637
At time: 90.60187411308289 and batch: 450, loss is 5.738735771179199 and perplexity is 310.6714028663422
At time: 90.94496726989746 and batch: 500, loss is 5.745552043914795 and perplexity is 312.7962574465998
At time: 91.28660035133362 and batch: 550, loss is 5.812789821624756 and perplexity is 334.55116303028007
At time: 91.62959003448486 and batch: 600, loss is 5.63640510559082 and perplexity is 280.45270625360644
At time: 91.98526453971863 and batch: 650, loss is 5.835816049575806 and perplexity is 342.34398975914814
At time: 92.32792901992798 and batch: 700, loss is 5.802184162139892 and perplexity is 331.0217761347794
At time: 92.66927003860474 and batch: 750, loss is 5.745393342971802 and perplexity is 312.7466203244115
At time: 93.01267957687378 and batch: 800, loss is 5.716769285202027 and perplexity is 303.9214516234485
At time: 93.35415816307068 and batch: 850, loss is 5.6718404006958005 and perplexity is 290.56880563641926
At time: 93.69470834732056 and batch: 900, loss is 5.663588991165161 and perplexity is 288.18106807209364
At time: 94.0368595123291 and batch: 950, loss is 5.70792031288147 and perplexity is 301.24392326936714
At time: 94.37895226478577 and batch: 1000, loss is 5.767981548309326 and perplexity is 319.8913952388264
At time: 94.72263288497925 and batch: 1050, loss is 5.621404571533203 and perplexity is 276.27716187645603
At time: 95.06628322601318 and batch: 1100, loss is 5.718782033920288 and perplexity is 304.53378516571024
At time: 95.40961122512817 and batch: 1150, loss is 5.7304850196838375 and perplexity is 308.11867576442387
At time: 95.75030779838562 and batch: 1200, loss is 5.712913274765015 and perplexity is 302.75178390871207
At time: 96.09075903892517 and batch: 1250, loss is 5.718379058837891 and perplexity is 304.41109036167506
At time: 96.43371391296387 and batch: 1300, loss is 5.7930599975585935 and perplexity is 328.0152160021457
At time: 96.77571868896484 and batch: 1350, loss is 5.727453708648682 and perplexity is 307.1860864207442
At time: 97.11616706848145 and batch: 1400, loss is 5.632490186691284 and perplexity is 279.35690304339397
At time: 97.45717716217041 and batch: 1450, loss is 5.684287147521973 and perplexity is 294.20804334808327
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.7839538052550745 and perplexity of 325.04180513922654
Finished 9 epochs...
Completing Train Step...
At time: 98.70098876953125 and batch: 50, loss is 5.782348690032959 and perplexity is 324.52049408405384
At time: 99.04249405860901 and batch: 100, loss is 5.779943923950196 and perplexity is 323.741035789781
At time: 99.38694620132446 and batch: 150, loss is 5.760398483276367 and perplexity is 317.47481211875373
At time: 99.73057913780212 and batch: 200, loss is 5.704652996063232 and perplexity is 300.2612701262289
At time: 100.07225775718689 and batch: 250, loss is 5.710423698425293 and perplexity is 301.9989976788912
At time: 100.41374468803406 and batch: 300, loss is 5.795134449005127 and perplexity is 328.69637391170016
At time: 100.77269244194031 and batch: 350, loss is 5.805156316757202 and perplexity is 332.00708755876866
At time: 101.11551856994629 and batch: 400, loss is 5.711429796218872 and perplexity is 302.3029911020325
At time: 101.45808339118958 and batch: 450, loss is 5.733472957611084 and perplexity is 309.0406920195398
At time: 101.79934597015381 and batch: 500, loss is 5.740851993560791 and perplexity is 311.329548788354
At time: 102.14219069480896 and batch: 550, loss is 5.809876899719239 and perplexity is 333.5780595942048
At time: 102.4861490726471 and batch: 600, loss is 5.630038461685181 and perplexity is 278.6728356537954
At time: 102.82882690429688 and batch: 650, loss is 5.830612115859985 and perplexity is 340.56708179409077
At time: 103.17185759544373 and batch: 700, loss is 5.79859806060791 and perplexity is 329.8368243847912
At time: 103.5146815776825 and batch: 750, loss is 5.743637495040893 and perplexity is 312.1979666353968
At time: 103.85847473144531 and batch: 800, loss is 5.712765312194824 and perplexity is 302.7069912905323
At time: 104.1988775730133 and batch: 850, loss is 5.669230651855469 and perplexity is 289.811482674065
At time: 104.5392656326294 and batch: 900, loss is 5.659572601318359 and perplexity is 287.0259418277235
At time: 104.88235402107239 and batch: 950, loss is 5.701369895935058 and perplexity is 299.2770987623682
At time: 105.22496390342712 and batch: 1000, loss is 5.762169771194458 and perplexity is 318.0376497443441
At time: 105.56643533706665 and batch: 1050, loss is 5.616997938156128 and perplexity is 275.0623882104468
At time: 105.91129207611084 and batch: 1100, loss is 5.71339485168457 and perplexity is 302.89761729237415
At time: 106.25431299209595 and batch: 1150, loss is 5.727602062225341 and perplexity is 307.2316619559281
At time: 106.59521055221558 and batch: 1200, loss is 5.708097496032715 and perplexity is 301.2973033458709
At time: 106.93951487541199 and batch: 1250, loss is 5.711430759429931 and perplexity is 302.303282283757
At time: 107.28227233886719 and batch: 1300, loss is 5.789263305664062 and perplexity is 326.7722044493647
At time: 107.62338900566101 and batch: 1350, loss is 5.722829828262329 and perplexity is 305.76897350594265
At time: 107.96455502510071 and batch: 1400, loss is 5.629675369262696 and perplexity is 278.57167002616495
At time: 108.30813312530518 and batch: 1450, loss is 5.682770357131958 and perplexity is 293.7621296795426
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.783035669571314 and perplexity of 324.74350961805
Finished 10 epochs...
Completing Train Step...
At time: 109.55418014526367 and batch: 50, loss is 5.777963943481446 and perplexity is 323.1006690280285
At time: 109.89651584625244 and batch: 100, loss is 5.776115283966065 and perplexity is 322.50391766679695
At time: 110.23841094970703 and batch: 150, loss is 5.75795913696289 and perplexity is 316.70132489134573
At time: 110.5810215473175 and batch: 200, loss is 5.700463428497314 and perplexity is 299.00593673581875
At time: 110.92418479919434 and batch: 250, loss is 5.707685604095459 and perplexity is 301.17322697068914
At time: 111.26649975776672 and batch: 300, loss is 5.790498371124268 and perplexity is 327.17603884205676
At time: 111.60846185684204 and batch: 350, loss is 5.801054258346557 and perplexity is 330.64796459955386
At time: 111.94990134239197 and batch: 400, loss is 5.707969179153443 and perplexity is 301.2586442965297
At time: 112.2923195362091 and batch: 450, loss is 5.72881365776062 and perplexity is 307.6041280594202
At time: 112.63493061065674 and batch: 500, loss is 5.737066030502319 and perplexity is 310.153095028095
At time: 112.97754263877869 and batch: 550, loss is 5.808419637680053 and perplexity is 333.09230297415763
At time: 113.32018613815308 and batch: 600, loss is 5.627062139511108 and perplexity is 277.84464860084637
At time: 113.66280817985535 and batch: 650, loss is 5.826605043411255 and perplexity is 339.20513535507075
At time: 114.00627374649048 and batch: 700, loss is 5.795922288894653 and perplexity is 328.9554360629588
At time: 114.34978818893433 and batch: 750, loss is 5.741225032806397 and perplexity is 311.4457085931046
At time: 114.69481110572815 and batch: 800, loss is 5.709693841934204 and perplexity is 301.77866216656565
At time: 115.03586196899414 and batch: 850, loss is 5.665173568725586 and perplexity is 288.63807531198415
At time: 115.37927603721619 and batch: 900, loss is 5.6565487098693845 and perplexity is 286.15931748592686
At time: 115.7206482887268 and batch: 950, loss is 5.698974819183349 and perplexity is 298.56116484138835
At time: 116.06354594230652 and batch: 1000, loss is 5.759839458465576 and perplexity is 317.29738541956226
At time: 116.40442967414856 and batch: 1050, loss is 5.612448873519898 and perplexity is 273.8139533857613
At time: 116.74795961380005 and batch: 1100, loss is 5.708524332046509 and perplexity is 301.42593533622806
At time: 117.09086418151855 and batch: 1150, loss is 5.723262844085693 and perplexity is 305.90140498015717
At time: 117.43120861053467 and batch: 1200, loss is 5.704945497512817 and perplexity is 300.34910982898896
At time: 117.7727358341217 and batch: 1250, loss is 5.709682779312134 and perplexity is 301.77532372174335
At time: 118.1160020828247 and batch: 1300, loss is 5.78678147315979 and perplexity is 325.9622161143184
At time: 118.45956873893738 and batch: 1350, loss is 5.720522241592407 and perplexity is 305.06419857596285
At time: 118.8011577129364 and batch: 1400, loss is 5.626919689178467 and perplexity is 277.8050723571221
At time: 119.14227199554443 and batch: 1450, loss is 5.6795831966400145 and perplexity is 292.82735305864384
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.779623439169337 and perplexity of 323.637298338896
Finished 11 epochs...
Completing Train Step...
At time: 120.40711784362793 and batch: 50, loss is 5.776037921905518 and perplexity is 322.4789690642419
At time: 120.76402831077576 and batch: 100, loss is 5.772545242309571 and perplexity is 321.35461799087403
At time: 121.10695433616638 and batch: 150, loss is 5.755226974487305 and perplexity is 315.83722638179125
At time: 121.45134401321411 and batch: 200, loss is 5.698501234054565 and perplexity is 298.4198041894804
At time: 121.79557824134827 and batch: 250, loss is 5.704419965744019 and perplexity is 300.19130829853407
At time: 122.136794090271 and batch: 300, loss is 5.7875654411315915 and perplexity is 326.2178602470822
At time: 122.48081064224243 and batch: 350, loss is 5.797912759780884 and perplexity is 329.6108643703922
At time: 122.8228108882904 and batch: 400, loss is 5.705244197845459 and perplexity is 300.4388376081951
At time: 123.16369199752808 and batch: 450, loss is 5.726661081314087 and perplexity is 306.94269880242206
At time: 123.5062575340271 and batch: 500, loss is 5.734809446334839 and perplexity is 309.45399754717334
At time: 123.84857773780823 and batch: 550, loss is 5.805244493484497 and perplexity is 332.03636414792624
At time: 124.19084239006042 and batch: 600, loss is 5.6243539142608645 and perplexity is 277.0932007122238
At time: 124.53251266479492 and batch: 650, loss is 5.8242044925689695 and perplexity is 338.39183275936665
At time: 124.87497067451477 and batch: 700, loss is 5.7936482334136965 and perplexity is 328.20822307449225
At time: 125.216872215271 and batch: 750, loss is 5.735864315032959 and perplexity is 309.78060311540355
At time: 125.56011438369751 and batch: 800, loss is 5.707350130081177 and perplexity is 301.07220812478937
At time: 125.90097379684448 and batch: 850, loss is 5.6630861186981205 and perplexity is 288.03618617904846
At time: 126.24124503135681 and batch: 900, loss is 5.655694742202758 and perplexity is 285.9150509939777
At time: 126.58186531066895 and batch: 950, loss is 5.694908876419067 and perplexity is 297.34969678238775
At time: 126.92468595504761 and batch: 1000, loss is 5.760526857376099 and perplexity is 317.515570278037
At time: 127.28007912635803 and batch: 1050, loss is 5.611498765945434 and perplexity is 273.55392422205546
At time: 127.62193131446838 and batch: 1100, loss is 5.70923155784607 and perplexity is 301.63918693398193
At time: 127.96510934829712 and batch: 1150, loss is 5.72191349029541 and perplexity is 305.48891412053393
At time: 128.30771660804749 and batch: 1200, loss is 5.702632598876953 and perplexity is 299.6552355223744
At time: 128.64934515953064 and batch: 1250, loss is 5.7071507453918455 and perplexity is 301.012184920159
At time: 128.9908790588379 and batch: 1300, loss is 5.784252462387085 and perplexity is 325.13889569020387
At time: 129.33249235153198 and batch: 1350, loss is 5.718448495864868 and perplexity is 304.43222849664477
At time: 129.67318630218506 and batch: 1400, loss is 5.62455376625061 and perplexity is 277.14858387376427
At time: 130.01413536071777 and batch: 1450, loss is 5.679010725021362 and perplexity is 292.6597656839373
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.7792989616720085 and perplexity of 323.53230235362724
Finished 12 epochs...
Completing Train Step...
At time: 131.25124955177307 and batch: 50, loss is 5.773686408996582 and perplexity is 321.72154649911784
At time: 131.606938123703 and batch: 100, loss is 5.771852712631226 and perplexity is 321.1321474232689
At time: 131.94933533668518 and batch: 150, loss is 5.752419834136963 and perplexity is 314.951870200392
At time: 132.29171657562256 and batch: 200, loss is 5.695408201217651 and perplexity is 297.49820793440756
At time: 132.63467359542847 and batch: 250, loss is 5.702826175689697 and perplexity is 299.7132474424892
At time: 132.97783303260803 and batch: 300, loss is 5.7853866386413575 and perplexity is 325.5078697062673
At time: 133.31976914405823 and batch: 350, loss is 5.795898160934448 and perplexity is 328.9474991350396
At time: 133.66159057617188 and batch: 400, loss is 5.703519315719604 and perplexity is 299.9210627060037
At time: 134.00459551811218 and batch: 450, loss is 5.72421049118042 and perplexity is 306.1914289563445
At time: 134.3466923236847 and batch: 500, loss is 5.7307540130615235 and perplexity is 308.20156879608436
At time: 134.68973875045776 and batch: 550, loss is 5.804057502746582 and perplexity is 331.6424738773308
At time: 135.032057762146 and batch: 600, loss is 5.62143533706665 and perplexity is 276.2856618214724
At time: 135.3757026195526 and batch: 650, loss is 5.821840810775757 and perplexity is 337.59292669711505
At time: 135.71835255622864 and batch: 700, loss is 5.791384229660034 and perplexity is 327.46599894161574
At time: 136.07474064826965 and batch: 750, loss is 5.734924907684326 and perplexity is 309.4897295861295
At time: 136.41823291778564 and batch: 800, loss is 5.704865312576294 and perplexity is 300.32502732022255
At time: 136.76031136512756 and batch: 850, loss is 5.661578197479248 and perplexity is 287.6021776097096
At time: 137.10133457183838 and batch: 900, loss is 5.65378134727478 and perplexity is 285.36850563088143
At time: 137.44310855865479 and batch: 950, loss is 5.692430677413941 and perplexity is 296.61371738801483
At time: 137.78457045555115 and batch: 1000, loss is 5.756864824295044 and perplexity is 316.3549441785608
At time: 138.12768816947937 and batch: 1050, loss is 5.60731725692749 and perplexity is 272.4124442386817
At time: 138.4697721004486 and batch: 1100, loss is 5.706724109649659 and perplexity is 300.8837897541692
At time: 138.8129448890686 and batch: 1150, loss is 5.718698310852051 and perplexity is 304.50828973012716
At time: 139.15321588516235 and batch: 1200, loss is 5.700662984848022 and perplexity is 299.06561122340725
At time: 139.4959261417389 and batch: 1250, loss is 5.705676736831665 and perplexity is 300.56881722703105
At time: 139.83861589431763 and batch: 1300, loss is 5.781745710372925 and perplexity is 324.32487381030717
At time: 140.18051505088806 and batch: 1350, loss is 5.714866762161255 and perplexity is 303.3437837466164
At time: 140.5218050479889 and batch: 1400, loss is 5.623098373413086 and perplexity is 276.7455171911928
At time: 140.863116979599 and batch: 1450, loss is 5.676903944015503 and perplexity is 292.0438446815649
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.774972247262286 and perplexity of 322.1354944525327
Finished 13 epochs...
Completing Train Step...
At time: 142.10632491111755 and batch: 50, loss is 5.772825527191162 and perplexity is 321.44470145585336
At time: 142.4473922252655 and batch: 100, loss is 5.768891563415528 and perplexity is 320.1826337364554
At time: 142.78956627845764 and batch: 150, loss is 5.75250433921814 and perplexity is 314.97848635833464
At time: 143.13179397583008 and batch: 200, loss is 5.693936910629272 and perplexity is 297.06082345974505
At time: 143.4757580757141 and batch: 250, loss is 5.700835456848145 and perplexity is 299.1171961158897
At time: 143.81827402114868 and batch: 300, loss is 5.783782739639282 and perplexity is 324.98620641832235
At time: 144.1635537147522 and batch: 350, loss is 5.793661823272705 and perplexity is 328.2126834082769
At time: 144.50654339790344 and batch: 400, loss is 5.701549997329712 and perplexity is 299.33100383928735
At time: 144.8643410205841 and batch: 450, loss is 5.7229062271118165 and perplexity is 305.792334796104
At time: 145.20649480819702 and batch: 500, loss is 5.729489583969116 and perplexity is 307.8121160357605
At time: 145.54852557182312 and batch: 550, loss is 5.802506771087646 and perplexity is 331.1285839493139
At time: 145.8909924030304 and batch: 600, loss is 5.618796882629394 and perplexity is 275.55765551914976
At time: 146.23339366912842 and batch: 650, loss is 5.819744901657105 and perplexity is 336.8861035809118
At time: 146.5763156414032 and batch: 700, loss is 5.790111684799195 and perplexity is 327.049548799506
At time: 146.9151177406311 and batch: 750, loss is 5.729907674789429 and perplexity is 307.9408363623745
At time: 147.25838661193848 and batch: 800, loss is 5.702660179138183 and perplexity is 299.66350020601976
At time: 147.5994908809662 and batch: 850, loss is 5.659774475097656 and perplexity is 287.0838906883374
At time: 147.9396562576294 and batch: 900, loss is 5.652472944259643 and perplexity is 284.9953727749969
At time: 148.2817258834839 and batch: 950, loss is 5.6905766868591305 and perplexity is 296.06430781500273
At time: 148.62549376487732 and batch: 1000, loss is 5.756110286712646 and perplexity is 316.11633251585494
At time: 148.96807479858398 and batch: 1050, loss is 5.607393646240235 and perplexity is 272.4332544329083
At time: 149.30912113189697 and batch: 1100, loss is 5.705904331207275 and perplexity is 300.63723278451835
At time: 149.65234661102295 and batch: 1150, loss is 5.7172709083557125 and perplexity is 304.0739439041164
At time: 149.99410557746887 and batch: 1200, loss is 5.698913507461548 and perplexity is 298.542860103462
At time: 150.33560299873352 and batch: 1250, loss is 5.70504337310791 and perplexity is 300.37850811551294
At time: 150.67697596549988 and batch: 1300, loss is 5.780529413223267 and perplexity is 323.9306381931592
At time: 151.01966166496277 and batch: 1350, loss is 5.713530950546264 and perplexity is 302.938844118696
At time: 151.36135363578796 and batch: 1400, loss is 5.622163095474243 and perplexity is 276.4868042174176
At time: 151.70106673240662 and batch: 1450, loss is 5.675345363616944 and perplexity is 291.5890253980039
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.777394351796207 and perplexity of 322.9166859760378
Annealing...
Finished 14 epochs...
Completing Train Step...
At time: 152.97184348106384 and batch: 50, loss is 5.75178900718689 and perplexity is 314.7532527259081
At time: 153.31452250480652 and batch: 100, loss is 5.720474948883057 and perplexity is 305.0497716046344
At time: 153.6718511581421 and batch: 150, loss is 5.693606157302856 and perplexity is 296.9625858513412
At time: 154.01555180549622 and batch: 200, loss is 5.630023422241211 and perplexity is 278.6686446008134
At time: 154.35922718048096 and batch: 250, loss is 5.640458488464356 and perplexity is 281.59179547274334
At time: 154.70063662528992 and batch: 300, loss is 5.703103876113891 and perplexity is 299.79648949608236
At time: 155.04394602775574 and batch: 350, loss is 5.715912761688233 and perplexity is 303.66124720529575
At time: 155.38764071464539 and batch: 400, loss is 5.62472243309021 and perplexity is 277.1953335919587
At time: 155.7323031425476 and batch: 450, loss is 5.657242784500122 and perplexity is 286.3580023516292
At time: 156.0793755054474 and batch: 500, loss is 5.647466592788696 and perplexity is 283.5721513172919
At time: 156.42609167099 and batch: 550, loss is 5.7131328105926515 and perplexity is 302.81825606840437
At time: 156.7728772163391 and batch: 600, loss is 5.543493146896362 and perplexity is 255.56918273278905
At time: 157.11757731437683 and batch: 650, loss is 5.73416958808899 and perplexity is 309.25605418973
At time: 157.45949053764343 and batch: 700, loss is 5.705618858337402 and perplexity is 300.5514212598986
At time: 157.8005998134613 and batch: 750, loss is 5.645263042449951 and perplexity is 282.9479737630934
At time: 158.14389276504517 and batch: 800, loss is 5.6157190704345705 and perplexity is 274.7108446375264
At time: 158.48788452148438 and batch: 850, loss is 5.566382503509521 and perplexity is 261.4864598817448
At time: 158.830824136734 and batch: 900, loss is 5.555395221710205 and perplexity is 258.62916018326774
At time: 159.17229342460632 and batch: 950, loss is 5.597796297073364 and perplexity is 269.8311241153615
At time: 159.5151059627533 and batch: 1000, loss is 5.66174861907959 and perplexity is 287.65119540980703
At time: 159.8590681552887 and batch: 1050, loss is 5.515610589981079 and perplexity is 248.54168799079892
At time: 160.20210099220276 and batch: 1100, loss is 5.607205257415772 and perplexity is 272.38193588643315
At time: 160.54451704025269 and batch: 1150, loss is 5.617835054397583 and perplexity is 275.2927438067844
At time: 160.88756275177002 and batch: 1200, loss is 5.594553270339966 and perplexity is 268.9574719706824
At time: 161.22976160049438 and batch: 1250, loss is 5.603350591659546 and perplexity is 271.33401555440565
At time: 161.57233786582947 and batch: 1300, loss is 5.676211338043213 and perplexity is 291.84164340155803
At time: 161.91267466545105 and batch: 1350, loss is 5.593759498596191 and perplexity is 268.74406583823907
At time: 162.2555432319641 and batch: 1400, loss is 5.493066482543945 and perplexity is 243.0012245295107
At time: 162.59832620620728 and batch: 1450, loss is 5.556660547256469 and perplexity is 258.9566173929534
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.6838561490050745 and perplexity of 294.0812674398174
Finished 15 epochs...
Completing Train Step...
At time: 163.85056948661804 and batch: 50, loss is 5.690235328674317 and perplexity is 295.9632610878437
At time: 164.20875668525696 and batch: 100, loss is 5.683158054351806 and perplexity is 293.87604252093513
At time: 164.5519096851349 and batch: 150, loss is 5.6629650688171385 and perplexity is 288.0013215432155
At time: 164.89471220970154 and batch: 200, loss is 5.605372505187988 and perplexity is 271.88318447012205
At time: 165.23689699172974 and batch: 250, loss is 5.6164994812011715 and perplexity is 274.9253156152285
At time: 165.58107829093933 and batch: 300, loss is 5.684742193222046 and perplexity is 294.3419519180847
At time: 165.92465329170227 and batch: 350, loss is 5.6993114948272705 and perplexity is 298.66170003673733
At time: 166.2662010192871 and batch: 400, loss is 5.611952676773071 and perplexity is 273.6781214953135
At time: 166.6073830127716 and batch: 450, loss is 5.641596050262451 and perplexity is 281.9123058075235
At time: 166.9493749141693 and batch: 500, loss is 5.6333301067352295 and perplexity is 279.59163907162224
At time: 167.29225993156433 and batch: 550, loss is 5.700792322158813 and perplexity is 299.1042940668265
At time: 167.63450074195862 and batch: 600, loss is 5.531499176025391 and perplexity is 252.52220262186313
At time: 167.9770097732544 and batch: 650, loss is 5.722495355606079 and perplexity is 305.66671924675546
At time: 168.32071805000305 and batch: 700, loss is 5.694121789932251 and perplexity is 297.1157489348639
At time: 168.6634488105774 and batch: 750, loss is 5.635045146942138 and perplexity is 280.0715613995544
At time: 169.0072205066681 and batch: 800, loss is 5.606065540313721 and perplexity is 272.07167437457394
At time: 169.34934210777283 and batch: 850, loss is 5.558692111968994 and perplexity is 259.4832392710105
At time: 169.69415736198425 and batch: 900, loss is 5.551035900115966 and perplexity is 257.5041663868412
At time: 170.0381302833557 and batch: 950, loss is 5.593272294998169 and perplexity is 268.61316465276906
At time: 170.38001489639282 and batch: 1000, loss is 5.657657299041748 and perplexity is 286.4767265124606
At time: 170.72234678268433 and batch: 1050, loss is 5.512375535964966 and perplexity is 247.738941369334
At time: 171.06477403640747 and batch: 1100, loss is 5.6039340209960935 and perplexity is 271.4923659677299
At time: 171.42440557479858 and batch: 1150, loss is 5.61510347366333 and perplexity is 274.5417855699898
At time: 171.76814007759094 and batch: 1200, loss is 5.593866453170777 and perplexity is 268.7728107826474
At time: 172.11055064201355 and batch: 1250, loss is 5.606803483963013 and perplexity is 272.2725220368448
At time: 172.45323204994202 and batch: 1300, loss is 5.677466154098511 and perplexity is 292.20808083901096
At time: 172.7951376438141 and batch: 1350, loss is 5.59948073387146 and perplexity is 270.28602060472866
At time: 173.13892602920532 and batch: 1400, loss is 5.499825649261474 and perplexity is 244.64927376399743
At time: 173.48151302337646 and batch: 1450, loss is 5.564007577896118 and perplexity is 260.86618583451735
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.681332319210737 and perplexity of 293.33999219484696
Finished 16 epochs...
Completing Train Step...
At time: 174.71720361709595 and batch: 50, loss is 5.6840154075622555 and perplexity is 294.1281061277958
At time: 175.0732307434082 and batch: 100, loss is 5.6780860710144045 and perplexity is 292.38928173022987
At time: 175.41488122940063 and batch: 150, loss is 5.658208770751953 and perplexity is 286.6347538925741
At time: 175.7576675415039 and batch: 200, loss is 5.600088195800781 and perplexity is 270.45025895149473
At time: 176.10504603385925 and batch: 250, loss is 5.610660457611084 and perplexity is 273.32469778212777
At time: 176.44726514816284 and batch: 300, loss is 5.6794596290588375 and perplexity is 292.7911713264145
At time: 176.78847432136536 and batch: 350, loss is 5.695595121383667 and perplexity is 297.55382154631485
At time: 177.13294410705566 and batch: 400, loss is 5.609417810440063 and perplexity is 272.9852625624452
At time: 177.47538423538208 and batch: 450, loss is 5.6373824119567875 and perplexity is 280.72692844650174
At time: 177.81896042823792 and batch: 500, loss is 5.629383821487426 and perplexity is 278.4904649136759
At time: 178.16103720664978 and batch: 550, loss is 5.697427959442138 and perplexity is 298.099689605955
At time: 178.5023593902588 and batch: 600, loss is 5.527884855270385 and perplexity is 251.61115378695987
At time: 178.84615969657898 and batch: 650, loss is 5.718773899078369 and perplexity is 304.5313078415852
At time: 179.1890823841095 and batch: 700, loss is 5.6903120708465575 and perplexity is 295.98597482294264
At time: 179.53139734268188 and batch: 750, loss is 5.632007064819336 and perplexity is 279.22197221009685
At time: 179.87651324272156 and batch: 800, loss is 5.603171663284302 and perplexity is 271.2854705430235
At time: 180.24711561203003 and batch: 850, loss is 5.556866521835327 and perplexity is 259.00996136672603
At time: 180.58941388130188 and batch: 900, loss is 5.5501038646698 and perplexity is 257.2642751871497
At time: 180.9302089214325 and batch: 950, loss is 5.5921721935272215 and perplexity is 268.31782539657934
At time: 181.27254128456116 and batch: 1000, loss is 5.6569201850891115 and perplexity is 286.2656383278233
At time: 181.61907744407654 and batch: 1050, loss is 5.512026786804199 and perplexity is 247.6525576854363
At time: 181.96153783798218 and batch: 1100, loss is 5.604036779403686 and perplexity is 271.52026552436274
At time: 182.30280470848083 and batch: 1150, loss is 5.615443887710572 and perplexity is 274.6352593593454
At time: 182.645325422287 and batch: 1200, loss is 5.59518196105957 and perplexity is 269.1266162014113
At time: 182.98874878883362 and batch: 1250, loss is 5.6095760059356685 and perplexity is 273.0284510173687
At time: 183.33173966407776 and batch: 1300, loss is 5.67992301940918 and perplexity is 292.92687937034316
At time: 183.67269802093506 and batch: 1350, loss is 5.602478628158569 and perplexity is 271.09752531668056
At time: 184.0144329071045 and batch: 1400, loss is 5.502758712768554 and perplexity is 245.36789899243863
At time: 184.35639691352844 and batch: 1450, loss is 5.566743955612183 and perplexity is 261.580991795837
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.6794574444110575 and perplexity of 292.79053168153075
Finished 17 epochs...
Completing Train Step...
At time: 185.60282063484192 and batch: 50, loss is 5.681178894042969 and perplexity is 293.29498990966107
At time: 185.9467134475708 and batch: 100, loss is 5.675180492401123 and perplexity is 291.54095472371057
At time: 186.29173398017883 and batch: 150, loss is 5.655765762329102 and perplexity is 285.9353574380973
At time: 186.63428449630737 and batch: 200, loss is 5.5972360992431645 and perplexity is 269.68000763662553
At time: 186.97762775421143 and batch: 250, loss is 5.607503643035889 and perplexity is 272.46322286611115
At time: 187.32301950454712 and batch: 300, loss is 5.676515760421753 and perplexity is 291.9305000530897
At time: 187.66677498817444 and batch: 350, loss is 5.693566455841064 and perplexity is 296.95079623661945
At time: 188.0083134174347 and batch: 400, loss is 5.608288784027099 and perplexity is 272.67722891244665
At time: 188.35203623771667 and batch: 450, loss is 5.635065822601319 and perplexity is 280.0773521235673
At time: 188.69774317741394 and batch: 500, loss is 5.62745735168457 and perplexity is 277.95447788981113
At time: 189.05750346183777 and batch: 550, loss is 5.695701208114624 and perplexity is 297.5853897329798
At time: 189.40050101280212 and batch: 600, loss is 5.525528993606567 and perplexity is 251.01909039911655
At time: 189.7426884174347 and batch: 650, loss is 5.716854677200318 and perplexity is 303.9474051916239
At time: 190.0885624885559 and batch: 700, loss is 5.688768482208252 and perplexity is 295.52944667158795
At time: 190.4337968826294 and batch: 750, loss is 5.630549402236938 and perplexity is 278.8152572875999
At time: 190.77676367759705 and batch: 800, loss is 5.601714887619019 and perplexity is 270.89055619184035
At time: 191.1203417778015 and batch: 850, loss is 5.556046199798584 and perplexity is 258.7975769114153
At time: 191.46279454231262 and batch: 900, loss is 5.549639539718628 and perplexity is 257.1448486936312
At time: 191.8052794933319 and batch: 950, loss is 5.591917448043823 and perplexity is 268.2494813479827
At time: 192.1483495235443 and batch: 1000, loss is 5.656786623001099 and perplexity is 286.22740664465056
At time: 192.49040818214417 and batch: 1050, loss is 5.511932077407837 and perplexity is 247.62910377186097
At time: 192.83409547805786 and batch: 1100, loss is 5.604223985671997 and perplexity is 271.5711005782141
At time: 193.17830157279968 and batch: 1150, loss is 5.615348892211914 and perplexity is 274.60917148506854
At time: 193.52140021324158 and batch: 1200, loss is 5.595821084976197 and perplexity is 269.29867643647526
At time: 193.86298298835754 and batch: 1250, loss is 5.61083197593689 and perplexity is 273.37158199732875
At time: 194.20653367042542 and batch: 1300, loss is 5.681298599243164 and perplexity is 293.33010094658954
At time: 194.55060720443726 and batch: 1350, loss is 5.6039684295654295 and perplexity is 271.50170779234696
At time: 194.89568662643433 and batch: 1400, loss is 5.504060697555542 and perplexity is 245.68757232389086
At time: 195.23802042007446 and batch: 1450, loss is 5.56816780090332 and perplexity is 261.95370794135255
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.679216955462072 and perplexity of 292.7201272603758
Finished 18 epochs...
Completing Train Step...
At time: 196.48359203338623 and batch: 50, loss is 5.679237508773804 and perplexity is 292.7261436902301
At time: 196.82559823989868 and batch: 100, loss is 5.6735027885437015 and perplexity is 291.0522454087562
At time: 197.16904759407043 and batch: 150, loss is 5.6542932891845705 and perplexity is 285.5146351303642
At time: 197.5109841823578 and batch: 200, loss is 5.595174293518067 and perplexity is 269.1245526698232
At time: 197.8678810596466 and batch: 250, loss is 5.6053677177429195 and perplexity is 271.881882847427
At time: 198.21073532104492 and batch: 300, loss is 5.674500770568848 and perplexity is 291.34285530565955
At time: 198.5548152923584 and batch: 350, loss is 5.692155809402466 and perplexity is 296.53219896925617
At time: 198.89870429039001 and batch: 400, loss is 5.607566423416138 and perplexity is 272.48032874779784
At time: 199.2400884628296 and batch: 450, loss is 5.633736801147461 and perplexity is 279.705370554351
At time: 199.5817425251007 and batch: 500, loss is 5.625745868682861 and perplexity is 277.4791703820354
At time: 199.92484521865845 and batch: 550, loss is 5.694342823028564 and perplexity is 297.18142860723765
At time: 200.27157306671143 and batch: 600, loss is 5.52355055809021 and perplexity is 250.52295626191713
At time: 200.61378979682922 and batch: 650, loss is 5.715531167984008 and perplexity is 303.54539409096066
At time: 200.95688891410828 and batch: 700, loss is 5.687680168151855 and perplexity is 295.2079927738222
At time: 201.29956364631653 and batch: 750, loss is 5.628972787857055 and perplexity is 278.3760194889292
At time: 201.64441084861755 and batch: 800, loss is 5.600485582351684 and perplexity is 270.55775360414026
At time: 201.9874668121338 and batch: 850, loss is 5.555161113739014 and perplexity is 258.56862012201833
At time: 202.32943487167358 and batch: 900, loss is 5.549112195968628 and perplexity is 257.00928071343316
At time: 202.67004656791687 and batch: 950, loss is 5.591557006835938 and perplexity is 268.1528106040176
At time: 203.01317167282104 and batch: 1000, loss is 5.6560464859008786 and perplexity is 286.0156375006603
At time: 203.3566117286682 and batch: 1050, loss is 5.511805000305176 and perplexity is 247.5976377821648
At time: 203.69849967956543 and batch: 1100, loss is 5.6041054439544675 and perplexity is 271.5389099815223
At time: 204.04151821136475 and batch: 1150, loss is 5.615561408996582 and perplexity is 274.66753674481185
At time: 204.38615036010742 and batch: 1200, loss is 5.5961414813995365 and perplexity is 269.38497259296736
At time: 204.73004961013794 and batch: 1250, loss is 5.611753740310669 and perplexity is 273.62368235313113
At time: 205.0716516971588 and batch: 1300, loss is 5.681897821426392 and perplexity is 293.50592352321826
At time: 205.41379261016846 and batch: 1350, loss is 5.604461040496826 and perplexity is 271.63548544896105
At time: 205.75560474395752 and batch: 1400, loss is 5.50444863319397 and perplexity is 245.78290177876508
At time: 206.0976483821869 and batch: 1450, loss is 5.56833441734314 and perplexity is 261.9973573718226
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.679126185229701 and perplexity of 292.6935581922631
Finished 19 epochs...
Completing Train Step...
At time: 207.33017086982727 and batch: 50, loss is 5.677420692443848 and perplexity is 292.19479687810787
At time: 207.68785691261292 and batch: 100, loss is 5.671946887969971 and perplexity is 290.59974916400705
At time: 208.03145837783813 and batch: 150, loss is 5.65354507446289 and perplexity is 285.30108877632983
At time: 208.37518858909607 and batch: 200, loss is 5.593347492218018 and perplexity is 268.6333643754378
At time: 208.71832990646362 and batch: 250, loss is 5.603592987060547 and perplexity is 271.39979364374227
At time: 209.06049489974976 and batch: 300, loss is 5.672940721511841 and perplexity is 290.8887005029685
At time: 209.40200757980347 and batch: 350, loss is 5.691198253631592 and perplexity is 296.24838875462353
At time: 209.74354100227356 and batch: 400, loss is 5.6068368339538575 and perplexity is 272.2816024743774
At time: 210.08655190467834 and batch: 450, loss is 5.632665491104126 and perplexity is 279.40587983405345
At time: 210.43055319786072 and batch: 500, loss is 5.624521980285644 and perplexity is 277.13977457859363
At time: 210.77399897575378 and batch: 550, loss is 5.69308032989502 and perplexity is 296.80647583165916
At time: 211.11695098876953 and batch: 600, loss is 5.522389802932739 and perplexity is 250.23232915445976
At time: 211.46027064323425 and batch: 650, loss is 5.714547472000122 and perplexity is 303.2469445217539
At time: 211.80435228347778 and batch: 700, loss is 5.6870387935638425 and perplexity is 295.01871457468076
At time: 212.14684224128723 and batch: 750, loss is 5.6280426502227785 and perplexity is 278.1172118587399
At time: 212.48974084854126 and batch: 800, loss is 5.599525413513184 and perplexity is 270.2980971570781
At time: 212.83281707763672 and batch: 850, loss is 5.554505910873413 and perplexity is 258.39926070960485
At time: 213.17674469947815 and batch: 900, loss is 5.5490327739715575 and perplexity is 256.98886933366026
At time: 213.51836943626404 and batch: 950, loss is 5.591616172790527 and perplexity is 268.16867659039116
At time: 213.86050581932068 and batch: 1000, loss is 5.655950212478638 and perplexity is 285.9881031218596
At time: 214.20362877845764 and batch: 1050, loss is 5.5117402935028075 and perplexity is 247.58161704908068
At time: 214.54866123199463 and batch: 1100, loss is 5.603986320495605 and perplexity is 271.50656525389576
At time: 214.8920397758484 and batch: 1150, loss is 5.61538182258606 and perplexity is 274.6182146167254
At time: 215.23705387115479 and batch: 1200, loss is 5.596309614181519 and perplexity is 269.4302688456194
At time: 215.59440779685974 and batch: 1250, loss is 5.612128648757935 and perplexity is 273.7262854151928
At time: 215.93795251846313 and batch: 1300, loss is 5.682317934036255 and perplexity is 293.6292549674933
At time: 216.28031849861145 and batch: 1350, loss is 5.604791326522827 and perplexity is 271.7252176718047
At time: 216.6229817867279 and batch: 1400, loss is 5.504857444763184 and perplexity is 245.88340121379335
At time: 216.96486449241638 and batch: 1450, loss is 5.5687058162689205 and perplexity is 262.0946809807311
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.678946209768964 and perplexity of 292.64088527433114
Finished 20 epochs...
Completing Train Step...
At time: 218.22362399101257 and batch: 50, loss is 5.676513071060181 and perplexity is 291.9297149474767
At time: 218.58199048042297 and batch: 100, loss is 5.6708833026885985 and perplexity is 290.29083585497074
At time: 218.9246108531952 and batch: 150, loss is 5.652168397903442 and perplexity is 284.9085916877868
At time: 219.26663279533386 and batch: 200, loss is 5.5924910545349125 and perplexity is 268.4033951304675
At time: 219.6101200580597 and batch: 250, loss is 5.602504386901855 and perplexity is 271.1045085381798
At time: 219.9522614479065 and batch: 300, loss is 5.671989583969117 and perplexity is 290.61215687552715
At time: 220.29621863365173 and batch: 350, loss is 5.6903934669494625 and perplexity is 296.01006790833605
At time: 220.63715386390686 and batch: 400, loss is 5.6065013885498045 and perplexity is 272.1902821795621
At time: 220.97874426841736 and batch: 450, loss is 5.631825380325317 and perplexity is 279.1712465155324
At time: 221.3198254108429 and batch: 500, loss is 5.623569898605346 and perplexity is 276.8760404444763
At time: 221.6628110408783 and batch: 550, loss is 5.69234790802002 and perplexity is 296.5891678663865
At time: 222.00520873069763 and batch: 600, loss is 5.5214228916168215 and perplexity is 249.9904936193909
At time: 222.34833121299744 and batch: 650, loss is 5.713445501327515 and perplexity is 302.91295933707005
At time: 222.69022583961487 and batch: 700, loss is 5.686034994125366 and perplexity is 294.72272353732296
At time: 223.03327059745789 and batch: 750, loss is 5.6274743747711184 and perplexity is 277.9592095732186
At time: 223.37743973731995 and batch: 800, loss is 5.5990313529968265 and perplexity is 270.1645865235084
At time: 223.71904039382935 and batch: 850, loss is 5.553872728347779 and perplexity is 258.2356986008858
At time: 224.06006717681885 and batch: 900, loss is 5.548488006591797 and perplexity is 256.848908307248
At time: 224.4158284664154 and batch: 950, loss is 5.590510635375977 and perplexity is 267.8723699042531
At time: 224.75842595100403 and batch: 1000, loss is 5.655244274139404 and perplexity is 285.78628439946925
At time: 225.10006952285767 and batch: 1050, loss is 5.5109172058105464 and perplexity is 247.37791950922647
At time: 225.4406750202179 and batch: 1100, loss is 5.603131046295166 and perplexity is 271.27445196778604
At time: 225.78318047523499 and batch: 1150, loss is 5.612340831756592 and perplexity is 273.7843716414805
At time: 226.12593960762024 and batch: 1200, loss is 5.591113729476929 and perplexity is 268.0339708757485
At time: 226.46792483329773 and batch: 1250, loss is 5.611017789840698 and perplexity is 273.42238295778617
At time: 226.81052780151367 and batch: 1300, loss is 5.680569639205933 and perplexity is 293.11635294162437
At time: 227.15157413482666 and batch: 1350, loss is 5.600121097564697 and perplexity is 270.4591573884521
At time: 227.4942569732666 and batch: 1400, loss is 5.500050592422485 and perplexity is 244.7043121349974
At time: 227.83662509918213 and batch: 1450, loss is 5.563276472091675 and perplexity is 260.6755347534191
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.6745177700988245 and perplexity of 291.34780803935877
Finished 21 epochs...
Completing Train Step...
At time: 229.0848639011383 and batch: 50, loss is 5.672289619445801 and perplexity is 290.699363914494
At time: 229.42770886421204 and batch: 100, loss is 5.665116643905639 and perplexity is 288.62164510916483
At time: 229.7699372768402 and batch: 150, loss is 5.644120807647705 and perplexity is 282.6249652511372
At time: 230.11174321174622 and batch: 200, loss is 5.585514392852783 and perplexity is 266.53735239168816
At time: 230.45482540130615 and batch: 250, loss is 5.59723370552063 and perplexity is 269.6793620982867
At time: 230.79699659347534 and batch: 300, loss is 5.6631685256958 and perplexity is 288.05992335441584
At time: 231.1390290260315 and batch: 350, loss is 5.682691068649292 and perplexity is 293.73883864938284
At time: 231.4818320274353 and batch: 400, loss is 5.599556722640991 and perplexity is 270.30656008723093
At time: 231.82423496246338 and batch: 450, loss is 5.622915506362915 and perplexity is 276.6949141817685
At time: 232.1670913696289 and batch: 500, loss is 5.614899711608887 and perplexity is 274.48585007069113
At time: 232.5099413394928 and batch: 550, loss is 5.682837429046631 and perplexity is 293.78183352881865
At time: 232.85194492340088 and batch: 600, loss is 5.508618860244751 and perplexity is 246.81001243818835
At time: 233.2102837562561 and batch: 650, loss is 5.702547788619995 and perplexity is 299.6298227624976
At time: 233.55831336975098 and batch: 700, loss is 5.675329627990723 and perplexity is 291.58443709819016
At time: 233.90038132667542 and batch: 750, loss is 5.6141037750244145 and perplexity is 274.2674636630948
At time: 234.24324917793274 and batch: 800, loss is 5.57805911064148 and perplexity is 264.55763007365374
At time: 234.5868582725525 and batch: 850, loss is 5.529786739349365 and perplexity is 252.09014438235252
At time: 234.92987275123596 and batch: 900, loss is 5.523433685302734 and perplexity is 250.4936786566032
At time: 235.27097821235657 and batch: 950, loss is 5.561844301223755 and perplexity is 260.3024700565276
At time: 235.6136965751648 and batch: 1000, loss is 5.610509538650513 and perplexity is 273.2834510153779
At time: 235.95642495155334 and batch: 1050, loss is 5.469729776382446 and perplexity is 237.39603407784003
At time: 236.29986310005188 and batch: 1100, loss is 5.566040410995483 and perplexity is 261.397022620078
At time: 236.6416778564453 and batch: 1150, loss is 5.561133460998535 and perplexity is 260.1175023391229
At time: 236.9838411808014 and batch: 1200, loss is 5.535889587402344 and perplexity is 253.63331631148765
At time: 237.32669043540955 and batch: 1250, loss is 5.544926509857178 and perplexity is 255.9357687959231
At time: 237.67023158073425 and batch: 1300, loss is 5.624600667953491 and perplexity is 277.1615829191352
At time: 238.01336479187012 and batch: 1350, loss is 5.544547681808472 and perplexity is 255.83883151047658
At time: 238.35585832595825 and batch: 1400, loss is 5.428063297271729 and perplexity is 227.70781575493737
At time: 238.69754838943481 and batch: 1450, loss is 5.497948827743531 and perplexity is 244.19054135672982
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.611076159354968 and perplexity of 273.4383429552541
Finished 22 epochs...
Completing Train Step...
At time: 239.94482231140137 and batch: 50, loss is 5.611214923858642 and perplexity is 273.4762891239295
At time: 240.28783988952637 and batch: 100, loss is 5.608041982650757 and perplexity is 272.6099401008812
At time: 240.63231682777405 and batch: 150, loss is 5.562659635543823 and perplexity is 260.5147901381258
At time: 240.97528076171875 and batch: 200, loss is 5.5278831958770756 and perplexity is 251.61073626544103
At time: 241.3188967704773 and batch: 250, loss is 5.549608306884766 and perplexity is 257.13681745671323
At time: 241.6613209247589 and batch: 300, loss is 5.606773109436035 and perplexity is 272.2642520133785
At time: 242.00462532043457 and batch: 350, loss is 5.628336791992187 and perplexity is 278.1990297799833
At time: 242.36195516586304 and batch: 400, loss is 5.521263103485108 and perplexity is 249.95055129670882
At time: 242.70419144630432 and batch: 450, loss is 5.5670981693267825 and perplexity is 261.673663782485
At time: 243.0471932888031 and batch: 500, loss is 5.5514023494720455 and perplexity is 257.59854591440376
At time: 243.39087414741516 and batch: 550, loss is 5.616706018447876 and perplexity is 274.9821037972005
At time: 243.73428297042847 and batch: 600, loss is 5.449213962554932 and perplexity is 232.57528116015948
At time: 244.07784008979797 and batch: 650, loss is 5.638671464920044 and perplexity is 281.0890336617408
At time: 244.42101001739502 and batch: 700, loss is 5.617452239990234 and perplexity is 275.18737794728787
At time: 244.76329398155212 and batch: 750, loss is 5.557414836883545 and perplexity is 259.15201936889275
At time: 245.1023395061493 and batch: 800, loss is 5.519647035598755 and perplexity is 249.5469404566823
At time: 245.44165968894958 and batch: 850, loss is 5.473100805282593 and perplexity is 238.1976533512431
At time: 245.786212682724 and batch: 900, loss is 5.452976579666138 and perplexity is 233.45202127702416
At time: 246.1298167705536 and batch: 950, loss is 5.505987310409546 and perplexity is 246.1613734278917
At time: 246.47469782829285 and batch: 1000, loss is 5.571293640136719 and perplexity is 262.7738142113844
At time: 246.81639051437378 and batch: 1050, loss is 5.441069793701172 and perplexity is 230.68884096979332
At time: 247.15810918807983 and batch: 1100, loss is 5.540606441497803 and perplexity is 254.83249360710033
At time: 247.50114703178406 and batch: 1150, loss is 5.535005502700805 and perplexity is 253.40918206816275
At time: 247.8428819179535 and batch: 1200, loss is 5.51076376914978 and perplexity is 247.33996557914628
At time: 248.18572425842285 and batch: 1250, loss is 5.516120471954346 and perplexity is 248.66844723049016
At time: 248.53052163124084 and batch: 1300, loss is 5.601421337127686 and perplexity is 270.8110478064066
At time: 248.87271881103516 and batch: 1350, loss is 5.52289309501648 and perplexity is 250.35830080242664
At time: 249.2137382030487 and batch: 1400, loss is 5.401413497924804 and perplexity is 221.71959500067587
At time: 249.55521750450134 and batch: 1450, loss is 5.478914260864258 and perplexity is 239.58643773551424
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.6020977313701925 and perplexity of 270.9942848031888
Finished 23 epochs...
Completing Train Step...
At time: 250.79194283485413 and batch: 50, loss is 5.594455900192261 and perplexity is 268.9312848168545
At time: 251.1497073173523 and batch: 100, loss is 5.5914449119567875 and perplexity is 268.1227537317613
At time: 251.49287915229797 and batch: 150, loss is 5.544234714508057 and perplexity is 255.7587748502493
At time: 251.83480596542358 and batch: 200, loss is 5.513370838165283 and perplexity is 247.9856392318803
At time: 252.17575001716614 and batch: 250, loss is 5.53577880859375 and perplexity is 253.60522067111646
At time: 252.51948952674866 and batch: 300, loss is 5.591891937255859 and perplexity is 268.2426381796303
At time: 252.86182045936584 and batch: 350, loss is 5.615209760665894 and perplexity is 274.57096734425073
At time: 253.20578837394714 and batch: 400, loss is 5.506488838195801 and perplexity is 246.28486116024447
At time: 253.5480182170868 and batch: 450, loss is 5.55280535697937 and perplexity is 257.9602122591697
At time: 253.88986921310425 and batch: 500, loss is 5.53844687461853 and perplexity is 254.28275960147022
At time: 254.2340817451477 and batch: 550, loss is 5.602972097396851 and perplexity is 271.231336619164
At time: 254.5764262676239 and batch: 600, loss is 5.439787187576294 and perplexity is 230.3931477189483
At time: 254.91770601272583 and batch: 650, loss is 5.6263916873931885 and perplexity is 277.6584295002101
At time: 255.2582070827484 and batch: 700, loss is 5.607511930465698 and perplexity is 272.46548089530285
At time: 255.60162377357483 and batch: 750, loss is 5.547869806289673 and perplexity is 256.6901733046007
At time: 255.94366145133972 and batch: 800, loss is 5.508789739608765 and perplexity is 246.8521907797474
At time: 256.2849633693695 and batch: 850, loss is 5.462876319885254 and perplexity is 235.7746132008919
At time: 256.626336812973 and batch: 900, loss is 5.442460556030273 and perplexity is 231.00989752448947
At time: 256.9670515060425 and batch: 950, loss is 5.4950606155395505 and perplexity is 243.4862847658891
At time: 257.3112189769745 and batch: 1000, loss is 5.561966161727906 and perplexity is 260.3341925795824
At time: 257.6534867286682 and batch: 1050, loss is 5.43344973564148 and perplexity is 228.93765913507167
At time: 257.9974162578583 and batch: 1100, loss is 5.531556339263916 and perplexity is 252.5366380213476
At time: 258.34090852737427 and batch: 1150, loss is 5.52718225479126 and perplexity is 251.43443375881384
At time: 258.68402433395386 and batch: 1200, loss is 5.502012405395508 and perplexity is 245.18484743517132
At time: 259.02632546424866 and batch: 1250, loss is 5.507375936508179 and perplexity is 246.50343697973045
At time: 259.36977076530457 and batch: 1300, loss is 5.5919077110290525 and perplexity is 268.2468694115369
At time: 259.7143497467041 and batch: 1350, loss is 5.5143133163452145 and perplexity is 248.21947045889866
At time: 260.0577507019043 and batch: 1400, loss is 5.393879203796387 and perplexity is 220.05537160473162
At time: 260.400475025177 and batch: 1450, loss is 5.471664819717407 and perplexity is 237.8558504301347
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.587144639756945 and perplexity of 266.97222846664124
Finished 24 epochs...
Completing Train Step...
At time: 261.6470618247986 and batch: 50, loss is 5.586251363754273 and perplexity is 266.7338550640429
At time: 262.00458574295044 and batch: 100, loss is 5.583686056137085 and perplexity is 266.05047758537546
At time: 262.3467388153076 and batch: 150, loss is 5.535658521652222 and perplexity is 253.5747171093932
At time: 262.69011878967285 and batch: 200, loss is 5.505681915283203 and perplexity is 246.08620842225025
At time: 263.0336744785309 and batch: 250, loss is 5.527512922286987 and perplexity is 251.517588700925
At time: 263.3771960735321 and batch: 300, loss is 5.584079837799072 and perplexity is 266.15526401474443
At time: 263.7195243835449 and batch: 350, loss is 5.607583208084106 and perplexity is 272.48490227802625
At time: 264.0618727207184 and batch: 400, loss is 5.498227729797363 and perplexity is 244.2586560984698
At time: 264.4060003757477 and batch: 450, loss is 5.545305328369141 and perplexity is 256.03274036917026
At time: 264.7498016357422 and batch: 500, loss is 5.530928697586059 and perplexity is 252.37818523312828
At time: 265.09262800216675 and batch: 550, loss is 5.594350214004517 and perplexity is 268.90286399646754
At time: 265.4365613460541 and batch: 600, loss is 5.433110942840576 and perplexity is 228.860109841614
At time: 265.7803466320038 and batch: 650, loss is 5.61947865486145 and perplexity is 275.7455871330117
At time: 266.1247341632843 and batch: 700, loss is 5.598096342086792 and perplexity is 269.9120977458795
At time: 266.46736335754395 and batch: 750, loss is 5.541150865554809 and perplexity is 254.97126831984525
At time: 266.80919671058655 and batch: 800, loss is 5.502053928375244 and perplexity is 245.19502845199463
At time: 267.1528582572937 and batch: 850, loss is 5.45689172744751 and perplexity is 234.36781199839035
At time: 267.49532747268677 and batch: 900, loss is 5.433259859085083 and perplexity is 228.89419336742125
At time: 267.83926582336426 and batch: 950, loss is 5.487947950363159 and perplexity is 241.7605927572579
At time: 268.1814341545105 and batch: 1000, loss is 5.555587711334229 and perplexity is 258.6789484047774
At time: 268.5403151512146 and batch: 1050, loss is 5.42418381690979 and perplexity is 226.82613908491575
At time: 268.8834431171417 and batch: 1100, loss is 5.523602905273438 and perplexity is 250.53607077626236
At time: 269.22678899765015 and batch: 1150, loss is 5.5196715831756595 and perplexity is 249.5530663045815
At time: 269.5702440738678 and batch: 1200, loss is 5.494694423675537 and perplexity is 243.3971383927435
At time: 269.91362833976746 and batch: 1250, loss is 5.498990707397461 and perplexity is 244.445091095522
At time: 270.2576277256012 and batch: 1300, loss is 5.58446005821228 and perplexity is 266.25648092035317
At time: 270.60081696510315 and batch: 1350, loss is 5.507174892425537 and perplexity is 246.453883903718
At time: 270.9440302848816 and batch: 1400, loss is 5.38591402053833 and perplexity is 218.30955235825448
At time: 271.28786063194275 and batch: 1450, loss is 5.462863101959228 and perplexity is 235.7714967700923
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.580504849425748 and perplexity of 265.2054608196655
Finished 25 epochs...
Completing Train Step...
At time: 272.531445980072 and batch: 50, loss is 5.579710988998413 and perplexity is 264.99500824524563
At time: 272.8748707771301 and batch: 100, loss is 5.577354793548584 and perplexity is 264.37136321590276
At time: 273.2181007862091 and batch: 150, loss is 5.5305854606628415 and perplexity is 252.29157458617783
At time: 273.56310987472534 and batch: 200, loss is 5.499175319671631 and perplexity is 244.49022282550632
At time: 273.90529918670654 and batch: 250, loss is 5.519673938751221 and perplexity is 249.55365414637808
At time: 274.24873399734497 and batch: 300, loss is 5.578191833496094 and perplexity is 264.5927452477686
At time: 274.59237241744995 and batch: 350, loss is 5.60165002822876 and perplexity is 270.87298696530974
At time: 274.9344973564148 and batch: 400, loss is 5.4924083423614505 and perplexity is 242.84134827551676
At time: 275.27673411369324 and batch: 450, loss is 5.53868335723877 and perplexity is 254.34290016556142
At time: 275.61752438545227 and batch: 500, loss is 5.524374074935913 and perplexity is 250.72935110978693
At time: 275.96186661720276 and batch: 550, loss is 5.588434791564941 and perplexity is 267.31688545199216
At time: 276.30529952049255 and batch: 600, loss is 5.4275743198394775 and perplexity is 227.5964989897969
At time: 276.64850187301636 and batch: 650, loss is 5.611207609176636 and perplexity is 273.4742887391543
At time: 276.9909574985504 and batch: 700, loss is 5.590612773895264 and perplexity is 267.8997313887799
At time: 277.3492681980133 and batch: 750, loss is 5.535645866394043 and perplexity is 253.5715080761863
At time: 277.6915080547333 and batch: 800, loss is 5.4972440624237064 and perplexity is 244.01850496151584
At time: 278.033127784729 and batch: 850, loss is 5.451161508560181 and perplexity is 233.02867357789114
At time: 278.37536907196045 and batch: 900, loss is 5.427022829055786 and perplexity is 227.4710162226787
At time: 278.71734976768494 and batch: 950, loss is 5.482625370025635 and perplexity is 240.4772210342198
At time: 279.05915999412537 and batch: 1000, loss is 5.5499445247650145 and perplexity is 257.223285987731
At time: 279.40042519569397 and batch: 1050, loss is 5.419755373001099 and perplexity is 225.82387312820094
At time: 279.74108719825745 and batch: 1100, loss is 5.519199934005737 and perplexity is 249.4353925605506
At time: 280.08294343948364 and batch: 1150, loss is 5.51403130531311 and perplexity is 248.14947969939314
At time: 280.4255647659302 and batch: 1200, loss is 5.489908208847046 and perplexity is 242.23497081017706
At time: 280.7679617404938 and batch: 1250, loss is 5.494600219726562 and perplexity is 243.37421050110365
At time: 281.11072635650635 and batch: 1300, loss is 5.578339252471924 and perplexity is 264.63175411453807
At time: 281.4553186893463 and batch: 1350, loss is 5.501157627105713 and perplexity is 244.97535829673603
At time: 281.7988395690918 and batch: 1400, loss is 5.3824100589752195 and perplexity is 217.54594268868073
At time: 282.14074206352234 and batch: 1450, loss is 5.458191928863525 and perplexity is 234.67273554747746
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.5765073075253735 and perplexity of 264.1474070938862
Finished 26 epochs...
Completing Train Step...
At time: 283.41029834747314 and batch: 50, loss is 5.573915243148804 and perplexity is 263.463606620079
At time: 283.7513527870178 and batch: 100, loss is 5.572556533813477 and perplexity is 263.1058792370459
At time: 284.0937170982361 and batch: 150, loss is 5.525402555465698 and perplexity is 250.9873540183906
At time: 284.4376964569092 and batch: 200, loss is 5.493965444564819 and perplexity is 243.21977161943747
At time: 284.78042340278625 and batch: 250, loss is 5.512376546859741 and perplexity is 247.73919180746196
At time: 285.12191247940063 and batch: 300, loss is 5.573074150085449 and perplexity is 263.24210237400524
At time: 285.46398997306824 and batch: 350, loss is 5.597276086807251 and perplexity is 269.69079169882656
At time: 285.80750346183777 and batch: 400, loss is 5.486872653961182 and perplexity is 241.5007681809777
At time: 286.1503064632416 and batch: 450, loss is 5.533895111083984 and perplexity is 253.12795480186355
At time: 286.5076310634613 and batch: 500, loss is 5.52010064125061 and perplexity is 249.6601620363095
At time: 286.8514606952667 and batch: 550, loss is 5.582178688049316 and perplexity is 265.6497436883491
At time: 287.1947798728943 and batch: 600, loss is 5.42326358795166 and perplexity is 226.61750311442307
At time: 287.54187774658203 and batch: 650, loss is 5.605399389266967 and perplexity is 271.89049389737954
At time: 287.88336420059204 and batch: 700, loss is 5.585922632217407 and perplexity is 266.6461856445747
At time: 288.22630190849304 and batch: 750, loss is 5.530418519973755 and perplexity is 252.2494603722514
At time: 288.5695674419403 and batch: 800, loss is 5.492378377914429 and perplexity is 242.8340717778204
At time: 288.9129092693329 and batch: 850, loss is 5.444951267242431 and perplexity is 231.58599361304232
At time: 289.25459265708923 and batch: 900, loss is 5.423110389709473 and perplexity is 226.58278837048385
At time: 289.5959599018097 and batch: 950, loss is 5.4808023738861085 and perplexity is 240.03923133669244
At time: 289.9391858577728 and batch: 1000, loss is 5.544485063552856 and perplexity is 255.82281183069617
At time: 290.28305768966675 and batch: 1050, loss is 5.416632061004639 and perplexity is 225.11965503505687
At time: 290.62626004219055 and batch: 1100, loss is 5.515457973480225 and perplexity is 248.50375932240541
At time: 290.9695153236389 and batch: 1150, loss is 5.509981031417847 and perplexity is 247.1464390056288
At time: 291.3117835521698 and batch: 1200, loss is 5.4842104244232175 and perplexity is 240.8586927577877
At time: 291.6557366847992 and batch: 1250, loss is 5.490609827041626 and perplexity is 242.4049869092809
At time: 291.998126745224 and batch: 1300, loss is 5.573696832656861 and perplexity is 263.40606968771164
At time: 292.34071159362793 and batch: 1350, loss is 5.4964331436157225 and perplexity is 243.82070597664415
At time: 292.68331837654114 and batch: 1400, loss is 5.377795886993408 and perplexity is 216.54446057736328
At time: 293.0258057117462 and batch: 1450, loss is 5.454161376953125 and perplexity is 233.72877851671348
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.571329230936165 and perplexity of 262.7831667079361
Finished 27 epochs...
Completing Train Step...
At time: 294.25663352012634 and batch: 50, loss is 5.5690669918060305 and perplexity is 262.18936026479935
At time: 294.6150300502777 and batch: 100, loss is 5.568637437820435 and perplexity is 262.07675996580184
At time: 294.9577479362488 and batch: 150, loss is 5.520643291473388 and perplexity is 249.79567694412935
At time: 295.3156189918518 and batch: 200, loss is 5.489563999176025 and perplexity is 242.15160553895404
At time: 295.65979838371277 and batch: 250, loss is 5.507864294052124 and perplexity is 246.62384819225665
At time: 296.00201416015625 and batch: 300, loss is 5.568885202407837 and perplexity is 262.141701350858
At time: 296.3449914455414 and batch: 350, loss is 5.593882331848144 and perplexity is 268.77707857327835
At time: 296.6878080368042 and batch: 400, loss is 5.482925729751587 and perplexity is 240.54946155495583
At time: 297.03026151657104 and batch: 450, loss is 5.531176233291626 and perplexity is 252.44066557801875
At time: 297.3734405040741 and batch: 500, loss is 5.5162821388244625 and perplexity is 248.7086519298471
At time: 297.7153480052948 and batch: 550, loss is 5.577961902618409 and perplexity is 264.53191419936087
At time: 298.057817697525 and batch: 600, loss is 5.420720090866089 and perplexity is 226.04183457169387
At time: 298.3998327255249 and batch: 650, loss is 5.601191635131836 and perplexity is 270.74884911208284
At time: 298.74381494522095 and batch: 700, loss is 5.582160005569458 and perplexity is 265.6447807387235
At time: 299.08694863319397 and batch: 750, loss is 5.526892032623291 and perplexity is 251.36147250034574
At time: 299.42961835861206 and batch: 800, loss is 5.489069290161133 and perplexity is 242.03184058356752
At time: 299.7723515033722 and batch: 850, loss is 5.440808944702148 and perplexity is 230.62867386414618
At time: 300.1178414821625 and batch: 900, loss is 5.4206163024902345 and perplexity is 226.01837527423072
At time: 300.4600398540497 and batch: 950, loss is 5.478866510391235 and perplexity is 239.5749976429196
At time: 300.80296754837036 and batch: 1000, loss is 5.541086483001709 and perplexity is 254.9548531470546
At time: 301.14714097976685 and batch: 1050, loss is 5.414672327041626 and perplexity is 224.67891241154524
At time: 301.48952746391296 and batch: 1100, loss is 5.512716999053955 and perplexity is 247.82354951797467
At time: 301.83135986328125 and batch: 1150, loss is 5.507344570159912 and perplexity is 246.49570518833676
At time: 302.17354130744934 and batch: 1200, loss is 5.4804372882843015 and perplexity is 239.95161246463013
At time: 302.51606249809265 and batch: 1250, loss is 5.488054580688477 and perplexity is 241.78637314237366
At time: 302.85877799987793 and batch: 1300, loss is 5.570684404373169 and perplexity is 262.61377176278427
At time: 303.20277404785156 and batch: 1350, loss is 5.493528394699097 and perplexity is 243.1134956765452
At time: 303.5450916290283 and batch: 1400, loss is 5.374802913665771 and perplexity is 215.89731770636985
At time: 303.88713908195496 and batch: 1450, loss is 5.451447057723999 and perplexity is 233.09522422206518
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.568897214710203 and perplexity of 262.1448502951504
Finished 28 epochs...
Completing Train Step...
At time: 305.1171054840088 and batch: 50, loss is 5.565928888320923 and perplexity is 261.36787255047045
At time: 305.47312092781067 and batch: 100, loss is 5.5653098487854 and perplexity is 261.20612557309835
At time: 305.81611490249634 and batch: 150, loss is 5.51761794090271 and perplexity is 249.04109945658766
At time: 306.1605579853058 and batch: 200, loss is 5.486113977432251 and perplexity is 241.31761670158934
At time: 306.50245332717896 and batch: 250, loss is 5.505242710113525 and perplexity is 245.97814981901044
At time: 306.8442599773407 and batch: 300, loss is 5.5661931896209715 and perplexity is 261.4369615487303
At time: 307.1868634223938 and batch: 350, loss is 5.591719045639038 and perplexity is 268.19626528507285
At time: 307.52960872650146 and batch: 400, loss is 5.479971523284912 and perplexity is 239.83987742515234
At time: 307.8716604709625 and batch: 450, loss is 5.52854022026062 and perplexity is 251.77610497401702
At time: 308.21291995048523 and batch: 500, loss is 5.514028301239014 and perplexity is 248.1487342410889
At time: 308.5565299987793 and batch: 550, loss is 5.575265865325928 and perplexity is 263.81968682082373
At time: 308.89944410324097 and batch: 600, loss is 5.417997074127197 and perplexity is 225.42715614210258
At time: 309.2415840625763 and batch: 650, loss is 5.597511186599731 and perplexity is 269.7542034017357
At time: 309.5832233428955 and batch: 700, loss is 5.578617248535156 and perplexity is 264.7053309269465
At time: 309.9254198074341 and batch: 750, loss is 5.523778648376465 and perplexity is 250.58010463197058
At time: 310.2681267261505 and batch: 800, loss is 5.4867080974578855 and perplexity is 241.4610309286237
At time: 310.6112160682678 and batch: 850, loss is 5.438536920547485 and perplexity is 230.10527475922638
At time: 310.95306849479675 and batch: 900, loss is 5.418374795913696 and perplexity is 225.5123209735394
At time: 311.2946984767914 and batch: 950, loss is 5.47726450920105 and perplexity is 239.19150547103143
At time: 311.6371319293976 and batch: 1000, loss is 5.538492126464844 and perplexity is 254.294266626183
At time: 311.9793212413788 and batch: 1050, loss is 5.411703214645386 and perplexity is 224.012804831014
At time: 312.3223271369934 and batch: 1100, loss is 5.510759115219116 and perplexity is 247.33881447877462
At time: 312.6795573234558 and batch: 1150, loss is 5.505277137756348 and perplexity is 245.98661841267065
At time: 313.02148246765137 and batch: 1200, loss is 5.478381481170654 and perplexity is 239.4588249443964
At time: 313.3642723560333 and batch: 1250, loss is 5.485865831375122 and perplexity is 241.2577421156175
At time: 313.7074761390686 and batch: 1300, loss is 5.567959718704223 and perplexity is 261.8992057084114
At time: 314.04957032203674 and batch: 1350, loss is 5.491193752288819 and perplexity is 242.5465746354835
At time: 314.3941469192505 and batch: 1400, loss is 5.371559076309204 and perplexity is 215.19811658248466
At time: 314.73810362815857 and batch: 1450, loss is 5.448670558929443 and perplexity is 232.4489332412456
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.568851829594017 and perplexity of 262.1329530906422
Finished 29 epochs...
Completing Train Step...
At time: 315.9821734428406 and batch: 50, loss is 5.563747148513794 and perplexity is 260.79825746052757
At time: 316.3243091106415 and batch: 100, loss is 5.562804307937622 and perplexity is 260.55248216286714
At time: 316.6669216156006 and batch: 150, loss is 5.514576625823975 and perplexity is 248.2848376038001
At time: 317.0111827850342 and batch: 200, loss is 5.484162063598633 and perplexity is 240.8470449144494
At time: 317.3550224304199 and batch: 250, loss is 5.5023977661132815 and perplexity is 245.27935025163322
At time: 317.6964120864868 and batch: 300, loss is 5.5637124824523925 and perplexity is 260.7892167688244
At time: 318.03933119773865 and batch: 350, loss is 5.589725599288941 and perplexity is 267.66216294797715
At time: 318.3812665939331 and batch: 400, loss is 5.477871637344361 and perplexity is 239.33676945810905
At time: 318.7236399650574 and batch: 450, loss is 5.526591711044311 and perplexity is 251.28599456042411
At time: 319.06547594070435 and batch: 500, loss is 5.512551507949829 and perplexity is 247.7825403185589
At time: 319.4081244468689 and batch: 550, loss is 5.572953109741211 and perplexity is 263.2102413875872
At time: 319.7504403591156 and batch: 600, loss is 5.415466585159302 and perplexity is 224.85743634925691
At time: 320.09329319000244 and batch: 650, loss is 5.59436954498291 and perplexity is 268.90806220216433
At time: 320.43705201148987 and batch: 700, loss is 5.575794944763183 and perplexity is 263.9593053236463
At time: 320.77881264686584 and batch: 750, loss is 5.521480312347412 and perplexity is 250.00484866831005
At time: 321.1208782196045 and batch: 800, loss is 5.484230451583862 and perplexity is 240.8635165218232
At time: 321.47761368751526 and batch: 850, loss is 5.436756362915039 and perplexity is 229.69592360080253
At time: 321.81969261169434 and batch: 900, loss is 5.416245279312133 and perplexity is 225.03259971065435
At time: 322.16565132141113 and batch: 950, loss is 5.475501146316528 and perplexity is 238.770095706356
At time: 322.508633852005 and batch: 1000, loss is 5.535794000625611 and perplexity is 253.6090734789749
At time: 322.85156989097595 and batch: 1050, loss is 5.409041147232056 and perplexity is 223.41726068413672
At time: 323.1947886943817 and batch: 1100, loss is 5.508123950958252 and perplexity is 246.68789409227603
At time: 323.5421152114868 and batch: 1150, loss is 5.5023894786834715 and perplexity is 245.27731752465724
At time: 323.88451051712036 and batch: 1200, loss is 5.4755096530914305 and perplexity is 238.77212687845292
At time: 324.22722721099854 and batch: 1250, loss is 5.4841061782836915 and perplexity is 240.8335854775877
At time: 324.56917667388916 and batch: 1300, loss is 5.565993947982788 and perplexity is 261.3848776090466
At time: 324.911838054657 and batch: 1350, loss is 5.489503002166748 and perplexity is 242.13683546569422
At time: 325.2553131580353 and batch: 1400, loss is 5.368355083465576 and perplexity is 214.50972674394308
At time: 325.5968768596649 and batch: 1450, loss is 5.445642175674439 and perplexity is 231.74605361580007
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.566330086471688 and perplexity of 261.47275389530114
Finished 30 epochs...
Completing Train Step...
At time: 326.8407483100891 and batch: 50, loss is 5.56196099281311 and perplexity is 260.3328469378003
At time: 327.1847155094147 and batch: 100, loss is 5.561139993667602 and perplexity is 260.1192016062346
At time: 327.5279314517975 and batch: 150, loss is 5.511927967071533 and perplexity is 247.62808593505758
At time: 327.86982440948486 and batch: 200, loss is 5.482170734405518 and perplexity is 240.36791637248996
At time: 328.21348333358765 and batch: 250, loss is 5.499761161804199 and perplexity is 244.63349746310033
At time: 328.5566084384918 and batch: 300, loss is 5.5602376174926755 and perplexity is 259.8845821095067
At time: 328.899090051651 and batch: 350, loss is 5.587679233551025 and perplexity is 267.114988319037
At time: 329.24343824386597 and batch: 400, loss is 5.476252593994141 and perplexity is 238.94958637073316
At time: 329.5847759246826 and batch: 450, loss is 5.524995012283325 and perplexity is 250.88508667399356
At time: 329.92488622665405 and batch: 500, loss is 5.509408435821533 and perplexity is 247.0049645506999
At time: 330.2682909965515 and batch: 550, loss is 5.570530443191529 and perplexity is 262.5733425485134
At time: 330.630175113678 and batch: 600, loss is 5.413252210617065 and perplexity is 224.3600686489943
At time: 330.97204661369324 and batch: 650, loss is 5.590765180587769 and perplexity is 267.9405642122827
At time: 331.3140745162964 and batch: 700, loss is 5.5739655113220214 and perplexity is 263.4768507871704
At time: 331.6556475162506 and batch: 750, loss is 5.519056987762451 and perplexity is 249.39973925655522
At time: 331.9982113838196 and batch: 800, loss is 5.480893497467041 and perplexity is 240.0611055676301
At time: 332.3392643928528 and batch: 850, loss is 5.434665603637695 and perplexity is 229.2161863998231
At time: 332.6810259819031 and batch: 900, loss is 5.413527784347534 and perplexity is 224.4219049099133
At time: 333.02236580848694 and batch: 950, loss is 5.472901210784912 and perplexity is 238.1501151546128
At time: 333.3651399612427 and batch: 1000, loss is 5.532320222854614 and perplexity is 252.72962031380146
At time: 333.7058641910553 and batch: 1050, loss is 5.40701379776001 and perplexity is 222.9647746472887
At time: 334.0488142967224 and batch: 1100, loss is 5.5061161327362065 and perplexity is 246.19308655138587
At time: 334.3913917541504 and batch: 1150, loss is 5.500682611465454 and perplexity is 244.85901880379382
At time: 334.73429346084595 and batch: 1200, loss is 5.473299598693847 and perplexity is 238.24501018226258
At time: 335.0766661167145 and batch: 1250, loss is 5.481865243911743 and perplexity is 240.29449747398854
At time: 335.4179241657257 and batch: 1300, loss is 5.56309513092041 and perplexity is 260.62826783247573
At time: 335.76269817352295 and batch: 1350, loss is 5.486635160446167 and perplexity is 241.44342012482886
At time: 336.10652899742126 and batch: 1400, loss is 5.365448274612427 and perplexity is 213.88709334770505
At time: 336.44914627075195 and batch: 1450, loss is 5.442795829772949 and perplexity is 231.08736206261494
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.564898107805822 and perplexity of 261.0985984452647
Finished 31 epochs...
Completing Train Step...
At time: 337.69511318206787 and batch: 50, loss is 5.559945793151855 and perplexity is 259.80875252764025
At time: 338.051233291626 and batch: 100, loss is 5.559128541946411 and perplexity is 259.5965102508933
At time: 338.39352440834045 and batch: 150, loss is 5.509940280914306 and perplexity is 247.1363678689944
At time: 338.73684883117676 and batch: 200, loss is 5.479629049301147 and perplexity is 239.75775257048062
At time: 339.07899260520935 and batch: 250, loss is 5.497240152359009 and perplexity is 244.01755083523932
At time: 339.44066047668457 and batch: 300, loss is 5.557637004852295 and perplexity is 259.2096010427983
At time: 339.78261256217957 and batch: 350, loss is 5.585678930282593 and perplexity is 266.5812113707219
At time: 340.1255130767822 and batch: 400, loss is 5.473922662734985 and perplexity is 238.3934983350982
At time: 340.46812415122986 and batch: 450, loss is 5.523415651321411 and perplexity is 250.4891612990138
At time: 340.81116008758545 and batch: 500, loss is 5.506952857971191 and perplexity is 246.39916872463624
At time: 341.1530601978302 and batch: 550, loss is 5.569235334396362 and perplexity is 262.2335016161942
At time: 341.4950280189514 and batch: 600, loss is 5.411060781478882 and perplexity is 223.86893779289537
At time: 341.8366074562073 and batch: 650, loss is 5.588863458633423 and perplexity is 267.43149996161236
At time: 342.1789405345917 and batch: 700, loss is 5.573115339279175 and perplexity is 263.2529453272615
At time: 342.52143144607544 and batch: 750, loss is 5.517427864074707 and perplexity is 248.99376701290356
At time: 342.86366629600525 and batch: 800, loss is 5.479115896224975 and perplexity is 239.6347517040486
At time: 343.2068998813629 and batch: 850, loss is 5.433466272354126 and perplexity is 228.94144504265785
At time: 343.55006861686707 and batch: 900, loss is 5.411365795135498 and perplexity is 223.9372312909097
At time: 343.89224219322205 and batch: 950, loss is 5.469543323516846 and perplexity is 237.35177503324513
At time: 344.23547077178955 and batch: 1000, loss is 5.530225973129273 and perplexity is 252.20089521031883
At time: 344.57697439193726 and batch: 1050, loss is 5.405372724533081 and perplexity is 222.5991731964939
At time: 344.9209942817688 and batch: 1100, loss is 5.5049642562866214 and perplexity is 245.9096657971201
At time: 345.2640450000763 and batch: 1150, loss is 5.49942910194397 and perplexity is 244.55227798373616
At time: 345.6064484119415 and batch: 1200, loss is 5.471704053878784 and perplexity is 237.8651826880253
At time: 345.94893169403076 and batch: 1250, loss is 5.479755468368531 and perplexity is 239.78806443791711
At time: 346.29255056381226 and batch: 1300, loss is 5.561242122650146 and perplexity is 260.14576867224537
At time: 346.6330966949463 and batch: 1350, loss is 5.484735918045044 and perplexity is 240.98529572620626
At time: 346.9747278690338 and batch: 1400, loss is 5.363183155059814 and perplexity is 213.40316179883004
At time: 347.317519903183 and batch: 1450, loss is 5.440702562332153 and perplexity is 230.60414034422186
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.563236595219017 and perplexity of 260.6651400355704
Finished 32 epochs...
Completing Train Step...
At time: 348.5504050254822 and batch: 50, loss is 5.558460397720337 and perplexity is 259.423120272667
At time: 348.90664052963257 and batch: 100, loss is 5.55749433517456 and perplexity is 259.17262233048496
At time: 349.24856305122375 and batch: 150, loss is 5.507868061065674 and perplexity is 246.6247772293844
At time: 349.5903232097626 and batch: 200, loss is 5.477842407226563 and perplexity is 239.329773718388
At time: 349.93277764320374 and batch: 250, loss is 5.494918756484985 and perplexity is 243.45174648157467
At time: 350.2772834300995 and batch: 300, loss is 5.555623140335083 and perplexity is 258.688113303812
At time: 350.6204261779785 and batch: 350, loss is 5.584123554229737 and perplexity is 266.1668996272217
At time: 350.9633116722107 and batch: 400, loss is 5.4724064064025875 and perplexity is 238.03230658248557
At time: 351.3062677383423 and batch: 450, loss is 5.52165771484375 and perplexity is 250.04920408682491
At time: 351.64740467071533 and batch: 500, loss is 5.505267448425293 and perplexity is 245.98423497843675
At time: 351.9914131164551 and batch: 550, loss is 5.567571239471436 and perplexity is 261.79748306575647
At time: 352.3328914642334 and batch: 600, loss is 5.409628381729126 and perplexity is 223.54849753648347
At time: 352.6746115684509 and batch: 650, loss is 5.587095022201538 and perplexity is 266.95898228592756
At time: 353.01546025276184 and batch: 700, loss is 5.572379884719848 and perplexity is 263.05940592680525
At time: 353.3581614494324 and batch: 750, loss is 5.515802812576294 and perplexity is 248.58946791112675
At time: 353.7014796733856 and batch: 800, loss is 5.477619533538818 and perplexity is 239.27643935276652
At time: 354.0441689491272 and batch: 850, loss is 5.432120447158813 and perplexity is 228.63353711926345
At time: 354.3884837627411 and batch: 900, loss is 5.409176940917969 and perplexity is 223.44760139745355
At time: 354.7309572696686 and batch: 950, loss is 5.4663558769226075 and perplexity is 236.59643337139363
At time: 355.07587218284607 and batch: 1000, loss is 5.528691701889038 and perplexity is 251.81424731725437
At time: 355.41997146606445 and batch: 1050, loss is 5.404105806350708 and perplexity is 222.31733682609863
At time: 355.7623131275177 and batch: 1100, loss is 5.5039551639556885 and perplexity is 245.6616453980492
At time: 356.1051068305969 and batch: 1150, loss is 5.498121490478516 and perplexity is 244.232707603623
At time: 356.4482159614563 and batch: 1200, loss is 5.469766893386841 and perplexity is 237.4048456710091
At time: 356.80444264411926 and batch: 1250, loss is 5.477939672470093 and perplexity is 239.35305331924246
At time: 357.1456468105316 and batch: 1300, loss is 5.560014610290527 and perplexity is 259.8266324378062
At time: 357.48834252357483 and batch: 1350, loss is 5.482623691558838 and perplexity is 240.47681740152768
At time: 357.8308758735657 and batch: 1400, loss is 5.360733222961426 and perplexity is 212.88097846088795
At time: 358.17346262931824 and batch: 1450, loss is 5.4393789577484135 and perplexity is 230.29911355899054
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.562195345886752 and perplexity of 260.3938638901261
Finished 33 epochs...
Completing Train Step...
At time: 359.42296838760376 and batch: 50, loss is 5.557553672790528 and perplexity is 259.1880014722944
At time: 359.76398849487305 and batch: 100, loss is 5.556354398727417 and perplexity is 258.87735033981517
At time: 360.10708808898926 and batch: 150, loss is 5.506412076950073 and perplexity is 246.26595675307013
At time: 360.4495906829834 and batch: 200, loss is 5.4770675373077395 and perplexity is 239.1443961070976
At time: 360.79384994506836 and batch: 250, loss is 5.492786893844604 and perplexity is 242.9332936300047
At time: 361.1346790790558 and batch: 300, loss is 5.554071598052978 and perplexity is 258.28705896497956
At time: 361.4780716896057 and batch: 350, loss is 5.582397727966309 and perplexity is 265.7079379593572
At time: 361.82020449638367 and batch: 400, loss is 5.470950632095337 and perplexity is 237.68603737233045
At time: 362.1622226238251 and batch: 450, loss is 5.520319805145264 and perplexity is 249.71488452613923
At time: 362.50297951698303 and batch: 500, loss is 5.503635864257813 and perplexity is 245.58321823044574
At time: 362.8450918197632 and batch: 550, loss is 5.565808544158935 and perplexity is 261.33642034546045
At time: 363.18812346458435 and batch: 600, loss is 5.408030071258545 and perplexity is 223.1914830182119
At time: 363.5310730934143 and batch: 650, loss is 5.58509596824646 and perplexity is 266.425849934256
At time: 363.87194561958313 and batch: 700, loss is 5.571722202301025 and perplexity is 262.88645326061925
At time: 364.2129154205322 and batch: 750, loss is 5.513575391769409 and perplexity is 248.03637077663998
At time: 364.5548985004425 and batch: 800, loss is 5.475685367584228 and perplexity is 238.81408628795185
At time: 364.89848470687866 and batch: 850, loss is 5.430721225738526 and perplexity is 228.31385188410167
At time: 365.2400093078613 and batch: 900, loss is 5.406411094665527 and perplexity is 222.83043357560453
At time: 365.5955300331116 and batch: 950, loss is 5.4636381816864015 and perplexity is 235.95430931548097
At time: 365.93750643730164 and batch: 1000, loss is 5.527320346832275 and perplexity is 251.4691572504169
At time: 366.27980065345764 and batch: 1050, loss is 5.402222499847412 and perplexity is 221.89903915485723
At time: 366.62360286712646 and batch: 1100, loss is 5.502432146072388 and perplexity is 245.28778309062398
At time: 366.96461272239685 and batch: 1150, loss is 5.496698026657104 and perplexity is 243.88529850114963
At time: 367.30654883384705 and batch: 1200, loss is 5.468523969650269 and perplexity is 237.10995285575126
At time: 367.6495409011841 and batch: 1250, loss is 5.475758590698242 and perplexity is 238.8315736392516
At time: 367.9926314353943 and batch: 1300, loss is 5.557786102294922 and perplexity is 259.2482514126822
At time: 368.3336088657379 and batch: 1350, loss is 5.47984787940979 and perplexity is 239.81022452653602
At time: 368.6748049259186 and batch: 1400, loss is 5.3586137580871585 and perplexity is 212.43026251167464
At time: 369.0179371833801 and batch: 1450, loss is 5.43773736000061 and perplexity is 229.92136519311535
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.559937566773504 and perplexity of 259.8066152513341
Finished 34 epochs...
Completing Train Step...
At time: 370.286306142807 and batch: 50, loss is 5.555393981933594 and perplexity is 258.62883954108275
At time: 370.6273157596588 and batch: 100, loss is 5.55406346321106 and perplexity is 258.2849578491315
At time: 370.977254152298 and batch: 150, loss is 5.503725671768189 and perplexity is 245.60527443825686
At time: 371.31792187690735 and batch: 200, loss is 5.474477090835571 and perplexity is 238.52570703629516
At time: 371.66035056114197 and batch: 250, loss is 5.490105543136597 and perplexity is 242.28277679277087
At time: 372.00266098976135 and batch: 300, loss is 5.55208046913147 and perplexity is 257.7732877938831
At time: 372.34536576271057 and batch: 350, loss is 5.580301027297974 and perplexity is 265.15141158674595
At time: 372.688330411911 and batch: 400, loss is 5.467426261901855 and perplexity is 236.84981822529636
At time: 373.0286531448364 and batch: 450, loss is 5.517534236907959 and perplexity is 249.02025459411738
At time: 373.37182569503784 and batch: 500, loss is 5.500822763442994 and perplexity is 244.89333868444106
At time: 373.7138922214508 and batch: 550, loss is 5.563234615325928 and perplexity is 260.6646239469719
At time: 374.0570960044861 and batch: 600, loss is 5.405241670608521 and perplexity is 222.57000261274405
At time: 374.39962887763977 and batch: 650, loss is 5.582678947448731 and perplexity is 265.78267071580655
At time: 374.75556206703186 and batch: 700, loss is 5.570713214874267 and perplexity is 262.6213379061358
At time: 375.09886479377747 and batch: 750, loss is 5.511298122406006 and perplexity is 247.4721678133498
At time: 375.44228434562683 and batch: 800, loss is 5.47383074760437 and perplexity is 238.37158737255086
At time: 375.7841019630432 and batch: 850, loss is 5.428836231231689 and perplexity is 227.88388689559898
At time: 376.1260962486267 and batch: 900, loss is 5.401419019699096 and perplexity is 221.72081928961572
At time: 376.4679911136627 and batch: 950, loss is 5.459991025924682 and perplexity is 235.095314592712
At time: 376.80992341041565 and batch: 1000, loss is 5.524199275970459 and perplexity is 250.6855277088581
At time: 377.1516160964966 and batch: 1050, loss is 5.3995262622833256 and perplexity is 221.30155247503043
At time: 377.4949197769165 and batch: 1100, loss is 5.500312013626099 and perplexity is 244.7682913932081
At time: 377.8370819091797 and batch: 1150, loss is 5.493980112075806 and perplexity is 243.22333907427276
At time: 378.1793532371521 and batch: 1200, loss is 5.466885957717896 and perplexity is 236.72188184293282
At time: 378.5215802192688 and batch: 1250, loss is 5.472229175567627 and perplexity is 237.99012365621036
At time: 378.8639316558838 and batch: 1300, loss is 5.554535493850708 and perplexity is 258.406905042138
At time: 379.2057671546936 and batch: 1350, loss is 5.475391960144043 and perplexity is 238.7440267367132
At time: 379.5500180721283 and batch: 1400, loss is 5.355921850204468 and perplexity is 211.859188797265
At time: 379.8919265270233 and batch: 1450, loss is 5.435278224945068 and perplexity is 229.3566521413664
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.556581154847756 and perplexity of 258.9360590194466
Finished 35 epochs...
Completing Train Step...
At time: 381.1251449584961 and batch: 50, loss is 5.5515664863586425 and perplexity is 257.6408308078825
At time: 381.48002886772156 and batch: 100, loss is 5.550267896652222 and perplexity is 257.30647821744367
At time: 381.8230390548706 and batch: 150, loss is 5.4993148517608645 and perplexity is 244.52433943722014
At time: 382.1668109893799 and batch: 200, loss is 5.4711815547943115 and perplexity is 237.74093081141558
At time: 382.5110447406769 and batch: 250, loss is 5.485198230743408 and perplexity is 241.09673204576742
At time: 382.854852437973 and batch: 300, loss is 5.547286653518677 and perplexity is 256.54052735621633
At time: 383.1982834339142 and batch: 350, loss is 5.574800214767456 and perplexity is 263.6968676339504
At time: 383.55898237228394 and batch: 400, loss is 5.4580371379852295 and perplexity is 234.6364131598897
At time: 383.90122389793396 and batch: 450, loss is 5.508609142303467 and perplexity is 246.80761396463316
At time: 384.24276638031006 and batch: 500, loss is 5.491229944229126 and perplexity is 242.55535302548685
At time: 384.5840678215027 and batch: 550, loss is 5.551152257919312 and perplexity is 257.53413074925413
At time: 384.93078660964966 and batch: 600, loss is 5.3852925109863286 and perplexity is 218.17391304110248
At time: 385.273738861084 and batch: 650, loss is 5.559288444519043 and perplexity is 259.63802371969564
At time: 385.6157898902893 and batch: 700, loss is 5.549309883117676 and perplexity is 257.0600931677354
At time: 385.9567940235138 and batch: 750, loss is 5.484172410964966 and perplexity is 240.84953705994704
At time: 386.30135917663574 and batch: 800, loss is 5.4389369010925295 and perplexity is 230.19733080152778
At time: 386.6438970565796 and batch: 850, loss is 5.392001209259033 and perplexity is 219.64249662876338
At time: 386.98717999458313 and batch: 900, loss is 5.361489419937134 and perplexity is 213.04201929460743
At time: 387.3293194770813 and batch: 950, loss is 5.415125684738159 and perplexity is 224.78079541871338
At time: 387.6720128059387 and batch: 1000, loss is 5.478413887023926 and perplexity is 239.46658493767615
At time: 388.015508890152 and batch: 1050, loss is 5.353516645431519 and perplexity is 211.35023637792864
At time: 388.35749411582947 and batch: 1100, loss is 5.45198844909668 and perplexity is 233.22145413228114
At time: 388.7000002861023 and batch: 1150, loss is 5.440529832839966 and perplexity is 230.5643116480581
At time: 389.04320335388184 and batch: 1200, loss is 5.408352603912354 and perplexity is 223.26348116979057
At time: 389.38622641563416 and batch: 1250, loss is 5.413512363433838 and perplexity is 224.4184441457703
At time: 389.72914123535156 and batch: 1300, loss is 5.497818107604981 and perplexity is 244.15862282157417
At time: 390.0720751285553 and batch: 1350, loss is 5.407891626358032 and perplexity is 223.160585434406
At time: 390.4139313697815 and batch: 1400, loss is 5.289396409988403 and perplexity is 198.22374342199782
At time: 390.758234500885 and batch: 1450, loss is 5.370977840423584 and perplexity is 215.07307205831185
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.490896893362714 and perplexity of 242.47458320598466
Finished 36 epochs...
Completing Train Step...
At time: 391.98919463157654 and batch: 50, loss is 5.48691219329834 and perplexity is 241.51031715005348
At time: 392.3533217906952 and batch: 100, loss is 5.473675060272217 and perplexity is 238.33447882479203
At time: 392.6957468986511 and batch: 150, loss is 5.419813928604126 and perplexity is 225.83709676842517
At time: 393.0360414981842 and batch: 200, loss is 5.4000234794616695 and perplexity is 221.41161476867924
At time: 393.379656791687 and batch: 250, loss is 5.416733875274658 and perplexity is 225.1425765952524
At time: 393.722891330719 and batch: 300, loss is 5.469259767532349 and perplexity is 237.28448205811722
At time: 394.0652163028717 and batch: 350, loss is 5.501280241012573 and perplexity is 245.00539752407704
At time: 394.407586812973 and batch: 400, loss is 5.385555553436279 and perplexity is 218.23130959023763
At time: 394.75025510787964 and batch: 450, loss is 5.437695484161377 and perplexity is 229.911737244581
At time: 395.0925488471985 and batch: 500, loss is 5.4192929935455325 and perplexity is 225.71948094495036
At time: 395.4356107711792 and batch: 550, loss is 5.484912900924683 and perplexity is 241.02794977220108
At time: 395.77930545806885 and batch: 600, loss is 5.325451250076294 and perplexity is 205.5010719195666
At time: 396.1221237182617 and batch: 650, loss is 5.4988538360595705 and perplexity is 244.41163585844683
At time: 396.4663178920746 and batch: 700, loss is 5.496516456604004 and perplexity is 243.84102025447385
At time: 396.80984926223755 and batch: 750, loss is 5.433193893432617 and perplexity is 228.87909471061198
At time: 397.1530737876892 and batch: 800, loss is 5.384151353836059 and perplexity is 217.92508432357138
At time: 397.49556827545166 and batch: 850, loss is 5.339814319610595 and perplexity is 208.4739971620995
At time: 397.8391091823578 and batch: 900, loss is 5.314852972030639 and perplexity is 203.33461505542272
At time: 398.18295788764954 and batch: 950, loss is 5.369770317077637 and perplexity is 214.81352304000404
At time: 398.5244379043579 and batch: 1000, loss is 5.43384464263916 and perplexity is 229.02808607263674
At time: 398.86726903915405 and batch: 1050, loss is 5.317283430099487 and perplexity is 203.8294123597415
At time: 399.20959424972534 and batch: 1100, loss is 5.415189046859741 and perplexity is 224.79503845803174
At time: 399.55192589759827 and batch: 1150, loss is 5.404997339248657 and perplexity is 222.51562842427109
At time: 399.89481568336487 and batch: 1200, loss is 5.371530752182007 and perplexity is 215.1920213699793
At time: 400.23766684532166 and batch: 1250, loss is 5.37910566329956 and perplexity is 216.8282712047001
At time: 400.57956051826477 and batch: 1300, loss is 5.46417160987854 and perplexity is 236.0802075719808
At time: 400.9220607280731 and batch: 1350, loss is 5.378859920501709 and perplexity is 216.77499376522263
At time: 401.2628481388092 and batch: 1400, loss is 5.261494331359863 and perplexity is 192.7693374410801
At time: 401.6041741371155 and batch: 1450, loss is 5.345244083404541 and perplexity is 209.6090404436844
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.465827094184028 and perplexity of 236.4713583330923
Finished 37 epochs...
Completing Train Step...
At time: 402.85080575942993 and batch: 50, loss is 5.460919532775879 and perplexity is 235.31370357513887
At time: 403.1923141479492 and batch: 100, loss is 5.448362483978271 and perplexity is 232.3773325772392
At time: 403.534414768219 and batch: 150, loss is 5.396239633560181 and perplexity is 220.57541036958438
At time: 403.8775510787964 and batch: 200, loss is 5.3773300743103025 and perplexity is 216.44361491058882
At time: 404.2202043533325 and batch: 250, loss is 5.396425580978393 and perplexity is 220.6164296112566
At time: 404.5614676475525 and batch: 300, loss is 5.447749843597412 and perplexity is 232.23501243968914
At time: 404.9033555984497 and batch: 350, loss is 5.479436092376709 and perplexity is 239.71149411502248
At time: 405.2479317188263 and batch: 400, loss is 5.3651040744781495 and perplexity is 213.81348605000218
At time: 405.5905156135559 and batch: 450, loss is 5.418763246536255 and perplexity is 225.5999383914348
At time: 405.9310507774353 and batch: 500, loss is 5.4005631065368656 and perplexity is 221.5311267138119
At time: 406.27339458465576 and batch: 550, loss is 5.469898796081543 and perplexity is 237.436162075202
At time: 406.6175503730774 and batch: 600, loss is 5.3109136486053465 and perplexity is 202.53518987414137
At time: 406.9598412513733 and batch: 650, loss is 5.4820044803619385 and perplexity is 240.32795755619577
At time: 407.30331587791443 and batch: 700, loss is 5.483023843765259 and perplexity is 240.57306398596126
At time: 407.6460564136505 and batch: 750, loss is 5.4174987316131595 and perplexity is 225.31484419361203
At time: 407.9904601573944 and batch: 800, loss is 5.370521945953369 and perplexity is 214.97504378104094
At time: 408.3335781097412 and batch: 850, loss is 5.32485110282898 and perplexity is 205.37777801788243
At time: 408.67484855651855 and batch: 900, loss is 5.300911178588867 and perplexity is 200.5194357763274
At time: 409.01740431785583 and batch: 950, loss is 5.356284065246582 and perplexity is 211.93594128187047
At time: 409.36048221588135 and batch: 1000, loss is 5.419934701919556 and perplexity is 225.86437351046715
At time: 409.7033612728119 and batch: 1050, loss is 5.306940622329712 and perplexity is 201.73210863085336
At time: 410.0623927116394 and batch: 1100, loss is 5.404392242431641 and perplexity is 222.38102565373603
At time: 410.4053463935852 and batch: 1150, loss is 5.392662267684937 and perplexity is 219.7877411541158
At time: 410.748818397522 and batch: 1200, loss is 5.36019513130188 and perplexity is 212.76645979543463
At time: 411.0924742221832 and batch: 1250, loss is 5.368318519592285 and perplexity is 214.50188358086385
At time: 411.4352374076843 and batch: 1300, loss is 5.452619438171387 and perplexity is 233.36866075982851
At time: 411.77868461608887 and batch: 1350, loss is 5.3696337413787845 and perplexity is 214.78418673633058
At time: 412.1212739944458 and batch: 1400, loss is 5.251038675308227 and perplexity is 190.76430776772472
At time: 412.46481585502625 and batch: 1450, loss is 5.336849088668823 and perplexity is 207.8567392236035
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.457842443743322 and perplexity of 234.59073524806323
Finished 38 epochs...
Completing Train Step...
At time: 413.71449160575867 and batch: 50, loss is 5.451347341537476 and perplexity is 233.07198201404046
At time: 414.055358171463 and batch: 100, loss is 5.438311567306519 and perplexity is 230.0534256321997
At time: 414.3972136974335 and batch: 150, loss is 5.387525396347046 and perplexity is 218.66161466590066
At time: 414.74087476730347 and batch: 200, loss is 5.368585405349731 and perplexity is 214.55913871848745
At time: 415.0853183269501 and batch: 250, loss is 5.387457485198975 and perplexity is 218.64676560882356
At time: 415.42795634269714 and batch: 300, loss is 5.438458309173584 and perplexity is 230.08718657841334
At time: 415.7699785232544 and batch: 350, loss is 5.4706760597229005 and perplexity is 237.6207843119078
At time: 416.11486768722534 and batch: 400, loss is 5.356769533157348 and perplexity is 212.03885435897797
At time: 416.45872020721436 and batch: 450, loss is 5.410679302215576 and perplexity is 223.78355272278145
At time: 416.8032591342926 and batch: 500, loss is 5.391727676391602 and perplexity is 219.58242540295265
At time: 417.145396232605 and batch: 550, loss is 5.462928810119629 and perplexity is 235.7869893904102
At time: 417.48768877983093 and batch: 600, loss is 5.304151563644409 and perplexity is 201.17024983396854
At time: 417.83716773986816 and batch: 650, loss is 5.4743036270141605 and perplexity is 238.4843350440236
At time: 418.1797924041748 and batch: 700, loss is 5.476967525482178 and perplexity is 239.12048003543504
At time: 418.52037477493286 and batch: 750, loss is 5.409801321029663 and perplexity is 223.58716120042067
At time: 418.8772974014282 and batch: 800, loss is 5.362984819412231 and perplexity is 213.36084054158417
At time: 419.2207865715027 and batch: 850, loss is 5.3176302814483645 and perplexity is 203.9001231287132
At time: 419.56735849380493 and batch: 900, loss is 5.293327760696411 and perplexity is 199.00456431075511
At time: 419.9088246822357 and batch: 950, loss is 5.349154396057129 and perplexity is 210.43028193569103
At time: 420.25136280059814 and batch: 1000, loss is 5.413095645904541 and perplexity is 224.3249445290149
At time: 420.59479451179504 and batch: 1050, loss is 5.300833616256714 and perplexity is 200.5038836243849
At time: 420.939334154129 and batch: 1100, loss is 5.398605651855469 and perplexity is 221.09791370848947
At time: 421.2815771102905 and batch: 1150, loss is 5.3857362174987795 and perplexity is 218.27073970688826
At time: 421.62521982192993 and batch: 1200, loss is 5.353731784820557 and perplexity is 211.39571103017505
At time: 421.9673628807068 and batch: 1250, loss is 5.362003746032715 and perplexity is 213.1516205475622
At time: 422.3114697933197 and batch: 1300, loss is 5.446100168228149 and perplexity is 231.85221589161804
At time: 422.6557230949402 and batch: 1350, loss is 5.364091587066651 and perplexity is 213.59711214338046
At time: 422.9969937801361 and batch: 1400, loss is 5.245443286895752 and perplexity is 189.69988806845552
At time: 423.3395001888275 and batch: 1450, loss is 5.331096591949463 and perplexity is 206.66447654448157
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.453429654113248 and perplexity of 233.55781638721174
Finished 39 epochs...
Completing Train Step...
At time: 424.61052799224854 and batch: 50, loss is 5.445424814224243 and perplexity is 231.6956864316493
At time: 424.9670584201813 and batch: 100, loss is 5.432543077468872 and perplexity is 228.7301850036701
At time: 425.3089163303375 and batch: 150, loss is 5.382426719665528 and perplexity is 217.54956718445288
At time: 425.6520562171936 and batch: 200, loss is 5.36276180267334 and perplexity is 213.31326280823217
At time: 425.99602007865906 and batch: 250, loss is 5.381579141616822 and perplexity is 217.36525506728813
At time: 426.3377740383148 and batch: 300, loss is 5.432572221755981 and perplexity is 228.73685127899378
At time: 426.67677187919617 and batch: 350, loss is 5.465012111663818 and perplexity is 236.27871681991627
At time: 427.0162088871002 and batch: 400, loss is 5.351656332015991 and perplexity is 210.95742418799904
At time: 427.3582921028137 and batch: 450, loss is 5.4056743812561034 and perplexity is 222.66633186255004
At time: 427.71306228637695 and batch: 500, loss is 5.385947866439819 and perplexity is 218.31694136690092
At time: 428.0544476509094 and batch: 550, loss is 5.45816743850708 and perplexity is 234.66698839891112
At time: 428.3972010612488 and batch: 600, loss is 5.299464368820191 and perplexity is 200.2295320661669
At time: 428.7388985157013 and batch: 650, loss is 5.469175148010254 and perplexity is 237.26440400815434
At time: 429.08224606513977 and batch: 700, loss is 5.472548112869263 and perplexity is 238.06603968964927
At time: 429.42395544052124 and batch: 750, loss is 5.404640636444092 and perplexity is 222.43627062996777
At time: 429.7664158344269 and batch: 800, loss is 5.357964525222778 and perplexity is 212.2923905642056
At time: 430.10827112197876 and batch: 850, loss is 5.312776956558228 and perplexity is 202.91292711528558
At time: 430.45270133018494 and batch: 900, loss is 5.287989864349365 and perplexity is 197.94512866825082
At time: 430.79468870162964 and batch: 950, loss is 5.3442095756530765 and perplexity is 209.39231039035724
At time: 431.1377878189087 and batch: 1000, loss is 5.40829532623291 and perplexity is 223.2506935219115
At time: 431.48100328445435 and batch: 1050, loss is 5.295766706466675 and perplexity is 199.49051801762343
At time: 431.8241243362427 and batch: 1100, loss is 5.393568696975708 and perplexity is 219.98705351808624
At time: 432.1667306423187 and batch: 1150, loss is 5.380531339645386 and perplexity is 217.13761860430097
At time: 432.50863242149353 and batch: 1200, loss is 5.348214855194092 and perplexity is 210.232666935213
At time: 432.85159277915955 and batch: 1250, loss is 5.356961307525634 and perplexity is 212.07952187569376
At time: 433.19418454170227 and batch: 1300, loss is 5.4402783203125 and perplexity is 230.506329127263
At time: 433.5373499393463 and batch: 1350, loss is 5.359968852996826 and perplexity is 212.71832080814954
At time: 433.8782706260681 and batch: 1400, loss is 5.241161603927612 and perplexity is 188.88938967546278
At time: 434.22175335884094 and batch: 1450, loss is 5.326410226821899 and perplexity is 205.69823719208006
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.44972163795406 and perplexity of 232.69338388523713
Finished 40 epochs...
Completing Train Step...
At time: 435.45221424102783 and batch: 50, loss is 5.440596265792847 and perplexity is 230.57962922490015
At time: 435.811003446579 and batch: 100, loss is 5.4277987289428715 and perplexity is 227.6475794473163
At time: 436.15300393104553 and batch: 150, loss is 5.3779328918457034 and perplexity is 216.57413025159826
At time: 436.5096335411072 and batch: 200, loss is 5.358219556808471 and perplexity is 212.34653873365508
At time: 436.8510465621948 and batch: 250, loss is 5.376723518371582 and perplexity is 216.3123695584145
At time: 437.19387555122375 and batch: 300, loss is 5.427124004364014 and perplexity is 227.49403183714435
At time: 437.53834867477417 and batch: 350, loss is 5.460165061950684 and perplexity is 235.13623320754849
At time: 437.88125586509705 and batch: 400, loss is 5.34756649017334 and perplexity is 210.09640360671412
At time: 438.22435235977173 and batch: 450, loss is 5.401559991836548 and perplexity is 221.7520779506768
At time: 438.56628012657166 and batch: 500, loss is 5.381222791671753 and perplexity is 217.28781077004015
At time: 438.9074659347534 and batch: 550, loss is 5.453717355728149 and perplexity is 233.62502101513562
At time: 439.2503066062927 and batch: 600, loss is 5.29488395690918 and perplexity is 199.31449555442506
At time: 439.59227681159973 and batch: 650, loss is 5.4645940208435055 and perplexity is 236.17995150525297
At time: 439.9626235961914 and batch: 700, loss is 5.468677825927735 and perplexity is 237.14643651699595
At time: 440.3053321838379 and batch: 750, loss is 5.400461082458496 and perplexity is 221.50852635768857
At time: 440.648090839386 and batch: 800, loss is 5.353484745025635 and perplexity is 211.34349432714217
At time: 440.9907159805298 and batch: 850, loss is 5.308587980270386 and perplexity is 202.06470750137353
At time: 441.33229064941406 and batch: 900, loss is 5.28362530708313 and perplexity is 197.08306844269092
At time: 441.67553973197937 and batch: 950, loss is 5.340298089981079 and perplexity is 208.57487510385508
At time: 442.0184814929962 and batch: 1000, loss is 5.4047102355957035 and perplexity is 222.4517525444491
At time: 442.3636374473572 and batch: 1050, loss is 5.29202971458435 and perplexity is 198.7464147910062
At time: 442.70962023735046 and batch: 1100, loss is 5.389935922622681 and perplexity is 219.18934002591385
At time: 443.0532145500183 and batch: 1150, loss is 5.376873779296875 and perplexity is 216.3448752973266
At time: 443.3965005874634 and batch: 1200, loss is 5.344210529327393 and perplexity is 209.39251008252091
At time: 443.7404794692993 and batch: 1250, loss is 5.353088283538819 and perplexity is 211.25972137862345
At time: 444.08259630203247 and batch: 1300, loss is 5.4364808082580565 and perplexity is 229.63263853901154
At time: 444.4274227619171 and batch: 1350, loss is 5.356831064224243 and perplexity is 212.0519017373153
At time: 444.77192759513855 and batch: 1400, loss is 5.237944259643554 and perplexity is 188.28264405543152
At time: 445.1145033836365 and batch: 1450, loss is 5.323431167602539 and perplexity is 205.08636182117155
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.446954710870727 and perplexity of 232.0504281752359
Finished 41 epochs...
Completing Train Step...
At time: 446.36535000801086 and batch: 50, loss is 5.437287139892578 and perplexity is 229.81787327005975
At time: 446.7093508243561 and batch: 100, loss is 5.424261178970337 and perplexity is 226.84368750120333
At time: 447.05180287361145 and batch: 150, loss is 5.374128065109253 and perplexity is 215.75166886414257
At time: 447.39359855651855 and batch: 200, loss is 5.3539509582519536 and perplexity is 211.44204843132223
At time: 447.73756408691406 and batch: 250, loss is 5.372194681167603 and perplexity is 215.33494102943803
At time: 448.08016538619995 and batch: 300, loss is 5.422598514556885 and perplexity is 226.46683595022608
At time: 448.4232454299927 and batch: 350, loss is 5.45605975151062 and perplexity is 234.17290470875616
At time: 448.7677505016327 and batch: 400, loss is 5.3437653923034665 and perplexity is 209.29932246591818
At time: 449.11020255088806 and batch: 450, loss is 5.397663974761963 and perplexity is 220.88980886688765
At time: 449.45202255249023 and batch: 500, loss is 5.376481428146362 and perplexity is 216.26000878642142
At time: 449.79331851005554 and batch: 550, loss is 5.450059986114502 and perplexity is 232.77212858443255
At time: 450.1367082595825 and batch: 600, loss is 5.2907002162933345 and perplexity is 198.48235734305385
At time: 450.4820692539215 and batch: 650, loss is 5.460740909576416 and perplexity is 235.27167484229398
At time: 450.82495760917664 and batch: 700, loss is 5.465171861648559 and perplexity is 236.31646535640667
At time: 451.16810154914856 and batch: 750, loss is 5.396715297698974 and perplexity is 220.68035513944992
At time: 451.5159113407135 and batch: 800, loss is 5.349091415405273 and perplexity is 210.41702931669826
At time: 451.86026215553284 and batch: 850, loss is 5.304390392303467 and perplexity is 201.21830079272323
At time: 452.2036328315735 and batch: 900, loss is 5.279021558761596 and perplexity is 196.17783293420536
At time: 452.55208468437195 and batch: 950, loss is 5.336416997909546 and perplexity is 207.7669456482156
At time: 452.8964743614197 and batch: 1000, loss is 5.4008755779266355 and perplexity is 221.60035966894898
At time: 453.24321842193604 and batch: 1050, loss is 5.287960090637207 and perplexity is 197.9392351947025
At time: 453.58506774902344 and batch: 1100, loss is 5.386205959320068 and perplexity is 218.37329468698798
At time: 453.9270956516266 and batch: 1150, loss is 5.373046331405639 and perplexity is 215.5184091974886
At time: 454.3007302284241 and batch: 1200, loss is 5.340345973968506 and perplexity is 208.58486273967407
At time: 454.6447801589966 and batch: 1250, loss is 5.348609399795532 and perplexity is 210.31562946413143
At time: 454.9874041080475 and batch: 1300, loss is 5.431880578994751 and perplexity is 228.5787017893595
At time: 455.32922101020813 and batch: 1350, loss is 5.352994775772094 and perplexity is 211.23996787744582
At time: 455.6737611293793 and batch: 1400, loss is 5.2343137836456295 and perplexity is 187.60032775127587
At time: 456.01877069473267 and batch: 1450, loss is 5.3200055027008055 and perplexity is 204.38500665941444
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.443032810830663 and perplexity of 231.142131879549
Finished 42 epochs...
Completing Train Step...
At time: 457.27356338500977 and batch: 50, loss is 5.433104639053345 and perplexity is 228.8586671607229
At time: 457.61750888824463 and batch: 100, loss is 5.420707769393921 and perplexity is 226.03904942067902
At time: 457.96050357818604 and batch: 150, loss is 5.3712771606445315 and perplexity is 215.13745741319883
At time: 458.30306482315063 and batch: 200, loss is 5.3505581092834475 and perplexity is 210.72587311975312
At time: 458.6475508213043 and batch: 250, loss is 5.368704442977905 and perplexity is 214.58468084967078
At time: 458.9913330078125 and batch: 300, loss is 5.419309778213501 and perplexity is 225.72326960328763
At time: 459.3337616920471 and batch: 350, loss is 5.453150138854981 and perplexity is 233.49254253678754
At time: 459.678213596344 and batch: 400, loss is 5.34107087135315 and perplexity is 208.73612017758742
At time: 460.0209403038025 and batch: 450, loss is 5.394847383499146 and perplexity is 220.26852791916036
At time: 460.36435890197754 and batch: 500, loss is 5.373387193679809 and perplexity is 215.59188381422422
At time: 460.7052149772644 and batch: 550, loss is 5.447376670837403 and perplexity is 232.14836482739602
At time: 461.0471887588501 and batch: 600, loss is 5.287858791351319 and perplexity is 197.9191851070749
At time: 461.3899748325348 and batch: 650, loss is 5.457810907363892 and perplexity is 234.58333722227965
At time: 461.7341537475586 and batch: 700, loss is 5.462849807739258 and perplexity is 235.76836239278614
At time: 462.0757465362549 and batch: 750, loss is 5.393875150680542 and perplexity is 220.05447969662575
At time: 462.41760993003845 and batch: 800, loss is 5.346151418685913 and perplexity is 209.79931242856242
At time: 462.75858902931213 and batch: 850, loss is 5.301474008560181 and perplexity is 200.63232589060297
At time: 463.1171612739563 and batch: 900, loss is 5.275754947662353 and perplexity is 195.53804179106243
At time: 463.4583365917206 and batch: 950, loss is 5.333893938064575 and perplexity is 207.24339795934833
At time: 463.80018949508667 and batch: 1000, loss is 5.39836895942688 and perplexity is 221.04558769916719
At time: 464.1413459777832 and batch: 1050, loss is 5.285244703292847 and perplexity is 197.40248257594087
At time: 464.48338532447815 and batch: 1100, loss is 5.383959836959839 and perplexity is 217.88335198852252
At time: 464.8247330188751 and batch: 1150, loss is 5.370750799179077 and perplexity is 215.02424714321623
At time: 465.1683671474457 and batch: 1200, loss is 5.337673625946045 and perplexity is 208.02819552975913
At time: 465.51396799087524 and batch: 1250, loss is 5.345818519592285 and perplexity is 209.72948205149063
At time: 465.8599166870117 and batch: 1300, loss is 5.429010457992554 and perplexity is 227.92359382597053
At time: 466.20481872558594 and batch: 1350, loss is 5.350907011032104 and perplexity is 210.79940857295
At time: 466.5456395149231 and batch: 1400, loss is 5.231903715133667 and perplexity is 187.148742502806
At time: 466.887752532959 and batch: 1450, loss is 5.317662153244019 and perplexity is 203.90662189533455
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.4411720210670405 and perplexity of 230.71242488778128
Finished 43 epochs...
Completing Train Step...
At time: 468.1820592880249 and batch: 50, loss is 5.430522050857544 and perplexity is 228.26838202820298
At time: 468.54381918907166 and batch: 100, loss is 5.418409442901611 and perplexity is 225.52013443155448
At time: 468.93112683296204 and batch: 150, loss is 5.369083852767944 and perplexity is 214.66611182525534
At time: 469.2732129096985 and batch: 200, loss is 5.347634906768799 and perplexity is 210.11077817909117
At time: 469.6158993244171 and batch: 250, loss is 5.365805702209473 and perplexity is 213.96355616166534
At time: 469.958603143692 and batch: 300, loss is 5.4165298366546635 and perplexity is 225.09664350084387
At time: 470.30188608169556 and batch: 350, loss is 5.450523386001587 and perplexity is 232.88002015907617
At time: 470.64662528038025 and batch: 400, loss is 5.338684463500977 and perplexity is 208.23858455893676
At time: 470.98884987831116 and batch: 450, loss is 5.392479991912841 and perplexity is 219.74768282484214
At time: 471.33128213882446 and batch: 500, loss is 5.370351238250732 and perplexity is 214.93834901732137
At time: 471.6717791557312 and batch: 550, loss is 5.445021371841431 and perplexity is 231.6022294253544
At time: 472.0326101779938 and batch: 600, loss is 5.285361452102661 and perplexity is 197.42553042621435
At time: 472.37506198883057 and batch: 650, loss is 5.455395994186401 and perplexity is 234.01752230193222
At time: 472.71670389175415 and batch: 700, loss is 5.460862436294556 and perplexity is 235.30026837421255
At time: 473.0597710609436 and batch: 750, loss is 5.391426095962524 and perplexity is 219.51621362547172
At time: 473.40405774116516 and batch: 800, loss is 5.343815317153931 and perplexity is 209.30977196413724
At time: 473.7487530708313 and batch: 850, loss is 5.2989148426055905 and perplexity is 200.1195309163853
At time: 474.0907244682312 and batch: 900, loss is 5.273159103393555 and perplexity is 195.03111372376344
At time: 474.4362144470215 and batch: 950, loss is 5.331685218811035 and perplexity is 206.7861606164516
At time: 474.78381180763245 and batch: 1000, loss is 5.396368627548218 and perplexity is 220.60386510663636
At time: 475.1268799304962 and batch: 1050, loss is 5.282929906845093 and perplexity is 196.94606447180072
At time: 475.4688196182251 and batch: 1100, loss is 5.38206524848938 and perplexity is 217.4709434974867
At time: 475.8177602291107 and batch: 1150, loss is 5.368728113174439 and perplexity is 214.5897601713536
At time: 476.16653513908386 and batch: 1200, loss is 5.335439186096192 and perplexity is 207.56388796661508
At time: 476.51267194747925 and batch: 1250, loss is 5.343500118255616 and perplexity is 209.2438081510143
At time: 476.8548974990845 and batch: 1300, loss is 5.426592016220093 and perplexity is 227.373039895387
At time: 477.19928097724915 and batch: 1350, loss is 5.349048709869384 and perplexity is 210.40804353657379
At time: 477.5440261363983 and batch: 1400, loss is 5.229769964218139 and perplexity is 186.74983943339248
At time: 477.8910312652588 and batch: 1450, loss is 5.315683727264404 and perplexity is 203.50360653664515
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.4398542876936435 and perplexity of 230.4086076448724
Finished 44 epochs...
Completing Train Step...
At time: 479.1657643318176 and batch: 50, loss is 5.428416528701782 and perplexity is 227.78826351983386
At time: 479.5239300727844 and batch: 100, loss is 5.416250133514405 and perplexity is 225.03369206706225
At time: 479.8655710220337 and batch: 150, loss is 5.367146797180176 and perplexity is 214.2506941073393
At time: 480.20721793174744 and batch: 200, loss is 5.3454290294647215 and perplexity is 209.647810394957
At time: 480.55174589157104 and batch: 250, loss is 5.363163070678711 and perplexity is 213.3988757714411
At time: 480.90863370895386 and batch: 300, loss is 5.414388828277588 and perplexity is 224.615225245614
At time: 481.2506055831909 and batch: 350, loss is 5.448080406188965 and perplexity is 232.31179333699754
At time: 481.5938551425934 and batch: 400, loss is 5.3364459419250485 and perplexity is 207.7729593449412
At time: 481.935400724411 and batch: 450, loss is 5.390293283462524 and perplexity is 219.26768371019892
At time: 482.2763092517853 and batch: 500, loss is 5.367633790969848 and perplexity is 214.35505827509076
At time: 482.6173589229584 and batch: 550, loss is 5.442782020568847 and perplexity is 231.08417095210024
At time: 482.95940017700195 and batch: 600, loss is 5.283006229400635 and perplexity is 196.96109647237824
At time: 483.30406975746155 and batch: 650, loss is 5.45307279586792 and perplexity is 233.47448422444216
At time: 483.64633226394653 and batch: 700, loss is 5.459167699813843 and perplexity is 234.9018341413551
At time: 483.98834776878357 and batch: 750, loss is 5.38895962715149 and perplexity is 218.97545089239847
At time: 484.3316857814789 and batch: 800, loss is 5.341658945083618 and perplexity is 208.85890850722063
At time: 484.6756052970886 and batch: 850, loss is 5.296466302871704 and perplexity is 199.6301296970863
At time: 485.01751470565796 and batch: 900, loss is 5.270189867019654 and perplexity is 194.4528791292749
At time: 485.36080861091614 and batch: 950, loss is 5.328479280471802 and perplexity is 206.12427847967186
At time: 485.70114398002625 and batch: 1000, loss is 5.394587516784668 and perplexity is 220.21129489730794
At time: 486.044353723526 and batch: 1050, loss is 5.280693387985229 and perplexity is 196.50608308097245
At time: 486.3871006965637 and batch: 1100, loss is 5.380309820175171 and perplexity is 217.08952372123716
At time: 486.7305517196655 and batch: 1150, loss is 5.3667685985565186 and perplexity is 214.16968011036698
At time: 487.0729205608368 and batch: 1200, loss is 5.332931632995606 and perplexity is 207.04406251311931
At time: 487.41714668273926 and batch: 1250, loss is 5.341297521591186 and perplexity is 208.78343563073926
At time: 487.763302564621 and batch: 1300, loss is 5.424525775909424 and perplexity is 226.9037175881058
At time: 488.1061565876007 and batch: 1350, loss is 5.346973009109497 and perplexity is 209.97175236232744
At time: 488.44799160957336 and batch: 1400, loss is 5.226440105438233 and perplexity is 186.12902303001692
At time: 488.7911217212677 and batch: 1450, loss is 5.31375093460083 and perplexity is 203.110656127083
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.437934027777778 and perplexity of 229.96658776369668
Finished 45 epochs...
Completing Train Step...
At time: 490.06399750709534 and batch: 50, loss is 5.426595430374146 and perplexity is 227.37381618329783
At time: 490.4070634841919 and batch: 100, loss is 5.413992385864258 and perplexity is 224.52619589231898
At time: 490.7504196166992 and batch: 150, loss is 5.364745016098023 and perplexity is 213.7367283071318
At time: 491.09341073036194 and batch: 200, loss is 5.343061447143555 and perplexity is 209.15203906669555
At time: 491.4364755153656 and batch: 250, loss is 5.360536413192749 and perplexity is 212.83908552736585
At time: 491.7809724807739 and batch: 300, loss is 5.412499313354492 and perplexity is 224.1912121412554
At time: 492.1234664916992 and batch: 350, loss is 5.445495405197144 and perplexity is 231.71204263286472
At time: 492.4677999019623 and batch: 400, loss is 5.33313063621521 and perplexity is 207.08526904814
At time: 492.81161880493164 and batch: 450, loss is 5.387134227752686 and perplexity is 218.5760978362907
At time: 493.1540775299072 and batch: 500, loss is 5.36469633102417 and perplexity is 213.7263227720284
At time: 493.4982144832611 and batch: 550, loss is 5.439873924255371 and perplexity is 230.4131321221415
At time: 493.8403913974762 and batch: 600, loss is 5.280532455444336 and perplexity is 196.474461402268
At time: 494.1851980686188 and batch: 650, loss is 5.450353507995605 and perplexity is 232.84046232571671
At time: 494.5266041755676 and batch: 700, loss is 5.457153272628784 and perplexity is 234.4291177870317
At time: 494.86960458755493 and batch: 750, loss is 5.3861339569091795 and perplexity is 218.3575718493447
At time: 495.2127287387848 and batch: 800, loss is 5.338839111328125 and perplexity is 208.27079069380733
At time: 495.55845308303833 and batch: 850, loss is 5.294015312194825 and perplexity is 199.14143724534173
At time: 495.9008252620697 and batch: 900, loss is 5.267312221527099 and perplexity is 193.89411702334715
At time: 496.24435114860535 and batch: 950, loss is 5.326130924224853 and perplexity is 205.64079316273126
At time: 496.58642530441284 and batch: 1000, loss is 5.392176647186279 and perplexity is 219.68103363343434
At time: 496.9300208091736 and batch: 1050, loss is 5.278574161529541 and perplexity is 196.09008314572986
At time: 497.2740886211395 and batch: 1100, loss is 5.378446989059448 and perplexity is 216.68549903326706
At time: 497.6161961555481 and batch: 1150, loss is 5.364670991897583 and perplexity is 213.72090720229386
At time: 497.9605996608734 and batch: 1200, loss is 5.329867973327636 and perplexity is 206.41072063666624
At time: 498.3026201725006 and batch: 1250, loss is 5.339167375564575 and perplexity is 208.33916976847763
At time: 498.6453547477722 and batch: 1300, loss is 5.422092714309692 and perplexity is 226.3523179326838
At time: 498.9895238876343 and batch: 1350, loss is 5.344581489562988 and perplexity is 209.47020078658304
At time: 499.3319396972656 and batch: 1400, loss is 5.22369912147522 and perplexity is 185.61954491748386
At time: 499.6731834411621 and batch: 1450, loss is 5.31159161567688 and perplexity is 202.67254862079514
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.436117579794337 and perplexity of 229.54924457494286
Finished 46 epochs...
Completing Train Step...
At time: 500.9407866001129 and batch: 50, loss is 5.424720582962036 and perplexity is 226.94792433830935
At time: 501.2814381122589 and batch: 100, loss is 5.411741952896119 and perplexity is 224.02148286329964
At time: 501.6240727901459 and batch: 150, loss is 5.3622920703887935 and perplexity is 213.21308621190187
At time: 501.9658319950104 and batch: 200, loss is 5.340827989578247 and perplexity is 208.68542813456824
At time: 502.30851006507874 and batch: 250, loss is 5.35821650505066 and perplexity is 212.3458907044355
At time: 502.65077471733093 and batch: 300, loss is 5.410356292724609 and perplexity is 223.711280184316
At time: 502.99257707595825 and batch: 350, loss is 5.442950839996338 and perplexity is 231.12318574267718
At time: 503.33615231513977 and batch: 400, loss is 5.3310027503967286 and perplexity is 206.64508373904724
At time: 503.6783814430237 and batch: 450, loss is 5.385153274536133 and perplexity is 218.14353739467307
At time: 504.0191125869751 and batch: 500, loss is 5.362553701400757 and perplexity is 213.26887666534952
At time: 504.3603434562683 and batch: 550, loss is 5.437631196975708 and perplexity is 229.89695734112553
At time: 504.7036612033844 and batch: 600, loss is 5.278029661178589 and perplexity is 195.98334108981962
At time: 505.0463469028473 and batch: 650, loss is 5.448047571182251 and perplexity is 232.30416550293415
At time: 505.387314081192 and batch: 700, loss is 5.455507411956787 and perplexity is 234.04359746508962
At time: 505.72767782211304 and batch: 750, loss is 5.3839208984375 and perplexity is 217.87486809792998
At time: 506.071252822876 and batch: 800, loss is 5.336884727478028 and perplexity is 207.86414712227807
At time: 506.41457772254944 and batch: 850, loss is 5.291673088073731 and perplexity is 198.67554918762866
At time: 506.7560861110687 and batch: 900, loss is 5.264932117462158 and perplexity is 193.43317760673906
At time: 507.0993196964264 and batch: 950, loss is 5.324470958709717 and perplexity is 205.2997197009867
At time: 507.45739674568176 and batch: 1000, loss is 5.390131645202636 and perplexity is 219.2322445275954
At time: 507.7998504638672 and batch: 1050, loss is 5.276829614639282 and perplexity is 195.74829302210094
At time: 508.14117312431335 and batch: 1100, loss is 5.376431331634522 and perplexity is 216.24917518569578
At time: 508.4834215641022 and batch: 1150, loss is 5.362880449295044 and perplexity is 213.33857320769607
At time: 508.8273301124573 and batch: 1200, loss is 5.327640533447266 and perplexity is 205.95146483800735
At time: 509.17167234420776 and batch: 1250, loss is 5.33761884689331 and perplexity is 208.01680025437992
At time: 509.5135817527771 and batch: 1300, loss is 5.42002760887146 and perplexity is 225.8853588557809
At time: 509.8568847179413 and batch: 1350, loss is 5.342179889678955 and perplexity is 208.96774077212427
At time: 510.20096731185913 and batch: 1400, loss is 5.2213989353179935 and perplexity is 185.19307607664817
At time: 510.54418873786926 and batch: 1450, loss is 5.309313621520996 and perplexity is 202.21138720041287
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.435110238882212 and perplexity of 229.31812665634607
Finished 47 epochs...
Completing Train Step...
At time: 511.79341077804565 and batch: 50, loss is 5.423092012405395 and perplexity is 226.57862442794436
At time: 512.150511264801 and batch: 100, loss is 5.409983987808228 and perplexity is 223.62800687734605
At time: 512.49356341362 and batch: 150, loss is 5.360034322738647 and perplexity is 212.73224787758926
At time: 512.8354213237762 and batch: 200, loss is 5.339214086532593 and perplexity is 208.34890172006627
At time: 513.1804583072662 and batch: 250, loss is 5.35644045829773 and perplexity is 211.9690891823585
At time: 513.5239958763123 and batch: 300, loss is 5.408709821701049 and perplexity is 223.34324910324472
At time: 513.8658504486084 and batch: 350, loss is 5.440710649490357 and perplexity is 230.60600528392823
At time: 514.2091290950775 and batch: 400, loss is 5.328841352462769 and perplexity is 206.19892382024568
At time: 514.5513694286346 and batch: 450, loss is 5.383348407745362 and perplexity is 217.7501724608445
At time: 514.8927550315857 and batch: 500, loss is 5.361005392074585 and perplexity is 212.93892597340786
At time: 515.233948469162 and batch: 550, loss is 5.435409383773804 and perplexity is 229.38673626407999
At time: 515.5767459869385 and batch: 600, loss is 5.2758203220367434 and perplexity is 195.55082538606925
At time: 515.9197435379028 and batch: 650, loss is 5.445974225997925 and perplexity is 231.82301774514465
At time: 516.2790238857269 and batch: 700, loss is 5.454049596786499 and perplexity is 233.702653735049
At time: 516.6211817264557 and batch: 750, loss is 5.3821602630615235 and perplexity is 217.49160738780654
At time: 516.9631969928741 and batch: 800, loss is 5.3350320816040036 and perplexity is 207.47940497327767
At time: 517.3063187599182 and batch: 850, loss is 5.289872417449951 and perplexity is 198.31812186356177
At time: 517.6495540142059 and batch: 900, loss is 5.2629814720153805 and perplexity is 193.0562258287451
At time: 517.9908156394958 and batch: 950, loss is 5.322755661010742 and perplexity is 204.94787141273176
At time: 518.3329672813416 and batch: 1000, loss is 5.388636922836303 and perplexity is 218.90479797009021
At time: 518.6751801967621 and batch: 1050, loss is 5.27545280456543 and perplexity is 195.47897024602852
At time: 519.0177993774414 and batch: 1100, loss is 5.374926834106446 and perplexity is 215.92407345487823
At time: 519.3620707988739 and batch: 1150, loss is 5.36131383895874 and perplexity is 213.00461645213062
At time: 519.7033200263977 and batch: 1200, loss is 5.325654783248901 and perplexity is 205.54290246151567
At time: 520.0452444553375 and batch: 1250, loss is 5.336054525375366 and perplexity is 207.6916494841278
At time: 520.3859324455261 and batch: 1300, loss is 5.418219842910767 and perplexity is 225.47737986939143
At time: 520.7297470569611 and batch: 1350, loss is 5.3402631473541256 and perplexity is 208.56758707713453
At time: 521.0737581253052 and batch: 1400, loss is 5.21937520980835 and perplexity is 184.8186750945704
At time: 521.4147431850433 and batch: 1450, loss is 5.307488079071045 and perplexity is 201.84257846963652
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.433615138388087 and perplexity of 228.97552918451328
Finished 48 epochs...
Completing Train Step...
At time: 522.6716451644897 and batch: 50, loss is 5.421590824127197 and perplexity is 226.23874243012722
At time: 523.0282685756683 and batch: 100, loss is 5.40843864440918 and perplexity is 223.2826916970633
At time: 523.3707511425018 and batch: 150, loss is 5.358037948608398 and perplexity is 212.30797836250971
At time: 523.7119414806366 and batch: 200, loss is 5.337600688934327 and perplexity is 208.01302312814556
At time: 524.0540869235992 and batch: 250, loss is 5.355028438568115 and perplexity is 211.6699958588958
At time: 524.3983361721039 and batch: 300, loss is 5.407409553527832 and perplexity is 223.0530317058445
At time: 524.7415070533752 and batch: 350, loss is 5.438823442459107 and perplexity is 230.17121440855064
At time: 525.0848362445831 and batch: 400, loss is 5.327039699554444 and perplexity is 205.8277593845924
At time: 525.4425549507141 and batch: 450, loss is 5.381879024505615 and perplexity is 217.43044896267926
At time: 525.784040927887 and batch: 500, loss is 5.3593559837341305 and perplexity is 212.58799222898344
At time: 526.1251773834229 and batch: 550, loss is 5.433595085144043 and perplexity is 228.9709375283854
At time: 526.4687395095825 and batch: 600, loss is 5.2738433265686036 and perplexity is 195.16460419505793
At time: 526.8138024806976 and batch: 650, loss is 5.444157609939575 and perplexity is 231.40226661575267
At time: 527.1555078029633 and batch: 700, loss is 5.452618207931518 and perplexity is 233.36837366057466
At time: 527.4979753494263 and batch: 750, loss is 5.380903329849243 and perplexity is 217.21840669656848
At time: 527.8407425880432 and batch: 800, loss is 5.333333940505981 and perplexity is 207.1273746518729
At time: 528.18790102005 and batch: 850, loss is 5.288474998474121 and perplexity is 198.04118190246396
At time: 528.5301878452301 and batch: 900, loss is 5.2610891151428225 and perplexity is 192.69124000364354
At time: 528.8747406005859 and batch: 950, loss is 5.3211532402038575 and perplexity is 204.61972166646117
At time: 529.2172355651855 and batch: 1000, loss is 5.387281293869019 and perplexity is 218.60824533796887
At time: 529.5640070438385 and batch: 1050, loss is 5.274228963851929 and perplexity is 195.2398814567474
At time: 529.9045255184174 and batch: 1100, loss is 5.373430747985839 and perplexity is 215.60127397359895
At time: 530.246255159378 and batch: 1150, loss is 5.359961595535278 and perplexity is 212.7167770187177
At time: 530.5885894298553 and batch: 1200, loss is 5.323830966949463 and perplexity is 205.16837160732769
At time: 530.9305131435394 and batch: 1250, loss is 5.334616107940674 and perplexity is 207.3931169531416
At time: 531.2725825309753 and batch: 1300, loss is 5.41660514831543 and perplexity is 225.11359654127165
At time: 531.6142528057098 and batch: 1350, loss is 5.338617000579834 and perplexity is 208.2245366495896
At time: 531.9569413661957 and batch: 1400, loss is 5.217684965133667 and perplexity is 184.50655017126454
At time: 532.2999563217163 and batch: 1450, loss is 5.3058047866821285 and perplexity is 201.50310419093168
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.432273929954594 and perplexity of 228.66863112684396
Finished 49 epochs...
Completing Train Step...
At time: 533.5654904842377 and batch: 50, loss is 5.420147094726563 and perplexity is 225.91235057357108
At time: 533.9075965881348 and batch: 100, loss is 5.407018575668335 and perplexity is 222.9658399550866
At time: 534.2658314704895 and batch: 150, loss is 5.356330471038818 and perplexity is 211.94577656533434
At time: 534.6088283061981 and batch: 200, loss is 5.336062965393066 and perplexity is 207.69340241272292
At time: 534.9517624378204 and batch: 250, loss is 5.353730773925781 and perplexity is 211.39549733146316
At time: 535.2950849533081 and batch: 300, loss is 5.406162252426148 and perplexity is 222.77499085004374
At time: 535.6378746032715 and batch: 350, loss is 5.43708758354187 and perplexity is 229.7720162296265
At time: 535.981205701828 and batch: 400, loss is 5.325524635314942 and perplexity is 205.51615321813736
At time: 536.3240537643433 and batch: 450, loss is 5.380566673278809 and perplexity is 217.14529100086503
At time: 536.6657421588898 and batch: 500, loss is 5.357981157302857 and perplexity is 212.29592145760847
At time: 537.0078930854797 and batch: 550, loss is 5.432120523452759 and perplexity is 228.6335545626187
At time: 537.3509681224823 and batch: 600, loss is 5.272175388336182 and perplexity is 194.8393530149493
At time: 537.6941299438477 and batch: 650, loss is 5.442675676345825 and perplexity is 231.05959779211756
At time: 538.0370860099792 and batch: 700, loss is 5.451503582000733 and perplexity is 233.10840013340038
At time: 538.3784649372101 and batch: 750, loss is 5.379829816818237 and perplexity is 216.98534502615772
At time: 538.7221202850342 and batch: 800, loss is 5.331674356460571 and perplexity is 206.7839144449032
At time: 539.0649929046631 and batch: 850, loss is 5.287168283462524 and perplexity is 197.7825675216032
At time: 539.4083774089813 and batch: 900, loss is 5.2593286418914795 and perplexity is 192.35231065541086
At time: 539.7507965564728 and batch: 950, loss is 5.319645109176636 and perplexity is 204.31136089810192
At time: 540.0920917987823 and batch: 1000, loss is 5.385979642868042 and perplexity is 218.32387880974113
At time: 540.434864282608 and batch: 1050, loss is 5.272955369949341 and perplexity is 194.99138341056985
At time: 540.7778897285461 and batch: 1100, loss is 5.3720990085601805 and perplexity is 215.31434035963625
At time: 541.1197733879089 and batch: 1150, loss is 5.358754320144653 and perplexity is 212.46012424511161
At time: 541.461106300354 and batch: 1200, loss is 5.322299699783326 and perplexity is 204.8544444308853
At time: 541.8030757904053 and batch: 1250, loss is 5.3332937145233155 and perplexity is 207.1190429172678
At time: 542.1489522457123 and batch: 1300, loss is 5.415040454864502 and perplexity is 224.76163819631466
At time: 542.4915792942047 and batch: 1350, loss is 5.337115716934204 and perplexity is 207.9121670944206
At time: 542.8340334892273 and batch: 1400, loss is 5.216262617111206 and perplexity is 184.24430419123476
At time: 543.1759247779846 and batch: 1450, loss is 5.304422855377197 and perplexity is 201.224833063286
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.431075136885684 and perplexity of 228.39466900152988
Finished Training.
Improved accuracyfrom -10000000 to -228.39466900152988
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f3cccdc08d0>
SETTINGS FOR THIS RUN
{'lr': 10.67664684982944, 'batch_size': 20, 'dropout': 0.046121755424648025, 'wordvec_source': 'glove', 'anneal': 5.355902851142083, 'num_layers': 1, 'seq_len': 35, 'wordvec_dim': 200, 'tune_wordvecs': True, 'data': 'ptb'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.619802713394165 and batch: 50, loss is 6.675519351959228 and perplexity is 792.7590679550588
At time: 0.9860994815826416 and batch: 100, loss is 5.837836866378784 and perplexity is 343.03650373232034
At time: 1.3343353271484375 and batch: 150, loss is 5.493241910934448 and perplexity is 243.04385758263479
At time: 1.6826775074005127 and batch: 200, loss is 5.387487707138061 and perplexity is 218.65337363790843
At time: 2.032912492752075 and batch: 250, loss is 5.3240450000762936 and perplexity is 205.21228913516484
At time: 2.382614850997925 and batch: 300, loss is 5.309039163589477 and perplexity is 202.15589629666
At time: 2.7301454544067383 and batch: 350, loss is 5.325188989639282 and perplexity is 205.44718418525787
At time: 3.078679323196411 and batch: 400, loss is 5.186159076690674 and perplexity is 178.78055011244277
At time: 3.4270331859588623 and batch: 450, loss is 5.187082471847535 and perplexity is 178.94571144941122
At time: 3.776305913925171 and batch: 500, loss is 5.159970474243164 and perplexity is 174.1593133436601
At time: 4.123817682266235 and batch: 550, loss is 5.198670778274536 and perplexity is 181.03145094075091
At time: 4.47289776802063 and batch: 600, loss is 5.04644733428955 and perplexity is 155.46915227537994
At time: 4.822081565856934 and batch: 650, loss is 5.178635549545288 and perplexity is 177.44053692417933
At time: 5.17128324508667 and batch: 700, loss is 5.180875062942505 and perplexity is 177.83836268561964
At time: 5.520998001098633 and batch: 750, loss is 5.1090977764129635 and perplexity is 165.52095058006344
At time: 5.868205785751343 and batch: 800, loss is 5.014800138473511 and perplexity is 150.62602940919922
At time: 6.2177088260650635 and batch: 850, loss is 4.974203138351441 and perplexity is 144.63352630546038
At time: 6.567165374755859 and batch: 900, loss is 4.952264280319214 and perplexity is 141.49498578672714
At time: 6.916306495666504 and batch: 950, loss is 4.9939769268035885 and perplexity is 147.52194240793517
At time: 7.265969514846802 and batch: 1000, loss is 5.020246372222901 and perplexity is 151.44861192919618
At time: 7.615628480911255 and batch: 1050, loss is 4.942945222854615 and perplexity is 140.18251089614913
At time: 7.964781761169434 and batch: 1100, loss is 5.0441623878479005 and perplexity is 155.11431913084888
At time: 8.31417441368103 and batch: 1150, loss is 5.008192405700684 and perplexity is 149.63401395420433
At time: 8.663840770721436 and batch: 1200, loss is 4.9398557472229 and perplexity is 139.7500887675081
At time: 9.026020765304565 and batch: 1250, loss is 4.921500549316407 and perplexity is 137.20834668205666
At time: 9.376552820205688 and batch: 1300, loss is 5.022145681381225 and perplexity is 151.73653300386258
At time: 9.725075960159302 and batch: 1350, loss is 4.946279611587524 and perplexity is 140.6507140328682
At time: 10.074018955230713 and batch: 1400, loss is 4.792069597244263 and perplexity is 120.55060186149173
At time: 10.425590753555298 and batch: 1450, loss is 4.893224382400513 and perplexity is 133.38295909431346
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.962306878505609 and perplexity of 142.92312217158144
Finished 1 epochs...
Completing Train Step...
At time: 11.67485761642456 and batch: 50, loss is 4.95415075302124 and perplexity is 141.76216414799427
At time: 12.0348060131073 and batch: 100, loss is 4.939018802642822 and perplexity is 139.6331746203043
At time: 12.379157304763794 and batch: 150, loss is 4.786409301757812 and perplexity is 119.87017735244763
At time: 12.722338438034058 and batch: 200, loss is 4.863896427154541 and perplexity is 129.52791621744242
At time: 13.063272476196289 and batch: 250, loss is 4.8908347892761235 and perplexity is 133.06460860790358
At time: 13.405763626098633 and batch: 300, loss is 4.899502849578857 and perplexity is 134.22303405709314
At time: 13.747762441635132 and batch: 350, loss is 4.914395217895508 and perplexity is 136.23689124862463
At time: 14.089580535888672 and batch: 400, loss is 4.784547872543335 and perplexity is 119.64725504379547
At time: 14.43126916885376 and batch: 450, loss is 4.816589984893799 and perplexity is 123.54308787469168
At time: 14.77342963218689 and batch: 500, loss is 4.806411237716675 and perplexity is 122.29195231617163
At time: 15.11716341972351 and batch: 550, loss is 4.868135213851929 and perplexity is 130.0781227058064
At time: 15.459447145462036 and batch: 600, loss is 4.7506399345397945 and perplexity is 115.65827457498263
At time: 15.802290201187134 and batch: 650, loss is 4.857027893066406 and perplexity is 128.6412976800081
At time: 16.144718170166016 and batch: 700, loss is 4.866538219451904 and perplexity is 129.87055445905835
At time: 16.48788857460022 and batch: 750, loss is 4.834984512329101 and perplexity is 125.83663427540203
At time: 16.830031156539917 and batch: 800, loss is 4.726568412780762 and perplexity is 112.90744505494575
At time: 17.173460006713867 and batch: 850, loss is 4.701700792312622 and perplexity is 110.13432886980733
At time: 17.5160710811615 and batch: 900, loss is 4.643424549102783 and perplexity is 103.89954813963337
At time: 17.875309944152832 and batch: 950, loss is 4.734977293014526 and perplexity is 113.86087325166118
At time: 18.21729564666748 and batch: 1000, loss is 4.757702112197876 and perplexity is 116.47796485004115
At time: 18.559823036193848 and batch: 1050, loss is 4.666516551971435 and perplexity is 106.32671299798342
At time: 18.901309967041016 and batch: 1100, loss is 4.809605836868286 and perplexity is 122.6832507713645
At time: 19.243529319763184 and batch: 1150, loss is 4.756347932815552 and perplexity is 116.32033954210502
At time: 19.58699631690979 and batch: 1200, loss is 4.6859308528900145 and perplexity is 108.41114017747056
At time: 19.928640842437744 and batch: 1250, loss is 4.65207872390747 and perplexity is 104.80261500437608
At time: 20.272136926651 and batch: 1300, loss is 4.749868288040161 and perplexity is 115.56906169708238
At time: 20.614784717559814 and batch: 1350, loss is 4.718801975250244 and perplexity is 112.03395278832903
At time: 20.956881523132324 and batch: 1400, loss is 4.5643340015411376 and perplexity is 95.99863777670187
At time: 21.299729108810425 and batch: 1450, loss is 4.664928903579712 and perplexity is 106.1580374972194
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.876369900173611 and perplexity of 131.15369767696012
Finished 2 epochs...
Completing Train Step...
At time: 22.548753261566162 and batch: 50, loss is 4.736982316970825 and perplexity is 114.08939605050153
At time: 22.891268253326416 and batch: 100, loss is 4.72976354598999 and perplexity is 113.26877632558231
At time: 23.233330965042114 and batch: 150, loss is 4.581696262359619 and perplexity is 97.6799445722001
At time: 23.57685685157776 and batch: 200, loss is 4.679383697509766 and perplexity is 107.70367407018453
At time: 23.918895721435547 and batch: 250, loss is 4.719543724060059 and perplexity is 112.11708466714316
At time: 24.264170169830322 and batch: 300, loss is 4.720792083740235 and perplexity is 112.25713451320316
At time: 24.607367753982544 and batch: 350, loss is 4.750257453918457 and perplexity is 115.61404598508882
At time: 24.949928760528564 and batch: 400, loss is 4.592073087692261 and perplexity is 98.69882954859386
At time: 25.2929368019104 and batch: 450, loss is 4.653308687210083 and perplexity is 104.93159768056793
At time: 25.63604187965393 and batch: 500, loss is 4.620062398910522 and perplexity is 101.50036544416892
At time: 25.9790141582489 and batch: 550, loss is 4.6745230579376225 and perplexity is 107.18143556469889
At time: 26.323479652404785 and batch: 600, loss is 4.590015125274658 and perplexity is 98.49591992852139
At time: 26.682125091552734 and batch: 650, loss is 4.668166027069092 and perplexity is 106.50224098801597
At time: 27.02495288848877 and batch: 700, loss is 4.692560043334961 and perplexity is 109.13220567163276
At time: 27.36711072921753 and batch: 750, loss is 4.66734546661377 and perplexity is 106.4148853058687
At time: 27.71190881729126 and batch: 800, loss is 4.567200322151184 and perplexity is 96.2741953802564
At time: 28.0551860332489 and batch: 850, loss is 4.54534441947937 and perplexity is 94.19286348024468
At time: 28.39697027206421 and batch: 900, loss is 4.473939037322998 and perplexity is 87.70150301064348
At time: 28.73926305770874 and batch: 950, loss is 4.6072433567047115 and perplexity is 100.20753212208943
At time: 29.08241868019104 and batch: 1000, loss is 4.629807291030883 and perplexity is 102.49431063427593
At time: 29.426578521728516 and batch: 1050, loss is 4.532811851501465 and perplexity is 93.01975142349902
At time: 29.768540143966675 and batch: 1100, loss is 4.6686889171600345 and perplexity is 106.55794451663417
At time: 30.110159397125244 and batch: 1150, loss is 4.6227129936218265 and perplexity is 101.76975864438467
At time: 30.45221257209778 and batch: 1200, loss is 4.551848831176758 and perplexity is 94.8075294966157
At time: 30.794625520706177 and batch: 1250, loss is 4.48769944190979 and perplexity is 88.9166524752154
At time: 31.13815474510193 and batch: 1300, loss is 4.599994144439697 and perplexity is 99.48373310722992
At time: 31.48026394844055 and batch: 1350, loss is 4.582941608428955 and perplexity is 97.80166568394876
At time: 31.821386098861694 and batch: 1400, loss is 4.433016672134399 and perplexity is 84.1849927621643
At time: 32.165475845336914 and batch: 1450, loss is 4.525774412155151 and perplexity is 92.367428598224
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.811238085102831 and perplexity of 122.88366380826149
Finished 3 epochs...
Completing Train Step...
At time: 33.41517663002014 and batch: 50, loss is 4.594807777404785 and perplexity is 98.96910962002265
At time: 33.756542444229126 and batch: 100, loss is 4.625667638778687 and perplexity is 102.07089682803989
At time: 34.09897470474243 and batch: 150, loss is 4.458728809356689 and perplexity is 86.37763683309481
At time: 34.44050431251526 and batch: 200, loss is 4.569670963287353 and perplexity is 96.5123484419481
At time: 34.782742500305176 and batch: 250, loss is 4.600313596725464 and perplexity is 99.51551848985386
At time: 35.12626242637634 and batch: 300, loss is 4.613412523269654 and perplexity is 100.82763988615238
At time: 35.482075452804565 and batch: 350, loss is 4.622723560333252 and perplexity is 101.77083402173773
At time: 35.82405424118042 and batch: 400, loss is 4.457239494323731 and perplexity is 86.24908906786803
At time: 36.16537690162659 and batch: 450, loss is 4.5373372554779055 and perplexity is 93.44165730372531
At time: 36.50876545906067 and batch: 500, loss is 4.495879573822021 and perplexity is 89.64698545924345
At time: 36.850099325180054 and batch: 550, loss is 4.563314294815063 and perplexity is 95.9007972128854
At time: 37.19201707839966 and batch: 600, loss is 4.478403062820434 and perplexity is 88.09387989486297
At time: 37.5356285572052 and batch: 650, loss is 4.563094434738159 and perplexity is 95.87971477391324
At time: 37.877713680267334 and batch: 700, loss is 4.590766849517823 and perplexity is 98.56998953585618
At time: 38.219295501708984 and batch: 750, loss is 4.556946325302124 and perplexity is 95.29204417748146
At time: 38.56158185005188 and batch: 800, loss is 4.466682500839234 and perplexity is 87.06739734234715
At time: 38.90340256690979 and batch: 850, loss is 4.440240306854248 and perplexity is 84.79531612134234
At time: 39.24787473678589 and batch: 900, loss is 4.359629969596863 and perplexity is 78.2281822610058
At time: 39.59007549285889 and batch: 950, loss is 4.506083717346192 and perplexity is 90.56643930676178
At time: 39.932326555252075 and batch: 1000, loss is 4.535866203308106 and perplexity is 93.30430080505658
At time: 40.27380180358887 and batch: 1050, loss is 4.431005086898804 and perplexity is 84.01581768575507
At time: 40.61902165412903 and batch: 1100, loss is 4.580972146987915 and perplexity is 97.6092386255491
At time: 40.960482597351074 and batch: 1150, loss is 4.530696506500244 and perplexity is 92.82319052766044
At time: 41.303184509277344 and batch: 1200, loss is 4.466222438812256 and perplexity is 87.02735015184433
At time: 41.64580941200256 and batch: 1250, loss is 4.383254776000976 and perplexity is 80.0983116641192
At time: 41.98912572860718 and batch: 1300, loss is 4.5085086917877195 and perplexity is 90.786327110739
At time: 42.33156991004944 and batch: 1350, loss is 4.496054763793945 and perplexity is 89.66269208789087
At time: 42.67488241195679 and batch: 1400, loss is 4.33983964920044 and perplexity is 76.69524020914434
At time: 43.01606249809265 and batch: 1450, loss is 4.442942209243775 and perplexity is 85.02473458216686
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.789385412493322 and perplexity of 120.22745566032944
Finished 4 epochs...
Completing Train Step...
At time: 44.27354025840759 and batch: 50, loss is 4.503119902610779 and perplexity is 90.29841454348049
At time: 44.61470985412598 and batch: 100, loss is 4.540804262161255 and perplexity is 93.76618239436009
At time: 44.959118604660034 and batch: 150, loss is 4.376048927307129 and perplexity is 79.52320988630761
At time: 45.30155539512634 and batch: 200, loss is 4.486303291320801 and perplexity is 88.79259805796599
At time: 45.64477181434631 and batch: 250, loss is 4.53380982875824 and perplexity is 93.11262935717471
At time: 45.98825001716614 and batch: 300, loss is 4.534475526809692 and perplexity is 93.17463488929455
At time: 46.33079409599304 and batch: 350, loss is 4.542243881225586 and perplexity is 93.90126719011786
At time: 46.672770261764526 and batch: 400, loss is 4.394898090362549 and perplexity is 81.03637195462233
At time: 47.01598072052002 and batch: 450, loss is 4.4611177730560305 and perplexity is 86.58423655328197
At time: 47.35849618911743 and batch: 500, loss is 4.420337724685669 and perplexity is 83.12435376462672
At time: 47.7010338306427 and batch: 550, loss is 4.485842990875244 and perplexity is 88.75173619060712
At time: 48.04392600059509 and batch: 600, loss is 4.391836538314819 and perplexity is 80.78865427789447
At time: 48.385998487472534 and batch: 650, loss is 4.486043314933777 and perplexity is 88.76951707951315
At time: 48.72884273529053 and batch: 700, loss is 4.5129729175567626 and perplexity is 91.1925237739076
At time: 49.07172966003418 and batch: 750, loss is 4.476130981445312 and perplexity is 87.89395064486301
At time: 49.41536736488342 and batch: 800, loss is 4.390057816505432 and perplexity is 80.64508146248193
At time: 49.7567834854126 and batch: 850, loss is 4.366638479232788 and perplexity is 78.77837097958314
At time: 50.098644495010376 and batch: 900, loss is 4.276724162101746 and perplexity is 72.00417922345606
At time: 50.44106721878052 and batch: 950, loss is 4.427658023834229 and perplexity is 83.73508152843716
At time: 50.78400206565857 and batch: 1000, loss is 4.455528602600098 and perplexity is 86.1016523752836
At time: 51.1287055015564 and batch: 1050, loss is 4.3600645351409915 and perplexity is 78.2621849212534
At time: 51.47266674041748 and batch: 1100, loss is 4.512400197982788 and perplexity is 91.14031098361282
At time: 51.81686544418335 and batch: 1150, loss is 4.459644660949707 and perplexity is 86.45678216654726
At time: 52.15982508659363 and batch: 1200, loss is 4.392586116790771 and perplexity is 80.8492344161897
At time: 52.501877784729004 and batch: 1250, loss is 4.322017397880554 and perplexity is 75.34046677920509
At time: 52.845128536224365 and batch: 1300, loss is 4.425082483291626 and perplexity is 83.51969591737104
At time: 53.188716411590576 and batch: 1350, loss is 4.42573224067688 and perplexity is 83.57398109079384
At time: 53.53175163269043 and batch: 1400, loss is 4.269654932022095 and perplexity is 71.49696005065877
At time: 53.87355852127075 and batch: 1450, loss is 4.378002033233643 and perplexity is 79.67867891314954
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.76801997779781 and perplexity of 117.68599024151943
Finished 5 epochs...
Completing Train Step...
At time: 55.10983180999756 and batch: 50, loss is 4.428665733337402 and perplexity is 83.81950469571215
At time: 55.46724605560303 and batch: 100, loss is 4.482352352142334 and perplexity is 88.44247601443838
At time: 55.81092715263367 and batch: 150, loss is 4.3054861640930175 and perplexity is 74.10523400055258
At time: 56.15322947502136 and batch: 200, loss is 4.407808246612549 and perplexity is 82.08934658691793
At time: 56.49428677558899 and batch: 250, loss is 4.472707595825195 and perplexity is 87.59357021052058
At time: 56.83651781082153 and batch: 300, loss is 4.46353744506836 and perplexity is 86.79399567898002
At time: 57.18205714225769 and batch: 350, loss is 4.472696895599365 and perplexity is 87.59263294455258
At time: 57.52527689933777 and batch: 400, loss is 4.314660301208496 and perplexity is 74.78821366255139
At time: 57.86748242378235 and batch: 450, loss is 4.404135112762451 and perplexity is 81.78837452296574
At time: 58.21036982536316 and batch: 500, loss is 4.35717583656311 and perplexity is 78.03643527728934
At time: 58.55414128303528 and batch: 550, loss is 4.422589044570923 and perplexity is 83.31170408882997
At time: 58.89755177497864 and batch: 600, loss is 4.318804836273193 and perplexity is 75.0988192497653
At time: 59.23860764503479 and batch: 650, loss is 4.426399416923523 and perplexity is 83.62975827035069
At time: 59.58214545249939 and batch: 700, loss is 4.4546936416625975 and perplexity is 86.02979086384839
At time: 59.925472021102905 and batch: 750, loss is 4.417563877105713 and perplexity is 82.89409897058901
At time: 60.26788520812988 and batch: 800, loss is 4.3245417022705075 and perplexity is 75.53088929131248
At time: 60.610687255859375 and batch: 850, loss is 4.304639759063721 and perplexity is 74.04253749485919
At time: 60.952380657196045 and batch: 900, loss is 4.216335077285766 and perplexity is 67.78460317112449
At time: 61.29463720321655 and batch: 950, loss is 4.371208996772766 and perplexity is 79.13925298646329
At time: 61.63675880432129 and batch: 1000, loss is 4.39419086933136 and perplexity is 80.97908158894836
At time: 61.993645429611206 and batch: 1050, loss is 4.298956737518311 and perplexity is 73.62294556327959
At time: 62.33573627471924 and batch: 1100, loss is 4.450517196655273 and perplexity is 85.67124142549191
At time: 62.67946910858154 and batch: 1150, loss is 4.4028028392791745 and perplexity is 81.67948259337017
At time: 63.02321481704712 and batch: 1200, loss is 4.334105086326599 and perplexity is 76.25668519452374
At time: 63.36608910560608 and batch: 1250, loss is 4.25393205165863 and perplexity is 70.38161311156014
At time: 63.70711541175842 and batch: 1300, loss is 4.369124870300293 and perplexity is 78.97448852892536
At time: 64.04927778244019 and batch: 1350, loss is 4.369485864639282 and perplexity is 79.00300301868386
At time: 64.39223504066467 and batch: 1400, loss is 4.2129625415802 and perplexity is 67.5563822345862
At time: 64.73454570770264 and batch: 1450, loss is 4.3151241970062255 and perplexity is 74.82291564901965
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.767241127470619 and perplexity of 117.59436615487068
Finished 6 epochs...
Completing Train Step...
At time: 65.96983671188354 and batch: 50, loss is 4.374479241371155 and perplexity is 79.39848134009803
At time: 66.32527446746826 and batch: 100, loss is 4.428209996223449 and perplexity is 83.78131373972823
At time: 66.66638278961182 and batch: 150, loss is 4.254326667785644 and perplexity is 70.40939231183897
At time: 67.00920176506042 and batch: 200, loss is 4.365369081497192 and perplexity is 78.67843333757573
At time: 67.35058832168579 and batch: 250, loss is 4.4258170366287235 and perplexity is 83.5810681265415
At time: 67.69400191307068 and batch: 300, loss is 4.424551162719727 and perplexity is 83.47533197155356
At time: 68.03845167160034 and batch: 350, loss is 4.414524164199829 and perplexity is 82.64250728509572
At time: 68.3818039894104 and batch: 400, loss is 4.265124416351318 and perplexity is 71.17377460389889
At time: 68.72442150115967 and batch: 450, loss is 4.3459513473510745 and perplexity is 77.16541368254113
At time: 69.06579780578613 and batch: 500, loss is 4.300873384475708 and perplexity is 73.7641900725787
At time: 69.40929865837097 and batch: 550, loss is 4.366938257217408 and perplexity is 78.80199054100243
At time: 69.75219082832336 and batch: 600, loss is 4.263865242004394 and perplexity is 71.08421081279178
At time: 70.09652280807495 and batch: 650, loss is 4.367280855178833 and perplexity is 78.8289925674735
At time: 70.43832302093506 and batch: 700, loss is 4.407832107543945 and perplexity is 82.09130533855391
At time: 70.79675650596619 and batch: 750, loss is 4.3712831449508665 and perplexity is 79.14512123544579
At time: 71.13912558555603 and batch: 800, loss is 4.2726898288726805 and perplexity is 71.7142755478014
At time: 71.48380756378174 and batch: 850, loss is 4.251941723823547 and perplexity is 70.24166994049814
At time: 71.82662582397461 and batch: 900, loss is 4.166999430656433 and perplexity is 64.52155994466851
At time: 72.16930270195007 and batch: 950, loss is 4.322892837524414 and perplexity is 75.40645168929939
At time: 72.51068353652954 and batch: 1000, loss is 4.354737277030945 and perplexity is 77.84637062036425
At time: 72.8538339138031 and batch: 1050, loss is 4.248340306282043 and perplexity is 69.98915533642271
At time: 73.19548964500427 and batch: 1100, loss is 4.403293085098267 and perplexity is 81.71953543528414
At time: 73.53770184516907 and batch: 1150, loss is 4.348920207023621 and perplexity is 77.39484737703869
At time: 73.87955045700073 and batch: 1200, loss is 4.290677685737609 and perplexity is 73.01593359366
At time: 74.22310519218445 and batch: 1250, loss is 4.202666821479798 and perplexity is 66.86440892637911
At time: 74.56518292427063 and batch: 1300, loss is 4.317716598510742 and perplexity is 75.01713833093338
At time: 74.90812373161316 and batch: 1350, loss is 4.325047264099121 and perplexity is 75.56908448002058
At time: 75.25008368492126 and batch: 1400, loss is 4.166553430557251 and perplexity is 64.49278973876805
At time: 75.59435844421387 and batch: 1450, loss is 4.276131324768066 and perplexity is 71.96150510848554
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.772124461638621 and perplexity of 118.17002315986845
Annealing...
Finished 7 epochs...
Completing Train Step...
At time: 76.83751773834229 and batch: 50, loss is 4.309708576202393 and perplexity is 74.41879837109028
At time: 77.18051481246948 and batch: 100, loss is 4.305375752449035 and perplexity is 74.09705237152076
At time: 77.52316641807556 and batch: 150, loss is 4.112104153633117 and perplexity is 61.07509384115689
At time: 77.8642897605896 and batch: 200, loss is 4.199895629882812 and perplexity is 66.6793713439381
At time: 78.20854234695435 and batch: 250, loss is 4.258420853614807 and perplexity is 70.69825236795842
At time: 78.55192875862122 and batch: 300, loss is 4.237341532707214 and perplexity is 69.22357838578174
At time: 78.89538359642029 and batch: 350, loss is 4.215420780181884 and perplexity is 67.722656228028
At time: 79.23762559890747 and batch: 400, loss is 4.03988272190094 and perplexity is 56.8196787107921
At time: 79.59470915794373 and batch: 450, loss is 4.122946667671203 and perplexity is 61.74090441101468
At time: 79.9383716583252 and batch: 500, loss is 4.0781019115448 and perplexity is 59.033312991874155
At time: 80.28028559684753 and batch: 550, loss is 4.1363962316513065 and perplexity is 62.576901954320974
At time: 80.62281060218811 and batch: 600, loss is 4.038277654647827 and perplexity is 56.72855245660785
At time: 80.96646451950073 and batch: 650, loss is 4.122294163703918 and perplexity is 61.70063136653226
At time: 81.3105092048645 and batch: 700, loss is 4.16187520980835 and perplexity is 64.19178286892952
At time: 81.65382242202759 and batch: 750, loss is 4.106303362846375 and perplexity is 60.72183557871091
At time: 81.99577283859253 and batch: 800, loss is 4.023579235076904 and perplexity is 55.90083039596378
At time: 82.33842349052429 and batch: 850, loss is 3.9725267028808595 and perplexity is 53.11857628157716
At time: 82.68071484565735 and batch: 900, loss is 3.885053052902222 and perplexity is 48.66952445052061
At time: 83.02419972419739 and batch: 950, loss is 4.034241166114807 and perplexity is 56.500029829884134
At time: 83.3665223121643 and batch: 1000, loss is 4.056562910079956 and perplexity is 57.77539020901749
At time: 83.70722842216492 and batch: 1050, loss is 3.943311543464661 and perplexity is 51.589158481519355
At time: 84.05053663253784 and batch: 1100, loss is 4.099926967620849 and perplexity is 60.33588096351553
At time: 84.39337825775146 and batch: 1150, loss is 4.01542582988739 and perplexity is 55.44690132383062
At time: 84.73761630058289 and batch: 1200, loss is 3.948140649795532 and perplexity is 51.83889051931116
At time: 85.07924485206604 and batch: 1250, loss is 3.865222496986389 and perplexity is 47.71388744790654
At time: 85.42293167114258 and batch: 1300, loss is 3.9650785303115845 and perplexity is 52.724409691396765
At time: 85.76623320579529 and batch: 1350, loss is 3.9393043088912965 and perplexity is 51.382842276839824
At time: 86.10870027542114 and batch: 1400, loss is 3.780367922782898 and perplexity is 43.83216562157552
At time: 86.45019578933716 and batch: 1450, loss is 3.873555693626404 and perplexity is 48.11315794373194
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.565212151943109 and perplexity of 96.08297604447625
Finished 8 epochs...
Completing Train Step...
At time: 87.69522714614868 and batch: 50, loss is 4.1240469121932986 and perplexity is 61.80887188644693
At time: 88.03939938545227 and batch: 100, loss is 4.158159689903259 and perplexity is 63.953719560291425
At time: 88.39865899085999 and batch: 150, loss is 3.987017984390259 and perplexity is 53.89393694005295
At time: 88.74101543426514 and batch: 200, loss is 4.0942302370071415 and perplexity is 59.99314087919515
At time: 89.08216595649719 and batch: 250, loss is 4.163314261436462 and perplexity is 64.28422465687834
At time: 89.42385339736938 and batch: 300, loss is 4.14962149143219 and perplexity is 63.40999452900126
At time: 89.76648569107056 and batch: 350, loss is 4.126043138504028 and perplexity is 61.932379616419205
At time: 90.10959243774414 and batch: 400, loss is 3.9531458902359007 and perplexity is 52.0990070603918
At time: 90.4516544342041 and batch: 450, loss is 4.045135827064514 and perplexity is 57.118943805740585
At time: 90.7939624786377 and batch: 500, loss is 4.007769508361816 and perplexity is 55.02400300826704
At time: 91.13724708557129 and batch: 550, loss is 4.065788221359253 and perplexity is 58.310852272488184
At time: 91.48070049285889 and batch: 600, loss is 3.9685537576675416 and perplexity is 52.90795775317678
At time: 91.8222885131836 and batch: 650, loss is 4.054382901191712 and perplexity is 57.649576532133814
At time: 92.16693425178528 and batch: 700, loss is 4.098862714767456 and perplexity is 60.27170248715899
At time: 92.51129674911499 and batch: 750, loss is 4.047462344169617 and perplexity is 57.251986708815
At time: 92.8560938835144 and batch: 800, loss is 3.9685483312606813 and perplexity is 52.90767065385082
At time: 93.19760775566101 and batch: 850, loss is 3.9242221450805665 and perplexity is 50.613692632945636
At time: 93.54061341285706 and batch: 900, loss is 3.8381529092788695 and perplexity is 46.43961698531933
At time: 93.88474416732788 and batch: 950, loss is 3.9924688863754274 and perplexity is 54.18850962194653
At time: 94.22667527198792 and batch: 1000, loss is 4.017230253219605 and perplexity is 55.54704132658622
At time: 94.56816673278809 and batch: 1050, loss is 3.911957097053528 and perplexity is 49.99670468986456
At time: 94.91116380691528 and batch: 1100, loss is 4.068736100196839 and perplexity is 58.482999209397065
At time: 95.25391149520874 and batch: 1150, loss is 3.9853938245773315 and perplexity is 53.806475618322594
At time: 95.59696841239929 and batch: 1200, loss is 3.922930107116699 and perplexity is 50.54834004867374
At time: 95.93918442726135 and batch: 1250, loss is 3.841903338432312 and perplexity is 46.61411249071738
At time: 96.27982139587402 and batch: 1300, loss is 3.945608124732971 and perplexity is 51.707773328719966
At time: 96.62254452705383 and batch: 1350, loss is 3.9256002616882326 and perplexity is 50.683492288323556
At time: 96.96802473068237 and batch: 1400, loss is 3.7750534057617187 and perplexity is 43.59983673603911
At time: 97.31030797958374 and batch: 1450, loss is 3.8736917304992677 and perplexity is 48.11970355249419
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.557304186698718 and perplexity of 95.32615162400036
Finished 9 epochs...
Completing Train Step...
At time: 98.56033682823181 and batch: 50, loss is 4.0764562606811525 and perplexity is 58.936244661562355
At time: 98.91633129119873 and batch: 100, loss is 4.113162565231323 and perplexity is 61.13977065014449
At time: 99.25973176956177 and batch: 150, loss is 3.94405234336853 and perplexity is 51.62738988432452
At time: 99.6025402545929 and batch: 200, loss is 4.054458799362183 and perplexity is 57.653952195571364
At time: 99.94510507583618 and batch: 250, loss is 4.123940949440002 and perplexity is 61.8023227951897
At time: 100.28836250305176 and batch: 300, loss is 4.11211130619049 and perplexity is 61.075530685831936
At time: 100.62985563278198 and batch: 350, loss is 4.085470480918884 and perplexity is 59.469910628573864
At time: 100.97365093231201 and batch: 400, loss is 3.9133018112182616 and perplexity is 50.063981190544965
At time: 101.31638741493225 and batch: 450, loss is 4.00729362487793 and perplexity is 54.997824223537755
At time: 101.6601734161377 and batch: 500, loss is 3.9732904291152953 and perplexity is 53.1591598272059
At time: 102.0026307106018 and batch: 550, loss is 4.029421358108521 and perplexity is 56.22836574403128
At time: 102.34491539001465 and batch: 600, loss is 3.936155457496643 and perplexity is 51.221299812360435
At time: 102.68856143951416 and batch: 650, loss is 4.019846520423889 and perplexity is 55.69255750069792
At time: 103.03289747238159 and batch: 700, loss is 4.068966360092163 and perplexity is 58.49646704916544
At time: 103.375967502594 and batch: 750, loss is 4.016963100433349 and perplexity is 55.5322037617642
At time: 103.71910667419434 and batch: 800, loss is 3.938842577934265 and perplexity is 51.35912270435221
At time: 104.06275939941406 and batch: 850, loss is 3.8969462537765502 and perplexity is 49.25181667680869
At time: 104.40646290779114 and batch: 900, loss is 3.8120111513137815 and perplexity is 45.24133460266493
At time: 104.74920463562012 and batch: 950, loss is 3.969094033241272 and perplexity is 52.93655035365309
At time: 105.09081673622131 and batch: 1000, loss is 3.994363102912903 and perplexity is 54.29125167013661
At time: 105.43456292152405 and batch: 1050, loss is 3.891893439292908 and perplexity is 49.00358404900098
At time: 105.78024864196777 and batch: 1100, loss is 4.0481734943389895 and perplexity is 57.292715949446574
At time: 106.13809275627136 and batch: 1150, loss is 3.9652432727813722 and perplexity is 52.7330963563791
At time: 106.48052096366882 and batch: 1200, loss is 3.906031861305237 and perplexity is 49.7013383496915
At time: 106.8249123096466 and batch: 1250, loss is 3.825941843986511 and perplexity is 45.875988048580325
At time: 107.1679298877716 and batch: 1300, loss is 3.930724973678589 and perplexity is 50.94389726932024
At time: 107.51122450828552 and batch: 1350, loss is 3.9120636796951294 and perplexity is 50.00203375470963
At time: 107.85312342643738 and batch: 1400, loss is 3.7654111862182615 and perplexity is 43.18145783027136
At time: 108.19600105285645 and batch: 1450, loss is 3.8651684761047362 and perplexity is 47.71130997125892
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.554484049479167 and perplexity of 95.05769751244664
Finished 10 epochs...
Completing Train Step...
At time: 109.42565107345581 and batch: 50, loss is 4.044271054267884 and perplexity is 57.069570248496646
At time: 109.7836685180664 and batch: 100, loss is 4.081475238800049 and perplexity is 59.23278793352835
At time: 110.12553215026855 and batch: 150, loss is 3.9147876071929932 and perplexity is 50.138421340019704
At time: 110.46868062019348 and batch: 200, loss is 4.025535416603089 and perplexity is 56.01028959380793
At time: 110.81118202209473 and batch: 250, loss is 4.095472545623779 and perplexity is 60.067717188853244
At time: 111.15484118461609 and batch: 300, loss is 4.085482044219971 and perplexity is 59.47059830103192
At time: 111.4976167678833 and batch: 350, loss is 4.057187194824219 and perplexity is 57.811469764505084
At time: 111.84103655815125 and batch: 400, loss is 3.8850449562072753 and perplexity is 48.66913038982324
At time: 112.18302583694458 and batch: 450, loss is 3.9814058685302736 and perplexity is 53.59232505384605
At time: 112.52519702911377 and batch: 500, loss is 3.948442325592041 and perplexity is 51.85453141702022
At time: 112.86806964874268 and batch: 550, loss is 4.00321521282196 and perplexity is 54.773977214621134
At time: 113.2106819152832 and batch: 600, loss is 3.9123804855346678 and perplexity is 50.01787720050748
At time: 113.55326867103577 and batch: 650, loss is 3.995807023048401 and perplexity is 54.36970052491516
At time: 113.89569473266602 and batch: 700, loss is 4.047554812431335 and perplexity is 57.257280945276555
At time: 114.23946332931519 and batch: 750, loss is 3.9952784156799317 and perplexity is 54.34096789540511
At time: 114.58008646965027 and batch: 800, loss is 3.916915650367737 and perplexity is 50.24523167353722
At time: 114.93713283538818 and batch: 850, loss is 3.8758726358413695 and perplexity is 48.22476259130021
At time: 115.27974271774292 and batch: 900, loss is 3.7917126417160034 and perplexity is 44.332260575510524
At time: 115.62430763244629 and batch: 950, loss is 3.950841326713562 and perplexity is 51.97907983220598
At time: 115.96598076820374 and batch: 1000, loss is 3.975993051528931 and perplexity is 53.30302328077511
At time: 116.30873441696167 and batch: 1050, loss is 3.875419816970825 and perplexity is 48.202930452146695
At time: 116.65082383155823 and batch: 1100, loss is 4.032383332252502 and perplexity is 56.39515960713414
At time: 116.99354529380798 and batch: 1150, loss is 3.9480437088012694 and perplexity is 51.83386544929432
At time: 117.33649945259094 and batch: 1200, loss is 3.889361581802368 and perplexity is 48.87967088908766
At time: 117.67949557304382 and batch: 1250, loss is 3.8122120809555056 and perplexity is 45.25042584113682
At time: 118.02157211303711 and batch: 1300, loss is 3.91573203086853 and perplexity is 50.18579561936154
At time: 118.36655044555664 and batch: 1350, loss is 3.8979983520507813 and perplexity is 49.30366169638259
At time: 118.70902967453003 and batch: 1400, loss is 3.753694005012512 and perplexity is 42.67844556205758
At time: 119.05198502540588 and batch: 1450, loss is 3.8559364652633668 and perplexity is 47.27286561591674
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.553892477964744 and perplexity of 95.00148071613873
Finished 11 epochs...
Completing Train Step...
At time: 120.29919600486755 and batch: 50, loss is 4.018689165115356 and perplexity is 55.62813870853485
At time: 120.64205574989319 and batch: 100, loss is 4.056150074005127 and perplexity is 57.75154336645903
At time: 120.98517751693726 and batch: 150, loss is 3.8911371278762816 and perplexity is 48.96653609059204
At time: 121.3290684223175 and batch: 200, loss is 4.002045722007751 and perplexity is 54.70995699423754
At time: 121.67144799232483 and batch: 250, loss is 4.072297224998474 and perplexity is 58.69163573822712
At time: 122.0129599571228 and batch: 300, loss is 4.06430293560028 and perplexity is 58.22430828120339
At time: 122.35601592063904 and batch: 350, loss is 4.03514527797699 and perplexity is 56.55113527610589
At time: 122.69954800605774 and batch: 400, loss is 3.8630020809173584 and perplexity is 47.60806029913162
At time: 123.04348921775818 and batch: 450, loss is 3.958461923599243 and perplexity is 52.37670459080791
At time: 123.3849585056305 and batch: 500, loss is 3.928366250991821 and perplexity is 50.823876346760606
At time: 123.7429347038269 and batch: 550, loss is 3.9815784740447997 and perplexity is 53.60157618306161
At time: 124.0867600440979 and batch: 600, loss is 3.8930608654022216 and perplexity is 49.06082551856166
At time: 124.43045377731323 and batch: 650, loss is 3.975175495147705 and perplexity is 53.25946286292839
At time: 124.77433180809021 and batch: 700, loss is 4.030141253471374 and perplexity is 56.26885885744472
At time: 125.11585187911987 and batch: 750, loss is 3.976398591995239 and perplexity is 53.324644197474036
At time: 125.45857214927673 and batch: 800, loss is 3.8978959131240845 and perplexity is 49.29861134087711
At time: 125.80282258987427 and batch: 850, loss is 3.859246435165405 and perplexity is 47.42959662265195
At time: 126.14559316635132 and batch: 900, loss is 3.7749753332138063 and perplexity is 43.59643291857064
At time: 126.48769950866699 and batch: 950, loss is 3.9368023586273195 and perplexity is 51.254445649007465
At time: 126.83018898963928 and batch: 1000, loss is 3.9600318336486815 and perplexity is 52.458995883764004
At time: 127.17313933372498 and batch: 1050, loss is 3.860687747001648 and perplexity is 47.4980067499727
At time: 127.51608800888062 and batch: 1100, loss is 4.018577990531921 and perplexity is 55.62195461714992
At time: 127.85849499702454 and batch: 1150, loss is 3.9322545528411865 and perplexity is 51.0218796179286
At time: 128.20175099372864 and batch: 1200, loss is 3.87506742477417 and perplexity is 48.18594710817415
At time: 128.54370427131653 and batch: 1250, loss is 3.7988250780105592 and perplexity is 44.648694930294724
At time: 128.88626623153687 and batch: 1300, loss is 3.9008726692199707 and perplexity is 49.44557991898521
At time: 129.22955775260925 and batch: 1350, loss is 3.8847795867919923 and perplexity is 48.65621680466041
At time: 129.57193684577942 and batch: 1400, loss is 3.7419746780395506 and perplexity is 42.18120227320684
At time: 129.9141743183136 and batch: 1450, loss is 3.845575380325317 and perplexity is 46.785596119434025
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.554668719951923 and perplexity of 95.07525348337023
Annealing...
Finished 12 epochs...
Completing Train Step...
At time: 131.15808415412903 and batch: 50, loss is 4.005602788925171 and perplexity is 54.90491049808698
At time: 131.501038312912 and batch: 100, loss is 4.044840717315674 and perplexity is 57.10208993557309
At time: 131.84349179267883 and batch: 150, loss is 3.871499080657959 and perplexity is 48.01430948050896
At time: 132.18505024909973 and batch: 200, loss is 3.977885069847107 and perplexity is 53.403969042738645
At time: 132.54314851760864 and batch: 250, loss is 4.049587149620056 and perplexity is 57.37376537439136
At time: 132.88781428337097 and batch: 300, loss is 4.03733202457428 and perplexity is 56.674933587179346
At time: 133.23114562034607 and batch: 350, loss is 4.003373742103577 and perplexity is 54.782661182193635
At time: 133.57570624351501 and batch: 400, loss is 3.827821717262268 and perplexity is 45.96231020444743
At time: 133.91865062713623 and batch: 450, loss is 3.9305501699447634 and perplexity is 50.93499286414624
At time: 134.26260352134705 and batch: 500, loss is 3.8877736377716063 and perplexity is 48.80211430153087
At time: 134.60451745986938 and batch: 550, loss is 3.937107744216919 and perplexity is 51.27010040835887
At time: 134.94578862190247 and batch: 600, loss is 3.852921390533447 and perplexity is 47.13054904874277
At time: 135.28739380836487 and batch: 650, loss is 3.9297616577148435 and perplexity is 50.894845829635955
At time: 135.6304430961609 and batch: 700, loss is 3.980631184577942 and perplexity is 53.55082401682791
At time: 135.97502207756042 and batch: 750, loss is 3.9263149738311767 and perplexity is 50.71972934369805
At time: 136.31756687164307 and batch: 800, loss is 3.847965111732483 and perplexity is 46.89753482633362
At time: 136.65993285179138 and batch: 850, loss is 3.797648286819458 and perplexity is 44.59618364287679
At time: 137.0038239955902 and batch: 900, loss is 3.707950458526611 and perplexity is 40.77016070324019
At time: 137.34576201438904 and batch: 950, loss is 3.8713694190979004 and perplexity is 48.00808427383031
At time: 137.68853878974915 and batch: 1000, loss is 3.8990646696090696 and perplexity is 49.35626309645147
At time: 138.03018045425415 and batch: 1050, loss is 3.792740488052368 and perplexity is 44.37785075296055
At time: 138.3720462322235 and batch: 1100, loss is 3.9474554872512817 and perplexity is 51.8033846182376
At time: 138.71404600143433 and batch: 1150, loss is 3.857799696922302 and perplexity is 47.36102802372997
At time: 139.0563507080078 and batch: 1200, loss is 3.7968297147750856 and perplexity is 44.55969339064877
At time: 139.39853858947754 and batch: 1250, loss is 3.7127039194107057 and perplexity is 40.964421406926526
At time: 139.74084186553955 and batch: 1300, loss is 3.8110561180114746 and perplexity is 45.198148246965
At time: 140.0844910144806 and batch: 1350, loss is 3.786776418685913 and perplexity is 44.113965868813644
At time: 140.42734742164612 and batch: 1400, loss is 3.641288104057312 and perplexity is 38.14093458962588
At time: 140.76918578147888 and batch: 1450, loss is 3.7436107349395753 and perplexity is 42.250269603872766
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.517581255008013 and perplexity of 91.61373950316067
Finished 13 epochs...
Completing Train Step...
At time: 141.99919414520264 and batch: 50, loss is 3.974232358932495 and perplexity is 53.20925561455846
At time: 142.35634875297546 and batch: 100, loss is 4.0146133947372435 and perplexity is 55.40187260616169
At time: 142.69909405708313 and batch: 150, loss is 3.841524500846863 and perplexity is 46.596456657451334
At time: 143.0423402786255 and batch: 200, loss is 3.9531963205337526 and perplexity is 52.101634495086245
At time: 143.38535976409912 and batch: 250, loss is 4.0248927927017215 and perplexity is 55.97430760567354
At time: 143.72790598869324 and batch: 300, loss is 4.015561842918396 and perplexity is 55.45444333783403
At time: 144.07102394104004 and batch: 350, loss is 3.9823437833786013 and perplexity is 53.64261367080422
At time: 144.41177558898926 and batch: 400, loss is 3.8060948514938353 and perplexity is 44.97446352598393
At time: 144.75492191314697 and batch: 450, loss is 3.9103099727630615 and perplexity is 49.914421686895984
At time: 145.09683084487915 and batch: 500, loss is 3.8685902690887453 and perplexity is 47.87484783376422
At time: 145.43833804130554 and batch: 550, loss is 3.919986853599548 and perplexity is 50.39978219799076
At time: 145.78219985961914 and batch: 600, loss is 3.8356685495376586 and perplexity is 46.32438746554051
At time: 146.12662482261658 and batch: 650, loss is 3.9154493522644045 and perplexity is 50.171611173623035
At time: 146.4718246459961 and batch: 700, loss is 3.969082570075989 and perplexity is 52.93594353670489
At time: 146.81515955924988 and batch: 750, loss is 3.913415803909302 and perplexity is 50.06968844377147
At time: 147.1601710319519 and batch: 800, loss is 3.8368493127822876 and perplexity is 46.37911790507668
At time: 147.50388050079346 and batch: 850, loss is 3.788556079864502 and perplexity is 44.192543681506066
At time: 147.8452651500702 and batch: 900, loss is 3.6990157318115235 and perplexity is 40.40751295099765
At time: 148.1879644393921 and batch: 950, loss is 3.8633258295059205 and perplexity is 47.62347583670226
At time: 148.53135538101196 and batch: 1000, loss is 3.892457003593445 and perplexity is 49.03120850291624
At time: 148.8742654323578 and batch: 1050, loss is 3.7872211742401123 and perplexity is 44.133590163835166
At time: 149.21677136421204 and batch: 1100, loss is 3.9443934249877928 and perplexity is 51.64500204148537
At time: 149.55932450294495 and batch: 1150, loss is 3.8558402109146117 and perplexity is 47.268315616005246
At time: 149.90217542648315 and batch: 1200, loss is 3.794777011871338 and perplexity is 44.46831939255566
At time: 150.26155281066895 and batch: 1250, loss is 3.712737350463867 and perplexity is 40.965790913568206
At time: 150.60382223129272 and batch: 1300, loss is 3.8125556564331053 and perplexity is 45.26597544888577
At time: 150.9460232257843 and batch: 1350, loss is 3.789132218360901 and perplexity is 44.21801204312207
At time: 151.28892850875854 and batch: 1400, loss is 3.6459388065338136 and perplexity is 38.31872984453258
At time: 151.63137578964233 and batch: 1450, loss is 3.7507933664321897 and perplexity is 42.55483018475028
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.515347472622863 and perplexity of 91.40932274190068
Finished 14 epochs...
Completing Train Step...
At time: 152.86082410812378 and batch: 50, loss is 3.9634406471252444 and perplexity is 52.63812394952605
At time: 153.21757578849792 and batch: 100, loss is 4.003898611068726 and perplexity is 54.81142244816412
At time: 153.5589611530304 and batch: 150, loss is 3.830386815071106 and perplexity is 46.08035936473559
At time: 153.90144324302673 and batch: 200, loss is 3.9433334970474245 and perplexity is 51.59029106081183
At time: 154.24534463882446 and batch: 250, loss is 4.014938054084777 and perplexity is 55.41986226207112
At time: 154.58773732185364 and batch: 300, loss is 4.005885982513428 and perplexity is 54.920461418560414
At time: 154.92988777160645 and batch: 350, loss is 3.972878031730652 and perplexity is 53.137241648533745
At time: 155.27275562286377 and batch: 400, loss is 3.796211824417114 and perplexity is 44.53216889018596
At time: 155.61512565612793 and batch: 450, loss is 3.901002540588379 and perplexity is 49.45200190111781
At time: 155.9574203491211 and batch: 500, loss is 3.859642753601074 and perplexity is 47.44839757152508
At time: 156.29940676689148 and batch: 550, loss is 3.9116061305999756 and perplexity is 49.97916060260338
At time: 156.64082741737366 and batch: 600, loss is 3.8284135675430297 and perplexity is 45.989521062229
At time: 156.98265600204468 and batch: 650, loss is 3.907694411277771 and perplexity is 49.784038035530905
At time: 157.32602286338806 and batch: 700, loss is 3.962625403404236 and perplexity is 52.595228536974176
At time: 157.66757011413574 and batch: 750, loss is 3.907134313583374 and perplexity is 49.75616191801275
At time: 158.00968503952026 and batch: 800, loss is 3.830989022254944 and perplexity is 46.10811764545801
At time: 158.3511209487915 and batch: 850, loss is 3.7835667753219604 and perplexity is 43.9726027549533
At time: 158.69478034973145 and batch: 900, loss is 3.6939309310913084 and perplexity is 40.20257028791199
At time: 159.05175924301147 and batch: 950, loss is 3.8586590671539307 and perplexity is 47.40174617483045
At time: 159.3934941291809 and batch: 1000, loss is 3.8887541484832764 and perplexity is 48.84998876423187
At time: 159.73755311965942 and batch: 1050, loss is 3.7842779636383055 and perplexity is 44.00388667933407
At time: 160.08115696907043 and batch: 1100, loss is 3.9427491998672486 and perplexity is 51.56015580405067
At time: 160.42572927474976 and batch: 1150, loss is 3.8546634578704833 and perplexity is 47.21272519622603
At time: 160.7691011428833 and batch: 1200, loss is 3.793179497718811 and perplexity is 44.39733733550314
At time: 161.1126046180725 and batch: 1250, loss is 3.712244725227356 and perplexity is 40.94561510109577
At time: 161.45664596557617 and batch: 1300, loss is 3.8124836826324464 and perplexity is 45.2627176018334
At time: 161.79933166503906 and batch: 1350, loss is 3.78950945854187 and perplexity is 44.23469600071905
At time: 162.14198327064514 and batch: 1400, loss is 3.647185893058777 and perplexity is 38.36654642568529
At time: 162.48400735855103 and batch: 1450, loss is 3.7530988311767577 and perplexity is 42.65305202544227
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.5144183819110575 and perplexity of 91.32443462965342
Finished 15 epochs...
Completing Train Step...
At time: 163.73354029655457 and batch: 50, loss is 3.955177049636841 and perplexity is 52.20493599121556
At time: 164.07561898231506 and batch: 100, loss is 3.995696849822998 and perplexity is 54.36371076960551
At time: 164.41923022270203 and batch: 150, loss is 3.8222163677215577 and perplexity is 45.705396109390485
At time: 164.76206469535828 and batch: 200, loss is 3.9359743928909303 and perplexity is 51.21202628748472
At time: 165.103901386261 and batch: 250, loss is 4.007457175254822 and perplexity is 55.00681987401873
At time: 165.4460587501526 and batch: 300, loss is 3.998762159347534 and perplexity is 54.53060803522343
At time: 165.7896728515625 and batch: 350, loss is 3.965919599533081 and perplexity is 52.76877322339521
At time: 166.13061451911926 and batch: 400, loss is 3.7888739013671877 and perplexity is 44.20659125433854
At time: 166.47254705429077 and batch: 450, loss is 3.8943766736984253 and perplexity is 49.12542264919776
At time: 166.8158459663391 and batch: 500, loss is 3.8529884576797486 and perplexity is 47.13371006617011
At time: 167.1588044166565 and batch: 550, loss is 3.905205101966858 and perplexity is 49.6602642856036
At time: 167.50105929374695 and batch: 600, loss is 3.8228991556167604 and perplexity is 45.736613856936685
At time: 167.85749554634094 and batch: 650, loss is 3.9017413234710694 and perplexity is 49.488549692416115
At time: 168.19909238815308 and batch: 700, loss is 3.957591691017151 and perplexity is 52.33114450274215
At time: 168.73225116729736 and batch: 750, loss is 3.902314281463623 and perplexity is 49.51691267712575
At time: 169.07500457763672 and batch: 800, loss is 3.826455945968628 and perplexity is 45.899579048537994
At time: 169.41855478286743 and batch: 850, loss is 3.7795677328109742 and perplexity is 43.797105591410464
At time: 169.76147627830505 and batch: 900, loss is 3.689686584472656 and perplexity is 40.03229824704324
At time: 170.1061658859253 and batch: 950, loss is 3.854764099121094 and perplexity is 47.21747698304338
At time: 170.4501302242279 and batch: 1000, loss is 3.885466203689575 and perplexity is 48.68963645722707
At time: 170.79206943511963 and batch: 1050, loss is 3.7816760396957396 and perplexity is 43.88954073724962
At time: 171.1363024711609 and batch: 1100, loss is 3.9409743785858153 and perplexity is 51.46872690123687
At time: 171.4797134399414 and batch: 1150, loss is 3.853084435462952 and perplexity is 47.138234072274976
At time: 171.8228394985199 and batch: 1200, loss is 3.791189351081848 and perplexity is 44.309067987521715
At time: 172.16688418388367 and batch: 1250, loss is 3.7109565687179566 and perplexity is 40.89290469738549
At time: 172.5096311569214 and batch: 1300, loss is 3.8115024900436403 and perplexity is 45.218327939738295
At time: 172.8547477722168 and batch: 1350, loss is 3.788720097541809 and perplexity is 44.19979263433695
At time: 173.19755959510803 and batch: 1400, loss is 3.646973328590393 and perplexity is 38.358391927849546
At time: 173.53995156288147 and batch: 1450, loss is 3.753440093994141 and perplexity is 42.66761041012286
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.513880020532852 and perplexity of 91.27528231320396
Finished 16 epochs...
Completing Train Step...
At time: 174.78792357444763 and batch: 50, loss is 3.9481228303909304 and perplexity is 51.83796678937708
At time: 175.13231539726257 and batch: 100, loss is 3.988814015388489 and perplexity is 53.99081909704956
At time: 175.47604513168335 and batch: 150, loss is 3.8154417085647583 and perplexity is 45.39680411218345
At time: 175.8193736076355 and batch: 200, loss is 3.929678421020508 and perplexity is 50.89060968721407
At time: 176.1623363494873 and batch: 250, loss is 4.001158680915832 and perplexity is 54.66144853192693
At time: 176.50706124305725 and batch: 300, loss is 3.992664909362793 and perplexity is 54.1991328566486
At time: 176.8671679496765 and batch: 350, loss is 3.9600238895416258 and perplexity is 52.45857914553997
At time: 177.21265196800232 and batch: 400, loss is 3.7828139781951906 and perplexity is 43.93951276253107
At time: 177.55599570274353 and batch: 450, loss is 3.888828558921814 and perplexity is 48.8536238485608
At time: 177.89847588539124 and batch: 500, loss is 3.8473983097076414 and perplexity is 46.87096074046825
At time: 178.24062085151672 and batch: 550, loss is 3.8997135829925536 and perplexity is 49.38830143006099
At time: 178.58471035957336 and batch: 600, loss is 3.818199553489685 and perplexity is 45.52217425425644
At time: 178.92737936973572 and batch: 650, loss is 3.8966237688064576 and perplexity is 49.23593626691503
At time: 179.27018284797668 and batch: 700, loss is 3.9532311391830444 and perplexity is 52.10344863520803
At time: 179.61315035820007 and batch: 750, loss is 3.8981391286849973 and perplexity is 49.310602988505146
At time: 179.95728254318237 and batch: 800, loss is 3.822477250099182 and perplexity is 45.71732139727886
At time: 180.30225729942322 and batch: 850, loss is 3.7759721279144287 and perplexity is 43.63991127776893
At time: 180.6463053226471 and batch: 900, loss is 3.6858620119094847 and perplexity is 39.87948422795128
At time: 180.98980927467346 and batch: 950, loss is 3.8512152576446534 and perplexity is 47.05020662585782
At time: 181.33352327346802 and batch: 1000, loss is 3.882404365539551 and perplexity is 48.540784667144926
At time: 181.67618131637573 and batch: 1050, loss is 3.779189319610596 and perplexity is 43.780535323918016
At time: 182.01871418952942 and batch: 1100, loss is 3.939170446395874 and perplexity is 51.37596450169909
At time: 182.36455082893372 and batch: 1150, loss is 3.8512556457519533 and perplexity is 47.05210693302615
At time: 182.70867156982422 and batch: 1200, loss is 3.7891049003601074 and perplexity is 44.2168041119332
At time: 183.0542709827423 and batch: 1250, loss is 3.7093676376342772 and perplexity is 40.827980283878794
At time: 183.39716124534607 and batch: 1300, loss is 3.810070276260376 and perplexity is 45.15361198181262
At time: 183.74010014533997 and batch: 1350, loss is 3.7873273038864137 and perplexity is 44.13827429470744
At time: 184.08428478240967 and batch: 1400, loss is 3.6460567903518677 and perplexity is 38.32325110129494
At time: 184.42901802062988 and batch: 1450, loss is 3.7528354692459107 and perplexity is 42.64182031437181
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.5135315463074255 and perplexity of 91.24348077122993
Finished 17 epochs...
Completing Train Step...
At time: 185.6741259098053 and batch: 50, loss is 3.9418009090423585 and perplexity is 51.51128495692203
At time: 186.03016328811646 and batch: 100, loss is 3.982725253105164 and perplexity is 53.663080607483494
At time: 186.37336492538452 and batch: 150, loss is 3.8094441795349123 and perplexity is 45.125350301403934
At time: 186.7181465625763 and batch: 200, loss is 3.9240736293792726 and perplexity is 50.60617626305246
At time: 187.06338715553284 and batch: 250, loss is 3.995541396141052 and perplexity is 54.35526038744067
At time: 187.40943717956543 and batch: 300, loss is 3.9872749996185304 and perplexity is 53.90779028274181
At time: 187.7526614665985 and batch: 350, loss is 3.954778175354004 and perplexity is 52.184116937180164
At time: 188.098317861557 and batch: 400, loss is 3.777448115348816 and perplexity is 43.70437079747094
At time: 188.44283366203308 and batch: 450, loss is 3.8839407348632813 and perplexity is 48.61541855758655
At time: 188.7853763103485 and batch: 500, loss is 3.8423703384399412 and perplexity is 46.63588636541029
At time: 189.1288456916809 and batch: 550, loss is 3.8947422647476198 and perplexity is 49.14338574738008
At time: 189.47199630737305 and batch: 600, loss is 3.8139586734771727 and perplexity is 45.32952895685914
At time: 189.8149609565735 and batch: 650, loss is 3.89199999332428 and perplexity is 49.00880585663046
At time: 190.15860772132874 and batch: 700, loss is 3.949231896400452 and perplexity is 51.89549040919531
At time: 190.50103282928467 and batch: 750, loss is 3.8942709732055665 and perplexity is 49.12023034223137
At time: 190.8435502052307 and batch: 800, loss is 3.8188940858840943 and perplexity is 45.55380186086727
At time: 191.18804931640625 and batch: 850, loss is 3.772490668296814 and perplexity is 43.48824485239687
At time: 191.5322389602661 and batch: 900, loss is 3.6822423696517945 and perplexity is 39.73539569341747
At time: 191.87568354606628 and batch: 950, loss is 3.8479491329193114 and perplexity is 46.89678546537338
At time: 192.21742153167725 and batch: 1000, loss is 3.8795336198806765 and perplexity is 48.401636245709014
At time: 192.5761113166809 and batch: 1050, loss is 3.7767752695083616 and perplexity is 43.674974384106456
At time: 192.92106771469116 and batch: 1100, loss is 3.9372235918045044 and perplexity is 51.27604026985912
At time: 193.26257181167603 and batch: 1150, loss is 3.8492200326919557 and perplexity is 46.956424468929754
At time: 193.60581755638123 and batch: 1200, loss is 3.7869367027282714 and perplexity is 44.121037200283205
At time: 193.94912695884705 and batch: 1250, loss is 3.707551531791687 and perplexity is 40.75389963985063
At time: 194.2934558391571 and batch: 1300, loss is 3.8082260513305664 and perplexity is 45.07041530519783
At time: 194.6366376876831 and batch: 1350, loss is 3.78556077003479 and perplexity is 44.06037136835079
At time: 194.980633020401 and batch: 1400, loss is 3.644712815284729 and perplexity is 38.271780202872705
At time: 195.3242392539978 and batch: 1450, loss is 3.751721715927124 and perplexity is 42.59435428310909
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.513324444110577 and perplexity of 91.22458600255567
Finished 18 epochs...
Completing Train Step...
At time: 196.55759358406067 and batch: 50, loss is 3.935964365005493 and perplexity is 51.21151274172699
At time: 196.91796851158142 and batch: 100, loss is 3.9771529626846314 and perplexity is 53.36488592275952
At time: 197.2615885734558 and batch: 150, loss is 3.8039708232879637 and perplexity is 44.87903787617271
At time: 197.60546469688416 and batch: 200, loss is 3.9189313411712647 and perplexity is 50.346612666984775
At time: 197.9475691318512 and batch: 250, loss is 3.990395827293396 and perplexity is 54.076289999076536
At time: 198.2921266555786 and batch: 300, loss is 3.9822683000564574 and perplexity is 53.63856470093263
At time: 198.63291263580322 and batch: 350, loss is 3.9500014114379884 and perplexity is 51.93544013843286
At time: 198.9765112400055 and batch: 400, loss is 3.7726283740997313 and perplexity is 43.49423384842203
At time: 199.31869673728943 and batch: 450, loss is 3.8794584131240843 and perplexity is 48.39799625251098
At time: 199.6604950428009 and batch: 500, loss is 3.8376488399505617 and perplexity is 46.41621409761314
At time: 200.00396347045898 and batch: 550, loss is 3.8900712585449218 and perplexity is 48.914371966518715
At time: 200.34600186347961 and batch: 600, loss is 3.810069465637207 and perplexity is 45.153575379263415
At time: 200.6902039051056 and batch: 650, loss is 3.8876888370513916 and perplexity is 48.797976022557094
At time: 201.03317093849182 and batch: 700, loss is 3.9454093313217165 and perplexity is 51.69749518571897
At time: 201.39039063453674 and batch: 750, loss is 3.890645318031311 and perplexity is 48.94245978703544
At time: 201.73469638824463 and batch: 800, loss is 3.8155538129806517 and perplexity is 45.401893579662435
At time: 202.08008551597595 and batch: 850, loss is 3.769112911224365 and perplexity is 43.341599930664664
At time: 202.42223978042603 and batch: 900, loss is 3.6788671112060545 and perplexity is 39.601504549227485
At time: 202.76526880264282 and batch: 950, loss is 3.8448373603820802 and perplexity is 46.75108015474346
At time: 203.10960483551025 and batch: 1000, loss is 3.8767203950881957 and perplexity is 48.26566291407683
At time: 203.45299196243286 and batch: 1050, loss is 3.774345178604126 and perplexity is 43.56896907954258
At time: 203.79625701904297 and batch: 1100, loss is 3.9351778984069825 and perplexity is 51.17125243126632
At time: 204.1393883228302 and batch: 1150, loss is 3.8469775819778445 and perplexity is 46.851244975337885
At time: 204.48336577415466 and batch: 1200, loss is 3.7846131992340086 and perplexity is 44.0186408214169
At time: 204.82682347297668 and batch: 1250, loss is 3.7055011320114137 and perplexity is 40.67042346199761
At time: 205.1707170009613 and batch: 1300, loss is 3.8062066507339476 and perplexity is 44.97949191791056
At time: 205.5150420665741 and batch: 1350, loss is 3.783522982597351 and perplexity is 43.97067711703527
At time: 205.85853338241577 and batch: 1400, loss is 3.6430770206451415 and perplexity is 38.20922660633686
At time: 206.2003481388092 and batch: 1450, loss is 3.750252571105957 and perplexity is 42.53182295314012
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.513179942073985 and perplexity of 91.21140481646813
Finished 19 epochs...
Completing Train Step...
At time: 207.45294308662415 and batch: 50, loss is 3.93050847530365 and perplexity is 50.93286919217183
At time: 207.79734015464783 and batch: 100, loss is 3.972004542350769 and perplexity is 53.090847097800996
At time: 208.1414270401001 and batch: 150, loss is 3.7988000679016114 and perplexity is 44.64757827553402
At time: 208.48443460464478 and batch: 200, loss is 3.914084334373474 and perplexity is 50.1031727472191
At time: 208.827561378479 and batch: 250, loss is 3.985527362823486 and perplexity is 53.81366132048078
At time: 209.17079782485962 and batch: 300, loss is 3.977534894943237 and perplexity is 53.38527158689381
At time: 209.51469731330872 and batch: 350, loss is 3.945520324707031 and perplexity is 51.70323358417817
At time: 209.85851883888245 and batch: 400, loss is 3.768103609085083 and perplexity is 43.29787722955427
At time: 210.21792078018188 and batch: 450, loss is 3.8752226877212523 and perplexity is 48.19342918115943
At time: 210.55989599227905 and batch: 500, loss is 3.833211636543274 and perplexity is 46.21071217834729
At time: 210.90338826179504 and batch: 550, loss is 3.8856969451904297 and perplexity is 48.70087247327703
At time: 211.246919631958 and batch: 600, loss is 3.8064097118377687 and perplexity is 44.98862643058944
At time: 211.59103536605835 and batch: 650, loss is 3.883612022399902 and perplexity is 48.59944068980029
At time: 211.9332435131073 and batch: 700, loss is 3.941829648017883 and perplexity is 51.51276535975219
At time: 212.27637839317322 and batch: 750, loss is 3.8871510934829714 and perplexity is 48.77174227894466
At time: 212.61854338645935 and batch: 800, loss is 3.812303910255432 and perplexity is 45.25458134685884
At time: 212.961519241333 and batch: 850, loss is 3.7659064102172852 and perplexity is 43.2028476204333
At time: 213.30378198623657 and batch: 900, loss is 3.6755443477630614 and perplexity is 39.470136490981425
At time: 213.6467559337616 and batch: 950, loss is 3.8418490409851076 and perplexity is 46.611581532118365
At time: 213.9895076751709 and batch: 1000, loss is 3.8739244318008423 and perplexity is 48.13090237308176
At time: 214.33299326896667 and batch: 1050, loss is 3.7719649934768675 and perplexity is 43.46539018470226
At time: 214.67615818977356 and batch: 1100, loss is 3.9331907558441164 and perplexity is 51.06966882154949
At time: 215.0206742286682 and batch: 1150, loss is 3.844813733100891 and perplexity is 46.749975566875996
At time: 215.36671662330627 and batch: 1200, loss is 3.7823347282409667 and perplexity is 43.91845979827005
At time: 215.71014189720154 and batch: 1250, loss is 3.7033576488494875 and perplexity is 40.583340457936906
At time: 216.05205607414246 and batch: 1300, loss is 3.8040949487686158 and perplexity is 44.884608854063295
At time: 216.39486074447632 and batch: 1350, loss is 3.7813130712509153 and perplexity is 43.87361310969214
At time: 216.73777079582214 and batch: 1400, loss is 3.641272940635681 and perplexity is 38.14035624693814
At time: 217.08141088485718 and batch: 1450, loss is 3.748556208610535 and perplexity is 42.45973472499081
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.513101170205663 and perplexity of 91.2042202066747
Finished 20 epochs...
Completing Train Step...
At time: 218.32560753822327 and batch: 50, loss is 3.925419454574585 and perplexity is 50.67432918077579
At time: 218.6705710887909 and batch: 100, loss is 3.967116594314575 and perplexity is 52.83197498811447
At time: 219.02853345870972 and batch: 150, loss is 3.793998107910156 and perplexity is 44.433696328205144
At time: 219.3729145526886 and batch: 200, loss is 3.909510669708252 and perplexity is 49.87454087771218
At time: 219.71615314483643 and batch: 250, loss is 3.980967164039612 and perplexity is 53.568819016658956
At time: 220.06085062026978 and batch: 300, loss is 3.9730374813079834 and perplexity is 53.14571503477613
At time: 220.40405225753784 and batch: 350, loss is 3.941333112716675 and perplexity is 51.48719380240406
At time: 220.74580812454224 and batch: 400, loss is 3.763878049850464 and perplexity is 43.115305490094144
At time: 221.08832168579102 and batch: 450, loss is 3.8712387609481813 and perplexity is 48.001812036135945
At time: 221.43245220184326 and batch: 500, loss is 3.8289875650405882 and perplexity is 46.01592650983807
At time: 221.77415108680725 and batch: 550, loss is 3.8815382862091066 and perplexity is 48.498762696667896
At time: 222.11749076843262 and batch: 600, loss is 3.802941017150879 and perplexity is 44.83284495649976
At time: 222.45971012115479 and batch: 650, loss is 3.8797080183029173 and perplexity is 48.41007815081021
At time: 222.8041021823883 and batch: 700, loss is 3.9383498668670653 and perplexity is 51.33382372924842
At time: 223.14771914482117 and batch: 750, loss is 3.8837389183044433 and perplexity is 48.605608151091324
At time: 223.48975276947021 and batch: 800, loss is 3.8091366338729857 and perplexity is 45.11147432953267
At time: 223.83117198944092 and batch: 850, loss is 3.762838406562805 and perplexity is 43.07050424483828
At time: 224.1749050617218 and batch: 900, loss is 3.672291431427002 and perplexity is 39.34195203888413
At time: 224.51838517189026 and batch: 950, loss is 3.8389298915863037 and perplexity is 46.47571376754554
At time: 224.861168384552 and batch: 1000, loss is 3.8711600732803344 and perplexity is 47.99803503409808
At time: 225.20398211479187 and batch: 1050, loss is 3.7695608711242676 and perplexity is 43.36101957871828
At time: 225.54845094680786 and batch: 1100, loss is 3.9310362720489502 and perplexity is 50.95975849017804
At time: 225.89410042762756 and batch: 1150, loss is 3.842397117614746 and perplexity is 46.637135252685454
At time: 226.2369086742401 and batch: 1200, loss is 3.7799632024765013 and perplexity is 43.81442944341295
At time: 226.58014464378357 and batch: 1250, loss is 3.7011699199676515 and perplexity is 40.494652160243874
At time: 226.92374062538147 and batch: 1300, loss is 3.801871085166931 and perplexity is 44.78490251389931
At time: 227.26673030853271 and batch: 1350, loss is 3.7791230630874635 and perplexity is 43.77763467396113
At time: 227.61035633087158 and batch: 1400, loss is 3.63933856010437 and perplexity is 38.066649595695516
At time: 227.9525306224823 and batch: 1450, loss is 3.7467087411880495 and perplexity is 42.38136416413883
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.51305422008547 and perplexity of 91.19993825809372
Finished 21 epochs...
Completing Train Step...
At time: 229.1846477985382 and batch: 50, loss is 3.9206183385849 and perplexity is 50.431618954872796
At time: 229.54350328445435 and batch: 100, loss is 3.9624946641922 and perplexity is 52.58835272771713
At time: 229.88804459571838 and batch: 150, loss is 3.7894041681289674 and perplexity is 44.230038756498395
At time: 230.23223233222961 and batch: 200, loss is 3.9051520824432373 and perplexity is 49.6576313918463
At time: 230.5743477344513 and batch: 250, loss is 3.9766832160949708 and perplexity is 53.339823836465314
At time: 230.91750049591064 and batch: 300, loss is 3.9687908124923705 and perplexity is 52.920501326532566
At time: 231.26110005378723 and batch: 350, loss is 3.9373618221282958 and perplexity is 51.28312866341253
At time: 231.60521817207336 and batch: 400, loss is 3.759880013465881 and perplexity is 42.94327305513088
At time: 231.9471206665039 and batch: 450, loss is 3.867412552833557 and perplexity is 47.81849803580542
At time: 232.28962540626526 and batch: 500, loss is 3.8249361181259154 and perplexity is 45.82987257466892
At time: 232.63227462768555 and batch: 550, loss is 3.877553758621216 and perplexity is 48.30590252222862
At time: 232.97525811195374 and batch: 600, loss is 3.799659838676453 and perplexity is 44.68598146510715
At time: 233.31956267356873 and batch: 650, loss is 3.8759631443023683 and perplexity is 48.2291275378737
At time: 233.6641607284546 and batch: 700, loss is 3.9350212812423706 and perplexity is 51.16323876235632
At time: 234.00775599479675 and batch: 750, loss is 3.8804725122451784 and perplexity is 48.44710151256559
At time: 234.3521008491516 and batch: 800, loss is 3.806011185646057 and perplexity is 44.97070085677031
At time: 234.69514751434326 and batch: 850, loss is 3.759866394996643 and perplexity is 42.942688237469966
At time: 235.03864288330078 and batch: 900, loss is 3.6690903806686403 and perplexity is 39.21621780167599
At time: 235.38024139404297 and batch: 950, loss is 3.836087284088135 and perplexity is 46.34378914889607
At time: 235.7256579399109 and batch: 1000, loss is 3.868454351425171 and perplexity is 47.868341238493315
At time: 236.0698277950287 and batch: 1050, loss is 3.7671502351760866 and perplexity is 43.25661783402942
At time: 236.41352796554565 and batch: 1100, loss is 3.9289316844940188 and perplexity is 50.852621995269104
At time: 236.77299094200134 and batch: 1150, loss is 3.8400897216796874 and perplexity is 46.52964897077437
At time: 237.11448287963867 and batch: 1200, loss is 3.777648696899414 and perplexity is 43.71313796717026
At time: 237.45419597625732 and batch: 1250, loss is 3.698935742378235 and perplexity is 40.40428090620254
At time: 237.7942464351654 and batch: 1300, loss is 3.7996482038497925 and perplexity is 44.6854615544832
At time: 238.13884949684143 and batch: 1350, loss is 3.7768714475631713 and perplexity is 43.679175160194575
At time: 238.48109579086304 and batch: 1400, loss is 3.6373609113693237 and perplexity is 37.99144152635889
At time: 238.82449197769165 and batch: 1450, loss is 3.7447413349151613 and perplexity is 42.298064771171695
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.513077173477564 and perplexity of 91.20203163006039
Annealing...
Finished 22 epochs...
Completing Train Step...
At time: 240.0798783302307 and batch: 50, loss is 3.9183863592147827 and perplexity is 50.31918214675949
At time: 240.43884253501892 and batch: 100, loss is 3.9623683738708495 and perplexity is 52.581711747106475
At time: 240.78272938728333 and batch: 150, loss is 3.787245874404907 and perplexity is 44.13468028424822
At time: 241.12716484069824 and batch: 200, loss is 3.904608907699585 and perplexity is 49.630665944782535
At time: 241.47045755386353 and batch: 250, loss is 3.975871453285217 and perplexity is 53.29654212081635
At time: 241.81314516067505 and batch: 300, loss is 3.966067090034485 and perplexity is 52.776556690196
At time: 242.1572630405426 and batch: 350, loss is 3.9359872913360596 and perplexity is 51.21268684725583
At time: 242.50313067436218 and batch: 400, loss is 3.7545988512039186 and perplexity is 42.71708046766714
At time: 242.84628009796143 and batch: 450, loss is 3.86619779586792 and perplexity is 47.76044544926077
At time: 243.19032263755798 and batch: 500, loss is 3.820081977844238 and perplexity is 45.60794700877776
At time: 243.53332567214966 and batch: 550, loss is 3.872793083190918 and perplexity is 48.07648033454118
At time: 243.87846732139587 and batch: 600, loss is 3.796542248725891 and perplexity is 44.546885832593695
At time: 244.22177147865295 and batch: 650, loss is 3.8702587842941285 and perplexity is 47.95479442283278
At time: 244.56420135498047 and batch: 700, loss is 3.929539303779602 and perplexity is 50.88353041844196
At time: 244.90864324569702 and batch: 750, loss is 3.8738534832000733 and perplexity is 48.12748767404013
At time: 245.25264716148376 and batch: 800, loss is 3.79670401096344 and perplexity is 44.5540924193829
At time: 245.61039543151855 and batch: 850, loss is 3.7467252588272095 and perplexity is 42.38206421000074
At time: 245.95364570617676 and batch: 900, loss is 3.6524094247817995 and perplexity is 38.56747963165405
At time: 246.2981653213501 and batch: 950, loss is 3.8187574100494386 and perplexity is 45.54757618243578
At time: 246.64086985588074 and batch: 1000, loss is 3.8540688800811767 and perplexity is 47.18466190218413
At time: 246.9853217601776 and batch: 1050, loss is 3.7528308391571046 and perplexity is 42.64162287941397
At time: 247.32789015769958 and batch: 1100, loss is 3.9145884132385254 and perplexity is 50.12843506423811
At time: 247.67112731933594 and batch: 1150, loss is 3.820026607513428 and perplexity is 45.60542175157712
At time: 248.01364922523499 and batch: 1200, loss is 3.760159969329834 and perplexity is 42.95529695924269
At time: 248.35872387886047 and batch: 1250, loss is 3.677603077888489 and perplexity is 39.551478551976054
At time: 248.7015609741211 and batch: 1300, loss is 3.777204155921936 and perplexity is 43.69371000467237
At time: 249.0452642440796 and batch: 1350, loss is 3.755006709098816 and perplexity is 42.73450651961771
At time: 249.38849115371704 and batch: 1400, loss is 3.611292452812195 and perplexity is 37.01386058172518
At time: 249.73350954055786 and batch: 1450, loss is 3.718603630065918 and perplexity is 41.20681396027943
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.506375304654113 and perplexity of 90.59285118148384
Finished 23 epochs...
Completing Train Step...
At time: 250.9824824333191 and batch: 50, loss is 3.9131287908554078 and perplexity is 50.055319851669076
At time: 251.32508087158203 and batch: 100, loss is 3.956784043312073 and perplexity is 52.288896437053566
At time: 251.6688940525055 and batch: 150, loss is 3.7817848682403565 and perplexity is 43.89431743200761
At time: 252.0113651752472 and batch: 200, loss is 3.899551019668579 and perplexity is 49.38027335616793
At time: 252.35566687583923 and batch: 250, loss is 3.970068588256836 and perplexity is 52.98816508091744
At time: 252.6998827457428 and batch: 300, loss is 3.9615210103988647 and perplexity is 52.53717479743459
At time: 253.04434967041016 and batch: 350, loss is 3.9311808729171753 and perplexity is 50.96712784829521
At time: 253.38690161705017 and batch: 400, loss is 3.74942985534668 and perplexity is 42.496845742249995
At time: 253.7314305305481 and batch: 450, loss is 3.860290274620056 and perplexity is 47.479131355581394
At time: 254.0763077735901 and batch: 500, loss is 3.814958052635193 and perplexity is 45.374852987514984
At time: 254.4335880279541 and batch: 550, loss is 3.8678152561187744 and perplexity is 47.83775857994051
At time: 254.77745032310486 and batch: 600, loss is 3.791772389411926 and perplexity is 44.334909405064906
At time: 255.12148141860962 and batch: 650, loss is 3.8665911817550658 and perplexity is 47.77923743047206
At time: 255.46590447425842 and batch: 700, loss is 3.925602493286133 and perplexity is 50.683605393624724
At time: 255.81200623512268 and batch: 750, loss is 3.869928951263428 and perplexity is 47.938979955861825
At time: 256.1567289829254 and batch: 800, loss is 3.793118944168091 and perplexity is 44.3946490004799
At time: 256.5026571750641 and batch: 850, loss is 3.7446142482757567 and perplexity is 42.29268959383046
At time: 256.8464493751526 and batch: 900, loss is 3.651015462875366 and perplexity is 38.51375548762491
At time: 257.1900100708008 and batch: 950, loss is 3.8178009462356566 and perplexity is 45.50403240135684
At time: 257.534227848053 and batch: 1000, loss is 3.8525515031814574 and perplexity is 47.11311927848182
At time: 257.87799525260925 and batch: 1050, loss is 3.752575297355652 and perplexity is 42.630727554451276
At time: 258.22361040115356 and batch: 1100, loss is 3.9142172956466674 and perplexity is 50.10983497175771
At time: 258.5656142234802 and batch: 1150, loss is 3.820091872215271 and perplexity is 45.60839827295999
At time: 258.90854835510254 and batch: 1200, loss is 3.7610000562667847 and perplexity is 42.99139830510232
At time: 259.2531569004059 and batch: 1250, loss is 3.6785989570617676 and perplexity is 39.590886665341024
At time: 259.59863114356995 and batch: 1300, loss is 3.7785884094238282 and perplexity is 43.75423505710026
At time: 259.94181060791016 and batch: 1350, loss is 3.756732368469238 and perplexity is 42.808315387399524
At time: 260.2855484485626 and batch: 1400, loss is 3.613477487564087 and perplexity is 37.09482557684884
At time: 260.62718534469604 and batch: 1450, loss is 3.7212228298187258 and perplexity is 41.314884304345355
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.5057065262753735 and perplexity of 90.53228489631374
Finished 24 epochs...
Completing Train Step...
At time: 261.8892638683319 and batch: 50, loss is 3.9110831022262573 and perplexity is 49.95302691843852
At time: 262.2323820590973 and batch: 100, loss is 3.954476990699768 and perplexity is 52.16840224859416
At time: 262.57653999328613 and batch: 150, loss is 3.779321508407593 and perplexity is 43.78632300273909
At time: 262.91923213005066 and batch: 200, loss is 3.897403712272644 and perplexity is 49.274352493002844
At time: 263.2764382362366 and batch: 250, loss is 3.96756103515625 and perplexity is 52.85546089420686
At time: 263.61878967285156 and batch: 300, loss is 3.959405040740967 and perplexity is 52.426125259811364
At time: 263.960946559906 and batch: 350, loss is 3.929099235534668 and perplexity is 50.86114311884578
At time: 264.3035798072815 and batch: 400, loss is 3.747221302986145 and perplexity is 42.4030928005193
At time: 264.64523243904114 and batch: 450, loss is 3.857727975845337 and perplexity is 47.357631361601534
At time: 264.9889249801636 and batch: 500, loss is 3.812885422706604 and perplexity is 45.280905102438645
At time: 265.33305621147156 and batch: 550, loss is 3.865807366371155 and perplexity is 47.74180200229137
At time: 265.6756730079651 and batch: 600, loss is 3.790065870285034 and perplexity is 44.259315553698166
At time: 266.01872181892395 and batch: 650, loss is 3.8651273441314697 and perplexity is 47.709347551292055
At time: 266.3606524467468 and batch: 700, loss is 3.9241225814819334 and perplexity is 50.60865360242315
At time: 266.70362615585327 and batch: 750, loss is 3.8684395027160643 and perplexity is 47.86763046069592
At time: 267.0473711490631 and batch: 800, loss is 3.791713376045227 and perplexity is 44.33229312999697
At time: 267.39019751548767 and batch: 850, loss is 3.7435586071014404 and perplexity is 42.24806724606028
At time: 267.7335903644562 and batch: 900, loss is 3.6502282333374025 and perplexity is 38.48344825262764
At time: 268.0769500732422 and batch: 950, loss is 3.81724732875824 and perplexity is 45.478847545757866
At time: 268.42206931114197 and batch: 1000, loss is 3.851974687576294 and perplexity is 47.08595153221732
At time: 268.76387071609497 and batch: 1050, loss is 3.752594618797302 and perplexity is 42.63155124952368
At time: 269.1078746318817 and batch: 1100, loss is 3.9140674591064455 and perplexity is 50.10232724993403
At time: 269.45251846313477 and batch: 1150, loss is 3.8200144386291504 and perplexity is 45.60486678785405
At time: 269.7995283603668 and batch: 1200, loss is 3.761426272392273 and perplexity is 43.00972583778478
At time: 270.14286518096924 and batch: 1250, loss is 3.679042544364929 and perplexity is 39.60845257570604
At time: 270.485547542572 and batch: 1300, loss is 3.7792225790023806 and perplexity is 43.7819914621099
At time: 270.8295896053314 and batch: 1350, loss is 3.757450909614563 and perplexity is 42.83908597701087
At time: 271.1734023094177 and batch: 1400, loss is 3.6142909383773802 and perplexity is 37.12501266907609
At time: 271.5156178474426 and batch: 1450, loss is 3.7223363494873047 and perplexity is 41.36091486383377
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.505467602330396 and perplexity of 90.51065714945464
Finished 25 epochs...
Completing Train Step...
At time: 272.7492105960846 and batch: 50, loss is 3.90938232421875 and perplexity is 49.86814011611276
At time: 273.1080219745636 and batch: 100, loss is 3.952733540534973 and perplexity is 52.07752847905945
At time: 273.44990491867065 and batch: 150, loss is 3.7774853324890136 and perplexity is 43.70599737943434
At time: 273.7942168712616 and batch: 200, loss is 3.8958437252044678 and perplexity is 49.19754506519434
At time: 274.1384708881378 and batch: 250, loss is 3.9657988595962523 and perplexity is 52.76240230966929
At time: 274.48231172561646 and batch: 300, loss is 3.9578397035598756 and perplexity is 52.34412489253717
At time: 274.82590317726135 and batch: 350, loss is 3.927650799751282 and perplexity is 50.78752734589868
At time: 275.17160964012146 and batch: 400, loss is 3.7456818771362306 and perplexity is 42.337866601675415
At time: 275.5157744884491 and batch: 450, loss is 3.8559788131713866 and perplexity is 47.27486756527056
At time: 275.85812616348267 and batch: 500, loss is 3.8114209175109863 and perplexity is 45.21463951664493
At time: 276.2018904685974 and batch: 550, loss is 3.864426703453064 and perplexity is 47.67593214911941
At time: 276.5463399887085 and batch: 600, loss is 3.788917942047119 and perplexity is 44.2085381855466
At time: 276.8888101577759 and batch: 650, loss is 3.8640928983688356 and perplexity is 47.660020336442436
At time: 277.2312376499176 and batch: 700, loss is 3.923151469230652 and perplexity is 50.5595307746394
At time: 277.5741846561432 and batch: 750, loss is 3.8674218463897705 and perplexity is 47.81894244177001
At time: 277.91817235946655 and batch: 800, loss is 3.790708818435669 and perplexity is 44.28778114875203
At time: 278.26171040534973 and batch: 850, loss is 3.7427311182022094 and perplexity is 42.21312189983727
At time: 278.6064078807831 and batch: 900, loss is 3.6495450496673585 and perplexity is 38.457165968050525
At time: 278.9490406513214 and batch: 950, loss is 3.8167270040512085 and perplexity is 45.45518993308644
At time: 279.2932975292206 and batch: 1000, loss is 3.8514925813674927 and perplexity is 47.06325657376609
At time: 279.63744735717773 and batch: 1050, loss is 3.7524904012680054 and perplexity is 42.62710852609123
At time: 279.9814977645874 and batch: 1100, loss is 3.9138786029815673 and perplexity is 50.09286601199671
At time: 280.3243088722229 and batch: 1150, loss is 3.819818081855774 and perplexity is 45.595912842474
At time: 280.6677131652832 and batch: 1200, loss is 3.7615754890441893 and perplexity is 43.01614408391683
At time: 281.02727603912354 and batch: 1250, loss is 3.6791913080215455 and perplexity is 39.61434531224577
At time: 281.3697760105133 and batch: 1300, loss is 3.779500651359558 and perplexity is 43.794167716539114
At time: 281.7121992111206 and batch: 1350, loss is 3.7577672576904297 and perplexity is 42.852640183242066
At time: 282.0559358596802 and batch: 1400, loss is 3.61459409236908 and perplexity is 37.136268970968835
At time: 282.4017927646637 and batch: 1450, loss is 3.722888317108154 and perplexity is 41.3837510514456
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.505349705361913 and perplexity of 90.49998684637188
Finished 26 epochs...
Completing Train Step...
At time: 283.66049885749817 and batch: 50, loss is 3.9078674030303957 and perplexity is 49.79265100848856
At time: 284.0186040401459 and batch: 100, loss is 3.9512548542022703 and perplexity is 52.0005790555079
At time: 284.36137223243713 and batch: 150, loss is 3.7759509658813477 and perplexity is 43.638987778294414
At time: 284.7051947116852 and batch: 200, loss is 3.8945409870147705 and perplexity is 49.13349527351178
At time: 285.05051016807556 and batch: 250, loss is 3.9643561744689944 and perplexity is 52.686337658442284
At time: 285.39475655555725 and batch: 300, loss is 3.9565119171142578 and perplexity is 52.27466919436873
At time: 285.7373344898224 and batch: 350, loss is 3.9264747047424318 and perplexity is 50.727831499349854
At time: 286.08047676086426 and batch: 400, loss is 3.7444214391708375 and perplexity is 42.28453596427751
At time: 286.4252896308899 and batch: 450, loss is 3.8545583295822143 and perplexity is 47.207762064129
At time: 286.768785238266 and batch: 500, loss is 3.810185651779175 and perplexity is 45.1588219037636
At time: 287.1120460033417 and batch: 550, loss is 3.8632888555526734 and perplexity is 47.6217150410852
At time: 287.4553623199463 and batch: 600, loss is 3.78797468662262 and perplexity is 44.16685790276067
At time: 287.80055141448975 and batch: 650, loss is 3.8632137537002564 and perplexity is 47.618138696367076
At time: 288.1442971229553 and batch: 700, loss is 3.922363715171814 and perplexity is 50.51971798246189
At time: 288.48770213127136 and batch: 750, loss is 3.8665830421447756 and perplexity is 47.77884852768217
At time: 288.83175802230835 and batch: 800, loss is 3.789845871925354 and perplexity is 44.249579647856706
At time: 289.17649364471436 and batch: 850, loss is 3.7419863176345824 and perplexity is 42.18169324817663
At time: 289.5206127166748 and batch: 900, loss is 3.648900475502014 and perplexity is 38.43238545969088
At time: 289.87766194343567 and batch: 950, loss is 3.8162031030654906 and perplexity is 45.43138215127923
At time: 290.22198700904846 and batch: 1000, loss is 3.851016111373901 and perplexity is 47.040837685595875
At time: 290.5657618045807 and batch: 1050, loss is 3.7522889947891236 and perplexity is 42.61852401477519
At time: 290.90870928764343 and batch: 1100, loss is 3.9136497354507447 and perplexity is 50.081402693281476
At time: 291.25262689590454 and batch: 1150, loss is 3.819560236930847 and perplexity is 45.584157683319354
At time: 291.594034910202 and batch: 1200, loss is 3.76158492565155 and perplexity is 43.01655001229401
At time: 291.9389088153839 and batch: 1250, loss is 3.6791702365875243 and perplexity is 39.613510589976656
At time: 292.28156638145447 and batch: 1300, loss is 3.779575562477112 and perplexity is 43.7974485094675
At time: 292.6250193119049 and batch: 1350, loss is 3.757874732017517 and perplexity is 42.8572459894082
At time: 292.967835187912 and batch: 1400, loss is 3.6146576833724975 and perplexity is 37.138630578663594
At time: 293.3107204437256 and batch: 1450, loss is 3.7231628274917603 and perplexity is 41.39511288022043
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.505277715177617 and perplexity of 90.49347197014644
Finished 27 epochs...
Completing Train Step...
At time: 294.557799577713 and batch: 50, loss is 3.9064671182632447 and perplexity is 49.722975911638585
At time: 294.9010920524597 and batch: 100, loss is 3.9499183082580567 and perplexity is 51.93112431753791
At time: 295.2446310520172 and batch: 150, loss is 3.774581570625305 and perplexity is 43.57926965364278
At time: 295.58793926239014 and batch: 200, loss is 3.8933766078948975 and perplexity is 49.07631855167936
At time: 295.93029618263245 and batch: 250, loss is 3.9630816841125487 and perplexity is 52.61923220089284
At time: 296.2738516330719 and batch: 300, loss is 3.9553164434432984 and perplexity is 52.2122135431703
At time: 296.6187708377838 and batch: 350, loss is 3.92542697429657 and perplexity is 50.674710239075736
At time: 296.96390175819397 and batch: 400, loss is 3.7433092069625853 and perplexity is 42.23753188603749
At time: 297.30842423439026 and batch: 450, loss is 3.853316307067871 and perplexity is 47.149165357540724
At time: 297.6510591506958 and batch: 500, loss is 3.8090724658966066 and perplexity is 45.108579710385385
At time: 297.9961190223694 and batch: 550, loss is 3.8622716522216796 and perplexity is 47.57329870272281
At time: 298.3379919528961 and batch: 600, loss is 3.7871207571029664 and perplexity is 44.12915861756426
At time: 298.6953880786896 and batch: 650, loss is 3.862402009963989 and perplexity is 47.57950065476336
At time: 299.03892731666565 and batch: 700, loss is 3.9216544675827025 and perplexity is 50.48389969779774
At time: 299.38335037231445 and batch: 750, loss is 3.8658249044418334 and perplexity is 47.74263930873155
At time: 299.7258789539337 and batch: 800, loss is 3.7890343189239504 and perplexity is 44.213683336532405
At time: 300.0700852870941 and batch: 850, loss is 3.741276378631592 and perplexity is 42.151757446481504
At time: 300.4141092300415 and batch: 900, loss is 3.6482749462127684 and perplexity is 38.40835239440704
At time: 300.7598443031311 and batch: 950, loss is 3.815682020187378 and perplexity is 45.407714802771764
At time: 301.1041362285614 and batch: 1000, loss is 3.8505505609512327 and perplexity is 47.01894290068731
At time: 301.4474723339081 and batch: 1050, loss is 3.7520393753051757 and perplexity is 42.60788692847123
At time: 301.79170060157776 and batch: 1100, loss is 3.913380751609802 and perplexity is 50.067933416815315
At time: 302.13507318496704 and batch: 1150, loss is 3.81921856880188 and perplexity is 45.568585689831586
At time: 302.4776887893677 and batch: 1200, loss is 3.7614532852172853 and perplexity is 43.01088766767475
At time: 302.82055926322937 and batch: 1250, loss is 3.6790270137786867 and perplexity is 39.60783743799412
At time: 303.16274666786194 and batch: 1300, loss is 3.7794891166687012 and perplexity is 43.79366256726655
At time: 303.50889468193054 and batch: 1350, loss is 3.7578319978713988 and perplexity is 42.85541456072841
At time: 303.85139775276184 and batch: 1400, loss is 3.6145849514007566 and perplexity is 37.13592951106203
At time: 304.1952950954437 and batch: 1450, loss is 3.723231987953186 and perplexity is 41.3979758843302
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.505207811665331 and perplexity of 90.48714637970983
Finished 28 epochs...
Completing Train Step...
At time: 305.44291591644287 and batch: 50, loss is 3.9051010274887084 and perplexity is 49.65509618845147
At time: 305.78561329841614 and batch: 100, loss is 3.9486328172683716 and perplexity is 51.864410214519665
At time: 306.12851333618164 and batch: 150, loss is 3.7732831192016603 and perplexity is 43.52272080982799
At time: 306.4727280139923 and batch: 200, loss is 3.8922838735580445 and perplexity is 49.02272046284095
At time: 306.8154923915863 and batch: 250, loss is 3.9618296575546266 and perplexity is 52.55339274969125
At time: 307.15990710258484 and batch: 300, loss is 3.954180817604065 and perplexity is 52.1529536592435
At time: 307.50175070762634 and batch: 350, loss is 3.924369897842407 and perplexity is 50.621171498317
At time: 307.8604006767273 and batch: 400, loss is 3.7423631858825686 and perplexity is 42.197593184910616
At time: 308.2035400867462 and batch: 450, loss is 3.8522456407547 and perplexity is 47.09871134902164
At time: 308.5470814704895 and batch: 500, loss is 3.808048129081726 and perplexity is 45.06239698889014
At time: 308.8906157016754 and batch: 550, loss is 3.8613153648376466 and perplexity is 47.527826702971694
At time: 309.23418378829956 and batch: 600, loss is 3.7862810707092285 and perplexity is 44.09211951629695
At time: 309.57798171043396 and batch: 650, loss is 3.8615911054611205 and perplexity is 47.540933862544264
At time: 309.92154026031494 and batch: 700, loss is 3.920986042022705 and perplexity is 50.45016624427864
At time: 310.2644989490509 and batch: 750, loss is 3.865109248161316 and perplexity is 47.708484212174206
At time: 310.6096942424774 and batch: 800, loss is 3.788199071884155 and perplexity is 44.17676940667849
At time: 310.9557628631592 and batch: 850, loss is 3.7405757093429566 and perplexity is 42.12223334909878
At time: 311.29886960983276 and batch: 900, loss is 3.647587356567383 and perplexity is 38.38195228626494
At time: 311.64166831970215 and batch: 950, loss is 3.8151430797576906 and perplexity is 45.38324934274979
At time: 311.9847710132599 and batch: 1000, loss is 3.850021915435791 and perplexity is 46.9940931163243
At time: 312.3278753757477 and batch: 1050, loss is 3.7517281770706177 and perplexity is 42.59462949223321
At time: 312.6705734729767 and batch: 1100, loss is 3.913088421821594 and perplexity is 50.05329920755544
At time: 313.0130832195282 and batch: 1150, loss is 3.818868384361267 and perplexity is 45.55263107383444
At time: 313.35582518577576 and batch: 1200, loss is 3.7612458801269533 and perplexity is 43.00196791566574
At time: 313.6994125843048 and batch: 1250, loss is 3.678817853927612 and perplexity is 39.59955393493254
At time: 314.0418236255646 and batch: 1300, loss is 3.779311933517456 and perplexity is 43.78590375551397
At time: 314.3843493461609 and batch: 1350, loss is 3.757710270881653 and perplexity is 42.850198217610945
At time: 314.72768688201904 and batch: 1400, loss is 3.6144317865371702 and perplexity is 37.13024202705679
At time: 315.0728590488434 and batch: 1450, loss is 3.723183455467224 and perplexity is 41.39596678640039
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.505163991553152 and perplexity of 90.48318130968026
Finished 29 epochs...
Completing Train Step...
At time: 316.3070242404938 and batch: 50, loss is 3.9038266944885254 and perplexity is 49.5918593616965
At time: 316.6674835681915 and batch: 100, loss is 3.9474367618560793 and perplexity is 51.80241458846992
At time: 317.00945687294006 and batch: 150, loss is 3.7720683813095093 and perplexity is 43.469884209498126
At time: 317.3533203601837 and batch: 200, loss is 3.8912657070159913 and perplexity is 48.97283257046644
At time: 317.6972997188568 and batch: 250, loss is 3.96070209980011 and perplexity is 52.49416915945405
At time: 318.041220664978 and batch: 300, loss is 3.953151206970215 and perplexity is 52.09928405770673
At time: 318.3843266963959 and batch: 350, loss is 3.923459053039551 and perplexity is 50.5750844595994
At time: 318.72729086875916 and batch: 400, loss is 3.7414480018615723 and perplexity is 42.1589922880595
At time: 319.07127571105957 and batch: 450, loss is 3.8511709547042847 and perplexity is 47.048122209532565
At time: 319.4140911102295 and batch: 500, loss is 3.807051773071289 and perplexity is 45.0175211586696
At time: 319.7561345100403 and batch: 550, loss is 3.860398168563843 and perplexity is 47.48425434267559
At time: 320.0989532470703 and batch: 600, loss is 3.78551992893219 and perplexity is 44.0585719309489
At time: 320.4406564235687 and batch: 650, loss is 3.8608597135543823 and perplexity is 47.50617552081279
At time: 320.78684306144714 and batch: 700, loss is 3.920333251953125 and perplexity is 50.41724362369473
At time: 321.1294538974762 and batch: 750, loss is 3.8644453716278075 and perplexity is 47.676822180059425
At time: 321.472825050354 and batch: 800, loss is 3.7874525117874147 and perplexity is 44.1438011013784
At time: 321.8157489299774 and batch: 850, loss is 3.7398997259140017 and perplexity is 42.093769039149045
At time: 322.15961933135986 and batch: 900, loss is 3.646963777542114 and perplexity is 38.35802556674591
At time: 322.50262808799744 and batch: 950, loss is 3.8146194934844972 and perplexity is 45.359493516016116
At time: 322.8459358215332 and batch: 1000, loss is 3.849529538154602 and perplexity is 46.9709599881045
At time: 323.1893558502197 and batch: 1050, loss is 3.751409454345703 and perplexity is 42.581055779095045
At time: 323.5339164733887 and batch: 1100, loss is 3.912763066291809 and perplexity is 50.03701673881351
At time: 323.87823843955994 and batch: 1150, loss is 3.8184787034988403 and perplexity is 45.53488354343285
At time: 324.2207043170929 and batch: 1200, loss is 3.7610373878479004 and perplexity is 42.99300327193322
At time: 324.56649708747864 and batch: 1250, loss is 3.6785623264312743 and perplexity is 39.589436452761944
At time: 324.91020917892456 and batch: 1300, loss is 3.779128284454346 and perplexity is 43.777863253649755
At time: 325.25539898872375 and batch: 1350, loss is 3.7575526094436644 and perplexity is 42.843442926280325
At time: 325.59802985191345 and batch: 1400, loss is 3.614212074279785 and perplexity is 37.122084953901066
At time: 325.942743062973 and batch: 1450, loss is 3.723100533485413 and perplexity is 41.392534293112014
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.505143646501068 and perplexity of 90.48134044337012
Finished 30 epochs...
Completing Train Step...
At time: 327.17123436927795 and batch: 50, loss is 3.9026393508911132 and perplexity is 49.53301172809366
At time: 327.5297827720642 and batch: 100, loss is 3.9463303899765014 and perplexity is 51.745133546584945
At time: 327.8747820854187 and batch: 150, loss is 3.7709407949447633 and perplexity is 43.42089578531651
At time: 328.21914315223694 and batch: 200, loss is 3.890304250717163 and perplexity is 48.925769960067086
At time: 328.5646092891693 and batch: 250, loss is 3.95967887878418 and perplexity is 52.440483493191294
At time: 328.9082922935486 and batch: 300, loss is 3.952167191505432 and perplexity is 52.04804277173345
At time: 329.25217604637146 and batch: 350, loss is 3.9226070642471313 and perplexity is 50.5320134050974
At time: 329.5959632396698 and batch: 400, loss is 3.7405528163909914 and perplexity is 42.12126905787183
At time: 329.939777135849 and batch: 450, loss is 3.8501480770111085 and perplexity is 47.000022339154654
At time: 330.286869764328 and batch: 500, loss is 3.806096568107605 and perplexity is 44.97454072983357
At time: 330.6306517124176 and batch: 550, loss is 3.859527883529663 and perplexity is 47.44294748373969
At time: 330.9769506454468 and batch: 600, loss is 3.784802532196045 and perplexity is 44.02697579008569
At time: 331.32178497314453 and batch: 650, loss is 3.8601605176925657 and perplexity is 47.47297100905925
At time: 331.67235803604126 and batch: 700, loss is 3.919703469276428 and perplexity is 50.385501713355495
At time: 332.02016043663025 and batch: 750, loss is 3.863805193901062 and perplexity is 47.64631030797025
At time: 332.40237855911255 and batch: 800, loss is 3.7867398118972777 and perplexity is 44.11235102774646
At time: 332.74736738204956 and batch: 850, loss is 3.7392346143722532 and perplexity is 42.06578129604265
At time: 333.09104442596436 and batch: 900, loss is 3.646355676651001 and perplexity is 38.334707107923784
At time: 333.43469500541687 and batch: 950, loss is 3.814092364311218 and perplexity is 45.33558950450308
At time: 333.7815411090851 and batch: 1000, loss is 3.8490345096588134 and perplexity is 46.94771377867859
At time: 334.15097308158875 and batch: 1050, loss is 3.7510682725906372 and perplexity is 42.56653037779363
At time: 334.4960153102875 and batch: 1100, loss is 3.912420220375061 and perplexity is 50.01986469236091
At time: 334.84256649017334 and batch: 1150, loss is 3.8180690479278563 and perplexity is 45.5162337449729
At time: 335.1903884410858 and batch: 1200, loss is 3.7608001804351807 and perplexity is 42.98280622231772
At time: 335.5354759693146 and batch: 1250, loss is 3.6782692289352417 and perplexity is 39.577834588390054
At time: 335.87955617904663 and batch: 1300, loss is 3.7788994693756104 and perplexity is 43.76784736435945
At time: 336.22281980514526 and batch: 1350, loss is 3.757355561256409 and perplexity is 42.83500153522363
At time: 336.5659296512604 and batch: 1400, loss is 3.613950810432434 and perplexity is 37.11238756200843
At time: 336.9117228984833 and batch: 1450, loss is 3.722967462539673 and perplexity is 41.387026515897745
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.505127996461004 and perplexity of 90.47992441784761
Finished 31 epochs...
Completing Train Step...
At time: 338.1637718677521 and batch: 50, loss is 3.9014982271194456 and perplexity is 49.47652066870387
At time: 338.50659799575806 and batch: 100, loss is 3.9452662801742555 and perplexity is 51.690100328645805
At time: 338.8491749763489 and batch: 150, loss is 3.769863972663879 and perplexity is 43.374164362513184
At time: 339.1931552886963 and batch: 200, loss is 3.8893815994262697 and perplexity is 48.88064935374919
At time: 339.5365252494812 and batch: 250, loss is 3.958704266548157 and perplexity is 52.38939925402176
At time: 339.87927079200745 and batch: 300, loss is 3.9512241888046264 and perplexity is 51.99898446152301
At time: 340.22092461586 and batch: 350, loss is 3.9217913246154783 and perplexity is 50.49080924731277
At time: 340.56513810157776 and batch: 400, loss is 3.7396886920928956 and perplexity is 42.084886767486786
At time: 340.90825605392456 and batch: 450, loss is 3.8491661310195924 and perplexity is 46.953893507334826
At time: 341.2509105205536 and batch: 500, loss is 3.8051719665527344 and perplexity is 44.93297641772005
At time: 341.5960166454315 and batch: 550, loss is 3.858686351776123 and perplexity is 47.40303953121037
At time: 341.93965005874634 and batch: 600, loss is 3.7841074323654174 and perplexity is 43.996383280326896
At time: 342.2842810153961 and batch: 650, loss is 3.859480309486389 and perplexity is 47.44069048459075
At time: 342.6286127567291 and batch: 700, loss is 3.919090790748596 and perplexity is 50.35464105313898
At time: 343.0013732910156 and batch: 750, loss is 3.86318302154541 and perplexity is 47.61667531084178
At time: 343.3437457084656 and batch: 800, loss is 3.7860462617874147 and perplexity is 44.08176750867228
At time: 343.69009804725647 and batch: 850, loss is 3.7385794830322268 and perplexity is 42.03823170965698
At time: 344.03494000434875 and batch: 900, loss is 3.6457559156417845 and perplexity is 38.31172233867392
At time: 344.38001704216003 and batch: 950, loss is 3.8135660600662233 and perplexity is 45.31173546908819
At time: 344.7768518924713 and batch: 1000, loss is 3.848537130355835 and perplexity is 46.92436876366783
At time: 345.1219651699066 and batch: 1050, loss is 3.7507126712799073 and perplexity is 42.55139635479675
At time: 345.4665138721466 and batch: 1100, loss is 3.912063994407654 and perplexity is 50.00204949097837
At time: 345.8096160888672 and batch: 1150, loss is 3.817643904685974 and perplexity is 45.496886938673676
At time: 346.1530463695526 and batch: 1200, loss is 3.760536150932312 and perplexity is 42.97145899142673
At time: 346.4993577003479 and batch: 1250, loss is 3.677950372695923 and perplexity is 39.565216960604396
At time: 346.84699034690857 and batch: 1300, loss is 3.778637375831604 and perplexity is 43.75637759727179
At time: 347.19342136383057 and batch: 1350, loss is 3.7571276903152464 and perplexity is 42.825241795131916
At time: 347.54045033454895 and batch: 1400, loss is 3.613657970428467 and perplexity is 37.101521161423584
At time: 347.8883309364319 and batch: 1450, loss is 3.7227932977676392 and perplexity is 41.37981898152696
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.505115476428953 and perplexity of 90.4787916133853
Finished 32 epochs...
Completing Train Step...
At time: 349.1489100456238 and batch: 50, loss is 3.900394320487976 and perplexity is 49.42193334463355
At time: 349.49353194236755 and batch: 100, loss is 3.944237914085388 and perplexity is 51.63697130506292
At time: 349.83709192276 and batch: 150, loss is 3.7688284969329833 and perplexity is 43.32927471305013
At time: 350.17977237701416 and batch: 200, loss is 3.888491072654724 and perplexity is 48.83713920324151
At time: 350.5241930484772 and batch: 250, loss is 3.957767195701599 and perplexity is 52.34032966974125
At time: 350.87366771698 and batch: 300, loss is 3.950312752723694 and perplexity is 51.951612302539786
At time: 351.2177731990814 and batch: 350, loss is 3.9210042810440062 and perplexity is 50.4510864143269
At time: 351.56154131889343 and batch: 400, loss is 3.738851337432861 and perplexity is 42.04966154149679
At time: 351.90510869026184 and batch: 450, loss is 3.8482157373428345 and perplexity is 46.90929002263853
At time: 352.2644581794739 and batch: 500, loss is 3.8042716646194457 and perplexity is 44.89254137678672
At time: 352.6104598045349 and batch: 550, loss is 3.857867546081543 and perplexity is 47.36424153867807
At time: 352.9533839225769 and batch: 600, loss is 3.7834311389923094 and perplexity is 43.96663887697882
At time: 353.2959871292114 and batch: 650, loss is 3.8588151216506956 and perplexity is 47.409144007693065
At time: 353.64080142974854 and batch: 700, loss is 3.9184928703308106 and perplexity is 50.32454198444363
At time: 353.98382592201233 and batch: 750, loss is 3.862575397491455 and perplexity is 47.58775106197813
At time: 354.3275375366211 and batch: 800, loss is 3.785368075370789 and perplexity is 44.051881987849626
At time: 354.6700053215027 and batch: 850, loss is 3.7379328203201294 and perplexity is 42.01105594045316
At time: 355.0141477584839 and batch: 900, loss is 3.6451623821258545 and perplexity is 38.28898979434375
At time: 355.35975074768066 and batch: 950, loss is 3.8130411863327027 and perplexity is 45.28795876974857
At time: 355.7034718990326 and batch: 1000, loss is 3.8480387687683106 and perplexity is 46.900989286957646
At time: 356.04769253730774 and batch: 1050, loss is 3.7503470849990843 and perplexity is 42.535842991280965
At time: 356.3907678127289 and batch: 1100, loss is 3.9116983366012574 and perplexity is 49.983769193616574
At time: 356.73576402664185 and batch: 1150, loss is 3.817210168838501 and perplexity is 45.477157586832824
At time: 357.07918190956116 and batch: 1200, loss is 3.7602536725997924 and perplexity is 42.959322199615954
At time: 357.4222583770752 and batch: 1250, loss is 3.67761209487915 and perplexity is 39.55183518889669
At time: 357.76640272140503 and batch: 1300, loss is 3.7783496713638307 and perplexity is 43.74379050271199
At time: 358.11004424095154 and batch: 1350, loss is 3.7568754863739016 and perplexity is 42.81444246223654
At time: 358.45446705818176 and batch: 1400, loss is 3.6133412456512453 and perplexity is 37.089772051114544
At time: 358.7989411354065 and batch: 1450, loss is 3.7225875997543336 and perplexity is 41.37130811033617
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.5051045214009084 and perplexity of 90.477800421115
Finished 33 epochs...
Completing Train Step...
At time: 360.0477488040924 and batch: 50, loss is 3.8993227338790892 and perplexity is 49.369001828093396
At time: 360.40622997283936 and batch: 100, loss is 3.94323935508728 and perplexity is 51.58543447829463
At time: 360.7509024143219 and batch: 150, loss is 3.7678269433975218 and perplexity is 43.28589984952206
At time: 361.11000299453735 and batch: 200, loss is 3.8876269102096557 and perplexity is 48.794954211585484
At time: 361.45173501968384 and batch: 250, loss is 3.9568607902526853 and perplexity is 52.29290960388028
At time: 361.7961256504059 and batch: 300, loss is 3.9494278144836428 and perplexity is 51.90565867024312
At time: 362.14186429977417 and batch: 350, loss is 3.920240125656128 and perplexity is 50.41254867110643
At time: 362.48503279685974 and batch: 400, loss is 3.73803626537323 and perplexity is 42.01540200115111
At time: 362.830463886261 and batch: 450, loss is 3.847290439605713 and perplexity is 46.865905037840164
At time: 363.1745958328247 and batch: 500, loss is 3.8033918142318726 and perplexity is 44.853060028244116
At time: 363.5180459022522 and batch: 550, loss is 3.857067232131958 and perplexity is 47.326350439873075
At time: 363.8628170490265 and batch: 600, loss is 3.782770028114319 and perplexity is 43.937581659828076
At time: 364.2051374912262 and batch: 650, loss is 3.858162136077881 and perplexity is 47.37819662583313
At time: 364.5492844581604 and batch: 700, loss is 3.9179071378707886 and perplexity is 50.295073897717565
At time: 364.8927285671234 and batch: 750, loss is 3.861979241371155 and perplexity is 47.559389787644825
At time: 365.23713541030884 and batch: 800, loss is 3.784702777862549 and perplexity is 44.02258412750722
At time: 365.58009362220764 and batch: 850, loss is 3.737293310165405 and perplexity is 41.98419803243635
At time: 365.9232623577118 and batch: 900, loss is 3.6445738792419435 and perplexity is 38.266463242548234
At time: 366.2654194831848 and batch: 950, loss is 3.8125181818008422 and perplexity is 45.26427915488598
At time: 366.6088192462921 and batch: 1000, loss is 3.847539954185486 and perplexity is 46.87760022344035
At time: 366.9526481628418 and batch: 1050, loss is 3.7499739360809325 and perplexity is 42.519973748465624
At time: 367.296683549881 and batch: 1100, loss is 3.911325364112854 and perplexity is 49.965130098991466
At time: 367.63997054100037 and batch: 1150, loss is 3.8167683982849123 and perplexity is 45.45707155478546
At time: 367.98527574539185 and batch: 1200, loss is 3.7599543285369874 and perplexity is 42.946464506106494
At time: 368.329651594162 and batch: 1250, loss is 3.67725905418396 and perplexity is 39.537874246041035
At time: 368.6722719669342 and batch: 1300, loss is 3.778041615486145 and perplexity is 43.73031704633065
At time: 369.0151345729828 and batch: 1350, loss is 3.75660352230072 and perplexity is 42.802800055303486
At time: 369.36076498031616 and batch: 1400, loss is 3.6130055713653566 and perplexity is 37.07732405772004
At time: 369.7053391933441 and batch: 1450, loss is 3.7223559713363645 and perplexity is 41.36172644942458
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.505097218048879 and perplexity of 90.47713963230063
Finished 34 epochs...
Completing Train Step...
At time: 370.9441831111908 and batch: 50, loss is 3.8982788944244384 and perplexity is 49.31749540304461
At time: 371.3033583164215 and batch: 100, loss is 3.9422665357589723 and perplexity is 51.53527557230738
At time: 371.64724373817444 and batch: 150, loss is 3.766855306625366 and perplexity is 43.24386210352957
At time: 371.990496635437 and batch: 200, loss is 3.88678569316864 and perplexity is 48.753924324526764
At time: 372.3362464904785 and batch: 250, loss is 3.955980043411255 and perplexity is 52.246873065161424
At time: 372.6813986301422 and batch: 300, loss is 3.94856463432312 and perplexity is 51.86087406683136
At time: 373.0248956680298 and batch: 350, loss is 3.9194945907592773 and perplexity is 50.37497836356082
At time: 373.3669638633728 and batch: 400, loss is 3.7372401571273803 and perplexity is 41.98196650406868
At time: 373.71135449409485 and batch: 450, loss is 3.8463859128952027 and perplexity is 46.823532741247206
At time: 374.0535297393799 and batch: 500, loss is 3.802529525756836 and perplexity is 44.81440042177361
At time: 374.3954083919525 and batch: 550, loss is 3.8562824869155885 and perplexity is 47.28922588132222
At time: 374.7380859851837 and batch: 600, loss is 3.7821221685409547 and perplexity is 43.90912549571376
At time: 375.0825660228729 and batch: 650, loss is 3.857519645690918 and perplexity is 47.347766366570696
At time: 375.4264667034149 and batch: 700, loss is 3.917331795692444 and perplexity is 50.26614534304806
At time: 375.7694044113159 and batch: 750, loss is 3.8613927793502807 and perplexity is 47.531506188933434
At time: 376.11186718940735 and batch: 800, loss is 3.7840484809875488 and perplexity is 43.993789709359326
At time: 376.46072793006897 and batch: 850, loss is 3.736659460067749 and perplexity is 41.95759477654235
At time: 376.80294847488403 and batch: 900, loss is 3.643989281654358 and perplexity is 38.24409929804213
At time: 377.1472475528717 and batch: 950, loss is 3.811996922492981 and perplexity is 45.24069087640182
At time: 377.4909110069275 and batch: 1000, loss is 3.8470415115356444 and perplexity is 46.85424025045383
At time: 377.8343870639801 and batch: 1050, loss is 3.7495949697494506 and perplexity is 42.50386316287703
At time: 378.1800560951233 and batch: 1100, loss is 3.910947251319885 and perplexity is 49.946241215388
At time: 378.54830288887024 and batch: 1150, loss is 3.8163219833374025 and perplexity is 45.43678336738536
At time: 378.890949010849 and batch: 1200, loss is 3.759642524719238 and perplexity is 42.93307572196014
At time: 379.23702001571655 and batch: 1250, loss is 3.6768942356109617 and perplexity is 39.52345272595836
At time: 379.5802335739136 and batch: 1300, loss is 3.777716736793518 and perplexity is 43.7161123056342
At time: 379.92237854003906 and batch: 1350, loss is 3.756315383911133 and perplexity is 42.790468702079174
At time: 380.2652952671051 and batch: 1400, loss is 3.612655029296875 and perplexity is 37.06432917361093
At time: 380.60943245887756 and batch: 1450, loss is 3.72210307598114 and perplexity is 41.35126758347651
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.5050920013688565 and perplexity of 90.47666764324497
Finished 35 epochs...
Completing Train Step...
At time: 381.8612825870514 and batch: 50, loss is 3.897259774208069 and perplexity is 49.26726054848442
At time: 382.2053470611572 and batch: 100, loss is 3.94131591796875 and perplexity is 51.486308500696545
At time: 382.5480089187622 and batch: 150, loss is 3.765909557342529 and perplexity is 43.20298358541961
At time: 382.891642332077 and batch: 200, loss is 3.8859636402130127 and perplexity is 48.71386248566993
At time: 383.23457288742065 and batch: 250, loss is 3.9551209592819214 and perplexity is 52.20200787994744
At time: 383.5778272151947 and batch: 300, loss is 3.947720046043396 and perplexity is 51.817091472154054
At time: 383.92129397392273 and batch: 350, loss is 3.9187641668319704 and perplexity is 50.33819670876219
At time: 384.2635717391968 and batch: 400, loss is 3.736460542678833 and perplexity is 41.9492495113809
At time: 384.60920310020447 and batch: 450, loss is 3.8454982614517212 and perplexity is 46.78198820608167
At time: 384.95229411125183 and batch: 500, loss is 3.8016827726364135 and perplexity is 44.77646974960045
At time: 385.29766392707825 and batch: 550, loss is 3.8555110025405885 and perplexity is 47.252757051823814
At time: 385.64014196395874 and batch: 600, loss is 3.78148542881012 and perplexity is 43.88117571027817
At time: 385.9834885597229 and batch: 650, loss is 3.8568857669830323 and perplexity is 47.31776313581417
At time: 386.3286921977997 and batch: 700, loss is 3.9167652320861817 and perplexity is 50.2376744405198
At time: 386.6721541881561 and batch: 750, loss is 3.8608137559890747 and perplexity is 47.503992302816854
At time: 387.0151219367981 and batch: 800, loss is 3.7834033298492433 and perplexity is 43.96541621942876
At time: 387.37218475341797 and batch: 850, loss is 3.7360308885574343 and perplexity is 41.931229714855874
At time: 387.7171473503113 and batch: 900, loss is 3.6434071588516237 and perplexity is 38.22184301434432
At time: 388.0604751110077 and batch: 950, loss is 3.811477017402649 and perplexity is 45.21717612417442
At time: 388.40277099609375 and batch: 1000, loss is 3.8465435457229615 and perplexity is 46.830914248887545
At time: 388.7457363605499 and batch: 1050, loss is 3.7492110204696654 and perplexity is 42.48754696772368
At time: 389.0890543460846 and batch: 1100, loss is 3.9105649518966676 and perplexity is 49.92715044560713
At time: 389.4328017234802 and batch: 1150, loss is 3.815871305465698 and perplexity is 45.41631062821203
At time: 389.77673506736755 and batch: 1200, loss is 3.7593188095092773 and perplexity is 42.91917988160732
At time: 390.1190576553345 and batch: 1250, loss is 3.676519570350647 and perplexity is 39.508647434941544
At time: 390.4616801738739 and batch: 1300, loss is 3.7773779582977296 and perplexity is 43.70130473525041
At time: 390.8056547641754 and batch: 1350, loss is 3.7560133600234984 and perplexity is 42.77754690981126
At time: 391.14818048477173 and batch: 1400, loss is 3.612292594909668 and perplexity is 37.050898220246346
At time: 391.49065685272217 and batch: 1450, loss is 3.721832208633423 and perplexity is 41.34006839211754
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.505089393028846 and perplexity of 90.47643164964049
Finished 36 epochs...
Completing Train Step...
At time: 392.7406759262085 and batch: 50, loss is 3.896262092590332 and perplexity is 49.218132019669085
At time: 393.08357787132263 and batch: 100, loss is 3.9403849029541016 and perplexity is 51.43839628139218
At time: 393.4292709827423 and batch: 150, loss is 3.7649863815307616 and perplexity is 43.16311804026216
At time: 393.7730178833008 and batch: 200, loss is 3.885159106254578 and perplexity is 48.674686290456535
At time: 394.1161632537842 and batch: 250, loss is 3.9542805624008177 and perplexity is 52.15815590445043
At time: 394.4587450027466 and batch: 300, loss is 3.9468907594680784 and perplexity is 51.77413806662712
At time: 394.80181336402893 and batch: 350, loss is 3.9180465602874754 and perplexity is 50.30208664732372
At time: 395.1469268798828 and batch: 400, loss is 3.735696816444397 and perplexity is 41.917223999932425
At time: 395.48937702178955 and batch: 450, loss is 3.8446256923675537 and perplexity is 46.74118549365871
At time: 395.83280086517334 and batch: 500, loss is 3.800849452018738 and perplexity is 44.73917213676462
At time: 396.1782007217407 and batch: 550, loss is 3.854751219749451 and perplexity is 47.21686885552544
At time: 396.53833866119385 and batch: 600, loss is 3.7808582162857056 and perplexity is 43.85366151681203
At time: 396.8799068927765 and batch: 650, loss is 3.856259183883667 and perplexity is 47.28812391182163
At time: 397.22281765937805 and batch: 700, loss is 3.916206035614014 and perplexity is 50.209589563416685
At time: 397.5656020641327 and batch: 750, loss is 3.8602409172058105 and perplexity is 47.47678796625936
At time: 397.90857911109924 and batch: 800, loss is 3.78276638507843 and perplexity is 43.93742159393278
At time: 398.25181436538696 and batch: 850, loss is 3.735407075881958 and perplexity is 41.90508063917185
At time: 398.59503984451294 and batch: 900, loss is 3.642827157974243 and perplexity is 38.19968073955159
At time: 398.93924713134766 and batch: 950, loss is 3.8109584999084474 and perplexity is 45.193736304819005
At time: 399.28615713119507 and batch: 1000, loss is 3.846046042442322 and perplexity is 46.80762151000081
At time: 399.62934041023254 and batch: 1050, loss is 3.748823256492615 and perplexity is 42.47107502135648
At time: 399.97372937202454 and batch: 1100, loss is 3.910179057121277 and perplexity is 49.90788753606714
At time: 400.3176145553589 and batch: 1150, loss is 3.8154180669784545 and perplexity is 45.39573087240772
At time: 400.6622951030731 and batch: 1200, loss is 3.7589860343933106 and perplexity is 42.90489982270093
At time: 401.00672364234924 and batch: 1250, loss is 3.6761365699768067 and perplexity is 39.493518505581775
At time: 401.35022592544556 and batch: 1300, loss is 3.7770274591445925 and perplexity is 43.68599014898126
At time: 401.6927032470703 and batch: 1350, loss is 3.7556988334655763 and perplexity is 42.76409435092979
At time: 402.03756308555603 and batch: 1400, loss is 3.6119206285476686 and perplexity is 37.037119095270924
At time: 402.3797206878662 and batch: 1450, loss is 3.7215460729599 and perplexity is 41.32824121597387
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.505087306356837 and perplexity of 90.47624285520011
Finished 37 epochs...
Completing Train Step...
At time: 403.6294791698456 and batch: 50, loss is 3.895283589363098 and perplexity is 49.16999547337313
At time: 403.98691296577454 and batch: 100, loss is 3.939471278190613 and perplexity is 51.391422350296175
At time: 404.33083152770996 and batch: 150, loss is 3.7640828275680542 and perplexity is 43.124135448004075
At time: 404.6755373477936 and batch: 200, loss is 3.8843694877624513 and perplexity is 48.63626702833923
At time: 405.0200426578522 and batch: 250, loss is 3.9534566450119017 and perplexity is 52.11519959148361
At time: 405.37818479537964 and batch: 300, loss is 3.9460748481750487 and perplexity is 51.73191219131846
At time: 405.72155499458313 and batch: 350, loss is 3.917339606285095 and perplexity is 50.26653795296674
At time: 406.06500792503357 and batch: 400, loss is 3.7349480676651 and perplexity is 41.885850276615216
At time: 406.40990948677063 and batch: 450, loss is 3.843768057823181 and perplexity is 46.701115823357206
At time: 406.7561752796173 and batch: 500, loss is 3.800027914047241 and perplexity is 44.70243230169211
At time: 407.09929943084717 and batch: 550, loss is 3.8540017366409303 and perplexity is 47.181493868014705
At time: 407.4436116218567 and batch: 600, loss is 3.7802390384674074 and perplexity is 43.82651670694897
At time: 407.7882959842682 and batch: 650, loss is 3.8556383800506593 and perplexity is 47.25877637371603
At time: 408.13138699531555 and batch: 700, loss is 3.9156527662277223 and perplexity is 50.18181781794969
At time: 408.4755816459656 and batch: 750, loss is 3.859673409461975 and perplexity is 47.449852165296804
At time: 408.819659948349 and batch: 800, loss is 3.7821359157562258 and perplexity is 43.90972912806343
At time: 409.1647274494171 and batch: 850, loss is 3.7347875833511353 and perplexity is 41.879128794029434
At time: 409.50791811943054 and batch: 900, loss is 3.6422490644454957 and perplexity is 38.17760413310232
At time: 409.8507957458496 and batch: 950, loss is 3.8104415798187254 and perplexity is 45.170380791580506
At time: 410.19365668296814 and batch: 1000, loss is 3.8455487489700317 and perplexity is 46.78435017219223
At time: 410.53790855407715 and batch: 1050, loss is 3.748432283401489 and perplexity is 42.45447321951231
At time: 410.88171887397766 and batch: 1100, loss is 3.90978982925415 and perplexity is 49.88846577543911
At time: 411.2252953052521 and batch: 1150, loss is 3.814962306022644 and perplexity is 45.37504598475573
At time: 411.5692512989044 and batch: 1200, loss is 3.7586446523666384 and perplexity is 42.890255360865545
At time: 411.91322445869446 and batch: 1250, loss is 3.675746455192566 and perplexity is 39.47811450499061
At time: 412.2561197280884 and batch: 1300, loss is 3.77666699886322 and perplexity is 43.670245922434766
At time: 412.59945464134216 and batch: 1350, loss is 3.755371594429016 and perplexity is 42.750102559350076
At time: 412.94339513778687 and batch: 1400, loss is 3.6115409088134767 and perplexity is 37.023058040051865
At time: 413.2876789569855 and batch: 1450, loss is 3.721246542930603 and perplexity is 41.315864020435065
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.5050883496928416 and perplexity of 90.47633725237107
Annealing...
Finished 38 epochs...
Completing Train Step...
At time: 414.52464866638184 and batch: 50, loss is 3.894869537353516 and perplexity is 49.14964075218364
At time: 414.88502740859985 and batch: 100, loss is 3.939723744392395 and perplexity is 51.404398585462616
At time: 415.2281708717346 and batch: 150, loss is 3.7643385887145997 and perplexity is 43.13516633690631
At time: 415.569947719574 and batch: 200, loss is 3.884987506866455 and perplexity is 48.66633446067697
At time: 415.91239500045776 and batch: 250, loss is 3.9537171220779417 and perplexity is 52.1287761738867
At time: 416.25757360458374 and batch: 300, loss is 3.946176085472107 and perplexity is 51.737149655389246
At time: 416.6007068157196 and batch: 350, loss is 3.9174524259567263 and perplexity is 50.2722093271879
At time: 416.9441249370575 and batch: 400, loss is 3.7338290119171145 and perplexity is 41.839003891850744
At time: 417.286728143692 and batch: 450, loss is 3.8435565853118896 and perplexity is 46.69124086529181
At time: 417.6276857852936 and batch: 500, loss is 3.798328466415405 and perplexity is 44.62652737547181
At time: 417.9667377471924 and batch: 550, loss is 3.8523775243759157 and perplexity is 47.10492330724772
At time: 418.31001710891724 and batch: 600, loss is 3.7790601444244385 and perplexity is 43.774880330367765
At time: 418.65520882606506 and batch: 650, loss is 3.8542931127548217 and perplexity is 47.195243431395454
At time: 418.99872946739197 and batch: 700, loss is 3.914499669075012 and perplexity is 50.12398665558817
At time: 419.34195709228516 and batch: 750, loss is 3.858989028930664 and perplexity is 47.41738951992959
At time: 419.68510818481445 and batch: 800, loss is 3.780818042755127 and perplexity is 43.85189979578762
At time: 420.0293517112732 and batch: 850, loss is 3.7322824096679685 and perplexity is 41.77434560754198
At time: 420.3712775707245 and batch: 900, loss is 3.6388128900527956 and perplexity is 38.046644356577495
At time: 420.7130880355835 and batch: 950, loss is 3.8063242053985595 and perplexity is 44.98477977779759
At time: 421.0577425956726 and batch: 1000, loss is 3.8422137308120727 and perplexity is 46.62858340173789
At time: 421.40364146232605 and batch: 1050, loss is 3.743776912689209 and perplexity is 42.25729124200082
At time: 421.74691438674927 and batch: 1100, loss is 3.9062112522125245 and perplexity is 49.71025511764108
At time: 422.09200954437256 and batch: 1150, loss is 3.8090892171859743 and perplexity is 45.109335343585975
At time: 422.4353578090668 and batch: 1200, loss is 3.753768973350525 and perplexity is 42.68164521412515
At time: 422.79543566703796 and batch: 1250, loss is 3.669837303161621 and perplexity is 39.24552021879661
At time: 423.1386983394623 and batch: 1300, loss is 3.770710492134094 and perplexity is 43.410896982395776
At time: 423.48225951194763 and batch: 1350, loss is 3.7493194007873534 and perplexity is 42.492152031106436
At time: 423.8250343799591 and batch: 1400, loss is 3.6044715070724487 and perplexity is 36.762250133207374
At time: 424.1687009334564 and batch: 1450, loss is 3.714708352088928 and perplexity is 41.046614179259265
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.504231770833333 and perplexity of 90.39887031760087
Finished 39 epochs...
Completing Train Step...
At time: 425.4137589931488 and batch: 50, loss is 3.894038496017456 and perplexity is 49.10881233646644
At time: 425.75782227516174 and batch: 100, loss is 3.9388388442993163 and perplexity is 51.35893094849472
At time: 426.100702047348 and batch: 150, loss is 3.763798780441284 and perplexity is 43.111887900758276
At time: 426.44349694252014 and batch: 200, loss is 3.884252109527588 and perplexity is 48.63055852419873
At time: 426.78775930404663 and batch: 250, loss is 3.9530038261413574 and perplexity is 52.091606187838735
At time: 427.1310963630676 and batch: 300, loss is 3.9455248308181763 and perplexity is 51.70346656522018
At time: 427.47572898864746 and batch: 350, loss is 3.9165623426437377 and perplexity is 50.22748278068793
At time: 427.8188326358795 and batch: 400, loss is 3.7331122064590456 and perplexity is 41.809024211583775
At time: 428.1626772880554 and batch: 450, loss is 3.842539281845093 and perplexity is 46.64376585643041
At time: 428.50689721107483 and batch: 500, loss is 3.797464108467102 and perplexity is 44.587970747594056
At time: 428.8516080379486 and batch: 550, loss is 3.85160165309906 and perplexity is 47.06839012461135
At time: 429.1949100494385 and batch: 600, loss is 3.778200445175171 and perplexity is 43.73726327060683
At time: 429.53843426704407 and batch: 650, loss is 3.8537064027786254 and perplexity is 47.16756163263306
At time: 429.88190817832947 and batch: 700, loss is 3.9138488721847535 and perplexity is 50.09137673331432
At time: 430.2278609275818 and batch: 750, loss is 3.8582204675674436 and perplexity is 47.38096034722031
At time: 430.5718059539795 and batch: 800, loss is 3.780257749557495 and perplexity is 43.82733675652329
At time: 430.9151260852814 and batch: 850, loss is 3.7319455432891844 and perplexity is 41.76027560499955
At time: 431.2582242488861 and batch: 900, loss is 3.6385269355773926 and perplexity is 38.03576630373774
At time: 431.6170856952667 and batch: 950, loss is 3.8061185121536254 and perplexity is 44.975527664053715
At time: 431.959477186203 and batch: 1000, loss is 3.8419556760787965 and perplexity is 46.6165522275026
At time: 432.3025231361389 and batch: 1050, loss is 3.743824019432068 and perplexity is 42.25928189223942
At time: 432.6472041606903 and batch: 1100, loss is 3.9062313079833983 and perplexity is 49.711252105125446
At time: 432.9915187358856 and batch: 1150, loss is 3.80915940284729 and perplexity is 45.112501483226076
At time: 433.3356125354767 and batch: 1200, loss is 3.7540899229049685 and perplexity is 42.695346067663344
At time: 433.6782236099243 and batch: 1250, loss is 3.670299038887024 and perplexity is 39.26364546175772
At time: 434.02187180519104 and batch: 1300, loss is 3.77108838558197 and perplexity is 43.427304775935426
At time: 434.3653631210327 and batch: 1350, loss is 3.7496598863601687 and perplexity is 42.5066224591771
At time: 434.70947909355164 and batch: 1400, loss is 3.6049400186538696 and perplexity is 36.77947770849802
At time: 435.0525758266449 and batch: 1450, loss is 3.7151564884185793 and perplexity is 41.065012780515076
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.504027276976496 and perplexity of 90.38038619396517
Finished 40 epochs...
Completing Train Step...
At time: 436.3012218475342 and batch: 50, loss is 3.893643341064453 and perplexity is 49.089410579638205
At time: 436.64472126960754 and batch: 100, loss is 3.9383824682235717 and perplexity is 51.33549730881699
At time: 436.9891662597656 and batch: 150, loss is 3.763488001823425 and perplexity is 43.0984917295528
At time: 437.33154129981995 and batch: 200, loss is 3.8838495874404906 and perplexity is 48.61098758941586
At time: 437.6752290725708 and batch: 250, loss is 3.9525298357009886 and perplexity is 52.066921115188634
At time: 438.0184950828552 and batch: 300, loss is 3.945113596916199 and perplexity is 51.68220871819208
At time: 438.3627960681915 and batch: 350, loss is 3.9160485315322875 and perplexity is 50.20168197087404
At time: 438.7063252925873 and batch: 400, loss is 3.7326787376403807 and perplexity is 41.79090523053961
At time: 439.0487997531891 and batch: 450, loss is 3.8419381046295165 and perplexity is 46.61573311431605
At time: 439.3916356563568 and batch: 500, loss is 3.7969523763656614 and perplexity is 44.565159488748925
At time: 439.73564648628235 and batch: 550, loss is 3.851141390800476 and perplexity is 47.04673130393359
At time: 440.07976746559143 and batch: 600, loss is 3.7777375888824465 and perplexity is 43.71702388739976
At time: 440.42267894744873 and batch: 650, loss is 3.8533503246307372 and perplexity is 47.15076928451805
At time: 440.77951216697693 and batch: 700, loss is 3.913436532020569 and perplexity is 50.07072630460104
At time: 441.1241273880005 and batch: 750, loss is 3.8578041315078737 and perplexity is 47.361238050727195
At time: 441.46803045272827 and batch: 800, loss is 3.779933934211731 and perplexity is 43.81314708985745
At time: 441.81216955184937 and batch: 850, loss is 3.731754922866821 and perplexity is 41.75231600228124
At time: 442.15514039993286 and batch: 900, loss is 3.638382339477539 and perplexity is 38.03026687788262
At time: 442.49829721450806 and batch: 950, loss is 3.806032476425171 and perplexity is 44.971658328221466
At time: 442.8429560661316 and batch: 1000, loss is 3.841815347671509 and perplexity is 46.610011059941826
At time: 443.1875054836273 and batch: 1050, loss is 3.7438660717010497 and perplexity is 42.26105902829457
At time: 443.53027510643005 and batch: 1100, loss is 3.9062729549407957 and perplexity is 49.71332247063595
At time: 443.87491965293884 and batch: 1150, loss is 3.809208092689514 and perplexity is 45.11469805728063
At time: 444.2198112010956 and batch: 1200, loss is 3.754298520088196 and perplexity is 42.704253125551276
At time: 444.5666332244873 and batch: 1250, loss is 3.670566258430481 and perplexity is 39.27413887713287
At time: 444.9096841812134 and batch: 1300, loss is 3.7713355445861816 and perplexity is 43.43803955188305
At time: 445.25333428382874 and batch: 1350, loss is 3.74990047454834 and perplexity is 42.51685028075703
At time: 445.59806656837463 and batch: 1400, loss is 3.6052178525924683 and perplexity is 36.78969771531601
At time: 445.9416341781616 and batch: 1450, loss is 3.7154170799255373 and perplexity is 41.07571536852
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.503926595052083 and perplexity of 90.37128698082483
Finished 41 epochs...
Completing Train Step...
At time: 447.1894721984863 and batch: 50, loss is 3.8933098554611205 and perplexity is 49.07304269731206
At time: 447.54675340652466 and batch: 100, loss is 3.9380269336700437 and perplexity is 51.3172490098438
At time: 447.88928413391113 and batch: 150, loss is 3.763220090866089 and perplexity is 43.08694671796039
At time: 448.2322573661804 and batch: 200, loss is 3.883522210121155 and perplexity is 48.59507605928773
At time: 448.5780656337738 and batch: 250, loss is 3.952156286239624 and perplexity is 52.047475177087115
At time: 448.9213185310364 and batch: 300, loss is 3.9447981309890747 and perplexity is 51.665907313707
At time: 449.26371908187866 and batch: 350, loss is 3.915666756629944 and perplexity is 50.18251988667628
At time: 449.6219832897186 and batch: 400, loss is 3.7323415088653564 and perplexity is 41.77681451079317
At time: 449.96613454818726 and batch: 450, loss is 3.841511206626892 and perplexity is 46.5958371980243
At time: 450.3112852573395 and batch: 500, loss is 3.796588826179504 and perplexity is 44.54896076142425
At time: 450.65600752830505 and batch: 550, loss is 3.850811033248901 and perplexity is 47.0311916279364
At time: 451.0012683868408 and batch: 600, loss is 3.7774203205108643 and perplexity is 43.70315605844866
At time: 451.3473131656647 and batch: 650, loss is 3.8530902814865113 and perplexity is 47.13850964430741
At time: 451.6901614665985 and batch: 700, loss is 3.9131368160247804 and perplexity is 50.05572155570076
At time: 452.0315282344818 and batch: 750, loss is 3.8575319194793702 and perplexity is 47.34834750660515
At time: 452.37550473213196 and batch: 800, loss is 3.77970956325531 and perplexity is 43.80331779488648
At time: 452.72042751312256 and batch: 850, loss is 3.731612424850464 and perplexity is 41.74636680395714
At time: 453.06508111953735 and batch: 900, loss is 3.638276448249817 and perplexity is 38.026240019440586
At time: 453.40849208831787 and batch: 950, loss is 3.805967082977295 and perplexity is 44.968717572580815
At time: 453.75096130371094 and batch: 1000, loss is 3.84171516418457 and perplexity is 46.60534174040585
At time: 454.0953805446625 and batch: 1050, loss is 3.7438936614990235 and perplexity is 42.26222501845996
At time: 454.4398441314697 and batch: 1100, loss is 3.9062983655929564 and perplexity is 49.71458573463112
At time: 454.7840299606323 and batch: 1150, loss is 3.809220690727234 and perplexity is 45.11526641752857
At time: 455.1266372203827 and batch: 1200, loss is 3.754429302215576 and perplexity is 42.70983844384516
At time: 455.47084617614746 and batch: 1250, loss is 3.6707257556915285 and perplexity is 39.28040349429513
At time: 455.81474709510803 and batch: 1300, loss is 3.771493663787842 and perplexity is 43.444908483059336
At time: 456.15837359428406 and batch: 1350, loss is 3.750058479309082 and perplexity is 42.523568676268404
At time: 456.501277923584 and batch: 1400, loss is 3.605390954017639 and perplexity is 36.796066615639084
At time: 456.84526348114014 and batch: 1450, loss is 3.715577664375305 and perplexity is 41.08231201931687
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.503863994891827 and perplexity of 90.36562990084616
Finished 42 epochs...
Completing Train Step...
At time: 458.0810134410858 and batch: 50, loss is 3.8930066442489624 and perplexity is 49.05816545613867
At time: 458.439843416214 and batch: 100, loss is 3.937718367576599 and perplexity is 51.301416689574744
At time: 458.78357672691345 and batch: 150, loss is 3.7629747724533082 and perplexity is 43.0763779929844
At time: 459.1268541812897 and batch: 200, loss is 3.8832348108291628 and perplexity is 48.581111875578365
At time: 459.4704897403717 and batch: 250, loss is 3.9518379402160644 and perplexity is 52.03090870740296
At time: 459.81434082984924 and batch: 300, loss is 3.9445299339294433 and perplexity is 51.65205252727182
At time: 460.1588704586029 and batch: 350, loss is 3.915353627204895 and perplexity is 50.16680872301887
At time: 460.5006294250488 and batch: 400, loss is 3.7320552492141723 and perplexity is 41.76485720597234
At time: 460.84313893318176 and batch: 450, loss is 3.8411747312545774 and perplexity is 46.58016148374857
At time: 461.1881351470947 and batch: 500, loss is 3.7962991428375243 and perplexity is 44.536057538603735
At time: 461.5336592197418 and batch: 550, loss is 3.850545287132263 and perplexity is 47.01869493194818
At time: 461.8766620159149 and batch: 600, loss is 3.777172884941101 and perplexity is 43.69234368086746
At time: 462.21887135505676 and batch: 650, loss is 3.852881374359131 and perplexity is 47.128663102210844
At time: 462.5627028942108 and batch: 700, loss is 3.9128984117507937 and perplexity is 50.04378948012981
At time: 462.90683364868164 and batch: 750, loss is 3.8573286390304564 and perplexity is 47.33872349148888
At time: 463.2508361339569 and batch: 800, loss is 3.779532723426819 and perplexity is 43.79557230855573
At time: 463.59450006484985 and batch: 850, loss is 3.731490979194641 and perplexity is 41.741297196909514
At time: 463.93792748451233 and batch: 900, loss is 3.6381836318969727 and perplexity is 38.022710726320184
At time: 464.28133368492126 and batch: 950, loss is 3.805903072357178 and perplexity is 44.96583918920765
At time: 464.6249976158142 and batch: 1000, loss is 3.8416308212280272 and perplexity is 46.60141107385712
At time: 464.97099137306213 and batch: 1050, loss is 3.74390540599823 and perplexity is 42.26272137004285
At time: 465.31597661972046 and batch: 1100, loss is 3.9063059091567993 and perplexity is 49.71496076119705
At time: 465.66014981269836 and batch: 1150, loss is 3.809207067489624 and perplexity is 45.11465180572083
At time: 466.0044457912445 and batch: 1200, loss is 3.7545107793807984 and perplexity is 42.71331846217775
At time: 466.34713673591614 and batch: 1250, loss is 3.6708215999603273 and perplexity is 39.28416847626925
At time: 466.689715385437 and batch: 1300, loss is 3.7715944147109983 and perplexity is 43.44928581820202
At time: 467.03372383117676 and batch: 1350, loss is 3.7501596355438234 and perplexity is 42.52787041793379
At time: 467.3769431114197 and batch: 1400, loss is 3.6055011224746703 and perplexity is 36.800120604829715
At time: 467.72081232070923 and batch: 1450, loss is 3.7156785917282105 and perplexity is 41.08645855756625
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.503821218115652 and perplexity of 90.36176443319873
Finished 43 epochs...
Completing Train Step...
At time: 468.9645915031433 and batch: 50, loss is 3.89272403717041 and perplexity is 49.044303230193826
At time: 469.30692529678345 and batch: 100, loss is 3.9374389457702637 and perplexity is 51.28708395758795
At time: 469.65054178237915 and batch: 150, loss is 3.7627460098266603 and perplexity is 43.06652485466611
At time: 469.995019197464 and batch: 200, loss is 3.8829747819900513 and perplexity is 48.568481027718136
At time: 470.33917021751404 and batch: 250, loss is 3.951555862426758 and perplexity is 52.01623401349908
At time: 470.6820549964905 and batch: 300, loss is 3.9442910528182984 and perplexity is 51.63971530119499
At time: 471.0277786254883 and batch: 350, loss is 3.915082015991211 and perplexity is 50.153184705516665
At time: 471.37300300598145 and batch: 400, loss is 3.7318001413345336 and perplexity is 41.754204020720636
At time: 471.7164978981018 and batch: 450, loss is 3.8408900833129884 and perplexity is 46.5669044235503
At time: 472.0612118244171 and batch: 500, loss is 3.7960501670837403 and perplexity is 44.52497052036413
At time: 472.40519547462463 and batch: 550, loss is 3.8503150653839113 and perplexity is 47.007871451743796
At time: 472.7520377635956 and batch: 600, loss is 3.7769633674621583 and perplexity is 43.68319033009732
At time: 473.09659004211426 and batch: 650, loss is 3.8527020454406737 and perplexity is 47.12021232778516
At time: 473.44074511528015 and batch: 700, loss is 3.9126964902877805 and perplexity is 50.03368558507423
At time: 473.78469133377075 and batch: 750, loss is 3.8571608543395994 and perplexity is 47.33078144469786
At time: 474.12811040878296 and batch: 800, loss is 3.7793808794021606 and perplexity is 43.78892271745729
At time: 474.47211742401123 and batch: 850, loss is 3.731379590034485 and perplexity is 41.73664792781482
At time: 474.815886259079 and batch: 900, loss is 3.638095932006836 and perplexity is 38.01937628498399
At time: 475.15969014167786 and batch: 950, loss is 3.805836224555969 and perplexity is 44.962833422193924
At time: 475.50362491607666 and batch: 1000, loss is 3.8415521335601808 and perplexity is 46.5977442617697
At time: 475.8475103378296 and batch: 1050, loss is 3.743902883529663 and perplexity is 42.26261476379109
At time: 476.20655369758606 and batch: 1100, loss is 3.906298952102661 and perplexity is 49.71461489272667
At time: 476.55053448677063 and batch: 1150, loss is 3.8091753625869753 and perplexity is 45.11322147275171
At time: 476.8946874141693 and batch: 1200, loss is 3.754560360908508 and perplexity is 42.7154363062632
At time: 477.2378189563751 and batch: 1250, loss is 3.6708776903152467 and perplexity is 39.286372001019465
At time: 477.5801627635956 and batch: 1300, loss is 3.7716574764251707 and perplexity is 43.45202589104122
At time: 477.92329359054565 and batch: 1350, loss is 3.75022180557251 and perplexity is 42.530514459046856
At time: 478.2674825191498 and batch: 1400, loss is 3.6055700969696045 and perplexity is 36.8026589621019
At time: 478.60993576049805 and batch: 1450, loss is 3.715740985870361 and perplexity is 41.08902219187902
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.503788874699519 and perplexity of 90.35884187231221
Finished 44 epochs...
Completing Train Step...
At time: 479.86251759529114 and batch: 50, loss is 3.8924574422836304 and perplexity is 49.03123001243092
At time: 480.20583868026733 and batch: 100, loss is 3.9371806287765505 and perplexity is 51.27383734323017
At time: 480.5492789745331 and batch: 150, loss is 3.76253059387207 and perplexity is 43.05724863726215
At time: 480.8925006389618 and batch: 200, loss is 3.8827351331710815 and perplexity is 48.556843043171014
At time: 481.23607301712036 and batch: 250, loss is 3.9512997674942016 and perplexity is 52.002914625144285
At time: 481.57955026626587 and batch: 300, loss is 3.9440730237960815 and perplexity is 51.62845757186077
At time: 481.9217221736908 and batch: 350, loss is 3.9148380279541017 and perplexity is 50.140949421117796
At time: 482.2649667263031 and batch: 400, loss is 3.731565933227539 and perplexity is 41.74442599272929
At time: 482.60845279693604 and batch: 450, loss is 3.840637445449829 and perplexity is 46.55514134628471
At time: 482.9522616863251 and batch: 500, loss is 3.7958254432678222 and perplexity is 44.5149658232741
At time: 483.29582142829895 and batch: 550, loss is 3.850106520652771 and perplexity is 46.99806922996679
At time: 483.6407103538513 and batch: 600, loss is 3.776775822639465 and perplexity is 43.674998542099914
At time: 483.98431420326233 and batch: 650, loss is 3.8525408506393433 and perplexity is 47.11261740666768
At time: 484.328382730484 and batch: 700, loss is 3.912517285346985 and perplexity is 50.02472010476435
At time: 484.6726026535034 and batch: 750, loss is 3.8570126152038573 and perplexity is 47.32376569058001
At time: 485.0302083492279 and batch: 800, loss is 3.7792427158355713 and perplexity is 43.782873101645414
At time: 485.377240896225 and batch: 850, loss is 3.7312733268737794 and perplexity is 41.73221309532259
At time: 485.72165036201477 and batch: 900, loss is 3.638009576797485 and perplexity is 38.0160932555409
At time: 486.0656819343567 and batch: 950, loss is 3.8057653665542603 and perplexity is 44.95964755853976
At time: 486.4084804058075 and batch: 1000, loss is 3.841474847793579 and perplexity is 46.59414305854519
At time: 486.7544159889221 and batch: 1050, loss is 3.7438884115219118 and perplexity is 42.26200314332834
At time: 487.0993936061859 and batch: 1100, loss is 3.9062805461883543 and perplexity is 49.713699858206205
At time: 487.4455578327179 and batch: 1150, loss is 3.8091307497024536 and perplexity is 45.11120888670571
At time: 487.7894067764282 and batch: 1200, loss is 3.754588232040405 and perplexity is 42.71662685041336
At time: 488.13519501686096 and batch: 1250, loss is 3.670907120704651 and perplexity is 39.2875282312598
At time: 488.4803514480591 and batch: 1300, loss is 3.771694903373718 and perplexity is 43.4536521982122
At time: 488.82362389564514 and batch: 1350, loss is 3.7502569580078124 and perplexity is 42.53200953648242
At time: 489.16758823394775 and batch: 1400, loss is 3.6056106662750245 and perplexity is 36.80415205070018
At time: 489.51042127609253 and batch: 1450, loss is 3.7157768774032593 and perplexity is 41.090496966336566
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.503765399639423 and perplexity of 90.35672071796628
Finished 45 epochs...
Completing Train Step...
At time: 490.74588799476624 and batch: 50, loss is 3.8922034692764282 and perplexity is 49.01877898467725
At time: 491.1052279472351 and batch: 100, loss is 3.9369378519058227 and perplexity is 51.2613907523831
At time: 491.4493315219879 and batch: 150, loss is 3.762325921058655 and perplexity is 43.048436890838865
At time: 491.793420791626 and batch: 200, loss is 3.882511143684387 and perplexity is 48.54596803881106
At time: 492.1371331214905 and batch: 250, loss is 3.9510627031326293 and perplexity is 51.99058804854251
At time: 492.48166680336 and batch: 300, loss is 3.943870115280151 and perplexity is 51.617982780903176
At time: 492.8240809440613 and batch: 350, loss is 3.914613223075867 and perplexity is 50.12967875798609
At time: 493.169025182724 and batch: 400, loss is 3.7313464450836182 and perplexity is 41.735264591595346
At time: 493.51205563545227 and batch: 450, loss is 3.8404066944122315 and perplexity is 46.54439993845671
At time: 493.87818717956543 and batch: 500, loss is 3.7956162214279177 and perplexity is 44.50565329444745
At time: 494.22215700149536 and batch: 550, loss is 3.8499118423461915 and perplexity is 46.98892061598383
At time: 494.5650153160095 and batch: 600, loss is 3.7766021251678468 and perplexity is 43.667412964097146
At time: 494.9099934101105 and batch: 650, loss is 3.8523910903930663 and perplexity is 47.105562337779716
At time: 495.2541275024414 and batch: 700, loss is 3.9123529529571535 and perplexity is 50.01650009838402
At time: 495.59684014320374 and batch: 750, loss is 3.8568759393692016 and perplexity is 47.31729811739575
At time: 495.9392657279968 and batch: 800, loss is 3.779113001823425 and perplexity is 43.77719421783548
At time: 496.2815501689911 and batch: 850, loss is 3.731169924736023 and perplexity is 41.72789811836799
At time: 496.6262149810791 and batch: 900, loss is 3.6379232358932496 and perplexity is 38.01281105336991
At time: 496.96995520591736 and batch: 950, loss is 3.805691304206848 and perplexity is 44.956317864806735
At time: 497.3122992515564 and batch: 1000, loss is 3.8413970279693603 and perplexity is 46.59051725160441
At time: 497.65676975250244 and batch: 1050, loss is 3.7438643169403076 and perplexity is 42.260984870312335
At time: 498.00014424324036 and batch: 1100, loss is 3.9062533235549926 and perplexity is 49.71234653880245
At time: 498.34429717063904 and batch: 1150, loss is 3.8090767526626585 and perplexity is 45.10877308072801
At time: 498.6856198310852 and batch: 1200, loss is 3.754600658416748 and perplexity is 42.71715766659276
At time: 499.0288882255554 and batch: 1250, loss is 3.6709180164337156 and perplexity is 39.28795629985509
At time: 499.37237215042114 and batch: 1300, loss is 3.771714072227478 and perplexity is 43.45448516289998
At time: 499.71884751319885 and batch: 1350, loss is 3.7502728939056396 and perplexity is 42.53268732764136
At time: 500.0618898868561 and batch: 1400, loss is 3.6056309366226196 and perplexity is 36.804898091216415
At time: 500.40686416625977 and batch: 1450, loss is 3.715794229507446 and perplexity is 41.091209979107134
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.503746097923344 and perplexity of 90.35497669502847
Finished 46 epochs...
Completing Train Step...
At time: 501.66389513015747 and batch: 50, loss is 3.8919591808319094 and perplexity is 49.00680572593079
At time: 502.02273201942444 and batch: 100, loss is 3.936707501411438 and perplexity is 51.24958402557532
At time: 502.36656856536865 and batch: 150, loss is 3.7621300125122072 and perplexity is 43.04000416018972
At time: 502.7242810726166 and batch: 200, loss is 3.8822995805740357 and perplexity is 48.53569858917441
At time: 503.0688695907593 and batch: 250, loss is 3.9508403015136717 and perplexity is 51.97902654328635
At time: 503.4115800857544 and batch: 300, loss is 3.9436789608001708 and perplexity is 51.60811671524842
At time: 503.75536155700684 and batch: 350, loss is 3.914402823448181 and perplexity is 50.119132601731984
At time: 504.10008931159973 and batch: 400, loss is 3.731138000488281 and perplexity is 41.72656600787414
At time: 504.44531774520874 and batch: 450, loss is 3.84019082069397 and perplexity is 46.53435331021826
At time: 504.7888152599335 and batch: 500, loss is 3.7954177331924437 and perplexity is 44.496820322505926
At time: 505.1335597038269 and batch: 550, loss is 3.8497269439697264 and perplexity is 46.980233244015324
At time: 505.47681856155396 and batch: 600, loss is 3.7764379262924193 and perplexity is 43.660243412627864
At time: 505.82039165496826 and batch: 650, loss is 3.8522490310668944 and perplexity is 47.098871028627755
At time: 506.1656451225281 and batch: 700, loss is 3.912198724746704 and perplexity is 50.00878673790509
At time: 506.50989174842834 and batch: 750, loss is 3.856746487617493 and perplexity is 47.311173206717086
At time: 506.85344195365906 and batch: 800, loss is 3.7789882898330687 and perplexity is 43.77173501723331
At time: 507.19749903678894 and batch: 850, loss is 3.731068072319031 and perplexity is 41.72364824752212
At time: 507.5404598712921 and batch: 900, loss is 3.637836241722107 and perplexity is 38.00950430421555
At time: 507.8863844871521 and batch: 950, loss is 3.8056142139434814 and perplexity is 44.95285230400476
At time: 508.2295331954956 and batch: 1000, loss is 3.841317925453186 and perplexity is 46.586831970219386
At time: 508.5724709033966 and batch: 1050, loss is 3.743832731246948 and perplexity is 42.25965004888389
At time: 508.91589403152466 and batch: 1100, loss is 3.9062192583084108 and perplexity is 49.71065310430325
At time: 509.2606179714203 and batch: 1150, loss is 3.809015517234802 and perplexity is 45.10601091028054
At time: 509.6053943634033 and batch: 1200, loss is 3.754601583480835 and perplexity is 42.71719718271948
At time: 509.9504978656769 and batch: 1250, loss is 3.6709151077270508 and perplexity is 39.28784202288095
At time: 510.2941336631775 and batch: 1300, loss is 3.7717197227478025 and perplexity is 43.454730704045296
At time: 510.6380548477173 and batch: 1350, loss is 3.750274510383606 and perplexity is 42.532756080848856
At time: 510.9832010269165 and batch: 1400, loss is 3.605635738372803 and perplexity is 36.805074819566876
At time: 511.32679414749146 and batch: 1450, loss is 3.7157977056503295 and perplexity is 41.09135281827254
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.503732534555288 and perplexity of 90.35375118553496
Finished 47 epochs...
Completing Train Step...
At time: 512.5924789905548 and batch: 50, loss is 3.8917230319976808 and perplexity is 48.995234192245206
At time: 512.9350106716156 and batch: 100, loss is 3.936486854553223 and perplexity is 51.238277213327414
At time: 513.2779219150543 and batch: 150, loss is 3.761941213607788 and perplexity is 43.03187902159084
At time: 513.623372554779 and batch: 200, loss is 3.8820975255966186 and perplexity is 48.525892700389726
At time: 513.9671170711517 and batch: 250, loss is 3.9506291151046753 and perplexity is 51.96805043837043
At time: 514.3106381893158 and batch: 300, loss is 3.9434966087341308 and perplexity is 51.59870672653248
At time: 514.654257774353 and batch: 350, loss is 3.914203233718872 and perplexity is 50.10913033583077
At time: 514.9983472824097 and batch: 400, loss is 3.730938220024109 and perplexity is 41.71823068779356
At time: 515.3417201042175 and batch: 450, loss is 3.839986653327942 and perplexity is 46.52485348368338
At time: 515.6853711605072 and batch: 500, loss is 3.7952268886566163 and perplexity is 44.488329157757654
At time: 516.0293283462524 and batch: 550, loss is 3.849549403190613 and perplexity is 46.97189307718401
At time: 516.3779644966125 and batch: 600, loss is 3.776280446052551 and perplexity is 43.65336832838171
At time: 516.7228133678436 and batch: 650, loss is 3.852112455368042 and perplexity is 47.09243890664763
At time: 517.0683178901672 and batch: 700, loss is 3.9120516204833984 and perplexity is 50.001430773233345
At time: 517.4119551181793 and batch: 750, loss is 3.856621880531311 and perplexity is 47.30527826656324
At time: 517.7543773651123 and batch: 800, loss is 3.7788670873641967 and perplexity is 43.76643009637366
At time: 518.099112033844 and batch: 850, loss is 3.7309670782089235 and perplexity is 41.71943461757642
At time: 518.4432537555695 and batch: 900, loss is 3.6377482318878176 and perplexity is 38.0061592412417
At time: 518.7872531414032 and batch: 950, loss is 3.8055343008041382 and perplexity is 44.94926012398781
At time: 519.1300227642059 and batch: 1000, loss is 3.841237659454346 and perplexity is 46.58309278168535
At time: 519.4743402004242 and batch: 1050, loss is 3.743794779777527 and perplexity is 42.2580462635005
At time: 519.817661523819 and batch: 1100, loss is 3.906179461479187 and perplexity is 49.70867481729609
At time: 520.1612498760223 and batch: 1150, loss is 3.808948826789856 and perplexity is 45.103002870648055
At time: 520.521481513977 and batch: 1200, loss is 3.7545939826965333 and perplexity is 42.71687249975165
At time: 520.8651447296143 and batch: 1250, loss is 3.6709015464782713 and perplexity is 39.287309234293915
At time: 521.210851430893 and batch: 1300, loss is 3.771715006828308 and perplexity is 43.454525775516856
At time: 521.5538301467896 and batch: 1350, loss is 3.750265588760376 and perplexity is 42.53237662131687
At time: 521.8990681171417 and batch: 1400, loss is 3.6056289958953855 and perplexity is 36.80482666301766
At time: 522.2428860664368 and batch: 1450, loss is 3.715790572166443 and perplexity is 41.091059694814824
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.503719492855235 and perplexity of 90.35257282669723
Finished 48 epochs...
Completing Train Step...
At time: 523.4914960861206 and batch: 50, loss is 3.8914933013916015 and perplexity is 48.98397978019018
At time: 523.8364923000336 and batch: 100, loss is 3.936274185180664 and perplexity is 51.22738155968845
At time: 524.1803443431854 and batch: 150, loss is 3.7617583751678465 and perplexity is 43.024011859194545
At time: 524.5236873626709 and batch: 200, loss is 3.8819033193588255 and perplexity is 48.5164695843764
At time: 524.8676166534424 and batch: 250, loss is 3.9504271745681763 and perplexity is 51.95755704194082
At time: 525.2101979255676 and batch: 300, loss is 3.9433213090896606 and perplexity is 51.58966228435511
At time: 525.5526556968689 and batch: 350, loss is 3.9140122985839843 and perplexity is 50.099563655607746
At time: 525.8959407806396 and batch: 400, loss is 3.730745496749878 and perplexity is 41.71019138848521
At time: 526.2382483482361 and batch: 450, loss is 3.8397909593582153 and perplexity is 46.51574974121701
At time: 526.5855367183685 and batch: 500, loss is 3.7950418519973756 and perplexity is 44.48009794751641
At time: 526.9282968044281 and batch: 550, loss is 3.849377307891846 and perplexity is 46.96381013074973
At time: 527.2716302871704 and batch: 600, loss is 3.7761279487609865 and perplexity is 43.64671181550695
At time: 527.6143209934235 and batch: 650, loss is 3.851979947090149 and perplexity is 47.08619918208304
At time: 527.9579019546509 and batch: 700, loss is 3.911910071372986 and perplexity is 49.99435361608251
At time: 528.3014566898346 and batch: 750, loss is 3.856500644683838 and perplexity is 47.29954351869818
At time: 528.6440951824188 and batch: 800, loss is 3.7787482261657717 and perplexity is 43.761228275195094
At time: 528.9873580932617 and batch: 850, loss is 3.730866413116455 and perplexity is 41.71523513820694
At time: 529.3484904766083 and batch: 900, loss is 3.637658939361572 and perplexity is 38.002765726780154
At time: 529.6928243637085 and batch: 950, loss is 3.8054523611068727 and perplexity is 44.945577146114054
At time: 530.037538766861 and batch: 1000, loss is 3.841155891418457 and perplexity is 46.579283929406266
At time: 530.3808076381683 and batch: 1050, loss is 3.743751826286316 and perplexity is 42.25623117186427
At time: 530.7254450321198 and batch: 1100, loss is 3.9061355495452883 and perplexity is 49.70649206117819
At time: 531.0691454410553 and batch: 1150, loss is 3.8088780641555786 and perplexity is 45.09981137627171
At time: 531.4147701263428 and batch: 1200, loss is 3.754579544067383 and perplexity is 42.716255731123816
At time: 531.7589304447174 and batch: 1250, loss is 3.670879912376404 and perplexity is 39.28645929783769
At time: 532.1036665439606 and batch: 1300, loss is 3.7717021322250366 and perplexity is 43.45396631933854
At time: 532.4475040435791 and batch: 1350, loss is 3.750248365402222 and perplexity is 42.53164407726962
At time: 532.7912242412567 and batch: 1400, loss is 3.6056129837036135 and perplexity is 36.80423734179317
At time: 533.1337094306946 and batch: 1450, loss is 3.715775089263916 and perplexity is 41.090423490868005
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.503708016159188 and perplexity of 90.3515358836322
Finished 49 epochs...
Completing Train Step...
At time: 534.3676519393921 and batch: 50, loss is 3.8912689590454104 and perplexity is 48.97299183181765
At time: 534.7265658378601 and batch: 100, loss is 3.9360681676864626 and perplexity is 51.21682890995757
At time: 535.0704395771027 and batch: 150, loss is 3.761580562591553 and perplexity is 43.01636232891487
At time: 535.4136185646057 and batch: 200, loss is 3.881715326309204 and perplexity is 48.507349682568304
At time: 535.7579524517059 and batch: 250, loss is 3.9502325010299684 and perplexity is 51.947443264949136
At time: 536.1004576683044 and batch: 300, loss is 3.943151578903198 and perplexity is 51.58090670442017
At time: 536.4456443786621 and batch: 350, loss is 3.9138278579711914 and perplexity is 50.09032411348605
At time: 536.7897613048553 and batch: 400, loss is 3.7305582904815675 and perplexity is 41.70238371005083
At time: 537.1327631473541 and batch: 450, loss is 3.839602074623108 and perplexity is 46.50696445587808
At time: 537.4751882553101 and batch: 500, loss is 3.7948614358901978 and perplexity is 44.47207374526726
At time: 537.8197662830353 and batch: 550, loss is 3.8492097997665407 and perplexity is 46.95594396979887
At time: 538.1795170307159 and batch: 600, loss is 3.775979509353638 and perplexity is 43.640233404309996
At time: 538.525307893753 and batch: 650, loss is 3.851850299835205 and perplexity is 47.08009498131832
At time: 538.8699657917023 and batch: 700, loss is 3.9117726039886476 and perplexity is 49.98748149541627
At time: 539.2154808044434 and batch: 750, loss is 3.8563818407058714 and perplexity is 47.293924478560925
At time: 539.5590751171112 and batch: 800, loss is 3.7786311531066894 and perplexity is 43.756105314217926
At time: 539.9012064933777 and batch: 850, loss is 3.7307659435272216 and perplexity is 41.71104423620046
At time: 540.2444386482239 and batch: 900, loss is 3.6375685501098634 and perplexity is 37.99933084046398
At time: 540.5878627300262 and batch: 950, loss is 3.8053685140609743 and perplexity is 44.94180875023079
At time: 540.9324088096619 and batch: 1000, loss is 3.841073126792908 and perplexity is 46.57542897194276
At time: 541.2756040096283 and batch: 1050, loss is 3.7437047958374023 and perplexity is 42.25424388907463
At time: 541.6204211711884 and batch: 1100, loss is 3.906087946891785 and perplexity is 49.704125956576604
At time: 541.9648447036743 and batch: 1150, loss is 3.8088038969039917 and perplexity is 45.09646657125387
At time: 542.3090131282806 and batch: 1200, loss is 3.75455940246582 and perplexity is 42.71539536598523
At time: 542.6526527404785 and batch: 1250, loss is 3.670851731300354 and perplexity is 39.28535217874045
At time: 542.9952235221863 and batch: 1300, loss is 3.7716825103759763 and perplexity is 43.45311368053556
At time: 543.3391728401184 and batch: 1350, loss is 3.750224509239197 and perplexity is 42.53062944753742
At time: 543.6839277744293 and batch: 1400, loss is 3.605589632987976 and perplexity is 36.80337794654653
At time: 544.0282249450684 and batch: 1450, loss is 3.715753026008606 and perplexity is 41.089516912364786
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.5037007128071584 and perplexity of 90.35087601696883
Finished Training.
Improved accuracyfrom -228.39466900152988 to -90.35087601696883
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f3cbdcfe358>
SETTINGS FOR THIS RUN
{'lr': 22.75285281568356, 'batch_size': 20, 'dropout': 0.7521985588596631, 'wordvec_source': 'glove', 'anneal': 2.5011846208586856, 'num_layers': 1, 'seq_len': 35, 'wordvec_dim': 200, 'tune_wordvecs': True, 'data': 'ptb'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.6109344959259033 and batch: 50, loss is 6.725515832901001 and perplexity is 833.401761736663
At time: 0.9769265651702881 and batch: 100, loss is 6.22247353553772 and perplexity is 503.94822546255125
At time: 1.3301808834075928 and batch: 150, loss is 6.139195423126221 and perplexity is 463.6803542488285
At time: 1.6796929836273193 and batch: 200, loss is 6.023850612640381 and perplexity is 413.16648067281096
At time: 2.029278516769409 and batch: 250, loss is 5.993892850875855 and perplexity is 400.97250179415875
At time: 2.37864351272583 and batch: 300, loss is 6.087402973175049 and perplexity is 440.2765152063341
At time: 2.727475881576538 and batch: 350, loss is 6.13740478515625 and perplexity is 462.8508135257914
At time: 3.079437732696533 and batch: 400, loss is 6.066833572387695 and perplexity is 431.31279631475445
At time: 3.4277548789978027 and batch: 450, loss is 6.115185089111328 and perplexity is 452.6798257243844
At time: 3.793259382247925 and batch: 500, loss is 6.076666460037232 and perplexity is 435.5747659779259
At time: 4.1439368724823 and batch: 550, loss is 6.156330432891846 and perplexity is 471.69398237357336
At time: 4.491751432418823 and batch: 600, loss is 6.004942598342896 and perplexity is 405.4277158447302
At time: 4.840635776519775 and batch: 650, loss is 6.220192279815674 and perplexity is 502.79990099847925
At time: 5.190505266189575 and batch: 700, loss is 6.178103437423706 and perplexity is 482.0767999836908
At time: 5.540006637573242 and batch: 750, loss is 6.137554349899292 and perplexity is 462.92004486593794
At time: 5.889913082122803 and batch: 800, loss is 6.127116613388061 and perplexity is 458.11333662825695
At time: 6.2385077476501465 and batch: 850, loss is 6.103043146133423 and perplexity is 447.2166470134558
At time: 6.588815450668335 and batch: 900, loss is 6.060532655715942 and perplexity is 428.6036742648823
At time: 6.938540697097778 and batch: 950, loss is 6.100574741363525 and perplexity is 446.11409663891374
At time: 7.288646221160889 and batch: 1000, loss is 6.185185403823852 and perplexity is 485.50296937197595
At time: 7.638500690460205 and batch: 1050, loss is 6.006571435928345 and perplexity is 406.08862986115304
At time: 7.987147569656372 and batch: 1100, loss is 6.096176557540893 and perplexity is 444.1563133374
At time: 8.338294744491577 and batch: 1150, loss is 6.1660434532165525 and perplexity is 476.2978782833838
At time: 8.68920373916626 and batch: 1200, loss is 6.1791368675231935 and perplexity is 482.57525017141086
At time: 9.040534496307373 and batch: 1250, loss is 6.184023046493531 and perplexity is 484.9389692849517
At time: 9.389151334762573 and batch: 1300, loss is 6.216273221969605 and perplexity is 500.83325531770555
At time: 9.739602327346802 and batch: 1350, loss is 6.195331764221192 and perplexity is 490.4541331429851
At time: 10.089407205581665 and batch: 1400, loss is 6.130539016723633 and perplexity is 459.68387120804357
At time: 10.439860582351685 and batch: 1450, loss is 6.15779522895813 and perplexity is 472.3854241504102
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 6.14993886051015 and perplexity of 468.6887305165288
Finished 1 epochs...
Completing Train Step...
At time: 11.686704874038696 and batch: 50, loss is 6.353032865524292 and perplexity is 574.23163804978
At time: 12.041897773742676 and batch: 100, loss is 6.602330455780029 and perplexity is 736.8102937860314
At time: 12.384329795837402 and batch: 150, loss is 6.664922370910644 and perplexity is 784.4025701601932
At time: 12.741026639938354 and batch: 200, loss is 6.59724289894104 and perplexity is 733.0712489034026
At time: 13.08585786819458 and batch: 250, loss is 6.516612987518311 and perplexity is 676.2839197637461
At time: 13.426551103591919 and batch: 300, loss is 6.573146886825562 and perplexity is 715.618273215982
At time: 13.766632795333862 and batch: 350, loss is 6.761615381240845 and perplexity is 864.0368179298314
At time: 14.107123613357544 and batch: 400, loss is 6.699222478866577 and perplexity is 811.7744079714763
At time: 14.447269678115845 and batch: 450, loss is 6.847977800369263 and perplexity is 941.9741196524341
At time: 14.79215383529663 and batch: 500, loss is 6.848334131240844 and perplexity is 942.3098339206239
At time: 15.13329792022705 and batch: 550, loss is 6.675919990539551 and perplexity is 793.076741454463
At time: 15.475032806396484 and batch: 600, loss is 6.6172825050354005 and perplexity is 747.9098916694873
At time: 15.816868782043457 and batch: 650, loss is 6.697276077270508 and perplexity is 810.195905666199
At time: 16.156800985336304 and batch: 700, loss is 6.640237102508545 and perplexity is 765.2764204697597
At time: 16.49910068511963 and batch: 750, loss is 6.616696367263794 and perplexity is 747.4716418821454
At time: 16.84063720703125 and batch: 800, loss is 6.802090072631836 and perplexity is 899.7258201489185
At time: 17.18020510673523 and batch: 850, loss is 6.55141697883606 and perplexity is 700.2356903244752
At time: 17.521697282791138 and batch: 900, loss is 6.475991592407227 and perplexity is 649.3628117052158
At time: 17.86194944381714 and batch: 950, loss is 6.59746808052063 and perplexity is 733.2363416324059
At time: 18.20299983024597 and batch: 1000, loss is 6.701580228805542 and perplexity is 813.6906271274374
At time: 18.543328046798706 and batch: 1050, loss is 6.468033761978149 and perplexity is 644.215799250951
At time: 18.883368015289307 and batch: 1100, loss is 6.503971891403198 and perplexity is 667.7887569428204
At time: 19.223675966262817 and batch: 1150, loss is 6.638804492950439 and perplexity is 764.1808630955588
At time: 19.56331157684326 and batch: 1200, loss is 6.431895484924317 and perplexity is 621.3505931859248
At time: 19.90377950668335 and batch: 1250, loss is 6.573571090698242 and perplexity is 715.9219056553161
At time: 20.244090795516968 and batch: 1300, loss is 6.638048315048218 and perplexity is 763.6032248397529
At time: 20.586214303970337 and batch: 1350, loss is 6.638178606033325 and perplexity is 763.7027219377945
At time: 20.926849842071533 and batch: 1400, loss is 6.523847513198852 and perplexity is 681.194253700546
At time: 21.26800298690796 and batch: 1450, loss is 6.568976049423218 and perplexity is 712.6397615180675
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 6.59307861328125 and perplexity of 730.0248781952449
Annealing...
Finished 2 epochs...
Completing Train Step...
At time: 22.51500129699707 and batch: 50, loss is 6.276601810455322 and perplexity is 531.9778272945465
At time: 22.855815649032593 and batch: 100, loss is 6.221938781738281 and perplexity is 503.6788092763495
At time: 23.196107864379883 and batch: 150, loss is 6.22290376663208 and perplexity is 504.16508630588686
At time: 23.537959575653076 and batch: 200, loss is 6.138514728546142 and perplexity is 463.3648369424453
At time: 23.88000988960266 and batch: 250, loss is 6.110346584320069 and perplexity is 450.4948225556416
At time: 24.221356630325317 and batch: 300, loss is 6.20317307472229 and perplexity is 494.31505384378164
At time: 24.56335687637329 and batch: 350, loss is 6.243108625411987 and perplexity is 514.4552765298715
At time: 24.903385639190674 and batch: 400, loss is 6.150062818527221 and perplexity is 468.74683184317547
At time: 25.24506711959839 and batch: 450, loss is 6.202960653305054 and perplexity is 494.2100618911473
At time: 25.585956573486328 and batch: 500, loss is 6.147834100723267 and perplexity is 467.70329074476683
At time: 25.927188396453857 and batch: 550, loss is 6.219608316421509 and perplexity is 502.50636997573395
At time: 26.266138553619385 and batch: 600, loss is 6.03350757598877 and perplexity is 417.1757417193716
At time: 26.60787343978882 and batch: 650, loss is 6.261855163574219 and perplexity is 524.1904977475567
At time: 26.949382305145264 and batch: 700, loss is 6.167829885482788 and perplexity is 477.14951264855523
At time: 27.289961576461792 and batch: 750, loss is 6.141712379455567 and perplexity is 464.8488874078187
At time: 27.63174843788147 and batch: 800, loss is 6.130904016494751 and perplexity is 459.85168634020033
At time: 27.9730806350708 and batch: 850, loss is 6.117470455169678 and perplexity is 453.7155478847408
At time: 28.31415843963623 and batch: 900, loss is 6.050114583969116 and perplexity is 424.1616293834001
At time: 28.656018018722534 and batch: 950, loss is 6.082910213470459 and perplexity is 438.3028954393921
At time: 28.99776864051819 and batch: 1000, loss is 6.171097202301025 and perplexity is 478.71106092334225
At time: 29.340700149536133 and batch: 1050, loss is 6.000691995620728 and perplexity is 403.7080610659323
At time: 29.681989431381226 and batch: 1100, loss is 6.113106355667115 and perplexity is 451.73980239859014
At time: 30.023425579071045 and batch: 1150, loss is 6.146874475479126 and perplexity is 467.25468614077766
At time: 30.38133668899536 and batch: 1200, loss is 6.115475254058838 and perplexity is 452.81119660094436
At time: 30.724034070968628 and batch: 1250, loss is 6.131465358734131 and perplexity is 460.10989297995985
At time: 31.067121267318726 and batch: 1300, loss is 6.209647960662842 and perplexity is 497.5260717050625
At time: 31.40842080116272 and batch: 1350, loss is 6.135912256240845 and perplexity is 462.1605105797845
At time: 31.74908137321472 and batch: 1400, loss is 6.122425508499146 and perplexity is 455.96931176973646
At time: 32.09083819389343 and batch: 1450, loss is 6.0990041160583495 and perplexity is 445.41396851313937
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 6.1835467998798075 and perplexity of 484.7080737289449
Annealing...
Finished 3 epochs...
Completing Train Step...
At time: 33.355584383010864 and batch: 50, loss is 6.090160093307495 and perplexity is 441.49208541676813
At time: 33.698339223861694 and batch: 100, loss is 6.036015167236328 and perplexity is 418.22316065843404
At time: 34.04099178314209 and batch: 150, loss is 6.051137561798096 and perplexity is 424.5957593409647
At time: 34.382744550704956 and batch: 200, loss is 5.946027135848999 and perplexity is 382.23176368499514
At time: 34.727559089660645 and batch: 250, loss is 5.934741144180298 and perplexity is 377.942150982999
At time: 35.068158864974976 and batch: 300, loss is 6.019900674819946 and perplexity is 411.5377176386843
At time: 35.41180443763733 and batch: 350, loss is 6.0480913734436035 and perplexity is 423.3043286526821
At time: 35.75361943244934 and batch: 400, loss is 5.951467428207398 and perplexity is 384.316882914481
At time: 36.093247413635254 and batch: 450, loss is 5.989107990264893 and perplexity is 399.05848706285514
At time: 36.43507528305054 and batch: 500, loss is 5.968743686676025 and perplexity is 391.0141257912054
At time: 36.77798342704773 and batch: 550, loss is 6.030404472351075 and perplexity is 415.8832086269316
At time: 37.1208770275116 and batch: 600, loss is 5.8761489295959475 and perplexity is 356.43394301358694
At time: 37.46294188499451 and batch: 650, loss is 6.066210289001464 and perplexity is 431.044049975807
At time: 37.807785987854004 and batch: 700, loss is 6.000548725128174 and perplexity is 403.65022575632094
At time: 38.15332579612732 and batch: 750, loss is 5.954255170822144 and perplexity is 385.3897542162532
At time: 38.4975426197052 and batch: 800, loss is 5.967121629714966 and perplexity is 390.3803927211118
At time: 38.838998317718506 and batch: 850, loss is 5.921850862503052 and perplexity is 373.1016350307358
At time: 39.19632959365845 and batch: 900, loss is 5.873502264022827 and perplexity is 355.4918288480316
At time: 39.54012489318848 and batch: 950, loss is 5.926581983566284 and perplexity is 374.871006289378
At time: 39.88227462768555 and batch: 1000, loss is 5.979676370620727 and perplexity is 395.312412740621
At time: 40.22426748275757 and batch: 1050, loss is 5.828655281066895 and perplexity is 339.9012999040894
At time: 40.566882610321045 and batch: 1100, loss is 5.926134605407714 and perplexity is 374.70333469798356
At time: 40.90952110290527 and batch: 1150, loss is 5.959346199035645 and perplexity is 387.3567871897903
At time: 41.25286912918091 and batch: 1200, loss is 5.9157491970062255 and perplexity is 370.83202489989435
At time: 41.59415006637573 and batch: 1250, loss is 5.954423360824585 and perplexity is 385.4545783711901
At time: 41.93636131286621 and batch: 1300, loss is 6.022732086181641 and perplexity is 412.70460139256676
At time: 42.27762794494629 and batch: 1350, loss is 5.956793727874756 and perplexity is 386.3693309244492
At time: 42.62132143974304 and batch: 1400, loss is 5.889667234420776 and perplexity is 361.2850411410112
At time: 42.96323752403259 and batch: 1450, loss is 5.911318225860596 and perplexity is 369.1925138931142
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.988838913094284 and perplexity of 398.95112397937396
Finished 4 epochs...
Completing Train Step...
At time: 44.21912884712219 and batch: 50, loss is 5.990831489562988 and perplexity is 399.7468571174626
At time: 44.56344294548035 and batch: 100, loss is 5.999565172195434 and perplexity is 403.2534095698286
At time: 44.9064416885376 and batch: 150, loss is 6.0233853149414065 and perplexity is 412.9742799787987
At time: 45.254924297332764 and batch: 200, loss is 5.91646300315857 and perplexity is 371.0968215762593
At time: 45.597304344177246 and batch: 250, loss is 5.9137962055206295 and perplexity is 370.108499861769
At time: 45.9371452331543 and batch: 300, loss is 5.994832181930542 and perplexity is 401.3493246701773
At time: 46.280266761779785 and batch: 350, loss is 6.033383922576904 and perplexity is 417.1241597047723
At time: 46.62198996543884 and batch: 400, loss is 5.9371810722351075 and perplexity is 378.865428547652
At time: 46.96367812156677 and batch: 450, loss is 5.9751867580413816 and perplexity is 393.54159128523054
At time: 47.30632567405701 and batch: 500, loss is 5.948947458267212 and perplexity is 383.3496351515297
At time: 47.649046659469604 and batch: 550, loss is 6.0143821239471436 and perplexity is 409.272880864149
At time: 48.00536847114563 and batch: 600, loss is 5.858881788253784 and perplexity is 350.33217935297887
At time: 48.349791049957275 and batch: 650, loss is 6.050977334976197 and perplexity is 424.52773316180844
At time: 48.69246745109558 and batch: 700, loss is 5.989454011917115 and perplexity is 399.19659383247006
At time: 49.035868883132935 and batch: 750, loss is 5.944472484588623 and perplexity is 381.63798826826985
At time: 49.37950420379639 and batch: 800, loss is 5.95249153137207 and perplexity is 384.7106646526568
At time: 49.72083759307861 and batch: 850, loss is 5.907236061096191 and perplexity is 367.6884811649299
At time: 50.062849044799805 and batch: 900, loss is 5.863643817901611 and perplexity is 352.0044501189667
At time: 50.407151222229004 and batch: 950, loss is 5.912274513244629 and perplexity is 369.5457369008647
At time: 50.748151540756226 and batch: 1000, loss is 5.966801490783691 and perplexity is 390.2554367620962
At time: 51.08977270126343 and batch: 1050, loss is 5.8099715042114255 and perplexity is 333.6096190699479
At time: 51.43411993980408 and batch: 1100, loss is 5.911439914703369 and perplexity is 369.23744323653483
At time: 51.77787518501282 and batch: 1150, loss is 5.941053714752197 and perplexity is 380.33548357605883
At time: 52.12004733085632 and batch: 1200, loss is 5.907874612808228 and perplexity is 367.9233442522066
At time: 52.462809324264526 and batch: 1250, loss is 5.941872072219849 and perplexity is 380.6468613510422
At time: 52.805886030197144 and batch: 1300, loss is 5.995659704208374 and perplexity is 401.6815876360768
At time: 53.147037744522095 and batch: 1350, loss is 5.950133390426636 and perplexity is 383.8045314969467
At time: 53.48899054527283 and batch: 1400, loss is 5.878956089019775 and perplexity is 357.4359156061184
At time: 53.83105707168579 and batch: 1450, loss is 5.902985792160035 and perplexity is 366.12902264191706
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.975301106770833 and perplexity of 393.58659483918086
Finished 5 epochs...
Completing Train Step...
At time: 55.072526931762695 and batch: 50, loss is 5.972404661178589 and perplexity is 392.44824206567034
At time: 55.431023597717285 and batch: 100, loss is 5.984792680740356 and perplexity is 397.3401364467538
At time: 55.772136926651 and batch: 150, loss is 6.009609994888305 and perplexity is 407.32443068195477
At time: 56.11489391326904 and batch: 200, loss is 5.900713872909546 and perplexity is 365.2981512609435
At time: 56.457799673080444 and batch: 250, loss is 5.899835987091064 and perplexity is 364.977601917882
At time: 56.8147611618042 and batch: 300, loss is 5.9796796226501465 and perplexity is 395.3136983103073
At time: 57.1571044921875 and batch: 350, loss is 6.017738571166992 and perplexity is 410.6488916492576
At time: 57.499733686447144 and batch: 400, loss is 5.922134742736817 and perplexity is 373.20756624528383
At time: 57.843331813812256 and batch: 450, loss is 5.956758184432983 and perplexity is 386.35559827268696
At time: 58.18706011772156 and batch: 500, loss is 5.938414707183838 and perplexity is 379.33309858891715
At time: 58.53019976615906 and batch: 550, loss is 6.003018884658814 and perplexity is 404.64853869701426
At time: 58.87324118614197 and batch: 600, loss is 5.845774154663086 and perplexity is 345.77011774413506
At time: 59.21771597862244 and batch: 650, loss is 6.036066761016846 and perplexity is 418.2447389290401
At time: 59.560017585754395 and batch: 700, loss is 5.977623376846314 and perplexity is 394.5016713266121
At time: 59.90336561203003 and batch: 750, loss is 5.931242160797119 and perplexity is 376.62204853199825
At time: 60.245877265930176 and batch: 800, loss is 5.935334348678589 and perplexity is 378.1664144775366
At time: 60.58907103538513 and batch: 850, loss is 5.893934879302979 and perplexity is 362.8301720878466
At time: 60.93091630935669 and batch: 900, loss is 5.849885053634644 and perplexity is 347.19446944263007
At time: 61.274556159973145 and batch: 950, loss is 5.903582258224487 and perplexity is 366.3474713212697
At time: 61.61603546142578 and batch: 1000, loss is 5.955822677612304 and perplexity is 385.99432898658375
At time: 61.95913648605347 and batch: 1050, loss is 5.799683971405029 and perplexity is 330.1951922962547
At time: 62.30083680152893 and batch: 1100, loss is 5.902335796356201 and perplexity is 365.89111764054064
At time: 62.64299559593201 and batch: 1150, loss is 5.932020788192749 and perplexity is 376.9154109719787
At time: 62.98505735397339 and batch: 1200, loss is 5.899187755584717 and perplexity is 364.7410886031808
At time: 63.326836824417114 and batch: 1250, loss is 5.932915992736817 and perplexity is 377.25297843402933
At time: 63.66958737373352 and batch: 1300, loss is 5.988051471710205 and perplexity is 398.63709700927
At time: 64.01163935661316 and batch: 1350, loss is 5.941681337356568 and perplexity is 380.5742656474699
At time: 64.35325241088867 and batch: 1400, loss is 5.867162361145019 and perplexity is 353.2451744897294
At time: 64.69628977775574 and batch: 1450, loss is 5.892794799804688 and perplexity is 362.4167525576327
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.970539842915331 and perplexity of 391.7170793711434
Finished 6 epochs...
Completing Train Step...
At time: 65.92915391921997 and batch: 50, loss is 5.964754705429077 and perplexity is 389.4574845466009
At time: 66.28932547569275 and batch: 100, loss is 5.977539539337158 and perplexity is 394.46859867551416
At time: 66.63111233711243 and batch: 150, loss is 6.0014116573333744 and perplexity is 403.99869886847387
At time: 66.97689080238342 and batch: 200, loss is 5.891692638397217 and perplexity is 362.0175308433393
At time: 67.3201231956482 and batch: 250, loss is 5.8877608013153075 and perplexity is 360.5969315039759
At time: 67.66273832321167 and batch: 300, loss is 5.9722501659393314 and perplexity is 392.38761536400506
At time: 68.00504112243652 and batch: 350, loss is 6.010541419982911 and perplexity is 407.70399962091386
At time: 68.34696435928345 and batch: 400, loss is 5.915960769653321 and perplexity is 370.9104911133897
At time: 68.68918561935425 and batch: 450, loss is 5.948824529647827 and perplexity is 383.3025134065036
At time: 69.03134083747864 and batch: 500, loss is 5.930831489562988 and perplexity is 376.4674124449963
At time: 69.37470078468323 and batch: 550, loss is 5.995389528274536 and perplexity is 401.57307759709244
At time: 69.71667671203613 and batch: 600, loss is 5.8377526664733885 and perplexity is 343.0076213071246
At time: 70.05918097496033 and batch: 650, loss is 6.028745365142822 and perplexity is 415.19378586898546
At time: 70.4012622833252 and batch: 700, loss is 5.968378019332886 and perplexity is 390.87117083327007
At time: 70.74429082870483 and batch: 750, loss is 5.925672693252563 and perplexity is 374.5302946408405
At time: 71.0875997543335 and batch: 800, loss is 5.927215595245361 and perplexity is 375.10860420156735
At time: 71.42889952659607 and batch: 850, loss is 5.885772476196289 and perplexity is 359.8806598936208
At time: 71.77030873298645 and batch: 900, loss is 5.842689819335938 and perplexity is 344.7052897423694
At time: 72.1129322052002 and batch: 950, loss is 5.895175790786743 and perplexity is 363.28069168470574
At time: 72.45280122756958 and batch: 1000, loss is 5.949307203292847 and perplexity is 383.48756808470995
At time: 72.79484057426453 and batch: 1050, loss is 5.794130325317383 and perplexity is 328.36648774755326
At time: 73.13567924499512 and batch: 1100, loss is 5.896269121170044 and perplexity is 363.67809470940495
At time: 73.47934103012085 and batch: 1150, loss is 5.925114345550537 and perplexity is 374.32123488093816
At time: 73.82104992866516 and batch: 1200, loss is 5.893038988113403 and perplexity is 362.5052612974499
At time: 74.17642855644226 and batch: 1250, loss is 5.924535284042358 and perplexity is 374.1045426072569
At time: 74.5209288597107 and batch: 1300, loss is 5.980686626434326 and perplexity is 395.7119812029771
At time: 74.86500406265259 and batch: 1350, loss is 5.935875587463379 and perplexity is 378.3711482080764
At time: 75.20644760131836 and batch: 1400, loss is 5.860782852172852 and perplexity is 350.99881667814674
At time: 75.54738235473633 and batch: 1450, loss is 5.885412702560425 and perplexity is 359.7512076082897
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.967032668936966 and perplexity of 390.34566572235263
Finished 7 epochs...
Completing Train Step...
At time: 76.79527950286865 and batch: 50, loss is 5.959704256057739 and perplexity is 387.4955078409689
At time: 77.13762784004211 and batch: 100, loss is 5.96852560043335 and perplexity is 390.92886028763314
At time: 77.47944784164429 and batch: 150, loss is 5.990813732147217 and perplexity is 399.73975870934225
At time: 77.82324075698853 and batch: 200, loss is 5.885059852600097 and perplexity is 359.62429180139287
At time: 78.1655650138855 and batch: 250, loss is 5.879305229187012 and perplexity is 357.56073262951986
At time: 78.50904321670532 and batch: 300, loss is 5.964146785736084 and perplexity is 389.2207976227717
At time: 78.851487159729 and batch: 350, loss is 6.002898759841919 and perplexity is 404.59993328481323
At time: 79.1933662891388 and batch: 400, loss is 5.909141597747802 and perplexity is 368.3897930176753
At time: 79.53535199165344 and batch: 450, loss is 5.933578577041626 and perplexity is 377.50302316519156
At time: 79.8776307106018 and batch: 500, loss is 5.918391561508178 and perplexity is 371.81319401100774
At time: 80.22140264511108 and batch: 550, loss is 5.9866468334198 and perplexity is 398.0775491520073
At time: 80.5677490234375 and batch: 600, loss is 5.828182344436645 and perplexity is 339.7405861354051
At time: 80.91053056716919 and batch: 650, loss is 6.02117657661438 and perplexity is 412.06313446995716
At time: 81.25212669372559 and batch: 700, loss is 5.960126428604126 and perplexity is 387.65913234268385
At time: 81.59519171714783 and batch: 750, loss is 5.921234655380249 and perplexity is 372.8717979665909
At time: 81.94078016281128 and batch: 800, loss is 5.92033094406128 and perplexity is 372.5349817174955
At time: 82.28265929222107 and batch: 850, loss is 5.880580320358276 and perplexity is 358.0169459578686
At time: 82.62503743171692 and batch: 900, loss is 5.834903144836426 and perplexity is 342.0316049188944
At time: 82.98405027389526 and batch: 950, loss is 5.886793336868286 and perplexity is 360.2482354957341
At time: 83.32577538490295 and batch: 1000, loss is 5.943391981124878 and perplexity is 381.2258497986687
At time: 83.66991758346558 and batch: 1050, loss is 5.78907283782959 and perplexity is 326.7099707821615
At time: 84.01282024383545 and batch: 1100, loss is 5.891090307235718 and perplexity is 361.7995420608123
At time: 84.35748839378357 and batch: 1150, loss is 5.918880996704101 and perplexity is 371.995217015064
At time: 84.70015120506287 and batch: 1200, loss is 5.885837612152099 and perplexity is 359.90410182782875
At time: 85.04073071479797 and batch: 1250, loss is 5.918754262924194 and perplexity is 371.94807564236964
At time: 85.3817982673645 and batch: 1300, loss is 5.9755627536773686 and perplexity is 393.6895890276422
At time: 85.72233629226685 and batch: 1350, loss is 5.928922681808472 and perplexity is 375.74949393099286
At time: 86.06484937667847 and batch: 1400, loss is 5.8536285781860355 and perplexity is 348.49663628916505
At time: 86.4063310623169 and batch: 1450, loss is 5.8809582805633545 and perplexity is 358.1522876914679
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.962849934895833 and perplexity of 388.71636346296094
Finished 8 epochs...
Completing Train Step...
At time: 87.65282893180847 and batch: 50, loss is 5.952489652633667 and perplexity is 384.70994188263603
At time: 87.99502110481262 and batch: 100, loss is 5.960207843780518 and perplexity is 387.69069496414414
At time: 88.33896899223328 and batch: 150, loss is 5.986053266525269 and perplexity is 397.8413336091728
At time: 88.68201327323914 and batch: 200, loss is 5.877428913116455 and perplexity is 356.89046469457935
At time: 89.02719235420227 and batch: 250, loss is 5.869539089202881 and perplexity is 354.0857407102188
At time: 89.36932611465454 and batch: 300, loss is 5.954256362915039 and perplexity is 385.39021363691506
At time: 89.71123147010803 and batch: 350, loss is 5.994590549468994 and perplexity is 401.25235736061325
At time: 90.05292344093323 and batch: 400, loss is 5.901524896621704 and perplexity is 365.59453689526646
At time: 90.3942060470581 and batch: 450, loss is 5.930864849090576 and perplexity is 376.4799714295076
At time: 90.73630023002625 and batch: 500, loss is 5.912852067947387 and perplexity is 369.75923142554484
At time: 91.07903289794922 and batch: 550, loss is 5.97850564956665 and perplexity is 394.8498829755828
At time: 91.42147660255432 and batch: 600, loss is 5.818756141662598 and perplexity is 336.5531687024544
At time: 91.76635193824768 and batch: 650, loss is 6.0103710174560545 and perplexity is 407.6345317480878
At time: 92.12423348426819 and batch: 700, loss is 5.950634212493896 and perplexity is 383.996797417324
At time: 92.46713876724243 and batch: 750, loss is 5.906955280303955 and perplexity is 367.5852557944211
At time: 92.81026411056519 and batch: 800, loss is 5.909174537658691 and perplexity is 368.4019279444902
At time: 93.1532027721405 and batch: 850, loss is 5.869676580429077 and perplexity is 354.13442773983064
At time: 93.4968192577362 and batch: 900, loss is 5.82530650138855 and perplexity is 338.7649490945273
At time: 93.84034490585327 and batch: 950, loss is 5.878159141540527 and perplexity is 357.1511714323298
At time: 94.18310499191284 and batch: 1000, loss is 5.9343616771698 and perplexity is 377.798761612313
At time: 94.52712154388428 and batch: 1050, loss is 5.777404899597168 and perplexity is 322.9200920549316
At time: 94.87002944946289 and batch: 1100, loss is 5.881078233718872 and perplexity is 358.195251765319
At time: 95.21320509910583 and batch: 1150, loss is 5.9051780509948735 and perplexity is 366.93255267759093
At time: 95.5567991733551 and batch: 1200, loss is 5.868383893966675 and perplexity is 353.67693871786014
At time: 95.899099111557 and batch: 1250, loss is 5.892541627883912 and perplexity is 362.3250104260221
At time: 96.24487709999084 and batch: 1300, loss is 5.952204208374024 and perplexity is 384.60014430938696
At time: 96.58758902549744 and batch: 1350, loss is 5.893622016906738 and perplexity is 362.71667392635794
At time: 96.93075919151306 and batch: 1400, loss is 5.810562591552735 and perplexity is 333.80686978317596
At time: 97.27303671836853 and batch: 1450, loss is 5.841320791244507 and perplexity is 344.23370139994717
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.922189044137286 and perplexity of 373.2278324890345
Finished 9 epochs...
Completing Train Step...
At time: 98.50657272338867 and batch: 50, loss is 5.914677734375 and perplexity is 370.4349050302949
At time: 98.864981174469 and batch: 100, loss is 5.918305692672729 and perplexity is 371.7812682157684
At time: 99.20839548110962 and batch: 150, loss is 5.924871587753296 and perplexity is 374.230376511233
At time: 99.55118799209595 and batch: 200, loss is 5.829090003967285 and perplexity is 340.0490949056385
At time: 99.89386510848999 and batch: 250, loss is 5.82384202003479 and perplexity is 338.2691972415468
At time: 100.23651909828186 and batch: 300, loss is 5.90236538887024 and perplexity is 365.901945438786
At time: 100.58040428161621 and batch: 350, loss is 5.930108413696289 and perplexity is 376.1952963366104
At time: 100.93699336051941 and batch: 400, loss is 5.838649845123291 and perplexity is 343.3154985114908
At time: 101.2796061038971 and batch: 450, loss is 5.860474376678467 and perplexity is 350.8905588429466
At time: 101.6230981349945 and batch: 500, loss is 5.84772289276123 and perplexity is 346.4445901173408
At time: 101.96585512161255 and batch: 550, loss is 5.904604110717774 and perplexity is 366.7220157302265
At time: 102.30863690376282 and batch: 600, loss is 5.730411434173584 and perplexity is 308.09600352863345
At time: 102.65153074264526 and batch: 650, loss is 5.913942642211914 and perplexity is 370.1627012943476
At time: 102.99500274658203 and batch: 700, loss is 5.860484638214111 and perplexity is 350.8941595373977
At time: 103.33795046806335 and batch: 750, loss is 5.810636920928955 and perplexity is 333.8316823617253
At time: 103.68125462532043 and batch: 800, loss is 5.807667064666748 and perplexity is 332.84172099844255
At time: 104.02238202095032 and batch: 850, loss is 5.761486387252807 and perplexity is 317.82038216871024
At time: 104.36739683151245 and batch: 900, loss is 5.7217716789245605 and perplexity is 305.4455953904599
At time: 104.71150875091553 and batch: 950, loss is 5.769146318435669 and perplexity is 320.26421226058994
At time: 105.0541775226593 and batch: 1000, loss is 5.824346103668213 and perplexity is 338.43975619194356
At time: 105.3970787525177 and batch: 1050, loss is 5.676074981689453 and perplexity is 291.801851652179
At time: 105.74070382118225 and batch: 1100, loss is 5.779311351776123 and perplexity is 323.53631097737133
At time: 106.08338594436646 and batch: 1150, loss is 5.799930238723755 and perplexity is 330.2765185945114
At time: 106.42560338973999 and batch: 1200, loss is 5.771193971633911 and perplexity is 320.9206741729027
At time: 106.76769685745239 and batch: 1250, loss is 5.791011095046997 and perplexity is 327.34383283643655
At time: 107.1092803478241 and batch: 1300, loss is 5.846560220718384 and perplexity is 346.04202275027706
At time: 107.45225143432617 and batch: 1350, loss is 5.793678684234619 and perplexity is 328.2182174364859
At time: 107.79407525062561 and batch: 1400, loss is 5.7089669895172115 and perplexity is 301.55939331427436
At time: 108.13708686828613 and batch: 1450, loss is 5.749841632843018 and perplexity is 314.1409067438419
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.82511706229968 and perplexity of 338.7007798495033
Finished 10 epochs...
Completing Train Step...
At time: 109.373690366745 and batch: 50, loss is 5.813252973556518 and perplexity is 334.7061469354879
At time: 109.73524832725525 and batch: 100, loss is 5.80753812789917 and perplexity is 332.7988082293981
At time: 110.07484841346741 and batch: 150, loss is 5.80621452331543 and perplexity is 332.3586055927434
At time: 110.41520500183105 and batch: 200, loss is 5.727866821289062 and perplexity is 307.3130150921078
At time: 110.75503659248352 and batch: 250, loss is 5.718754434585572 and perplexity is 304.5253803518252
At time: 111.09238266944885 and batch: 300, loss is 5.789087419509888 and perplexity is 326.7147347972392
At time: 111.42980313301086 and batch: 350, loss is 5.8217736434936525 and perplexity is 337.5702522592699
At time: 111.77285957336426 and batch: 400, loss is 5.733438949584961 and perplexity is 309.03018233432056
At time: 112.1132287979126 and batch: 450, loss is 5.755692863464356 and perplexity is 315.98440574606457
At time: 112.45452237129211 and batch: 500, loss is 5.747862396240234 and perplexity is 313.5197624613039
At time: 112.79897618293762 and batch: 550, loss is 5.817724590301514 and perplexity is 336.20617582445954
At time: 113.14201664924622 and batch: 600, loss is 5.645840902328491 and perplexity is 283.1115252952283
At time: 113.48734045028687 and batch: 650, loss is 5.821040525436401 and perplexity is 337.32286410518935
At time: 113.8313238620758 and batch: 700, loss is 5.783771629333496 and perplexity is 324.9825957422508
At time: 114.17649865150452 and batch: 750, loss is 5.730632820129395 and perplexity is 308.164219207574
At time: 114.52479791641235 and batch: 800, loss is 5.703457317352295 and perplexity is 299.9024686662002
At time: 114.8692057132721 and batch: 850, loss is 5.63675537109375 and perplexity is 280.5509563676187
At time: 115.21216225624084 and batch: 900, loss is 5.592968692779541 and perplexity is 268.53162547839133
At time: 115.55550217628479 and batch: 950, loss is 5.627522792816162 and perplexity is 277.9726681405641
At time: 115.90011692047119 and batch: 1000, loss is 5.685727052688598 and perplexity is 294.63198017092714
At time: 116.24410390853882 and batch: 1050, loss is 5.545269222259521 and perplexity is 256.02349618986705
At time: 116.58608102798462 and batch: 1100, loss is 5.642096395492554 and perplexity is 282.05339457864505
At time: 116.92809271812439 and batch: 1150, loss is 5.651260976791382 and perplexity is 284.65017687993986
At time: 117.27278351783752 and batch: 1200, loss is 5.615491876602173 and perplexity is 274.648439117275
At time: 117.6188576221466 and batch: 1250, loss is 5.633600578308106 and perplexity is 279.6672708896723
At time: 117.96282148361206 and batch: 1300, loss is 5.6874789619445805 and perplexity is 295.1486010684292
At time: 118.3064489364624 and batch: 1350, loss is 5.63025839805603 and perplexity is 278.73413268639985
At time: 118.64946055412292 and batch: 1400, loss is 5.532913913726807 and perplexity is 252.87970813098957
At time: 118.996572971344 and batch: 1450, loss is 5.582764263153076 and perplexity is 265.8053471188744
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.669534797342415 and perplexity of 289.89964093437436
Finished 11 epochs...
Completing Train Step...
At time: 120.27056407928467 and batch: 50, loss is 5.646680727005005 and perplexity is 283.3493892083881
At time: 120.61604499816895 and batch: 100, loss is 5.646596164703369 and perplexity is 283.325429544926
At time: 120.95907664299011 and batch: 150, loss is 5.6350232696533205 and perplexity is 280.0654342601389
At time: 121.30439138412476 and batch: 200, loss is 5.576919412612915 and perplexity is 264.25628601744864
At time: 121.64886140823364 and batch: 250, loss is 5.578619461059571 and perplexity is 264.70591659460166
At time: 121.99064707756042 and batch: 300, loss is 5.643455305099487 and perplexity is 282.43694018909116
At time: 122.33555555343628 and batch: 350, loss is 5.678820991516114 and perplexity is 292.6042435881164
At time: 122.6784873008728 and batch: 400, loss is 5.593398780822754 and perplexity is 268.647142559211
At time: 123.02319884300232 and batch: 450, loss is 5.612296657562256 and perplexity is 273.7722777045633
At time: 123.36916589736938 and batch: 500, loss is 5.607382926940918 and perplexity is 272.43033415496194
At time: 123.7118911743164 and batch: 550, loss is 5.682770853042602 and perplexity is 293.76227535934567
At time: 124.05625820159912 and batch: 600, loss is 5.5120894145965575 and perplexity is 247.6680681040826
At time: 124.40067887306213 and batch: 650, loss is 5.67820556640625 and perplexity is 292.4242229896398
At time: 124.74836754798889 and batch: 700, loss is 5.65431655883789 and perplexity is 285.5212790342418
At time: 125.09676194190979 and batch: 750, loss is 5.600496692657471 and perplexity is 270.56075960021445
At time: 125.43902349472046 and batch: 800, loss is 5.580479154586792 and perplexity is 265.19864649560634
At time: 125.7837975025177 and batch: 850, loss is 5.542062520980835 and perplexity is 255.2038202475966
At time: 126.12843704223633 and batch: 900, loss is 5.511158790588379 and perplexity is 247.43768946841718
At time: 126.47234797477722 and batch: 950, loss is 5.549093971252441 and perplexity is 257.0045968349161
At time: 126.8177444934845 and batch: 1000, loss is 5.611494636535644 and perplexity is 273.552794608135
At time: 127.16187953948975 and batch: 1050, loss is 5.479746551513672 and perplexity is 239.7859262920824
At time: 127.5327250957489 and batch: 1100, loss is 5.575399017333984 and perplexity is 263.8548172806823
At time: 127.87579774856567 and batch: 1150, loss is 5.583799295425415 and perplexity is 266.0806066579821
At time: 128.2189700603485 and batch: 1200, loss is 5.559452304840088 and perplexity is 259.68057157547514
At time: 128.5622034072876 and batch: 1250, loss is 5.577848281860351 and perplexity is 264.5018595901853
At time: 128.90688061714172 and batch: 1300, loss is 5.6391261959075925 and perplexity is 281.2168826218457
At time: 129.24919962882996 and batch: 1350, loss is 5.588801965713501 and perplexity is 267.41505532342035
At time: 129.59176015853882 and batch: 1400, loss is 5.4996192932128904 and perplexity is 244.59879411514413
At time: 129.93372988700867 and batch: 1450, loss is 5.550401430130005 and perplexity is 257.3408395404788
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.638020833333333 and perplexity of 280.9062077403715
Finished 12 epochs...
Completing Train Step...
At time: 131.21482014656067 and batch: 50, loss is 5.615350494384765 and perplexity is 274.60961145678027
At time: 131.55684971809387 and batch: 100, loss is 5.616665563583374 and perplexity is 274.97097965846524
At time: 131.9012758731842 and batch: 150, loss is 5.6085577392578125 and perplexity is 272.75057674265827
At time: 132.247624874115 and batch: 200, loss is 5.547826375961304 and perplexity is 256.6790254081651
At time: 132.58986687660217 and batch: 250, loss is 5.550393342971802 and perplexity is 257.33875839281245
At time: 132.933265209198 and batch: 300, loss is 5.613884439468384 and perplexity is 274.2073136532103
At time: 133.2778239250183 and batch: 350, loss is 5.652667694091797 and perplexity is 285.05088098094075
At time: 133.6235065460205 and batch: 400, loss is 5.564289875030518 and perplexity is 260.9398380066497
At time: 133.9686563014984 and batch: 450, loss is 5.584067897796631 and perplexity is 266.1520861392144
At time: 134.3142340183258 and batch: 500, loss is 5.583450212478637 and perplexity is 265.98773866598884
At time: 134.65702748298645 and batch: 550, loss is 5.664550981521606 and perplexity is 288.4584288683049
At time: 135.00005340576172 and batch: 600, loss is 5.493761262893677 and perplexity is 243.1701156696033
At time: 135.34379363059998 and batch: 650, loss is 5.656933393478393 and perplexity is 286.26941946078364
At time: 135.6871497631073 and batch: 700, loss is 5.636258525848389 and perplexity is 280.4116005808625
At time: 136.0309283733368 and batch: 750, loss is 5.579536685943603 and perplexity is 264.9488228310454
At time: 136.401025056839 and batch: 800, loss is 5.563960132598877 and perplexity is 260.8538092543978
At time: 136.7434949874878 and batch: 850, loss is 5.523123521804809 and perplexity is 250.41599670869803
At time: 137.08554029464722 and batch: 900, loss is 5.490653495788575 and perplexity is 242.41557266244482
At time: 137.42943143844604 and batch: 950, loss is 5.530562314987183 and perplexity is 252.28573519479963
At time: 137.77468585968018 and batch: 1000, loss is 5.593892326354981 and perplexity is 268.77976488105173
At time: 138.11741518974304 and batch: 1050, loss is 5.4599912643432615 and perplexity is 235.09537064380953
At time: 138.46133470535278 and batch: 1100, loss is 5.558758001327515 and perplexity is 259.5003370184667
At time: 138.80521774291992 and batch: 1150, loss is 5.568999433517456 and perplexity is 262.17164779865624
At time: 139.14914226531982 and batch: 1200, loss is 5.541777276992798 and perplexity is 255.13103527337864
At time: 139.49467611312866 and batch: 1250, loss is 5.557968101501465 and perplexity is 259.2954386826295
At time: 139.8380196094513 and batch: 1300, loss is 5.619629602432251 and perplexity is 275.7872134011615
At time: 140.1794490814209 and batch: 1350, loss is 5.5699771213531495 and perplexity is 262.4280951718836
At time: 140.52341723442078 and batch: 1400, loss is 5.485919713973999 and perplexity is 241.27074205999415
At time: 140.86698651313782 and batch: 1450, loss is 5.5268638134002686 and perplexity is 251.35437937497574
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.625873793903579 and perplexity of 277.5146692367021
Finished 13 epochs...
Completing Train Step...
At time: 142.11733388900757 and batch: 50, loss is 5.598628082275391 and perplexity is 270.0556590209071
At time: 142.47545790672302 and batch: 100, loss is 5.600123329162598 and perplexity is 270.4597609452133
At time: 142.81890535354614 and batch: 150, loss is 5.596247262954712 and perplexity is 269.4134700615359
At time: 143.16206097602844 and batch: 200, loss is 5.5309235382080075 and perplexity is 252.37688312201766
At time: 143.5051829814911 and batch: 250, loss is 5.5314545249938964 and perplexity is 252.51092749676567
At time: 143.84753155708313 and batch: 300, loss is 5.599436368942261 and perplexity is 270.2740296505517
At time: 144.18984079360962 and batch: 350, loss is 5.637027072906494 and perplexity is 280.6271929273675
At time: 144.5322551727295 and batch: 400, loss is 5.551254425048828 and perplexity is 257.5604436162775
At time: 144.87364673614502 and batch: 450, loss is 5.5670046043395995 and perplexity is 261.6491814348502
At time: 145.23197841644287 and batch: 500, loss is 5.562709999084473 and perplexity is 260.52791091575045
At time: 145.57446575164795 and batch: 550, loss is 5.643796405792236 and perplexity is 282.5332960576401
At time: 145.9174144268036 and batch: 600, loss is 5.473731956481934 and perplexity is 238.34803953905498
At time: 146.2595465183258 and batch: 650, loss is 5.639841766357422 and perplexity is 281.4181851275156
At time: 146.60240483283997 and batch: 700, loss is 5.624575424194336 and perplexity is 277.15458640719845
At time: 146.94489979743958 and batch: 750, loss is 5.565517520904541 and perplexity is 261.2603764357294
At time: 147.2895724773407 and batch: 800, loss is 5.549911975860596 and perplexity is 257.2149137878348
At time: 147.63283824920654 and batch: 850, loss is 5.5062229347229 and perplexity is 246.21938186631075
At time: 147.9763433933258 and batch: 900, loss is 5.473093585968018 and perplexity is 238.19593373365964
At time: 148.31938004493713 and batch: 950, loss is 5.515805625915528 and perplexity is 248.59016727861365
At time: 148.66477227210999 and batch: 1000, loss is 5.576097145080566 and perplexity is 264.0390859637514
At time: 149.00871896743774 and batch: 1050, loss is 5.446995153427124 and perplexity is 232.0598130775378
At time: 149.35138726234436 and batch: 1100, loss is 5.546319742202758 and perplexity is 256.29259530079514
At time: 149.69356894493103 and batch: 1150, loss is 5.555194673538208 and perplexity is 258.57729777859686
At time: 150.03796672821045 and batch: 1200, loss is 5.5279120922088625 and perplexity is 251.61800699780554
At time: 150.38064789772034 and batch: 1250, loss is 5.54820538520813 and perplexity is 256.77632757030597
At time: 150.72401189804077 and batch: 1300, loss is 5.609385709762574 and perplexity is 272.9764996912201
At time: 151.06774520874023 and batch: 1350, loss is 5.56127368927002 and perplexity is 260.1539807244494
At time: 151.41101574897766 and batch: 1400, loss is 5.469007997512818 and perplexity is 237.2247484593152
At time: 151.75489401817322 and batch: 1450, loss is 5.517439336776733 and perplexity is 248.99662366058547
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.619509444277511 and perplexity of 275.75407730932386
Finished 14 epochs...
Completing Train Step...
At time: 153.0005383491516 and batch: 50, loss is 5.586651983261109 and perplexity is 266.84073525723085
At time: 153.3587737083435 and batch: 100, loss is 5.588138952255249 and perplexity is 267.2378143058843
At time: 153.70174479484558 and batch: 150, loss is 5.581696176528931 and perplexity is 265.52159554559597
At time: 154.0614790916443 and batch: 200, loss is 5.52418251991272 and perplexity is 250.68132724287307
At time: 154.4033498764038 and batch: 250, loss is 5.521892747879028 and perplexity is 250.1079808171965
At time: 154.7473659515381 and batch: 300, loss is 5.587916202545166 and perplexity is 267.1782937895596
At time: 155.09148478507996 and batch: 350, loss is 5.624350957870483 and perplexity is 277.09238151776134
At time: 155.4349765777588 and batch: 400, loss is 5.54037636756897 and perplexity is 254.77387003823785
At time: 155.78114891052246 and batch: 450, loss is 5.557951469421386 and perplexity is 259.29112609599304
At time: 156.12483644485474 and batch: 500, loss is 5.554169445037842 and perplexity is 258.31233281139333
At time: 156.46760177612305 and batch: 550, loss is 5.634355039596557 and perplexity is 279.8783486341867
At time: 156.810467004776 and batch: 600, loss is 5.465247468948364 and perplexity is 236.334333281716
At time: 157.15523767471313 and batch: 650, loss is 5.6293910694122316 and perplexity is 278.4924833989395
At time: 157.49953722953796 and batch: 700, loss is 5.613838348388672 and perplexity is 274.1946754333159
At time: 157.84327578544617 and batch: 750, loss is 5.559172611236573 and perplexity is 259.6079507369138
At time: 158.18686747550964 and batch: 800, loss is 5.546083602905274 and perplexity is 256.23208169249193
At time: 158.53092432022095 and batch: 850, loss is 5.50081579208374 and perplexity is 244.8916314509492
At time: 158.87369298934937 and batch: 900, loss is 5.467070875167846 and perplexity is 236.76565989720908
At time: 159.21632838249207 and batch: 950, loss is 5.509315223693847 and perplexity is 246.98194176542324
At time: 159.55986332893372 and batch: 1000, loss is 5.569938745498657 and perplexity is 262.4180244627259
At time: 159.90410947799683 and batch: 1050, loss is 5.441137380599976 and perplexity is 230.70443304004704
At time: 160.2467062473297 and batch: 1100, loss is 5.543071603775024 and perplexity is 255.46147200573503
At time: 160.5904507637024 and batch: 1150, loss is 5.54711835861206 and perplexity is 256.4973565249389
At time: 160.93208193778992 and batch: 1200, loss is 5.521308727264405 and perplexity is 249.96195524563993
At time: 161.27550888061523 and batch: 1250, loss is 5.540741014480591 and perplexity is 254.86678948347367
At time: 161.62004280090332 and batch: 1300, loss is 5.602473373413086 and perplexity is 271.09610077192673
At time: 161.96212005615234 and batch: 1350, loss is 5.55410101890564 and perplexity is 258.2946581022718
At time: 162.30410957336426 and batch: 1400, loss is 5.4640450859069825 and perplexity is 236.05033965605617
At time: 162.6479458808899 and batch: 1450, loss is 5.516203832626343 and perplexity is 248.68917726337853
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.609445425180288 and perplexity of 272.99280108364286
Finished 15 epochs...
Completing Train Step...
At time: 163.89430403709412 and batch: 50, loss is 5.579140787124634 and perplexity is 264.8439506657521
At time: 164.2364203929901 and batch: 100, loss is 5.584111061096191 and perplexity is 266.16357438937064
At time: 164.57988810539246 and batch: 150, loss is 5.577853593826294 and perplexity is 264.50326461878694
At time: 164.9221978187561 and batch: 200, loss is 5.519083795547485 and perplexity is 249.40642520076992
At time: 165.2648003101349 and batch: 250, loss is 5.517809000015259 and perplexity is 249.0886855737739
At time: 165.60861539840698 and batch: 300, loss is 5.579144306182862 and perplexity is 264.8448826686757
At time: 165.95254230499268 and batch: 350, loss is 5.6173726844787595 and perplexity is 275.16548614550226
At time: 166.29607367515564 and batch: 400, loss is 5.532971935272217 and perplexity is 252.89438102812613
At time: 166.64055347442627 and batch: 450, loss is 5.553479347229004 and perplexity is 258.13413353106284
At time: 166.9834063053131 and batch: 500, loss is 5.550634346008301 and perplexity is 257.40078528902893
At time: 167.32610249519348 and batch: 550, loss is 5.630661125183106 and perplexity is 278.84640908973364
At time: 167.67092561721802 and batch: 600, loss is 5.460986471176147 and perplexity is 235.32945562521996
At time: 168.0150260925293 and batch: 650, loss is 5.625717115402222 and perplexity is 277.4711920602799
At time: 168.3579752445221 and batch: 700, loss is 5.608205366134643 and perplexity is 272.65448370138205
At time: 168.70196318626404 and batch: 750, loss is 5.552585735321045 and perplexity is 257.90356483030024
At time: 169.05094861984253 and batch: 800, loss is 5.535402269363403 and perplexity is 253.50974633255805
At time: 169.3989007472992 and batch: 850, loss is 5.496420679092407 and perplexity is 243.8176668867101
At time: 169.74399638175964 and batch: 900, loss is 5.456447534561157 and perplexity is 234.26373060132997
At time: 170.08687925338745 and batch: 950, loss is 5.499637451171875 and perplexity is 244.60323557033908
At time: 170.43166851997375 and batch: 1000, loss is 5.563076791763305 and perplexity is 260.62348817355354
At time: 170.7759439945221 and batch: 1050, loss is 5.432783288955688 and perplexity is 228.7851352210621
At time: 171.11891198158264 and batch: 1100, loss is 5.531431865692139 and perplexity is 252.50520584028706
At time: 171.46259355545044 and batch: 1150, loss is 5.543645658493042 and perplexity is 255.60816296930324
At time: 171.82302045822144 and batch: 1200, loss is 5.515794992446899 and perplexity is 248.58752391692266
At time: 172.16785550117493 and batch: 1250, loss is 5.5330451965332035 and perplexity is 252.9129090680622
At time: 172.51141119003296 and batch: 1300, loss is 5.593176736831665 and perplexity is 268.5874976976191
At time: 172.8540449142456 and batch: 1350, loss is 5.547517290115357 and perplexity is 256.5997018139916
At time: 173.19847083091736 and batch: 1400, loss is 5.4567599201202395 and perplexity is 234.33692263925926
At time: 173.5409550666809 and batch: 1450, loss is 5.5068381690979 and perplexity is 246.37091110204383
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.607721312433227 and perplexity of 272.52253622674664
Finished 16 epochs...
Completing Train Step...
At time: 174.79959750175476 and batch: 50, loss is 5.574857158660889 and perplexity is 263.7118839878202
At time: 175.14440155029297 and batch: 100, loss is 5.5762779712677 and perplexity is 264.0868354619704
At time: 175.4875795841217 and batch: 150, loss is 5.57242748260498 and perplexity is 263.07192729618447
At time: 175.82926297187805 and batch: 200, loss is 5.507713756561279 and perplexity is 246.58672485126482
At time: 176.17469334602356 and batch: 250, loss is 5.509721136093139 and perplexity is 247.0822151477148
At time: 176.51623344421387 and batch: 300, loss is 5.571882925033569 and perplexity is 262.9287084853328
At time: 176.85879683494568 and batch: 350, loss is 5.613876686096192 and perplexity is 274.20518763009164
At time: 177.20304107666016 and batch: 400, loss is 5.529523782730102 and perplexity is 252.023864325008
At time: 177.54595828056335 and batch: 450, loss is 5.547783994674683 and perplexity is 256.66814725133656
At time: 177.89026260375977 and batch: 500, loss is 5.546004304885864 and perplexity is 256.21176380149944
At time: 178.2311246395111 and batch: 550, loss is 5.6244111824035645 and perplexity is 277.109069779575
At time: 178.57284498214722 and batch: 600, loss is 5.4582260227203365 and perplexity is 234.68073658251308
At time: 178.91598081588745 and batch: 650, loss is 5.621267280578613 and perplexity is 276.2392341247988
At time: 179.25809407234192 and batch: 700, loss is 5.603849782943725 and perplexity is 271.4694969428225
At time: 179.60297346115112 and batch: 750, loss is 5.547979707717896 and perplexity is 256.718385471508
At time: 179.94713926315308 and batch: 800, loss is 5.532773265838623 and perplexity is 252.8441436351706
At time: 180.29262351989746 and batch: 850, loss is 5.49169768333435 and perplexity is 242.66883218653015
At time: 180.6521508693695 and batch: 900, loss is 5.455807580947876 and perplexity is 234.1138606404972
At time: 180.9935486316681 and batch: 950, loss is 5.499064912796021 and perplexity is 244.4632309139607
At time: 181.33525609970093 and batch: 1000, loss is 5.563481178283691 and perplexity is 260.7289021116182
At time: 181.67994260787964 and batch: 1050, loss is 5.4301167011260985 and perplexity is 228.17587225152363
At time: 182.02289056777954 and batch: 1100, loss is 5.528969898223877 and perplexity is 251.8843108631772
At time: 182.36438870429993 and batch: 1150, loss is 5.541838817596435 and perplexity is 255.1467366744278
At time: 182.70627760887146 and batch: 1200, loss is 5.513174934387207 and perplexity is 247.93706266656787
At time: 183.05018043518066 and batch: 1250, loss is 5.53070894241333 and perplexity is 252.32272991495896
At time: 183.39492678642273 and batch: 1300, loss is 5.591905136108398 and perplexity is 268.2461786980216
At time: 183.73711824417114 and batch: 1350, loss is 5.54496434211731 and perplexity is 255.94545160766538
At time: 184.07951045036316 and batch: 1400, loss is 5.452789134979248 and perplexity is 233.40826603696394
At time: 184.42263674736023 and batch: 1450, loss is 5.5059341621398925 and perplexity is 246.14829072450303
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.6114152435563565 and perplexity of 273.5310772988909
Annealing...
Finished 17 epochs...
Completing Train Step...
At time: 185.66326475143433 and batch: 50, loss is 5.554070663452149 and perplexity is 258.2868175697928
At time: 186.02290773391724 and batch: 100, loss is 5.536597938537597 and perplexity is 253.8130414057574
At time: 186.3666365146637 and batch: 150, loss is 5.526492366790771 and perplexity is 251.26103198083442
At time: 186.71098852157593 and batch: 200, loss is 5.4589644718170165 and perplexity is 234.85410036273603
At time: 187.053884267807 and batch: 250, loss is 5.457332000732422 and perplexity is 234.47102060318514
At time: 187.39829564094543 and batch: 300, loss is 5.5096179866790775 and perplexity is 247.05673007640493
At time: 187.74212765693665 and batch: 350, loss is 5.547568626403809 and perplexity is 256.61287502842976
At time: 188.08474373817444 and batch: 400, loss is 5.468084735870361 and perplexity is 237.0058290239309
At time: 188.4296591281891 and batch: 450, loss is 5.49373875617981 and perplexity is 243.16464277097768
At time: 188.77289080619812 and batch: 500, loss is 5.482929697036743 and perplexity is 240.55041588515707
At time: 189.1173117160797 and batch: 550, loss is 5.551523170471191 and perplexity is 257.6296711083503
At time: 189.47536993026733 and batch: 600, loss is 5.394930458068847 and perplexity is 220.28682739243595
At time: 189.82061529159546 and batch: 650, loss is 5.55615761756897 and perplexity is 258.82641316682185
At time: 190.166175365448 and batch: 700, loss is 5.540257120132447 and perplexity is 254.7434907187066
At time: 190.5101137161255 and batch: 750, loss is 5.483723430633545 and perplexity is 240.74142462696943
At time: 190.8535463809967 and batch: 800, loss is 5.4605471134185795 and perplexity is 235.22608451341966
At time: 191.19669365882874 and batch: 850, loss is 5.419105901718139 and perplexity is 225.677254625005
At time: 191.5396056175232 and batch: 900, loss is 5.380193433761597 and perplexity is 217.064258920415
At time: 191.88382482528687 and batch: 950, loss is 5.427028732299805 and perplexity is 227.4723590435582
At time: 192.2278118133545 and batch: 1000, loss is 5.487017621994019 and perplexity is 241.5357806100496
At time: 192.5713713169098 and batch: 1050, loss is 5.363275718688965 and perplexity is 213.42291608420848
At time: 192.91436171531677 and batch: 1100, loss is 5.457988367080689 and perplexity is 234.6249700088304
At time: 193.25878238677979 and batch: 1150, loss is 5.46668249130249 and perplexity is 236.67372178982896
At time: 193.6005415916443 and batch: 1200, loss is 5.436078329086303 and perplexity is 229.54023478138615
At time: 193.94462752342224 and batch: 1250, loss is 5.455891799926758 and perplexity is 234.1335783010715
At time: 194.28699898719788 and batch: 1300, loss is 5.513569231033325 and perplexity is 248.03484269472747
At time: 194.6285696029663 and batch: 1350, loss is 5.4596546459198 and perplexity is 235.01624652884485
At time: 194.97161078453064 and batch: 1400, loss is 5.371866312026977 and perplexity is 215.26424328801914
At time: 195.31459283828735 and batch: 1450, loss is 5.427775411605835 and perplexity is 227.64227137386615
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.537519927717682 and perplexity of 254.04716219553052
Finished 18 epochs...
Completing Train Step...
At time: 196.54995369911194 and batch: 50, loss is 5.509404048919678 and perplexity is 247.00388096653947
At time: 196.90727877616882 and batch: 100, loss is 5.510805702209472 and perplexity is 247.3503375181492
At time: 197.25064373016357 and batch: 150, loss is 5.508679189682007 and perplexity is 246.82490279650676
At time: 197.59399366378784 and batch: 200, loss is 5.440779609680176 and perplexity is 230.62190846616292
At time: 197.9381844997406 and batch: 250, loss is 5.441839113235473 and perplexity is 230.86638268589533
At time: 198.29723620414734 and batch: 300, loss is 5.496898202896118 and perplexity is 243.93412342958663
At time: 198.64046144485474 and batch: 350, loss is 5.533477735519409 and perplexity is 253.0223274234952
At time: 198.98465490341187 and batch: 400, loss is 5.458525724411011 and perplexity is 234.75108133672992
At time: 199.33037304878235 and batch: 450, loss is 5.486971235275268 and perplexity is 241.52457681758185
At time: 199.67359614372253 and batch: 500, loss is 5.475258922576904 and perplexity is 238.71226692489816
At time: 200.01585006713867 and batch: 550, loss is 5.543451538085938 and perplexity is 255.55854902434385
At time: 200.35813879966736 and batch: 600, loss is 5.385710458755494 and perplexity is 218.26511739934944
At time: 200.7018265724182 and batch: 650, loss is 5.547151203155518 and perplexity is 256.50578120186356
At time: 201.04394507408142 and batch: 700, loss is 5.532885484695434 and perplexity is 252.8725191080226
At time: 201.38819766044617 and batch: 750, loss is 5.479014291763305 and perplexity is 239.61040498099308
At time: 201.73105669021606 and batch: 800, loss is 5.452178440093994 and perplexity is 233.2657683184617
At time: 202.07494020462036 and batch: 850, loss is 5.412328014373779 and perplexity is 224.15281170420255
At time: 202.41734623908997 and batch: 900, loss is 5.3762804126739505 and perplexity is 216.21654154753168
At time: 202.7594027519226 and batch: 950, loss is 5.421367654800415 and perplexity is 226.1882585157272
At time: 203.1021637916565 and batch: 1000, loss is 5.484466056823731 and perplexity is 240.92027191408033
At time: 203.44501543045044 and batch: 1050, loss is 5.3604538536071775 and perplexity is 212.821514346016
At time: 203.78843998908997 and batch: 1100, loss is 5.4544549083709715 and perplexity is 233.79739532656512
At time: 204.13191485404968 and batch: 1150, loss is 5.4648654079437256 and perplexity is 236.24405639564878
At time: 204.4753212928772 and batch: 1200, loss is 5.434902648925782 and perplexity is 229.27052745715366
At time: 204.81922245025635 and batch: 1250, loss is 5.456097793579102 and perplexity is 234.1818132998833
At time: 205.16287326812744 and batch: 1300, loss is 5.513714809417724 and perplexity is 248.07095383483855
At time: 205.5054907798767 and batch: 1350, loss is 5.461281747817993 and perplexity is 235.39895317660122
At time: 205.84753155708313 and batch: 1400, loss is 5.372720079421997 and perplexity is 215.44810735765745
At time: 206.19204688072205 and batch: 1450, loss is 5.4290297317504885 and perplexity is 227.92798681248004
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.536093687399839 and perplexity of 253.68508815384837
Finished 19 epochs...
Completing Train Step...
At time: 207.44311261177063 and batch: 50, loss is 5.505394115447998 and perplexity is 246.0153950425483
At time: 207.78642177581787 and batch: 100, loss is 5.506964454650879 and perplexity is 246.40202615343955
At time: 208.13075852394104 and batch: 150, loss is 5.504791879653931 and perplexity is 245.86728037021751
At time: 208.47335934638977 and batch: 200, loss is 5.436549263000488 and perplexity is 229.6483585201842
At time: 208.81649327278137 and batch: 250, loss is 5.437254610061646 and perplexity is 229.81039745509125
At time: 209.15985560417175 and batch: 300, loss is 5.493140964508057 and perplexity is 243.01932441204426
At time: 209.50421476364136 and batch: 350, loss is 5.53003755569458 and perplexity is 252.15338064104333
At time: 209.84592080116272 and batch: 400, loss is 5.455193290710449 and perplexity is 233.9700909441409
At time: 210.18945932388306 and batch: 450, loss is 5.483051424026489 and perplexity is 240.57969914541027
At time: 210.53193736076355 and batch: 500, loss is 5.471759777069092 and perplexity is 237.8784376641693
At time: 210.8748755455017 and batch: 550, loss is 5.540398817062378 and perplexity is 254.77958964675477
At time: 211.21768808364868 and batch: 600, loss is 5.382966680526733 and perplexity is 217.66706715594276
At time: 211.56201267242432 and batch: 650, loss is 5.544308919906616 and perplexity is 255.77775423624982
At time: 211.9048888683319 and batch: 700, loss is 5.530551347732544 and perplexity is 252.2829683280725
At time: 212.2494330406189 and batch: 750, loss is 5.4761169910430905 and perplexity is 238.9171862984914
At time: 212.59281468391418 and batch: 800, loss is 5.44852686882019 and perplexity is 232.41553502818638
At time: 212.9356813430786 and batch: 850, loss is 5.410527515411377 and perplexity is 223.74958791025168
At time: 213.2782621383667 and batch: 900, loss is 5.375115871429443 and perplexity is 215.96489502197323
At time: 213.62261247634888 and batch: 950, loss is 5.419200801849366 and perplexity is 225.69867244234445
At time: 213.967435836792 and batch: 1000, loss is 5.483296699523926 and perplexity is 240.6387146880288
At time: 214.3114333152771 and batch: 1050, loss is 5.359495964050293 and perplexity is 212.6177524462217
At time: 214.65454363822937 and batch: 1100, loss is 5.453727426528931 and perplexity is 233.6273738180272
At time: 214.99781680107117 and batch: 1150, loss is 5.463251676559448 and perplexity is 235.86312938709378
At time: 215.33994030952454 and batch: 1200, loss is 5.434208879470825 and perplexity is 229.11152173131762
At time: 215.68361282348633 and batch: 1250, loss is 5.455799407958985 and perplexity is 234.11194723833407
At time: 216.02772688865662 and batch: 1300, loss is 5.513139610290527 and perplexity is 247.92830466848085
At time: 216.37028646469116 and batch: 1350, loss is 5.460796995162964 and perplexity is 235.2848705622169
At time: 216.71322560310364 and batch: 1400, loss is 5.372246246337891 and perplexity is 215.3460450986304
At time: 217.05588793754578 and batch: 1450, loss is 5.426685705184936 and perplexity is 227.39434323805648
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.534416003104968 and perplexity of 253.259841480185
Finished 20 epochs...
Completing Train Step...
At time: 218.32257103919983 and batch: 50, loss is 5.503229894638062 and perplexity is 245.48353913943376
At time: 218.66697120666504 and batch: 100, loss is 5.5040283203125 and perplexity is 245.6796177664233
At time: 219.01159691810608 and batch: 150, loss is 5.501416330337524 and perplexity is 245.0387424121257
At time: 219.3547089099884 and batch: 200, loss is 5.434240446090699 and perplexity is 229.11875412178324
At time: 219.69567847251892 and batch: 250, loss is 5.433230676651001 and perplexity is 228.88751377517548
At time: 220.03842544555664 and batch: 300, loss is 5.489233026504516 and perplexity is 242.0714732366913
At time: 220.3837673664093 and batch: 350, loss is 5.526527805328369 and perplexity is 251.2699364621431
At time: 220.72728824615479 and batch: 400, loss is 5.452993631362915 and perplexity is 233.4560020640425
At time: 221.0713050365448 and batch: 450, loss is 5.480243520736694 and perplexity is 239.9051221334427
At time: 221.41542601585388 and batch: 500, loss is 5.470081901550293 and perplexity is 237.47964191553376
At time: 221.75893664360046 and batch: 550, loss is 5.538472270965576 and perplexity is 254.28921753668445
At time: 222.10306525230408 and batch: 600, loss is 5.38036696434021 and perplexity is 217.10192947526377
At time: 222.4452805519104 and batch: 650, loss is 5.541875286102295 and perplexity is 255.1560416643578
At time: 222.78730154037476 and batch: 700, loss is 5.529019832611084 and perplexity is 251.8968888659221
At time: 223.13059949874878 and batch: 750, loss is 5.473886613845825 and perplexity is 238.38490466919725
At time: 223.47468996047974 and batch: 800, loss is 5.4450533485412596 and perplexity is 231.60963541873335
At time: 223.8166241645813 and batch: 850, loss is 5.4078270530700685 and perplexity is 223.14617568690795
At time: 224.1603720188141 and batch: 900, loss is 5.371047897338867 and perplexity is 215.0881399420993
At time: 224.50258111953735 and batch: 950, loss is 5.417219390869141 and perplexity is 225.25191336737765
At time: 224.8611249923706 and batch: 1000, loss is 5.480586061477661 and perplexity is 239.98731348788002
At time: 225.20528984069824 and batch: 1050, loss is 5.358127851486206 and perplexity is 212.32706631876417
At time: 225.54923677444458 and batch: 1100, loss is 5.452695875167847 and perplexity is 233.38649944108388
At time: 225.89233946800232 and batch: 1150, loss is 5.460735845565796 and perplexity is 235.27048342705052
At time: 226.23262524604797 and batch: 1200, loss is 5.432778053283691 and perplexity is 228.78393738027196
At time: 226.5785415172577 and batch: 1250, loss is 5.4537779808044435 and perplexity is 233.63918497920028
At time: 226.92103171348572 and batch: 1300, loss is 5.510596170425415 and perplexity is 247.29851519004382
At time: 227.26598167419434 and batch: 1350, loss is 5.458062782287597 and perplexity is 234.64243032416795
At time: 227.6104006767273 and batch: 1400, loss is 5.370167074203491 and perplexity is 214.8987687458023
At time: 227.95350289344788 and batch: 1450, loss is 5.4242072010040285 and perplexity is 226.83144327074447
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.5332740718482905 and perplexity of 252.97080121460363
Finished 21 epochs...
Completing Train Step...
At time: 229.21589493751526 and batch: 50, loss is 5.499780359268189 and perplexity is 244.63819385093785
At time: 229.57296895980835 and batch: 100, loss is 5.499841232299804 and perplexity is 244.65308617271225
At time: 229.9166669845581 and batch: 150, loss is 5.498694238662719 and perplexity is 244.3726315101827
At time: 230.2603199481964 and batch: 200, loss is 5.430728702545166 and perplexity is 228.31555894900723
At time: 230.60290932655334 and batch: 250, loss is 5.432099828720093 and perplexity is 228.62882310128686
At time: 230.94632768630981 and batch: 300, loss is 5.488310384750366 and perplexity is 241.84823099014
At time: 231.28929233551025 and batch: 350, loss is 5.526745157241821 and perplexity is 251.3245563992851
At time: 231.63175630569458 and batch: 400, loss is 5.453097610473633 and perplexity is 233.48027787359558
At time: 231.97517776489258 and batch: 450, loss is 5.481655158996582 and perplexity is 240.2440205272812
At time: 232.31943249702454 and batch: 500, loss is 5.469157180786133 and perplexity is 237.26014106372835
At time: 232.66187858581543 and batch: 550, loss is 5.53647783279419 and perplexity is 253.7825588323355
At time: 233.00635814666748 and batch: 600, loss is 5.3795304870605465 and perplexity is 216.92040457519826
At time: 233.3494050502777 and batch: 650, loss is 5.541413841247558 and perplexity is 255.03832838295955
At time: 233.7068383693695 and batch: 700, loss is 5.526523017883301 and perplexity is 251.26873352400457
At time: 234.04959225654602 and batch: 750, loss is 5.473052129745484 and perplexity is 238.18605923470523
At time: 234.39291667938232 and batch: 800, loss is 5.443217353820801 and perplexity is 231.18479147585663
At time: 234.73871088027954 and batch: 850, loss is 5.406598529815674 and perplexity is 222.87220374585576
At time: 235.08073163032532 and batch: 900, loss is 5.369715175628662 and perplexity is 214.801678237657
At time: 235.42421460151672 and batch: 950, loss is 5.415568828582764 and perplexity is 224.88042771867825
At time: 235.76900458335876 and batch: 1000, loss is 5.4796223640441895 and perplexity is 239.75614973365475
At time: 236.11233639717102 and batch: 1050, loss is 5.357855653762817 and perplexity is 212.26927923981088
At time: 236.45546126365662 and batch: 1100, loss is 5.452322416305542 and perplexity is 233.29935545788447
At time: 236.79800152778625 and batch: 1150, loss is 5.461180019378662 and perplexity is 235.3750076264668
At time: 237.140789270401 and batch: 1200, loss is 5.431676769256592 and perplexity is 228.53211997107442
At time: 237.4836766719818 and batch: 1250, loss is 5.453024778366089 and perplexity is 233.46327363212296
At time: 237.82727646827698 and batch: 1300, loss is 5.510196514129639 and perplexity is 247.19970052877812
At time: 238.1698501110077 and batch: 1350, loss is 5.455520896911621 and perplexity is 234.04675355371057
At time: 238.512610912323 and batch: 1400, loss is 5.369154930114746 and perplexity is 214.68137026519048
At time: 238.8549463748932 and batch: 1450, loss is 5.4234436511993405 and perplexity is 226.65831227201951
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.531257825020032 and perplexity of 252.46126348854125
Finished 22 epochs...
Completing Train Step...
At time: 240.09382367134094 and batch: 50, loss is 5.497705774307251 and perplexity is 244.13119721873656
At time: 240.4516191482544 and batch: 100, loss is 5.4991218376159665 and perplexity is 244.477147335455
At time: 240.79383897781372 and batch: 150, loss is 5.497858734130859 and perplexity is 244.16854233967914
At time: 241.13774251937866 and batch: 200, loss is 5.429819793701172 and perplexity is 228.1081351971778
At time: 241.48110842704773 and batch: 250, loss is 5.430509986877442 and perplexity is 228.26562821959527
At time: 241.82378554344177 and batch: 300, loss is 5.486886434555053 and perplexity is 241.5040962279148
At time: 242.16824102401733 and batch: 350, loss is 5.525776472091675 and perplexity is 251.0812199108832
At time: 242.51284193992615 and batch: 400, loss is 5.451238527297973 and perplexity is 233.04662184336712
At time: 242.8734495639801 and batch: 450, loss is 5.480135908126831 and perplexity is 239.87930670618803
At time: 243.2180516719818 and batch: 500, loss is 5.4683120059967045 and perplexity is 237.05969948997918
At time: 243.5623767375946 and batch: 550, loss is 5.535438804626465 and perplexity is 253.5190085470268
At time: 243.90560960769653 and batch: 600, loss is 5.378563795089722 and perplexity is 216.71081068447504
At time: 244.25092387199402 and batch: 650, loss is 5.540043239593506 and perplexity is 254.68901186981046
At time: 244.59467387199402 and batch: 700, loss is 5.526052560806274 and perplexity is 251.1505501723595
At time: 244.93800806999207 and batch: 750, loss is 5.4731463527679445 and perplexity is 238.20850290245284
At time: 245.27972602844238 and batch: 800, loss is 5.44123911857605 and perplexity is 230.72790563614276
At time: 245.62293910980225 and batch: 850, loss is 5.405956993103027 and perplexity is 222.7292688988026
At time: 245.965026140213 and batch: 900, loss is 5.369195852279663 and perplexity is 214.6901556713868
At time: 246.310284614563 and batch: 950, loss is 5.414659957885743 and perplexity is 224.67613334024128
At time: 246.6528673171997 and batch: 1000, loss is 5.47896294593811 and perplexity is 239.59810230287226
At time: 246.99528455734253 and batch: 1050, loss is 5.3569370365142825 and perplexity is 212.07437455367645
At time: 247.3398551940918 and batch: 1100, loss is 5.450361461639404 and perplexity is 232.84231426318078
At time: 247.68329095840454 and batch: 1150, loss is 5.45944637298584 and perplexity is 234.9673041025204
At time: 248.0239827632904 and batch: 1200, loss is 5.430541830062866 and perplexity is 228.27289704005128
At time: 248.36811804771423 and batch: 1250, loss is 5.453860359191895 and perplexity is 233.65843259128698
At time: 248.7119927406311 and batch: 1300, loss is 5.508651809692383 and perplexity is 246.81814482574626
At time: 249.05460214614868 and batch: 1350, loss is 5.454588222503662 and perplexity is 233.8285659012413
At time: 249.39857459068298 and batch: 1400, loss is 5.368272924423218 and perplexity is 214.49210355417947
At time: 249.7419285774231 and batch: 1450, loss is 5.421975946426391 and perplexity is 226.32588879470578
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.530794062166133 and perplexity of 252.34420847746782
Finished 23 epochs...
Completing Train Step...
At time: 250.99426293373108 and batch: 50, loss is 5.495892677307129 and perplexity is 243.68896470379286
At time: 251.3390474319458 and batch: 100, loss is 5.497605628967285 and perplexity is 244.1067498411608
At time: 251.6963448524475 and batch: 150, loss is 5.4953317451477055 and perplexity is 243.55231005717002
At time: 252.03866481781006 and batch: 200, loss is 5.427592153549194 and perplexity is 227.60055791588525
At time: 252.38065838813782 and batch: 250, loss is 5.428772230148315 and perplexity is 227.86930254666615
At time: 252.72587752342224 and batch: 300, loss is 5.484068441390991 and perplexity is 240.824497337894
At time: 253.07051348686218 and batch: 350, loss is 5.5224654006958005 and perplexity is 250.25124687384903
At time: 253.41189980506897 and batch: 400, loss is 5.447683944702148 and perplexity is 232.219708913176
At time: 253.75434517860413 and batch: 450, loss is 5.476363906860351 and perplexity is 238.97618601448576
At time: 254.0975534915924 and batch: 500, loss is 5.465561723709106 and perplexity is 236.40861414202217
At time: 254.4442172050476 and batch: 550, loss is 5.533321323394776 and perplexity is 252.98275475858614
At time: 254.7872679233551 and batch: 600, loss is 5.37532169342041 and perplexity is 216.00934992138667
At time: 255.13038659095764 and batch: 650, loss is 5.538761987686157 and perplexity is 254.3629000478807
At time: 255.47353267669678 and batch: 700, loss is 5.523898334503174 and perplexity is 250.61009738894697
At time: 255.81745529174805 and batch: 750, loss is 5.470580625534057 and perplexity is 237.59810824715788
At time: 256.1607451438904 and batch: 800, loss is 5.439346866607666 and perplexity is 230.29172311630782
At time: 256.5043029785156 and batch: 850, loss is 5.404086399078369 and perplexity is 222.31302229486386
At time: 256.8456699848175 and batch: 900, loss is 5.36778862953186 and perplexity is 214.38825127378584
At time: 257.1896436214447 and batch: 950, loss is 5.412471446990967 and perplexity is 224.184964834484
At time: 257.5341594219208 and batch: 1000, loss is 5.477140712738037 and perplexity is 239.16189624146807
At time: 257.8776979446411 and batch: 1050, loss is 5.3546571445465085 and perplexity is 211.5914186434078
At time: 258.2220094203949 and batch: 1100, loss is 5.448781175613403 and perplexity is 232.47464739361175
At time: 258.5656507015228 and batch: 1150, loss is 5.4590361785888675 and perplexity is 234.870941595937
At time: 258.90884470939636 and batch: 1200, loss is 5.4303957462310795 and perplexity is 228.23955249616725
At time: 259.25198769569397 and batch: 1250, loss is 5.450625171661377 and perplexity is 232.90372521197685
At time: 259.5955259799957 and batch: 1300, loss is 5.507713289260864 and perplexity is 246.58660962121283
At time: 259.9382507801056 and batch: 1350, loss is 5.453411407470703 and perplexity is 233.5535547801028
At time: 260.28153109550476 and batch: 1400, loss is 5.365402336120606 and perplexity is 213.87726792290096
At time: 260.62514758110046 and batch: 1450, loss is 5.419748830795288 and perplexity is 225.8223957467786
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.527517465444712 and perplexity of 251.5187313875967
Finished 24 epochs...
Completing Train Step...
At time: 261.87509274482727 and batch: 50, loss is 5.494383277893067 and perplexity is 243.3214181802905
At time: 262.2170536518097 and batch: 100, loss is 5.495430498123169 and perplexity is 243.57636276008768
At time: 262.5622479915619 and batch: 150, loss is 5.49293249130249 and perplexity is 242.96866667504327
At time: 262.9065945148468 and batch: 200, loss is 5.426594963073731 and perplexity is 227.37370993144393
At time: 263.2504417896271 and batch: 250, loss is 5.4279996776580814 and perplexity is 227.69332953248335
At time: 263.59338092803955 and batch: 300, loss is 5.482121057510376 and perplexity is 240.35597593729727
At time: 263.936518907547 and batch: 350, loss is 5.520145998001099 and perplexity is 249.6714860667946
At time: 264.2807674407959 and batch: 400, loss is 5.446277656555176 and perplexity is 231.89337060566672
At time: 264.62456154823303 and batch: 450, loss is 5.4749218845367436 and perplexity is 238.63182536698554
At time: 264.96814942359924 and batch: 500, loss is 5.464602537155152 and perplexity is 236.18196289588934
At time: 265.3118636608124 and batch: 550, loss is 5.5321431350708 and perplexity is 252.68486894801302
At time: 265.6557343006134 and batch: 600, loss is 5.375047006607056 and perplexity is 215.95002314991586
At time: 265.9980273246765 and batch: 650, loss is 5.537576475143433 and perplexity is 254.06152831475168
At time: 266.34209299087524 and batch: 700, loss is 5.522387599945068 and perplexity is 250.23177789633084
At time: 266.6857554912567 and batch: 750, loss is 5.468806276321411 and perplexity is 237.1769000266085
At time: 267.03038215637207 and batch: 800, loss is 5.437460832595825 and perplexity is 229.85779442462874
At time: 267.37287616729736 and batch: 850, loss is 5.401617078781128 and perplexity is 221.76473746060432
At time: 267.7149176597595 and batch: 900, loss is 5.366037120819092 and perplexity is 214.0130770401469
At time: 268.0576808452606 and batch: 950, loss is 5.410898265838623 and perplexity is 223.8325585453143
At time: 268.40489077568054 and batch: 1000, loss is 5.474501094818115 and perplexity is 238.53143267192186
At time: 268.74749851226807 and batch: 1050, loss is 5.353687944412232 and perplexity is 211.3864435590317
At time: 269.11363196372986 and batch: 1100, loss is 5.447358922958374 and perplexity is 232.14424472286203
At time: 269.45642495155334 and batch: 1150, loss is 5.457785625457763 and perplexity is 234.5774065833379
At time: 269.79975986480713 and batch: 1200, loss is 5.427530918121338 and perplexity is 227.58662112505795
At time: 270.1430902481079 and batch: 1250, loss is 5.449977111816406 and perplexity is 232.7528385569948
At time: 270.48865365982056 and batch: 1300, loss is 5.506179990768433 and perplexity is 246.20880845942054
At time: 270.8322608470917 and batch: 1350, loss is 5.450821304321289 and perplexity is 232.94940971907164
At time: 271.1766564846039 and batch: 1400, loss is 5.364410009384155 and perplexity is 213.66513706059254
At time: 271.5193462371826 and batch: 1450, loss is 5.418788595199585 and perplexity is 225.60565712080114
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.526819473657852 and perplexity of 251.34323463361832
Finished 25 epochs...
Completing Train Step...
At time: 272.764271736145 and batch: 50, loss is 5.494133348464966 and perplexity is 243.2606125962689
At time: 273.1232097148895 and batch: 100, loss is 5.4948600387573245 and perplexity is 243.4374519679011
At time: 273.46556425094604 and batch: 150, loss is 5.489631843566895 and perplexity is 242.16803472443772
At time: 273.8073637485504 and batch: 200, loss is 5.424033975601196 and perplexity is 226.7921537056824
At time: 274.14901518821716 and batch: 250, loss is 5.42654483795166 and perplexity is 227.36231308211455
At time: 274.4919686317444 and batch: 300, loss is 5.480567941665649 and perplexity is 239.98296500227138
At time: 274.8354535102844 and batch: 350, loss is 5.520069036483765 and perplexity is 249.65227170978437
At time: 275.17972230911255 and batch: 400, loss is 5.443255348205566 and perplexity is 231.1935753666441
At time: 275.52288484573364 and batch: 450, loss is 5.472480545043945 and perplexity is 238.04995462848782
At time: 275.86587929725647 and batch: 500, loss is 5.462080192565918 and perplexity is 235.58698128947256
At time: 276.2080702781677 and batch: 550, loss is 5.529969549179077 and perplexity is 252.13623315133063
At time: 276.5505759716034 and batch: 600, loss is 5.3717428398132325 and perplexity is 215.23766577618613
At time: 276.89360547065735 and batch: 650, loss is 5.536114130020142 and perplexity is 253.69027419478982
At time: 277.23723673820496 and batch: 700, loss is 5.521319313049316 and perplexity is 249.96460130313955
At time: 277.5799095630646 and batch: 750, loss is 5.468094415664673 and perplexity is 237.00812320271012
At time: 277.9373970031738 and batch: 800, loss is 5.4343885231018065 and perplexity is 229.15268385412705
At time: 278.2803943157196 and batch: 850, loss is 5.400843772888184 and perplexity is 221.59331177306868
At time: 278.6243233680725 and batch: 900, loss is 5.365332889556885 and perplexity is 213.86241539732006
At time: 278.96769618988037 and batch: 950, loss is 5.410145721435547 and perplexity is 223.66417797103074
At time: 279.31155276298523 and batch: 1000, loss is 5.473350353240967 and perplexity is 238.25710250672554
At time: 279.6553463935852 and batch: 1050, loss is 5.3527015113830565 and perplexity is 211.17802780017925
At time: 279.99784326553345 and batch: 1100, loss is 5.445498733520508 and perplexity is 231.71281384675348
At time: 280.34183144569397 and batch: 1150, loss is 5.455311832427978 and perplexity is 233.99782780452693
At time: 280.68371629714966 and batch: 1200, loss is 5.426597185134888 and perplexity is 227.3742151702943
At time: 281.02759766578674 and batch: 1250, loss is 5.449130764007569 and perplexity is 232.55593203953484
At time: 281.3708658218384 and batch: 1300, loss is 5.504376020431518 and perplexity is 245.76505545124692
At time: 281.7141716480255 and batch: 1350, loss is 5.448820781707764 and perplexity is 232.4838549887701
At time: 282.057820558548 and batch: 1400, loss is 5.362149677276611 and perplexity is 213.18272829842837
At time: 282.40061211586 and batch: 1450, loss is 5.416929388046265 and perplexity is 225.18659914775472
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.527195074619391 and perplexity of 251.43765712570243
Annealing...
Finished 26 epochs...
Completing Train Step...
At time: 283.6388154029846 and batch: 50, loss is 5.487815027236938 and perplexity is 241.7284593191575
At time: 283.99594712257385 and batch: 100, loss is 5.480157976150513 and perplexity is 239.88460042681984
At time: 284.33939957618713 and batch: 150, loss is 5.472536954879761 and perplexity is 238.06338336609724
At time: 284.681587934494 and batch: 200, loss is 5.403613109588623 and perplexity is 222.20782877343564
At time: 285.02560782432556 and batch: 250, loss is 5.410407466888428 and perplexity is 223.7227287149482
At time: 285.369172334671 and batch: 300, loss is 5.4580255794525145 and perplexity is 234.6337011229057
At time: 285.71263360977173 and batch: 350, loss is 5.498235244750976 and perplexity is 244.2604916978372
At time: 286.05529403686523 and batch: 400, loss is 5.422216300964355 and perplexity is 226.38029378711784
At time: 286.39969301223755 and batch: 450, loss is 5.4503673076629635 and perplexity is 232.84367546881444
At time: 286.7443165779114 and batch: 500, loss is 5.432223205566406 and perplexity is 228.65703234460543
At time: 287.105135679245 and batch: 550, loss is 5.503826656341553 and perplexity is 245.63007803448116
At time: 287.4492440223694 and batch: 600, loss is 5.346815948486328 and perplexity is 209.9387766577136
At time: 287.79190373420715 and batch: 650, loss is 5.510134744644165 and perplexity is 247.18443160204885
At time: 288.13431453704834 and batch: 700, loss is 5.4957852268219 and perplexity is 243.66278161300846
At time: 288.47812938690186 and batch: 750, loss is 5.435702056884765 and perplexity is 229.45388141910715
At time: 288.82085943222046 and batch: 800, loss is 5.403110666275024 and perplexity is 222.09620997904585
At time: 289.16463446617126 and batch: 850, loss is 5.370965003967285 and perplexity is 215.07031129994053
At time: 289.50781750679016 and batch: 900, loss is 5.332056455612182 and perplexity is 206.8629415003034
At time: 289.85051369667053 and batch: 950, loss is 5.380528593063355 and perplexity is 217.13702221883844
At time: 290.1934287548065 and batch: 1000, loss is 5.444601135253906 and perplexity is 231.5049221422699
At time: 290.5369780063629 and batch: 1050, loss is 5.32173996925354 and perplexity is 204.73981322845964
At time: 290.880078792572 and batch: 1100, loss is 5.411011323928833 and perplexity is 223.85786605749294
At time: 291.2237820625305 and batch: 1150, loss is 5.422099132537841 and perplexity is 226.3537707181645
At time: 291.5664005279541 and batch: 1200, loss is 5.393918542861939 and perplexity is 220.0640285476971
At time: 291.9107971191406 and batch: 1250, loss is 5.414117298126221 and perplexity is 224.55424371904
At time: 292.25191378593445 and batch: 1300, loss is 5.47059775352478 and perplexity is 237.6021778602037
At time: 292.59633207321167 and batch: 1350, loss is 5.410669679641724 and perplexity is 223.7813993593789
At time: 292.9401705265045 and batch: 1400, loss is 5.32501708984375 and perplexity is 205.4118708915647
At time: 293.28290700912476 and batch: 1450, loss is 5.377609949111939 and perplexity is 216.50420050217213
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.501809666299413 and perplexity of 245.13514391941922
Finished 27 epochs...
Completing Train Step...
At time: 294.56249022483826 and batch: 50, loss is 5.470883388519287 and perplexity is 237.67005505056053
At time: 294.9057698249817 and batch: 100, loss is 5.468155860900879 and perplexity is 237.02268667024626
At time: 295.2523765563965 and batch: 150, loss is 5.461691608428955 and perplexity is 235.495453709903
At time: 295.5959680080414 and batch: 200, loss is 5.394495487213135 and perplexity is 220.19102987869655
At time: 295.95335817337036 and batch: 250, loss is 5.40237663269043 and perplexity is 221.93324372058083
At time: 296.2979109287262 and batch: 300, loss is 5.451412992477417 and perplexity is 233.0872839110201
At time: 296.64210295677185 and batch: 350, loss is 5.493234176635742 and perplexity is 243.04197781611086
At time: 296.9856073856354 and batch: 400, loss is 5.418127145767212 and perplexity is 225.4564797290479
At time: 297.32853150367737 and batch: 450, loss is 5.443732328414917 and perplexity is 231.30387643024406
At time: 297.6722264289856 and batch: 500, loss is 5.425986614227295 and perplexity is 227.2354294629437
At time: 298.01412868499756 and batch: 550, loss is 5.499324541091919 and perplexity is 244.5267087259743
At time: 298.35739827156067 and batch: 600, loss is 5.342203798294068 and perplexity is 208.97273696113507
At time: 298.70026993751526 and batch: 650, loss is 5.506692132949829 and perplexity is 246.33493467018343
At time: 299.04366517066956 and batch: 700, loss is 5.492193412780762 and perplexity is 242.78916009495086
At time: 299.38636684417725 and batch: 750, loss is 5.4322006893157955 and perplexity is 228.6518839035233
At time: 299.72976899147034 and batch: 800, loss is 5.400315399169922 and perplexity is 221.47625861761392
At time: 300.0731384754181 and batch: 850, loss is 5.369122896194458 and perplexity is 214.67449328943692
At time: 300.41695737838745 and batch: 900, loss is 5.331595125198365 and perplexity is 206.76753134339324
At time: 300.75852036476135 and batch: 950, loss is 5.380285863876343 and perplexity is 217.08432312202822
At time: 301.10203981399536 and batch: 1000, loss is 5.444560613632202 and perplexity is 231.49554137745534
At time: 301.4457006454468 and batch: 1050, loss is 5.3210884475708005 and perplexity is 204.60646424541525
At time: 301.7884409427643 and batch: 1100, loss is 5.411262884140014 and perplexity is 223.91418687329403
At time: 302.13104248046875 and batch: 1150, loss is 5.42194314956665 and perplexity is 226.3184661379958
At time: 302.4749698638916 and batch: 1200, loss is 5.394277791976929 and perplexity is 220.14310055761845
At time: 302.8185484409332 and batch: 1250, loss is 5.416262769699097 and perplexity is 225.0365356523232
At time: 303.16149973869324 and batch: 1300, loss is 5.473342971801758 and perplexity is 238.255343832898
At time: 303.50360321998596 and batch: 1350, loss is 5.412386894226074 and perplexity is 224.1660101772055
At time: 303.84730195999146 and batch: 1400, loss is 5.325927362442017 and perplexity is 205.59893681657195
At time: 304.1916780471802 and batch: 1450, loss is 5.378235120773315 and perplexity is 216.63959511092142
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.500590006510417 and perplexity of 244.83634469525077
Finished 28 epochs...
Completing Train Step...
At time: 305.4434218406677 and batch: 50, loss is 5.46816083908081 and perplexity is 237.02386661476532
At time: 305.78755950927734 and batch: 100, loss is 5.4651895523071286 and perplexity is 236.32064598728851
At time: 306.1305639743805 and batch: 150, loss is 5.458940706253052 and perplexity is 234.84851898891398
At time: 306.47331047058105 and batch: 200, loss is 5.3919478702545165 and perplexity is 219.63078142908503
At time: 306.81775736808777 and batch: 250, loss is 5.39973518371582 and perplexity is 221.34779194242648
At time: 307.1622591018677 and batch: 300, loss is 5.449164590835571 and perplexity is 232.56379880210199
At time: 307.50501561164856 and batch: 350, loss is 5.491535778045654 and perplexity is 242.62954599960403
At time: 307.84726572036743 and batch: 400, loss is 5.417053747177124 and perplexity is 225.21460489885513
At time: 308.190402507782 and batch: 450, loss is 5.440968227386475 and perplexity is 230.6654119441943
At time: 308.5373330116272 and batch: 500, loss is 5.423292779922486 and perplexity is 226.62411862252193
At time: 308.8827087879181 and batch: 550, loss is 5.4974890804290775 and perplexity is 244.07830121415526
At time: 309.2258765697479 and batch: 600, loss is 5.340769329071045 and perplexity is 208.6731869005502
At time: 309.5708792209625 and batch: 650, loss is 5.505538139343262 and perplexity is 246.05082968969398
At time: 309.91458773612976 and batch: 700, loss is 5.490539789199829 and perplexity is 242.38800998167747
At time: 310.25672459602356 and batch: 750, loss is 5.430811185836792 and perplexity is 228.33439194453166
At time: 310.59925961494446 and batch: 800, loss is 5.399109621047973 and perplexity is 221.20936832801382
At time: 310.94225668907166 and batch: 850, loss is 5.368164892196655 and perplexity is 214.46893274627192
At time: 311.28708124160767 and batch: 900, loss is 5.331392908096314 and perplexity is 206.7257236396656
At time: 311.6294324398041 and batch: 950, loss is 5.380246915817261 and perplexity is 217.07586827363656
At time: 311.97346472740173 and batch: 1000, loss is 5.444598493576049 and perplexity is 231.50431058165108
At time: 312.31620812416077 and batch: 1050, loss is 5.320786218643189 and perplexity is 204.54463559681767
At time: 312.66089820861816 and batch: 1100, loss is 5.411482162475586 and perplexity is 223.96329178712767
At time: 313.0046708583832 and batch: 1150, loss is 5.421844120025635 and perplexity is 226.29605503386983
At time: 313.3625226020813 and batch: 1200, loss is 5.394520320892334 and perplexity is 220.19649809999285
At time: 313.7073872089386 and batch: 1250, loss is 5.417185411453247 and perplexity is 225.24425956896908
At time: 314.0506043434143 and batch: 1300, loss is 5.474491539001465 and perplexity is 238.52915332017656
At time: 314.39181566238403 and batch: 1350, loss is 5.412832651138306 and perplexity is 224.26595599984506
At time: 314.73544001579285 and batch: 1400, loss is 5.325895366668701 and perplexity is 205.59235862483325
At time: 315.07854104042053 and batch: 1450, loss is 5.378068170547485 and perplexity is 216.60343010055632
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.499910273103633 and perplexity of 244.6699778015399
Finished 29 epochs...
Completing Train Step...
At time: 316.32106828689575 and batch: 50, loss is 5.466669578552246 and perplexity is 236.67066570090142
At time: 316.6799659729004 and batch: 100, loss is 5.463566827774048 and perplexity is 235.9374736530269
At time: 317.0244228839874 and batch: 150, loss is 5.457401390075684 and perplexity is 234.48729095780672
At time: 317.3678231239319 and batch: 200, loss is 5.390311336517334 and perplexity is 219.27164219744213
At time: 317.7113833427429 and batch: 250, loss is 5.398102674484253 and perplexity is 220.98673442374712
At time: 318.0555455684662 and batch: 300, loss is 5.447836627960205 and perplexity is 232.25516768182922
At time: 318.40198707580566 and batch: 350, loss is 5.490720520019531 and perplexity is 242.43182092428194
At time: 318.74632716178894 and batch: 400, loss is 5.416546087265015 and perplexity is 225.10030148841105
At time: 319.08817744255066 and batch: 450, loss is 5.439230947494507 and perplexity is 230.2650294511792
At time: 319.4327566623688 and batch: 500, loss is 5.421720609664917 and perplexity is 226.26810685246414
At time: 319.7764232158661 and batch: 550, loss is 5.496274719238281 and perplexity is 243.78208189267147
At time: 320.1203787326813 and batch: 600, loss is 5.339900064468384 and perplexity is 208.49187350172983
At time: 320.4635591506958 and batch: 650, loss is 5.504860363006592 and perplexity is 245.88411876245505
At time: 320.8069095611572 and batch: 700, loss is 5.489373826980591 and perplexity is 242.1055594149859
At time: 321.15164017677307 and batch: 750, loss is 5.429787549972534 and perplexity is 228.1007802589425
At time: 321.49526810646057 and batch: 800, loss is 5.398189535140991 and perplexity is 221.00593031030124
At time: 321.83818101882935 and batch: 850, loss is 5.367513999938965 and perplexity is 214.3293819996094
At time: 322.19665026664734 and batch: 900, loss is 5.3311741065979 and perplexity is 206.68049668961524
At time: 322.53962111473083 and batch: 950, loss is 5.38029670715332 and perplexity is 217.0866770402334
At time: 322.88272738456726 and batch: 1000, loss is 5.444431037902832 and perplexity is 231.46554711714145
At time: 323.22744035720825 and batch: 1050, loss is 5.320480251312256 and perplexity is 204.4820611939572
At time: 323.5718424320221 and batch: 1100, loss is 5.411492948532104 and perplexity is 223.96570748087876
At time: 323.9156188964844 and batch: 1150, loss is 5.421782722473145 and perplexity is 226.2821614364734
At time: 324.2598180770874 and batch: 1200, loss is 5.394317131042481 and perplexity is 220.15176095182684
At time: 324.60212755203247 and batch: 1250, loss is 5.417523126602173 and perplexity is 225.32034081380547
At time: 324.9462299346924 and batch: 1300, loss is 5.47514461517334 and perplexity is 238.68498190493673
At time: 325.2896988391876 and batch: 1350, loss is 5.412755661010742 and perplexity is 224.2486903999333
At time: 325.63293623924255 and batch: 1400, loss is 5.325572052001953 and perplexity is 205.5258983442893
At time: 325.97589206695557 and batch: 1450, loss is 5.377642307281494 and perplexity is 216.51120629514813
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.499376606737447 and perplexity of 244.53944049835388
Finished 30 epochs...
Completing Train Step...
At time: 327.2137863636017 and batch: 50, loss is 5.46554407119751 and perplexity is 236.4044409730531
At time: 327.57104110717773 and batch: 100, loss is 5.462587509155274 and perplexity is 235.70652879496927
At time: 327.91405153274536 and batch: 150, loss is 5.456251583099365 and perplexity is 234.21783077808945
At time: 328.25636887550354 and batch: 200, loss is 5.389037914276123 and perplexity is 218.99259452186817
At time: 328.59919238090515 and batch: 250, loss is 5.396950159072876 and perplexity is 220.7321905176769
At time: 328.94225311279297 and batch: 300, loss is 5.446737585067749 and perplexity is 232.00004950913905
At time: 329.2847602367401 and batch: 350, loss is 5.489978666305542 and perplexity is 242.2520386718512
At time: 329.63014698028564 and batch: 400, loss is 5.416136732101441 and perplexity is 225.00817437531583
At time: 329.9736273288727 and batch: 450, loss is 5.437980041503907 and perplexity is 229.97716962673843
At time: 330.3153052330017 and batch: 500, loss is 5.420474424362182 and perplexity is 225.98631048494136
At time: 330.6605648994446 and batch: 550, loss is 5.495327405929565 and perplexity is 243.551253232861
At time: 331.00689721107483 and batch: 600, loss is 5.339278154373169 and perplexity is 208.3622506118986
At time: 331.3655135631561 and batch: 650, loss is 5.504263715744019 and perplexity is 245.73745643327464
At time: 331.708856344223 and batch: 700, loss is 5.488513832092285 and perplexity is 241.89743937537062
At time: 332.05344820022583 and batch: 750, loss is 5.428936719894409 and perplexity is 227.90678779326953
At time: 332.39635181427 and batch: 800, loss is 5.397368097305298 and perplexity is 220.82446221981348
At time: 332.73994517326355 and batch: 850, loss is 5.367042894363403 and perplexity is 214.22843401318934
At time: 333.0825481414795 and batch: 900, loss is 5.330881910324097 and perplexity is 206.62011424080757
At time: 333.4241669178009 and batch: 950, loss is 5.380139007568359 and perplexity is 217.0524452606032
At time: 333.76706171035767 and batch: 1000, loss is 5.444061212539673 and perplexity is 231.37996111403282
At time: 334.11025404930115 and batch: 1050, loss is 5.320201864242554 and perplexity is 204.425143955014
At time: 334.4532160758972 and batch: 1100, loss is 5.411409397125244 and perplexity is 223.94699561264252
At time: 334.7966949939728 and batch: 1150, loss is 5.4216491222381595 and perplexity is 226.25193210590032
At time: 335.13947224617004 and batch: 1200, loss is 5.393979349136353 and perplexity is 220.07741022824655
At time: 335.48304629325867 and batch: 1250, loss is 5.417648344039917 and perplexity is 225.34855661607213
At time: 335.8250300884247 and batch: 1300, loss is 5.475398187637329 and perplexity is 238.74551351816632
At time: 336.1671676635742 and batch: 1350, loss is 5.412573003768921 and perplexity is 224.20773349331463
At time: 336.51172614097595 and batch: 1400, loss is 5.325058650970459 and perplexity is 205.42040821776757
At time: 336.8464243412018 and batch: 1450, loss is 5.377154521942138 and perplexity is 216.40562105647038
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.498978574051816 and perplexity of 244.4421251767339
Finished 31 epochs...
Completing Train Step...
At time: 338.10087966918945 and batch: 50, loss is 5.464667596817017 and perplexity is 236.19732931439555
At time: 338.44516038894653 and batch: 100, loss is 5.461732864379883 and perplexity is 235.50516949920058
At time: 338.7887635231018 and batch: 150, loss is 5.45528881072998 and perplexity is 233.99244083921187
At time: 339.13203501701355 and batch: 200, loss is 5.388106565475464 and perplexity is 218.78873098037556
At time: 339.4760103225708 and batch: 250, loss is 5.3960114765167235 and perplexity is 220.52509027675515
At time: 339.82006549835205 and batch: 300, loss is 5.445871257781983 and perplexity is 231.79914857149734
At time: 340.1854314804077 and batch: 350, loss is 5.489362077713013 and perplexity is 242.1027148686968
At time: 340.5270414352417 and batch: 400, loss is 5.415879554748535 and perplexity is 224.9503148090519
At time: 340.8697512149811 and batch: 450, loss is 5.43700945854187 and perplexity is 229.75406599204885
At time: 341.2137312889099 and batch: 500, loss is 5.419377422332763 and perplexity is 225.73853897149263
At time: 341.5562164783478 and batch: 550, loss is 5.494537496566773 and perplexity is 243.3589457803405
At time: 341.89979672431946 and batch: 600, loss is 5.338765697479248 and perplexity is 208.25550129468763
At time: 342.24160408973694 and batch: 650, loss is 5.503695497512817 and perplexity is 245.59786359379424
At time: 342.58519649505615 and batch: 700, loss is 5.487855806350708 and perplexity is 241.7383169924936
At time: 342.9300136566162 and batch: 750, loss is 5.428150568008423 and perplexity is 227.72768885092657
At time: 343.2736449241638 and batch: 800, loss is 5.396453132629395 and perplexity is 220.62250804186544
At time: 343.61667370796204 and batch: 850, loss is 5.366611175537109 and perplexity is 214.13596752629604
At time: 343.9607951641083 and batch: 900, loss is 5.330576801300049 and perplexity is 206.55708219571483
At time: 344.30256962776184 and batch: 950, loss is 5.379878826141358 and perplexity is 216.99597959163887
At time: 344.6454737186432 and batch: 1000, loss is 5.443593711853027 and perplexity is 231.27181610423884
At time: 344.98763942718506 and batch: 1050, loss is 5.319998807907105 and perplexity is 204.38363834853962
At time: 345.33390498161316 and batch: 1100, loss is 5.4111431694030765 and perplexity is 223.88738264977815
At time: 345.67734003067017 and batch: 1150, loss is 5.421314382553101 and perplexity is 226.17620927982782
At time: 346.0192413330078 and batch: 1200, loss is 5.39356912612915 and perplexity is 219.98714792630764
At time: 346.36189794540405 and batch: 1250, loss is 5.417539892196655 and perplexity is 225.3241184749353
At time: 346.70464611053467 and batch: 1300, loss is 5.475534973144531 and perplexity is 238.77817267792403
At time: 347.0481128692627 and batch: 1350, loss is 5.412061042785645 and perplexity is 224.09297725948088
At time: 347.39243960380554 and batch: 1400, loss is 5.324455089569092 and perplexity is 205.2964617967147
At time: 347.73589754104614 and batch: 1450, loss is 5.376537199020386 and perplexity is 216.27207013246064
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.498349442441239 and perplexity of 244.28838727458654
Finished 32 epochs...
Completing Train Step...
At time: 348.98795437812805 and batch: 50, loss is 5.464005918502807 and perplexity is 236.04109435805555
At time: 349.3305633068085 and batch: 100, loss is 5.460768175125122 and perplexity is 235.27808974105596
At time: 349.6748604774475 and batch: 150, loss is 5.454420394897461 and perplexity is 233.78932630560053
At time: 350.0180561542511 and batch: 200, loss is 5.38711256980896 and perplexity is 218.571363978727
At time: 350.3609642982483 and batch: 250, loss is 5.395151224136352 and perplexity is 220.3354646175695
At time: 350.7033395767212 and batch: 300, loss is 5.445275707244873 and perplexity is 231.66114156321697
At time: 351.04591703414917 and batch: 350, loss is 5.48871376991272 and perplexity is 241.9458086574314
At time: 351.3893530368805 and batch: 400, loss is 5.415513296127319 and perplexity is 224.8679399030883
At time: 351.7323315143585 and batch: 450, loss is 5.436095705032349 and perplexity is 229.544223294773
At time: 352.07749009132385 and batch: 500, loss is 5.418312129974365 and perplexity is 225.4981894749013
At time: 352.4210579395294 and batch: 550, loss is 5.493810262680054 and perplexity is 243.1820312452523
At time: 352.76603293418884 and batch: 600, loss is 5.338266849517822 and perplexity is 208.15163937021953
At time: 353.10992980003357 and batch: 650, loss is 5.5030769348144535 and perplexity is 245.4459928921952
At time: 353.45219469070435 and batch: 700, loss is 5.487242879867554 and perplexity is 241.59019457472942
At time: 353.7953910827637 and batch: 750, loss is 5.42732494354248 and perplexity is 227.53974889402775
At time: 354.1396572589874 and batch: 800, loss is 5.395569391250611 and perplexity is 220.42762093000408
At time: 354.4815397262573 and batch: 850, loss is 5.365906362533569 and perplexity is 213.98509488660275
At time: 354.8242952823639 and batch: 900, loss is 5.330232696533203 and perplexity is 206.48601714671776
At time: 355.1678445339203 and batch: 950, loss is 5.379515752792359 and perplexity is 216.9172084353283
At time: 355.5122036933899 and batch: 1000, loss is 5.443105163574219 and perplexity is 231.1588562519618
At time: 355.8551652431488 and batch: 1050, loss is 5.319565868377685 and perplexity is 204.29517174405882
At time: 356.1982800960541 and batch: 1100, loss is 5.410557975769043 and perplexity is 223.75640350652935
At time: 356.5408651828766 and batch: 1150, loss is 5.421100082397461 and perplexity is 226.12774487612728
At time: 356.8854923248291 and batch: 1200, loss is 5.393227672576904 and perplexity is 219.91204535594912
At time: 357.2272140979767 and batch: 1250, loss is 5.4172970485687255 and perplexity is 225.2694065920298
At time: 357.5708703994751 and batch: 1300, loss is 5.475535984039307 and perplexity is 238.77841405765338
At time: 357.9133939743042 and batch: 1350, loss is 5.411504373550415 and perplexity is 223.96826630780504
At time: 358.2575047016144 and batch: 1400, loss is 5.323935775756836 and perplexity is 205.18987618658159
At time: 358.60075855255127 and batch: 1450, loss is 5.375990839004516 and perplexity is 216.15393999452155
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.498021313267896 and perplexity of 244.20824227768756
Finished 33 epochs...
Completing Train Step...
At time: 359.84693670272827 and batch: 50, loss is 5.463414192199707 and perplexity is 235.9014639494782
At time: 360.2055506706238 and batch: 100, loss is 5.46012505531311 and perplexity is 235.12682638565508
At time: 360.54952335357666 and batch: 150, loss is 5.453659954071045 and perplexity is 233.61161093667246
At time: 360.8936564922333 and batch: 200, loss is 5.386267614364624 and perplexity is 218.38675891726635
At time: 361.23693656921387 and batch: 250, loss is 5.3943086528778075 and perplexity is 220.14989447685653
At time: 361.5799207687378 and batch: 300, loss is 5.444863958358765 and perplexity is 231.56577498111304
At time: 361.92220091819763 and batch: 350, loss is 5.4882656955719 and perplexity is 241.83742323288024
At time: 362.2648575305939 and batch: 400, loss is 5.415159769058228 and perplexity is 224.78845704985972
At time: 362.6107847690582 and batch: 450, loss is 5.4353108310699465 and perplexity is 229.36413069493045
At time: 362.9552218914032 and batch: 500, loss is 5.417527284622192 and perplexity is 225.32127770224105
At time: 363.29965591430664 and batch: 550, loss is 5.493191900253296 and perplexity is 243.0317030976969
At time: 363.6429500579834 and batch: 600, loss is 5.3378841590881345 and perplexity is 208.07199697007286
At time: 363.98581433296204 and batch: 650, loss is 5.502591762542725 and perplexity is 245.32693818559358
At time: 364.3287298679352 and batch: 700, loss is 5.486675643920899 and perplexity is 241.4531947912815
At time: 364.6702687740326 and batch: 750, loss is 5.4266724777221675 and perplexity is 227.39133540774054
At time: 365.01229190826416 and batch: 800, loss is 5.394781293869019 and perplexity is 220.25397093465978
At time: 365.3552725315094 and batch: 850, loss is 5.36540449142456 and perplexity is 213.8777288939191
At time: 365.696702003479 and batch: 900, loss is 5.329888248443604 and perplexity is 206.41490568039006
At time: 366.03887486457825 and batch: 950, loss is 5.379276962280273 and perplexity is 216.8654168479618
At time: 366.38133668899536 and batch: 1000, loss is 5.442703342437744 and perplexity is 231.06599039661756
At time: 366.7393145561218 and batch: 1050, loss is 5.319214553833008 and perplexity is 204.22341248459156
At time: 367.0826325416565 and batch: 1100, loss is 5.410205125808716 and perplexity is 223.67746499597325
At time: 367.4250030517578 and batch: 1150, loss is 5.42087537765503 and perplexity is 226.0769386078767
At time: 367.7676703929901 and batch: 1200, loss is 5.3929489231109615 and perplexity is 219.85075353368006
At time: 368.1112880706787 and batch: 1250, loss is 5.417087354660034 and perplexity is 225.22217392202762
At time: 368.45452094078064 and batch: 1300, loss is 5.47545636177063 and perplexity is 238.75940273548738
At time: 368.7970712184906 and batch: 1350, loss is 5.411067304611206 and perplexity is 223.8703981243628
At time: 369.13986015319824 and batch: 1400, loss is 5.323468103408813 and perplexity is 205.09393699119786
At time: 369.4818720817566 and batch: 1450, loss is 5.3754962539672855 and perplexity is 216.04705992288257
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.497645190638354 and perplexity of 244.1164073031351
Finished 34 epochs...
Completing Train Step...
At time: 370.7395486831665 and batch: 50, loss is 5.462983522415161 and perplexity is 235.7998901907694
At time: 371.0984170436859 and batch: 100, loss is 5.45941535949707 and perplexity is 234.96001705967217
At time: 371.44124698638916 and batch: 150, loss is 5.452998294830322 and perplexity is 233.45709078103766
At time: 371.78485131263733 and batch: 200, loss is 5.385431461334228 and perplexity is 218.20423048848335
At time: 372.1276957988739 and batch: 250, loss is 5.393642692565918 and perplexity is 220.00333219221744
At time: 372.4728887081146 and batch: 300, loss is 5.4444529151916505 and perplexity is 231.47061101115926
At time: 372.81712770462036 and batch: 350, loss is 5.487707071304321 and perplexity is 241.70236470645102
At time: 373.1590988636017 and batch: 400, loss is 5.414761981964111 and perplexity is 224.69905688503366
At time: 373.5018095970154 and batch: 450, loss is 5.434598026275634 and perplexity is 229.20069709797352
At time: 373.8443102836609 and batch: 500, loss is 5.4168062496185305 and perplexity is 225.15887173117906
At time: 374.1873378753662 and batch: 550, loss is 5.492400169372559 and perplexity is 242.83936354398543
At time: 374.5302758216858 and batch: 600, loss is 5.33736400604248 and perplexity is 207.96379583014934
At time: 374.8744583129883 and batch: 650, loss is 5.501956758499145 and perplexity is 245.1712040389862
At time: 375.21882152557373 and batch: 700, loss is 5.486099433898926 and perplexity is 241.31410711630983
At time: 375.57746720314026 and batch: 750, loss is 5.426074075698852 and perplexity is 227.25530467713963
At time: 375.919392824173 and batch: 800, loss is 5.393890600204468 and perplexity is 220.05787945983715
At time: 376.2626144886017 and batch: 850, loss is 5.36486557006836 and perplexity is 213.7624966715442
At time: 376.60641980171204 and batch: 900, loss is 5.329595193862915 and perplexity is 206.3544237094502
At time: 376.9490144252777 and batch: 950, loss is 5.3788633632659915 and perplexity is 216.7757400717132
At time: 377.29259419441223 and batch: 1000, loss is 5.44216326713562 and perplexity is 230.94123105479574
At time: 377.63594365119934 and batch: 1050, loss is 5.318822059631348 and perplexity is 204.1432717077721
At time: 377.9808542728424 and batch: 1100, loss is 5.409810914993286 and perplexity is 223.5893062978017
At time: 378.3245379924774 and batch: 1150, loss is 5.420590581893921 and perplexity is 226.0125620216014
At time: 378.66674971580505 and batch: 1200, loss is 5.392551469802856 and perplexity is 219.7633904869147
At time: 379.00933861732483 and batch: 1250, loss is 5.416650896072388 and perplexity is 225.12389521894303
At time: 379.353458404541 and batch: 1300, loss is 5.47515751838684 and perplexity is 238.68806172808735
At time: 379.69758701324463 and batch: 1350, loss is 5.41035267829895 and perplexity is 223.71047159798593
At time: 380.0411231517792 and batch: 1400, loss is 5.3233323097229 and perplexity is 205.0660884204083
At time: 380.3845944404602 and batch: 1450, loss is 5.375044813156128 and perplexity is 215.94954947465678
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.497355143229167 and perplexity of 244.04561223911548
Finished 35 epochs...
Completing Train Step...
At time: 381.6378858089447 and batch: 50, loss is 5.462521018981934 and perplexity is 235.69085714802344
At time: 381.98113799095154 and batch: 100, loss is 5.458802919387818 and perplexity is 234.81616217690072
At time: 382.325386762619 and batch: 150, loss is 5.4522891330719 and perplexity is 233.29159063014822
At time: 382.67059659957886 and batch: 200, loss is 5.38472186088562 and perplexity is 218.04944759214177
At time: 383.01629066467285 and batch: 250, loss is 5.392809762954712 and perplexity is 219.8201611971332
At time: 383.3594591617584 and batch: 300, loss is 5.444016180038452 and perplexity is 231.3695417302588
At time: 383.70331740379333 and batch: 350, loss is 5.487206573486328 and perplexity is 241.5814234682493
At time: 384.04616832733154 and batch: 400, loss is 5.414145936965943 and perplexity is 224.56067478412342
At time: 384.4049484729767 and batch: 450, loss is 5.433687362670899 and perplexity is 228.99206737511224
At time: 384.74762296676636 and batch: 500, loss is 5.415914516448975 and perplexity is 224.95817959205434
At time: 385.091187953949 and batch: 550, loss is 5.491601991653442 and perplexity is 242.64561190908563
At time: 385.436350107193 and batch: 600, loss is 5.336692199707032 and perplexity is 207.8241313535596
At time: 385.7793037891388 and batch: 650, loss is 5.5013611698150635 and perplexity is 245.0252263198519
At time: 386.12166452407837 and batch: 700, loss is 5.485261631011963 and perplexity is 241.11201812789264
At time: 386.4647047519684 and batch: 750, loss is 5.4252775859832765 and perplexity is 227.07437022993275
At time: 386.8081934452057 and batch: 800, loss is 5.392891349792481 and perplexity is 219.83809636058987
At time: 387.1516170501709 and batch: 850, loss is 5.364271955490112 and perplexity is 213.63564179241533
At time: 387.4949629306793 and batch: 900, loss is 5.329042415618897 and perplexity is 206.24038699487787
At time: 387.8395800590515 and batch: 950, loss is 5.378484573364258 and perplexity is 216.6936431601553
At time: 388.1831843852997 and batch: 1000, loss is 5.4415144348144535 and perplexity is 230.7914375204957
At time: 388.52603793144226 and batch: 1050, loss is 5.318402366638184 and perplexity is 204.05761218364316
At time: 388.86931467056274 and batch: 1100, loss is 5.409227991104126 and perplexity is 223.4590087302721
At time: 389.2121238708496 and batch: 1150, loss is 5.41994381904602 and perplexity is 225.86643275391145
At time: 389.55915904045105 and batch: 1200, loss is 5.392156314849854 and perplexity is 219.67656705016046
At time: 389.90216994285583 and batch: 1250, loss is 5.415797176361084 and perplexity is 224.93178452811912
At time: 390.24595618247986 and batch: 1300, loss is 5.4745360851287845 and perplexity is 238.53977910687678
At time: 390.5888292789459 and batch: 1350, loss is 5.40959677696228 and perplexity is 223.5414324499858
At time: 390.93175888061523 and batch: 1400, loss is 5.322446813583374 and perplexity is 204.8845835635492
At time: 391.2757787704468 and batch: 1450, loss is 5.37400450706482 and perplexity is 215.72501265668288
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.496630546374199 and perplexity of 243.86884160747445
Finished 36 epochs...
Completing Train Step...
At time: 392.5283536911011 and batch: 50, loss is 5.46156831741333 and perplexity is 235.4664210260113
At time: 392.87139415740967 and batch: 100, loss is 5.458018684387207 and perplexity is 234.63208331379064
At time: 393.23030400276184 and batch: 150, loss is 5.451282510757446 and perplexity is 233.0568722654371
At time: 393.57329773902893 and batch: 200, loss is 5.383957576751709 and perplexity is 217.8828595273555
At time: 393.91635489463806 and batch: 250, loss is 5.391870069503784 and perplexity is 219.61369465409646
At time: 394.26066541671753 and batch: 300, loss is 5.443401832580566 and perplexity is 231.2274440935947
At time: 394.60331988334656 and batch: 350, loss is 5.486540794372559 and perplexity is 241.42063713226074
At time: 394.946768283844 and batch: 400, loss is 5.413419218063354 and perplexity is 224.39754158015077
At time: 395.29111433029175 and batch: 450, loss is 5.432883129119873 and perplexity is 228.80797830683537
At time: 395.6345317363739 and batch: 500, loss is 5.4151179981231685 and perplexity is 224.77906762192217
At time: 395.98100209236145 and batch: 550, loss is 5.490854864120483 and perplexity is 242.46439239714985
At time: 396.32450437545776 and batch: 600, loss is 5.336060028076172 and perplexity is 207.69279235227927
At time: 396.669273853302 and batch: 650, loss is 5.500622320175171 and perplexity is 244.8442563826399
At time: 397.01493525505066 and batch: 700, loss is 5.484617280960083 and perplexity is 240.95670762904055
At time: 397.3580024242401 and batch: 750, loss is 5.424598579406738 and perplexity is 226.92023757364888
At time: 397.701185464859 and batch: 800, loss is 5.391813812255859 and perplexity is 219.60134013954735
At time: 398.04410910606384 and batch: 850, loss is 5.363804054260254 and perplexity is 213.53570479502434
At time: 398.38938188552856 and batch: 900, loss is 5.328601217269897 and perplexity is 206.14941414664955
At time: 398.7321949005127 and batch: 950, loss is 5.377977752685547 and perplexity is 216.58384616690023
At time: 399.07632994651794 and batch: 1000, loss is 5.440912208557129 and perplexity is 230.65249069976645
At time: 399.4195375442505 and batch: 1050, loss is 5.3180298995971675 and perplexity is 203.98162160150846
At time: 399.76454758644104 and batch: 1100, loss is 5.408760137557984 and perplexity is 223.35448709293598
At time: 400.10676288604736 and batch: 1150, loss is 5.419304723739624 and perplexity is 225.72212869380138
At time: 400.44878363609314 and batch: 1200, loss is 5.391743497848511 and perplexity is 219.58589954431707
At time: 400.7898669242859 and batch: 1250, loss is 5.415463895797729 and perplexity is 224.85683162712144
At time: 401.1335952281952 and batch: 1300, loss is 5.474073257446289 and perplexity is 238.42940183852772
At time: 401.47718572616577 and batch: 1350, loss is 5.408978128433228 and perplexity is 223.4031816403578
At time: 401.821120262146 and batch: 1400, loss is 5.321910848617554 and perplexity is 204.7748020268792
At time: 402.1646821498871 and batch: 1450, loss is 5.373365392684937 and perplexity is 215.58718374790388
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.4963118072248935 and perplexity of 243.79112344692655
Finished 37 epochs...
Completing Train Step...
At time: 403.40582752227783 and batch: 50, loss is 5.461102027893066 and perplexity is 235.3566510957857
At time: 403.76629972457886 and batch: 100, loss is 5.457495746612548 and perplexity is 234.50941741039162
At time: 404.11007165908813 and batch: 150, loss is 5.450579414367676 and perplexity is 232.89306841163315
At time: 404.4548556804657 and batch: 200, loss is 5.383353509902954 and perplexity is 217.75128345937443
At time: 404.7992527484894 and batch: 250, loss is 5.391300172805786 and perplexity is 219.48857319121865
At time: 405.1437041759491 and batch: 300, loss is 5.442930002212524 and perplexity is 231.1183696978763
At time: 405.48738503456116 and batch: 350, loss is 5.4859541893005375 and perplexity is 241.27906009099343
At time: 405.8305187225342 and batch: 400, loss is 5.412715797424316 and perplexity is 224.23975122105776
At time: 406.17319536209106 and batch: 450, loss is 5.432298583984375 and perplexity is 228.6742687995812
At time: 406.5180695056915 and batch: 500, loss is 5.414496974945068 and perplexity is 224.63951794725347
At time: 406.8585915565491 and batch: 550, loss is 5.490294933319092 and perplexity is 242.32866711753437
At time: 407.19831228256226 and batch: 600, loss is 5.3356136703491215 and perplexity is 207.60010775634169
At time: 407.5385868549347 and batch: 650, loss is 5.500068311691284 and perplexity is 244.7086481548958
At time: 407.88264751434326 and batch: 700, loss is 5.48410737991333 and perplexity is 240.83387487053582
At time: 408.22785091400146 and batch: 750, loss is 5.4240420532226565 and perplexity is 226.79398565424916
At time: 408.5693955421448 and batch: 800, loss is 5.390960607528687 and perplexity is 219.41405514562928
At time: 408.91241121292114 and batch: 850, loss is 5.363409929275512 and perplexity is 213.45156162118295
At time: 409.25623083114624 and batch: 900, loss is 5.32816294670105 and perplexity is 206.05908472145413
At time: 409.5985281467438 and batch: 950, loss is 5.377538471221924 and perplexity is 216.4887257917973
At time: 409.94075989723206 and batch: 1000, loss is 5.44047402381897 and perplexity is 230.551444438605
At time: 410.2835624217987 and batch: 1050, loss is 5.317776184082032 and perplexity is 203.92987486405823
At time: 410.62710905075073 and batch: 1100, loss is 5.408438873291016 and perplexity is 223.2827428024216
At time: 410.9854347705841 and batch: 1150, loss is 5.418959760665894 and perplexity is 225.6442763233468
At time: 411.3297483921051 and batch: 1200, loss is 5.391475582122803 and perplexity is 219.52707690879186
At time: 411.67229104042053 and batch: 1250, loss is 5.4152623462677 and perplexity is 224.8115164051674
At time: 412.01656460762024 and batch: 1300, loss is 5.473811902999878 and perplexity is 238.3670953965896
At time: 412.36539459228516 and batch: 1350, loss is 5.408496246337891 and perplexity is 223.295553581184
At time: 412.70784735679626 and batch: 1400, loss is 5.321447420120239 and perplexity is 204.6799255340212
At time: 413.05006217956543 and batch: 1450, loss is 5.37281572341919 and perplexity is 215.4687146612994
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.496190780248398 and perplexity of 243.76161992975602
Finished 38 epochs...
Completing Train Step...
At time: 414.2872066497803 and batch: 50, loss is 5.460847597122193 and perplexity is 235.2967767388797
At time: 414.64480447769165 and batch: 100, loss is 5.457124729156494 and perplexity is 234.4224264615013
At time: 414.98846316337585 and batch: 150, loss is 5.450110340118409 and perplexity is 232.78384988820955
At time: 415.33176589012146 and batch: 200, loss is 5.382831058502197 and perplexity is 217.63754870934125
At time: 415.6743621826172 and batch: 250, loss is 5.390815601348877 and perplexity is 219.3822410583715
At time: 416.0175635814667 and batch: 300, loss is 5.44256669998169 and perplexity is 231.03441912921608
At time: 416.36152386665344 and batch: 350, loss is 5.485507135391235 and perplexity is 241.17121945103287
At time: 416.7052958011627 and batch: 400, loss is 5.412220458984375 and perplexity is 224.1287041577253
At time: 417.0486481189728 and batch: 450, loss is 5.431749544143677 and perplexity is 228.5487519754893
At time: 417.3905556201935 and batch: 500, loss is 5.413857688903809 and perplexity is 224.4959549329194
At time: 417.733913898468 and batch: 550, loss is 5.4897230052948 and perplexity is 242.1901121872211
At time: 418.0762104988098 and batch: 600, loss is 5.335151844024658 and perplexity is 207.50425469705502
At time: 418.42188596725464 and batch: 650, loss is 5.499522380828857 and perplexity is 244.57509061147485
At time: 418.7662227153778 and batch: 700, loss is 5.48354697227478 and perplexity is 240.69894753812196
At time: 419.1112115383148 and batch: 750, loss is 5.4234067249298095 and perplexity is 226.64994278061712
At time: 419.4538161754608 and batch: 800, loss is 5.390174493789673 and perplexity is 219.24163852076455
At time: 419.81127977371216 and batch: 850, loss is 5.362919130325317 and perplexity is 213.34682552310773
At time: 420.1540114879608 and batch: 900, loss is 5.327733135223388 and perplexity is 205.97053719249973
At time: 420.4964234828949 and batch: 950, loss is 5.377233781814575 and perplexity is 216.42277401815173
At time: 420.8397674560547 and batch: 1000, loss is 5.440187969207764 and perplexity is 230.48550356659797
At time: 421.18243527412415 and batch: 1050, loss is 5.317425594329834 and perplexity is 203.85839167113363
At time: 421.52711033821106 and batch: 1100, loss is 5.408041715621948 and perplexity is 223.19408195608014
At time: 421.8699572086334 and batch: 1150, loss is 5.418626356124878 and perplexity is 225.5690580367222
At time: 422.2138514518738 and batch: 1200, loss is 5.391161403656006 and perplexity is 219.45811706176494
At time: 422.5561592578888 and batch: 1250, loss is 5.414897451400757 and perplexity is 224.7294988016127
At time: 422.8978581428528 and batch: 1300, loss is 5.473432607650757 and perplexity is 238.27670101009113
At time: 423.24109268188477 and batch: 1350, loss is 5.407939224243164 and perplexity is 223.17120765911318
At time: 423.58604192733765 and batch: 1400, loss is 5.320875787734986 and perplexity is 204.56295729457665
At time: 423.92848014831543 and batch: 1450, loss is 5.372220096588134 and perplexity is 215.34041392706717
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.495998284755609 and perplexity of 243.71470143254905
Finished 39 epochs...
Completing Train Step...
At time: 425.1919410228729 and batch: 50, loss is 5.460633239746094 and perplexity is 235.2463445446629
At time: 425.5351824760437 and batch: 100, loss is 5.456669940948486 and perplexity is 234.31583814564578
At time: 425.8793749809265 and batch: 150, loss is 5.449561853408813 and perplexity is 232.65620604901207
At time: 426.2259919643402 and batch: 200, loss is 5.382375612258911 and perplexity is 217.53844907437477
At time: 426.5688781738281 and batch: 250, loss is 5.39029969215393 and perplexity is 219.26908893362193
At time: 426.91366600990295 and batch: 300, loss is 5.442197294235229 and perplexity is 230.9490894487671
At time: 427.2575879096985 and batch: 350, loss is 5.484955062866211 and perplexity is 241.03811219275823
At time: 427.59969186782837 and batch: 400, loss is 5.411462993621826 and perplexity is 223.95899870868655
At time: 427.9437930583954 and batch: 450, loss is 5.431137008666992 and perplexity is 228.4088006237121
At time: 428.2866611480713 and batch: 500, loss is 5.413048620223999 and perplexity is 224.31439574386982
At time: 428.6447026729584 and batch: 550, loss is 5.489050388336182 and perplexity is 242.0272657833203
At time: 428.9890067577362 and batch: 600, loss is 5.334593696594238 and perplexity is 207.38846904623233
At time: 429.3328845500946 and batch: 650, loss is 5.498801975250244 and perplexity is 244.3989608018747
At time: 429.6762909889221 and batch: 700, loss is 5.482951574325561 and perplexity is 240.55567853364667
At time: 430.01916694641113 and batch: 750, loss is 5.42253381729126 and perplexity is 226.45218463914037
At time: 430.3617649078369 and batch: 800, loss is 5.389281587600708 and perplexity is 219.04596367749045
At time: 430.7057399749756 and batch: 850, loss is 5.362300701141358 and perplexity is 213.21492640923353
At time: 431.04908633232117 and batch: 900, loss is 5.327224626541137 and perplexity is 205.86582601157812
At time: 431.3925518989563 and batch: 950, loss is 5.376807441711426 and perplexity is 216.3305239766964
At time: 431.7363431453705 and batch: 1000, loss is 5.439817848205567 and perplexity is 230.40021182613194
At time: 432.0780026912689 and batch: 1050, loss is 5.3169835186004635 and perplexity is 203.7682907411318
At time: 432.4224991798401 and batch: 1100, loss is 5.407536935806275 and perplexity is 223.08144651897013
At time: 432.76520705223083 and batch: 1150, loss is 5.418159494400024 and perplexity is 225.4637730558898
At time: 433.10880398750305 and batch: 1200, loss is 5.39065993309021 and perplexity is 219.34809286488724
At time: 433.45321822166443 and batch: 1250, loss is 5.41424033164978 and perplexity is 224.58187311851128
At time: 433.7977225780487 and batch: 1300, loss is 5.472977466583252 and perplexity is 238.16827617420134
At time: 434.1400043964386 and batch: 1350, loss is 5.407164926528931 and perplexity is 222.99847358556917
At time: 434.4849133491516 and batch: 1400, loss is 5.3201829624176025 and perplexity is 204.42127998324546
At time: 434.8324673175812 and batch: 1450, loss is 5.37158727645874 and perplexity is 215.20418528712102
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.495779705862714 and perplexity of 243.66143636444963
Finished 40 epochs...
Completing Train Step...
At time: 436.08816957473755 and batch: 50, loss is 5.460260372161866 and perplexity is 235.15864515961903
At time: 436.4323661327362 and batch: 100, loss is 5.4555816745758055 and perplexity is 234.0609788009857
At time: 436.77700686454773 and batch: 150, loss is 5.449081497192383 and perplexity is 232.54447503163817
At time: 437.11955308914185 and batch: 200, loss is 5.381933841705322 and perplexity is 217.44236821770963
At time: 437.47817397117615 and batch: 250, loss is 5.389377660751343 and perplexity is 219.06700912428983
At time: 437.8210723400116 and batch: 300, loss is 5.44161545753479 and perplexity is 230.81475387706547
At time: 438.16299533843994 and batch: 350, loss is 5.484026851654053 and perplexity is 240.81448171867646
At time: 438.50579476356506 and batch: 400, loss is 5.4105840587615965 and perplexity is 223.7622398192497
At time: 438.84826278686523 and batch: 450, loss is 5.430472564697266 and perplexity is 228.2570861819599
At time: 439.1926293373108 and batch: 500, loss is 5.412021045684814 and perplexity is 224.08401436932002
At time: 439.5364308357239 and batch: 550, loss is 5.488321695327759 and perplexity is 241.85096644874372
At time: 439.8803479671478 and batch: 600, loss is 5.333990497589111 and perplexity is 207.2634102494916
At time: 440.22373127937317 and batch: 650, loss is 5.498154611587524 and perplexity is 244.240796995719
At time: 440.56584668159485 and batch: 700, loss is 5.482341957092285 and perplexity is 240.40907633660325
At time: 440.90919280052185 and batch: 750, loss is 5.421588106155395 and perplexity is 226.23812752044054
At time: 441.2541103363037 and batch: 800, loss is 5.388379468917846 and perplexity is 218.84844732624205
At time: 441.59830617904663 and batch: 850, loss is 5.361707792282105 and perplexity is 213.08854685992006
At time: 441.9414646625519 and batch: 900, loss is 5.326694164276123 and perplexity is 205.75665091841668
At time: 442.28526401519775 and batch: 950, loss is 5.37622712135315 and perplexity is 216.2050193894719
At time: 442.62841057777405 and batch: 1000, loss is 5.439268531799317 and perplexity is 230.27368396486904
At time: 442.97170329093933 and batch: 1050, loss is 5.316396780014038 and perplexity is 203.64876709026203
At time: 443.31506967544556 and batch: 1100, loss is 5.406821813583374 and perplexity is 222.92197304735555
At time: 443.6588017940521 and batch: 1150, loss is 5.417560043334961 and perplexity is 225.32865905815927
At time: 444.0017545223236 and batch: 1200, loss is 5.390088224411011 and perplexity is 219.22272549665166
At time: 444.3431146144867 and batch: 1250, loss is 5.413539686203003 and perplexity is 224.4245759628849
At time: 444.68702840805054 and batch: 1300, loss is 5.472403564453125 and perplexity is 238.0316301076611
At time: 445.03373312950134 and batch: 1350, loss is 5.406569004058838 and perplexity is 222.86562337250822
At time: 445.3788435459137 and batch: 1400, loss is 5.319518632888794 and perplexity is 204.28552198965065
At time: 445.7204382419586 and batch: 1450, loss is 5.370802211761474 and perplexity is 215.03530237922666
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.495133359208066 and perplexity of 243.50399749571287
Finished 41 epochs...
Completing Train Step...
At time: 446.9790105819702 and batch: 50, loss is 5.459653291702271 and perplexity is 235.01592826593964
At time: 447.33694767951965 and batch: 100, loss is 5.454703464508056 and perplexity is 233.85551432662587
At time: 447.6805429458618 and batch: 150, loss is 5.447916584014893 and perplexity is 232.27373863113783
At time: 448.02616453170776 and batch: 200, loss is 5.381239166259766 and perplexity is 217.29136879755222
At time: 448.36971855163574 and batch: 250, loss is 5.388046808242798 and perplexity is 218.77565716190512
At time: 448.7131071090698 and batch: 300, loss is 5.440716476440429 and perplexity is 230.6073490175224
At time: 449.05716824531555 and batch: 350, loss is 5.483286733627319 and perplexity is 240.63631651942865
At time: 449.4001245498657 and batch: 400, loss is 5.409667463302612 and perplexity is 223.55723433424038
At time: 449.7428448200226 and batch: 450, loss is 5.429911241531372 and perplexity is 228.1289961450224
At time: 450.0845036506653 and batch: 500, loss is 5.410856761932373 and perplexity is 223.82326881257026
At time: 450.4278655052185 and batch: 550, loss is 5.487440271377563 and perplexity is 241.63788713493835
At time: 450.7726686000824 and batch: 600, loss is 5.3332294082641605 and perplexity is 207.10572429465802
At time: 451.11468505859375 and batch: 650, loss is 5.4971457862854 and perplexity is 243.994524943524
At time: 451.45993733406067 and batch: 700, loss is 5.481544160842896 and perplexity is 240.21735536448782
At time: 451.80218529701233 and batch: 750, loss is 5.420260562896728 and perplexity is 225.93798588897712
At time: 452.14604687690735 and batch: 800, loss is 5.387148752212524 and perplexity is 218.57927255910087
At time: 452.4900543689728 and batch: 850, loss is 5.361000261306763 and perplexity is 212.93783343602118
At time: 452.83254289627075 and batch: 900, loss is 5.325849742889404 and perplexity is 205.58297893840827
At time: 453.1763596534729 and batch: 950, loss is 5.3755545234680175 and perplexity is 216.05964924398205
At time: 453.51986837387085 and batch: 1000, loss is 5.438367319107056 and perplexity is 230.06625188243837
At time: 453.86506390571594 and batch: 1050, loss is 5.31564115524292 and perplexity is 203.4949431611456
At time: 454.2082998752594 and batch: 1100, loss is 5.406021595001221 and perplexity is 222.74365809713646
At time: 454.5510575771332 and batch: 1150, loss is 5.4166867065429685 and perplexity is 225.13195715591982
At time: 454.8945837020874 and batch: 1200, loss is 5.389356441497803 and perplexity is 219.0623607351988
At time: 455.2534923553467 and batch: 1250, loss is 5.412431020736694 and perplexity is 224.17590205927968
At time: 455.5997939109802 and batch: 1300, loss is 5.471937255859375 and perplexity is 237.92065978817521
At time: 455.94229459762573 and batch: 1350, loss is 5.405851373672485 and perplexity is 222.7057456025369
At time: 456.286461353302 and batch: 1400, loss is 5.318677711486816 and perplexity is 204.11380613198426
At time: 456.63120579719543 and batch: 1450, loss is 5.370050525665283 and perplexity is 214.87372406793094
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.494293995392629 and perplexity of 243.29969480543824
Finished 42 epochs...
Completing Train Step...
At time: 457.8687927722931 and batch: 50, loss is 5.458614683151245 and perplexity is 234.77196542609153
At time: 458.22947120666504 and batch: 100, loss is 5.45393479347229 and perplexity is 233.67582543587912
At time: 458.5719587802887 and batch: 150, loss is 5.446616439819336 and perplexity is 231.97194550787705
At time: 458.91816568374634 and batch: 200, loss is 5.380541858673095 and perplexity is 217.13990269294098
At time: 459.26279616355896 and batch: 250, loss is 5.386654968261719 and perplexity is 218.47136826522922
At time: 459.6059775352478 and batch: 300, loss is 5.43980001449585 and perplexity is 230.39610297227367
At time: 459.9479115009308 and batch: 350, loss is 5.482449321746826 and perplexity is 240.4348891597003
At time: 460.2892196178436 and batch: 400, loss is 5.40857515335083 and perplexity is 223.31317386149232
At time: 460.63390278816223 and batch: 450, loss is 5.42919885635376 and perplexity is 227.966538302735
At time: 460.97616744041443 and batch: 500, loss is 5.409840154647827 and perplexity is 223.59584406745753
At time: 461.3209524154663 and batch: 550, loss is 5.485650224685669 and perplexity is 241.2057309397152
At time: 461.6627674102783 and batch: 600, loss is 5.332470989227295 and perplexity is 206.9487109192017
At time: 462.006774187088 and batch: 650, loss is 5.49598466873169 and perplexity is 243.7113830299367
At time: 462.3502984046936 and batch: 700, loss is 5.4804967021942135 and perplexity is 239.96586935164083
At time: 462.69478011131287 and batch: 750, loss is 5.419304885864258 and perplexity is 225.7221652889218
At time: 463.037428855896 and batch: 800, loss is 5.386695184707642 and perplexity is 218.4801545838728
At time: 463.38455057144165 and batch: 850, loss is 5.3603306579589844 and perplexity is 212.7952972765543
At time: 463.7283968925476 and batch: 900, loss is 5.32499267578125 and perplexity is 205.4068560145274
At time: 464.08550333976746 and batch: 950, loss is 5.374842290878296 and perplexity is 215.9058193083162
At time: 464.42857027053833 and batch: 1000, loss is 5.437520961761475 and perplexity is 229.87161599756132
At time: 464.7724378108978 and batch: 1050, loss is 5.314623422622681 and perplexity is 203.28794507165782
At time: 465.1172420978546 and batch: 1100, loss is 5.4052158546447755 and perplexity is 222.5642568277926
At time: 465.45974111557007 and batch: 1150, loss is 5.4161172580719 and perplexity is 225.0037926021466
At time: 465.80321168899536 and batch: 1200, loss is 5.388577280044555 and perplexity is 218.8917422661554
At time: 466.1460165977478 and batch: 1250, loss is 5.411392269134521 and perplexity is 223.94315988342856
At time: 466.48884987831116 and batch: 1300, loss is 5.471360235214234 and perplexity is 237.78341425613252
At time: 466.832270860672 and batch: 1350, loss is 5.405219345092774 and perplexity is 222.56503367811308
At time: 467.1751039028168 and batch: 1400, loss is 5.317818336486816 and perplexity is 203.93847117986758
At time: 467.51990509033203 and batch: 1450, loss is 5.369281148910522 and perplexity is 214.7084687993571
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.493868835970887 and perplexity of 243.19627563426022
Finished 43 epochs...
Completing Train Step...
At time: 468.7725410461426 and batch: 50, loss is 5.457894668579102 and perplexity is 234.60298703060784
At time: 469.11502027511597 and batch: 100, loss is 5.453071994781494 and perplexity is 233.47429719127703
At time: 469.45858216285706 and batch: 150, loss is 5.445562267303467 and perplexity is 231.72753590604637
At time: 469.8015012741089 and batch: 200, loss is 5.37943021774292 and perplexity is 216.8986552046677
At time: 470.14635157585144 and batch: 250, loss is 5.385504150390625 and perplexity is 218.2200921245761
At time: 470.49194598197937 and batch: 300, loss is 5.439082527160645 and perplexity is 230.2308559747134
At time: 470.8371434211731 and batch: 350, loss is 5.481768178939819 and perplexity is 240.27117442728147
At time: 471.18159317970276 and batch: 400, loss is 5.407729368209839 and perplexity is 223.12437874855806
At time: 471.52501368522644 and batch: 450, loss is 5.4282262420654295 and perplexity is 227.74492258109953
At time: 471.869642496109 and batch: 500, loss is 5.408655471801758 and perplexity is 223.33111075001068
At time: 472.2153215408325 and batch: 550, loss is 5.48482494354248 and perplexity is 241.0067505170306
At time: 472.5589292049408 and batch: 600, loss is 5.3317366790771485 and perplexity is 206.7968021611115
At time: 472.9163167476654 and batch: 650, loss is 5.495067567825317 and perplexity is 243.48797755800544
At time: 473.2612853050232 and batch: 700, loss is 5.479322357177734 and perplexity is 239.68423203090154
At time: 473.6108646392822 and batch: 750, loss is 5.418310718536377 and perplexity is 225.4978711984151
At time: 473.953488111496 and batch: 800, loss is 5.38561674118042 and perplexity is 218.24466308030313
At time: 474.29686212539673 and batch: 850, loss is 5.359464588165284 and perplexity is 212.6110814807243
At time: 474.6398649215698 and batch: 900, loss is 5.324068307876587 and perplexity is 205.21707223795934
At time: 474.9837725162506 and batch: 950, loss is 5.373963699340821 and perplexity is 215.71620958952448
At time: 475.3278033733368 and batch: 1000, loss is 5.436919898986816 and perplexity is 229.73349024151807
At time: 475.6720607280731 and batch: 1050, loss is 5.313426084518433 and perplexity is 203.04468632943156
At time: 476.017050743103 and batch: 1100, loss is 5.404270401000977 and perplexity is 222.35393208201117
At time: 476.3621039390564 and batch: 1150, loss is 5.415449562072754 and perplexity is 224.85360861423712
At time: 476.7056653499603 and batch: 1200, loss is 5.387369365692138 and perplexity is 218.62749941254307
At time: 477.0504138469696 and batch: 1250, loss is 5.410433177947998 and perplexity is 223.72848093730096
At time: 477.3955645561218 and batch: 1300, loss is 5.4708091926574705 and perplexity is 237.65242157017187
At time: 477.7396788597107 and batch: 1350, loss is 5.404510660171509 and perplexity is 222.40736107144306
At time: 478.0838849544525 and batch: 1400, loss is 5.317017631530762 and perplexity is 203.775241993194
At time: 478.42805552482605 and batch: 1450, loss is 5.368432025909424 and perplexity is 214.52623228152805
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.493169279180021 and perplexity of 243.02620552191374
Finished 44 epochs...
Completing Train Step...
At time: 479.67859864234924 and batch: 50, loss is 5.457100706100464 and perplexity is 234.41679498605868
At time: 480.0217053890228 and batch: 100, loss is 5.452120780944824 and perplexity is 233.2523188004776
At time: 480.36557173728943 and batch: 150, loss is 5.444233989715576 and perplexity is 231.41994174404542
At time: 480.7087845802307 and batch: 200, loss is 5.378566207885743 and perplexity is 216.7113335640875
At time: 481.0511636734009 and batch: 250, loss is 5.3842666053771975 and perplexity is 217.95020197278845
At time: 481.3940987586975 and batch: 300, loss is 5.438312349319458 and perplexity is 230.0536055370255
At time: 481.73592829704285 and batch: 350, loss is 5.48090012550354 and perplexity is 240.0626967066729
At time: 482.09466314315796 and batch: 400, loss is 5.40704912185669 and perplexity is 222.97265081565294
At time: 482.4367551803589 and batch: 450, loss is 5.427320976257324 and perplexity is 227.53884618075014
At time: 482.7797112464905 and batch: 500, loss is 5.407669878005981 and perplexity is 223.11110542860072
At time: 483.12227964401245 and batch: 550, loss is 5.483948230743408 and perplexity is 240.7955494090747
At time: 483.4653649330139 and batch: 600, loss is 5.3311739349365235 and perplexity is 206.68046121055968
At time: 483.80740666389465 and batch: 650, loss is 5.49421088218689 and perplexity is 243.27947422815777
At time: 484.1502161026001 and batch: 700, loss is 5.478517007827759 and perplexity is 239.49128019768168
At time: 484.4922904968262 and batch: 750, loss is 5.4174476146698 and perplexity is 225.3033270818455
At time: 484.83840012550354 and batch: 800, loss is 5.384535722732544 and perplexity is 218.00886404787772
At time: 485.18209433555603 and batch: 850, loss is 5.358696441650391 and perplexity is 212.4478277288849
At time: 485.5257227420807 and batch: 900, loss is 5.323229894638062 and perplexity is 205.04508763498217
At time: 485.8689546585083 and batch: 950, loss is 5.373220739364624 and perplexity is 215.55600060138502
At time: 486.213995218277 and batch: 1000, loss is 5.436042470932007 and perplexity is 229.5320040398006
At time: 486.5575032234192 and batch: 1050, loss is 5.312651596069336 and perplexity is 202.88749144588724
At time: 486.8999819755554 and batch: 1100, loss is 5.403457918167114 and perplexity is 222.17334670034816
At time: 487.24252104759216 and batch: 1150, loss is 5.414818391799927 and perplexity is 224.71173247945123
At time: 487.5862374305725 and batch: 1200, loss is 5.386568050384522 and perplexity is 218.4523800228921
At time: 487.9286639690399 and batch: 1250, loss is 5.40981050491333 and perplexity is 223.58921460832764
At time: 488.2727949619293 and batch: 1300, loss is 5.470360765457153 and perplexity is 237.54587565094806
At time: 488.6148977279663 and batch: 1350, loss is 5.403746252059936 and perplexity is 222.23741604252115
At time: 488.95768213272095 and batch: 1400, loss is 5.3163316822052 and perplexity is 203.6355104332461
At time: 489.30211544036865 and batch: 1450, loss is 5.367444553375244 and perplexity is 214.3144980773497
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.492812979934562 and perplexity of 242.93963089241285
Finished 45 epochs...
Completing Train Step...
At time: 490.53623509407043 and batch: 50, loss is 5.456259393692017 and perplexity is 234.21966016530172
At time: 490.89276480674744 and batch: 100, loss is 5.4513242816925045 and perplexity is 233.06660747223634
At time: 491.2354214191437 and batch: 150, loss is 5.44322473526001 and perplexity is 231.18649795863914
At time: 491.57723331451416 and batch: 200, loss is 5.377757568359375 and perplexity is 216.5361630484024
At time: 491.921861410141 and batch: 250, loss is 5.383307514190673 and perplexity is 217.74126806432605
At time: 492.26696491241455 and batch: 300, loss is 5.437420978546142 and perplexity is 229.84863384321415
At time: 492.60887336730957 and batch: 350, loss is 5.480128059387207 and perplexity is 239.877423963357
At time: 492.9520089626312 and batch: 400, loss is 5.406517782211304 and perplexity is 222.85420807588602
At time: 493.2955319881439 and batch: 450, loss is 5.426657991409302 and perplexity is 227.38804136957216
At time: 493.6406078338623 and batch: 500, loss is 5.406638565063477 and perplexity is 222.88112666837569
At time: 493.98321294784546 and batch: 550, loss is 5.483322381973267 and perplexity is 240.64489495899005
At time: 494.32724809646606 and batch: 600, loss is 5.330415706634522 and perplexity is 206.52380963173445
At time: 494.67113184928894 and batch: 650, loss is 5.493393182754517 and perplexity is 243.0806260502742
At time: 495.01576495170593 and batch: 700, loss is 5.477889242172242 and perplexity is 239.34098297782995
At time: 495.35888147354126 and batch: 750, loss is 5.416758985519409 and perplexity is 225.14823005143413
At time: 495.70199394226074 and batch: 800, loss is 5.383554344177246 and perplexity is 217.79501977209242
At time: 496.04494857788086 and batch: 850, loss is 5.357838478088379 and perplexity is 212.26563340308735
At time: 496.3901574611664 and batch: 900, loss is 5.322520189285278 and perplexity is 204.8996176652396
At time: 496.73266220092773 and batch: 950, loss is 5.37220232963562 and perplexity is 215.33658801814593
At time: 497.076354265213 and batch: 1000, loss is 5.434996137619018 and perplexity is 229.2919626611223
At time: 497.41974997520447 and batch: 1050, loss is 5.311830778121948 and perplexity is 202.72102607983416
At time: 497.76364636421204 and batch: 1100, loss is 5.40270751953125 and perplexity is 222.00669066111146
At time: 498.10683846473694 and batch: 1150, loss is 5.414246978759766 and perplexity is 224.58336594388425
At time: 498.4491717815399 and batch: 1200, loss is 5.3856724262237545 and perplexity is 218.25681638219976
At time: 498.7929718494415 and batch: 1250, loss is 5.4092489528656005 and perplexity is 223.46369287380614
At time: 499.1376461982727 and batch: 1300, loss is 5.469907398223877 and perplexity is 237.4382045436483
At time: 499.4820337295532 and batch: 1350, loss is 5.402724752426147 and perplexity is 222.01051651204318
At time: 499.8265516757965 and batch: 1400, loss is 5.315162544250488 and perplexity is 203.39757154786534
At time: 500.1710844039917 and batch: 1450, loss is 5.366513471603394 and perplexity is 214.11504662196282
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.492240710136218 and perplexity of 242.80064365172555
Finished 46 epochs...
Completing Train Step...
At time: 501.4052414894104 and batch: 50, loss is 5.455510683059693 and perplexity is 234.04436304703353
At time: 501.76506209373474 and batch: 100, loss is 5.450258350372314 and perplexity is 232.81830683486442
At time: 502.10932207107544 and batch: 150, loss is 5.44217924118042 and perplexity is 230.94492014983152
At time: 502.45213317871094 and batch: 200, loss is 5.37698727607727 and perplexity is 216.36943113760591
At time: 502.79532265663147 and batch: 250, loss is 5.382363376617431 and perplexity is 217.53578736818775
At time: 503.14052534103394 and batch: 300, loss is 5.436379880905151 and perplexity is 229.60946349418077
At time: 503.48496675491333 and batch: 350, loss is 5.479489555358887 and perplexity is 239.72431014894892
At time: 503.82664132118225 and batch: 400, loss is 5.405834283828735 and perplexity is 222.70193962866418
At time: 504.1706008911133 and batch: 450, loss is 5.425889472961426 and perplexity is 227.21335659778586
At time: 504.51513743400574 and batch: 500, loss is 5.405663499832153 and perplexity is 222.663908948976
At time: 504.8594832420349 and batch: 550, loss is 5.482302074432373 and perplexity is 240.39948837436987
At time: 505.20278787612915 and batch: 600, loss is 5.329382743835449 and perplexity is 206.3105883630405
At time: 505.54693818092346 and batch: 650, loss is 5.49220027923584 and perplexity is 242.7908272015357
At time: 505.8898344039917 and batch: 700, loss is 5.476939783096314 and perplexity is 239.11384635482736
At time: 506.2347753047943 and batch: 750, loss is 5.415866003036499 and perplexity is 224.94726636781903
At time: 506.5777449607849 and batch: 800, loss is 5.382680463790893 and perplexity is 217.60477611327624
At time: 506.9221901893616 and batch: 850, loss is 5.357122840881348 and perplexity is 212.11378255958763
At time: 507.266539812088 and batch: 900, loss is 5.321730327606201 and perplexity is 204.7378392089008
At time: 507.61020374298096 and batch: 950, loss is 5.371322040557861 and perplexity is 215.1471129803104
At time: 507.9525640010834 and batch: 1000, loss is 5.434141654968261 and perplexity is 229.09612034091882
At time: 508.314284324646 and batch: 1050, loss is 5.311135578155517 and perplexity is 202.58014340579794
At time: 508.6573565006256 and batch: 1100, loss is 5.40208173751831 and perplexity is 221.86780632753462
At time: 509.0012540817261 and batch: 1150, loss is 5.413755340576172 and perplexity is 224.47297932314842
At time: 509.3452134132385 and batch: 1200, loss is 5.384994125366211 and perplexity is 218.10882279424592
At time: 509.68664836883545 and batch: 1250, loss is 5.408740901947022 and perplexity is 223.35019077423698
At time: 510.0285849571228 and batch: 1300, loss is 5.469340229034424 and perplexity is 237.30357509207957
At time: 510.3720624446869 and batch: 1350, loss is 5.401829099655151 and perplexity is 221.81176119889903
At time: 510.7162997722626 and batch: 1400, loss is 5.314378032684326 and perplexity is 203.23806637546377
At time: 511.0595738887787 and batch: 1450, loss is 5.365635147094727 and perplexity is 213.9270666946138
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.491751907218216 and perplexity of 242.68199098986193
Finished 47 epochs...
Completing Train Step...
At time: 512.310075044632 and batch: 50, loss is 5.454961175918579 and perplexity is 233.9157893275257
At time: 512.6533527374268 and batch: 100, loss is 5.449500226974488 and perplexity is 232.6418687183934
At time: 512.9977786540985 and batch: 150, loss is 5.441153659820556 and perplexity is 230.70818875897137
At time: 513.341325044632 and batch: 200, loss is 5.376367750167847 and perplexity is 216.23542618306578
At time: 513.6841826438904 and batch: 250, loss is 5.38146674156189 and perplexity is 217.3408245736984
At time: 514.0282316207886 and batch: 300, loss is 5.435707902908325 and perplexity is 229.45522281582464
At time: 514.3719925880432 and batch: 350, loss is 5.478928394317627 and perplexity is 239.58982394318926
At time: 514.7156047821045 and batch: 400, loss is 5.4052972412109375 and perplexity is 222.58237130553377
At time: 515.0606253147125 and batch: 450, loss is 5.425182933807373 and perplexity is 227.05287816385007
At time: 515.404180765152 and batch: 500, loss is 5.404868288040161 and perplexity is 222.4869143663454
At time: 515.74888920784 and batch: 550, loss is 5.481509275436402 and perplexity is 240.20897543056853
At time: 516.0936150550842 and batch: 600, loss is 5.328713254928589 and perplexity is 206.17251193823833
At time: 516.4361681938171 and batch: 650, loss is 5.491391820907593 and perplexity is 242.5946202585179
At time: 516.7790389060974 and batch: 700, loss is 5.476196870803833 and perplexity is 238.93627170842913
At time: 517.1463088989258 and batch: 750, loss is 5.4152066516876225 and perplexity is 224.798995970828
At time: 517.4909284114838 and batch: 800, loss is 5.381846504211426 and perplexity is 217.423378175486
At time: 517.8337061405182 and batch: 850, loss is 5.356514225006103 and perplexity is 211.9847260210764
At time: 518.1756665706635 and batch: 900, loss is 5.321081495285034 and perplexity is 204.60504176775086
At time: 518.5199761390686 and batch: 950, loss is 5.370852842330932 and perplexity is 215.0461900146609
At time: 518.8644173145294 and batch: 1000, loss is 5.4335391807556155 and perplexity is 228.95813740594997
At time: 519.207525730133 and batch: 1050, loss is 5.310590200424194 and perplexity is 202.4696908287018
At time: 519.5504295825958 and batch: 1100, loss is 5.401600799560547 and perplexity is 221.76112733291114
At time: 519.8933119773865 and batch: 1150, loss is 5.413217678070068 and perplexity is 224.3523210581522
At time: 520.2379755973816 and batch: 1200, loss is 5.384385433197021 and perplexity is 217.97610205891394
At time: 520.5802674293518 and batch: 1250, loss is 5.408288507461548 and perplexity is 223.2491712316661
At time: 520.9236824512482 and batch: 1300, loss is 5.468821315765381 and perplexity is 237.18046706213053
At time: 521.2651772499084 and batch: 1350, loss is 5.401005554199219 and perplexity is 221.62916432962248
At time: 521.611515045166 and batch: 1400, loss is 5.313700704574585 and perplexity is 203.10045412972053
At time: 521.955470085144 and batch: 1450, loss is 5.3647027111053465 and perplexity is 213.7276863676671
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.4912495409321584 and perplexity of 242.5601063572838
Finished 48 epochs...
Completing Train Step...
At time: 523.2322995662689 and batch: 50, loss is 5.454106206893921 and perplexity is 233.71588404186284
At time: 523.5768280029297 and batch: 100, loss is 5.4485847282409665 and perplexity is 232.42898284546024
At time: 523.9191689491272 and batch: 150, loss is 5.440108289718628 and perplexity is 230.4671393310568
At time: 524.2618727684021 and batch: 200, loss is 5.375500955581665 and perplexity is 216.04807569523405
At time: 524.6045708656311 and batch: 250, loss is 5.380571498870849 and perplexity is 217.14633885798122
At time: 524.9488456249237 and batch: 300, loss is 5.434513816833496 and perplexity is 229.18139704776777
At time: 525.2932207584381 and batch: 350, loss is 5.478009386062622 and perplexity is 239.36974006211176
At time: 525.6368398666382 and batch: 400, loss is 5.4046970558166505 and perplexity is 222.4488206988212
At time: 525.9795165061951 and batch: 450, loss is 5.4243943405151365 and perplexity is 226.87389636834413
At time: 526.3377621173859 and batch: 500, loss is 5.40389386177063 and perplexity is 222.27022286445165
At time: 526.6798102855682 and batch: 550, loss is 5.480863218307495 and perplexity is 240.05383682916005
At time: 527.0231535434723 and batch: 600, loss is 5.328010807037353 and perplexity is 206.02773734625302
At time: 527.3672950267792 and batch: 650, loss is 5.490600843429565 and perplexity is 242.4028092466984
At time: 527.7113814353943 and batch: 700, loss is 5.475376300811767 and perplexity is 238.7402881939414
At time: 528.0536556243896 and batch: 750, loss is 5.414363422393799 and perplexity is 224.60951876979357
At time: 528.3965590000153 and batch: 800, loss is 5.3808706188201905 and perplexity is 217.2113013751681
At time: 528.740168094635 and batch: 850, loss is 5.35568751335144 and perplexity is 211.80954819821523
At time: 529.0853650569916 and batch: 900, loss is 5.320091896057129 and perplexity is 204.40266492888946
At time: 529.4299690723419 and batch: 950, loss is 5.370099191665649 and perplexity is 214.88418136712056
At time: 529.7744965553284 and batch: 1000, loss is 5.432978582382202 and perplexity is 228.8298198172168
At time: 530.1171109676361 and batch: 1050, loss is 5.309548196792602 and perplexity is 202.25882655531953
At time: 530.4606339931488 and batch: 1100, loss is 5.400857753753662 and perplexity is 221.59640986100848
At time: 530.8036270141602 and batch: 1150, loss is 5.412347755432129 and perplexity is 224.1572367616152
At time: 531.1462936401367 and batch: 1200, loss is 5.383751964569091 and perplexity is 217.83806476238559
At time: 531.4893734455109 and batch: 1250, loss is 5.407242164611817 and perplexity is 223.01569822534594
At time: 531.834558725357 and batch: 1300, loss is 5.467423582077027 and perplexity is 236.84918351012328
At time: 532.1770071983337 and batch: 1350, loss is 5.399747085571289 and perplexity is 221.35042640753207
At time: 532.5201523303986 and batch: 1400, loss is 5.313111228942871 and perplexity is 202.9807666411157
At time: 532.862954378128 and batch: 1450, loss is 5.363936166763306 and perplexity is 213.56391739505338
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.491238585904113 and perplexity of 242.55744911907098
Finished 49 epochs...
Completing Train Step...
At time: 534.1029524803162 and batch: 50, loss is 5.453671455383301 and perplexity is 233.61429779220748
At time: 534.4621157646179 and batch: 100, loss is 5.447611875534058 and perplexity is 232.20297363499648
At time: 534.8057150840759 and batch: 150, loss is 5.439509382247925 and perplexity is 230.32915216445687
At time: 535.1647515296936 and batch: 200, loss is 5.37485221862793 and perplexity is 215.9079627778747
At time: 535.5071978569031 and batch: 250, loss is 5.379919090270996 and perplexity is 217.00471692179147
At time: 535.8512704372406 and batch: 300, loss is 5.433884201049804 and perplexity is 229.03714623891634
At time: 536.1938080787659 and batch: 350, loss is 5.477432594299317 and perplexity is 239.23171337781338
At time: 536.5377449989319 and batch: 400, loss is 5.404181613922119 and perplexity is 222.3341908023073
At time: 536.8790109157562 and batch: 450, loss is 5.423605756759644 and perplexity is 226.69505782297634
At time: 537.2222993373871 and batch: 500, loss is 5.4032003116607665 and perplexity is 222.11612077190333
At time: 537.5671772956848 and batch: 550, loss is 5.48022891998291 and perplexity is 239.90161936339433
At time: 537.9115104675293 and batch: 600, loss is 5.3274353408813475 and perplexity is 205.90920946387521
At time: 538.2556698322296 and batch: 650, loss is 5.489900903701782 and perplexity is 242.23320125499075
At time: 538.5996735095978 and batch: 700, loss is 5.474632062911987 and perplexity is 238.5626747247989
At time: 538.943375825882 and batch: 750, loss is 5.413712587356567 and perplexity is 224.4633825857153
At time: 539.2857737541199 and batch: 800, loss is 5.380071935653686 and perplexity is 217.0378876257248
At time: 539.6291453838348 and batch: 850, loss is 5.355052270889282 and perplexity is 211.67504050633113
At time: 539.9733154773712 and batch: 900, loss is 5.319469413757324 and perplexity is 204.27546748112553
At time: 540.3170192241669 and batch: 950, loss is 5.369547386169433 and perplexity is 214.76563980374326
At time: 540.6645820140839 and batch: 1000, loss is 5.432367734909057 and perplexity is 228.69008238347544
At time: 541.006765127182 and batch: 1050, loss is 5.308871574401856 and perplexity is 202.12201999295712
At time: 541.3493256568909 and batch: 1100, loss is 5.400351486206055 and perplexity is 221.48425118357432
At time: 541.6938543319702 and batch: 1150, loss is 5.4118750953674315 and perplexity is 224.05131162284857
At time: 542.0390629768372 and batch: 1200, loss is 5.38326132774353 and perplexity is 217.73121160099564
At time: 542.3828892707825 and batch: 1250, loss is 5.4069414138793945 and perplexity is 222.9486361757488
At time: 542.7286694049835 and batch: 1300, loss is 5.46757321357727 and perplexity is 236.8846262603932
At time: 543.0783958435059 and batch: 1350, loss is 5.3991819095611575 and perplexity is 221.22535980234568
At time: 543.4250245094299 and batch: 1400, loss is 5.311449451446533 and perplexity is 202.64373788188482
At time: 543.7693381309509 and batch: 1450, loss is 5.362378969192505 and perplexity is 213.2316149790814
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.489877554086538 and perplexity of 242.22754526897492
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f3cbdcfe358>
SETTINGS FOR THIS RUN
{'lr': 28.981646950798023, 'batch_size': 20, 'dropout': 0.8673038668667764, 'wordvec_source': 'glove', 'anneal': 3.365168688768163, 'num_layers': 1, 'seq_len': 35, 'wordvec_dim': 200, 'tune_wordvecs': True, 'data': 'ptb'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.6419219970703125 and batch: 50, loss is 6.982017240524292 and perplexity is 1077.0889244181312
At time: 0.9957540035247803 and batch: 100, loss is 6.499922552108765 and perplexity is 665.0901212222765
At time: 1.3470633029937744 and batch: 150, loss is 6.382131204605103 and perplexity is 591.1863049935439
At time: 1.6978175640106201 and batch: 200, loss is 6.211714839935302 and perplexity is 498.5554614759067
At time: 2.0494751930236816 and batch: 250, loss is 6.163250036239624 and perplexity is 474.96923629362647
At time: 2.403756856918335 and batch: 300, loss is 6.2385027217864994 and perplexity is 512.0911936548654
At time: 2.7564592361450195 and batch: 350, loss is 6.263367252349854 and perplexity is 524.9837198754973
At time: 3.1073319911956787 and batch: 400, loss is 6.16295970916748 and perplexity is 474.83135988149076
At time: 3.458455801010132 and batch: 450, loss is 6.211872882843018 and perplexity is 498.63426085737353
At time: 3.8091928958892822 and batch: 500, loss is 6.188071546554565 and perplexity is 486.90622426064493
At time: 4.1772918701171875 and batch: 550, loss is 6.240273132324218 and perplexity is 512.998608311607
At time: 4.527099609375 and batch: 600, loss is 6.0663337230682375 and perplexity is 431.0972587796758
At time: 4.87700629234314 and batch: 650, loss is 6.297577800750733 and perplexity is 543.2544446800931
At time: 5.2290472984313965 and batch: 700, loss is 6.227954235076904 and perplexity is 506.7177969314422
At time: 5.5818376541137695 and batch: 750, loss is 6.188866710662841 and perplexity is 487.29354858706637
At time: 5.932379722595215 and batch: 800, loss is 6.186486225128174 and perplexity is 486.13493292455894
At time: 6.284592151641846 and batch: 850, loss is 6.141859626770019 and perplexity is 464.9173401977369
At time: 6.636363506317139 and batch: 900, loss is 6.106934700012207 and perplexity is 448.960405455111
At time: 6.988864421844482 and batch: 950, loss is 6.119765539169311 and perplexity is 454.75805904680846
At time: 7.342416048049927 and batch: 1000, loss is 6.206238460540772 and perplexity is 495.83264501257145
At time: 7.693303346633911 and batch: 1050, loss is 6.065679111480713 and perplexity is 430.81514986468494
At time: 8.044225931167603 and batch: 1100, loss is 6.130482692718505 and perplexity is 459.65798070046003
At time: 8.395265579223633 and batch: 1150, loss is 6.205678148269653 and perplexity is 495.5549017159049
At time: 8.745469093322754 and batch: 1200, loss is 6.177077665328979 and perplexity is 481.58255259068164
At time: 9.096184968948364 and batch: 1250, loss is 6.179626350402832 and perplexity is 482.8115203148847
At time: 9.448688983917236 and batch: 1300, loss is 6.243849058151245 and perplexity is 514.8363371169557
At time: 9.80140233039856 and batch: 1350, loss is 6.2044659614562985 and perplexity is 494.9545605350947
At time: 10.151805639266968 and batch: 1400, loss is 6.127149696350098 and perplexity is 458.1284926250823
At time: 10.502249240875244 and batch: 1450, loss is 6.174121894836426 and perplexity is 480.16120671291645
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 6.040352063301282 and perplexity of 420.0408898403466
Finished 1 epochs...
Completing Train Step...
At time: 11.763579368591309 and batch: 50, loss is 6.304239234924316 and perplexity is 546.8853785896579
At time: 12.103142738342285 and batch: 100, loss is 6.820873336791992 and perplexity is 916.7853229118192
At time: 12.445281267166138 and batch: 150, loss is 6.9663365650177 and perplexity is 1060.331172309047
At time: 12.787600994110107 and batch: 200, loss is 6.752221841812133 and perplexity is 855.9584556220274
At time: 13.127807855606079 and batch: 250, loss is 6.989526290893554 and perplexity is 1085.2072818344764
At time: 13.470159530639648 and batch: 300, loss is 6.816864986419677 and perplexity is 913.117881227372
At time: 13.81393575668335 and batch: 350, loss is 6.907497272491455 and perplexity is 999.7420267901307
At time: 14.155455350875854 and batch: 400, loss is 6.64293327331543 and perplexity is 767.342520441444
At time: 14.49722671508789 and batch: 450, loss is 6.945913915634155 and perplexity is 1038.89602679446
At time: 14.837555646896362 and batch: 500, loss is 7.163836488723755 and perplexity is 1291.8576351046581
At time: 15.18033218383789 and batch: 550, loss is 6.997605457305908 and perplexity is 1094.010364959536
At time: 15.521942615509033 and batch: 600, loss is 6.6264139175415036 and perplexity is 754.7706419057166
At time: 15.86399531364441 and batch: 650, loss is 6.942663354873657 and perplexity is 1035.5245147565483
At time: 16.205633640289307 and batch: 700, loss is 7.137044887542725 and perplexity is 1257.706228761613
At time: 16.562155723571777 and batch: 750, loss is 6.895093336105346 and perplexity is 987.4178822529743
At time: 16.904463052749634 and batch: 800, loss is 7.0574813556671145 and perplexity is 1161.5160328255538
At time: 17.245688438415527 and batch: 850, loss is 6.789139986038208 and perplexity is 888.1494123933273
At time: 17.58706831932068 and batch: 900, loss is 6.802590093612671 and perplexity is 900.1758144299067
At time: 17.928726196289062 and batch: 950, loss is 7.014695997238159 and perplexity is 1112.8682797513552
At time: 18.2707576751709 and batch: 1000, loss is 7.118335847854614 and perplexity is 1234.3945029891502
At time: 18.611817359924316 and batch: 1050, loss is 6.709631223678588 and perplexity is 820.2680882190473
At time: 18.954301357269287 and batch: 1100, loss is 7.076697750091553 and perplexity is 1184.052019765487
At time: 19.297415494918823 and batch: 1150, loss is 6.878447494506836 and perplexity is 971.1175235668339
At time: 19.637946128845215 and batch: 1200, loss is 6.8825282382965085 and perplexity is 975.0885021326837
At time: 19.98042106628418 and batch: 1250, loss is 6.9814529132843015 and perplexity is 1076.4812652736205
At time: 20.320822715759277 and batch: 1300, loss is 6.824762935638428 and perplexity is 920.3581940595034
At time: 20.66119122505188 and batch: 1350, loss is 7.0076928806304934 and perplexity is 1105.101959383552
At time: 21.0063579082489 and batch: 1400, loss is 7.087738656997681 and perplexity is 1197.1974631587987
At time: 21.351652145385742 and batch: 1450, loss is 6.770200862884521 and perplexity is 871.4869257892246
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 6.173621544471154 and perplexity of 479.92101797202145
Annealing...
Finished 2 epochs...
Completing Train Step...
At time: 22.588598012924194 and batch: 50, loss is 6.077972145080566 and perplexity is 436.14386088362045
At time: 22.946746349334717 and batch: 100, loss is 6.084138402938843 and perplexity is 438.8415451537754
At time: 23.289865732192993 and batch: 150, loss is 6.107707929611206 and perplexity is 449.3076891771111
At time: 23.631853580474854 and batch: 200, loss is 6.021810636520386 and perplexity is 412.32449003105296
At time: 23.97527837753296 and batch: 250, loss is 5.988832139968872 and perplexity is 398.9484218425291
At time: 24.31999969482422 and batch: 300, loss is 6.091068305969238 and perplexity is 441.89323625636484
At time: 24.663095712661743 and batch: 350, loss is 6.122565660476685 and perplexity is 456.0332212488935
At time: 25.021960973739624 and batch: 400, loss is 6.030664806365967 and perplexity is 415.9914912665753
At time: 25.365818738937378 and batch: 450, loss is 6.071368789672851 and perplexity is 433.2733359401129
At time: 25.705796003341675 and batch: 500, loss is 6.048932151794434 and perplexity is 423.66038342862475
At time: 26.04379892349243 and batch: 550, loss is 6.105860834121704 and perplexity is 448.47854096473304
At time: 26.386290073394775 and batch: 600, loss is 5.925931224822998 and perplexity is 374.6271350637032
At time: 26.729681253433228 and batch: 650, loss is 6.140960340499878 and perplexity is 464.4994343536043
At time: 27.07459783554077 and batch: 700, loss is 6.06313850402832 and perplexity is 429.72200689591256
At time: 27.41870880126953 and batch: 750, loss is 6.020748062133789 and perplexity is 411.8865972769923
At time: 27.761964321136475 and batch: 800, loss is 5.967328958511352 and perplexity is 390.4613382089427
At time: 28.10487985610962 and batch: 850, loss is 5.943403186798096 and perplexity is 381.23012171489853
At time: 28.447905778884888 and batch: 900, loss is 5.8886379051208495 and perplexity is 360.9133511910352
At time: 28.79019522666931 and batch: 950, loss is 5.92545407295227 and perplexity is 374.448423665012
At time: 29.13375687599182 and batch: 1000, loss is 6.002304992675781 and perplexity is 404.3597664376573
At time: 29.478920459747314 and batch: 1050, loss is 5.8457896900177 and perplexity is 345.7754894472545
At time: 29.82483172416687 and batch: 1100, loss is 5.946156072616577 and perplexity is 382.2810505904493
At time: 30.173661947250366 and batch: 1150, loss is 5.969169788360595 and perplexity is 391.1807730707176
At time: 30.516562938690186 and batch: 1200, loss is 5.9240406799316405 and perplexity is 373.91955471430254
At time: 30.8610622882843 and batch: 1250, loss is 5.950948486328125 and perplexity is 384.1174965284726
At time: 31.20818305015564 and batch: 1300, loss is 6.031997394561768 and perplexity is 416.54620613854786
At time: 31.55250072479248 and batch: 1350, loss is 5.965005683898926 and perplexity is 389.5552422571706
At time: 31.896095752716064 and batch: 1400, loss is 5.909409255981445 and perplexity is 368.4884087760375
At time: 32.24067497253418 and batch: 1450, loss is 5.916880416870117 and perplexity is 371.2517548112756
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 6.055491912059295 and perplexity of 426.448629090905
Annealing...
Finished 3 epochs...
Completing Train Step...
At time: 33.51449203491211 and batch: 50, loss is 5.927644157409668 and perplexity is 375.26939600901585
At time: 33.85932278633118 and batch: 100, loss is 5.872880620956421 and perplexity is 355.27090849138256
At time: 34.223036766052246 and batch: 150, loss is 5.849297924041748 and perplexity is 346.99068112606034
At time: 34.56762623786926 and batch: 200, loss is 5.7735497093200685 and perplexity is 321.67757027362035
At time: 34.914374113082886 and batch: 250, loss is 5.773528785705566 and perplexity is 321.6708396865602
At time: 35.259363651275635 and batch: 300, loss is 5.843166627883911 and perplexity is 344.8696873610305
At time: 35.61239695549011 and batch: 350, loss is 5.863945360183716 and perplexity is 352.1106103492613
At time: 35.96599268913269 and batch: 400, loss is 5.756642513275146 and perplexity is 316.2846228051685
At time: 36.32817101478577 and batch: 450, loss is 5.8066690731048585 and perplexity is 332.50971346735486
At time: 36.672425508499146 and batch: 500, loss is 5.796896724700928 and perplexity is 329.27613824499576
At time: 37.016594648361206 and batch: 550, loss is 5.834828786849975 and perplexity is 342.00617308299184
At time: 37.36263132095337 and batch: 600, loss is 5.702919864654541 and perplexity is 299.74132858181804
At time: 37.7083945274353 and batch: 650, loss is 5.883652820587158 and perplexity is 359.1186447244307
At time: 38.054638624191284 and batch: 700, loss is 5.826832008361817 and perplexity is 339.28213176926005
At time: 38.39976501464844 and batch: 750, loss is 5.764263496398926 and perplexity is 318.70423076281656
At time: 38.742201805114746 and batch: 800, loss is 5.76247501373291 and perplexity is 318.13474318164526
At time: 39.08711814880371 and batch: 850, loss is 5.717803182601929 and perplexity is 304.235837715533
At time: 39.431885957717896 and batch: 900, loss is 5.671179323196411 and perplexity is 290.3767806156922
At time: 39.777496099472046 and batch: 950, loss is 5.729564542770386 and perplexity is 307.83519012778726
At time: 40.12099003791809 and batch: 1000, loss is 5.790279150009155 and perplexity is 327.1043228071055
At time: 40.465155363082886 and batch: 1050, loss is 5.652213382720947 and perplexity is 284.92140853706906
At time: 40.80986452102661 and batch: 1100, loss is 5.7486124610900875 and perplexity is 313.75501082959744
At time: 41.15696120262146 and batch: 1150, loss is 5.759519853591919 and perplexity is 317.1959918325889
At time: 41.50153875350952 and batch: 1200, loss is 5.72276029586792 and perplexity is 305.74771339622043
At time: 41.843674182891846 and batch: 1250, loss is 5.740356369018555 and perplexity is 311.1752844550037
At time: 42.190391302108765 and batch: 1300, loss is 5.801591281890869 and perplexity is 330.82557802845065
At time: 42.53523516654968 and batch: 1350, loss is 5.738010568618774 and perplexity is 310.44618484374666
At time: 42.88165259361267 and batch: 1400, loss is 5.648118600845337 and perplexity is 283.75710293300955
At time: 43.228034019470215 and batch: 1450, loss is 5.693186187744141 and perplexity is 296.8378967898441
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.778438209468483 and perplexity of 323.2539410287129
Finished 4 epochs...
Completing Train Step...
At time: 44.49717330932617 and batch: 50, loss is 5.77767394065857 and perplexity is 323.00698250727163
At time: 44.84267210960388 and batch: 100, loss is 5.803174600601197 and perplexity is 331.3497952479507
At time: 45.18861126899719 and batch: 150, loss is 5.781212491989136 and perplexity is 324.15198392340085
At time: 45.53236222267151 and batch: 200, loss is 5.720431499481201 and perplexity is 305.03651766246185
At time: 45.875473737716675 and batch: 250, loss is 5.731322593688965 and perplexity is 308.3768560651993
At time: 46.22042536735535 and batch: 300, loss is 5.793994035720825 and perplexity is 328.3217378609563
At time: 46.57017731666565 and batch: 350, loss is 5.81868013381958 and perplexity is 336.52758899418205
At time: 46.918835163116455 and batch: 400, loss is 5.7196590614318845 and perplexity is 304.80098682798854
At time: 47.267836809158325 and batch: 450, loss is 5.764597826004028 and perplexity is 318.8108008362044
At time: 47.611921548843384 and batch: 500, loss is 5.750298261642456 and perplexity is 314.2843852846666
At time: 47.95629668235779 and batch: 550, loss is 5.7917293930053715 and perplexity is 327.579047710318
At time: 48.30007004737854 and batch: 600, loss is 5.657406482696533 and perplexity is 286.4048824771334
At time: 48.64570593833923 and batch: 650, loss is 5.842037763595581 and perplexity is 344.4805959438633
At time: 48.988914489746094 and batch: 700, loss is 5.792518978118896 and perplexity is 327.83780139047644
At time: 49.33655762672424 and batch: 750, loss is 5.7327674293518065 and perplexity is 308.8227319755798
At time: 49.680702447891235 and batch: 800, loss is 5.724341878890991 and perplexity is 306.2316613901573
At time: 50.025073528289795 and batch: 850, loss is 5.672655735015869 and perplexity is 290.80581296297015
At time: 50.37018275260925 and batch: 900, loss is 5.6354405975341795 and perplexity is 280.18233776617006
At time: 50.713459968566895 and batch: 950, loss is 5.690622844696045 and perplexity is 296.0779738184332
At time: 51.059709548950195 and batch: 1000, loss is 5.754546852111816 and perplexity is 315.6224914484107
At time: 51.40323281288147 and batch: 1050, loss is 5.612017059326172 and perplexity is 273.6957421587289
At time: 51.771769762039185 and batch: 1100, loss is 5.7104669857025145 and perplexity is 302.0120706761695
At time: 52.117647647857666 and batch: 1150, loss is 5.707494878768921 and perplexity is 301.1157910860438
At time: 52.46204853057861 and batch: 1200, loss is 5.6822281837463375 and perplexity is 293.60290283930505
At time: 52.804022550582886 and batch: 1250, loss is 5.7081953716278075 and perplexity is 301.32679444194144
At time: 53.149731159210205 and batch: 1300, loss is 5.771653490066528 and perplexity is 321.06817702563734
At time: 53.494415283203125 and batch: 1350, loss is 5.710059051513672 and perplexity is 301.8888947526409
At time: 53.839617013931274 and batch: 1400, loss is 5.624251136779785 and perplexity is 277.06472323447707
At time: 54.181453227996826 and batch: 1450, loss is 5.6659492492675785 and perplexity is 288.86205310706026
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.760518913595085 and perplexity of 317.51304801389654
Finished 5 epochs...
Completing Train Step...
At time: 55.43647313117981 and batch: 50, loss is 5.7531313133239745 and perplexity is 315.1760316345916
At time: 55.79959583282471 and batch: 100, loss is 5.776505851745606 and perplexity is 322.6299019069043
At time: 56.14306044578552 and batch: 150, loss is 5.7424893283844 and perplexity is 311.8397170443548
At time: 56.488553524017334 and batch: 200, loss is 5.690823640823364 and perplexity is 296.1374310981564
At time: 56.834328174591064 and batch: 250, loss is 5.705101442337036 and perplexity is 300.39595137037867
At time: 57.178003549575806 and batch: 300, loss is 5.767800378799438 and perplexity is 319.8334459210171
At time: 57.521456241607666 and batch: 350, loss is 5.7914125442504885 and perplexity is 327.47527113853215
At time: 57.867769718170166 and batch: 400, loss is 5.6884769821167 and perplexity is 295.44331236551585
At time: 58.21297860145569 and batch: 450, loss is 5.731218719482422 and perplexity is 308.34482532757187
At time: 58.55615186691284 and batch: 500, loss is 5.714790630340576 and perplexity is 303.3206905111444
At time: 58.89966821670532 and batch: 550, loss is 5.76264796257019 and perplexity is 318.18976897376314
At time: 59.245219469070435 and batch: 600, loss is 5.623211011886597 and perplexity is 276.77669113946024
At time: 59.59124827384949 and batch: 650, loss is 5.810805568695068 and perplexity is 333.88798707691217
At time: 59.93488812446594 and batch: 700, loss is 5.77110520362854 and perplexity is 320.8921879491253
At time: 60.27698802947998 and batch: 750, loss is 5.709451389312744 and perplexity is 301.7055040078749
At time: 60.63796257972717 and batch: 800, loss is 5.693770227432251 and perplexity is 297.0113125384148
At time: 60.98254990577698 and batch: 850, loss is 5.643259391784668 and perplexity is 282.3816124518085
At time: 61.32696986198425 and batch: 900, loss is 5.604689884185791 and perplexity is 271.69765462874585
At time: 61.67073917388916 and batch: 950, loss is 5.66615626335144 and perplexity is 288.921857810341
At time: 62.01751923561096 and batch: 1000, loss is 5.72914213180542 and perplexity is 307.70518462788243
At time: 62.36233043670654 and batch: 1050, loss is 5.589715127944946 and perplexity is 267.65936018006903
At time: 62.70548486709595 and batch: 1100, loss is 5.690259227752685 and perplexity is 295.9703344215374
At time: 63.05018138885498 and batch: 1150, loss is 5.687833566665649 and perplexity is 295.2532807146363
At time: 63.394458055496216 and batch: 1200, loss is 5.6621089553833 and perplexity is 287.7548652552017
At time: 63.73885178565979 and batch: 1250, loss is 5.686257514953613 and perplexity is 294.7883127790833
At time: 64.08146023750305 and batch: 1300, loss is 5.748080797195435 and perplexity is 313.5882429547302
At time: 64.42668533325195 and batch: 1350, loss is 5.687899169921875 and perplexity is 295.27265092663004
At time: 64.7731294631958 and batch: 1400, loss is 5.598029117584229 and perplexity is 269.8939536492436
At time: 65.12036347389221 and batch: 1450, loss is 5.647123584747314 and perplexity is 283.4749004689432
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.74227305355235 and perplexity of 311.7722812545196
Finished 6 epochs...
Completing Train Step...
At time: 66.37821650505066 and batch: 50, loss is 5.7285202121734615 and perplexity is 307.5138762280979
At time: 66.73741579055786 and batch: 100, loss is 5.754361009597778 and perplexity is 315.56384082117177
At time: 67.08181858062744 and batch: 150, loss is 5.717358245849609 and perplexity is 304.1005021200834
At time: 67.4244544506073 and batch: 200, loss is 5.673747282028199 and perplexity is 291.1234144862403
At time: 67.76975917816162 and batch: 250, loss is 5.68667142868042 and perplexity is 294.91035496397
At time: 68.1129834651947 and batch: 300, loss is 5.746730365753174 and perplexity is 313.16504934281426
At time: 68.45771431922913 and batch: 350, loss is 5.771859331130981 and perplexity is 321.13427284334165
At time: 68.80178809165955 and batch: 400, loss is 5.670713405609131 and perplexity is 290.24152047915067
At time: 69.14618229866028 and batch: 450, loss is 5.717150917053223 and perplexity is 304.0374598644617
At time: 69.49129819869995 and batch: 500, loss is 5.701351356506348 and perplexity is 299.27155038736305
At time: 69.85073685646057 and batch: 550, loss is 5.746551685333252 and perplexity is 313.1090978791571
At time: 70.19508075714111 and batch: 600, loss is 5.607269325256348 and perplexity is 272.3993873679107
At time: 70.53815698623657 and batch: 650, loss is 5.789890985488892 and perplexity is 326.97737715406026
At time: 70.88375449180603 and batch: 700, loss is 5.748194580078125 and perplexity is 313.62392595901036
At time: 71.22798943519592 and batch: 750, loss is 5.690033168792724 and perplexity is 295.9034352374237
At time: 71.57141304016113 and batch: 800, loss is 5.6746087169647215 and perplexity is 291.3743064143397
At time: 71.91790580749512 and batch: 850, loss is 5.625340671539306 and perplexity is 277.36675939064503
At time: 72.26426601409912 and batch: 900, loss is 5.583685989379883 and perplexity is 266.05045982459046
At time: 72.60792875289917 and batch: 950, loss is 5.6402599906921385 and perplexity is 281.53590567585087
At time: 72.95178508758545 and batch: 1000, loss is 5.706168775558472 and perplexity is 300.7167451153175
At time: 73.29681587219238 and batch: 1050, loss is 5.569498920440674 and perplexity is 262.3026318180493
At time: 73.64184713363647 and batch: 1100, loss is 5.66606743812561 and perplexity is 288.8961954008254
At time: 73.9858067035675 and batch: 1150, loss is 5.663962574005127 and perplexity is 288.28874768630396
At time: 74.32844185829163 and batch: 1200, loss is 5.638639631271363 and perplexity is 281.08008571461863
At time: 74.67159271240234 and batch: 1250, loss is 5.660047607421875 and perplexity is 287.16231328803286
At time: 75.01464915275574 and batch: 1300, loss is 5.724632816314697 and perplexity is 306.3207686024623
At time: 75.35961318016052 and batch: 1350, loss is 5.664487991333008 and perplexity is 288.44025938972317
At time: 75.70418643951416 and batch: 1400, loss is 5.572101383209229 and perplexity is 262.9861536857754
At time: 76.04687809944153 and batch: 1450, loss is 5.6243040657043455 and perplexity is 277.0793883604128
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.719671265691773 and perplexity of 304.8047067211454
Finished 7 epochs...
Completing Train Step...
At time: 77.32516503334045 and batch: 50, loss is 5.704104900360107 and perplexity is 300.09674330659817
At time: 77.67001295089722 and batch: 100, loss is 5.72910231590271 and perplexity is 307.69293331208814
At time: 78.01607894897461 and batch: 150, loss is 5.689060144424438 and perplexity is 295.615654016054
At time: 78.35958909988403 and batch: 200, loss is 5.6491703701019285 and perplexity is 284.0557069339411
At time: 78.72001576423645 and batch: 250, loss is 5.656238651275634 and perplexity is 286.0706050840907
At time: 79.06319427490234 and batch: 300, loss is 5.719324769973755 and perplexity is 304.69911149063887
At time: 79.40806889533997 and batch: 350, loss is 5.75038293838501 and perplexity is 314.310998989413
At time: 79.75244212150574 and batch: 400, loss is 5.643524923324585 and perplexity is 282.4566036320282
At time: 80.09823203086853 and batch: 450, loss is 5.689220275878906 and perplexity is 295.66299517099793
At time: 80.44359850883484 and batch: 500, loss is 5.667980031967163 and perplexity is 289.44926521536286
At time: 80.78969216346741 and batch: 550, loss is 5.716672801971436 and perplexity is 303.892129714509
At time: 81.13573026657104 and batch: 600, loss is 5.584180269241333 and perplexity is 266.18199571410395
At time: 81.48054099082947 and batch: 650, loss is 5.759120264053345 and perplexity is 317.06926895282965
At time: 81.82325887680054 and batch: 700, loss is 5.719794359207153 and perplexity is 304.8422285132973
At time: 82.1684160232544 and batch: 750, loss is 5.669841833114624 and perplexity is 289.98866416045
At time: 82.51381039619446 and batch: 800, loss is 5.6523901462554935 and perplexity is 284.9717767038065
At time: 82.85751581192017 and batch: 850, loss is 5.605913105010987 and perplexity is 272.03020420736425
At time: 83.2008330821991 and batch: 900, loss is 5.563947715759277 and perplexity is 260.85057029459836
At time: 83.54494547843933 and batch: 950, loss is 5.621383323669433 and perplexity is 276.27129163932295
At time: 83.88984751701355 and batch: 1000, loss is 5.68834545135498 and perplexity is 295.40445503711845
At time: 84.23409104347229 and batch: 1050, loss is 5.553101282119751 and perplexity is 258.03656046731527
At time: 84.57768058776855 and batch: 1100, loss is 5.646415452957154 and perplexity is 283.2742339377689
At time: 84.92091965675354 and batch: 1150, loss is 5.646079454421997 and perplexity is 283.179070198452
At time: 85.26668763160706 and batch: 1200, loss is 5.618541536331176 and perplexity is 275.487301874521
At time: 85.61344289779663 and batch: 1250, loss is 5.636164903640747 and perplexity is 280.3853490566499
At time: 85.9574224948883 and batch: 1300, loss is 5.706088371276856 and perplexity is 300.69256717347474
At time: 86.30201864242554 and batch: 1350, loss is 5.647066984176636 and perplexity is 283.45885608186865
At time: 86.6492657661438 and batch: 1400, loss is 5.554724493026733 and perplexity is 258.45574834979726
At time: 86.99386477470398 and batch: 1450, loss is 5.608321752548218 and perplexity is 272.68621882561786
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.7045308952657585 and perplexity of 300.22461022384323
Finished 8 epochs...
Completing Train Step...
At time: 88.2695825099945 and batch: 50, loss is 5.6893090152740475 and perplexity is 295.6892332905153
At time: 88.61421179771423 and batch: 100, loss is 5.710524730682373 and perplexity is 302.02951086064434
At time: 88.95771741867065 and batch: 150, loss is 5.669803037643432 and perplexity is 289.97741413181006
At time: 89.30161356925964 and batch: 200, loss is 5.628212842941284 and perplexity is 278.1645494112285
At time: 89.64743113517761 and batch: 250, loss is 5.635534296035766 and perplexity is 280.20859166134596
At time: 89.99084043502808 and batch: 300, loss is 5.6963926029205325 and perplexity is 297.79120986904303
At time: 90.33589315414429 and batch: 350, loss is 5.719526576995849 and perplexity is 304.76060811598023
At time: 90.68136882781982 and batch: 400, loss is 5.615924091339111 and perplexity is 274.76717187731464
At time: 91.02704620361328 and batch: 450, loss is 5.651817378997802 and perplexity is 284.80860093607396
At time: 91.37112021446228 and batch: 500, loss is 5.626400394439697 and perplexity is 277.6608470955943
At time: 91.71398735046387 and batch: 550, loss is 5.665865573883057 and perplexity is 288.83788347490855
At time: 92.05881237983704 and batch: 600, loss is 5.535587663650513 and perplexity is 253.556749948221
At time: 92.4042980670929 and batch: 650, loss is 5.701737422943115 and perplexity is 299.38711139412453
At time: 92.74872016906738 and batch: 700, loss is 5.667717771530151 and perplexity is 289.3733640779425
At time: 93.09203624725342 and batch: 750, loss is 5.613933773040771 and perplexity is 274.2208416132561
At time: 93.43843078613281 and batch: 800, loss is 5.584039039611817 and perplexity is 266.1444055839479
At time: 93.78413915634155 and batch: 850, loss is 5.539914236068726 and perplexity is 254.65615820872117
At time: 94.13085460662842 and batch: 900, loss is 5.491723384857178 and perplexity is 242.67506922521042
At time: 94.47521829605103 and batch: 950, loss is 5.5443996143341066 and perplexity is 255.80095290521425
At time: 94.82096147537231 and batch: 1000, loss is 5.608252754211426 and perplexity is 272.6674045791362
At time: 95.16668009757996 and batch: 1050, loss is 5.4810113430023195 and perplexity is 240.0893973641135
At time: 95.5114586353302 and batch: 1100, loss is 5.572648830413819 and perplexity is 263.130164135919
At time: 95.85902976989746 and batch: 1150, loss is 5.571272878646851 and perplexity is 262.7683586921357
At time: 96.21774482727051 and batch: 1200, loss is 5.5371530151367185 and perplexity is 253.95396619400123
At time: 96.56132674217224 and batch: 1250, loss is 5.555974817276001 and perplexity is 258.77910394686813
At time: 96.90495705604553 and batch: 1300, loss is 5.627253684997559 and perplexity is 277.8978735865605
At time: 97.24893188476562 and batch: 1350, loss is 5.556538743972778 and perplexity is 258.92507754748874
At time: 97.59444117546082 and batch: 1400, loss is 5.466571063995361 and perplexity is 236.64735134356297
At time: 97.93978905677795 and batch: 1450, loss is 5.51740517616272 and perplexity is 248.98811792831538
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.632633567875267 and perplexity of 279.3969604385758
Finished 9 epochs...
Completing Train Step...
At time: 99.17990159988403 and batch: 50, loss is 5.60847951889038 and perplexity is 272.7292429267085
At time: 99.5400333404541 and batch: 100, loss is 5.615152406692505 and perplexity is 274.5552200598852
At time: 99.88356947898865 and batch: 150, loss is 5.575018825531006 and perplexity is 263.7545209091133
At time: 100.2277340888977 and batch: 200, loss is 5.543762683868408 and perplexity is 255.6380773608587
At time: 100.57234740257263 and batch: 250, loss is 5.552017860412597 and perplexity is 257.7571494437808
At time: 100.91819405555725 and batch: 300, loss is 5.605560674667358 and perplexity is 271.9343494010814
At time: 101.2620964050293 and batch: 350, loss is 5.6370280075073245 and perplexity is 280.62745520189765
At time: 101.60771465301514 and batch: 400, loss is 5.54217004776001 and perplexity is 255.23126296780816
At time: 101.9519567489624 and batch: 450, loss is 5.578398838043213 and perplexity is 264.64752281857704
At time: 102.29746556282043 and batch: 500, loss is 5.549510908126831 and perplexity is 257.11177386970064
At time: 102.6430835723877 and batch: 550, loss is 5.603017997741699 and perplexity is 271.24378651677364
At time: 102.98858952522278 and batch: 600, loss is 5.475059595108032 and perplexity is 238.66468975481934
At time: 103.33465433120728 and batch: 650, loss is 5.633293199539184 and perplexity is 279.5813203186057
At time: 103.67968916893005 and batch: 700, loss is 5.609443292617798 and perplexity is 272.99221891005595
At time: 104.02291893959045 and batch: 750, loss is 5.556470861434937 and perplexity is 258.90750165266894
At time: 104.36846017837524 and batch: 800, loss is 5.527484655380249 and perplexity is 251.5104791771848
At time: 104.71270275115967 and batch: 850, loss is 5.487210235595703 and perplexity is 241.5823081674649
At time: 105.0724425315857 and batch: 900, loss is 5.438113031387329 and perplexity is 230.00775629753068
At time: 105.41644954681396 and batch: 950, loss is 5.493255338668823 and perplexity is 243.0471211329069
At time: 105.76029348373413 and batch: 1000, loss is 5.55706636428833 and perplexity is 259.06172772514344
At time: 106.10488414764404 and batch: 1050, loss is 5.434251670837402 and perplexity is 229.12132593619725
At time: 106.45033288002014 and batch: 1100, loss is 5.534335031509399 and perplexity is 253.23933545694072
At time: 106.79402112960815 and batch: 1150, loss is 5.525971851348877 and perplexity is 251.13028076570745
At time: 107.13822603225708 and batch: 1200, loss is 5.493790121078491 and perplexity is 243.177133218999
At time: 107.48282361030579 and batch: 1250, loss is 5.515338964462281 and perplexity is 248.4741868937807
At time: 107.82638478279114 and batch: 1300, loss is 5.5864504528045655 and perplexity is 266.78696414047096
At time: 108.17078590393066 and batch: 1350, loss is 5.521162042617798 and perplexity is 249.92529235357696
At time: 108.51526546478271 and batch: 1400, loss is 5.424473667144776 and perplexity is 226.89189422374133
At time: 108.86073565483093 and batch: 1450, loss is 5.478670721054077 and perplexity is 239.52809600450163
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.604053986378205 and perplexity of 271.5249376068491
Finished 10 epochs...
Completing Train Step...
At time: 110.12793064117432 and batch: 50, loss is 5.567446250915527 and perplexity is 261.7647634212407
At time: 110.49172234535217 and batch: 100, loss is 5.579469690322876 and perplexity is 264.9310730147854
At time: 110.83741354942322 and batch: 150, loss is 5.535987405776978 and perplexity is 253.65812752371872
At time: 111.18029308319092 and batch: 200, loss is 5.504891109466553 and perplexity is 245.89167894489148
At time: 111.52307486534119 and batch: 250, loss is 5.5164939975738525 and perplexity is 248.76134861573732
At time: 111.86751222610474 and batch: 300, loss is 5.566670532226563 and perplexity is 261.5617863388789
At time: 112.21146416664124 and batch: 350, loss is 5.6091953468322755 and perplexity is 272.9245400305899
At time: 112.56182265281677 and batch: 400, loss is 5.512329454421997 and perplexity is 247.72752543969602
At time: 112.90507483482361 and batch: 450, loss is 5.549104633331299 and perplexity is 257.0073370528026
At time: 113.24846601486206 and batch: 500, loss is 5.519017572402954 and perplexity is 249.3899092699014
At time: 113.59536385536194 and batch: 550, loss is 5.576297492980957 and perplexity is 264.09199093976883
At time: 113.94628310203552 and batch: 600, loss is 5.447436008453369 and perplexity is 232.16214036661518
At time: 114.30659031867981 and batch: 650, loss is 5.608420352935791 and perplexity is 272.7131071180563
At time: 114.65007424354553 and batch: 700, loss is 5.588052253723145 and perplexity is 267.21464618399693
At time: 114.99527645111084 and batch: 750, loss is 5.532123403549194 and perplexity is 252.6798831402508
At time: 115.3411808013916 and batch: 800, loss is 5.4998803806304934 and perplexity is 244.66266412011296
At time: 115.68354725837708 and batch: 850, loss is 5.453970880508423 and perplexity is 233.68425825599178
At time: 116.02671003341675 and batch: 900, loss is 5.41388424873352 and perplexity is 224.50191758643652
At time: 116.37362599372864 and batch: 950, loss is 5.467126779556274 and perplexity is 236.77889650661515
At time: 116.71998286247253 and batch: 1000, loss is 5.53310622215271 and perplexity is 252.92834370596856
At time: 117.07116222381592 and batch: 1050, loss is 5.4109012889862065 and perplexity is 223.8332352251957
At time: 117.41522336006165 and batch: 1100, loss is 5.511727771759033 and perplexity is 247.57851691491834
At time: 117.75843381881714 and batch: 1150, loss is 5.50361406326294 and perplexity is 245.5778643303245
At time: 118.10350847244263 and batch: 1200, loss is 5.47668836593628 and perplexity is 239.05373658728217
At time: 118.44715905189514 and batch: 1250, loss is 5.491329574584961 and perplexity is 242.579520105486
At time: 118.79074764251709 and batch: 1300, loss is 5.566229429244995 and perplexity is 261.4464360975987
At time: 119.13561391830444 and batch: 1350, loss is 5.4987774753570555 and perplexity is 244.39297312678858
At time: 119.48213124275208 and batch: 1400, loss is 5.40551791191101 and perplexity is 222.6314941330187
At time: 119.82860970497131 and batch: 1450, loss is 5.461669998168945 and perplexity is 235.49036464690533
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.583826309595352 and perplexity of 266.0877947017965
Finished 11 epochs...
Completing Train Step...
At time: 121.10184454917908 and batch: 50, loss is 5.549475240707397 and perplexity is 257.10260351976297
At time: 121.44733023643494 and batch: 100, loss is 5.567604379653931 and perplexity is 261.806159225886
At time: 121.79169774055481 and batch: 150, loss is 5.51319314956665 and perplexity is 247.941578925787
At time: 122.13510179519653 and batch: 200, loss is 5.488478698730469 and perplexity is 241.88894085440228
At time: 122.47999024391174 and batch: 250, loss is 5.501278963088989 and perplexity is 245.00508442610143
At time: 122.83006024360657 and batch: 300, loss is 5.552633743286133 and perplexity is 257.9159465528451
At time: 123.19172596931458 and batch: 350, loss is 5.5900782871246335 and perplexity is 267.7565807859569
At time: 123.53813815116882 and batch: 400, loss is 5.500637130737305 and perplexity is 244.847882690566
At time: 123.88278555870056 and batch: 450, loss is 5.533271703720093 and perplexity is 252.97020214802544
At time: 124.22924900054932 and batch: 500, loss is 5.502000494003296 and perplexity is 245.18192695968253
At time: 124.5764548778534 and batch: 550, loss is 5.561511764526367 and perplexity is 260.2159243234267
At time: 124.9199891090393 and batch: 600, loss is 5.433898649215698 and perplexity is 229.04045542950686
At time: 125.26558065414429 and batch: 650, loss is 5.593980360031128 and perplexity is 268.80342759337066
At time: 125.60994219779968 and batch: 700, loss is 5.578249292373657 and perplexity is 264.60794888670983
At time: 125.95465278625488 and batch: 750, loss is 5.5240168857574465 and perplexity is 250.63980929148275
At time: 126.29893779754639 and batch: 800, loss is 5.486979780197143 and perplexity is 241.5266406350392
At time: 126.64438915252686 and batch: 850, loss is 5.444852342605591 and perplexity is 231.56308518584945
At time: 126.98722648620605 and batch: 900, loss is 5.398984441757202 and perplexity is 221.1816792292616
At time: 127.32865571975708 and batch: 950, loss is 5.451438035964966 and perplexity is 233.0931213026065
At time: 127.6707034111023 and batch: 1000, loss is 5.516553831100464 and perplexity is 248.77623332980767
At time: 128.01193165779114 and batch: 1050, loss is 5.392475891113281 and perplexity is 219.7467816854887
At time: 128.35719180107117 and batch: 1100, loss is 5.496350545883178 and perplexity is 243.80056777087967
At time: 128.70462250709534 and batch: 1150, loss is 5.486953630447387 and perplexity is 241.5203248564056
At time: 129.05325627326965 and batch: 1200, loss is 5.459891214370727 and perplexity is 235.07185053504642
At time: 129.3992440700531 and batch: 1250, loss is 5.469505395889282 and perplexity is 237.34277301423373
At time: 129.7452630996704 and batch: 1300, loss is 5.546341724395752 and perplexity is 256.29822923601085
At time: 130.09026074409485 and batch: 1350, loss is 5.477072277069092 and perplexity is 239.14552959715013
At time: 130.43669652938843 and batch: 1400, loss is 5.380963344573974 and perplexity is 217.2314433906458
At time: 130.78365659713745 and batch: 1450, loss is 5.439070959091186 and perplexity is 230.22819266358462
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.561367458767361 and perplexity of 260.1783763762194
Finished 12 epochs...
Completing Train Step...
At time: 132.0837061405182 and batch: 50, loss is 5.52214204788208 and perplexity is 250.17034051039042
At time: 132.42884922027588 and batch: 100, loss is 5.539127883911132 and perplexity is 254.4559875019175
At time: 132.77714467048645 and batch: 150, loss is 5.487037477493286 and perplexity is 241.54057647117642
At time: 133.12259340286255 and batch: 200, loss is 5.464185018539428 and perplexity is 236.08337311264933
At time: 133.46710205078125 and batch: 250, loss is 5.479908504486084 and perplexity is 239.82476348040223
At time: 133.81220388412476 and batch: 300, loss is 5.5241100883483885 and perplexity is 250.66317065975502
At time: 134.1581380367279 and batch: 350, loss is 5.564598398208618 and perplexity is 261.02035641502346
At time: 134.5048439502716 and batch: 400, loss is 5.4761948394775395 and perplexity is 238.93578635139082
At time: 134.85107970237732 and batch: 450, loss is 5.507093229293823 and perplexity is 246.43375852949714
At time: 135.19734358787537 and batch: 500, loss is 5.480403461456299 and perplexity is 239.94349579998763
At time: 135.5424189567566 and batch: 550, loss is 5.540536279678345 and perplexity is 254.81461472290664
At time: 135.89016604423523 and batch: 600, loss is 5.410125904083252 and perplexity is 223.6597455831393
At time: 136.23504996299744 and batch: 650, loss is 5.569220170974732 and perplexity is 262.22952528919103
At time: 136.5796012878418 and batch: 700, loss is 5.55461311340332 and perplexity is 258.4269632489437
At time: 136.92315816879272 and batch: 750, loss is 5.498798856735229 and perplexity is 244.39819864123416
At time: 137.27185344696045 and batch: 800, loss is 5.461929388046265 and perplexity is 235.55145638664794
At time: 137.61547017097473 and batch: 850, loss is 5.413460083007813 and perplexity is 224.40671176059226
At time: 137.9596197605133 and batch: 900, loss is 5.361589756011963 and perplexity is 213.0633961670149
At time: 138.30672550201416 and batch: 950, loss is 5.420134153366089 and perplexity is 225.90942697932448
At time: 138.65309071540833 and batch: 1000, loss is 5.485745935440064 and perplexity is 241.22881802701147
At time: 138.99961519241333 and batch: 1050, loss is 5.363051519393921 and perplexity is 213.37507218036137
At time: 139.34414076805115 and batch: 1100, loss is 5.466941804885864 and perplexity is 236.73510245879342
At time: 139.69065237045288 and batch: 1150, loss is 5.458697919845581 and perplexity is 234.7915078817298
At time: 140.03657412528992 and batch: 1200, loss is 5.432493457794189 and perplexity is 228.7188357678751
At time: 140.380845785141 and batch: 1250, loss is 5.442097940444946 and perplexity is 230.92614492119972
At time: 140.7263514995575 and batch: 1300, loss is 5.517208366394043 and perplexity is 248.93911945626976
At time: 141.07025361061096 and batch: 1350, loss is 5.4463967609405515 and perplexity is 231.9209917679135
At time: 141.4162073135376 and batch: 1400, loss is 5.3483000659942626 and perplexity is 210.25058179224334
At time: 141.76056671142578 and batch: 1450, loss is 5.408267450332642 and perplexity is 223.24447029458355
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.532031458667201 and perplexity of 252.656651586241
Finished 13 epochs...
Completing Train Step...
At time: 143.02442145347595 and batch: 50, loss is 5.495836029052734 and perplexity is 243.67516054032166
At time: 143.3850133419037 and batch: 100, loss is 5.5119000339508055 and perplexity is 247.62116900644378
At time: 143.7298288345337 and batch: 150, loss is 5.457355604171753 and perplexity is 234.47655499100986
At time: 144.0749671459198 and batch: 200, loss is 5.432005805969238 and perplexity is 228.60732780095375
At time: 144.42020630836487 and batch: 250, loss is 5.447535429000855 and perplexity is 232.18522320115082
At time: 144.7642858028412 and batch: 300, loss is 5.492335062026978 and perplexity is 242.82355343230537
At time: 145.10770392417908 and batch: 350, loss is 5.533452749252319 and perplexity is 253.01600541902445
At time: 145.4545760154724 and batch: 400, loss is 5.443261489868164 and perplexity is 231.19499528393914
At time: 145.80264234542847 and batch: 450, loss is 5.472043113708496 and perplexity is 237.9458468905846
At time: 146.1469304561615 and batch: 500, loss is 5.449772701263428 and perplexity is 232.70526628286115
At time: 146.49017691612244 and batch: 550, loss is 5.507859325408935 and perplexity is 246.62262280939748
At time: 146.83659410476685 and batch: 600, loss is 5.379116191864013 and perplexity is 216.83055410714655
At time: 147.18341898918152 and batch: 650, loss is 5.541287145614624 and perplexity is 255.00601818734614
At time: 147.52901911735535 and batch: 700, loss is 5.531337652206421 and perplexity is 252.4814175652887
At time: 147.87129735946655 and batch: 750, loss is 5.471036605834961 and perplexity is 237.70647300827108
At time: 148.21642637252808 and batch: 800, loss is 5.430125284194946 and perplexity is 228.17783070914933
At time: 148.5620777606964 and batch: 850, loss is 5.390806131362915 and perplexity is 219.3801635214654
At time: 148.9059407711029 and batch: 900, loss is 5.34717101097107 and perplexity is 210.01333127638816
At time: 149.2494421005249 and batch: 950, loss is 5.405365686416626 and perplexity is 222.59760652310337
At time: 149.5956470966339 and batch: 1000, loss is 5.467403717041016 and perplexity is 236.8444785392961
At time: 149.96029043197632 and batch: 1050, loss is 5.345268211364746 and perplexity is 209.61409794328412
At time: 150.30347561836243 and batch: 1100, loss is 5.45640679359436 and perplexity is 234.25418666487582
At time: 150.64914464950562 and batch: 1150, loss is 5.444629373550415 and perplexity is 231.51145953920673
At time: 150.99463272094727 and batch: 1200, loss is 5.418447399139405 and perplexity is 225.528694489857
At time: 151.34069752693176 and batch: 1250, loss is 5.431488056182861 and perplexity is 228.48899704132663
At time: 151.68414330482483 and batch: 1300, loss is 5.5031397342681885 and perplexity is 245.46140725047184
At time: 152.0278561115265 and batch: 1350, loss is 5.4337192821502684 and perplexity is 228.9993767993386
At time: 152.37058758735657 and batch: 1400, loss is 5.338741044998169 and perplexity is 208.25036734316498
At time: 152.71686100959778 and batch: 1450, loss is 5.396922779083252 and perplexity is 220.72614695532758
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.522321130475428 and perplexity of 250.21514567554047
Finished 14 epochs...
Completing Train Step...
At time: 153.96936750411987 and batch: 50, loss is 5.484257488250733 and perplexity is 240.87002875651484
At time: 154.32963752746582 and batch: 100, loss is 5.502328300476075 and perplexity is 245.26231235705524
At time: 154.67387175559998 and batch: 150, loss is 5.443229722976684 and perplexity is 231.18765105426553
At time: 155.0183846950531 and batch: 200, loss is 5.419915237426758 and perplexity is 225.8599772177816
At time: 155.36408686637878 and batch: 250, loss is 5.433969135284424 and perplexity is 229.05660015977185
At time: 155.71130871772766 and batch: 300, loss is 5.478149709701538 and perplexity is 239.40333165187553
At time: 156.05550861358643 and batch: 350, loss is 5.521762027740478 and perplexity is 250.0752888040904
At time: 156.3987226486206 and batch: 400, loss is 5.4281834125518795 and perplexity is 227.73516858573285
At time: 156.74315428733826 and batch: 450, loss is 5.458314218521118 and perplexity is 234.7014353507628
At time: 157.08899450302124 and batch: 500, loss is 5.43857593536377 and perplexity is 230.1142524493775
At time: 157.43378973007202 and batch: 550, loss is 5.494807195663452 and perplexity is 243.42458831965521
At time: 157.77749705314636 and batch: 600, loss is 5.363636493682861 and perplexity is 213.49992762654014
At time: 158.12093925476074 and batch: 650, loss is 5.524714441299438 and perplexity is 250.8147054723061
At time: 158.46645069122314 and batch: 700, loss is 5.513187160491944 and perplexity is 247.94009398959471
At time: 158.82584476470947 and batch: 750, loss is 5.457290258407593 and perplexity is 234.46123344195087
At time: 159.17014050483704 and batch: 800, loss is 5.413626232147217 and perplexity is 224.44399984023318
At time: 159.51502799987793 and batch: 850, loss is 5.375096483230591 and perplexity is 215.96070789223396
At time: 159.8604073524475 and batch: 900, loss is 5.328200006484986 and perplexity is 206.0667213681173
At time: 160.20853209495544 and batch: 950, loss is 5.3908846569061275 and perplexity is 219.39739114437137
At time: 160.55462074279785 and batch: 1000, loss is 5.446655817031861 and perplexity is 231.98108009632116
At time: 160.89855289459229 and batch: 1050, loss is 5.330673885345459 and perplexity is 206.57713656632643
At time: 161.24412775039673 and batch: 1100, loss is 5.4371266746521 and perplexity is 229.78099844840193
At time: 161.59077143669128 and batch: 1150, loss is 5.4299040699005126 and perplexity is 228.1273600939402
At time: 161.9339678287506 and batch: 1200, loss is 5.404272661209107 and perplexity is 222.35443464874416
At time: 162.27823734283447 and batch: 1250, loss is 5.410748100280761 and perplexity is 223.79894912784442
At time: 162.62089371681213 and batch: 1300, loss is 5.483801288604736 and perplexity is 240.76016899556234
At time: 162.96699929237366 and batch: 1350, loss is 5.410334510803223 and perplexity is 223.70640737586749
At time: 163.31202602386475 and batch: 1400, loss is 5.315652742385864 and perplexity is 203.4973010998012
At time: 163.65721988677979 and batch: 1450, loss is 5.376776819229126 and perplexity is 216.32389950048443
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.507443159054487 and perplexity of 246.520008125409
Finished 15 epochs...
Completing Train Step...
At time: 164.918541431427 and batch: 50, loss is 5.463490953445435 and perplexity is 235.91957273473753
At time: 165.26200318336487 and batch: 100, loss is 5.480641174316406 and perplexity is 240.00054023446756
At time: 165.6056935787201 and batch: 150, loss is 5.425131874084473 and perplexity is 227.0412852027765
At time: 165.95320391654968 and batch: 200, loss is 5.397838582992554 and perplexity is 220.92838141301343
At time: 166.29718279838562 and batch: 250, loss is 5.415216188430787 and perplexity is 224.80113983133882
At time: 166.6412491798401 and batch: 300, loss is 5.460929002761841 and perplexity is 235.31593200315987
At time: 166.9876046180725 and batch: 350, loss is 5.503334369659424 and perplexity is 245.5091873772062
At time: 167.33432698249817 and batch: 400, loss is 5.410935125350952 and perplexity is 223.8408090563197
At time: 167.70245480537415 and batch: 450, loss is 5.441771430969238 and perplexity is 230.8507576546924
At time: 168.04708814620972 and batch: 500, loss is 5.421579599380493 and perplexity is 226.23620297180128
At time: 168.39234685897827 and batch: 550, loss is 5.483401937484741 and perplexity is 240.6640403482428
At time: 168.73774194717407 and batch: 600, loss is 5.345170907974243 and perplexity is 209.59370277313266
At time: 169.08327460289001 and batch: 650, loss is 5.509032382965088 and perplexity is 246.91209509123155
At time: 169.42790508270264 and batch: 700, loss is 5.4993845558166505 and perplexity is 244.54138436946084
At time: 169.77284359931946 and batch: 750, loss is 5.443112478256226 and perplexity is 231.16054711167237
At time: 170.11763262748718 and batch: 800, loss is 5.398527069091797 and perplexity is 221.08053990603776
At time: 170.46221923828125 and batch: 850, loss is 5.360712213516235 and perplexity is 212.876505996621
At time: 170.8049976825714 and batch: 900, loss is 5.318787641525269 and perplexity is 204.13624560390446
At time: 171.15002489089966 and batch: 950, loss is 5.381437501907349 and perplexity is 217.33446969597784
At time: 171.49497842788696 and batch: 1000, loss is 5.439684009552002 and perplexity is 230.3693774354627
At time: 171.84003067016602 and batch: 1050, loss is 5.318803901672363 and perplexity is 204.1395649162715
At time: 172.1853587627411 and batch: 1100, loss is 5.4248137855529786 and perplexity is 226.96907745861427
At time: 172.52890968322754 and batch: 1150, loss is 5.421061172485351 and perplexity is 226.11894643662288
At time: 172.87477684020996 and batch: 1200, loss is 5.396028642654419 and perplexity is 220.52887587331207
At time: 173.21839952468872 and batch: 1250, loss is 5.398861827850342 and perplexity is 221.15456094201903
At time: 173.56211256980896 and batch: 1300, loss is 5.474428491592407 and perplexity is 238.51411514913877
At time: 173.9054503440857 and batch: 1350, loss is 5.402698631286621 and perplexity is 222.0047174201049
At time: 174.25050711631775 and batch: 1400, loss is 5.305863552093506 and perplexity is 201.5149459516828
At time: 174.59669423103333 and batch: 1450, loss is 5.368483476638794 and perplexity is 214.53727009659718
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.504394009581998 and perplexity of 245.76947659557823
Finished 16 epochs...
Completing Train Step...
At time: 175.85909366607666 and batch: 50, loss is 5.457986488342285 and perplexity is 234.6245292103028
At time: 176.2045032978058 and batch: 100, loss is 5.474523086547851 and perplexity is 238.53667844840436
At time: 176.5642147064209 and batch: 150, loss is 5.419512825012207 and perplexity is 225.7691066439488
At time: 176.91016745567322 and batch: 200, loss is 5.392046470642089 and perplexity is 219.6524381769212
At time: 177.2554759979248 and batch: 250, loss is 5.410867080688477 and perplexity is 223.8255784022075
At time: 177.5995922088623 and batch: 300, loss is 5.454909057617187 and perplexity is 233.9035983516064
At time: 177.94466710090637 and batch: 350, loss is 5.498772239685058 and perplexity is 244.39169356869252
At time: 178.29036664962769 and batch: 400, loss is 5.403869028091431 and perplexity is 222.26470314557923
At time: 178.63263607025146 and batch: 450, loss is 5.437190895080566 and perplexity is 229.7957555564246
At time: 178.97593188285828 and batch: 500, loss is 5.416461582183838 and perplexity is 225.081280172871
At time: 179.31888127326965 and batch: 550, loss is 5.476276063919068 and perplexity is 238.95519456539833
At time: 179.66278314590454 and batch: 600, loss is 5.339079170227051 and perplexity is 208.32079395212324
At time: 180.00791573524475 and batch: 650, loss is 5.503477506637573 and perplexity is 245.54433133553522
At time: 180.3517472743988 and batch: 700, loss is 5.492938556671143 and perplexity is 242.97014037404693
At time: 180.69562292099 and batch: 750, loss is 5.437833032608032 and perplexity is 229.9433634219226
At time: 181.0395143032074 and batch: 800, loss is 5.398158721923828 and perplexity is 220.99912051149258
At time: 181.3859293460846 and batch: 850, loss is 5.3578298473358155 and perplexity is 212.26380139883355
At time: 181.73131704330444 and batch: 900, loss is 5.3102709007263185 and perplexity is 202.40505263761784
At time: 182.0811402797699 and batch: 950, loss is 5.3737916660308835 and perplexity is 215.67910240790886
At time: 182.42879509925842 and batch: 1000, loss is 5.4338266563415525 and perplexity is 229.02396674236596
At time: 182.7766628265381 and batch: 1050, loss is 5.310188674926758 and perplexity is 202.38841040454952
At time: 183.12234163284302 and batch: 1100, loss is 5.419615726470948 and perplexity is 225.79233980970383
At time: 183.46748757362366 and batch: 1150, loss is 5.414862508773804 and perplexity is 224.7216462997651
At time: 183.8109438419342 and batch: 1200, loss is 5.393609867095948 and perplexity is 219.9961105979699
At time: 184.15571331977844 and batch: 1250, loss is 5.39467267036438 and perplexity is 220.23004747577468
At time: 184.5020887851715 and batch: 1300, loss is 5.468313188552856 and perplexity is 237.0599798265509
At time: 184.84588360786438 and batch: 1350, loss is 5.395111608505249 and perplexity is 220.32673606197892
At time: 185.19140601158142 and batch: 1400, loss is 5.300085783004761 and perplexity is 200.35399620544823
At time: 185.53743076324463 and batch: 1450, loss is 5.364303321838379 and perplexity is 213.64234286745145
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.502490443042201 and perplexity of 245.30208304192826
Finished 17 epochs...
Completing Train Step...
At time: 186.79176497459412 and batch: 50, loss is 5.454127464294434 and perplexity is 233.7208522868219
At time: 187.15242338180542 and batch: 100, loss is 5.467223634719849 and perplexity is 236.80183087600548
At time: 187.497629404068 and batch: 150, loss is 5.41514256477356 and perplexity is 224.78458975852163
At time: 187.84180164337158 and batch: 200, loss is 5.383159008026123 and perplexity is 217.70893454466437
At time: 188.18622851371765 and batch: 250, loss is 5.402281999588013 and perplexity is 221.9122424829198
At time: 188.53292059898376 and batch: 300, loss is 5.449689435958862 and perplexity is 232.68589081465333
At time: 188.8768322467804 and batch: 350, loss is 5.4910728454589846 and perplexity is 242.5172508708146
At time: 189.2231366634369 and batch: 400, loss is 5.39624475479126 and perplexity is 220.57653999012376
At time: 189.56842684745789 and batch: 450, loss is 5.4323336696624756 and perplexity is 228.6822921321174
At time: 189.91539359092712 and batch: 500, loss is 5.411604633331299 and perplexity is 223.99072244281476
At time: 190.2616376876831 and batch: 550, loss is 5.468073377609253 and perplexity is 237.00313706512858
At time: 190.6054835319519 and batch: 600, loss is 5.335500555038452 and perplexity is 207.5766263337371
At time: 190.9490008354187 and batch: 650, loss is 5.497577104568482 and perplexity is 244.09978694218432
At time: 191.29519605636597 and batch: 700, loss is 5.488102321624756 and perplexity is 241.79791652575074
At time: 191.63916110992432 and batch: 750, loss is 5.4330877017974855 and perplexity is 228.85479095574783
At time: 191.98384475708008 and batch: 800, loss is 5.389662046432495 and perplexity is 219.1293175042831
At time: 192.3280644416809 and batch: 850, loss is 5.3536993026733395 and perplexity is 211.38884455508781
At time: 192.67308235168457 and batch: 900, loss is 5.305836772918701 and perplexity is 201.50954961997434
At time: 193.0171093940735 and batch: 950, loss is 5.370018730163574 and perplexity is 214.8668921586827
At time: 193.35990691184998 and batch: 1000, loss is 5.429491672515869 and perplexity is 228.03330036359836
At time: 193.70495581626892 and batch: 1050, loss is 5.3065614414215085 and perplexity is 201.65563016719184
At time: 194.0482177734375 and batch: 1100, loss is 5.415944490432739 and perplexity is 224.96492258593378
At time: 194.41427278518677 and batch: 1150, loss is 5.408532314300537 and perplexity is 223.3036075421137
At time: 194.75781893730164 and batch: 1200, loss is 5.385038690567017 and perplexity is 218.11854307432284
At time: 195.10255360603333 and batch: 1250, loss is 5.388880338668823 and perplexity is 218.95808934945026
At time: 195.44905185699463 and batch: 1300, loss is 5.462248973846435 and perplexity is 235.62674731763394
At time: 195.79444646835327 and batch: 1350, loss is 5.392774295806885 and perplexity is 219.81236494123704
At time: 196.13999462127686 and batch: 1400, loss is 5.294091539382935 and perplexity is 199.15661781571788
At time: 196.48427939414978 and batch: 1450, loss is 5.358681621551514 and perplexity is 212.44467925440216
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.501950516659989 and perplexity of 245.16967372454096
Finished 18 epochs...
Completing Train Step...
At time: 197.737868309021 and batch: 50, loss is 5.452238702774048 and perplexity is 233.27982596239687
At time: 198.09831953048706 and batch: 100, loss is 5.462265567779541 and perplexity is 235.63065732455797
At time: 198.44480061531067 and batch: 150, loss is 5.412734689712525 and perplexity is 224.24398766308354
At time: 198.79022359848022 and batch: 200, loss is 5.379901733398437 and perplexity is 217.00095043126257
At time: 199.13390493392944 and batch: 250, loss is 5.397060165405273 and perplexity is 220.75647379203025
At time: 199.4789469242096 and batch: 300, loss is 5.443749647140503 and perplexity is 231.30788235329558
At time: 199.82530689239502 and batch: 350, loss is 5.486944990158081 and perplexity is 241.51823805994078
At time: 200.1707091331482 and batch: 400, loss is 5.395610246658325 and perplexity is 220.43662677429623
At time: 200.51459407806396 and batch: 450, loss is 5.426512489318847 and perplexity is 227.35495834109182
At time: 200.857675075531 and batch: 500, loss is 5.40650408744812 and perplexity is 222.85115616117955
At time: 201.2036657333374 and batch: 550, loss is 5.465085430145264 and perplexity is 236.29604105171677
At time: 201.54927444458008 and batch: 600, loss is 5.331131210327149 and perplexity is 206.67163105722284
At time: 201.8936185836792 and batch: 650, loss is 5.491382141113281 and perplexity is 242.59227200385797
At time: 202.23748111724854 and batch: 700, loss is 5.4814113426208495 and perplexity is 240.1854522411486
At time: 202.58243680000305 and batch: 750, loss is 5.430016994476318 and perplexity is 228.15312273389873
At time: 202.92814135551453 and batch: 800, loss is 5.385600318908692 and perplexity is 218.24107903657193
At time: 203.28744173049927 and batch: 850, loss is 5.348659219741822 and perplexity is 210.326107638504
At time: 203.6291036605835 and batch: 900, loss is 5.298654317855835 and perplexity is 200.06740161645334
At time: 203.97496151924133 and batch: 950, loss is 5.361137008666992 and perplexity is 212.966954113679
At time: 204.32366180419922 and batch: 1000, loss is 5.424271478652954 and perplexity is 226.84602393122051
At time: 204.66794323921204 and batch: 1050, loss is 5.300504293441772 and perplexity is 200.43786399250516
At time: 205.01292514801025 and batch: 1100, loss is 5.410163888931274 and perplexity is 223.66824142593967
At time: 205.35900616645813 and batch: 1150, loss is 5.401795330047608 and perplexity is 221.80427082924902
At time: 205.70378422737122 and batch: 1200, loss is 5.382584648132324 and perplexity is 217.58392716718885
At time: 206.04770755767822 and batch: 1250, loss is 5.386726694107056 and perplexity is 218.48703887078696
At time: 206.39239835739136 and batch: 1300, loss is 5.45401328086853 and perplexity is 233.6941667627539
At time: 206.73892092704773 and batch: 1350, loss is 5.38407193183899 and perplexity is 217.9077769654644
At time: 207.08555841445923 and batch: 1400, loss is 5.286885299682617 and perplexity is 197.7266061814955
At time: 207.429358959198 and batch: 1450, loss is 5.35193395614624 and perplexity is 211.01599918994964
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.492475982405182 and perplexity of 242.85777463046733
Finished 19 epochs...
Completing Train Step...
At time: 208.70155429840088 and batch: 50, loss is 5.446657819747925 and perplexity is 231.98154468902206
At time: 209.04676795005798 and batch: 100, loss is 5.455123682022094 and perplexity is 233.95380515981867
At time: 209.3908030986786 and batch: 150, loss is 5.407056436538697 and perplexity is 222.97428179565492
At time: 209.73573803901672 and batch: 200, loss is 5.373889541625976 and perplexity is 215.70021316150303
At time: 210.08056926727295 and batch: 250, loss is 5.389876899719238 and perplexity is 219.17640321644956
At time: 210.4248082637787 and batch: 300, loss is 5.4381122875213626 and perplexity is 230.00758520265245
At time: 210.7689666748047 and batch: 350, loss is 5.479814987182618 and perplexity is 239.80233676387644
At time: 211.11352610588074 and batch: 400, loss is 5.389556999206543 and perplexity is 219.1062997863495
At time: 211.45823860168457 and batch: 450, loss is 5.422434711456299 and perplexity is 226.42974301836915
At time: 211.80283665657043 and batch: 500, loss is 5.40004677772522 and perplexity is 221.41677333492584
At time: 212.16432547569275 and batch: 550, loss is 5.4565537071228025 and perplexity is 234.28860430213746
At time: 212.5086064338684 and batch: 600, loss is 5.32494083404541 and perplexity is 205.39620764257575
At time: 212.85540556907654 and batch: 650, loss is 5.485709190368652 and perplexity is 241.2199542197182
At time: 213.19945812225342 and batch: 700, loss is 5.478512620925903 and perplexity is 239.49022957524457
At time: 213.54389095306396 and batch: 750, loss is 5.423364276885986 and perplexity is 226.64032213810364
At time: 213.89045524597168 and batch: 800, loss is 5.379282846450805 and perplexity is 216.8666929248114
At time: 214.2352957725525 and batch: 850, loss is 5.343170299530029 and perplexity is 209.17480700443363
At time: 214.58207273483276 and batch: 900, loss is 5.295901403427124 and perplexity is 199.5173905938254
At time: 214.92742109298706 and batch: 950, loss is 5.358225584030151 and perplexity is 212.347818597174
At time: 215.27259254455566 and batch: 1000, loss is 5.417649717330932 and perplexity is 225.34886608543272
At time: 215.6188404560089 and batch: 1050, loss is 5.29802357673645 and perplexity is 199.94125066808286
At time: 215.96405816078186 and batch: 1100, loss is 5.405759687423706 and perplexity is 222.68532748418573
At time: 216.30860495567322 and batch: 1150, loss is 5.3983332061767575 and perplexity is 221.0376847422608
At time: 216.65436458587646 and batch: 1200, loss is 5.376630964279175 and perplexity is 216.29234988983902
At time: 216.99507212638855 and batch: 1250, loss is 5.381429300308228 and perplexity is 217.3326872130919
At time: 217.335355758667 and batch: 1300, loss is 5.452480316162109 and perplexity is 233.336196301154
At time: 217.6748640537262 and batch: 1350, loss is 5.383552503585816 and perplexity is 217.79461890081436
At time: 218.02069807052612 and batch: 1400, loss is 5.282742185592651 and perplexity is 196.9090969798152
At time: 218.36500024795532 and batch: 1450, loss is 5.347795581817627 and perplexity is 210.14454045093902
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.492165589943911 and perplexity of 242.78240510573218
Finished 20 epochs...
Completing Train Step...
At time: 219.6689522266388 and batch: 50, loss is 5.44225625038147 and perplexity is 230.96270571843618
At time: 220.01231622695923 and batch: 100, loss is 5.448927631378174 and perplexity is 232.5086971392155
At time: 220.35689997673035 and batch: 150, loss is 5.401782331466674 and perplexity is 221.80138770722158
At time: 220.7023630142212 and batch: 200, loss is 5.369887046813965 and perplexity is 214.83859962947147
At time: 221.0636284351349 and batch: 250, loss is 5.3845552062988284 and perplexity is 218.01311167941046
At time: 221.40818643569946 and batch: 300, loss is 5.4314965152740475 and perplexity is 228.49092985876268
At time: 221.75140810012817 and batch: 350, loss is 5.477259712219238 and perplexity is 239.19035807648217
At time: 222.09731101989746 and batch: 400, loss is 5.385786552429199 and perplexity is 218.28172662589455
At time: 222.44382452964783 and batch: 450, loss is 5.41718825340271 and perplexity is 225.2448997026811
At time: 222.7889518737793 and batch: 500, loss is 5.397158603668213 and perplexity is 220.77820574545342
At time: 223.1335904598236 and batch: 550, loss is 5.45619462966919 and perplexity is 234.20449164907654
At time: 223.47928261756897 and batch: 600, loss is 5.320960998535156 and perplexity is 204.58038901052768
At time: 223.82627820968628 and batch: 650, loss is 5.482386283874511 and perplexity is 240.41973313356422
At time: 224.16982913017273 and batch: 700, loss is 5.472933530807495 and perplexity is 238.1578122960979
At time: 224.51454710960388 and batch: 750, loss is 5.417420148849487 and perplexity is 225.29713902612852
At time: 224.85983085632324 and batch: 800, loss is 5.373187332153321 and perplexity is 215.5487995968087
At time: 225.20450234413147 and batch: 850, loss is 5.338029184341431 and perplexity is 208.1021748523619
At time: 225.54868149757385 and batch: 900, loss is 5.292978200912476 and perplexity is 198.93501247522298
At time: 225.8941366672516 and batch: 950, loss is 5.352402925491333 and perplexity is 211.1149824331331
At time: 226.24018216133118 and batch: 1000, loss is 5.409692211151123 and perplexity is 223.56276696326927
At time: 226.58837628364563 and batch: 1050, loss is 5.287240934371948 and perplexity is 197.79693712697807
At time: 226.93161821365356 and batch: 1100, loss is 5.397414979934692 and perplexity is 220.83481529392458
At time: 227.2771074771881 and batch: 1150, loss is 5.395537548065185 and perplexity is 220.4206019241523
At time: 227.6227605342865 and batch: 1200, loss is 5.369965114593506 and perplexity is 214.85537225659667
At time: 227.96709537506104 and batch: 1250, loss is 5.373211488723755 and perplexity is 215.5540065794594
At time: 228.31050562858582 and batch: 1300, loss is 5.443887987136841 and perplexity is 231.3398836983751
At time: 228.6529791355133 and batch: 1350, loss is 5.375116271972656 and perplexity is 215.96498152526345
At time: 228.99667239189148 and batch: 1400, loss is 5.277925910949707 and perplexity is 195.96300882808114
At time: 229.34154725074768 and batch: 1450, loss is 5.344759187698364 and perplexity is 209.50742655805678
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.494042029747596 and perplexity of 243.23839936339738
Annealing...
Finished 21 epochs...
Completing Train Step...
At time: 230.5822627544403 and batch: 50, loss is 5.427111167907714 and perplexity is 227.49111163868878
At time: 230.9443483352661 and batch: 100, loss is 5.418016834259033 and perplexity is 225.43161065643804
At time: 231.28842496871948 and batch: 150, loss is 5.365844964981079 and perplexity is 213.97195712882456
At time: 231.63244891166687 and batch: 200, loss is 5.3279452133178715 and perplexity is 206.01422366385526
At time: 231.97819662094116 and batch: 250, loss is 5.3471794700622555 and perplexity is 210.01510780582154
At time: 232.32443833351135 and batch: 300, loss is 5.390030345916748 and perplexity is 219.21003758257388
At time: 232.6685676574707 and batch: 350, loss is 5.4282313823699955 and perplexity is 227.7460932623738
At time: 233.0128002166748 and batch: 400, loss is 5.333915424346924 and perplexity is 207.24785089735022
At time: 233.3583540916443 and batch: 450, loss is 5.373895578384399 and perplexity is 215.70151529551197
At time: 233.70583367347717 and batch: 500, loss is 5.345790510177612 and perplexity is 209.7236077337272
At time: 234.0511758327484 and batch: 550, loss is 5.402771797180176 and perplexity is 222.02096118786588
At time: 234.39593362808228 and batch: 600, loss is 5.269685363769531 and perplexity is 194.35480176201395
At time: 234.7412464618683 and batch: 650, loss is 5.4239664649963375 and perplexity is 226.7768433470202
At time: 235.0874376296997 and batch: 700, loss is 5.4177337074279786 and perplexity is 225.3677939534301
At time: 235.431791305542 and batch: 750, loss is 5.359544115066528 and perplexity is 212.62799045355496
At time: 235.77683568000793 and batch: 800, loss is 5.317538528442383 and perplexity is 203.88141553774813
At time: 236.12169289588928 and batch: 850, loss is 5.278772945404053 and perplexity is 196.12906656672033
At time: 236.46640300750732 and batch: 900, loss is 5.227017116546631 and perplexity is 186.23645253492882
At time: 236.8115005493164 and batch: 950, loss is 5.292132148742676 and perplexity is 198.76677425546
At time: 237.15497422218323 and batch: 1000, loss is 5.352038631439209 and perplexity is 211.03808850756863
At time: 237.4993278980255 and batch: 1050, loss is 5.2334029006958005 and perplexity is 187.4295236144427
At time: 237.84692215919495 and batch: 1100, loss is 5.331451177597046 and perplexity is 206.7377697953289
At time: 238.1916527748108 and batch: 1150, loss is 5.331357555389404 and perplexity is 206.71841545492993
At time: 238.53549003601074 and batch: 1200, loss is 5.308149881362915 and perplexity is 201.976202562153
At time: 238.89492630958557 and batch: 1250, loss is 5.308187122344971 and perplexity is 201.98372449434945
At time: 239.23993706703186 and batch: 1300, loss is 5.375901327133179 and perplexity is 216.13459251678307
At time: 239.58632588386536 and batch: 1350, loss is 5.301798143386841 and perplexity is 200.69736835547252
At time: 239.93093872070312 and batch: 1400, loss is 5.2031254482269285 and perplexity is 181.8396851775239
At time: 240.2762315273285 and batch: 1450, loss is 5.272300691604614 and perplexity is 194.8637685523427
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.431571243155716 and perplexity of 228.5080051399233
Finished 22 epochs...
Completing Train Step...
At time: 241.52351665496826 and batch: 50, loss is 5.388022298812866 and perplexity is 218.7702951609752
At time: 241.88292622566223 and batch: 100, loss is 5.394550886154175 and perplexity is 220.20322856647238
At time: 242.22848868370056 and batch: 150, loss is 5.342465581893921 and perplexity is 209.02744975763196
At time: 242.5728621482849 and batch: 200, loss is 5.309023103713989 and perplexity is 202.15264972420613
At time: 242.91757488250732 and batch: 250, loss is 5.330534086227417 and perplexity is 206.54825928338323
At time: 243.2625081539154 and batch: 300, loss is 5.376136455535889 and perplexity is 216.18541787330017
At time: 243.60649037361145 and batch: 350, loss is 5.415476942062378 and perplexity is 224.85976518799097
At time: 243.9512267112732 and batch: 400, loss is 5.323877506256103 and perplexity is 205.1779202232781
At time: 244.29541492462158 and batch: 450, loss is 5.361979112625122 and perplexity is 213.14636996148437
At time: 244.6403226852417 and batch: 500, loss is 5.3348815059661865 and perplexity is 207.44816598151448
At time: 244.98630714416504 and batch: 550, loss is 5.393953247070312 and perplexity is 220.0716658281215
At time: 245.32975459098816 and batch: 600, loss is 5.260889930725098 and perplexity is 192.65286273340672
At time: 245.67577838897705 and batch: 650, loss is 5.415216121673584 and perplexity is 224.80112482424414
At time: 246.01922249794006 and batch: 700, loss is 5.409424104690552 and perplexity is 223.50283637535114
At time: 246.36451196670532 and batch: 750, loss is 5.351733188629151 and perplexity is 210.97363828421535
At time: 246.70869088172913 and batch: 800, loss is 5.311074419021606 and perplexity is 202.56775415854133
At time: 247.0537281036377 and batch: 850, loss is 5.275341691970826 and perplexity is 195.45725127710176
At time: 247.39751768112183 and batch: 900, loss is 5.221672201156617 and perplexity is 185.24368993309344
At time: 247.77187538146973 and batch: 950, loss is 5.28702452659607 and perplexity is 197.75413696304994
At time: 248.11774230003357 and batch: 1000, loss is 5.349644060134888 and perplexity is 210.5333473172758
At time: 248.46309566497803 and batch: 1050, loss is 5.231549663543701 and perplexity is 187.0824939213626
At time: 248.80741095542908 and batch: 1100, loss is 5.330028810501099 and perplexity is 206.4439218234667
At time: 249.15328431129456 and batch: 1150, loss is 5.331420602798462 and perplexity is 206.7314489262879
At time: 249.49911236763 and batch: 1200, loss is 5.306254749298096 and perplexity is 201.5937934566784
At time: 249.84442806243896 and batch: 1250, loss is 5.3076611995697025 and perplexity is 201.87752458232845
At time: 250.18758535385132 and batch: 1300, loss is 5.377203149795532 and perplexity is 216.41614465315257
At time: 250.53327775001526 and batch: 1350, loss is 5.304575777053833 and perplexity is 201.25560705508397
At time: 250.87895846366882 and batch: 1400, loss is 5.205621194839478 and perplexity is 182.29407774432926
At time: 251.22259426116943 and batch: 1450, loss is 5.274299831390381 and perplexity is 195.25371811683308
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.427844968616453 and perplexity of 227.65810604045285
Finished 23 epochs...
Completing Train Step...
At time: 252.4803307056427 and batch: 50, loss is 5.382675895690918 and perplexity is 217.60378207517422
At time: 252.82376551628113 and batch: 100, loss is 5.38935977935791 and perplexity is 219.06309193593407
At time: 253.167959690094 and batch: 150, loss is 5.337492551803589 and perplexity is 207.99053041283915
At time: 253.5133240222931 and batch: 200, loss is 5.303956642150879 and perplexity is 201.13104124983894
At time: 253.8573944568634 and batch: 250, loss is 5.326836996078491 and perplexity is 205.78604161062933
At time: 254.20183897018433 and batch: 300, loss is 5.3720125961303715 and perplexity is 215.2957353281776
At time: 254.5466377735138 and batch: 350, loss is 5.412049160003662 and perplexity is 224.09031442730927
At time: 254.89363145828247 and batch: 400, loss is 5.321961755752564 and perplexity is 204.78522679071773
At time: 255.2407510280609 and batch: 450, loss is 5.357952585220337 and perplexity is 212.2898558076766
At time: 255.58585000038147 and batch: 500, loss is 5.330779294967652 and perplexity is 206.5989129319446
At time: 255.93058800697327 and batch: 550, loss is 5.391416330337524 and perplexity is 219.5140699229153
At time: 256.2765324115753 and batch: 600, loss is 5.25712293624878 and perplexity is 191.928505644786
At time: 256.63569164276123 and batch: 650, loss is 5.411060123443604 and perplexity is 223.86879047928517
At time: 256.98054695129395 and batch: 700, loss is 5.4057325267791745 and perplexity is 222.67927928930033
At time: 257.3260123729706 and batch: 750, loss is 5.349090557098389 and perplexity is 210.41684871439094
At time: 257.6731913089752 and batch: 800, loss is 5.308505878448487 and perplexity is 202.04811830175723
At time: 258.018102645874 and batch: 850, loss is 5.273880462646485 and perplexity is 195.17185197757527
At time: 258.36399698257446 and batch: 900, loss is 5.219621896743774 and perplexity is 184.86427307112007
At time: 258.7085027694702 and batch: 950, loss is 5.285126609802246 and perplexity is 197.37917200416072
At time: 259.05407190322876 and batch: 1000, loss is 5.348809862136841 and perplexity is 210.35779405369263
At time: 259.3990740776062 and batch: 1050, loss is 5.229959230422974 and perplexity is 186.78518821181459
At time: 259.7434058189392 and batch: 1100, loss is 5.329398727416992 and perplexity is 206.31388597150644
At time: 260.08670234680176 and batch: 1150, loss is 5.331393737792968 and perplexity is 206.72589515937804
At time: 260.4325678348541 and batch: 1200, loss is 5.304865417480468 and perplexity is 201.3139072576144
At time: 260.7801568508148 and batch: 1250, loss is 5.306890649795532 and perplexity is 201.72202781804356
At time: 261.1253077983856 and batch: 1300, loss is 5.377703294754029 and perplexity is 216.5244111690573
At time: 261.4690160751343 and batch: 1350, loss is 5.304750947952271 and perplexity is 201.29086426851623
At time: 261.81444454193115 and batch: 1400, loss is 5.206861505508423 and perplexity is 182.5203193097511
At time: 262.1600880622864 and batch: 1450, loss is 5.27286361694336 and perplexity is 194.97349318575496
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.427068726629273 and perplexity of 227.48145682995954
Finished 24 epochs...
Completing Train Step...
At time: 263.4166610240936 and batch: 50, loss is 5.380004558563233 and perplexity is 217.0232647369678
At time: 263.76023411750793 and batch: 100, loss is 5.386478633880615 and perplexity is 218.43284764807166
At time: 264.1044647693634 and batch: 150, loss is 5.334563407897949 and perplexity is 207.38218761500823
At time: 264.4486150741577 and batch: 200, loss is 5.300312976837159 and perplexity is 200.39952056891386
At time: 264.79356622695923 and batch: 250, loss is 5.324231443405151 and perplexity is 205.2505531643993
At time: 265.13907289505005 and batch: 300, loss is 5.369431180953979 and perplexity is 214.74068436630188
At time: 265.48383498191833 and batch: 350, loss is 5.410112504959106 and perplexity is 223.6567487585194
At time: 265.84319829940796 and batch: 400, loss is 5.32030571937561 and perplexity is 204.44637565803106
At time: 266.1894111633301 and batch: 450, loss is 5.355740251541138 and perplexity is 211.82071894490784
At time: 266.5357596874237 and batch: 500, loss is 5.328859090805054 and perplexity is 206.20258147977546
At time: 266.8796684741974 and batch: 550, loss is 5.3891442775726315 and perplexity is 219.01588853492441
At time: 267.2247016429901 and batch: 600, loss is 5.25480954170227 and perplexity is 191.48501247164208
At time: 267.5683071613312 and batch: 650, loss is 5.408399906158447 and perplexity is 223.27404228370077
At time: 267.9147593975067 and batch: 700, loss is 5.402818613052368 and perplexity is 222.0313555361172
At time: 268.25922894477844 and batch: 750, loss is 5.347123355865478 and perplexity is 210.00332330737785
At time: 268.60416531562805 and batch: 800, loss is 5.306730871200561 and perplexity is 201.68979953062797
At time: 268.9487211704254 and batch: 850, loss is 5.272741022109986 and perplexity is 194.94959190796206
At time: 269.293741941452 and batch: 900, loss is 5.21818359375 and perplexity is 184.5985733578712
At time: 269.63810324668884 and batch: 950, loss is 5.283334007263184 and perplexity is 197.02566654132676
At time: 269.9830446243286 and batch: 1000, loss is 5.348265218734741 and perplexity is 210.24325526331054
At time: 270.3285014629364 and batch: 1050, loss is 5.2289008522033695 and perplexity is 186.58760341503316
At time: 270.67542815208435 and batch: 1100, loss is 5.3282986259460445 and perplexity is 206.08704455923538
At time: 271.02147221565247 and batch: 1150, loss is 5.331094694137573 and perplexity is 206.66408433455294
At time: 271.3658130168915 and batch: 1200, loss is 5.303691577911377 and perplexity is 201.07773566836374
At time: 271.71058773994446 and batch: 1250, loss is 5.30655179977417 and perplexity is 201.65368588409507
At time: 272.05525493621826 and batch: 1300, loss is 5.377347259521485 and perplexity is 216.44733457178157
At time: 272.4003601074219 and batch: 1350, loss is 5.304217414855957 and perplexity is 201.18349757483256
At time: 272.7448868751526 and batch: 1400, loss is 5.206595792770385 and perplexity is 182.47182777865393
At time: 273.08922600746155 and batch: 1450, loss is 5.272011470794678 and perplexity is 194.8074180446373
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.426502716846955 and perplexity of 227.35273653200818
Finished 25 epochs...
Completing Train Step...
At time: 274.3281157016754 and batch: 50, loss is 5.3782297801971435 and perplexity is 216.63843813375144
At time: 274.6892263889313 and batch: 100, loss is 5.383564672470093 and perplexity is 217.79726923445372
At time: 275.0346009731293 and batch: 150, loss is 5.329662761688232 and perplexity is 206.36836710016178
At time: 275.37758708000183 and batch: 200, loss is 5.2944144439697265 and perplexity is 199.22093678498678
At time: 275.72143268585205 and batch: 250, loss is 5.320709066390991 and perplexity is 204.5288551262637
At time: 276.0663471221924 and batch: 300, loss is 5.362429723739624 and perplexity is 213.24243772778084
At time: 276.4129157066345 and batch: 350, loss is 5.407547378540039 and perplexity is 223.08377611128765
At time: 276.7584421634674 and batch: 400, loss is 5.3158261013031005 and perplexity is 203.53258222964132
At time: 277.1021008491516 and batch: 450, loss is 5.351259069442749 and perplexity is 210.87363534300968
At time: 277.44704818725586 and batch: 500, loss is 5.32685733795166 and perplexity is 205.7902277267643
At time: 277.79300451278687 and batch: 550, loss is 5.387493467330932 and perplexity is 218.65463312713996
At time: 278.1384723186493 and batch: 600, loss is 5.2525190734863285 and perplexity is 191.04692404208495
At time: 278.48231077194214 and batch: 650, loss is 5.406048822402954 and perplexity is 222.74972291076318
At time: 278.8276197910309 and batch: 700, loss is 5.400174608230591 and perplexity is 221.44507896208165
At time: 279.1745719909668 and batch: 750, loss is 5.3459092712402345 and perplexity is 209.748516211288
At time: 279.5197522640228 and batch: 800, loss is 5.306044626235962 and perplexity is 201.5514384015329
At time: 279.8645601272583 and batch: 850, loss is 5.271703157424927 and perplexity is 194.7473655710934
At time: 280.20852065086365 and batch: 900, loss is 5.217324542999267 and perplexity is 184.44006190928144
At time: 280.5544888973236 and batch: 950, loss is 5.282170457839966 and perplexity is 196.79655076027987
At time: 280.8984386920929 and batch: 1000, loss is 5.34749981880188 and perplexity is 210.08239665828324
At time: 281.2422926425934 and batch: 1050, loss is 5.228079175949096 and perplexity is 186.43435178220142
At time: 281.5864140987396 and batch: 1100, loss is 5.327433290481568 and perplexity is 205.90878726811033
At time: 281.93238639831543 and batch: 1150, loss is 5.330489377975464 and perplexity is 206.53902507819086
At time: 282.27799129486084 and batch: 1200, loss is 5.302705917358399 and perplexity is 200.8796389203463
At time: 282.62334060668945 and batch: 1250, loss is 5.30615463256836 and perplexity is 201.5736115556323
At time: 282.9682900905609 and batch: 1300, loss is 5.376998195648193 and perplexity is 216.37179381185447
At time: 283.31314420700073 and batch: 1350, loss is 5.303548097610474 and perplexity is 201.0488870439992
At time: 283.65773725509644 and batch: 1400, loss is 5.2056842708587645 and perplexity is 182.30557649173673
At time: 284.00150871276855 and batch: 1450, loss is 5.271278629302978 and perplexity is 194.6647073843369
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.425748906583867 and perplexity of 227.18142028395445
Finished 26 epochs...
Completing Train Step...
At time: 285.2363512516022 and batch: 50, loss is 5.376659288406372 and perplexity is 216.29847626863068
At time: 285.59472584724426 and batch: 100, loss is 5.382862539291382 and perplexity is 217.64440021897565
At time: 285.93766045570374 and batch: 150, loss is 5.33019323348999 and perplexity is 206.47786874088177
At time: 286.28304386138916 and batch: 200, loss is 5.296330223083496 and perplexity is 199.60296591957956
At time: 286.628130197525 and batch: 250, loss is 5.321624097824096 and perplexity is 204.71609110802146
At time: 286.97193002700806 and batch: 300, loss is 5.3660679626464844 and perplexity is 214.0196776963163
At time: 287.314879655838 and batch: 350, loss is 5.408368377685547 and perplexity is 223.26700290508037
At time: 287.658549785614 and batch: 400, loss is 5.31860842704773 and perplexity is 204.09966471131247
At time: 288.0035865306854 and batch: 450, loss is 5.353309116363525 and perplexity is 211.30637961128727
At time: 288.3476450443268 and batch: 500, loss is 5.326375370025635 and perplexity is 205.69106733549413
At time: 288.6938726902008 and batch: 550, loss is 5.386541967391968 and perplexity is 218.4466822053989
At time: 289.03526067733765 and batch: 600, loss is 5.25103796005249 and perplexity is 190.7641713225079
At time: 289.3814024925232 and batch: 650, loss is 5.404895544052124 and perplexity is 222.4929785549874
At time: 289.724582195282 and batch: 700, loss is 5.399201431274414 and perplexity is 221.2296785425393
At time: 290.06845712661743 and batch: 750, loss is 5.344725847244263 and perplexity is 209.50044160175915
At time: 290.4125030040741 and batch: 800, loss is 5.304886140823364 and perplexity is 201.31807919797237
At time: 290.75864815711975 and batch: 850, loss is 5.270953950881958 and perplexity is 194.60151421379945
At time: 291.10191893577576 and batch: 900, loss is 5.216213684082032 and perplexity is 184.23528877990003
At time: 291.44943165779114 and batch: 950, loss is 5.281343154907226 and perplexity is 196.6338077248603
At time: 291.79498863220215 and batch: 1000, loss is 5.346974563598633 and perplexity is 209.97207876138896
At time: 292.1663203239441 and batch: 1050, loss is 5.2277968215942385 and perplexity is 186.38171866202566
At time: 292.514399766922 and batch: 1100, loss is 5.32674123764038 and perplexity is 205.76633680416555
At time: 292.85768270492554 and batch: 1150, loss is 5.330053415298462 and perplexity is 206.44900139682068
At time: 293.20171308517456 and batch: 1200, loss is 5.301727380752563 and perplexity is 200.68316698346428
At time: 293.5481481552124 and batch: 1250, loss is 5.306005535125732 and perplexity is 201.54355968603227
At time: 293.892205953598 and batch: 1300, loss is 5.376481533050537 and perplexity is 216.26003147300045
At time: 294.2355680465698 and batch: 1350, loss is 5.3030908489227295 and perplexity is 200.95697871830788
At time: 294.5807936191559 and batch: 1400, loss is 5.205435256958008 and perplexity is 182.26018552073083
At time: 294.92582297325134 and batch: 1450, loss is 5.270564794540405 and perplexity is 194.52579853404146
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.425200633513621 and perplexity of 227.0568969686621
Finished 27 epochs...
Completing Train Step...
At time: 296.1809256076813 and batch: 50, loss is 5.375265274047852 and perplexity is 215.99716315318543
At time: 296.5275752544403 and batch: 100, loss is 5.381628885269165 and perplexity is 217.37606787789977
At time: 296.87089133262634 and batch: 150, loss is 5.328970737457276 and perplexity is 206.22560459288005
At time: 297.21471095085144 and batch: 200, loss is 5.295175256729126 and perplexity is 199.37256428838805
At time: 297.5590000152588 and batch: 250, loss is 5.320109558105469 and perplexity is 204.40627513052002
At time: 297.90403032302856 and batch: 300, loss is 5.3649095439910885 and perplexity is 213.77189685373511
At time: 298.2478187084198 and batch: 350, loss is 5.4075805187225345 and perplexity is 223.09116927084432
At time: 298.5919075012207 and batch: 400, loss is 5.317759523391723 and perplexity is 203.92647727987165
At time: 298.9364204406738 and batch: 450, loss is 5.351614866256714 and perplexity is 210.94867685958855
At time: 299.2833962440491 and batch: 500, loss is 5.325304174423218 and perplexity is 205.47084993771958
At time: 299.6303381919861 and batch: 550, loss is 5.385526285171509 and perplexity is 218.22492243195842
At time: 299.97866129875183 and batch: 600, loss is 5.2498292636871335 and perplexity is 190.5337346540266
At time: 300.3246159553528 and batch: 650, loss is 5.404028692245483 and perplexity is 222.3001936845908
At time: 300.66993737220764 and batch: 700, loss is 5.3983453750610355 and perplexity is 221.0403745406334
At time: 301.0286295413971 and batch: 750, loss is 5.34387843132019 and perplexity is 209.32298279277555
At time: 301.37386202812195 and batch: 800, loss is 5.304207239151001 and perplexity is 201.18145040133496
At time: 301.71996212005615 and batch: 850, loss is 5.270056123733521 and perplexity is 194.4268741012598
At time: 302.0655155181885 and batch: 900, loss is 5.215268621444702 and perplexity is 184.06125714034957
At time: 302.40989923477173 and batch: 950, loss is 5.280297956466675 and perplexity is 196.42839374355324
At time: 302.75316739082336 and batch: 1000, loss is 5.346348819732666 and perplexity is 209.84073112035577
At time: 303.0959846973419 and batch: 1050, loss is 5.226981067657471 and perplexity is 186.2297390387016
At time: 303.4425332546234 and batch: 1100, loss is 5.326223602294922 and perplexity is 205.65985243774378
At time: 303.7874321937561 and batch: 1150, loss is 5.329471530914307 and perplexity is 206.32890689073096
At time: 304.12990498542786 and batch: 1200, loss is 5.300857381820679 and perplexity is 200.5086487688793
At time: 304.47492957115173 and batch: 1250, loss is 5.305105581283569 and perplexity is 201.3622613774207
At time: 304.82069849967957 and batch: 1300, loss is 5.37599627494812 and perplexity is 216.1551149983427
At time: 305.1654155254364 and batch: 1350, loss is 5.302406740188599 and perplexity is 200.81954930767205
At time: 305.51039147377014 and batch: 1400, loss is 5.204982461929322 and perplexity is 182.1776776957757
At time: 305.8543701171875 and batch: 1450, loss is 5.2700537586212155 and perplexity is 194.42641426041124
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.4242981478699255 and perplexity of 226.8520738177244
Finished 28 epochs...
Completing Train Step...
At time: 307.1152241230011 and batch: 50, loss is 5.374123296737671 and perplexity is 215.7506400824688
At time: 307.46108055114746 and batch: 100, loss is 5.3806695556640625 and perplexity is 217.16763257560737
At time: 307.8077087402344 and batch: 150, loss is 5.328087282180786 and perplexity is 206.04349394950432
At time: 308.15171670913696 and batch: 200, loss is 5.2940105628967284 and perplexity is 199.14049146553884
At time: 308.4959361553192 and batch: 250, loss is 5.318997211456299 and perplexity is 204.17903090591625
At time: 308.84041261672974 and batch: 300, loss is 5.363427705764771 and perplexity is 213.45535607430122
At time: 309.1865837574005 and batch: 350, loss is 5.40688793182373 and perplexity is 222.93671274322625
At time: 309.5309648513794 and batch: 400, loss is 5.316859045028687 and perplexity is 203.74292855266222
At time: 309.8736729621887 and batch: 450, loss is 5.350216884613037 and perplexity is 210.65398051961276
At time: 310.23410272598267 and batch: 500, loss is 5.324221715927124 and perplexity is 205.24855660386422
At time: 310.57936930656433 and batch: 550, loss is 5.384375667572021 and perplexity is 217.97397339643612
At time: 310.9246606826782 and batch: 600, loss is 5.248074922561646 and perplexity is 190.19976652020097
At time: 311.26777386665344 and batch: 650, loss is 5.402730646133423 and perplexity is 222.01182498089557
At time: 311.61169695854187 and batch: 700, loss is 5.395468168258667 and perplexity is 220.40530971592943
At time: 311.9571809768677 and batch: 750, loss is 5.342747888565063 and perplexity is 209.0864679313705
At time: 312.3026921749115 and batch: 800, loss is 5.3025914001464844 and perplexity is 200.85663606130362
At time: 312.6456334590912 and batch: 850, loss is 5.26790223121643 and perplexity is 194.00855018611298
At time: 312.989394903183 and batch: 900, loss is 5.213721265792847 and perplexity is 183.77666915002618
At time: 313.33537006378174 and batch: 950, loss is 5.277995271682739 and perplexity is 195.9766014374118
At time: 313.68055868148804 and batch: 1000, loss is 5.3441896152496335 and perplexity is 209.3881308770765
At time: 314.0262396335602 and batch: 1050, loss is 5.225001678466797 and perplexity is 185.86148248801948
At time: 314.37142610549927 and batch: 1100, loss is 5.323889799118042 and perplexity is 205.1804424626271
At time: 314.7162597179413 and batch: 1150, loss is 5.328262233734131 and perplexity is 206.07954473230566
At time: 315.0628249645233 and batch: 1200, loss is 5.298900737762451 and perplexity is 200.11670828169898
At time: 315.40855503082275 and batch: 1250, loss is 5.303514451980591 and perplexity is 201.04212274135256
At time: 315.7532374858856 and batch: 1300, loss is 5.373972053527832 and perplexity is 215.7180117306085
At time: 316.0971505641937 and batch: 1350, loss is 5.300737094879151 and perplexity is 200.48453164728542
At time: 316.441933631897 and batch: 1400, loss is 5.203473882675171 and perplexity is 181.90305542744522
At time: 316.7863025665283 and batch: 1450, loss is 5.268551292419434 and perplexity is 194.13451448393695
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.4223283294938565 and perplexity of 226.40565625917253
Finished 29 epochs...
Completing Train Step...
At time: 318.0280439853668 and batch: 50, loss is 5.372207202911377 and perplexity is 215.33763741527696
At time: 318.38766074180603 and batch: 100, loss is 5.3780646324157715 and perplexity is 216.60266373044672
At time: 318.7304060459137 and batch: 150, loss is 5.325970716476441 and perplexity is 205.60785055317803
At time: 319.0902783870697 and batch: 200, loss is 5.291486778259277 and perplexity is 198.63853743085693
At time: 319.4364929199219 and batch: 250, loss is 5.316373701095581 and perplexity is 203.6440671512074
At time: 319.7808723449707 and batch: 300, loss is 5.360756845474243 and perplexity is 212.88600730392685
At time: 320.1251029968262 and batch: 350, loss is 5.405245456695557 and perplexity is 222.57084528374074
At time: 320.46976923942566 and batch: 400, loss is 5.314794673919677 and perplexity is 203.32276137699873
At time: 320.8144133090973 and batch: 450, loss is 5.3481418800354 and perplexity is 210.2173257327513
At time: 321.15842938423157 and batch: 500, loss is 5.32204571723938 and perplexity is 204.80242158467726
At time: 321.5030014514923 and batch: 550, loss is 5.3823514080047605 and perplexity is 217.5331837821874
At time: 321.8508155345917 and batch: 600, loss is 5.246777477264405 and perplexity is 189.95315274612878
At time: 322.1976704597473 and batch: 650, loss is 5.400973491668701 and perplexity is 221.6220584516944
At time: 322.54302310943604 and batch: 700, loss is 5.394008483886719 and perplexity is 220.0838222220602
At time: 322.8866527080536 and batch: 750, loss is 5.341178379058838 and perplexity is 208.7585621252815
At time: 323.23086071014404 and batch: 800, loss is 5.301898670196533 and perplexity is 200.71754483574858
At time: 323.5758707523346 and batch: 850, loss is 5.266717653274537 and perplexity is 193.77886800210612
At time: 323.92037868499756 and batch: 900, loss is 5.2124605560302735 and perplexity is 183.54512609405873
At time: 324.264981508255 and batch: 950, loss is 5.276876897811889 and perplexity is 195.75754884124805
At time: 324.60882592201233 and batch: 1000, loss is 5.343484649658203 and perplexity is 209.24057146781843
At time: 324.95444917678833 and batch: 1050, loss is 5.224166336059571 and perplexity is 185.70628933856122
At time: 325.29840779304504 and batch: 1100, loss is 5.323308143615723 and perplexity is 205.06113283121593
At time: 325.643595457077 and batch: 1150, loss is 5.327818212509155 and perplexity is 205.98806135219536
At time: 325.98690366744995 and batch: 1200, loss is 5.29811936378479 and perplexity is 199.9604033676013
At time: 326.33188819885254 and batch: 1250, loss is 5.302556991577148 and perplexity is 200.8497249907158
At time: 326.67577958106995 and batch: 1300, loss is 5.3734156608581545 and perplexity is 215.59802119418708
At time: 327.01950120925903 and batch: 1350, loss is 5.300084857940674 and perplexity is 200.35381086524742
At time: 327.3633005619049 and batch: 1400, loss is 5.202857713699341 and perplexity is 181.7910069320306
At time: 327.71029710769653 and batch: 1450, loss is 5.267618808746338 and perplexity is 193.9535715950523
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.421411758814102 and perplexity of 226.19823454576655
Finished 30 epochs...
Completing Train Step...
At time: 328.94650626182556 and batch: 50, loss is 5.3710275077819825 and perplexity is 215.08375443494415
At time: 329.3069865703583 and batch: 100, loss is 5.377120046615601 and perplexity is 216.39816053062265
At time: 329.6508812904358 and batch: 150, loss is 5.325105504989624 and perplexity is 205.4300332149942
At time: 329.9948375225067 and batch: 200, loss is 5.2903196144104 and perplexity is 198.40682895815434
At time: 330.33847761154175 and batch: 250, loss is 5.315165224075318 and perplexity is 203.3981166184582
At time: 330.6834628582001 and batch: 300, loss is 5.358835783004761 and perplexity is 212.4774325594742
At time: 331.0277645587921 and batch: 350, loss is 5.402711868286133 and perplexity is 222.00765611589068
At time: 331.37042212486267 and batch: 400, loss is 5.310429372787476 and perplexity is 202.43713072517113
At time: 331.7161693572998 and batch: 450, loss is 5.344877223968506 and perplexity is 209.53215749279968
At time: 332.06185007095337 and batch: 500, loss is 5.318312158584595 and perplexity is 204.03920537386182
At time: 332.4067003726959 and batch: 550, loss is 5.379198207855224 and perplexity is 216.8483384092551
At time: 332.7497248649597 and batch: 600, loss is 5.242448673248291 and perplexity is 189.13265993317623
At time: 333.0947823524475 and batch: 650, loss is 5.397878761291504 and perplexity is 220.93725811789264
At time: 333.4417338371277 and batch: 700, loss is 5.391663265228272 and perplexity is 219.56828229897738
At time: 333.78611159324646 and batch: 750, loss is 5.338534412384033 and perplexity is 208.2073404708966
At time: 334.1302878856659 and batch: 800, loss is 5.298352928161621 and perplexity is 200.00711244918116
At time: 334.47539258003235 and batch: 850, loss is 5.262032337188721 and perplexity is 192.87307637182093
At time: 334.8219208717346 and batch: 900, loss is 5.210101776123047 and perplexity is 183.11269374542502
At time: 335.1672031879425 and batch: 950, loss is 5.273587465286255 and perplexity is 195.11467551683972
At time: 335.5101888179779 and batch: 1000, loss is 5.341008586883545 and perplexity is 208.72311956392713
At time: 335.8560094833374 and batch: 1050, loss is 5.222554359436035 and perplexity is 185.4071762876965
At time: 336.20050263404846 and batch: 1100, loss is 5.320249319076538 and perplexity is 204.43484514646497
At time: 336.5601828098297 and batch: 1150, loss is 5.323299837112427 and perplexity is 205.0594294973146
At time: 336.9040551185608 and batch: 1200, loss is 5.294464902877808 and perplexity is 199.23098950954648
At time: 337.24961733818054 and batch: 1250, loss is 5.298758201599121 and perplexity is 200.08818644662702
At time: 337.59491062164307 and batch: 1300, loss is 5.370004501342773 and perplexity is 214.86383487792898
At time: 337.93988585472107 and batch: 1350, loss is 5.295506334304809 and perplexity is 199.43858300168506
At time: 338.2846767902374 and batch: 1400, loss is 5.199292163848877 and perplexity is 181.14397623004263
At time: 338.6289188861847 and batch: 1450, loss is 5.264884767532348 and perplexity is 193.42401877619318
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.419043907752404 and perplexity of 225.66326443067285
Finished 31 epochs...
Completing Train Step...
At time: 339.8871636390686 and batch: 50, loss is 5.369615716934204 and perplexity is 214.7803154055494
At time: 340.2294771671295 and batch: 100, loss is 5.373837032318115 and perplexity is 215.68888718996652
At time: 340.57623648643494 and batch: 150, loss is 5.320144472122192 and perplexity is 204.41341189921414
At time: 340.9207377433777 and batch: 200, loss is 5.287278032302856 and perplexity is 197.8042751201967
At time: 341.26440477371216 and batch: 250, loss is 5.312947940826416 and perplexity is 202.94762499994604
At time: 341.60896825790405 and batch: 300, loss is 5.357618532180786 and perplexity is 212.218951579624
At time: 341.9546022415161 and batch: 350, loss is 5.401664686203003 and perplexity is 221.77529535933274
At time: 342.2995285987854 and batch: 400, loss is 5.310483474731445 and perplexity is 202.44808326374908
At time: 342.6466944217682 and batch: 450, loss is 5.34469744682312 and perplexity is 209.4944917854771
At time: 342.9915060997009 and batch: 500, loss is 5.3180471038818355 and perplexity is 203.9851309895817
At time: 343.33621883392334 and batch: 550, loss is 5.377897624969482 and perplexity is 216.5664924932347
At time: 343.6820375919342 and batch: 600, loss is 5.240952310562133 and perplexity is 188.84986051613413
At time: 344.0275197029114 and batch: 650, loss is 5.396633892059326 and perplexity is 220.66239124517315
At time: 344.37211871147156 and batch: 700, loss is 5.390875597000122 and perplexity is 219.39540343363393
At time: 344.7189841270447 and batch: 750, loss is 5.337805318832397 and perplexity is 208.05559316726848
At time: 345.06588077545166 and batch: 800, loss is 5.297050895690918 and perplexity is 199.74686615572915
At time: 345.43393540382385 and batch: 850, loss is 5.260577688217163 and perplexity is 192.59271771079105
At time: 345.778151512146 and batch: 900, loss is 5.209002408981323 and perplexity is 182.91149628189314
At time: 346.12325716018677 and batch: 950, loss is 5.272643451690674 and perplexity is 194.93057152246345
At time: 346.4684853553772 and batch: 1000, loss is 5.339921655654908 and perplexity is 208.496375137257
At time: 346.81167578697205 and batch: 1050, loss is 5.221807088851929 and perplexity is 185.26867871280118
At time: 347.1559147834778 and batch: 1100, loss is 5.319994220733642 and perplexity is 204.38270080748796
At time: 347.5010130405426 and batch: 1150, loss is 5.322494020462036 and perplexity is 204.89425575352038
At time: 347.84543228149414 and batch: 1200, loss is 5.293728628158569 and perplexity is 199.0843547570366
At time: 348.1895384788513 and batch: 1250, loss is 5.29792311668396 and perplexity is 199.9211655684378
At time: 348.53374791145325 and batch: 1300, loss is 5.3690946006774904 and perplexity is 214.6684190496068
At time: 348.87831711769104 and batch: 1350, loss is 5.29480884552002 and perplexity is 199.29952532800857
At time: 349.22331738471985 and batch: 1400, loss is 5.19815993309021 and perplexity is 180.93899551304185
At time: 349.5688352584839 and batch: 1450, loss is 5.263994998931885 and perplexity is 193.25199270076016
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.418330265925481 and perplexity of 225.5022791361272
Finished 32 epochs...
Completing Train Step...
At time: 350.82913041114807 and batch: 50, loss is 5.368516225814819 and perplexity is 214.54429613046733
At time: 351.17650628089905 and batch: 100, loss is 5.372563457489013 and perplexity is 215.4143661010048
At time: 351.5223135948181 and batch: 150, loss is 5.318680391311646 and perplexity is 204.1143531219629
At time: 351.8696331977844 and batch: 200, loss is 5.28466980934143 and perplexity is 197.28902969752488
At time: 352.213237285614 and batch: 250, loss is 5.311354322433472 and perplexity is 202.62446149998314
At time: 352.5572564601898 and batch: 300, loss is 5.354890918731689 and perplexity is 211.64088903711755
At time: 352.9017825126648 and batch: 350, loss is 5.398202905654907 and perplexity is 221.00888529292266
At time: 353.2449564933777 and batch: 400, loss is 5.30682294845581 and perplexity is 201.70837142879202
At time: 353.5889608860016 and batch: 450, loss is 5.3405468463897705 and perplexity is 208.62676589454492
At time: 353.9332187175751 and batch: 500, loss is 5.316475191116333 and perplexity is 203.66473604063384
At time: 354.27632212638855 and batch: 550, loss is 5.376400527954101 and perplexity is 216.2425140178069
At time: 354.63583850860596 and batch: 600, loss is 5.240020990371704 and perplexity is 188.6740627028088
At time: 354.98072385787964 and batch: 650, loss is 5.395725383758545 and perplexity is 220.462008669456
At time: 355.32489466667175 and batch: 700, loss is 5.3900046634674075 and perplexity is 219.2044078041823
At time: 355.66819310188293 and batch: 750, loss is 5.336681385040283 and perplexity is 207.82188381698987
At time: 356.01296186447144 and batch: 800, loss is 5.296158266067505 and perplexity is 199.5686457400595
At time: 356.36038160324097 and batch: 850, loss is 5.258667840957641 and perplexity is 192.22524605573054
At time: 356.70789790153503 and batch: 900, loss is 5.207807111740112 and perplexity is 182.69299328902912
At time: 357.0518333911896 and batch: 950, loss is 5.272258186340332 and perplexity is 194.8554859923889
At time: 357.396849155426 and batch: 1000, loss is 5.338807935714722 and perplexity is 208.26429782536366
At time: 357.7423529624939 and batch: 1050, loss is 5.2209060001373295 and perplexity is 185.10181039011647
At time: 358.08864736557007 and batch: 1100, loss is 5.319039545059204 and perplexity is 204.1876747228928
At time: 358.4353268146515 and batch: 1150, loss is 5.321540832519531 and perplexity is 204.69904606998597
At time: 358.7795593738556 and batch: 1200, loss is 5.29282039642334 and perplexity is 198.90362211404326
At time: 359.12602186203003 and batch: 1250, loss is 5.296820631027222 and perplexity is 199.7008768058337
At time: 359.47140669822693 and batch: 1300, loss is 5.368340606689453 and perplexity is 214.5066213571309
At time: 359.81586480140686 and batch: 1350, loss is 5.2938636112213135 and perplexity is 199.11122958676876
At time: 360.1597261428833 and batch: 1400, loss is 5.19743634223938 and perplexity is 180.8081170682633
At time: 360.5052742958069 and batch: 1450, loss is 5.2633067226409915 and perplexity is 193.11902769959428
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.417744954427083 and perplexity of 225.37032867906086
Finished 33 epochs...
Completing Train Step...
At time: 361.74161887168884 and batch: 50, loss is 5.367456579208374 and perplexity is 214.31707540323816
At time: 362.10106205940247 and batch: 100, loss is 5.371718664169311 and perplexity is 215.23246232991843
At time: 362.44614839553833 and batch: 150, loss is 5.317915744781494 and perplexity is 203.95833744611835
At time: 362.7920386791229 and batch: 200, loss is 5.284926137924194 and perplexity is 197.3396069968289
At time: 363.13859701156616 and batch: 250, loss is 5.3110333347320555 and perplexity is 202.55943197723244
At time: 363.49901485443115 and batch: 300, loss is 5.356011991500854 and perplexity is 211.87828691994636
At time: 363.846314907074 and batch: 350, loss is 5.399984636306763 and perplexity is 221.40301461005836
At time: 364.190927028656 and batch: 400, loss is 5.308845329284668 and perplexity is 202.11671534646698
At time: 364.53471183776855 and batch: 450, loss is 5.3434131050109865 and perplexity is 209.22560196044986
At time: 364.8849730491638 and batch: 500, loss is 5.316426391601563 and perplexity is 203.6547975428381
At time: 365.2351903915405 and batch: 550, loss is 5.375692777633667 and perplexity is 216.08952245551913
At time: 365.5815312862396 and batch: 600, loss is 5.239337797164917 and perplexity is 188.545205886936
At time: 365.92813444137573 and batch: 650, loss is 5.394965906143188 and perplexity is 220.29463627467376
At time: 366.2738435268402 and batch: 700, loss is 5.389141235351563 and perplexity is 219.01522224118742
At time: 366.62239718437195 and batch: 750, loss is 5.335768432617187 and perplexity is 207.63223890614944
At time: 366.96729803085327 and batch: 800, loss is 5.295244350433349 and perplexity is 199.38634015328245
At time: 367.3111972808838 and batch: 850, loss is 5.257739639282226 and perplexity is 192.04690504130298
At time: 367.6554844379425 and batch: 900, loss is 5.206886777877807 and perplexity is 182.5249320889686
At time: 367.99848198890686 and batch: 950, loss is 5.271469917297363 and perplexity is 194.70194796751463
At time: 368.3424913883209 and batch: 1000, loss is 5.33814754486084 and perplexity is 208.12680739159902
At time: 368.68724274635315 and batch: 1050, loss is 5.22001802444458 and perplexity is 184.93751743667613
At time: 369.03095054626465 and batch: 1100, loss is 5.318520355224609 and perplexity is 204.08169007328422
At time: 369.3763573169708 and batch: 1150, loss is 5.320975322723388 and perplexity is 204.58331947951666
At time: 369.72184467315674 and batch: 1200, loss is 5.291784896850586 and perplexity is 198.6977640996622
At time: 370.06515765190125 and batch: 1250, loss is 5.296120452880859 and perplexity is 199.561099556283
At time: 370.4124319553375 and batch: 1300, loss is 5.367484064102173 and perplexity is 214.32296596624516
At time: 370.7562925815582 and batch: 1350, loss is 5.293069810867309 and perplexity is 198.95323773752563
At time: 371.10033416748047 and batch: 1400, loss is 5.196970224380493 and perplexity is 180.72385881453008
At time: 371.4455828666687 and batch: 1450, loss is 5.262434635162354 and perplexity is 192.95068442934905
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.4174705570579595 and perplexity of 225.30849613752414
Finished 34 epochs...
Completing Train Step...
At time: 372.6885812282562 and batch: 50, loss is 5.366616487503052 and perplexity is 214.1371050122838
At time: 373.048623085022 and batch: 100, loss is 5.371271238327027 and perplexity is 215.1361833046417
At time: 373.3954038619995 and batch: 150, loss is 5.317033348083496 and perplexity is 203.77844466269804
At time: 373.74219036102295 and batch: 200, loss is 5.284058637619019 and perplexity is 197.1684890606982
At time: 374.0870223045349 and batch: 250, loss is 5.310186223983765 and perplexity is 202.38791436270097
At time: 374.4321620464325 and batch: 300, loss is 5.355086507797242 and perplexity is 211.6822877292708
At time: 374.77780985832214 and batch: 350, loss is 5.399001436233521 and perplexity is 221.18543812801153
At time: 375.1214199066162 and batch: 400, loss is 5.308126230239868 and perplexity is 201.97142565462335
At time: 375.46544337272644 and batch: 450, loss is 5.342277908325196 and perplexity is 208.98822451106045
At time: 375.810019493103 and batch: 500, loss is 5.315647974014282 and perplexity is 203.49633075136714
At time: 376.15623354911804 and batch: 550, loss is 5.374734754562378 and perplexity is 215.88260284025168
At time: 376.50443625450134 and batch: 600, loss is 5.238527030944824 and perplexity is 188.39240175562674
At time: 376.85007405281067 and batch: 650, loss is 5.394392719268799 and perplexity is 220.16840246190122
At time: 377.19583106040955 and batch: 700, loss is 5.388252897262573 and perplexity is 218.82074906895411
At time: 377.54107689857483 and batch: 750, loss is 5.334851417541504 and perplexity is 207.44192428689868
At time: 377.8853271007538 and batch: 800, loss is 5.294499397277832 and perplexity is 199.23786198152607
At time: 378.22816276550293 and batch: 850, loss is 5.256820993423462 and perplexity is 191.87056295766214
At time: 378.5724391937256 and batch: 900, loss is 5.205943899154663 and perplexity is 182.3529143227484
At time: 378.9198389053345 and batch: 950, loss is 5.270789299011231 and perplexity is 194.5694753481398
At time: 379.2639682292938 and batch: 1000, loss is 5.337500505447387 and perplexity is 207.99218470201035
At time: 379.6079580783844 and batch: 1050, loss is 5.219275741577149 and perplexity is 184.80029242212694
At time: 379.95051288604736 and batch: 1100, loss is 5.317877140045166 and perplexity is 203.95046384025946
At time: 380.2983202934265 and batch: 1150, loss is 5.3201366138458255 and perplexity is 204.4118055684419
At time: 380.6459038257599 and batch: 1200, loss is 5.291114177703857 and perplexity is 198.5645383883806
At time: 381.00448203086853 and batch: 1250, loss is 5.295384826660157 and perplexity is 199.4143511614184
At time: 381.35020089149475 and batch: 1300, loss is 5.36697211265564 and perplexity is 214.21327109541335
At time: 381.6958305835724 and batch: 1350, loss is 5.292407903671265 and perplexity is 198.82159273098574
At time: 382.04214119911194 and batch: 1400, loss is 5.196487407684327 and perplexity is 180.63662337915576
At time: 382.3885097503662 and batch: 1450, loss is 5.26168514251709 and perplexity is 192.8061234909178
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.416620759882479 and perplexity of 225.11711094471028
Finished 35 epochs...
Completing Train Step...
At time: 383.66140365600586 and batch: 50, loss is 5.365627460479736 and perplexity is 213.92542232593584
At time: 384.0057682991028 and batch: 100, loss is 5.370948810577392 and perplexity is 215.0668286107336
At time: 384.35164308547974 and batch: 150, loss is 5.316153650283813 and perplexity is 203.5992600390206
At time: 384.69885897636414 and batch: 200, loss is 5.283340282440186 and perplexity is 197.02690291613746
At time: 385.04355907440186 and batch: 250, loss is 5.309516839981079 and perplexity is 202.2524844628507
At time: 385.3881256580353 and batch: 300, loss is 5.354426145553589 and perplexity is 211.54254688367166
At time: 385.7329912185669 and batch: 350, loss is 5.398411169052124 and perplexity is 221.05491814750178
At time: 386.0817024707794 and batch: 400, loss is 5.30702844619751 and perplexity is 201.74982630289816
At time: 386.42453384399414 and batch: 450, loss is 5.341472597122192 and perplexity is 208.81999170154094
At time: 386.7688376903534 and batch: 500, loss is 5.314899406433105 and perplexity is 203.34405699598724
At time: 387.11429929733276 and batch: 550, loss is 5.374421968460083 and perplexity is 215.8150883217079
At time: 387.4595067501068 and batch: 600, loss is 5.238047895431518 and perplexity is 188.3021578867563
At time: 387.80665469169617 and batch: 650, loss is 5.393535718917847 and perplexity is 219.97979889192897
At time: 388.153119802475 and batch: 700, loss is 5.38726170539856 and perplexity is 218.6039631787536
At time: 388.4991388320923 and batch: 750, loss is 5.33410457611084 and perplexity is 207.28705590164617
At time: 388.84605979919434 and batch: 800, loss is 5.293427467346191 and perplexity is 199.02440737837995
At time: 389.1902232170105 and batch: 850, loss is 5.254545888900757 and perplexity is 191.43453356640086
At time: 389.5345940589905 and batch: 900, loss is 5.205077743530273 and perplexity is 182.19503670354806
At time: 389.905348777771 and batch: 950, loss is 5.269774465560913 and perplexity is 194.37211989454158
At time: 390.25145959854126 and batch: 1000, loss is 5.336537828445435 and perplexity is 207.79205175635997
At time: 390.59541964530945 and batch: 1050, loss is 5.218730478286743 and perplexity is 184.69955507329803
At time: 390.9409387111664 and batch: 1100, loss is 5.3171177673339844 and perplexity is 203.79564821240737
At time: 391.2847146987915 and batch: 1150, loss is 5.319434061050415 and perplexity is 204.26824591804655
At time: 391.62983536720276 and batch: 1200, loss is 5.29028076171875 and perplexity is 198.39912046855636
At time: 391.9745833873749 and batch: 1250, loss is 5.294655027389527 and perplexity is 199.26887180520865
At time: 392.31798005104065 and batch: 1300, loss is 5.366239128112793 and perplexity is 214.05631360956045
At time: 392.66319251060486 and batch: 1350, loss is 5.291588182449341 and perplexity is 198.65868123217618
At time: 393.01056241989136 and batch: 1400, loss is 5.195969018936157 and perplexity is 180.54300765285473
At time: 393.3566105365753 and batch: 1450, loss is 5.260777616500855 and perplexity is 192.63122629164351
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.416509122930021 and perplexity of 225.091980959242
Finished 36 epochs...
Completing Train Step...
At time: 394.63099670410156 and batch: 50, loss is 5.365299482345581 and perplexity is 213.85527096975727
At time: 394.97537755966187 and batch: 100, loss is 5.370464897155761 and perplexity is 214.9627800630961
At time: 395.32039618492126 and batch: 150, loss is 5.315084323883057 and perplexity is 203.3816623373045
At time: 395.6656823158264 and batch: 200, loss is 5.2823765754699705 and perplexity is 196.83711817960221
At time: 396.01105308532715 and batch: 250, loss is 5.308923063278198 and perplexity is 202.13242729657844
At time: 396.35650634765625 and batch: 300, loss is 5.35416916847229 and perplexity is 211.4881922816456
At time: 396.7007348537445 and batch: 350, loss is 5.397501277923584 and perplexity is 220.85387371670168
At time: 397.0463500022888 and batch: 400, loss is 5.306236667633057 and perplexity is 201.5901483381862
At time: 397.3867840766907 and batch: 450, loss is 5.340404214859009 and perplexity is 208.59701126159246
At time: 397.7277913093567 and batch: 500, loss is 5.314046487808228 and perplexity is 203.17069500486238
At time: 398.0674421787262 and batch: 550, loss is 5.373609380722046 and perplexity is 215.6397908591844
At time: 398.4106843471527 and batch: 600, loss is 5.237061233520508 and perplexity is 188.1164589459091
At time: 398.756689786911 and batch: 650, loss is 5.39176679611206 and perplexity is 219.59101557407348
At time: 399.116815328598 and batch: 700, loss is 5.385914735794067 and perplexity is 218.30970850547016
At time: 399.45992636680603 and batch: 750, loss is 5.333389940261841 and perplexity is 207.13897405906428
At time: 399.8054447174072 and batch: 800, loss is 5.293504972457885 and perplexity is 199.0398333850931
At time: 400.1508209705353 and batch: 850, loss is 5.255223236083984 and perplexity is 191.56424513340752
At time: 400.4955105781555 and batch: 900, loss is 5.2046121406555175 and perplexity is 182.11022591629802
At time: 400.83952617645264 and batch: 950, loss is 5.269132146835327 and perplexity is 194.24731112999575
At time: 401.18453192710876 and batch: 1000, loss is 5.335968389511108 and perplexity is 207.67376055485056
At time: 401.5300016403198 and batch: 1050, loss is 5.217860708236694 and perplexity is 184.5389787743886
At time: 401.8749363422394 and batch: 1100, loss is 5.316851158142089 and perplexity is 203.74132166162644
At time: 402.22007966041565 and batch: 1150, loss is 5.318813781738282 and perplexity is 204.14158183859303
At time: 402.567156791687 and batch: 1200, loss is 5.289190492630005 and perplexity is 198.18292991462954
At time: 402.9131362438202 and batch: 1250, loss is 5.294337415695191 and perplexity is 199.20559173098394
At time: 403.25930166244507 and batch: 1300, loss is 5.365775241851806 and perplexity is 213.95703885447733
At time: 403.60239815711975 and batch: 1350, loss is 5.290947437286377 and perplexity is 198.5314324144816
At time: 403.9475722312927 and batch: 1400, loss is 5.195668506622314 and perplexity is 180.48876040726768
At time: 404.29272961616516 and batch: 1450, loss is 5.259942922592163 and perplexity is 192.47050526619591
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.416121523604434 and perplexity of 225.00475236519125
Finished 37 epochs...
Completing Train Step...
At time: 405.5354130268097 and batch: 50, loss is 5.364763145446777 and perplexity is 213.74060324994596
At time: 405.89470291137695 and batch: 100, loss is 5.370023603439331 and perplexity is 214.8679392668507
At time: 406.2389488220215 and batch: 150, loss is 5.3146333980560305 and perplexity is 203.2899729671192
At time: 406.58281445503235 and batch: 200, loss is 5.281764278411865 and perplexity is 196.7166322815596
At time: 406.9285526275635 and batch: 250, loss is 5.308445024490356 and perplexity is 202.0358232481309
At time: 407.2741253376007 and batch: 300, loss is 5.353429546356201 and perplexity is 211.33182876942647
At time: 407.6190848350525 and batch: 350, loss is 5.3969047737121585 and perplexity is 220.72217273492035
At time: 407.9780797958374 and batch: 400, loss is 5.305498275756836 and perplexity is 201.44135075255207
At time: 408.3252646923065 and batch: 450, loss is 5.339810514450074 and perplexity is 208.47320388658494
At time: 408.6707923412323 and batch: 500, loss is 5.313535213470459 and perplexity is 203.06684559235174
At time: 409.01468420028687 and batch: 550, loss is 5.37327787399292 and perplexity is 215.56831666518985
At time: 409.3607609272003 and batch: 600, loss is 5.236272888183594 and perplexity is 187.96821665343995
At time: 409.70732140541077 and batch: 650, loss is 5.392409038543701 and perplexity is 219.73209153951865
At time: 410.0535213947296 and batch: 700, loss is 5.3861329460144045 and perplexity is 218.35735111292783
At time: 410.39998865127563 and batch: 750, loss is 5.332919597625732 and perplexity is 207.04157067624206
At time: 410.7435073852539 and batch: 800, loss is 5.292592849731445 and perplexity is 198.85836740180056
At time: 411.09181356430054 and batch: 850, loss is 5.254184999465942 and perplexity is 191.3654593306088
At time: 411.4369127750397 and batch: 900, loss is 5.2038724231719975 and perplexity is 181.9755656096918
At time: 411.7829222679138 and batch: 950, loss is 5.2683799362182615 and perplexity is 194.1012511810365
At time: 412.12607312202454 and batch: 1000, loss is 5.335413284301758 and perplexity is 207.55851175908413
At time: 412.4740924835205 and batch: 1050, loss is 5.217634210586548 and perplexity is 184.4971858625126
At time: 412.81963539123535 and batch: 1100, loss is 5.316133308410644 and perplexity is 203.59511849081915
At time: 413.1645829677582 and batch: 1150, loss is 5.318174724578857 and perplexity is 204.01116537540855
At time: 413.5085017681122 and batch: 1200, loss is 5.288660535812378 and perplexity is 198.07792934512528
At time: 413.85281229019165 and batch: 1250, loss is 5.293714513778687 and perplexity is 199.08154482465514
At time: 414.19648480415344 and batch: 1300, loss is 5.36514009475708 and perplexity is 213.8211878101177
At time: 414.54057788848877 and batch: 1350, loss is 5.290324249267578 and perplexity is 198.4077485476008
At time: 414.8850259780884 and batch: 1400, loss is 5.195339021682739 and perplexity is 180.42930187483424
At time: 415.2301034927368 and batch: 1450, loss is 5.259282131195068 and perplexity is 192.34336442353523
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.416053185096154 and perplexity of 224.98937640144993
Finished 38 epochs...
Completing Train Step...
At time: 416.4675750732422 and batch: 50, loss is 5.364372205734253 and perplexity is 213.65705989122904
At time: 416.8303461074829 and batch: 100, loss is 5.369471244812011 and perplexity is 214.74928787893785
At time: 417.17514848709106 and batch: 150, loss is 5.313941917419434 and perplexity is 203.14945047708775
At time: 417.5210886001587 and batch: 200, loss is 5.281231508255005 and perplexity is 196.61185544398646
At time: 417.8667712211609 and batch: 250, loss is 5.307884798049927 and perplexity is 201.92266913695536
At time: 418.2114396095276 and batch: 300, loss is 5.353021450042725 and perplexity is 211.245602624668
At time: 418.5556571483612 and batch: 350, loss is 5.396262693405151 and perplexity is 220.58049686299842
At time: 418.8991267681122 and batch: 400, loss is 5.3048132705688475 and perplexity is 201.30340963279636
At time: 419.24300026893616 and batch: 450, loss is 5.33907732963562 and perplexity is 208.32041051900782
At time: 419.58848428726196 and batch: 500, loss is 5.312833595275879 and perplexity is 202.92442016874503
At time: 419.9333906173706 and batch: 550, loss is 5.3723516941070555 and perplexity is 215.36875405596783
At time: 420.27896547317505 and batch: 600, loss is 5.235525703430175 and perplexity is 187.8278221246866
At time: 420.62329053878784 and batch: 650, loss is 5.391369705200195 and perplexity is 219.50383528785702
At time: 420.96994805336 and batch: 700, loss is 5.3854512596130375 and perplexity is 218.20855059944114
At time: 421.3156740665436 and batch: 750, loss is 5.332312564849854 and perplexity is 206.91592779540375
At time: 421.65982937812805 and batch: 800, loss is 5.291729631423951 and perplexity is 198.6867832863903
At time: 422.0046634674072 and batch: 850, loss is 5.253446016311646 and perplexity is 191.22409571894622
At time: 422.34807801246643 and batch: 900, loss is 5.203223800659179 and perplexity is 181.8575704323556
At time: 422.6935086250305 and batch: 950, loss is 5.267619895935058 and perplexity is 193.95378245930223
At time: 423.0378403663635 and batch: 1000, loss is 5.334616441726684 and perplexity is 207.39318617807425
At time: 423.3819649219513 and batch: 1050, loss is 5.216068964004517 and perplexity is 184.2086281638366
At time: 423.7272071838379 and batch: 1100, loss is 5.314299249649048 and perplexity is 203.2220552944198
At time: 424.0741980075836 and batch: 1150, loss is 5.314243249893188 and perplexity is 203.2106752275814
At time: 424.41883540153503 and batch: 1200, loss is 5.2833551502227785 and perplexity is 197.02983229107153
At time: 424.76294207572937 and batch: 1250, loss is 5.289345140457153 and perplexity is 198.21358084410753
At time: 425.1076879501343 and batch: 1300, loss is 5.363245944976807 and perplexity is 213.41656178633306
At time: 425.45383644104004 and batch: 1350, loss is 5.2894984722137455 and perplexity is 198.24397561082068
At time: 425.79825735092163 and batch: 1400, loss is 5.194522171020508 and perplexity is 180.28197825900025
At time: 426.1425111293793 and batch: 1450, loss is 5.258706674575806 and perplexity is 192.23271100248198
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.415580553886218 and perplexity of 224.88306452539285
Finished 39 epochs...
Completing Train Step...
At time: 427.4094545841217 and batch: 50, loss is 5.36352159500122 and perplexity is 213.47539817555318
At time: 427.75398421287537 and batch: 100, loss is 5.369167594909668 and perplexity is 214.68408917793568
At time: 428.09903168678284 and batch: 150, loss is 5.313385629653931 and perplexity is 203.0364723503071
At time: 428.4462823867798 and batch: 200, loss is 5.2804836082458495 and perplexity is 196.46486440964944
At time: 428.789742231369 and batch: 250, loss is 5.307323541641235 and perplexity is 201.80937054259732
At time: 429.13010263442993 and batch: 300, loss is 5.35240065574646 and perplexity is 211.1145032565279
At time: 429.4742567539215 and batch: 350, loss is 5.395606050491333 and perplexity is 220.43570178733972
At time: 429.819593667984 and batch: 400, loss is 5.30411581993103 and perplexity is 201.16305939072535
At time: 430.1634752750397 and batch: 450, loss is 5.33823317527771 and perplexity is 208.1446301399516
At time: 430.5074257850647 and batch: 500, loss is 5.312039699554443 and perplexity is 202.76338327150822
At time: 430.8519971370697 and batch: 550, loss is 5.371798896789551 and perplexity is 215.2497316871055
At time: 431.1957206726074 and batch: 600, loss is 5.234920072555542 and perplexity is 187.7141022361064
At time: 431.5408251285553 and batch: 650, loss is 5.3905930328369145 and perplexity is 219.33341891276575
At time: 431.88489174842834 and batch: 700, loss is 5.384945363998413 and perplexity is 218.09818776900903
At time: 432.23208355903625 and batch: 750, loss is 5.331843452453613 and perplexity is 206.81888373276135
At time: 432.5792031288147 and batch: 800, loss is 5.291025772094726 and perplexity is 198.54698494533542
At time: 432.9235649108887 and batch: 850, loss is 5.2526795768737795 and perplexity is 191.0775901814996
At time: 433.2678668498993 and batch: 900, loss is 5.202500782012939 and perplexity is 181.72613154008397
At time: 433.6132004261017 and batch: 950, loss is 5.267266473770142 and perplexity is 193.8852470052993
At time: 433.95957922935486 and batch: 1000, loss is 5.334339685440064 and perplexity is 207.3357967518058
At time: 434.303085565567 and batch: 1050, loss is 5.21686544418335 and perplexity is 184.35540512965173
At time: 434.66223669052124 and batch: 1100, loss is 5.315722513198852 and perplexity is 203.51149976726043
At time: 435.0050265789032 and batch: 1150, loss is 5.31684757232666 and perplexity is 203.74059108416148
At time: 435.3525311946869 and batch: 1200, loss is 5.2876284885406495 and perplexity is 197.87360901081237
At time: 435.69764852523804 and batch: 1250, loss is 5.292285633087158 and perplexity is 198.79728418484993
At time: 436.04197692871094 and batch: 1300, loss is 5.364294319152832 and perplexity is 213.64041952127687
At time: 436.3865075111389 and batch: 1350, loss is 5.28909815788269 and perplexity is 198.16463158867245
At time: 436.7316460609436 and batch: 1400, loss is 5.1944215965271 and perplexity is 180.26384740213237
At time: 437.0794949531555 and batch: 1450, loss is 5.257943143844605 and perplexity is 192.08599143966487
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.415395883413462 and perplexity of 224.84153909793022
Finished 40 epochs...
Completing Train Step...
At time: 438.3465850353241 and batch: 50, loss is 5.363291816711426 and perplexity is 213.4263517987593
At time: 438.69123125076294 and batch: 100, loss is 5.368742647171021 and perplexity is 214.59287904085926
At time: 439.0363337993622 and batch: 150, loss is 5.312823133468628 and perplexity is 202.9222972236797
At time: 439.38325572013855 and batch: 200, loss is 5.279978551864624 and perplexity is 196.365663629295
At time: 439.72867703437805 and batch: 250, loss is 5.306816349029541 and perplexity is 201.70704027365926
At time: 440.0727210044861 and batch: 300, loss is 5.351930675506591 and perplexity is 211.0153069236317
At time: 440.41693925857544 and batch: 350, loss is 5.393615045547485 and perplexity is 219.9972498401169
At time: 440.7615077495575 and batch: 400, loss is 5.301921739578247 and perplexity is 200.72217531881796
At time: 441.108594417572 and batch: 450, loss is 5.3344384288787845 and perplexity is 207.3562708121699
At time: 441.45194458961487 and batch: 500, loss is 5.31066349029541 and perplexity is 202.4845303500545
At time: 441.7955410480499 and batch: 550, loss is 5.370714855194092 and perplexity is 215.01651845380633
At time: 442.13803148269653 and batch: 600, loss is 5.233993453979492 and perplexity is 187.54024342482995
At time: 442.48474860191345 and batch: 650, loss is 5.38985876083374 and perplexity is 219.17242763682424
At time: 442.8317108154297 and batch: 700, loss is 5.384373397827148 and perplexity is 217.97347865168902
At time: 443.1751141548157 and batch: 750, loss is 5.331288766860962 and perplexity is 206.70419608839913
At time: 443.53511214256287 and batch: 800, loss is 5.2902183341979985 and perplexity is 198.38673528993817
At time: 443.8805446624756 and batch: 850, loss is 5.2519416236877445 and perplexity is 190.9366358802798
At time: 444.2245922088623 and batch: 900, loss is 5.202015037536621 and perplexity is 181.63788051094588
At time: 444.56843972206116 and batch: 950, loss is 5.266505527496338 and perplexity is 193.7377668683918
At time: 444.91358971595764 and batch: 1000, loss is 5.333604440689087 and perplexity is 207.18341022311697
At time: 445.2584855556488 and batch: 1050, loss is 5.2160777759552 and perplexity is 184.21025140833532
At time: 445.6043186187744 and batch: 1100, loss is 5.314976596832276 and perplexity is 203.3597538107296
At time: 445.9488756656647 and batch: 1150, loss is 5.315995168685913 and perplexity is 203.5669958596652
At time: 446.29563546180725 and batch: 1200, loss is 5.286802349090576 and perplexity is 197.71020532269029
At time: 446.64134645462036 and batch: 1250, loss is 5.291723470687867 and perplexity is 198.68555923332562
At time: 446.989129781723 and batch: 1300, loss is 5.363235149383545 and perplexity is 213.4142578403729
At time: 447.33408546447754 and batch: 1350, loss is 5.288416051864624 and perplexity is 198.02950839031047
At time: 447.67806792259216 and batch: 1400, loss is 5.1939292240142825 and perplexity is 180.17511228577564
At time: 448.0228748321533 and batch: 1450, loss is 5.257169342041015 and perplexity is 191.937412445805
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.413138625968216 and perplexity of 224.33458623661383
Finished 41 epochs...
Completing Train Step...
At time: 449.28275966644287 and batch: 50, loss is 5.362257652282715 and perplexity is 213.2057479475685
At time: 449.64441299438477 and batch: 100, loss is 5.368698005676269 and perplexity is 214.58329950779978
At time: 449.9902355670929 and batch: 150, loss is 5.312700777053833 and perplexity is 202.89746989783177
At time: 450.3335952758789 and batch: 200, loss is 5.279418182373047 and perplexity is 196.25565712722633
At time: 450.67646884918213 and batch: 250, loss is 5.30594352722168 and perplexity is 201.53106277977838
At time: 451.0223045349121 and batch: 300, loss is 5.3521794414520265 and perplexity is 211.06780687578922
At time: 451.36672616004944 and batch: 350, loss is 5.395104722976685 and perplexity is 220.3252190011672
At time: 451.7105870246887 and batch: 400, loss is 5.302989921569824 and perplexity is 200.93669768587066
At time: 452.0544595718384 and batch: 450, loss is 5.33791335105896 and perplexity is 208.07807109039538
At time: 452.4170126914978 and batch: 500, loss is 5.310758991241455 and perplexity is 202.5038687376648
At time: 452.7611446380615 and batch: 550, loss is 5.370659379959107 and perplexity is 215.0045906927701
At time: 453.1048309803009 and batch: 600, loss is 5.232948551177978 and perplexity is 187.34438444369806
At time: 453.45110392570496 and batch: 650, loss is 5.389058961868286 and perplexity is 218.9972038371916
At time: 453.79839849472046 and batch: 700, loss is 5.38369797706604 and perplexity is 217.82630454665477
At time: 454.1426565647125 and batch: 750, loss is 5.330705585479737 and perplexity is 206.58368519308988
At time: 454.48960185050964 and batch: 800, loss is 5.289488086700439 and perplexity is 198.24191675606525
At time: 454.83324217796326 and batch: 850, loss is 5.251423282623291 and perplexity is 190.83769122694824
At time: 455.17770981788635 and batch: 900, loss is 5.201318740844727 and perplexity is 181.51145067706895
At time: 455.52271795272827 and batch: 950, loss is 5.2662953186035155 and perplexity is 193.69704574704141
At time: 455.8681089878082 and batch: 1000, loss is 5.333147430419922 and perplexity is 207.08874690974514
At time: 456.21149373054504 and batch: 1050, loss is 5.216003589630127 and perplexity is 184.19658603364076
At time: 456.55557084083557 and batch: 1100, loss is 5.314343194961548 and perplexity is 203.23098614737972
At time: 456.90092158317566 and batch: 1150, loss is 5.315143280029297 and perplexity is 203.3936532897984
At time: 457.24597668647766 and batch: 1200, loss is 5.286227540969849 and perplexity is 197.5965925470214
At time: 457.5888934135437 and batch: 1250, loss is 5.291084413528442 and perplexity is 198.55862836658272
At time: 457.9334285259247 and batch: 1300, loss is 5.3623350238800045 and perplexity is 213.22224465501867
At time: 458.2790803909302 and batch: 1350, loss is 5.287651653289795 and perplexity is 197.8781927564181
At time: 458.62220001220703 and batch: 1400, loss is 5.193628253936768 and perplexity is 180.12089312784616
At time: 458.9665765762329 and batch: 1450, loss is 5.256397504806518 and perplexity is 191.7893251611781
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.412744766626602 and perplexity of 224.246247361865
Finished 42 epochs...
Completing Train Step...
At time: 460.2063181400299 and batch: 50, loss is 5.361895380020141 and perplexity is 213.12852340786486
At time: 460.5661292076111 and batch: 100, loss is 5.368055553436279 and perplexity is 214.44548426096372
At time: 460.9129087924957 and batch: 150, loss is 5.312043991088867 and perplexity is 202.76425343941457
At time: 461.272451877594 and batch: 200, loss is 5.278975305557251 and perplexity is 196.1687592906547
At time: 461.61771178245544 and batch: 250, loss is 5.305699548721313 and perplexity is 201.4818995309359
At time: 461.9630494117737 and batch: 300, loss is 5.351071901321411 and perplexity is 210.8341702142651
At time: 462.3088550567627 and batch: 350, loss is 5.394491147994995 and perplexity is 220.1900744238585
At time: 462.6534581184387 and batch: 400, loss is 5.30246657371521 and perplexity is 200.83156540899893
At time: 462.9988648891449 and batch: 450, loss is 5.336975774765015 and perplexity is 207.88307345051777
At time: 463.3427155017853 and batch: 500, loss is 5.310139780044556 and perplexity is 202.37851488898562
At time: 463.687447309494 and batch: 550, loss is 5.3696952819824215 and perplexity is 214.79740509156264
At time: 464.0311257839203 and batch: 600, loss is 5.232418489456177 and perplexity is 187.2451066707081
At time: 464.37680649757385 and batch: 650, loss is 5.38820972442627 and perplexity is 218.81130216050119
At time: 464.721396446228 and batch: 700, loss is 5.382724695205688 and perplexity is 217.61440129325592
At time: 465.06811332702637 and batch: 750, loss is 5.329970045089722 and perplexity is 206.43179041793147
At time: 465.4123501777649 and batch: 800, loss is 5.288215312957764 and perplexity is 197.9897601529124
At time: 465.75742959976196 and batch: 850, loss is 5.250172462463379 and perplexity is 190.59913682092318
At time: 466.1020781993866 and batch: 900, loss is 5.200435495376587 and perplexity is 181.35120229059126
At time: 466.44682216644287 and batch: 950, loss is 5.2653811645507815 and perplexity is 193.52005771715696
At time: 466.79268431663513 and batch: 1000, loss is 5.332568264007568 and perplexity is 206.96884278872994
At time: 467.13730239868164 and batch: 1050, loss is 5.214840869903565 and perplexity is 183.98254149051465
At time: 467.48151111602783 and batch: 1100, loss is 5.314011945724487 and perplexity is 203.16367718690756
At time: 467.82656955718994 and batch: 1150, loss is 5.31428521156311 and perplexity is 203.2192024657672
At time: 468.1724112033844 and batch: 1200, loss is 5.28460428237915 and perplexity is 197.27610237026644
At time: 468.5178060531616 and batch: 1250, loss is 5.289682159423828 and perplexity is 198.2803938382952
At time: 468.8620674610138 and batch: 1300, loss is 5.361772365570069 and perplexity is 213.10230713228648
At time: 469.2074773311615 and batch: 1350, loss is 5.2865140247344975 and perplexity is 197.6532088721778
At time: 469.55267095565796 and batch: 1400, loss is 5.193075170516968 and perplexity is 180.02129879282413
At time: 469.8965229988098 and batch: 1450, loss is 5.255450296401977 and perplexity is 191.60774671037765
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.412289872128739 and perplexity of 224.14426217578233
Finished 43 epochs...
Completing Train Step...
At time: 471.15548753738403 and batch: 50, loss is 5.361051721572876 and perplexity is 212.94879155554685
At time: 471.49914741516113 and batch: 100, loss is 5.367127828598022 and perplexity is 214.24663011399082
At time: 471.8419258594513 and batch: 150, loss is 5.310505380630493 and perplexity is 202.45251811959818
At time: 472.18601298332214 and batch: 200, loss is 5.278027486801148 and perplexity is 195.9829149485271
At time: 472.53002429008484 and batch: 250, loss is 5.304621286392212 and perplexity is 201.2647662730196
At time: 472.87297797203064 and batch: 300, loss is 5.349752750396728 and perplexity is 210.55623148554247
At time: 473.21719908714294 and batch: 350, loss is 5.393642387390137 and perplexity is 220.00326505253886
At time: 473.56346559524536 and batch: 400, loss is 5.301857042312622 and perplexity is 200.70918956300054
At time: 473.9096086025238 and batch: 450, loss is 5.335926504135132 and perplexity is 207.66506224347654
At time: 474.2531626224518 and batch: 500, loss is 5.3092850399017335 and perplexity is 202.20560775412673
At time: 474.59558176994324 and batch: 550, loss is 5.368595972061157 and perplexity is 214.56140591496845
At time: 474.9398829936981 and batch: 600, loss is 5.2306324481964115 and perplexity is 186.91097765742802
At time: 475.28614473342896 and batch: 650, loss is 5.384962968826294 and perplexity is 218.1020273838636
At time: 475.63266468048096 and batch: 700, loss is 5.379453897476196 and perplexity is 216.90379136778222
At time: 475.97830295562744 and batch: 750, loss is 5.326884994506836 and perplexity is 205.79591925425572
At time: 476.324316740036 and batch: 800, loss is 5.282047891616822 and perplexity is 196.77243162845102
At time: 476.6724171638489 and batch: 850, loss is 5.24580945968628 and perplexity is 189.76936372510352
At time: 477.01633882522583 and batch: 900, loss is 5.199606971740723 and perplexity is 181.20101076030917
At time: 477.36057782173157 and batch: 950, loss is 5.263885536193848 and perplexity is 193.2308399662472
At time: 477.7051999568939 and batch: 1000, loss is 5.331760492324829 and perplexity is 206.80172672321555
At time: 478.05013847351074 and batch: 1050, loss is 5.2143089485168455 and perplexity is 183.8847032653419
At time: 478.39318799972534 and batch: 1100, loss is 5.313314409255981 and perplexity is 203.0220125268713
At time: 478.7377197742462 and batch: 1150, loss is 5.313410148620606 and perplexity is 203.04145065583762
At time: 479.11055040359497 and batch: 1200, loss is 5.2835478019714355 and perplexity is 197.067794089386
At time: 479.4573049545288 and batch: 1250, loss is 5.288721876144409 and perplexity is 198.09007988373466
At time: 479.8015024662018 and batch: 1300, loss is 5.361089181900025 and perplexity is 212.95676883635926
At time: 480.14482498168945 and batch: 1350, loss is 5.2854985332489015 and perplexity is 197.45259559924241
At time: 480.4900658130646 and batch: 1400, loss is 5.192359275817871 and perplexity is 179.89246861921524
At time: 480.8358430862427 and batch: 1450, loss is 5.254617195129395 and perplexity is 191.4481845277141
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.411581446981837 and perplexity of 223.985528975857
Finished 44 epochs...
Completing Train Step...
At time: 482.09303069114685 and batch: 50, loss is 5.360388994216919 and perplexity is 212.80771131999435
At time: 482.4378545284271 and batch: 100, loss is 5.366016302108765 and perplexity is 214.00862161026805
At time: 482.7836260795593 and batch: 150, loss is 5.309634265899658 and perplexity is 202.27623554109246
At time: 483.12919211387634 and batch: 200, loss is 5.277020215988159 and perplexity is 195.78560646667486
At time: 483.47631072998047 and batch: 250, loss is 5.303958730697632 and perplexity is 201.13146132186083
At time: 483.82197523117065 and batch: 300, loss is 5.348878002166748 and perplexity is 210.37212832843392
At time: 484.1665029525757 and batch: 350, loss is 5.3929017066955565 and perplexity is 219.84037321423676
At time: 484.51002073287964 and batch: 400, loss is 5.300976781845093 and perplexity is 200.5325909357568
At time: 484.8547718524933 and batch: 450, loss is 5.335028553009034 and perplexity is 207.47867286378457
At time: 485.20292949676514 and batch: 500, loss is 5.308739938735962 and perplexity is 202.0954152773667
At time: 485.5452754497528 and batch: 550, loss is 5.368470802307129 and perplexity is 214.5345509973129
At time: 485.88822984695435 and batch: 600, loss is 5.23127028465271 and perplexity is 187.0302343221413
At time: 486.2323970794678 and batch: 650, loss is 5.386607265472412 and perplexity is 218.4609468201472
At time: 486.5787265300751 and batch: 700, loss is 5.380663709640503 and perplexity is 217.16636301222195
At time: 486.92528796195984 and batch: 750, loss is 5.329481735229492 and perplexity is 206.33101234667095
At time: 487.2704474925995 and batch: 800, loss is 5.286896381378174 and perplexity is 197.72879733968952
At time: 487.61663150787354 and batch: 850, loss is 5.248864526748657 and perplexity is 190.35000836020092
At time: 487.9785737991333 and batch: 900, loss is 5.1991596698760985 and perplexity is 181.11997733487652
At time: 488.32494139671326 and batch: 950, loss is 5.264019336700439 and perplexity is 193.2566960802658
At time: 488.6699888706207 and batch: 1000, loss is 5.331331329345703 and perplexity is 206.71299411982278
At time: 489.0125925540924 and batch: 1050, loss is 5.2137000942230225 and perplexity is 183.7727783506305
At time: 489.35878896713257 and batch: 1100, loss is 5.312934246063232 and perplexity is 202.9448456993139
At time: 489.7037663459778 and batch: 1150, loss is 5.312458667755127 and perplexity is 202.8483524798173
At time: 490.04902625083923 and batch: 1200, loss is 5.2811692237854 and perplexity is 196.59960996020777
At time: 490.39568161964417 and batch: 1250, loss is 5.285747289657593 and perplexity is 197.50171930747575
At time: 490.7426211833954 and batch: 1300, loss is 5.359125928878784 and perplexity is 212.53909095438635
At time: 491.0858564376831 and batch: 1350, loss is 5.28150710105896 and perplexity is 196.66604772367717
At time: 491.43043208122253 and batch: 1400, loss is 5.1868501567840575 and perplexity is 178.90414449359884
At time: 491.77356243133545 and batch: 1450, loss is 5.248936185836792 and perplexity is 190.3636491569641
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.40898197532719 and perplexity of 223.40404105036146
Finished 45 epochs...
Completing Train Step...
At time: 493.0180244445801 and batch: 50, loss is 5.358382196426391 and perplexity is 212.38107750219126
At time: 493.37884855270386 and batch: 100, loss is 5.3648787784576415 and perplexity is 213.76532014846086
At time: 493.7249343395233 and batch: 150, loss is 5.308195867538452 and perplexity is 201.98549088882396
At time: 494.069890499115 and batch: 200, loss is 5.275450038909912 and perplexity is 195.47842961928342
At time: 494.41367983818054 and batch: 250, loss is 5.302976636886597 and perplexity is 200.93402832322403
At time: 494.7569828033447 and batch: 300, loss is 5.348250999450683 and perplexity is 210.24026577599696
At time: 495.1028542518616 and batch: 350, loss is 5.392162008285522 and perplexity is 219.67781776812333
At time: 495.44938611984253 and batch: 400, loss is 5.300284938812256 and perplexity is 200.39390184093503
At time: 495.79361152648926 and batch: 450, loss is 5.334124736785888 and perplexity is 207.29123499074848
At time: 496.139422416687 and batch: 500, loss is 5.30754656791687 and perplexity is 201.85438435434253
At time: 496.4855194091797 and batch: 550, loss is 5.367935676574707 and perplexity is 214.41977875011088
At time: 496.84477496147156 and batch: 600, loss is 5.230419816970826 and perplexity is 186.8712387721869
At time: 497.18790912628174 and batch: 650, loss is 5.386044645309449 and perplexity is 218.3380708561349
At time: 497.5338685512543 and batch: 700, loss is 5.3795151519775395 and perplexity is 216.91707810829408
At time: 497.88007044792175 and batch: 750, loss is 5.329166822433471 and perplexity is 206.26604630052364
At time: 498.2255861759186 and batch: 800, loss is 5.286232347488403 and perplexity is 197.59754230099233
At time: 498.5702209472656 and batch: 850, loss is 5.247837600708007 and perplexity is 190.15463331480865
At time: 498.9138560295105 and batch: 900, loss is 5.198203125 and perplexity is 180.94681078259055
At time: 499.2578887939453 and batch: 950, loss is 5.263343963623047 and perplexity is 193.12621977575859
At time: 499.6019775867462 and batch: 1000, loss is 5.3307253074646 and perplexity is 206.58775947357853
At time: 499.9447069168091 and batch: 1050, loss is 5.213154411315918 and perplexity is 183.67252404271218
At time: 500.2875933647156 and batch: 1100, loss is 5.312413167953491 and perplexity is 202.83912312998572
At time: 500.63102984428406 and batch: 1150, loss is 5.31154281616211 and perplexity is 202.6626585400827
At time: 500.9748475551605 and batch: 1200, loss is 5.281311159133911 and perplexity is 196.62751637477106
At time: 501.3190710544586 and batch: 1250, loss is 5.286458473205567 and perplexity is 197.6422292391974
At time: 501.66370010375977 and batch: 1300, loss is 5.3599878025054934 and perplexity is 212.72235175400544
At time: 502.0102198123932 and batch: 1350, loss is 5.284545011520386 and perplexity is 197.2644099927774
At time: 502.35679149627686 and batch: 1400, loss is 5.1912351322174075 and perplexity is 179.6903572742168
At time: 502.7016191482544 and batch: 1450, loss is 5.2529650402069095 and perplexity is 191.13214361341105
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.409948104467148 and perplexity of 223.61998250127183
Annealing...
Finished 46 epochs...
Completing Train Step...
At time: 503.9430181980133 and batch: 50, loss is 5.3596336364746096 and perplexity is 212.64702606269236
At time: 504.30164647102356 and batch: 100, loss is 5.3587443637847905 and perplexity is 212.4580089261886
At time: 504.6467206478119 and batch: 150, loss is 5.298340225219727 and perplexity is 200.00457178659033
At time: 504.9929995536804 and batch: 200, loss is 5.265967321395874 and perplexity is 193.63352407494304
At time: 505.33706617355347 and batch: 250, loss is 5.2971415615081785 and perplexity is 199.76497718960778
At time: 505.69660115242004 and batch: 300, loss is 5.335740699768066 and perplexity is 207.62648075244053
At time: 506.04056906700134 and batch: 350, loss is 5.377605619430542 and perplexity is 216.50326310999225
At time: 506.3894326686859 and batch: 400, loss is 5.2838434314727785 and perplexity is 197.12606175547958
At time: 506.7337143421173 and batch: 450, loss is 5.320036354064942 and perplexity is 204.3913123129474
At time: 507.07802057266235 and batch: 500, loss is 5.292095413208008 and perplexity is 198.75947258584978
At time: 507.42283964157104 and batch: 550, loss is 5.355244102478028 and perplexity is 211.71565036065113
At time: 507.7667028903961 and batch: 600, loss is 5.2159104156494145 and perplexity is 184.17942450400284
At time: 508.1114275455475 and batch: 650, loss is 5.370624551773071 and perplexity is 214.997102603286
At time: 508.4554195404053 and batch: 700, loss is 5.364711685180664 and perplexity is 213.72960438462823
At time: 508.8003225326538 and batch: 750, loss is 5.313307132720947 and perplexity is 203.02053523545925
At time: 509.1441898345947 and batch: 800, loss is 5.264143314361572 and perplexity is 193.2806570787277
At time: 509.490186214447 and batch: 850, loss is 5.2262053966522215 and perplexity is 186.0853420393368
At time: 509.8345549106598 and batch: 900, loss is 5.177002162933349 and perplexity is 177.15094449933184
At time: 510.1772394180298 and batch: 950, loss is 5.23758171081543 and perplexity is 188.2143947760688
At time: 510.5221047401428 and batch: 1000, loss is 5.306661577224731 and perplexity is 201.6758241267453
At time: 510.86749267578125 and batch: 1050, loss is 5.189888067245484 and perplexity is 179.44846564658724
At time: 511.2123444080353 and batch: 1100, loss is 5.293890104293824 and perplexity is 199.11650472488876
At time: 511.55670499801636 and batch: 1150, loss is 5.283854675292969 and perplexity is 197.12827821793354
At time: 511.90118622779846 and batch: 1200, loss is 5.255120601654053 and perplexity is 191.54458505523067
At time: 512.2469296455383 and batch: 1250, loss is 5.260439929962158 and perplexity is 192.56618830143705
At time: 512.5926008224487 and batch: 1300, loss is 5.33453634262085 and perplexity is 207.37657483459103
At time: 512.9382066726685 and batch: 1350, loss is 5.257957372665405 and perplexity is 192.08872461626027
At time: 513.2834248542786 and batch: 1400, loss is 5.159301223754883 and perplexity is 174.04279613211548
At time: 513.6298975944519 and batch: 1450, loss is 5.220595607757568 and perplexity is 185.04436511444044
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.393075796274038 and perplexity of 219.8786484637073
Finished 47 epochs...
Completing Train Step...
At time: 514.8806657791138 and batch: 50, loss is 5.347935447692871 and perplexity is 210.17393455658524
At time: 515.2269563674927 and batch: 100, loss is 5.3498928928375244 and perplexity is 210.58574141749634
At time: 515.570827960968 and batch: 150, loss is 5.289775362014771 and perplexity is 198.29887494596426
At time: 515.9144065380096 and batch: 200, loss is 5.260197744369507 and perplexity is 192.51955719191815
At time: 516.2619302272797 and batch: 250, loss is 5.29036322593689 and perplexity is 198.41548197151536
At time: 516.6087629795074 and batch: 300, loss is 5.33030484199524 and perplexity is 206.50091471321835
At time: 516.954240322113 and batch: 350, loss is 5.372689981460571 and perplexity is 215.4416229064177
At time: 517.2984974384308 and batch: 400, loss is 5.279952840805054 and perplexity is 196.36061492492394
At time: 517.6433010101318 and batch: 450, loss is 5.315770225524902 and perplexity is 203.52121000593945
At time: 517.9863114356995 and batch: 500, loss is 5.287967348098755 and perplexity is 197.9406717363036
At time: 518.3295698165894 and batch: 550, loss is 5.351676616668701 and perplexity is 210.9617034294867
At time: 518.6727566719055 and batch: 600, loss is 5.213328065872193 and perplexity is 183.70442238294066
At time: 519.0183110237122 and batch: 650, loss is 5.367621698379517 and perplexity is 214.35246618285808
At time: 519.3655591011047 and batch: 700, loss is 5.363179388046265 and perplexity is 213.40235790774227
At time: 519.7124025821686 and batch: 750, loss is 5.310848302841187 and perplexity is 202.5219554898
At time: 520.0574405193329 and batch: 800, loss is 5.264312906265259 and perplexity is 193.3134386929771
At time: 520.4029381275177 and batch: 850, loss is 5.2250542640686035 and perplexity is 185.87125638290954
At time: 520.7480874061584 and batch: 900, loss is 5.173669042587281 and perplexity is 176.56146203563975
At time: 521.0915460586548 and batch: 950, loss is 5.23677357673645 and perplexity is 188.0623537525365
At time: 521.4337160587311 and batch: 1000, loss is 5.305670118331909 and perplexity is 201.4759699274304
At time: 521.780847787857 and batch: 1050, loss is 5.19084436416626 and perplexity is 179.62015374103703
At time: 522.1261169910431 and batch: 1100, loss is 5.2929320144653325 and perplexity is 198.92582458596397
At time: 522.4690320491791 and batch: 1150, loss is 5.283843870162964 and perplexity is 197.12614823276715
At time: 522.8135454654694 and batch: 1200, loss is 5.255726461410522 and perplexity is 191.6606693727426
At time: 523.16108751297 and batch: 1250, loss is 5.261563949584961 and perplexity is 192.78275816736416
At time: 523.5036196708679 and batch: 1300, loss is 5.336257400512696 and perplexity is 207.73378923044797
At time: 523.8530519008636 and batch: 1350, loss is 5.257979059219361 and perplexity is 192.0928904039215
At time: 524.1967732906342 and batch: 1400, loss is 5.159653291702271 and perplexity is 174.10408180983566
At time: 524.5402822494507 and batch: 1450, loss is 5.222398529052734 and perplexity is 185.37828646736315
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.392400757879273 and perplexity of 219.730272019338
Finished 48 epochs...
Completing Train Step...
At time: 525.7949931621552 and batch: 50, loss is 5.346988582611084 and perplexity is 209.97502238320885
At time: 526.1389389038086 and batch: 100, loss is 5.349065818786621 and perplexity is 210.41164342117156
At time: 526.4839265346527 and batch: 150, loss is 5.287589063644409 and perplexity is 197.86580801808614
At time: 526.8302602767944 and batch: 200, loss is 5.256757068634033 and perplexity is 191.858298064347
At time: 527.1783709526062 and batch: 250, loss is 5.287330245971679 and perplexity is 197.814603476748
At time: 527.5227417945862 and batch: 300, loss is 5.328277750015259 and perplexity is 206.08274234526382
At time: 527.8685657978058 and batch: 350, loss is 5.3709392166137695 and perplexity is 215.06476527730126
At time: 528.212943315506 and batch: 400, loss is 5.278766975402832 and perplexity is 196.12789567944867
At time: 528.5559577941895 and batch: 450, loss is 5.314444742202759 and perplexity is 203.25162474122988
At time: 528.899982213974 and batch: 500, loss is 5.286416225433349 and perplexity is 197.63387947169673
At time: 529.244859457016 and batch: 550, loss is 5.350363759994507 and perplexity is 210.68492267562468
At time: 529.5906662940979 and batch: 600, loss is 5.212344608306885 and perplexity is 183.52384568828018
At time: 529.9350464344025 and batch: 650, loss is 5.366373748779297 and perplexity is 214.08513195289675
At time: 530.2824485301971 and batch: 700, loss is 5.362736330032349 and perplexity is 213.30782922527413
At time: 530.6276016235352 and batch: 750, loss is 5.30987208366394 and perplexity is 202.3243461437475
At time: 530.9723722934723 and batch: 800, loss is 5.264389095306396 and perplexity is 193.32816761959432
At time: 531.3163366317749 and batch: 850, loss is 5.2264245510101315 and perplexity is 186.12612792202663
At time: 531.6597764492035 and batch: 900, loss is 5.176253442764282 and perplexity is 177.01835765563172
At time: 532.0046598911285 and batch: 950, loss is 5.237841997146607 and perplexity is 188.26339078657892
At time: 532.3651821613312 and batch: 1000, loss is 5.3056136322021485 and perplexity is 201.4645896510664
At time: 532.7097973823547 and batch: 1050, loss is 5.191352510452271 and perplexity is 179.7114502490795
At time: 533.0537745952606 and batch: 1100, loss is 5.293154983520508 and perplexity is 198.970183834308
At time: 533.3993492126465 and batch: 1150, loss is 5.284400310516357 and perplexity is 197.2358676996913
At time: 533.7437040805817 and batch: 1200, loss is 5.256051244735718 and perplexity is 191.72292767193218
At time: 534.0880365371704 and batch: 1250, loss is 5.262193794250488 and perplexity is 192.90421960610587
At time: 534.4323170185089 and batch: 1300, loss is 5.337290649414062 and perplexity is 207.94854086678743
At time: 534.776346206665 and batch: 1350, loss is 5.258407421112061 and perplexity is 192.17519330448377
At time: 535.1218767166138 and batch: 1400, loss is 5.159933090209961 and perplexity is 174.15280268780543
At time: 535.4646687507629 and batch: 1450, loss is 5.22298900604248 and perplexity is 185.48778040356427
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.392162877270299 and perplexity of 219.67800866488565
Finished 49 epochs...
Completing Train Step...
At time: 536.7109396457672 and batch: 50, loss is 5.346380491256713 and perplexity is 209.84737720136286
At time: 537.0813550949097 and batch: 100, loss is 5.34836742401123 and perplexity is 210.26474433147408
At time: 537.4258718490601 and batch: 150, loss is 5.286391859054565 and perplexity is 197.62906390839814
At time: 537.7720017433167 and batch: 200, loss is 5.255516414642334 and perplexity is 191.62041589625636
At time: 538.1159338951111 and batch: 250, loss is 5.28597204208374 and perplexity is 197.54611328669878
At time: 538.4596972465515 and batch: 300, loss is 5.327016143798828 and perplexity is 205.82291101329724
At time: 538.8051288127899 and batch: 350, loss is 5.36989242553711 and perplexity is 214.83975518992747
At time: 539.1517760753632 and batch: 400, loss is 5.2783160972595216 and perplexity is 196.03948583052528
At time: 539.4961082935333 and batch: 450, loss is 5.313726978302002 and perplexity is 203.1057904057922
At time: 539.8404533863068 and batch: 500, loss is 5.285440053939819 and perplexity is 197.4410490454958
At time: 540.1860725879669 and batch: 550, loss is 5.349453649520874 and perplexity is 210.4932633496703
At time: 540.5317275524139 and batch: 600, loss is 5.211701240539551 and perplexity is 183.40581033556924
At time: 540.8771758079529 and batch: 650, loss is 5.365502500534058 and perplexity is 213.89869188693473
At time: 541.236053943634 and batch: 700, loss is 5.362352886199951 and perplexity is 213.22605333298827
At time: 541.5811097621918 and batch: 750, loss is 5.309210081100463 and perplexity is 202.19045123222386
At time: 541.9289247989655 and batch: 800, loss is 5.2638034248352055 and perplexity is 193.21497417083592
At time: 542.2750399112701 and batch: 850, loss is 5.226463584899903 and perplexity is 186.13339329058434
At time: 542.6196570396423 and batch: 900, loss is 5.176338300704956 and perplexity is 177.03337970628502
At time: 542.9631423950195 and batch: 950, loss is 5.238320713043213 and perplexity is 188.35353703999817
At time: 543.3088760375977 and batch: 1000, loss is 5.30550368309021 and perplexity is 201.44244001603587
At time: 543.653487443924 and batch: 1050, loss is 5.1916635227203365 and perplexity is 179.7673514073412
At time: 543.9986217021942 and batch: 1100, loss is 5.2929139328002925 and perplexity is 198.92222770835488
At time: 544.3430979251862 and batch: 1150, loss is 5.284473562240601 and perplexity is 197.25031609626154
At time: 544.6869666576385 and batch: 1200, loss is 5.256151733398437 and perplexity is 191.74219462058525
At time: 545.0328402519226 and batch: 1250, loss is 5.262584266662597 and perplexity is 192.97955808988394
At time: 545.37659907341 and batch: 1300, loss is 5.337898693084717 and perplexity is 208.07502110974207
At time: 545.7198224067688 and batch: 1350, loss is 5.258228731155396 and perplexity is 192.14085659542397
At time: 546.0650148391724 and batch: 1400, loss is 5.15985857963562 and perplexity is 174.13982694587511
At time: 546.4105865955353 and batch: 1450, loss is 5.223192472457885 and perplexity is 185.52552477707036
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.391995943509615 and perplexity of 219.64134004945976
Finished Training.
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f3cbdcfe358>
SETTINGS FOR THIS RUN
{'lr': 0.6456549527031341, 'batch_size': 20, 'dropout': 0.7685258544297481, 'wordvec_source': 'glove', 'anneal': 3.209469390982112, 'num_layers': 1, 'seq_len': 35, 'wordvec_dim': 200, 'tune_wordvecs': True, 'data': 'ptb'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.632260799407959 and batch: 50, loss is 8.192137870788574 and perplexity is 3612.436920404729
At time: 0.9985263347625732 and batch: 100, loss is 6.98537769317627 and perplexity is 1080.7145191584602
At time: 1.3479137420654297 and batch: 150, loss is 6.673540258407593 and perplexity is 791.1916751157975
At time: 1.6977810859680176 and batch: 200, loss is 6.376778402328491 and perplexity is 588.0302559831557
At time: 2.048551559448242 and batch: 250, loss is 6.273932209014893 and perplexity is 530.5595524770824
At time: 2.3982479572296143 and batch: 300, loss is 6.323133811950684 and perplexity is 557.316784665949
At time: 2.7489330768585205 and batch: 350, loss is 6.299873027801514 and perplexity is 544.5027690228584
At time: 3.1006228923797607 and batch: 400, loss is 6.156201419830322 and perplexity is 471.63313161416085
At time: 3.450920581817627 and batch: 450, loss is 6.179946517944336 and perplexity is 482.9661256408364
At time: 3.8001537322998047 and batch: 500, loss is 6.126070013046265 and perplexity is 457.6341258683757
At time: 4.149286508560181 and batch: 550, loss is 6.176722688674927 and perplexity is 481.41163236565257
At time: 4.51528263092041 and batch: 600, loss is 5.973853349685669 and perplexity is 393.01718933775754
At time: 4.865407705307007 and batch: 650, loss is 6.173075084686279 and perplexity is 479.6588320793312
At time: 5.214889764785767 and batch: 700, loss is 6.106150674819946 and perplexity is 448.6085471378227
At time: 5.565349102020264 and batch: 750, loss is 6.035760774612426 and perplexity is 418.1167813028532
At time: 5.9153733253479 and batch: 800, loss is 6.006657314300537 and perplexity is 406.1235055891652
At time: 6.266887426376343 and batch: 850, loss is 5.939093723297119 and perplexity is 379.59075934316206
At time: 6.61698842048645 and batch: 900, loss is 5.897540855407715 and perplexity is 364.1408908083862
At time: 6.965007781982422 and batch: 950, loss is 5.915542058944702 and perplexity is 370.75521942804863
At time: 7.315704584121704 and batch: 1000, loss is 5.986386947631836 and perplexity is 397.97410789651326
At time: 7.665465593338013 and batch: 1050, loss is 5.823056612014771 and perplexity is 338.00362220714084
At time: 8.013987302780151 and batch: 1100, loss is 5.927373008728027 and perplexity is 375.1676560009857
At time: 8.363590478897095 and batch: 1150, loss is 5.933362102508545 and perplexity is 377.42131221900365
At time: 8.713404417037964 and batch: 1200, loss is 5.8976842975616455 and perplexity is 364.1931277084952
At time: 9.055830717086792 and batch: 1250, loss is 5.916154384613037 and perplexity is 370.9823118857486
At time: 9.415722846984863 and batch: 1300, loss is 5.971078681945801 and perplexity is 391.9282086996631
At time: 9.76591181755066 and batch: 1350, loss is 5.894356822967529 and perplexity is 362.98329828330895
At time: 10.11590838432312 and batch: 1400, loss is 5.793959178924561 and perplexity is 328.310293816483
At time: 10.467029809951782 and batch: 1450, loss is 5.834142618179321 and perplexity is 341.77157965638617
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.690833980201656 and perplexity of 296.14049299091204
Finished 1 epochs...
Completing Train Step...
At time: 11.714205265045166 and batch: 50, loss is 5.66301495552063 and perplexity is 288.01568933812655
At time: 12.07498574256897 and batch: 100, loss is 5.615780820846558 and perplexity is 274.72780866912274
At time: 12.418098211288452 and batch: 150, loss is 5.525321521759033 and perplexity is 250.96701640679564
At time: 12.761873722076416 and batch: 200, loss is 5.478499441146851 and perplexity is 239.48707316773405
At time: 13.105814456939697 and batch: 250, loss is 5.446231279373169 and perplexity is 231.88261629399125
At time: 13.466182947158813 and batch: 300, loss is 5.497429141998291 and perplexity is 244.0636719822224
At time: 13.810692548751831 and batch: 350, loss is 5.500072994232178 and perplexity is 244.7097940158306
At time: 14.154005289077759 and batch: 400, loss is 5.363621482849121 and perplexity is 213.49672283867628
At time: 14.496744155883789 and batch: 450, loss is 5.401680479049682 and perplexity is 221.7787978502267
At time: 14.840454339981079 and batch: 500, loss is 5.370617733001709 and perplexity is 214.9956365921981
At time: 15.184256553649902 and batch: 550, loss is 5.4239826488494876 and perplexity is 226.7805134998493
At time: 15.528469324111938 and batch: 600, loss is 5.245168857574463 and perplexity is 189.6478359995578
At time: 15.871916055679321 and batch: 650, loss is 5.411693677902222 and perplexity is 224.01066848861575
At time: 16.215298175811768 and batch: 700, loss is 5.395787220001221 and perplexity is 220.47564163322633
At time: 16.559005737304688 and batch: 750, loss is 5.316587743759155 and perplexity is 203.6876603349956
At time: 16.90260410308838 and batch: 800, loss is 5.247015609741211 and perplexity is 189.99839214714083
At time: 17.245659589767456 and batch: 850, loss is 5.1793742179870605 and perplexity is 177.57165506955258
At time: 17.58971667289734 and batch: 900, loss is 5.150957021713257 and perplexity is 172.59658998652003
At time: 17.93406343460083 and batch: 950, loss is 5.174547443389892 and perplexity is 176.71662190190108
At time: 18.277416467666626 and batch: 1000, loss is 5.227864227294922 and perplexity is 186.39428227579145
At time: 18.620471477508545 and batch: 1050, loss is 5.128320121765137 and perplexity is 168.7334282158631
At time: 18.965454578399658 and batch: 1100, loss is 5.220919237136841 and perplexity is 185.10426059890688
At time: 19.30883264541626 and batch: 1150, loss is 5.1837442588806155 and perplexity is 178.3493485021437
At time: 19.65214776992798 and batch: 1200, loss is 5.133452529907227 and perplexity is 169.60166319893742
At time: 19.99943494796753 and batch: 1250, loss is 5.143091430664063 and perplexity is 171.24434088410337
At time: 20.343122005462646 and batch: 1300, loss is 5.222244329452515 and perplexity is 185.34970341350493
At time: 20.688583374023438 and batch: 1350, loss is 5.129107236862183 and perplexity is 168.86629312771737
At time: 21.033329486846924 and batch: 1400, loss is 4.9996102428436275 and perplexity is 148.3553252830212
At time: 21.37750244140625 and batch: 1450, loss is 5.079042377471924 and perplexity is 160.62016876538715
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 5.1649681156517095 and perplexity of 175.03187770547626
Finished 2 epochs...
Completing Train Step...
At time: 22.628737926483154 and batch: 50, loss is 5.171703224182129 and perplexity is 176.21471519625422
At time: 22.973302125930786 and batch: 100, loss is 5.148140144348145 and perplexity is 172.11109067592903
At time: 23.314659595489502 and batch: 150, loss is 5.05953685760498 and perplexity is 157.51754637324763
At time: 23.664582014083862 and batch: 200, loss is 5.081952781677246 and perplexity is 161.08831930321455
At time: 23.998960494995117 and batch: 250, loss is 5.089501161575317 and perplexity is 162.308875951687
At time: 24.355342388153076 and batch: 300, loss is 5.134474229812622 and perplexity is 169.7750337534409
At time: 24.700677156448364 and batch: 350, loss is 5.15635274887085 and perplexity is 173.53039109687765
At time: 25.045382738113403 and batch: 400, loss is 5.02449215888977 and perplexity is 152.0929974200919
At time: 25.388882875442505 and batch: 450, loss is 5.076957807540894 and perplexity is 160.28569353089
At time: 25.73309063911438 and batch: 500, loss is 5.053485260009766 and perplexity is 156.56719204968877
At time: 26.078052759170532 and batch: 550, loss is 5.12469741821289 and perplexity is 168.1232629173962
At time: 26.42293095588684 and batch: 600, loss is 4.967295036315918 and perplexity is 143.63782630629967
At time: 26.767405033111572 and batch: 650, loss is 5.1222075080871585 and perplexity is 167.705171823313
At time: 27.110113620758057 and batch: 700, loss is 5.136804723739624 and perplexity is 170.1711548381666
At time: 27.452695608139038 and batch: 750, loss is 5.059527654647827 and perplexity is 157.51609675268782
At time: 27.79710865020752 and batch: 800, loss is 4.984581747055054 and perplexity is 146.14243773665777
At time: 28.139678478240967 and batch: 850, loss is 4.928710346221924 and perplexity is 138.20116570648685
At time: 28.482789754867554 and batch: 900, loss is 4.904076089859009 and perplexity is 134.83827399070313
At time: 28.82574987411499 and batch: 950, loss is 4.943740701675415 and perplexity is 140.2940674791805
At time: 29.169601678848267 and batch: 1000, loss is 4.990383539199829 and perplexity is 146.99279018271415
At time: 29.512401342391968 and batch: 1050, loss is 4.910221710205078 and perplexity is 135.66949038480257
At time: 29.8555908203125 and batch: 1100, loss is 5.012681188583374 and perplexity is 150.30719831358297
At time: 30.199549913406372 and batch: 1150, loss is 4.968693542480469 and perplexity is 143.83884522218509
At time: 30.542742252349854 and batch: 1200, loss is 4.915781269073486 and perplexity is 136.42585347763207
At time: 30.886062145233154 and batch: 1250, loss is 4.91935700416565 and perplexity is 136.91454939225554
At time: 31.231831312179565 and batch: 1300, loss is 5.0121589946746825 and perplexity is 150.22872929999465
At time: 31.576050519943237 and batch: 1350, loss is 4.9280234050750735 and perplexity is 138.1062622395006
At time: 31.921652793884277 and batch: 1400, loss is 4.795744075775146 and perplexity is 120.99437728223137
At time: 32.26533770561218 and batch: 1450, loss is 4.886966314315796 and perplexity is 132.55084588122892
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.999445988581731 and perplexity of 148.33095928973228
Finished 3 epochs...
Completing Train Step...
At time: 33.52228331565857 and batch: 50, loss is 4.988357429504394 and perplexity is 146.69526817326022
At time: 33.863553285598755 and batch: 100, loss is 4.966040096282959 and perplexity is 143.45768250629578
At time: 34.20692777633667 and batch: 150, loss is 4.865463829040527 and perplexity is 129.7310977095393
At time: 34.551100969314575 and batch: 200, loss is 4.911518659591675 and perplexity is 135.84556099979474
At time: 34.89564824104309 and batch: 250, loss is 4.929039793014526 and perplexity is 138.2467031379313
At time: 35.24051642417908 and batch: 300, loss is 4.970040645599365 and perplexity is 144.03274154905395
At time: 35.58421802520752 and batch: 350, loss is 4.994053077697754 and perplexity is 147.53317676350628
At time: 35.92759943008423 and batch: 400, loss is 4.853561811447143 and perplexity is 128.1961882810128
At time: 36.270222663879395 and batch: 450, loss is 4.914038009643555 and perplexity is 136.1882349975748
At time: 36.613932371139526 and batch: 500, loss is 4.888819408416748 and perplexity is 132.79670279945492
At time: 36.95748686790466 and batch: 550, loss is 4.963520851135254 and perplexity is 143.09673228768457
At time: 37.30138683319092 and batch: 600, loss is 4.819393424987793 and perplexity is 123.88991945419964
At time: 37.64624357223511 and batch: 650, loss is 4.966259098052978 and perplexity is 143.4891034331812
At time: 37.98931956291199 and batch: 700, loss is 4.9902128314971925 and perplexity is 146.96769952284328
At time: 38.333054065704346 and batch: 750, loss is 4.9133638000488284 and perplexity is 136.09644652866072
At time: 38.678868770599365 and batch: 800, loss is 4.837119426727295 and perplexity is 126.10557169477298
At time: 39.02484345436096 and batch: 850, loss is 4.785289154052735 and perplexity is 119.73598022271425
At time: 39.36861038208008 and batch: 900, loss is 4.758014736175537 and perplexity is 116.51438434722982
At time: 39.71020865440369 and batch: 950, loss is 4.8096631813049315 and perplexity is 122.69028617498451
At time: 40.06741166114807 and batch: 1000, loss is 4.8499797916412355 and perplexity is 127.73780844848513
At time: 40.41179704666138 and batch: 1050, loss is 4.7770872402191165 and perplexity is 118.75793244482347
At time: 40.75601840019226 and batch: 1100, loss is 4.886677913665771 and perplexity is 132.51262364303957
At time: 41.098751068115234 and batch: 1150, loss is 4.839161672592163 and perplexity is 126.36337343476961
At time: 41.446346044540405 and batch: 1200, loss is 4.7844029235839844 and perplexity is 119.62991355553339
At time: 41.79035449028015 and batch: 1250, loss is 4.776788511276245 and perplexity is 118.72246131159748
At time: 42.13362240791321 and batch: 1300, loss is 4.8785638332366945 and perplexity is 131.44175598541923
At time: 42.47737407684326 and batch: 1350, loss is 4.801918659210205 and perplexity is 121.74377839885568
At time: 42.82142877578735 and batch: 1400, loss is 4.664631261825561 and perplexity is 106.12644513455785
At time: 43.165714263916016 and batch: 1450, loss is 4.762381496429444 and perplexity is 117.02428723136894
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.891995943509615 and perplexity of 133.21920688036568
Finished 4 epochs...
Completing Train Step...
At time: 44.41539144515991 and batch: 50, loss is 4.8655649757385255 and perplexity is 129.74422024533976
At time: 44.76447153091431 and batch: 100, loss is 4.845341558456421 and perplexity is 127.14670260945785
At time: 45.10704255104065 and batch: 150, loss is 4.736155815124512 and perplexity is 113.99513991082337
At time: 45.45097351074219 and batch: 200, loss is 4.795076789855957 and perplexity is 120.91366636959255
At time: 45.79585075378418 and batch: 250, loss is 4.821921215057373 and perplexity is 124.20348330714839
At time: 46.14055395126343 and batch: 300, loss is 4.859412069320679 and perplexity is 128.9483671156279
At time: 46.48443293571472 and batch: 350, loss is 4.882091369628906 and perplexity is 131.90624032416696
At time: 46.82835078239441 and batch: 400, loss is 4.7326687145233155 and perplexity is 113.59831966806722
At time: 47.172428607940674 and batch: 450, loss is 4.802162256240845 and perplexity is 121.77343843417407
At time: 47.51802682876587 and batch: 500, loss is 4.775496501922607 and perplexity is 118.56916982943433
At time: 47.861138582229614 and batch: 550, loss is 4.850557527542114 and perplexity is 127.81162848851575
At time: 48.205058336257935 and batch: 600, loss is 4.714675922393798 and perplexity is 111.57264711764873
At time: 48.549052238464355 and batch: 650, loss is 4.855959835052491 and perplexity is 128.50397465863148
At time: 48.909265995025635 and batch: 700, loss is 4.885223035812378 and perplexity is 132.31997413633792
At time: 49.25277400016785 and batch: 750, loss is 4.809094839096069 and perplexity is 122.62057591825094
At time: 49.59639048576355 and batch: 800, loss is 4.731889991760254 and perplexity is 113.50989250528703
At time: 49.94212245941162 and batch: 850, loss is 4.682905874252319 and perplexity is 108.083694302425
At time: 50.286685943603516 and batch: 900, loss is 4.652716579437256 and perplexity is 104.86948525640543
At time: 50.629323959350586 and batch: 950, loss is 4.714413728713989 and perplexity is 111.54339730945988
At time: 50.972825050354004 and batch: 1000, loss is 4.750393104553223 and perplexity is 115.62973016757515
At time: 51.315385580062866 and batch: 1050, loss is 4.6804900646209715 and perplexity is 107.82289981449144
At time: 51.65891408920288 and batch: 1100, loss is 4.796148729324341 and perplexity is 121.04334799384915
At time: 52.002429723739624 and batch: 1150, loss is 4.744996614456177 and perplexity is 115.00741613980297
At time: 52.34591627120972 and batch: 1200, loss is 4.689197788238525 and perplexity is 108.76589152282595
At time: 52.68960094451904 and batch: 1250, loss is 4.6697977352142335 and perplexity is 106.67616341884681
At time: 53.034383058547974 and batch: 1300, loss is 4.779384508132934 and perplexity is 119.03106484156595
At time: 53.37724804878235 and batch: 1350, loss is 4.707432851791382 and perplexity is 110.7674381701464
At time: 53.72045159339905 and batch: 1400, loss is 4.566105089187622 and perplexity is 96.16881042900621
At time: 54.06486654281616 and batch: 1450, loss is 4.670463142395019 and perplexity is 106.74717012557069
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.812270987747062 and perplexity of 123.01065624366242
Finished 5 epochs...
Completing Train Step...
At time: 55.3062527179718 and batch: 50, loss is 4.770738534927368 and perplexity is 118.00636160595799
At time: 55.665351152420044 and batch: 100, loss is 4.754593114852906 and perplexity is 116.11639751375746
At time: 56.010480880737305 and batch: 150, loss is 4.639973058700561 and perplexity is 103.54155800158526
At time: 56.354907751083374 and batch: 200, loss is 4.707221651077271 and perplexity is 110.74404647836255
At time: 56.698622941970825 and batch: 250, loss is 4.7416698932647705 and perplexity is 114.6254542240282
At time: 57.04316163063049 and batch: 300, loss is 4.774504747390747 and perplexity is 118.45163660960239
At time: 57.38689684867859 and batch: 350, loss is 4.794981250762939 and perplexity is 120.90211493938946
At time: 57.74505066871643 and batch: 400, loss is 4.639747133255005 and perplexity is 103.51816797126118
At time: 58.08918523788452 and batch: 450, loss is 4.714722213745117 and perplexity is 111.57781208579974
At time: 58.43225169181824 and batch: 500, loss is 4.687923440933227 and perplexity is 108.62737428033843
At time: 58.779661893844604 and batch: 550, loss is 4.7642410850524906 and perplexity is 117.2421067290849
At time: 59.12343430519104 and batch: 600, loss is 4.633561115264893 and perplexity is 102.87977929954879
At time: 59.467121839523315 and batch: 650, loss is 4.77057692527771 and perplexity is 117.98729218014452
At time: 59.810088872909546 and batch: 700, loss is 4.804501543045044 and perplexity is 122.0586348798903
At time: 60.154842376708984 and batch: 750, loss is 4.727689743041992 and perplexity is 113.03412260021302
At time: 60.4987256526947 and batch: 800, loss is 4.650729074478149 and perplexity is 104.66126362370576
At time: 60.84361529350281 and batch: 850, loss is 4.603923730850219 and perplexity is 99.87543213646747
At time: 61.18756031990051 and batch: 900, loss is 4.569505681991577 and perplexity is 96.49639807412427
At time: 61.53227615356445 and batch: 950, loss is 4.63919828414917 and perplexity is 103.46136770614571
At time: 61.8751482963562 and batch: 1000, loss is 4.672626886367798 and perplexity is 106.97839373567581
At time: 62.217557430267334 and batch: 1050, loss is 4.604246253967285 and perplexity is 99.90764946729612
At time: 62.561726093292236 and batch: 1100, loss is 4.72511510848999 and perplexity is 112.74347535837904
At time: 62.90585684776306 and batch: 1150, loss is 4.67134274482727 and perplexity is 106.84110650332569
At time: 63.25081443786621 and batch: 1200, loss is 4.614420499801636 and perplexity is 100.92932301942946
At time: 63.59384632110596 and batch: 1250, loss is 4.585087985992431 and perplexity is 98.01181042914953
At time: 63.9369101524353 and batch: 1300, loss is 4.699779739379883 and perplexity is 109.92295808657256
At time: 64.28134393692017 and batch: 1350, loss is 4.633643522262573 and perplexity is 102.88825766261625
At time: 64.62470722198486 and batch: 1400, loss is 4.489144344329834 and perplexity is 89.04522122383884
At time: 64.9690933227539 and batch: 1450, loss is 4.597659502029419 and perplexity is 99.25174507470665
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.755372658754006 and perplexity of 116.20695063373762
Finished 6 epochs...
Completing Train Step...
At time: 66.21895575523376 and batch: 50, loss is 4.693622121810913 and perplexity is 109.24817421125354
At time: 66.57773280143738 and batch: 100, loss is 4.682386083602905 and perplexity is 108.02752800739455
At time: 66.92220282554626 and batch: 150, loss is 4.563357009887695 and perplexity is 95.90489370989425
At time: 67.26840782165527 and batch: 200, loss is 4.639099674224854 and perplexity is 103.45116589151485
At time: 67.61287307739258 and batch: 250, loss is 4.676838426589966 and perplexity is 107.42988761877284
At time: 67.95722675323486 and batch: 300, loss is 4.705905284881592 and perplexity is 110.59836266686504
At time: 68.3008542060852 and batch: 350, loss is 4.724573078155518 and perplexity is 112.68238153356991
At time: 68.64599943161011 and batch: 400, loss is 4.564219064712525 and perplexity is 95.98760463179416
At time: 68.98996353149414 and batch: 450, loss is 4.644494380950928 and perplexity is 104.01076266505413
At time: 69.33371329307556 and batch: 500, loss is 4.6172842502594 and perplexity is 101.21877367383321
At time: 69.67711400985718 and batch: 550, loss is 4.695248708724976 and perplexity is 109.42602046379248
At time: 70.02129745483398 and batch: 600, loss is 4.568808727264404 and perplexity is 96.42916788425204
At time: 70.36511206626892 and batch: 650, loss is 4.7016785526275635 and perplexity is 110.13187954425533
At time: 70.70830464363098 and batch: 700, loss is 4.739231071472168 and perplexity is 114.34624377893063
At time: 71.05181312561035 and batch: 750, loss is 4.661634826660157 and perplexity is 105.80892008157274
At time: 71.39629697799683 and batch: 800, loss is 4.584509224891662 and perplexity is 97.95510141792502
At time: 71.74015927314758 and batch: 850, loss is 4.539247465133667 and perplexity is 93.62032104803482
At time: 72.08419251441956 and batch: 900, loss is 4.500966739654541 and perplexity is 90.10419650885196
At time: 72.4286196231842 and batch: 950, loss is 4.5776494693756105 and perplexity is 97.28545280944299
At time: 72.7733371257782 and batch: 1000, loss is 4.608723564147949 and perplexity is 100.3559698892465
At time: 73.11755132675171 and batch: 1050, loss is 4.542133026123047 and perplexity is 93.8908583324631
At time: 73.46176290512085 and batch: 1100, loss is 4.666749429702759 and perplexity is 106.35147700506647
At time: 73.80539441108704 and batch: 1150, loss is 4.6108887577056885 and perplexity is 100.57349539616338
At time: 74.14804124832153 and batch: 1200, loss is 4.552989721298218 and perplexity is 94.91575619610528
At time: 74.49336624145508 and batch: 1250, loss is 4.515497331619263 and perplexity is 91.42302227774206
At time: 74.8363196849823 and batch: 1300, loss is 4.6339040374755855 and perplexity is 102.91506511070014
At time: 75.18027830123901 and batch: 1350, loss is 4.572924423217773 and perplexity is 96.82685884646973
At time: 75.52591323852539 and batch: 1400, loss is 4.426059093475342 and perplexity is 83.60130194509755
At time: 75.87180352210999 and batch: 1450, loss is 4.537540187835694 and perplexity is 93.46062156372349
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.709363105969551 and perplexity of 110.98145396647215
Finished 7 epochs...
Completing Train Step...
At time: 77.12272930145264 and batch: 50, loss is 4.629060764312744 and perplexity is 102.41782444597386
At time: 77.46497011184692 and batch: 100, loss is 4.622407360076904 and perplexity is 101.7386591450515
At time: 77.80758738517761 and batch: 150, loss is 4.500059413909912 and perplexity is 90.02247972913538
At time: 78.15009379386902 and batch: 200, loss is 4.5823006916046145 and perplexity is 97.73900303388174
At time: 78.49362802505493 and batch: 250, loss is 4.622490034103394 and perplexity is 101.74707063735386
At time: 78.83534359931946 and batch: 300, loss is 4.647995281219482 and perplexity is 104.37553211016466
At time: 79.17827415466309 and batch: 350, loss is 4.6661274623870845 and perplexity is 106.28535042881191
At time: 79.52087759971619 and batch: 400, loss is 4.5017408275604245 and perplexity is 90.17397208036762
At time: 79.86474967002869 and batch: 450, loss is 4.5853096389770505 and perplexity is 98.03353744729932
At time: 80.20797991752625 and batch: 500, loss is 4.5581754875183105 and perplexity is 95.4092455726949
At time: 80.55133366584778 and batch: 550, loss is 4.637017374038696 and perplexity is 103.23597363471461
At time: 80.89431643486023 and batch: 600, loss is 4.514312057495117 and perplexity is 91.31472512866803
At time: 81.23744630813599 and batch: 650, loss is 4.642778730392456 and perplexity is 103.83246953009221
At time: 81.58133816719055 and batch: 700, loss is 4.6838766288757325 and perplexity is 108.18866799198828
At time: 81.92596316337585 and batch: 750, loss is 4.606212453842163 and perplexity is 100.10428112039672
At time: 82.2689700126648 and batch: 800, loss is 4.528846507072449 and perplexity is 92.65162642397641
At time: 82.6139407157898 and batch: 850, loss is 4.484237909317017 and perplexity is 88.60939667940808
At time: 82.96079802513123 and batch: 900, loss is 4.442828164100647 and perplexity is 85.01503847704942
At time: 83.30448126792908 and batch: 950, loss is 4.525742979049682 and perplexity is 92.36452524872988
At time: 83.64782214164734 and batch: 1000, loss is 4.554573621749878 and perplexity is 95.06621242760582
At time: 83.99072289466858 and batch: 1050, loss is 4.489401578903198 and perplexity is 89.06812967962762
At time: 84.34930086135864 and batch: 1100, loss is 4.6175242614746095 and perplexity is 101.2430702303111
At time: 84.69276428222656 and batch: 1150, loss is 4.559711685180664 and perplexity is 95.555925668675
At time: 85.03573393821716 and batch: 1200, loss is 4.5009188556671145 and perplexity is 90.09988206393648
At time: 85.3779969215393 and batch: 1250, loss is 4.4564369106292725 and perplexity is 86.17989472615972
At time: 85.72113537788391 and batch: 1300, loss is 4.577350635528564 and perplexity is 97.25638496676223
At time: 86.06374049186707 and batch: 1350, loss is 4.52142105102539 and perplexity is 91.96619381853046
At time: 86.40824246406555 and batch: 1400, loss is 4.372204427719116 and perplexity is 79.21806986983127
At time: 86.7527003288269 and batch: 1450, loss is 4.486422300338745 and perplexity is 88.80316580667782
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.671902648404113 and perplexity of 106.90094397105362
Finished 8 epochs...
Completing Train Step...
At time: 88.00540208816528 and batch: 50, loss is 4.574087743759155 and perplexity is 96.93956506434193
At time: 88.35032296180725 and batch: 100, loss is 4.571525459289551 and perplexity is 96.6914962694182
At time: 88.69444489479065 and batch: 150, loss is 4.445863924026489 and perplexity is 85.27351586308997
At time: 89.03632426261902 and batch: 200, loss is 4.533518543243408 and perplexity is 93.08551094678694
At time: 89.37924218177795 and batch: 250, loss is 4.575852689743042 and perplexity is 97.11080923428433
At time: 89.72202229499817 and batch: 300, loss is 4.598068952560425 and perplexity is 99.29239207533085
At time: 90.06605887413025 and batch: 350, loss is 4.615744152069092 and perplexity is 101.06300680259986
At time: 90.41048192977905 and batch: 400, loss is 4.448297681808472 and perplexity is 85.4813036959828
At time: 90.75306749343872 and batch: 450, loss is 4.533630161285401 and perplexity is 93.09590154913522
At time: 91.09753131866455 and batch: 500, loss is 4.507571611404419 and perplexity is 90.70129287271233
At time: 91.44171857833862 and batch: 550, loss is 4.586559448242188 and perplexity is 98.15613726793235
At time: 91.78485655784607 and batch: 600, loss is 4.466768655776978 and perplexity is 87.07489895169041
At time: 92.12697458267212 and batch: 650, loss is 4.591338129043579 and perplexity is 98.62631664046091
At time: 92.47230124473572 and batch: 700, loss is 4.635336179733276 and perplexity is 103.06255971581685
At time: 92.81678462028503 and batch: 750, loss is 4.55825252532959 and perplexity is 95.41659597527548
At time: 93.17408776283264 and batch: 800, loss is 4.4805135869979855 and perplexity is 88.28000049520223
At time: 93.51686358451843 and batch: 850, loss is 4.436569876670838 and perplexity is 84.48465131914664
At time: 93.86077785491943 and batch: 900, loss is 4.392207336425781 and perplexity is 80.81861611284052
At time: 94.20361638069153 and batch: 950, loss is 4.480807228088379 and perplexity is 88.30592693715562
At time: 94.54734992980957 and batch: 1000, loss is 4.5074773693084715 and perplexity is 90.69274539553926
At time: 94.88912725448608 and batch: 1050, loss is 4.443376903533935 and perplexity is 85.06170238307602
At time: 95.23326182365417 and batch: 1100, loss is 4.5745056533813475 and perplexity is 96.98008550770533
At time: 95.57699966430664 and batch: 1150, loss is 4.515475225448609 and perplexity is 91.42100128714814
At time: 95.91937565803528 and batch: 1200, loss is 4.455383319854736 and perplexity is 86.08914419947936
At time: 96.26218342781067 and batch: 1250, loss is 4.4048007345199585 and perplexity is 81.84283276684474
At time: 96.60552191734314 and batch: 1300, loss is 4.527768516540528 and perplexity is 92.55180266212615
At time: 96.94937992095947 and batch: 1350, loss is 4.476619443893433 and perplexity is 87.93689402643078
At time: 97.29354405403137 and batch: 1400, loss is 4.325163378715515 and perplexity is 75.57785966472996
At time: 97.63717722892761 and batch: 1450, loss is 4.441654357910156 and perplexity is 84.91530584344274
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.640811757144765 and perplexity of 103.6284345717212
Finished 9 epochs...
Completing Train Step...
At time: 98.8738968372345 and batch: 50, loss is 4.525920839309692 and perplexity is 92.38095468823518
At time: 99.23124480247498 and batch: 100, loss is 4.5268743705749515 and perplexity is 92.46908482758907
At time: 99.57532978057861 and batch: 150, loss is 4.3983686161041256 and perplexity is 81.31809935782404
At time: 99.91845369338989 and batch: 200, loss is 4.490712308883667 and perplexity is 89.18495049104799
At time: 100.26173162460327 and batch: 250, loss is 4.5347780418395995 and perplexity is 93.20282588063898
At time: 100.60556054115295 and batch: 300, loss is 4.554203987121582 and perplexity is 95.03107915714837
At time: 100.94877815246582 and batch: 350, loss is 4.5712623786926265 and perplexity is 96.66606195864567
At time: 101.29197859764099 and batch: 400, loss is 4.40142439365387 and perplexity is 81.56696943236513
At time: 101.63612580299377 and batch: 450, loss is 4.487611923217774 and perplexity is 88.90887094661188
At time: 101.99473834037781 and batch: 500, loss is 4.463151998519898 and perplexity is 86.76054767954044
At time: 102.33927321434021 and batch: 550, loss is 4.542309627532959 and perplexity is 93.90744105464547
At time: 102.68355774879456 and batch: 600, loss is 4.424631280899048 and perplexity is 83.48202013108735
At time: 103.02644920349121 and batch: 650, loss is 4.545561456680298 and perplexity is 94.21330905432663
At time: 103.37012076377869 and batch: 700, loss is 4.591787786483764 and perplexity is 98.67067466974794
At time: 103.71265077590942 and batch: 750, loss is 4.515550394058227 and perplexity is 91.42787353499025
At time: 104.05612277984619 and batch: 800, loss is 4.437687931060791 and perplexity is 84.57916257895684
At time: 104.3995509147644 and batch: 850, loss is 4.394368019104004 and perplexity is 80.99342828556027
At time: 104.74333071708679 and batch: 900, loss is 4.347011737823486 and perplexity is 77.24728255082245
At time: 105.08913683891296 and batch: 950, loss is 4.440713119506836 and perplexity is 84.83541789925165
At time: 105.43324732780457 and batch: 1000, loss is 4.4659531211853025 and perplexity is 87.00391530827126
At time: 105.77725267410278 and batch: 1050, loss is 4.402489681243896 and perplexity is 81.65390801173055
At time: 106.12241792678833 and batch: 1100, loss is 4.536060905456543 and perplexity is 93.32246912152945
At time: 106.46588563919067 and batch: 1150, loss is 4.476282606124878 and perplexity is 87.90727854735923
At time: 106.80962252616882 and batch: 1200, loss is 4.414682154655456 and perplexity is 82.65556504394937
At time: 107.15410947799683 and batch: 1250, loss is 4.35908417224884 and perplexity is 78.18549717634973
At time: 107.49709248542786 and batch: 1300, loss is 4.483797464370728 and perplexity is 88.57037771193122
At time: 107.84186601638794 and batch: 1350, loss is 4.4367879867553714 and perplexity is 84.50308028328607
At time: 108.18625950813293 and batch: 1400, loss is 4.283451180458069 and perplexity is 72.49018551267893
At time: 108.52972292900085 and batch: 1450, loss is 4.402050733566284 and perplexity is 81.61807408362598
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.613726232805822 and perplexity of 100.8592754402221
Finished 10 epochs...
Completing Train Step...
At time: 109.76965975761414 and batch: 50, loss is 4.482836508750916 and perplexity is 88.48530639114847
At time: 110.12883496284485 and batch: 100, loss is 4.486931147575379 and perplexity is 88.84836455085566
At time: 110.47180390357971 and batch: 150, loss is 4.355924854278564 and perplexity is 77.93887411557408
At time: 110.8310296535492 and batch: 200, loss is 4.452685241699219 and perplexity is 85.8571820268395
At time: 111.17472672462463 and batch: 250, loss is 4.497971706390381 and perplexity is 89.83473516733547
At time: 111.51753044128418 and batch: 300, loss is 4.5150955867767335 and perplexity is 91.38630092685412
At time: 111.86162948608398 and batch: 350, loss is 4.531299896240235 and perplexity is 92.87921598935257
At time: 112.20560121536255 and batch: 400, loss is 4.35928183555603 and perplexity is 78.20095310778082
At time: 112.55234932899475 and batch: 450, loss is 4.446232213973999 and perplexity is 85.3049270256238
At time: 112.89540553092957 and batch: 500, loss is 4.423190603256225 and perplexity is 83.36183604515702
At time: 113.2393581867218 and batch: 550, loss is 4.502482147216797 and perplexity is 90.2408446022589
At time: 113.5849335193634 and batch: 600, loss is 4.3870237350463865 and perplexity is 80.40076853613502
At time: 113.92854166030884 and batch: 650, loss is 4.504337215423584 and perplexity is 90.40840289201105
At time: 114.2723741531372 and batch: 700, loss is 4.551587133407593 and perplexity is 94.78272182384427
At time: 114.61618566513062 and batch: 750, loss is 4.477136197090149 and perplexity is 87.98234744061536
At time: 114.9592833518982 and batch: 800, loss is 4.399394426345825 and perplexity is 81.40155909658962
At time: 115.30401921272278 and batch: 850, loss is 4.356440410614014 and perplexity is 77.97906635569394
At time: 115.6467216014862 and batch: 900, loss is 4.306289491653442 and perplexity is 74.16478869515797
At time: 115.9907009601593 and batch: 950, loss is 4.40450834274292 and perplexity is 81.8189060936859
At time: 116.33326935768127 and batch: 1000, loss is 4.428936166763306 and perplexity is 83.84217535683868
At time: 116.67846965789795 and batch: 1050, loss is 4.365605144500733 and perplexity is 78.69700859724277
At time: 117.0215470790863 and batch: 1100, loss is 4.501209049224854 and perplexity is 90.12603226339068
At time: 117.36597323417664 and batch: 1150, loss is 4.440987377166748 and perplexity is 84.85868785327808
At time: 117.71198534965515 and batch: 1200, loss is 4.37793384552002 and perplexity is 79.6732459914413
At time: 118.05583691596985 and batch: 1250, loss is 4.317612624168396 and perplexity is 75.00933887878918
At time: 118.4005880355835 and batch: 1300, loss is 4.444228076934815 and perplexity is 85.1341354637607
At time: 118.74376606941223 and batch: 1350, loss is 4.4006295585632325 and perplexity is 81.50216290148761
At time: 119.08774137496948 and batch: 1400, loss is 4.246117129325866 and perplexity is 69.83372989224551
At time: 119.43285298347473 and batch: 1450, loss is 4.366362152099609 and perplexity is 78.75660538552447
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.588711730435363 and perplexity of 98.36762448276859
Finished 11 epochs...
Completing Train Step...
At time: 120.68028521537781 and batch: 50, loss is 4.443562679290771 and perplexity is 85.07750625315649
At time: 121.02336430549622 and batch: 100, loss is 4.450890951156616 and perplexity is 85.70326742216771
At time: 121.36732721328735 and batch: 150, loss is 4.317539300918579 and perplexity is 75.00383915192737
At time: 121.70945048332214 and batch: 200, loss is 4.418433923721313 and perplexity is 82.96625208458637
At time: 122.0535135269165 and batch: 250, loss is 4.464710760116577 and perplexity is 86.89589214684484
At time: 122.39691662788391 and batch: 300, loss is 4.479776086807251 and perplexity is 88.21491798013255
At time: 122.74065589904785 and batch: 350, loss is 4.495113925933838 and perplexity is 89.57837370371921
At time: 123.08355283737183 and batch: 400, loss is 4.321148934364319 and perplexity is 75.275064736266
At time: 123.42775225639343 and batch: 450, loss is 4.408840894699097 and perplexity is 82.17415977714934
At time: 123.77492141723633 and batch: 500, loss is 4.386464967727661 and perplexity is 80.35585576333996
At time: 124.1186044216156 and batch: 550, loss is 4.466056461334229 and perplexity is 87.0129067704179
At time: 124.46200394630432 and batch: 600, loss is 4.353067770004272 and perplexity is 77.71651398605624
At time: 124.8062002658844 and batch: 650, loss is 4.466835670471191 and perplexity is 87.08073444494704
At time: 125.14975571632385 and batch: 700, loss is 4.515410165786744 and perplexity is 91.41505366119442
At time: 125.49338889122009 and batch: 750, loss is 4.442592430114746 and perplexity is 84.99499990514667
At time: 125.83678841590881 and batch: 800, loss is 4.364739980697632 and perplexity is 78.62895223818639
At time: 126.17956233024597 and batch: 850, loss is 4.322054491043091 and perplexity is 75.34326144721616
At time: 126.52230501174927 and batch: 900, loss is 4.269244499206543 and perplexity is 71.46762137323162
At time: 126.86720156669617 and batch: 950, loss is 4.371699891090393 and perplexity is 79.17811153299512
At time: 127.2123064994812 and batch: 1000, loss is 4.395541439056396 and perplexity is 81.08852337264801
At time: 127.55571103096008 and batch: 1050, loss is 4.331904125213623 and perplexity is 76.08903176282726
At time: 127.8990695476532 and batch: 1100, loss is 4.469437942504883 and perplexity is 87.30763730830891
At time: 128.24379920959473 and batch: 1150, loss is 4.409022569656372 and perplexity is 82.18909012030966
At time: 128.60190963745117 and batch: 1200, loss is 4.344292731285095 and perplexity is 77.03753197031749
At time: 128.94851160049438 and batch: 1250, loss is 4.280203199386596 and perplexity is 72.25512071192688
At time: 129.29272770881653 and batch: 1300, loss is 4.408314599990844 and perplexity is 82.13092333025814
At time: 129.6660475730896 and batch: 1350, loss is 4.367663555145263 and perplexity is 78.85916619363744
At time: 130.0094244480133 and batch: 1400, loss is 4.212321815490722 and perplexity is 67.51311096197473
At time: 130.35351943969727 and batch: 1450, loss is 4.333699631690979 and perplexity is 76.22577283521774
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.568347376635951 and perplexity of 96.38469048767377
Finished 12 epochs...
Completing Train Step...
At time: 131.60821294784546 and batch: 50, loss is 4.407711186408997 and perplexity is 82.08137936488505
At time: 131.95263266563416 and batch: 100, loss is 4.418213658332824 and perplexity is 82.947979503322
At time: 132.29774594306946 and batch: 150, loss is 4.282518329620362 and perplexity is 72.42259451345952
At time: 132.64273405075073 and batch: 200, loss is 4.3870688247680665 and perplexity is 80.40439386614311
At time: 132.985942363739 and batch: 250, loss is 4.4344054698944095 and perplexity is 84.30198991542613
At time: 133.32798147201538 and batch: 300, loss is 4.447506427764893 and perplexity is 85.4136930209204
At time: 133.671701669693 and batch: 350, loss is 4.462076778411865 and perplexity is 86.66731112798156
At time: 134.01314878463745 and batch: 400, loss is 4.2865871238708495 and perplexity is 72.71786744466806
At time: 134.3549346923828 and batch: 450, loss is 4.374617929458618 and perplexity is 79.40949372724837
At time: 134.69766807556152 and batch: 500, loss is 4.352954273223877 and perplexity is 77.70769391246974
At time: 135.04177403450012 and batch: 550, loss is 4.432667531967163 and perplexity is 84.15560553014264
At time: 135.3856360912323 and batch: 600, loss is 4.322262101173401 and perplexity is 75.35890509537688
At time: 135.7289593219757 and batch: 650, loss is 4.432606410980225 and perplexity is 84.15046201366624
At time: 136.07320618629456 and batch: 700, loss is 4.481858396530152 and perplexity is 88.39880014491428
At time: 136.4165916442871 and batch: 750, loss is 4.411011319160462 and perplexity is 82.35270627437379
At time: 136.7613170146942 and batch: 800, loss is 4.333023343086243 and perplexity is 76.17423964128213
At time: 137.1035714149475 and batch: 850, loss is 4.29059329032898 and perplexity is 73.00977164413166
At time: 137.46284770965576 and batch: 900, loss is 4.235566558837891 and perplexity is 69.10081732407451
At time: 137.80773067474365 and batch: 950, loss is 4.341584792137146 and perplexity is 76.82920122243397
At time: 138.15013980865479 and batch: 1000, loss is 4.365030093193054 and perplexity is 78.65176678896577
At time: 138.49205780029297 and batch: 1050, loss is 4.3011743927001955 and perplexity is 73.7863970425358
At time: 138.83537411689758 and batch: 1100, loss is 4.440457763671875 and perplexity is 84.81375744595901
At time: 139.17892408370972 and batch: 1150, loss is 4.379819946289063 and perplexity is 79.82365956496645
At time: 139.522775888443 and batch: 1200, loss is 4.313479080200195 and perplexity is 74.69992440822658
At time: 139.8661196231842 and batch: 1250, loss is 4.246026287078857 and perplexity is 69.82738632744127
At time: 140.20939230918884 and batch: 1300, loss is 4.37516077041626 and perplexity is 79.45261215503459
At time: 140.55276894569397 and batch: 1350, loss is 4.3374042987823485 and perplexity is 76.50868767643219
At time: 140.8962459564209 and batch: 1400, loss is 4.181322197914124 and perplexity is 65.45233697050634
At time: 141.23837876319885 and batch: 1450, loss is 4.303692135810852 and perplexity is 73.97240629885178
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.550965398804754 and perplexity of 94.72381044145531
Finished 13 epochs...
Completing Train Step...
At time: 142.52818751335144 and batch: 50, loss is 4.374915189743042 and perplexity is 79.43310252474478
At time: 142.88784861564636 and batch: 100, loss is 4.388143925666809 and perplexity is 80.49088318629371
At time: 143.2312240600586 and batch: 150, loss is 4.250147438049316 and perplexity is 70.11574931394317
At time: 143.57515907287598 and batch: 200, loss is 4.358028573989868 and perplexity is 78.10300824689836
At time: 143.92009472846985 and batch: 250, loss is 4.406624283790588 and perplexity is 81.99221336488829
At time: 144.26661014556885 and batch: 300, loss is 4.417804956436157 and perplexity is 82.91408543353138
At time: 144.60921716690063 and batch: 350, loss is 4.431779441833496 and perplexity is 84.0809009442913
At time: 144.95289731025696 and batch: 400, loss is 4.255215849876404 and perplexity is 70.47202692516531
At time: 145.29626750946045 and batch: 450, loss is 4.34325343132019 and perplexity is 76.9575084574645
At time: 145.64028763771057 and batch: 500, loss is 4.321844863891601 and perplexity is 75.32746910924428
At time: 145.98303294181824 and batch: 550, loss is 4.401972336769104 and perplexity is 81.61167573883395
At time: 146.35389614105225 and batch: 600, loss is 4.294068922996521 and perplexity is 73.2639682826865
At time: 146.7002580165863 and batch: 650, loss is 4.401251664161682 and perplexity is 81.55288162788048
At time: 147.04483652114868 and batch: 700, loss is 4.450948276519775 and perplexity is 85.70818053391825
At time: 147.3902895450592 and batch: 750, loss is 4.381832132339477 and perplexity is 79.98444132639588
At time: 147.7366178035736 and batch: 800, loss is 4.3037285900115965 and perplexity is 73.97510295295241
At time: 148.08305764198303 and batch: 850, loss is 4.261635966300965 and perplexity is 70.92592101008898
At time: 148.42733764648438 and batch: 900, loss is 4.204987378120422 and perplexity is 67.01975174573029
At time: 148.7714593410492 and batch: 950, loss is 4.313901557922363 and perplexity is 74.7314901295742
At time: 149.11580848693848 and batch: 1000, loss is 4.3371006107330325 and perplexity is 76.4854564300205
At time: 149.46886253356934 and batch: 1050, loss is 4.272437162399292 and perplexity is 71.69615804364648
At time: 149.8138027191162 and batch: 1100, loss is 4.413707323074341 and perplexity is 82.57502904968266
At time: 150.15822768211365 and batch: 1150, loss is 4.353110160827637 and perplexity is 77.7198085229017
At time: 150.50163078308105 and batch: 1200, loss is 4.285117082595825 and perplexity is 72.61104771203725
At time: 150.84654259681702 and batch: 1250, loss is 4.214530100822449 and perplexity is 67.66236391050681
At time: 151.1895890235901 and batch: 1300, loss is 4.344357738494873 and perplexity is 77.04254012810047
At time: 151.53409242630005 and batch: 1350, loss is 4.309402680397033 and perplexity is 74.39603745424063
At time: 151.8772566318512 and batch: 1400, loss is 4.152603712081909 and perplexity is 63.599379377427056
At time: 152.2222557067871 and batch: 1450, loss is 4.275951542854309 and perplexity is 71.94856889426381
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.535364917200854 and perplexity of 93.257540376472
Finished 14 epochs...
Completing Train Step...
At time: 153.46125650405884 and batch: 50, loss is 4.344498991966248 and perplexity is 77.05342342297058
At time: 153.81983494758606 and batch: 100, loss is 4.360349225997925 and perplexity is 78.28446862157645
At time: 154.1620397567749 and batch: 150, loss is 4.220271391868591 and perplexity is 68.05195052952811
At time: 154.50636219978333 and batch: 200, loss is 4.3311874961853025 and perplexity is 76.03452368729656
At time: 154.84999465942383 and batch: 250, loss is 4.380930471420288 and perplexity is 79.91235498511084
At time: 155.2082622051239 and batch: 300, loss is 4.39023271560669 and perplexity is 80.65918744827674
At time: 155.55193710327148 and batch: 350, loss is 4.403804922103882 and perplexity is 81.76137322375243
At time: 155.89506793022156 and batch: 400, loss is 4.2256055927276615 and perplexity is 68.41592319111588
At time: 156.24133825302124 and batch: 450, loss is 4.314119744300842 and perplexity is 74.74779730170064
At time: 156.586594581604 and batch: 500, loss is 4.293603878021241 and perplexity is 73.22990516342266
At time: 156.9309754371643 and batch: 550, loss is 4.373171143531799 and perplexity is 79.29468825876181
At time: 157.27637434005737 and batch: 600, loss is 4.267772951126099 and perplexity is 71.36253067415824
At time: 157.62304949760437 and batch: 650, loss is 4.372207813262939 and perplexity is 79.2183380665324
At time: 157.96601176261902 and batch: 700, loss is 4.422218389511109 and perplexity is 83.28082990635713
At time: 158.30921816825867 and batch: 750, loss is 4.354730267524719 and perplexity is 77.84582495765713
At time: 158.65239214897156 and batch: 800, loss is 4.276497259140014 and perplexity is 71.98784311535896
At time: 158.995751619339 and batch: 850, loss is 4.2347805166244505 and perplexity is 69.0465225064794
At time: 159.33888006210327 and batch: 900, loss is 4.1763275480270385 and perplexity is 65.12624050978673
At time: 159.6820194721222 and batch: 950, loss is 4.288385286331176 and perplexity is 72.84874361714779
At time: 160.02423214912415 and batch: 1000, loss is 4.311199069023132 and perplexity is 74.52980176011751
At time: 160.3677442073822 and batch: 1050, loss is 4.2457215785980225 and perplexity is 69.80611257194424
At time: 160.71177053451538 and batch: 1100, loss is 4.388799729347229 and perplexity is 80.5436867162097
At time: 161.05499267578125 and batch: 1150, loss is 4.328283338546753 and perplexity is 75.81402777695205
At time: 161.3985505104065 and batch: 1200, loss is 4.25895092010498 and perplexity is 70.73573707626866
At time: 161.74176597595215 and batch: 1250, loss is 4.185184841156006 and perplexity is 65.70564490170874
At time: 162.1018214225769 and batch: 1300, loss is 4.315623264312745 and perplexity is 74.86026663955238
At time: 162.44703269004822 and batch: 1350, loss is 4.283392963409423 and perplexity is 72.48596547086298
At time: 162.79282021522522 and batch: 1400, loss is 4.125891218185425 and perplexity is 61.92297154423277
At time: 163.13809418678284 and batch: 1450, loss is 4.250158629417419 and perplexity is 70.11653400949449
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.521500546708066 and perplexity of 91.97350502449196
Finished 15 epochs...
Completing Train Step...
At time: 164.39988732337952 and batch: 50, loss is 4.315947270393371 and perplexity is 74.88452575097851
At time: 164.79563784599304 and batch: 100, loss is 4.334396290779114 and perplexity is 76.27889471438496
At time: 165.14175128936768 and batch: 150, loss is 4.192470121383667 and perplexity is 66.18607685313417
At time: 165.48618817329407 and batch: 200, loss is 4.306338820457459 and perplexity is 74.16844724571968
At time: 165.84205150604248 and batch: 250, loss is 4.3569814348220826 and perplexity is 78.02126633289024
At time: 166.1880190372467 and batch: 300, loss is 4.364458055496216 and perplexity is 78.60678787948196
At time: 166.53331780433655 and batch: 350, loss is 4.377841100692749 and perplexity is 79.66585705265197
At time: 166.88885855674744 and batch: 400, loss is 4.19777590751648 and perplexity is 66.53817928597624
At time: 167.23692774772644 and batch: 450, loss is 4.287088112831116 and perplexity is 72.75430742072263
At time: 167.59160375595093 and batch: 500, loss is 4.266789469718933 and perplexity is 71.29238145295356
At time: 167.9359655380249 and batch: 550, loss is 4.34614294052124 and perplexity is 77.18019946515794
At time: 168.27751421928406 and batch: 600, loss is 4.243359293937683 and perplexity is 69.64140528236364
At time: 168.63123750686646 and batch: 650, loss is 4.345254163742066 and perplexity is 77.1116339702846
At time: 168.99574542045593 and batch: 700, loss is 4.3955189037323 and perplexity is 81.08669603708317
At time: 169.3511414527893 and batch: 750, loss is 4.329420981407165 and perplexity is 75.90032614342431
At time: 169.70214128494263 and batch: 800, loss is 4.251048884391785 and perplexity is 70.17898339649585
At time: 170.0513665676117 and batch: 850, loss is 4.209746904373169 and perplexity is 67.33949432161248
At time: 170.4093039035797 and batch: 900, loss is 4.149679532051087 and perplexity is 63.41367499113508
At time: 170.7563099861145 and batch: 950, loss is 4.264531502723694 and perplexity is 71.13158721098276
At time: 171.1157968044281 and batch: 1000, loss is 4.28700382232666 and perplexity is 72.74817518189722
At time: 171.46279072761536 and batch: 1050, loss is 4.220747585296631 and perplexity is 68.08436413809673
At time: 171.81338906288147 and batch: 1100, loss is 4.365581045150757 and perplexity is 78.69511207334311
At time: 172.1586835384369 and batch: 1150, loss is 4.30501492023468 and perplexity is 74.07032059117016
At time: 172.49995040893555 and batch: 1200, loss is 4.234569010734558 and perplexity is 69.03192030457296
At time: 172.8477156162262 and batch: 1250, loss is 4.157655801773071 and perplexity is 63.92150215778864
At time: 173.20161247253418 and batch: 1300, loss is 4.288612132072449 and perplexity is 72.86527091889751
At time: 173.54925084114075 and batch: 1350, loss is 4.259109859466553 and perplexity is 70.74698066266048
At time: 173.90519213676453 and batch: 1400, loss is 4.100916266441345 and perplexity is 60.3956007148554
At time: 174.2546112537384 and batch: 1450, loss is 4.225927505493164 and perplexity is 68.43795069543195
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.509500095986913 and perplexity of 90.87637768755015
Finished 16 epochs...
Completing Train Step...
At time: 175.5674033164978 and batch: 50, loss is 4.289307837486267 and perplexity is 72.9159813200601
At time: 175.91573858261108 and batch: 100, loss is 4.309963474273681 and perplexity is 74.43776999707539
At time: 176.26175045967102 and batch: 150, loss is 4.166471467018128 and perplexity is 64.4875038980992
At time: 176.61973524093628 and batch: 200, loss is 4.283150897026062 and perplexity is 72.46842117888433
At time: 176.97696661949158 and batch: 250, loss is 4.334492197036743 and perplexity is 76.2862106885314
At time: 177.32196378707886 and batch: 300, loss is 4.340251941680908 and perplexity is 76.72686759938985
At time: 177.6707170009613 and batch: 350, loss is 4.353515138626099 and perplexity is 77.75128969401165
At time: 178.0308268070221 and batch: 400, loss is 4.171703686714173 and perplexity is 64.82580093658613
At time: 178.37573051452637 and batch: 450, loss is 4.261811785697937 and perplexity is 70.93839225906228
At time: 178.7213044166565 and batch: 500, loss is 4.241611533164978 and perplexity is 69.51979506979116
At time: 179.06839156150818 and batch: 550, loss is 4.320810656547547 and perplexity is 75.24960515815765
At time: 179.42159414291382 and batch: 600, loss is 4.220412278175354 and perplexity is 68.06153879291789
At time: 179.7758605480194 and batch: 650, loss is 4.320037932395935 and perplexity is 75.19148043093514
At time: 180.1234791278839 and batch: 700, loss is 4.370561418533325 and perplexity is 79.08802071858494
At time: 180.50645518302917 and batch: 750, loss is 4.305702300071716 and perplexity is 74.12125253885885
At time: 180.87045288085938 and batch: 800, loss is 4.227207975387573 and perplexity is 68.52563956042712
At time: 181.2197675704956 and batch: 850, loss is 4.186418194770813 and perplexity is 65.78673319135002
At time: 181.59076142311096 and batch: 900, loss is 4.12469322681427 and perplexity is 61.84883277631555
At time: 181.94768977165222 and batch: 950, loss is 4.24217866897583 and perplexity is 69.55923341753095
At time: 182.3227481842041 and batch: 1000, loss is 4.2642723751068115 and perplexity is 71.11315744023814
At time: 182.66538524627686 and batch: 1050, loss is 4.1972608423233035 and perplexity is 66.50391661032201
At time: 183.0245382785797 and batch: 1100, loss is 4.343877973556519 and perplexity is 77.00558668377757
At time: 183.37010526657104 and batch: 1150, loss is 4.283131942749024 and perplexity is 72.46704760537034
At time: 183.7188708782196 and batch: 1200, loss is 4.211686925888062 and perplexity is 67.47026119365722
At time: 184.0672345161438 and batch: 1250, loss is 4.131877684593201 and perplexity is 62.294783141663174
At time: 184.40443325042725 and batch: 1300, loss is 4.263215079307556 and perplexity is 71.03800953138945
At time: 184.7633557319641 and batch: 1350, loss is 4.236278948783874 and perplexity is 69.15006159007277
At time: 185.1106469631195 and batch: 1400, loss is 4.077602534294129 and perplexity is 59.00384045790324
At time: 185.45547366142273 and batch: 1450, loss is 4.203138861656189 and perplexity is 66.89597906436356
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.498974922375801 and perplexity of 89.92490403156187
Finished 17 epochs...
Completing Train Step...
At time: 186.72982478141785 and batch: 50, loss is 4.264364466667176 and perplexity is 71.1197066634287
At time: 187.09536981582642 and batch: 100, loss is 4.286925206184387 and perplexity is 72.74245622581107
At time: 187.4418625831604 and batch: 150, loss is 4.141934590339661 and perplexity is 62.92443678087344
At time: 187.8059856891632 and batch: 200, loss is 4.261419658660889 and perplexity is 70.91058085065173
At time: 188.1475715637207 and batch: 250, loss is 4.313350319862366 and perplexity is 74.69030663993078
At time: 188.49226570129395 and batch: 300, loss is 4.317466058731079 and perplexity is 74.99834590784806
At time: 188.84559059143066 and batch: 350, loss is 4.330658283233642 and perplexity is 75.99429587806563
At time: 189.1931495666504 and batch: 400, loss is 4.147154045104981 and perplexity is 63.25372664148857
At time: 189.53773140907288 and batch: 450, loss is 4.238013768196106 and perplexity is 69.27012857643285
At time: 189.88654446601868 and batch: 500, loss is 4.2179188585281375 and perplexity is 67.89204421324365
At time: 190.25180006027222 and batch: 550, loss is 4.296984715461731 and perplexity is 73.47790255177179
At time: 190.60312962532043 and batch: 600, loss is 4.198728609085083 and perplexity is 66.60160051971144
At time: 190.94471335411072 and batch: 650, loss is 4.296213984489441 and perplexity is 73.42129267479132
At time: 191.33213353157043 and batch: 700, loss is 4.347063856124878 and perplexity is 77.25130865289202
At time: 191.67775416374207 and batch: 750, loss is 4.283479690551758 and perplexity is 72.4922522441206
At time: 192.03493642807007 and batch: 800, loss is 4.204830446243286 and perplexity is 67.00923503550877
At time: 192.375328540802 and batch: 850, loss is 4.164575185775757 and perplexity is 64.36533332558169
At time: 192.72903728485107 and batch: 900, loss is 4.100944862365723 and perplexity is 60.39732780757998
At time: 193.07611918449402 and batch: 950, loss is 4.2211951684951785 and perplexity is 68.11484437628116
At time: 193.44857740402222 and batch: 1000, loss is 4.242803735733032 and perplexity is 69.60272617351858
At time: 193.7922911643982 and batch: 1050, loss is 4.175029006004333 and perplexity is 65.04172623424886
At time: 194.15372395515442 and batch: 1100, loss is 4.323465266227722 and perplexity is 75.44962886340888
At time: 194.50287199020386 and batch: 1150, loss is 4.262505841255188 and perplexity is 70.98764453436274
At time: 194.85875129699707 and batch: 1200, loss is 4.190196394920349 and perplexity is 66.03575877454655
At time: 195.212388753891 and batch: 1250, loss is 4.107625393867493 and perplexity is 60.80216481617739
At time: 195.55419826507568 and batch: 1300, loss is 4.239374852180481 and perplexity is 69.36447523132911
At time: 195.90476393699646 and batch: 1350, loss is 4.214749202728272 and perplexity is 67.67719048759841
At time: 196.24911904335022 and batch: 1400, loss is 4.055823864936829 and perplexity is 57.732707361709494
At time: 196.59656858444214 and batch: 1450, loss is 4.1816784954071045 and perplexity is 65.47566162909058
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.4895202115050745 and perplexity of 89.07869669037936
Finished 18 epochs...
Completing Train Step...
At time: 197.86470484733582 and batch: 50, loss is 4.240879836082459 and perplexity is 69.46894624379873
At time: 198.2357041835785 and batch: 100, loss is 4.265186457633972 and perplexity is 71.17819045314774
At time: 198.59083104133606 and batch: 150, loss is 4.1188198709487915 and perplexity is 61.48663726432327
At time: 198.93775606155396 and batch: 200, loss is 4.2408520174026485 and perplexity is 69.46701373630643
At time: 199.28804206848145 and batch: 250, loss is 4.293502888679504 and perplexity is 73.22251009692252
At time: 199.6398663520813 and batch: 300, loss is 4.296008853912354 and perplexity is 73.40623326727973
At time: 199.99835586547852 and batch: 350, loss is 4.309099721908569 and perplexity is 74.37350195701822
At time: 200.35807514190674 and batch: 400, loss is 4.124187026023865 and perplexity is 61.81753277099061
At time: 200.73598456382751 and batch: 450, loss is 4.215542178153992 and perplexity is 67.73087812021026
At time: 201.08840131759644 and batch: 500, loss is 4.195677223205567 and perplexity is 66.39868308347849
At time: 201.43837594985962 and batch: 550, loss is 4.2745973587036135 and perplexity is 71.8512032230056
At time: 201.8021378517151 and batch: 600, loss is 4.178176984786988 and perplexity is 65.24679882114589
At time: 202.15654468536377 and batch: 650, loss is 4.273681807518005 and perplexity is 71.78544987357897
At time: 202.49954962730408 and batch: 700, loss is 4.32477972984314 and perplexity is 75.54886986540058
At time: 202.8465085029602 and batch: 750, loss is 4.262595844268799 and perplexity is 70.9940339238278
At time: 203.193767786026 and batch: 800, loss is 4.183742461204528 and perplexity is 65.61094071293425
At time: 203.55338788032532 and batch: 850, loss is 4.143990592956543 and perplexity is 63.05394267416849
At time: 203.90131664276123 and batch: 900, loss is 4.078490395545959 and perplexity is 59.05625094473229
At time: 204.25858545303345 and batch: 950, loss is 4.2012818241119385 and perplexity is 66.77186599666277
At time: 204.60697412490845 and batch: 1000, loss is 4.2223825263977055 and perplexity is 68.19576910883364
At time: 204.96361660957336 and batch: 1050, loss is 4.15400414943695 and perplexity is 63.68850871952782
At time: 205.3130383491516 and batch: 1100, loss is 4.304139370918274 and perplexity is 74.00549675498439
At time: 205.66305828094482 and batch: 1150, loss is 4.242982954978943 and perplexity is 69.6152014394872
At time: 206.00891971588135 and batch: 1200, loss is 4.16995557308197 and perplexity is 64.71257706318215
At time: 206.3641219139099 and batch: 1250, loss is 4.084828987121582 and perplexity is 59.43177328352249
At time: 206.72620558738708 and batch: 1300, loss is 4.217032403945923 and perplexity is 67.83188766651739
At time: 207.0790638923645 and batch: 1350, loss is 4.194368886947632 and perplexity is 66.31186808291147
At time: 207.44671177864075 and batch: 1400, loss is 4.035379576683044 and perplexity is 56.56438668626049
At time: 207.79827404022217 and batch: 1450, loss is 4.161397562026978 and perplexity is 64.16112912768843
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.481066059862447 and perplexity of 88.32878627511936
Finished 19 epochs...
Completing Train Step...
At time: 209.11738276481628 and batch: 50, loss is 4.218650827407837 and perplexity is 67.9417572687721
At time: 209.46528458595276 and batch: 100, loss is 4.244607224464416 and perplexity is 69.72836716785018
At time: 209.8301980495453 and batch: 150, loss is 4.097007503509522 and perplexity is 60.15998940389604
At time: 210.19705080986023 and batch: 200, loss is 4.221300001144409 and perplexity is 68.12198541016927
At time: 210.54269194602966 and batch: 250, loss is 4.274730644226074 and perplexity is 71.86078058641438
At time: 210.88522291183472 and batch: 300, loss is 4.275702013969421 and perplexity is 71.93061788783879
At time: 211.2391176223755 and batch: 350, loss is 4.288675289154053 and perplexity is 72.86987302208524
At time: 211.5842113494873 and batch: 400, loss is 4.102335915565491 and perplexity is 60.48140216607966
At time: 211.9296088218689 and batch: 450, loss is 4.194250564575196 and perplexity is 66.3040223695301
At time: 212.2747185230255 and batch: 500, loss is 4.17464771270752 and perplexity is 65.01693098745366
At time: 212.6293387413025 and batch: 550, loss is 4.253511152267456 and perplexity is 70.35199576685005
At time: 212.98253321647644 and batch: 600, loss is 4.158666667938232 and perplexity is 63.98615091166005
At time: 213.32574439048767 and batch: 650, loss is 4.252329301834107 and perplexity is 70.26889934361013
At time: 213.6708002090454 and batch: 700, loss is 4.303574752807617 and perplexity is 73.96372370524834
At time: 214.02703976631165 and batch: 750, loss is 4.2428374767303465 and perplexity is 69.6050746785357
At time: 214.37297320365906 and batch: 800, loss is 4.163776588439942 and perplexity is 64.31395186115007
At time: 214.71745347976685 and batch: 850, loss is 4.124462084770203 and perplexity is 61.83453856274495
At time: 215.06742596626282 and batch: 900, loss is 4.057254767417907 and perplexity is 57.81537636745017
At time: 215.41365933418274 and batch: 950, loss is 4.1822759771347044 and perplexity is 65.51479382973979
At time: 215.75949239730835 and batch: 1000, loss is 4.202920498847962 and perplexity is 66.88137306527749
At time: 216.11595225334167 and batch: 1050, loss is 4.134074463844299 and perplexity is 62.43178145114798
At time: 216.47835302352905 and batch: 1100, loss is 4.285836501121521 and perplexity is 72.66330423983474
At time: 216.84023475646973 and batch: 1150, loss is 4.224391283988953 and perplexity is 68.33289555851036
At time: 217.18854808807373 and batch: 1200, loss is 4.1508672189712525 and perplexity is 63.489035326865626
At time: 217.54162001609802 and batch: 1250, loss is 4.063389277458191 and perplexity is 58.171135462463035
At time: 217.90250444412231 and batch: 1300, loss is 4.19590461730957 and perplexity is 66.41378346932954
At time: 218.2810935974121 and batch: 1350, loss is 4.175019655227661 and perplexity is 65.041118046436
At time: 218.62971544265747 and batch: 1400, loss is 4.016098594665527 and perplexity is 55.484216596891365
At time: 218.97940969467163 and batch: 1450, loss is 4.1420907258987425 and perplexity is 62.93426229002585
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.4732441698384084 and perplexity of 87.64058325588135
Finished 20 epochs...
Completing Train Step...
At time: 220.29523634910583 and batch: 50, loss is 4.197516074180603 and perplexity is 66.5208926948028
At time: 220.6522707939148 and batch: 100, loss is 4.225131487846374 and perplexity is 68.38349455586777
At time: 220.99028491973877 and batch: 150, loss is 4.076413021087647 and perplexity is 58.933696337395084
At time: 221.34634709358215 and batch: 200, loss is 4.202665758132935 and perplexity is 66.86433782635743
At time: 221.7030589580536 and batch: 250, loss is 4.256887187957764 and perplexity is 70.5899079895515
At time: 222.04824829101562 and batch: 300, loss is 4.256467003822326 and perplexity is 70.56025346070987
At time: 222.39451360702515 and batch: 350, loss is 4.269260091781616 and perplexity is 71.46873574617112
At time: 222.74070143699646 and batch: 400, loss is 4.081563777923584 and perplexity is 59.23803258483151
At time: 223.08666157722473 and batch: 450, loss is 4.174064846038818 and perplexity is 64.97904582755085
At time: 223.4316005706787 and batch: 500, loss is 4.1548055934906 and perplexity is 63.73957195555714
At time: 223.78255438804626 and batch: 550, loss is 4.233641133308411 and perplexity is 68.96789685159062
At time: 224.13565063476562 and batch: 600, loss is 4.140151882171631 and perplexity is 62.812360802518455
At time: 224.48156070709229 and batch: 650, loss is 4.2320601272583005 and perplexity is 68.85894433938996
At time: 224.84037518501282 and batch: 700, loss is 4.283361711502075 and perplexity is 72.48370018158353
At time: 225.18708753585815 and batch: 750, loss is 4.223984751701355 and perplexity is 68.30512167603327
At time: 225.54096150398254 and batch: 800, loss is 4.144873328208924 and perplexity is 63.10962718589344
At time: 225.89029240608215 and batch: 850, loss is 4.1059171581268314 and perplexity is 60.698389047103085
At time: 226.26670455932617 and batch: 900, loss is 4.037214670181275 and perplexity is 56.66828292499946
At time: 226.6210482120514 and batch: 950, loss is 4.164112319946289 and perplexity is 64.33554770608751
At time: 226.97511267662048 and batch: 1000, loss is 4.184390239715576 and perplexity is 65.6534558391236
At time: 227.32221364974976 and batch: 1050, loss is 4.115117783546448 and perplexity is 61.25942919066718
At time: 227.72420954704285 and batch: 1100, loss is 4.268417534828186 and perplexity is 71.40854462669924
At time: 228.0941460132599 and batch: 1150, loss is 4.206656403541565 and perplexity is 67.1317028137138
At time: 228.43879318237305 and batch: 1200, loss is 4.13276771068573 and perplexity is 62.350251804704804
At time: 228.77934432029724 and batch: 1250, loss is 4.043190197944641 and perplexity is 57.007919566395564
At time: 229.12899136543274 and batch: 1300, loss is 4.175740537643432 and perplexity is 65.08802194880576
At time: 229.48870420455933 and batch: 1350, loss is 4.156578202247619 and perplexity is 63.8526574775566
At time: 229.83920097351074 and batch: 1400, loss is 3.9978206014633177 and perplexity is 54.479288475256276
At time: 230.17946076393127 and batch: 1450, loss is 4.123690333366394 and perplexity is 61.78683608040178
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.4663393721621265 and perplexity of 87.03752714643137
Finished 21 epochs...
Completing Train Step...
At time: 231.4695496559143 and batch: 50, loss is 4.177360033988952 and perplexity is 65.19351716398926
At time: 231.86191248893738 and batch: 100, loss is 4.20666063785553 and perplexity is 67.1319870710223
At time: 232.21347880363464 and batch: 150, loss is 4.056810903549194 and perplexity is 57.78971990523412
At time: 232.57210683822632 and batch: 200, loss is 4.18492669582367 and perplexity is 65.6886854852605
At time: 232.9230179786682 and batch: 250, loss is 4.239914808273316 and perplexity is 69.4019391158727
At time: 233.27251291275024 and batch: 300, loss is 4.238166437149048 and perplexity is 69.28070478174132
At time: 233.62045645713806 and batch: 350, loss is 4.250715494155884 and perplexity is 70.15559030839627
At time: 233.97225522994995 and batch: 400, loss is 4.061955699920654 and perplexity is 58.08780237582342
At time: 234.33878135681152 and batch: 450, loss is 4.154792609214783 and perplexity is 63.738744348747346
At time: 234.69495725631714 and batch: 500, loss is 4.135992112159729 and perplexity is 62.5516185176276
At time: 235.04270267486572 and batch: 550, loss is 4.214697160720825 and perplexity is 67.67366852239296
At time: 235.3882405757904 and batch: 600, loss is 4.122533645629883 and perplexity is 61.71540932202113
At time: 235.74779295921326 and batch: 650, loss is 4.212728366851807 and perplexity is 67.54056408930239
At time: 236.09215354919434 and batch: 700, loss is 4.264144864082336 and perplexity is 71.1040903067713
At time: 236.43710112571716 and batch: 750, loss is 4.206023435592652 and perplexity is 67.08922404274526
At time: 236.8066864013672 and batch: 800, loss is 4.12684892654419 and perplexity is 61.98230409878696
At time: 237.15926003456116 and batch: 850, loss is 4.088259353637695 and perplexity is 59.635996127926624
At time: 237.5055968761444 and batch: 900, loss is 4.018258514404297 and perplexity is 55.604187568703
At time: 237.8542308807373 and batch: 950, loss is 4.146772742271423 and perplexity is 63.229612413990914
At time: 238.22003078460693 and batch: 1000, loss is 4.166791453361511 and perplexity is 64.50814232049603
At time: 238.58321237564087 and batch: 1050, loss is 4.097132720947266 and perplexity is 60.167522955280056
At time: 238.92572450637817 and batch: 1100, loss is 4.251757817268372 and perplexity is 70.22875322472036
At time: 239.2640299797058 and batch: 1150, loss is 4.189710245132447 and perplexity is 66.0036633066589
At time: 239.61072731018066 and batch: 1200, loss is 4.115523166656494 and perplexity is 61.284267762820825
At time: 239.96064925193787 and batch: 1250, loss is 4.024022564888001 and perplexity is 55.92561839476678
At time: 240.30489349365234 and batch: 1300, loss is 4.156502809524536 and perplexity is 63.84784363329996
At time: 240.65095949172974 and batch: 1350, loss is 4.138977460861206 and perplexity is 62.7386359279396
At time: 241.00654220581055 and batch: 1400, loss is 3.98046914100647 and perplexity is 53.54214715308292
At time: 241.3516833782196 and batch: 1450, loss is 4.106213655471802 and perplexity is 60.71638862658142
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.459825303819445 and perplexity of 86.47240137849325
Finished 22 epochs...
Completing Train Step...
At time: 242.64086437225342 and batch: 50, loss is 4.158036937713623 and perplexity is 63.94586958299084
At time: 243.00623655319214 and batch: 100, loss is 4.189136419296265 and perplexity is 65.96579956400676
At time: 243.36398768424988 and batch: 150, loss is 4.038223705291748 and perplexity is 56.72549207028518
At time: 243.7083203792572 and batch: 200, loss is 4.167955803871155 and perplexity is 64.58329615309412
At time: 244.05516624450684 and batch: 250, loss is 4.223736906051636 and perplexity is 68.28819464650431
At time: 244.43226027488708 and batch: 300, loss is 4.220651965141297 and perplexity is 68.07785421186706
At time: 244.78155207633972 and batch: 350, loss is 4.233003702163696 and perplexity is 68.92394857464026
At time: 245.14341235160828 and batch: 400, loss is 4.043457045555114 and perplexity is 57.02313402339038
At time: 245.49415349960327 and batch: 450, loss is 4.136427435874939 and perplexity is 62.57885464842978
At time: 245.8372631072998 and batch: 500, loss is 4.118318800926208 and perplexity is 61.45583587107252
At time: 246.19711804389954 and batch: 550, loss is 4.1966229963302615 and perplexity is 66.46151087919108
At time: 246.5588357448578 and batch: 600, loss is 4.1057087469100955 and perplexity is 60.6857401401207
At time: 246.90948963165283 and batch: 650, loss is 4.1942786121368405 and perplexity is 66.3058820617646
At time: 247.26308345794678 and batch: 700, loss is 4.2458489847183225 and perplexity is 69.81500686450188
At time: 247.61055612564087 and batch: 750, loss is 4.188898696899414 and perplexity is 65.9501198798041
At time: 247.97509264945984 and batch: 800, loss is 4.109633827209473 and perplexity is 60.92440462542212
At time: 248.32964062690735 and batch: 850, loss is 4.071371216773986 and perplexity is 58.63731195684092
At time: 248.68195605278015 and batch: 900, loss is 4.000494594573975 and perplexity is 54.62516066100406
At time: 249.0348014831543 and batch: 950, loss is 4.130121054649353 and perplexity is 62.18545031702231
At time: 249.3839955329895 and batch: 1000, loss is 4.150038890838623 and perplexity is 63.436467347564616
At time: 249.7281517982483 and batch: 1050, loss is 4.079925456047058 and perplexity is 59.14106107708677
At time: 250.07197499275208 and batch: 1100, loss is 4.235889735221863 and perplexity is 69.12315268528306
At time: 250.4196376800537 and batch: 1150, loss is 4.173464913368225 and perplexity is 64.9400744663202
At time: 250.7698037624359 and batch: 1200, loss is 4.099112501144409 and perplexity is 60.28675941778584
At time: 251.1232192516327 and batch: 1250, loss is 4.005735011100769 and perplexity is 54.91217062476832
At time: 251.4696216583252 and batch: 1300, loss is 4.137966809272766 and perplexity is 62.67526105623419
At time: 251.81764435768127 and batch: 1350, loss is 4.122070293426514 and perplexity is 61.68681997510992
At time: 252.1684226989746 and batch: 1400, loss is 3.9640081691741944 and perplexity is 52.66800572396367
At time: 252.53046298027039 and batch: 1450, loss is 4.089490647315979 and perplexity is 59.70947077811044
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.453524076021635 and perplexity of 85.92923219280084
Finished 23 epochs...
Completing Train Step...
At time: 253.8456552028656 and batch: 50, loss is 4.13991051197052 and perplexity is 62.79720159992275
At time: 254.2114508152008 and batch: 100, loss is 4.172323546409607 and perplexity is 64.86599629426505
At time: 254.57721376419067 and batch: 150, loss is 4.020443181991578 and perplexity is 55.72579702475202
At time: 254.92252278327942 and batch: 200, loss is 4.1517224836349484 and perplexity is 63.54335848233913
At time: 255.29876136779785 and batch: 250, loss is 4.208328461647033 and perplexity is 67.24404481654194
At time: 255.66395568847656 and batch: 300, loss is 4.203847360610962 and perplexity is 66.94339158948812
At time: 256.0065999031067 and batch: 350, loss is 4.216032915115356 and perplexity is 67.76412432243241
At time: 256.35446190834045 and batch: 400, loss is 4.025723342895508 and perplexity is 56.020816388968434
At time: 256.6978614330292 and batch: 450, loss is 4.118872628211975 and perplexity is 61.489881216597986
At time: 257.0462472438812 and batch: 500, loss is 4.101559886932373 and perplexity is 60.43448507308596
At time: 257.395791053772 and batch: 550, loss is 4.179286546707154 and perplexity is 65.31923436295854
At time: 257.7405369281769 and batch: 600, loss is 4.089579510688782 and perplexity is 59.71477699883288
At time: 258.0876281261444 and batch: 650, loss is 4.176574931144715 and perplexity is 65.14235363518199
At time: 258.43264746665955 and batch: 700, loss is 4.228506979942321 and perplexity is 68.61471251889728
At time: 258.77960658073425 and batch: 750, loss is 4.172654747962952 and perplexity is 64.88748357111028
At time: 259.13100934028625 and batch: 800, loss is 4.093145966529846 and perplexity is 59.92812734019949
At time: 259.4752371311188 and batch: 850, loss is 4.0554010725021366 and perplexity is 57.708303569035635
At time: 259.8353521823883 and batch: 900, loss is 3.983082962036133 and perplexity is 53.68227980433748
At time: 260.1793339252472 and batch: 950, loss is 4.114247851371765 and perplexity is 61.2061608155076
At time: 260.5289001464844 and batch: 1000, loss is 4.134069261550903 and perplexity is 62.431456663548445
At time: 260.88650393486023 and batch: 1050, loss is 4.063421926498413 and perplexity is 58.17303472520892
At time: 261.2363440990448 and batch: 1100, loss is 4.220720081329346 and perplexity is 68.08249157372445
At time: 261.581015586853 and batch: 1150, loss is 4.15784574508667 and perplexity is 63.93364477288645
At time: 261.9525830745697 and batch: 1200, loss is 4.083356642723084 and perplexity is 59.34433363147261
At time: 262.32072710990906 and batch: 1250, loss is 3.988172392845154 and perplexity is 53.956188481463656
At time: 262.6711308956146 and batch: 1300, loss is 4.120161576271057 and perplexity is 61.569189580846206
At time: 263.02035760879517 and batch: 1350, loss is 4.10586030960083 and perplexity is 60.694938531234406
At time: 263.367547750473 and batch: 1400, loss is 3.948366742134094 and perplexity is 51.8506122203406
At time: 263.71672773361206 and batch: 1450, loss is 4.073530483245849 and perplexity is 58.76406233322143
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.447493593916934 and perplexity of 85.41259684160471
Finished 24 epochs...
Completing Train Step...
At time: 265.00949335098267 and batch: 50, loss is 4.122098922729492 and perplexity is 61.688586051049384
At time: 265.36400747299194 and batch: 100, loss is 4.156275839805603 and perplexity is 63.83335375062052
At time: 265.7164900302887 and batch: 150, loss is 4.003517212867737 and perplexity is 54.79052145630248
At time: 266.07597494125366 and batch: 200, loss is 4.136136808395386 and perplexity is 62.560670156214535
At time: 266.42392349243164 and batch: 250, loss is 4.193640427589417 and perplexity is 66.26358017207136
At time: 266.78036403656006 and batch: 300, loss is 4.187793092727661 and perplexity is 65.87724544470038
At time: 267.14467763900757 and batch: 350, loss is 4.199840221405029 and perplexity is 66.67567684382666
At time: 267.50081872940063 and batch: 400, loss is 4.008570823669434 and perplexity is 55.06811225451082
At time: 267.8479790687561 and batch: 450, loss is 4.10207308769226 and perplexity is 60.46550805657734
At time: 268.2054145336151 and batch: 500, loss is 4.085209493637085 and perplexity is 59.45439176345136
At time: 268.55113410949707 and batch: 550, loss is 4.162728095054627 and perplexity is 64.246554447086
At time: 268.89826107025146 and batch: 600, loss is 4.074087886810303 and perplexity is 58.796826761684024
At time: 269.24473094940186 and batch: 650, loss is 4.159724431037903 and perplexity is 64.05386890947008
At time: 269.59833097457886 and batch: 700, loss is 4.212019596099854 and perplexity is 67.49271027360123
At time: 269.96522092819214 and batch: 750, loss is 4.156953535079956 and perplexity is 63.876627974515735
At time: 270.3201093673706 and batch: 800, loss is 4.077279887199402 and perplexity is 58.98480611105525
At time: 270.66407799720764 and batch: 850, loss is 4.03998484134674 and perplexity is 56.825481401171295
At time: 271.0270538330078 and batch: 900, loss is 3.966407017707825 and perplexity is 52.7944999518514
At time: 271.37473726272583 and batch: 950, loss is 4.099038882255554 and perplexity is 60.28232133691011
At time: 271.72859025001526 and batch: 1000, loss is 4.118849411010742 and perplexity is 61.488453610224525
At time: 272.09306049346924 and batch: 1050, loss is 4.047877264022827 and perplexity is 57.275746623625544
At time: 272.4621284008026 and batch: 1100, loss is 4.206153168678283 and perplexity is 67.09792829939579
At time: 272.81265568733215 and batch: 1150, loss is 4.14276505947113 and perplexity is 62.97671528807367
At time: 273.18575048446655 and batch: 1200, loss is 4.068323879241944 and perplexity is 58.45889625982959
At time: 273.5349020957947 and batch: 1250, loss is 3.9713636159896852 and perplexity is 53.05683067653876
At time: 273.89491271972656 and batch: 1300, loss is 4.102959332466125 and perplexity is 60.519119049813874
At time: 274.2465262413025 and batch: 1350, loss is 4.090322775840759 and perplexity is 59.759177410229434
At time: 274.5931522846222 and batch: 1400, loss is 3.9334827852249146 and perplexity is 51.08458484316529
At time: 274.9419710636139 and batch: 1450, loss is 4.058233423233032 and perplexity is 57.87198541760568
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.441861666165865 and perplexity of 84.93291131219657
Finished 25 epochs...
Completing Train Step...
At time: 276.2427713871002 and batch: 50, loss is 4.105560579299927 and perplexity is 60.67674914513639
At time: 276.6250364780426 and batch: 100, loss is 4.140832614898682 and perplexity is 62.855133789014175
At time: 276.9715600013733 and batch: 150, loss is 3.9870176315307617 and perplexity is 53.89391792306882
At time: 277.31347608566284 and batch: 200, loss is 4.121062445640564 and perplexity is 61.624680369067775
At time: 277.6857407093048 and batch: 250, loss is 4.179555187225342 and perplexity is 65.33678411310689
At time: 278.0256247520447 and batch: 300, loss is 4.172370371818542 and perplexity is 64.86903374218183
At time: 278.370414018631 and batch: 350, loss is 4.184213366508484 and perplexity is 65.64184452872777
At time: 278.7229163646698 and batch: 400, loss is 3.99241988658905 and perplexity is 54.18585446160263
At time: 279.07037448883057 and batch: 450, loss is 4.085939679145813 and perplexity is 59.49782035228083
At time: 279.41826272010803 and batch: 500, loss is 4.069475946426391 and perplexity is 58.526283645794194
At time: 279.7849533557892 and batch: 550, loss is 4.146706547737121 and perplexity is 63.22542709776714
At time: 280.1336581707001 and batch: 600, loss is 4.059173617362976 and perplexity is 57.92642190500648
At time: 280.49598574638367 and batch: 650, loss is 4.143621158599854 and perplexity is 63.03065268374613
At time: 280.8448278903961 and batch: 700, loss is 4.196233310699463 and perplexity is 66.43561682899761
At time: 281.18918800354004 and batch: 750, loss is 4.141916680335998 and perplexity is 62.92330981407227
At time: 281.54935240745544 and batch: 800, loss is 4.062022857666015 and perplexity is 58.09170355265963
At time: 281.89492988586426 and batch: 850, loss is 4.0252441310882565 and perplexity is 55.99397698369657
At time: 282.2704610824585 and batch: 900, loss is 3.9508218955993653 and perplexity is 51.978069830582676
At time: 282.6458489894867 and batch: 950, loss is 4.084351162910462 and perplexity is 59.403382126869026
At time: 282.9949128627777 and batch: 1000, loss is 4.104238829612732 and perplexity is 60.59660264940477
At time: 283.3430368900299 and batch: 1050, loss is 4.033037714958191 and perplexity is 56.43207570157513
At time: 283.69313859939575 and batch: 1100, loss is 4.192172269821167 and perplexity is 66.1663661623035
At time: 284.03929376602173 and batch: 1150, loss is 4.128279819488525 and perplexity is 62.07105762364859
At time: 284.40122270584106 and batch: 1200, loss is 4.053951086997986 and perplexity is 57.624688000722266
At time: 284.7486250400543 and batch: 1250, loss is 3.9553241777420043 and perplexity is 52.21261736958759
At time: 285.0991451740265 and batch: 1300, loss is 4.086443266868591 and perplexity is 59.52779026975018
At time: 285.44292974472046 and batch: 1350, loss is 4.075339860916138 and perplexity is 58.87048496575578
At time: 285.78711676597595 and batch: 1400, loss is 3.919255404472351 and perplexity is 50.362930800395425
At time: 286.130499124527 and batch: 1450, loss is 4.043611392974854 and perplexity is 57.03193607626194
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.436721671340812 and perplexity of 84.49747661229244
Finished 26 epochs...
Completing Train Step...
At time: 287.4045743942261 and batch: 50, loss is 4.08942409992218 and perplexity is 59.70549740065546
At time: 287.77366518974304 and batch: 100, loss is 4.126018052101135 and perplexity is 61.93082597527975
At time: 288.1142590045929 and batch: 150, loss is 3.971248607635498 and perplexity is 53.05072904864008
At time: 288.47630310058594 and batch: 200, loss is 4.1066215467453 and perplexity is 60.741159363200765
At time: 288.8303396701813 and batch: 250, loss is 4.1659790849685665 and perplexity is 64.45575922465382
At time: 289.175564289093 and batch: 300, loss is 4.1575556659698485 and perplexity is 63.915101647292346
At time: 289.5248861312866 and batch: 350, loss is 4.16919593334198 and perplexity is 64.66343748451916
At time: 289.89916801452637 and batch: 400, loss is 3.9765563917160036 and perplexity is 53.33305947538505
At time: 290.2409646511078 and batch: 450, loss is 4.070353889465332 and perplexity is 58.57768895127931
At time: 290.585734128952 and batch: 500, loss is 4.0543023872375485 and perplexity is 57.64493512362296
At time: 290.94340896606445 and batch: 550, loss is 4.13137312412262 and perplexity is 62.263359584775436
At time: 291.29109358787537 and batch: 600, loss is 4.044899187088013 and perplexity is 57.10542877938144
At time: 291.67540168762207 and batch: 650, loss is 4.128092927932739 and perplexity is 62.05945815107553
At time: 292.01502776145935 and batch: 700, loss is 4.181196160316468 and perplexity is 65.44408803504251
At time: 292.35379457473755 and batch: 750, loss is 4.127403650283814 and perplexity is 62.01669669261935
At time: 292.7051570415497 and batch: 800, loss is 4.047381930351257 and perplexity is 57.247383043056715
At time: 293.0527694225311 and batch: 850, loss is 4.011184220314026 and perplexity is 55.21221529148068
At time: 293.407249212265 and batch: 900, loss is 3.9360252141952516 and perplexity is 51.21462901559404
At time: 293.76018238067627 and batch: 950, loss is 4.070137348175049 and perplexity is 58.56500583619058
At time: 294.11880826950073 and batch: 1000, loss is 4.090236401557922 and perplexity is 59.75401597704844
At time: 294.4665925502777 and batch: 1050, loss is 4.018630604743958 and perplexity is 55.624881199453284
At time: 294.853036403656 and batch: 1100, loss is 4.178680944442749 and perplexity is 65.27968886235013
At time: 295.2097952365875 and batch: 1150, loss is 4.114290223121643 and perplexity is 61.20875428258918
At time: 295.5704667568207 and batch: 1200, loss is 4.040143475532532 and perplexity is 56.834496580184485
At time: 295.94123101234436 and batch: 1250, loss is 3.93994375705719 and perplexity is 51.41570944839849
At time: 296.28881764411926 and batch: 1300, loss is 4.07056556224823 and perplexity is 58.590089566105384
At time: 296.6505722999573 and batch: 1350, loss is 4.060960474014283 and perplexity is 58.03002064776044
At time: 297.0164873600006 and batch: 1400, loss is 3.905616035461426 and perplexity is 49.68067554509551
At time: 297.3634204864502 and batch: 1450, loss is 4.0295636224746705 and perplexity is 56.23636560587764
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.431997445913462 and perplexity of 84.09923292189472
Finished 27 epochs...
Completing Train Step...
At time: 298.69301104545593 and batch: 50, loss is 4.074069104194641 and perplexity is 58.79572241385612
At time: 299.04873418807983 and batch: 100, loss is 4.111688165664673 and perplexity is 61.049692620614735
At time: 299.40863704681396 and batch: 150, loss is 3.95616485118866 and perplexity is 52.25652958592154
At time: 299.7466125488281 and batch: 200, loss is 4.092560205459595 and perplexity is 59.893034055334006
At time: 300.090699672699 and batch: 250, loss is 4.153051772117615 and perplexity is 63.627882102610954
At time: 300.4448342323303 and batch: 300, loss is 4.143306975364685 and perplexity is 63.01085261995808
At time: 300.83115577697754 and batch: 350, loss is 4.154651045799255 and perplexity is 63.72972191303436
At time: 301.168732881546 and batch: 400, loss is 3.9614708375930787 and perplexity is 52.53453892609201
At time: 301.5235261917114 and batch: 450, loss is 4.055349736213684 and perplexity is 57.70534111495888
At time: 301.86337447166443 and batch: 500, loss is 4.039731168746949 and perplexity is 56.81106816176909
At time: 302.2071144580841 and batch: 550, loss is 4.116646580696106 and perplexity is 61.35315405630261
At time: 302.5616331100464 and batch: 600, loss is 4.031075549125672 and perplexity is 56.321455174176606
At time: 302.9030668735504 and batch: 650, loss is 4.1132464027404785 and perplexity is 61.144896671099545
At time: 303.263375043869 and batch: 700, loss is 4.166798090934753 and perplexity is 64.50857049943643
At time: 303.6036591529846 and batch: 750, loss is 4.1133601236343384 and perplexity is 61.15185051879536
At time: 303.95836305618286 and batch: 800, loss is 4.03325900554657 and perplexity is 56.44456497063846
At time: 304.29618406295776 and batch: 850, loss is 3.9976807165145876 and perplexity is 54.47166817577608
At time: 304.6497895717621 and batch: 900, loss is 3.9218127393722533 and perplexity is 50.49189050728959
At time: 305.011351108551 and batch: 950, loss is 4.05648588180542 and perplexity is 57.77094004179561
At time: 305.36903500556946 and batch: 1000, loss is 4.076771020889282 and perplexity is 58.954798366029166
At time: 305.7200930118561 and batch: 1050, loss is 4.004917106628418 and perplexity is 54.86727607705626
At time: 306.06898975372314 and batch: 1100, loss is 4.165630903244018 and perplexity is 64.43332081379889
At time: 306.4416129589081 and batch: 1150, loss is 4.100784659385681 and perplexity is 60.3876527506858
At time: 306.8064696788788 and batch: 1200, loss is 4.02689269065857 and perplexity is 56.086362520940334
At time: 307.16213274002075 and batch: 1250, loss is 3.9256888246536255 and perplexity is 50.687981167468365
At time: 307.50152564048767 and batch: 1300, loss is 4.055295605659484 and perplexity is 57.7022175774042
At time: 307.8456642627716 and batch: 1350, loss is 4.047056288719177 and perplexity is 57.22874394680784
At time: 308.20763087272644 and batch: 1400, loss is 3.8923196029663085 and perplexity is 49.02447204692592
At time: 308.57712411880493 and batch: 1450, loss is 4.016061992645263 and perplexity is 55.482185799637044
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.427583612947383 and perplexity of 83.7288509585745
Finished 28 epochs...
Completing Train Step...
At time: 309.866819858551 and batch: 50, loss is 4.059052124023437 and perplexity is 57.91938465805966
At time: 310.2161102294922 and batch: 100, loss is 4.097887372970581 and perplexity is 60.21294563521909
At time: 310.5621426105499 and batch: 150, loss is 3.9414977550506594 and perplexity is 51.4956714720345
At time: 310.934401512146 and batch: 200, loss is 4.0790414094924925 and perplexity is 59.08880072950195
At time: 311.27885007858276 and batch: 250, loss is 4.140537400245666 and perplexity is 62.83658077119849
At time: 311.642160654068 and batch: 300, loss is 4.129507479667663 and perplexity is 62.14730658369956
At time: 311.99041533470154 and batch: 350, loss is 4.140699081420898 and perplexity is 62.84674108476873
At time: 312.33317017555237 and batch: 400, loss is 3.9469026279449464 and perplexity is 51.774752550433604
At time: 312.694185256958 and batch: 450, loss is 4.041034851074219 and perplexity is 56.88518004600516
At time: 313.0481517314911 and batch: 500, loss is 4.025763487815857 and perplexity is 56.02306538532284
At time: 313.4055564403534 and batch: 550, loss is 4.102384090423584 and perplexity is 60.48431591923053
At time: 313.75044322013855 and batch: 600, loss is 4.017740879058838 and perplexity is 55.57541232404627
At time: 314.10710883140564 and batch: 650, loss is 4.098816685676574 and perplexity is 60.26892829933476
At time: 314.45210909843445 and batch: 700, loss is 4.153142132759094 and perplexity is 63.63363181862383
At time: 314.79773235321045 and batch: 750, loss is 4.099828729629516 and perplexity is 60.329953978896675
At time: 315.14380526542664 and batch: 800, loss is 4.019593467712403 and perplexity is 55.6784661310176
At time: 315.50877046585083 and batch: 850, loss is 3.9845221138000486 and perplexity is 53.759592370923315
At time: 315.8555340766907 and batch: 900, loss is 3.9078083848953247 and perplexity is 49.78971242580149
At time: 316.19802713394165 and batch: 950, loss is 4.043403015136719 and perplexity is 57.0200531228328
At time: 316.5524318218231 and batch: 1000, loss is 4.063957681655884 and perplexity is 58.20420957888732
At time: 316.89749574661255 and batch: 1050, loss is 3.9915880012512206 and perplexity is 54.14079678776582
At time: 317.26710653305054 and batch: 1100, loss is 4.152972483634949 and perplexity is 63.62283734438206
At time: 317.61754751205444 and batch: 1150, loss is 4.087692613601685 and perplexity is 59.60220759689461
At time: 317.9863076210022 and batch: 1200, loss is 4.014054093360901 and perplexity is 55.37089492629813
At time: 318.33657717704773 and batch: 1250, loss is 3.9113142347335814 and perplexity is 49.9645740212026
At time: 318.68452310562134 and batch: 1300, loss is 4.040811243057251 and perplexity is 56.87246148573925
At time: 319.03077244758606 and batch: 1350, loss is 4.033737788200378 and perplexity is 56.47159611975446
At time: 319.3854880332947 and batch: 1400, loss is 3.879564685821533 and perplexity is 48.40313991143426
At time: 319.7334814071655 and batch: 1450, loss is 4.003094935417176 and perplexity is 54.76738953897425
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.423595461071047 and perplexity of 83.39559256877287
Finished 29 epochs...
Completing Train Step...
At time: 321.01654291152954 and batch: 50, loss is 4.044738559722901 and perplexity is 57.09625682147646
At time: 321.39930486679077 and batch: 100, loss is 4.084568514823913 and perplexity is 59.41629496890442
At time: 321.76224184036255 and batch: 150, loss is 3.927420039176941 and perplexity is 50.77580893904413
At time: 322.1200969219208 and batch: 200, loss is 4.06595675945282 and perplexity is 58.32068070057343
At time: 322.47284507751465 and batch: 250, loss is 4.128301582336426 and perplexity is 62.07240848133389
At time: 322.8161532878876 and batch: 300, loss is 4.116163177490234 and perplexity is 61.323502912247925
At time: 323.1795780658722 and batch: 350, loss is 4.127230339050293 and perplexity is 62.005949433753905
At time: 323.5273449420929 and batch: 400, loss is 3.9328880643844606 and perplexity is 51.05421280826938
At time: 323.86921787261963 and batch: 450, loss is 4.027110848426819 and perplexity is 56.09859953136804
At time: 324.2154664993286 and batch: 500, loss is 4.012284274101257 and perplexity is 55.27298511692362
At time: 324.55822014808655 and batch: 550, loss is 4.088710885047913 and perplexity is 59.66292973358489
At time: 324.9094932079315 and batch: 600, loss is 4.0048947381973266 and perplexity is 54.866048795898394
At time: 325.26830649375916 and batch: 650, loss is 4.084969134330749 and perplexity is 59.44010306436819
At time: 325.61759972572327 and batch: 700, loss is 4.13982928276062 and perplexity is 62.79210084002103
At time: 325.97377157211304 and batch: 750, loss is 4.086648273468017 and perplexity is 59.53999511059845
At time: 326.31496810913086 and batch: 800, loss is 4.006393103599549 and perplexity is 54.948319805796
At time: 326.65500020980835 and batch: 850, loss is 3.9719337892532347 and perplexity is 53.08709088880139
At time: 326.9969937801361 and batch: 900, loss is 3.894287405014038 and perplexity is 49.12103748307982
At time: 327.353182554245 and batch: 950, loss is 4.030834803581238 and perplexity is 56.30789766680761
At time: 327.6928460597992 and batch: 1000, loss is 4.051446537971497 and perplexity is 57.48054472678459
At time: 328.07539105415344 and batch: 1050, loss is 3.9787572908401487 and perplexity is 53.45056942561125
At time: 328.44145107269287 and batch: 1100, loss is 4.140776596069336 and perplexity is 62.85161281662223
At time: 328.7868084907532 and batch: 1150, loss is 4.075061030387879 and perplexity is 58.854072365607216
At time: 329.13527274131775 and batch: 1200, loss is 4.001697640419007 and perplexity is 54.69091677945319
At time: 329.5013861656189 and batch: 1250, loss is 3.8977276515960693 and perplexity is 49.290316979034436
At time: 329.86276364326477 and batch: 1300, loss is 4.026772246360779 and perplexity is 56.079607645192176
At time: 330.20642471313477 and batch: 1350, loss is 4.020868058204651 and perplexity is 55.74947862087958
At time: 330.5720248222351 and batch: 1400, loss is 3.867140784263611 and perplexity is 47.805504236710334
At time: 330.94622111320496 and batch: 1450, loss is 3.9906096029281617 and perplexity is 54.08785142802874
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.420015253572383 and perplexity of 83.09755288321435
Finished 30 epochs...
Completing Train Step...
At time: 332.2421009540558 and batch: 50, loss is 4.030893807411194 and perplexity is 56.31122014644529
At time: 332.60908794403076 and batch: 100, loss is 4.071709785461426 and perplexity is 58.65716807572551
At time: 332.95370149612427 and batch: 150, loss is 3.9138627099990844 and perplexity is 50.09206989328103
At time: 333.31148409843445 and batch: 200, loss is 4.053375587463379 and perplexity is 57.59153456040575
At time: 333.6691641807556 and batch: 250, loss is 4.116454477310181 and perplexity is 61.34136903967826
At time: 334.018917798996 and batch: 300, loss is 4.103232827186584 and perplexity is 60.53567297296295
At time: 334.36589097976685 and batch: 350, loss is 4.114234170913696 and perplexity is 61.20532349291852
At time: 334.70423412323 and batch: 400, loss is 3.9194423961639404 and perplexity is 50.372349130566505
At time: 335.0442178249359 and batch: 450, loss is 4.013787550926208 and perplexity is 55.356138199887624
At time: 335.3865170478821 and batch: 500, loss is 3.999457211494446 and perplexity is 54.56852282626281
At time: 335.7265486717224 and batch: 550, loss is 4.075493845939636 and perplexity is 58.879550836752856
At time: 336.07488107681274 and batch: 600, loss is 3.9923932266235354 and perplexity is 54.18440988784752
At time: 336.4144997596741 and batch: 650, loss is 4.071387615203857 and perplexity is 58.63827352457294
At time: 336.7699682712555 and batch: 700, loss is 4.1271496725082395 and perplexity is 62.00094782996011
At time: 337.1473970413208 and batch: 750, loss is 4.073975839614868 and perplexity is 58.79023911121568
At time: 337.49863600730896 and batch: 800, loss is 3.9935207843780516 and perplexity is 54.24554039700356
At time: 337.84835290908813 and batch: 850, loss is 3.959626274108887 and perplexity is 52.43772495114166
At time: 338.1972496509552 and batch: 900, loss is 3.8809197664260866 and perplexity is 48.46877452758197
At time: 338.5824725627899 and batch: 950, loss is 4.018662405014038 and perplexity is 55.62665011382444
At time: 338.9302909374237 and batch: 1000, loss is 4.039424285888672 and perplexity is 56.793636493666746
At time: 339.2809147834778 and batch: 1050, loss is 3.9663712930679322 and perplexity is 52.7926139210414
At time: 339.6239683628082 and batch: 1100, loss is 4.128867168426513 and perplexity is 62.10752570211883
At time: 340.00523710250854 and batch: 1150, loss is 4.062800440788269 and perplexity is 58.136892247591504
At time: 340.3508734703064 and batch: 1200, loss is 3.9896952724456787 and perplexity is 54.03841985857519
At time: 340.71195459365845 and batch: 1250, loss is 3.8848778676986693 and perplexity is 48.66099901675967
At time: 341.07105231285095 and batch: 1300, loss is 4.013689565658569 and perplexity is 55.350714379602216
At time: 341.41901326179504 and batch: 1350, loss is 4.00838800907135 and perplexity is 55.058045919866274
At time: 341.76411390304565 and batch: 1400, loss is 3.8551739645004273 and perplexity is 47.236833758723336
At time: 342.10278367996216 and batch: 1450, loss is 3.9785294246673586 and perplexity is 53.438391236474146
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.416626498230502 and perplexity of 82.8164322006161
Finished 31 epochs...
Completing Train Step...
At time: 343.4107632637024 and batch: 50, loss is 4.017704095840454 and perplexity is 55.57336811911441
At time: 343.75369811058044 and batch: 100, loss is 4.059305052757264 and perplexity is 57.934035987478225
At time: 344.093861579895 and batch: 150, loss is 3.9010855627059935 and perplexity is 49.45610768146885
At time: 344.4532747268677 and batch: 200, loss is 4.041278376579284 and perplexity is 56.899034725122
At time: 344.8237383365631 and batch: 250, loss is 4.104992070198059 and perplexity is 60.642263664559245
At time: 345.1672430038452 and batch: 300, loss is 4.090632863044739 and perplexity is 59.77771083980588
At time: 345.5266435146332 and batch: 350, loss is 4.101621642112732 and perplexity is 60.438217330853476
At time: 345.88630867004395 and batch: 400, loss is 3.906426901817322 and perplexity is 49.72097627047622
At time: 346.2620298862457 and batch: 450, loss is 4.0008841180801396 and perplexity is 54.646442589746215
At time: 346.62118196487427 and batch: 500, loss is 3.986817922592163 and perplexity is 53.88315590059529
At time: 346.98606729507446 and batch: 550, loss is 4.062827701568604 and perplexity is 58.13847712624281
At time: 347.34410667419434 and batch: 600, loss is 3.980249810218811 and perplexity is 53.53040499952985
At time: 347.69055581092834 and batch: 650, loss is 4.058301033973694 and perplexity is 57.875898317678896
At time: 348.0415141582489 and batch: 700, loss is 4.114751558303833 and perplexity is 61.23699854893371
At time: 348.4038796424866 and batch: 750, loss is 4.061588830947876 and perplexity is 58.066495672058124
At time: 348.76554918289185 and batch: 800, loss is 3.9811309003829956 and perplexity is 53.57759089732236
At time: 349.13956785202026 and batch: 850, loss is 3.9475232934951783 and perplexity is 51.80689733026025
At time: 349.48993849754333 and batch: 900, loss is 3.8682979679107667 and perplexity is 47.8608560043606
At time: 349.86661028862 and batch: 950, loss is 4.006892905235291 and perplexity is 54.975789930150924
At time: 350.22379446029663 and batch: 1000, loss is 4.02768337726593 and perplexity is 56.13072679344795
At time: 350.60123014450073 and batch: 1050, loss is 3.9542473459243777 and perplexity is 52.156423423067295
At time: 350.9466428756714 and batch: 1100, loss is 4.117366766929626 and perplexity is 61.39735566802265
At time: 351.31583523750305 and batch: 1150, loss is 4.050995841026306 and perplexity is 57.45464425793782
At time: 351.66129994392395 and batch: 1200, loss is 3.9781189823150633 and perplexity is 53.41646235805025
At time: 352.0094871520996 and batch: 1250, loss is 3.8720487260818484 and perplexity is 48.04070758012887
At time: 352.3663589954376 and batch: 1300, loss is 4.000466222763062 and perplexity is 54.62361086826
At time: 352.7070224285126 and batch: 1350, loss is 3.996206955909729 and perplexity is 54.391449103511384
At time: 353.0572726726532 and batch: 1400, loss is 3.8433326482772827 and perplexity is 46.68078613791433
At time: 353.39287281036377 and batch: 1450, loss is 3.9667917251586915 and perplexity is 52.81481429663702
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.41349596854968 and perplexity of 82.55757828788266
Finished 32 epochs...
Completing Train Step...
At time: 354.7011432647705 and batch: 50, loss is 4.004806046485901 and perplexity is 54.86118284791933
At time: 355.04733777046204 and batch: 100, loss is 4.04742127418518 and perplexity is 57.24963541889596
At time: 355.4087059497833 and batch: 150, loss is 3.8884126567840576 and perplexity is 48.833309746597074
At time: 355.7761375904083 and batch: 200, loss is 4.029570426940918 and perplexity is 56.23674826563117
At time: 356.12914299964905 and batch: 250, loss is 4.093710417747498 and perplexity is 59.96196339315052
At time: 356.49057483673096 and batch: 300, loss is 4.078525762557984 and perplexity is 59.05833962480456
At time: 356.83906984329224 and batch: 350, loss is 4.08952027797699 and perplexity is 59.71124003541022
At time: 357.2052903175354 and batch: 400, loss is 3.8936190509796145 and perplexity is 49.08821820817201
At time: 357.5616674423218 and batch: 450, loss is 3.9884368896484377 and perplexity is 53.97046160834939
At time: 357.8989701271057 and batch: 500, loss is 3.9746977376937864 and perplexity is 53.234023834880425
At time: 358.23858094215393 and batch: 550, loss is 4.050548739433289 and perplexity is 57.428961936695075
At time: 358.5960030555725 and batch: 600, loss is 3.9684368562698364 and perplexity is 52.901773100470024
At time: 358.95543599128723 and batch: 650, loss is 4.045634098052979 and perplexity is 57.14741161008226
At time: 359.30432629585266 and batch: 700, loss is 4.102783451080322 and perplexity is 60.508475799290075
At time: 359.649028301239 and batch: 750, loss is 4.04976939201355 and perplexity is 57.38422225953192
At time: 360.0117087364197 and batch: 800, loss is 3.9692055082321165 and perplexity is 52.94245178404394
At time: 360.37037467956543 and batch: 850, loss is 3.9358252239227296 and perplexity is 51.20438761210477
At time: 360.71734523773193 and batch: 900, loss is 3.855898590087891 and perplexity is 47.27107518174301
At time: 361.07490825653076 and batch: 950, loss is 3.9955420541763305 and perplexity is 54.35529615513134
At time: 361.4637110233307 and batch: 1000, loss is 4.016314263343811 and perplexity is 55.49618409501131
At time: 361.816508769989 and batch: 1050, loss is 3.9424759197235106 and perplexity is 51.546067362394744
At time: 362.16339898109436 and batch: 1100, loss is 4.106151599884033 and perplexity is 60.712620952301826
At time: 362.5254831314087 and batch: 1150, loss is 4.039595251083374 and perplexity is 56.80334705884839
At time: 362.88523507118225 and batch: 1200, loss is 3.9668188810348513 and perplexity is 52.81624854866755
At time: 363.2262661457062 and batch: 1250, loss is 3.8596815776824953 and perplexity is 47.45023974773588
At time: 363.57240533828735 and batch: 1300, loss is 3.987809648513794 and perplexity is 53.93661972939175
At time: 363.9336304664612 and batch: 1350, loss is 3.984453115463257 and perplexity is 53.755883176428725
At time: 364.30892848968506 and batch: 1400, loss is 3.8319872283935545 and perplexity is 46.15416603059824
At time: 364.6724829673767 and batch: 1450, loss is 3.955462784767151 and perplexity is 52.21985490673148
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.410592364449786 and perplexity of 82.31821144653311
Finished 33 epochs...
Completing Train Step...
At time: 366.13834714889526 and batch: 50, loss is 3.9925103521347047 and perplexity is 54.19075663622887
At time: 366.48008847236633 and batch: 100, loss is 4.035786595344543 and perplexity is 56.58741413320046
At time: 366.8285822868347 and batch: 150, loss is 3.8760273694992065 and perplexity is 48.23222516255487
At time: 367.19569158554077 and batch: 200, loss is 4.018237996101379 and perplexity is 55.603046676843576
At time: 367.55536913871765 and batch: 250, loss is 4.083018350601196 and perplexity is 59.32426130627257
At time: 367.90658378601074 and batch: 300, loss is 4.066756038665772 and perplexity is 58.36731384231041
At time: 368.26004362106323 and batch: 350, loss is 4.07779103755951 and perplexity is 59.01496392287137
At time: 368.6085059642792 and batch: 400, loss is 3.8813436603546143 and perplexity is 48.48932450202438
At time: 368.9974126815796 and batch: 450, loss is 3.9763624906539916 and perplexity is 53.322719141045724
At time: 369.34962034225464 and batch: 500, loss is 3.962766742706299 and perplexity is 52.60266283523432
At time: 369.7054212093353 and batch: 550, loss is 4.038700914382934 and perplexity is 56.75256845083677
At time: 370.0614011287689 and batch: 600, loss is 3.9569552516937256 and perplexity is 52.29784950078887
At time: 370.4327189922333 and batch: 650, loss is 4.033284225463867 and perplexity is 56.44598851584969
At time: 370.77895283699036 and batch: 700, loss is 4.091080250740052 and perplexity is 59.80446063540809
At time: 371.1407513618469 and batch: 750, loss is 4.038288254737854 and perplexity is 56.72915378755802
At time: 371.49692130088806 and batch: 800, loss is 3.9576605463027956 and perplexity is 52.334747902700144
At time: 371.8512177467346 and batch: 850, loss is 3.9245304679870605 and perplexity is 50.62930039975898
At time: 372.20132780075073 and batch: 900, loss is 3.8440415239334107 and perplexity is 46.713888742245416
At time: 372.5407860279083 and batch: 950, loss is 3.9845539712905884 and perplexity is 53.76130504390928
At time: 372.88604521751404 and batch: 1000, loss is 4.005303368568421 and perplexity is 54.888473311135286
At time: 373.23145961761475 and batch: 1050, loss is 3.9311111545562745 and perplexity is 50.963574627545604
At time: 373.5940251350403 and batch: 1100, loss is 4.095302410125733 and perplexity is 60.057498407186216
At time: 373.94963908195496 and batch: 1150, loss is 4.028576765060425 and perplexity is 56.18089570647179
At time: 374.2984960079193 and batch: 1200, loss is 3.9558615684509277 and perplexity is 52.24068348561015
At time: 374.65127205848694 and batch: 1250, loss is 3.847698907852173 and perplexity is 46.88505218212374
At time: 375.00479674339294 and batch: 1300, loss is 3.975597105026245 and perplexity is 53.28192231282741
At time: 375.361780166626 and batch: 1350, loss is 3.973053503036499 and perplexity is 53.14656652781535
At time: 375.7274193763733 and batch: 1400, loss is 3.820901641845703 and perplexity is 45.645345526136914
At time: 376.07743072509766 and batch: 1450, loss is 3.944491620063782 and perplexity is 51.65007357538104
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.4078838641826925 and perplexity of 82.09555421854152
Finished 34 epochs...
Completing Train Step...
At time: 377.3966248035431 and batch: 50, loss is 3.980610384941101 and perplexity is 53.54971019071946
At time: 377.75900077819824 and batch: 100, loss is 4.0245069313049315 and perplexity is 55.95271344760039
At time: 378.1093771457672 and batch: 150, loss is 3.8640474033355714 and perplexity is 47.65785209155442
At time: 378.4662582874298 and batch: 200, loss is 4.007270731925964 and perplexity is 54.99656517540134
At time: 378.8301131725311 and batch: 250, loss is 4.072593183517456 and perplexity is 58.70900859851302
At time: 379.1949346065521 and batch: 300, loss is 4.055314888954163 and perplexity is 57.70333027699756
At time: 379.5470564365387 and batch: 350, loss is 4.06642746925354 and perplexity is 58.34813927856777
At time: 379.8960225582123 and batch: 400, loss is 3.869512887001038 and perplexity is 47.91903840829707
At time: 380.26151967048645 and batch: 450, loss is 3.9646750831604005 and perplexity is 52.703142468897546
At time: 380.63490319252014 and batch: 500, loss is 3.951227374076843 and perplexity is 51.999150092707296
At time: 381.0118935108185 and batch: 550, loss is 4.0271494007110595 and perplexity is 56.10076230221228
At time: 381.3658916950226 and batch: 600, loss is 3.9458164978027344 and perplexity is 51.71854895881567
At time: 381.71514439582825 and batch: 650, loss is 4.02128948688507 and perplexity is 55.77297800139751
At time: 382.07158613204956 and batch: 700, loss is 4.079638080596924 and perplexity is 59.1240678298763
At time: 382.41930174827576 and batch: 750, loss is 4.027162103652954 and perplexity is 56.10147495146242
At time: 382.77057933807373 and batch: 800, loss is 3.9465152263641357 and perplexity is 51.75469881412486
At time: 383.12577390670776 and batch: 850, loss is 3.913528170585632 and perplexity is 50.075314924355325
At time: 383.4810812473297 and batch: 900, loss is 3.8338676261901856 and perplexity is 46.24103587203985
At time: 383.82283091545105 and batch: 950, loss is 3.9736885595321656 and perplexity is 53.18032831929906
At time: 384.1886396408081 and batch: 1000, loss is 3.9946405839920045 and perplexity is 54.30631855552695
At time: 384.5532052516937 and batch: 1050, loss is 3.920147385597229 and perplexity is 50.407873625158786
At time: 384.90287160873413 and batch: 1100, loss is 4.084708480834961 and perplexity is 59.42461181272661
At time: 385.2565977573395 and batch: 1150, loss is 4.017861042022705 and perplexity is 55.58209083155586
At time: 385.6038091182709 and batch: 1200, loss is 3.9450678300857542 and perplexity is 51.67984344143469
At time: 385.9793996810913 and batch: 1250, loss is 3.836126894950867 and perplexity is 46.34562490272419
At time: 386.3268013000488 and batch: 1300, loss is 3.9635597705841064 and perplexity is 52.64439475841173
At time: 386.67884254455566 and batch: 1350, loss is 3.96205105304718 and perplexity is 52.56502912203709
At time: 387.0518333911896 and batch: 1400, loss is 3.810151948928833 and perplexity is 45.15729994839464
At time: 387.4119725227356 and batch: 1450, loss is 3.933771138191223 and perplexity is 51.099317358717656
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.4055316631610575 and perplexity of 81.90267590525032
Finished 35 epochs...
Completing Train Step...
At time: 388.7884693145752 and batch: 50, loss is 3.9691271018981933 and perplexity is 52.93830092321966
At time: 389.1215395927429 and batch: 100, loss is 4.01351688861847 and perplexity is 55.34115740723434
At time: 389.51007652282715 and batch: 150, loss is 3.852392373085022 and perplexity is 47.10562275974435
At time: 389.8766493797302 and batch: 200, loss is 3.9966843843460085 and perplexity is 54.417423327927146
At time: 390.28740406036377 and batch: 250, loss is 4.062440338134766 and perplexity is 58.11596076739369
At time: 390.62160992622375 and batch: 300, loss is 4.044186263084412 and perplexity is 57.064731457241365
At time: 390.995525598526 and batch: 350, loss is 4.055391759872436 and perplexity is 57.707766155476236
At time: 391.37558364868164 and batch: 400, loss is 3.8580979013442995 and perplexity is 47.37515339773682
At time: 391.7448959350586 and batch: 450, loss is 3.9533279180526733 and perplexity is 52.10849139208293
At time: 392.0876696109772 and batch: 500, loss is 3.939996304512024 and perplexity is 51.41841128405517
At time: 392.421213388443 and batch: 550, loss is 4.016061668395996 and perplexity is 55.48216780958186
At time: 392.78252482414246 and batch: 600, loss is 3.9349824142456056 and perplexity is 51.161250239565064
At time: 393.1336681842804 and batch: 650, loss is 4.009625916481018 and perplexity is 55.126244886166084
At time: 393.5067925453186 and batch: 700, loss is 4.068530426025391 and perplexity is 58.47097200387605
At time: 393.86515736579895 and batch: 750, loss is 4.016322355270386 and perplexity is 55.49663316787513
At time: 394.2335774898529 and batch: 800, loss is 3.935608162879944 and perplexity is 51.19327434050728
At time: 394.6040930747986 and batch: 850, loss is 3.902964487075806 and perplexity is 49.54911932098201
At time: 394.99931478500366 and batch: 900, loss is 3.821827116012573 and perplexity is 45.68760866796567
At time: 395.3565411567688 and batch: 950, loss is 3.963361735343933 and perplexity is 52.63397034528663
At time: 395.7075731754303 and batch: 1000, loss is 3.9842591762542723 and perplexity is 53.7454588138462
At time: 396.0719106197357 and batch: 1050, loss is 3.9092909574508665 and perplexity is 49.86358403347044
At time: 396.4488682746887 and batch: 1100, loss is 4.074414181709289 and perplexity is 58.8160149966743
At time: 396.815233707428 and batch: 1150, loss is 4.007482657432556 and perplexity is 55.0082215854386
At time: 397.19322896003723 and batch: 1200, loss is 3.934653525352478 and perplexity is 51.144426639302026
At time: 397.5965509414673 and batch: 1250, loss is 3.824991879463196 and perplexity is 45.832428180902426
At time: 397.95079588890076 and batch: 1300, loss is 3.9520110177993772 and perplexity is 52.03991487069961
At time: 398.3020124435425 and batch: 1350, loss is 3.951330890655518 and perplexity is 52.00453314543168
At time: 398.6979296207428 and batch: 1400, loss is 3.7997215509414675 and perplexity is 44.688739223330636
At time: 399.06048941612244 and batch: 1450, loss is 3.923349289894104 and perplexity is 50.569533483899725
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.4031679854433765 and perplexity of 81.70931298902897
Finished 36 epochs...
Completing Train Step...
At time: 400.453001499176 and batch: 50, loss is 3.9579243946075437 and perplexity is 52.34855815903993
At time: 400.82482624053955 and batch: 100, loss is 4.002863683700562 and perplexity is 54.75472595042362
At time: 401.18839287757874 and batch: 150, loss is 3.840995736122131 and perplexity is 46.571824607726796
At time: 401.5380947589874 and batch: 200, loss is 3.9862168979644776 and perplexity is 53.85078052705462
At time: 401.88879132270813 and batch: 250, loss is 4.052556376457215 and perplexity is 57.544374261187514
At time: 402.22704815864563 and batch: 300, loss is 4.033384385108948 and perplexity is 56.45164240916692
At time: 402.5770299434662 and batch: 350, loss is 4.044699854850769 and perplexity is 57.094046960923464
At time: 402.9268054962158 and batch: 400, loss is 3.846981334686279 and perplexity is 46.851420794729975
At time: 403.30523777008057 and batch: 450, loss is 3.942224245071411 and perplexity is 51.53309615615459
At time: 403.6952335834503 and batch: 500, loss is 3.929184522628784 and perplexity is 50.865481102930204
At time: 404.0560426712036 and batch: 550, loss is 4.005337634086609 and perplexity is 54.8903541253392
At time: 404.4076626300812 and batch: 600, loss is 3.92452986240387 and perplexity is 50.62926973951499
At time: 404.77701926231384 and batch: 650, loss is 3.9982988262176513 and perplexity is 54.5053480502739
At time: 405.14233565330505 and batch: 700, loss is 4.057838344573975 and perplexity is 57.84912594715172
At time: 405.5101635456085 and batch: 750, loss is 4.005850467681885 and perplexity is 54.91851096226013
At time: 405.89270210266113 and batch: 800, loss is 3.9252484369277956 and perplexity is 50.66566371724138
At time: 406.2657780647278 and batch: 850, loss is 3.8924263048172 and perplexity is 49.02970332792102
At time: 406.6426250934601 and batch: 900, loss is 3.81069703578949 and perplexity is 45.1819213090397
At time: 407.0148756504059 and batch: 950, loss is 3.953267707824707 and perplexity is 52.105354022389065
At time: 407.36999344825745 and batch: 1000, loss is 3.974236168861389 and perplexity is 53.209458338425044
At time: 407.7372884750366 and batch: 1050, loss is 3.8987859153747557 and perplexity is 49.34250674653289
At time: 408.09576869010925 and batch: 1100, loss is 4.064347400665283 and perplexity is 58.22689728641556
At time: 408.4843702316284 and batch: 1150, loss is 3.997436728477478 and perplexity is 54.45837936160155
At time: 408.865473985672 and batch: 1200, loss is 3.9244959497451783 and perplexity is 50.62755279548375
At time: 409.2450873851776 and batch: 1250, loss is 3.8141671895980833 and perplexity is 45.338981879909106
At time: 409.5901050567627 and batch: 1300, loss is 3.9412812423706054 and perplexity is 51.48452321310617
At time: 409.9653465747833 and batch: 1350, loss is 3.9407237911224366 and perplexity is 51.45583109934998
At time: 410.33596873283386 and batch: 1400, loss is 3.7895755624771117 and perplexity is 44.23762018484789
At time: 410.69991517066956 and batch: 1450, loss is 3.9131760597229004 and perplexity is 50.05768596587178
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.401032276642629 and perplexity of 81.53499190597107
Finished 37 epochs...
Completing Train Step...
At time: 411.9668130874634 and batch: 50, loss is 3.947066216468811 and perplexity is 51.783222998591945
At time: 412.3159725666046 and batch: 100, loss is 3.992745518684387 and perplexity is 54.203501988073164
At time: 412.6688268184662 and batch: 150, loss is 3.83014196395874 and perplexity is 46.06907791868059
At time: 413.0240652561188 and batch: 200, loss is 3.9760179901123047 and perplexity is 53.304352599240865
At time: 413.3864336013794 and batch: 250, loss is 4.042972598075867 and perplexity is 56.995516000134955
At time: 413.71626567840576 and batch: 300, loss is 4.022895040512085 and perplexity is 55.86259643286438
At time: 414.0693416595459 and batch: 350, loss is 4.034288773536682 and perplexity is 56.50271971466893
At time: 414.42136120796204 and batch: 400, loss is 3.836348648071289 and perplexity is 46.355903329258744
At time: 414.7784514427185 and batch: 450, loss is 3.931388053894043 and perplexity is 50.97768836156192
At time: 415.10705947875977 and batch: 500, loss is 3.9187235689163207 and perplexity is 50.33615312438116
At time: 415.47571659088135 and batch: 550, loss is 3.9951543617248535 and perplexity is 54.334227101534616
At time: 415.83940625190735 and batch: 600, loss is 3.9141415119171143 and perplexity is 50.106037605467364
At time: 416.1787586212158 and batch: 650, loss is 3.987245826721191 and perplexity is 53.906217659249215
At time: 416.54083609580994 and batch: 700, loss is 4.047443804740905 and perplexity is 57.250925299527815
At time: 416.8976261615753 and batch: 750, loss is 3.995698618888855 and perplexity is 54.36380694267516
At time: 417.24422335624695 and batch: 800, loss is 3.9151016330718993 and perplexity is 50.15416857423809
At time: 417.59755849838257 and batch: 850, loss is 3.8832314586639405 and perplexity is 48.58094902393763
At time: 417.9492871761322 and batch: 900, loss is 3.800270199775696 and perplexity is 44.71326437524145
At time: 418.34559297561646 and batch: 950, loss is 3.9433269357681273 and perplexity is 51.58995256361364
At time: 418.69826436042786 and batch: 1000, loss is 3.9642874574661255 and perplexity is 52.68271733561655
At time: 419.0572507381439 and batch: 1050, loss is 3.8885286140441893 and perplexity is 48.83897265171959
At time: 419.4011142253876 and batch: 1100, loss is 4.054505915641784 and perplexity is 57.65666869929841
At time: 419.747474193573 and batch: 1150, loss is 3.9876318645477293 and perplexity is 53.92703151556073
At time: 420.11431670188904 and batch: 1200, loss is 3.914611358642578 and perplexity is 50.12958529463139
At time: 420.4927668571472 and batch: 1250, loss is 3.8035789012908934 and perplexity is 44.86145224034554
At time: 420.8504765033722 and batch: 1300, loss is 3.930176868438721 and perplexity is 50.91598230315608
At time: 421.233256816864 and batch: 1350, loss is 3.9307149410247804 and perplexity is 50.94338616939912
At time: 421.61721110343933 and batch: 1400, loss is 3.779764952659607 and perplexity is 43.805744101760595
At time: 422.016818523407 and batch: 1450, loss is 3.9033271169662473 and perplexity is 49.567090570952125
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.399281037159455 and perplexity of 81.39232956330893
Finished 38 epochs...
Completing Train Step...
At time: 423.321950674057 and batch: 50, loss is 3.936604132652283 and perplexity is 51.244286693461426
At time: 423.7117655277252 and batch: 100, loss is 3.9824727249145506 and perplexity is 53.64953087775133
At time: 424.08163619041443 and batch: 150, loss is 3.8196032190322877 and perplexity is 45.58611702831707
At time: 424.41958355903625 and batch: 200, loss is 3.9660480308532713 and perplexity is 52.77555082182375
At time: 424.75383162498474 and batch: 250, loss is 4.0336414194107055 and perplexity is 56.46615428260135
At time: 425.1085283756256 and batch: 300, loss is 4.012727570533753 and perplexity is 55.29749286573678
At time: 425.45137453079224 and batch: 350, loss is 4.024113984107971 and perplexity is 55.93073130488234
At time: 425.80041217803955 and batch: 400, loss is 3.82578293800354 and perplexity is 45.868698658783856
At time: 426.1501262187958 and batch: 450, loss is 3.920945153236389 and perplexity is 50.44810344038454
At time: 426.51277136802673 and batch: 500, loss is 3.908434042930603 and perplexity is 49.820873506528656
At time: 426.8842103481293 and batch: 550, loss is 3.9847629833221436 and perplexity is 53.77254297788636
At time: 427.23737931251526 and batch: 600, loss is 3.9039581394195557 and perplexity is 49.5983783886671
At time: 427.6165268421173 and batch: 650, loss is 3.976461801528931 and perplexity is 53.328014929898124
At time: 427.98966550827026 and batch: 700, loss is 4.037432289123535 and perplexity is 56.68061635873503
At time: 428.3556823730469 and batch: 750, loss is 3.9857434034347534 and perplexity is 53.82528851269463
At time: 428.7068614959717 and batch: 800, loss is 3.905157642364502 and perplexity is 49.65790748513456
At time: 429.05839920043945 and batch: 850, loss is 3.8727269411087035 and perplexity is 48.073300561185896
At time: 429.4148738384247 and batch: 900, loss is 3.7894923973083494 and perplexity is 44.23394130867887
At time: 429.78034687042236 and batch: 950, loss is 3.9338280057907102 and perplexity is 51.10222333685849
At time: 430.15606594085693 and batch: 1000, loss is 3.954756565093994 and perplexity is 52.18298923702976
At time: 430.5114850997925 and batch: 1050, loss is 3.878401255607605 and perplexity is 48.346858981827644
At time: 430.8605411052704 and batch: 1100, loss is 4.0451007747650145 and perplexity is 57.11694169050479
At time: 431.21529054641724 and batch: 1150, loss is 3.9781199169158934 and perplexity is 53.41651228114363
At time: 431.5846312046051 and batch: 1200, loss is 3.9049600553512573 and perplexity is 49.64809669678469
At time: 431.9278361797333 and batch: 1250, loss is 3.793405752182007 and perplexity is 44.40738356768889
At time: 432.32251620292664 and batch: 1300, loss is 3.919940252304077 and perplexity is 50.39743355757415
At time: 432.6752943992615 and batch: 1350, loss is 3.9207081985473633 and perplexity is 50.4361509418781
At time: 433.0199146270752 and batch: 1400, loss is 3.770190544128418 and perplexity is 43.38833144004791
At time: 433.3658685684204 and batch: 1450, loss is 3.893687539100647 and perplexity is 49.09158028313171
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.39769047142094 and perplexity of 81.26297261516417
Finished 39 epochs...
Completing Train Step...
At time: 434.70300793647766 and batch: 50, loss is 3.926374940872192 and perplexity is 50.722770946984966
At time: 435.0789155960083 and batch: 100, loss is 3.9726704788208007 and perplexity is 53.12621400385758
At time: 435.43351697921753 and batch: 150, loss is 3.8092977714538576 and perplexity is 45.11874406907408
At time: 435.7884089946747 and batch: 200, loss is 3.956348543167114 and perplexity is 52.26612957292164
At time: 436.15783643722534 and batch: 250, loss is 4.024528484344483 and perplexity is 55.953919411642374
At time: 436.50944662094116 and batch: 300, loss is 4.002898592948913 and perplexity is 54.75663743011421
At time: 436.9195365905762 and batch: 350, loss is 4.0142069339752195 and perplexity is 55.37935849466605
At time: 437.28120851516724 and batch: 400, loss is 3.8155289554595946 and perplexity is 45.400765015163465
At time: 437.6443214416504 and batch: 450, loss is 3.9105933237075807 and perplexity is 49.92856698937386
At time: 438.0093960762024 and batch: 500, loss is 3.898478932380676 and perplexity is 49.327361760821915
At time: 438.3700976371765 and batch: 550, loss is 3.974592056274414 and perplexity is 53.22839828494593
At time: 438.711403131485 and batch: 600, loss is 3.8941721963882445 and perplexity is 49.11537864183375
At time: 439.0508916378021 and batch: 650, loss is 3.9659249687194826 and perplexity is 52.76905654953544
At time: 439.4067225456238 and batch: 700, loss is 4.027701349258423 and perplexity is 56.13173558351343
At time: 439.7667889595032 and batch: 750, loss is 3.9760662603378294 and perplexity is 53.30692567446324
At time: 440.11070728302 and batch: 800, loss is 3.8956469297409058 and perplexity is 49.18786416411707
At time: 440.4741699695587 and batch: 850, loss is 3.8640168142318725 and perplexity is 47.65639430287106
At time: 440.83827018737793 and batch: 900, loss is 3.779655041694641 and perplexity is 43.800929634741536
At time: 441.2095708847046 and batch: 950, loss is 3.9244707679748534 and perplexity is 50.62627792012901
At time: 441.57187151908875 and batch: 1000, loss is 3.945337510108948 and perplexity is 51.69378234224969
At time: 441.9398286342621 and batch: 1050, loss is 3.8686941385269167 and perplexity is 47.87982082557772
At time: 442.2892715930939 and batch: 1100, loss is 4.0357812929153445 and perplexity is 56.58711408323897
At time: 442.6518247127533 and batch: 1150, loss is 3.968835916519165 and perplexity is 52.922888308073205
At time: 443.0154812335968 and batch: 1200, loss is 3.8955821561813355 and perplexity is 49.18467819425192
At time: 443.399094581604 and batch: 1250, loss is 3.7832909345626833 and perplexity is 43.96047499156461
At time: 443.77663373947144 and batch: 1300, loss is 3.910053734779358 and perplexity is 49.90163335462341
At time: 444.14691948890686 and batch: 1350, loss is 3.9111445331573487 and perplexity is 49.956095673650225
At time: 444.4905421733856 and batch: 1400, loss is 3.7608385848999024 and perplexity is 42.984456985681064
At time: 444.84345722198486 and batch: 1450, loss is 3.8842328119277956 and perplexity is 48.62962008019754
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.396649743756678 and perplexity of 81.17844398475489
Finished 40 epochs...
Completing Train Step...
At time: 446.18760418891907 and batch: 50, loss is 3.9164499711990355 and perplexity is 50.22183896299202
At time: 446.53949904441833 and batch: 100, loss is 3.9630323171615602 and perplexity is 52.61663461395373
At time: 446.8958206176758 and batch: 150, loss is 3.799402942657471 and perplexity is 44.67450328877649
At time: 447.2433285713196 and batch: 200, loss is 3.9467046546936033 and perplexity is 51.764503548881265
At time: 447.60713148117065 and batch: 250, loss is 4.015707201957703 and perplexity is 55.46250472832669
At time: 447.96234703063965 and batch: 300, loss is 3.99335422039032 and perplexity is 54.23650579591885
At time: 448.3141987323761 and batch: 350, loss is 4.004490633010864 and perplexity is 54.843881620256234
At time: 448.67022466659546 and batch: 400, loss is 3.8056147956848143 and perplexity is 44.95287845494458
At time: 449.05029582977295 and batch: 450, loss is 3.900577354431152 and perplexity is 49.4309800638761
At time: 449.4185326099396 and batch: 500, loss is 3.8887875413894655 and perplexity is 48.851620034560284
At time: 449.7875289916992 and batch: 550, loss is 3.964634380340576 and perplexity is 52.70099734604203
At time: 450.13864946365356 and batch: 600, loss is 3.8845387935638427 and perplexity is 48.64450212761052
At time: 450.4985291957855 and batch: 650, loss is 3.955660648345947 and perplexity is 52.230188336378504
At time: 450.85751080513 and batch: 700, loss is 4.018160729408264 and perplexity is 55.59875057927451
At time: 451.2105312347412 and batch: 750, loss is 3.966774654388428 and perplexity is 52.813912714771014
At time: 451.55666875839233 and batch: 800, loss is 3.886197290420532 and perplexity is 48.72524581955616
At time: 451.90514850616455 and batch: 850, loss is 3.854182062149048 and perplexity is 47.19000266202345
At time: 452.2525131702423 and batch: 900, loss is 3.76927743434906 and perplexity is 43.34873121272885
At time: 452.5961503982544 and batch: 950, loss is 3.915337243080139 and perplexity is 50.165986790499474
At time: 452.96812677383423 and batch: 1000, loss is 3.9361986398696898 and perplexity is 51.22351171739418
At time: 453.34464836120605 and batch: 1050, loss is 3.859007339477539 and perplexity is 47.4182577662121
At time: 453.6992566585541 and batch: 1100, loss is 4.0267347240447995 and perplexity is 56.077503447911525
At time: 454.0569906234741 and batch: 1150, loss is 3.959745764732361 and perplexity is 52.4439911419577
At time: 454.411808013916 and batch: 1200, loss is 3.8864356899261474 and perplexity is 48.73686327881377
At time: 454.76449608802795 and batch: 1250, loss is 3.774092082977295 and perplexity is 43.557943359342644
At time: 455.10626697540283 and batch: 1300, loss is 3.900044741630554 and perplexity is 49.404659501104504
At time: 455.47072744369507 and batch: 1350, loss is 3.901696968078613 and perplexity is 49.4863546570536
At time: 455.84477734565735 and batch: 1400, loss is 3.751845569610596 and perplexity is 42.5996300774887
At time: 456.184424161911 and batch: 1450, loss is 3.875132260322571 and perplexity is 48.18907137176069
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.395559457632212 and perplexity of 81.0899844855177
Finished 41 epochs...
Completing Train Step...
At time: 457.446364402771 and batch: 50, loss is 3.9067506408691406 and perplexity is 49.737075498023245
At time: 457.82718896865845 and batch: 100, loss is 3.953701457977295 and perplexity is 52.127959629885346
At time: 458.19439244270325 and batch: 150, loss is 3.7897715044021605 and perplexity is 44.246289038574695
At time: 458.56828022003174 and batch: 200, loss is 3.9373923635482786 and perplexity is 51.28469494690122
At time: 458.9228286743164 and batch: 250, loss is 4.007157006263733 and perplexity is 54.990311010242586
At time: 459.28714513778687 and batch: 300, loss is 3.9840796995162964 and perplexity is 53.73581361978715
At time: 459.6528367996216 and batch: 350, loss is 3.9950401067733763 and perplexity is 54.32801950168484
At time: 460.01928663253784 and batch: 400, loss is 3.7959729719161985 and perplexity is 44.52153354046584
At time: 460.36323642730713 and batch: 450, loss is 3.89075713634491 and perplexity is 48.94793275633559
At time: 460.725031375885 and batch: 500, loss is 3.8793033742904663 and perplexity is 48.390493265264766
At time: 461.094051361084 and batch: 550, loss is 3.9551594257354736 and perplexity is 52.2040159446802
At time: 461.48686146736145 and batch: 600, loss is 3.8752440118789675 and perplexity is 48.19445687640145
At time: 461.8630566596985 and batch: 650, loss is 3.945664029121399 and perplexity is 51.71066410096755
At time: 462.22438311576843 and batch: 700, loss is 4.008927130699158 and perplexity is 55.087736906013774
At time: 462.57842087745667 and batch: 750, loss is 3.957787208557129 and perplexity is 52.34137715967893
At time: 462.92474699020386 and batch: 800, loss is 3.876983070373535 and perplexity is 48.278342776125164
At time: 463.3007698059082 and batch: 850, loss is 3.8448072195053102 and perplexity is 46.749671057433474
At time: 463.6384723186493 and batch: 900, loss is 3.7599361753463745 and perplexity is 42.94568489782637
At time: 463.98566603660583 and batch: 950, loss is 3.9064775705337524 and perplexity is 49.7234956323494
At time: 464.33875370025635 and batch: 1000, loss is 3.927348780632019 and perplexity is 50.77219085769303
At time: 464.74483370780945 and batch: 1050, loss is 3.849696092605591 and perplexity is 46.97878386209016
At time: 465.09322452545166 and batch: 1100, loss is 4.01789388179779 and perplexity is 55.583916164889125
At time: 465.45447397232056 and batch: 1150, loss is 3.9508769035339357 and perplexity is 51.980929115487974
At time: 465.8322832584381 and batch: 1200, loss is 3.877544116973877 and perplexity is 48.30543677599741
At time: 466.18850922584534 and batch: 1250, loss is 3.7647267532348634 and perplexity is 43.151913128098776
At time: 466.5471239089966 and batch: 1300, loss is 3.8901888036727907 and perplexity is 48.920121950560834
At time: 466.9223916530609 and batch: 1350, loss is 3.8923619318008424 and perplexity is 49.02654723961125
At time: 467.30185294151306 and batch: 1400, loss is 3.7431041622161865 and perplexity is 42.228872189866344
At time: 467.63865852355957 and batch: 1450, loss is 3.866141924858093 and perplexity is 47.75777709948612
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.395185943342682 and perplexity of 81.05970187342085
Finished 42 epochs...
Completing Train Step...
At time: 468.94049620628357 and batch: 50, loss is 3.897256302833557 and perplexity is 49.26708952366873
At time: 469.3147873878479 and batch: 100, loss is 3.944674277305603 and perplexity is 51.65950869703059
At time: 469.6716492176056 and batch: 150, loss is 3.7803838205337525 and perplexity is 43.832862459963046
At time: 470.03660583496094 and batch: 200, loss is 3.9282111072540284 and perplexity is 50.815991952238086
At time: 470.4042661190033 and batch: 250, loss is 3.9986943197250366 and perplexity is 54.526908824837705
At time: 470.76543283462524 and batch: 300, loss is 3.9751279401779174 and perplexity is 53.25693017100255
At time: 471.1170346736908 and batch: 350, loss is 3.9857586574554444 and perplexity is 53.826109571021505
At time: 471.4792799949646 and batch: 400, loss is 3.78663800239563 and perplexity is 44.107860199880164
At time: 471.84469771385193 and batch: 450, loss is 3.8813224601745606 and perplexity is 48.48829653051088
At time: 472.1993923187256 and batch: 500, loss is 3.870050411224365 and perplexity is 47.94480297611939
At time: 472.54228234291077 and batch: 550, loss is 3.9458167219161986 and perplexity is 51.71856054964014
At time: 472.8832221031189 and batch: 600, loss is 3.866120958328247 and perplexity is 47.756775795124156
At time: 473.2169740200043 and batch: 650, loss is 3.935864472389221 and perplexity is 51.206397345235395
At time: 473.5588583946228 and batch: 700, loss is 3.9998401594161987 and perplexity is 54.589423730395715
At time: 473.94610261917114 and batch: 750, loss is 3.9489927911758422 and perplexity is 51.88308340965312
At time: 474.32328939437866 and batch: 800, loss is 3.8680603981018065 and perplexity is 47.84948706045535
At time: 474.67770409584045 and batch: 850, loss is 3.8356139135360716 and perplexity is 46.321856555373465
At time: 475.03901076316833 and batch: 900, loss is 3.7507082128524782 and perplexity is 42.551206642907005
At time: 475.3868374824524 and batch: 950, loss is 3.897795753479004 and perplexity is 49.2936738567347
At time: 475.7622218132019 and batch: 1000, loss is 3.9186554861068728 and perplexity is 50.332726214317816
At time: 476.1138904094696 and batch: 1050, loss is 3.8405058431625365 and perplexity is 46.54901498632864
At time: 476.46654748916626 and batch: 1100, loss is 4.0091405820846555 and perplexity is 55.099496714809376
At time: 476.8191201686859 and batch: 1150, loss is 3.942262315750122 and perplexity is 51.53505809344723
At time: 477.17249631881714 and batch: 1200, loss is 3.8688490533828737 and perplexity is 47.88723869567846
At time: 477.52910828590393 and batch: 1250, loss is 3.755670356750488 and perplexity is 42.762876587337985
At time: 477.8964579105377 and batch: 1300, loss is 3.8814055156707763 and perplexity is 48.492323917285866
At time: 478.2484440803528 and batch: 1350, loss is 3.8834469985961912 and perplexity is 48.59142128695381
At time: 478.59979271888733 and batch: 1400, loss is 3.7345178270339967 and perplexity is 41.86783315808406
At time: 478.9455692768097 and batch: 1450, loss is 3.8573875999450684 and perplexity is 47.34151470820804
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.394397181323451 and perplexity of 80.99579026812987
Finished 43 epochs...
Completing Train Step...
At time: 480.2148461341858 and batch: 50, loss is 3.888110795021057 and perplexity is 48.81857106225836
At time: 480.5973889827728 and batch: 100, loss is 3.9357688760757448 and perplexity is 51.20150243639414
At time: 480.94903445243835 and batch: 150, loss is 3.771481976509094 and perplexity is 43.44440073327083
At time: 481.31244707107544 and batch: 200, loss is 3.9192020654678346 and perplexity is 50.36024456344325
At time: 481.67881178855896 and batch: 250, loss is 3.990582208633423 and perplexity is 54.086369749779784
At time: 482.03622698783875 and batch: 300, loss is 3.9663957452774046 and perplexity is 52.79390483287835
At time: 482.3922348022461 and batch: 350, loss is 3.9766594982147216 and perplexity is 53.338558743913765
At time: 482.75240302085876 and batch: 400, loss is 3.7774386262893676 and perplexity is 43.70395608606591
At time: 483.122266292572 and batch: 450, loss is 3.8721406269073486 and perplexity is 48.04512276368949
At time: 483.47283577919006 and batch: 500, loss is 3.861231460571289 and perplexity is 47.52383908283213
At time: 483.8107497692108 and batch: 550, loss is 3.9367277145385744 and perplexity is 51.25061995040252
At time: 484.1280815601349 and batch: 600, loss is 3.857328872680664 and perplexity is 47.33873455219275
At time: 484.4870054721832 and batch: 650, loss is 3.9262684202194214 and perplexity is 50.71736821206988
At time: 484.8364541530609 and batch: 700, loss is 3.991098256111145 and perplexity is 54.114288087442624
At time: 485.1823673248291 and batch: 750, loss is 3.940216188430786 and perplexity is 51.429718608928724
At time: 485.52091693878174 and batch: 800, loss is 3.859333634376526 and perplexity is 47.43373262638673
At time: 485.85705494880676 and batch: 850, loss is 3.826865301132202 and perplexity is 45.9183721244863
At time: 486.1978211402893 and batch: 900, loss is 3.74174485206604 and perplexity is 42.17150905125031
At time: 486.5332992076874 and batch: 950, loss is 3.889362082481384 and perplexity is 48.879695362119314
At time: 486.8996648788452 and batch: 1000, loss is 3.910251622200012 and perplexity is 49.911509237258635
At time: 487.2634255886078 and batch: 1050, loss is 3.8314923906326293 and perplexity is 46.13133285624664
At time: 487.60165524482727 and batch: 1100, loss is 4.000565376281738 and perplexity is 54.62902726000312
At time: 487.9569959640503 and batch: 1150, loss is 3.9337654542922973 and perplexity is 51.09902691618804
At time: 488.30547285079956 and batch: 1200, loss is 3.8603058671951294 and perplexity is 47.47987168327327
At time: 488.6746258735657 and batch: 1250, loss is 3.7469455337524415 and perplexity is 42.39140094431225
At time: 489.0438964366913 and batch: 1300, loss is 3.872177858352661 and perplexity is 48.04691158635023
At time: 489.39003229141235 and batch: 1350, loss is 3.8746546363830565 and perplexity is 48.16606061333256
At time: 489.75454020500183 and batch: 1400, loss is 3.7261592626571653 and perplexity is 41.51933667345531
At time: 490.10619616508484 and batch: 1450, loss is 3.8487418842315675 and perplexity is 46.93397769373776
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.394304846087072 and perplexity of 80.98831184795596
Finished 44 epochs...
Completing Train Step...
At time: 491.32297253608704 and batch: 50, loss is 3.879041452407837 and perplexity is 48.377820395890716
At time: 491.6695909500122 and batch: 100, loss is 3.9271015453338625 and perplexity is 50.759639731552916
At time: 492.0250825881958 and batch: 150, loss is 3.762515888214111 and perplexity is 43.05661545674672
At time: 492.36514139175415 and batch: 200, loss is 3.91055766582489 and perplexity is 49.926786674130575
At time: 492.718941450119 and batch: 250, loss is 3.9825440406799317 and perplexity is 53.65335707154056
At time: 493.0659828186035 and batch: 300, loss is 3.9579031229019166 and perplexity is 52.34744462776416
At time: 493.40275740623474 and batch: 350, loss is 3.967761549949646 and perplexity is 52.8660602586571
At time: 493.7418031692505 and batch: 400, loss is 3.768705492019653 and perplexity is 43.32394532714644
At time: 494.09718227386475 and batch: 450, loss is 3.863098268508911 and perplexity is 47.612639824033494
At time: 494.47148180007935 and batch: 500, loss is 3.852901759147644 and perplexity is 47.12962381983307
At time: 494.8372554779053 and batch: 550, loss is 3.9277799987792967 and perplexity is 50.79408946896788
At time: 495.19794034957886 and batch: 600, loss is 3.8486486673355103 and perplexity is 46.929602857925005
At time: 495.572594165802 and batch: 650, loss is 3.9170275592803954 and perplexity is 50.250854877417524
At time: 495.92159152030945 and batch: 700, loss is 3.982559576034546 and perplexity is 53.65419060194349
At time: 496.2741050720215 and batch: 750, loss is 3.931856894493103 and perplexity is 51.001594375129
At time: 496.6062066555023 and batch: 800, loss is 3.8510802173614502 and perplexity is 47.043853381611896
At time: 496.9687490463257 and batch: 850, loss is 3.818213171958923 and perplexity is 45.522794200807525
At time: 497.3282198905945 and batch: 900, loss is 3.7328202724456787 and perplexity is 41.79682051677421
At time: 497.6856391429901 and batch: 950, loss is 3.881033630371094 and perplexity is 48.47429368767006
At time: 498.0398471355438 and batch: 1000, loss is 3.9019725799560545 and perplexity is 49.49999556387999
At time: 498.3645842075348 and batch: 1050, loss is 3.822894368171692 and perplexity is 45.73639489593437
At time: 498.7155876159668 and batch: 1100, loss is 3.9921285629272463 and perplexity is 54.17007113920217
At time: 499.0953106880188 and batch: 1150, loss is 3.925595006942749 and perplexity is 50.6832259601711
At time: 499.44974088668823 and batch: 1200, loss is 3.8520601081848143 and perplexity is 47.08997381464042
At time: 499.77409863471985 and batch: 1250, loss is 3.7384181451797485 and perplexity is 42.03144989872708
At time: 500.12192130088806 and batch: 1300, loss is 3.863449840545654 and perplexity is 47.62938203966612
At time: 500.4634618759155 and batch: 1350, loss is 3.8660555505752563 and perplexity is 47.753652233882995
At time: 500.81041383743286 and batch: 1400, loss is 3.717935676574707 and perplexity is 41.17929891544113
At time: 501.18016505241394 and batch: 1450, loss is 3.8403295612335206 and perplexity is 46.5408099593933
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.393827519865117 and perplexity of 80.94966322777276
Finished 45 epochs...
Completing Train Step...
At time: 502.4376974105835 and batch: 50, loss is 3.870249843597412 and perplexity is 47.9543656754764
At time: 502.79310274124146 and batch: 100, loss is 3.918599495887756 and perplexity is 50.329908152841014
At time: 503.1190330982208 and batch: 150, loss is 3.7539076042175292 and perplexity is 42.687562617764264
At time: 503.45607233047485 and batch: 200, loss is 3.90196008682251 and perplexity is 49.499377157687874
At time: 503.7995173931122 and batch: 250, loss is 3.9746425104141236 and perplexity is 53.23108394574031
At time: 504.15513730049133 and batch: 300, loss is 3.9496716165542605 and perplexity is 51.91831492005097
At time: 504.478031873703 and batch: 350, loss is 3.9590856885910033 and perplexity is 52.409385537070875
At time: 504.8251292705536 and batch: 400, loss is 3.760149750709534 and perplexity is 42.95485801761588
At time: 505.17683577537537 and batch: 450, loss is 3.8544633769989014 and perplexity is 47.20327977797428
At time: 505.4962069988251 and batch: 500, loss is 3.8446206188201906 and perplexity is 46.74094835064188
At time: 505.843474149704 and batch: 550, loss is 3.9189057683944704 and perplexity is 50.34532518075906
At time: 506.1987609863281 and batch: 600, loss is 3.8401662921905517 and perplexity is 46.533211906172546
At time: 506.5478341579437 and batch: 650, loss is 3.9078788232803343 and perplexity is 49.79321965625523
At time: 506.8916666507721 and batch: 700, loss is 3.974219379425049 and perplexity is 53.208564989111004
At time: 507.2399711608887 and batch: 750, loss is 3.923581862449646 and perplexity is 50.58129593729355
At time: 507.6059808731079 and batch: 800, loss is 3.842592353820801 and perplexity is 46.646241398929256
At time: 507.9615709781647 and batch: 850, loss is 3.8098339223861695 and perplexity is 45.14294101179853
At time: 508.31508684158325 and batch: 900, loss is 3.7238102340698243 and perplexity is 41.42192102554725
At time: 508.6546046733856 and batch: 950, loss is 3.872917504310608 and perplexity is 48.082462436197346
At time: 508.9890887737274 and batch: 1000, loss is 3.8939639806747435 and perplexity is 49.10515311282082
At time: 509.3344132900238 and batch: 1050, loss is 3.814309067726135 and perplexity is 45.34541494613091
At time: 509.70450806617737 and batch: 1100, loss is 3.9838877010345457 and perplexity is 53.72549741553598
At time: 510.0821237564087 and batch: 1150, loss is 3.9174834299087524 and perplexity is 50.27376798851634
At time: 510.42569518089294 and batch: 1200, loss is 3.8438740587234497 and perplexity is 46.70606644605862
At time: 510.77865386009216 and batch: 1250, loss is 3.730072703361511 and perplexity is 41.68213848545354
At time: 511.1282250881195 and batch: 1300, loss is 3.8544964933395387 and perplexity is 47.204843003750625
At time: 511.48320508003235 and batch: 1350, loss is 3.857861890792847 and perplexity is 47.36397368097571
At time: 511.8360855579376 and batch: 1400, loss is 3.710042190551758 and perplexity is 40.85553020799033
At time: 512.1871809959412 and batch: 1450, loss is 3.8320641899108887 and perplexity is 46.15771826193805
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.393952198517629 and perplexity of 80.95975655190323
Annealing...
Finished 46 epochs...
Completing Train Step...
At time: 513.3758316040039 and batch: 50, loss is 3.8721837282180784 and perplexity is 48.04719361608269
At time: 513.7619264125824 and batch: 100, loss is 3.9178313541412355 and perplexity is 50.29126249386247
At time: 514.1249063014984 and batch: 150, loss is 3.754148931503296 and perplexity is 42.69786553452428
At time: 514.461677312851 and batch: 200, loss is 3.902572999000549 and perplexity is 49.52972522815411
At time: 514.8040909767151 and batch: 250, loss is 3.9710931062698362 and perplexity is 53.04248022919163
At time: 515.1437289714813 and batch: 300, loss is 3.9476669311523436 and perplexity is 51.81433928607753
At time: 515.4808428287506 and batch: 350, loss is 3.950621552467346 and perplexity is 51.96765742433837
At time: 515.8289160728455 and batch: 400, loss is 3.7508093881607056 and perplexity is 42.555511992148396
At time: 516.1793620586395 and batch: 450, loss is 3.8444092416763307 and perplexity is 46.73106942660438
At time: 516.52756690979 and batch: 500, loss is 3.8307197666168213 and perplexity is 46.09570444605571
At time: 516.8566098213196 and batch: 550, loss is 3.90453471660614 and perplexity is 49.626983927995816
At time: 517.213630437851 and batch: 600, loss is 3.825029215812683 and perplexity is 45.834139428404505
At time: 517.5740733146667 and batch: 650, loss is 3.8906779193878176 and perplexity is 48.944055403624745
At time: 517.9327988624573 and batch: 700, loss is 3.961250691413879 and perplexity is 52.52297492100389
At time: 518.2863645553589 and batch: 750, loss is 3.908444128036499 and perplexity is 49.821375957847444
At time: 518.6340658664703 and batch: 800, loss is 3.8234865951538084 and perplexity is 45.76348924526693
At time: 519.0121388435364 and batch: 850, loss is 3.788953356742859 and perplexity is 44.210103845199065
At time: 519.3593118190765 and batch: 900, loss is 3.698731918334961 and perplexity is 40.39604638152822
At time: 519.7081639766693 and batch: 950, loss is 3.849104709625244 and perplexity is 46.951009622292545
At time: 520.0564725399017 and batch: 1000, loss is 3.8706374549865723 and perplexity is 47.97295693663168
At time: 520.4087359905243 and batch: 1050, loss is 3.7883660221099853 and perplexity is 44.18414534399745
At time: 520.7425734996796 and batch: 1100, loss is 3.955146589279175 and perplexity is 52.203345834411834
At time: 521.0900974273682 and batch: 1150, loss is 3.888756103515625 and perplexity is 48.85008426763348
At time: 521.4241673946381 and batch: 1200, loss is 3.8143823766708373 and perplexity is 45.348739292498365
At time: 521.7647769451141 and batch: 1250, loss is 3.699784531593323 and perplexity is 40.438590182691215
At time: 522.0887885093689 and batch: 1300, loss is 3.8221622800827024 and perplexity is 45.70292407928572
At time: 522.4302871227264 and batch: 1350, loss is 3.821363887786865 and perplexity is 45.66644977914119
At time: 522.7867414951324 and batch: 1400, loss is 3.673781228065491 and perplexity is 39.400607228086365
At time: 523.1401708126068 and batch: 1450, loss is 3.794061818122864 and perplexity is 44.43652729862951
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.372563288762019 and perplexity of 79.2465032505127
Finished 47 epochs...
Completing Train Step...
At time: 524.3421132564545 and batch: 50, loss is 3.857611975669861 and perplexity is 47.352138186664234
At time: 524.7024705410004 and batch: 100, loss is 3.9031752586364745 and perplexity is 49.55956396686955
At time: 525.0584528446198 and batch: 150, loss is 3.7396126985549927 and perplexity is 42.081688709566485
At time: 525.4068412780762 and batch: 200, loss is 3.8907948684692384 and perplexity is 48.94977970066432
At time: 525.7515113353729 and batch: 250, loss is 3.9597795486450194 and perplexity is 52.44576293510279
At time: 526.1125745773315 and batch: 300, loss is 3.937759504318237 and perplexity is 51.303527106106294
At time: 526.4456980228424 and batch: 350, loss is 3.9407695007324217 and perplexity is 51.458183179076904
At time: 526.7720718383789 and batch: 400, loss is 3.740692014694214 and perplexity is 42.127132675147585
At time: 527.1165418624878 and batch: 450, loss is 3.834747524261475 and perplexity is 46.28174117595103
At time: 527.4625160694122 and batch: 500, loss is 3.822407088279724 and perplexity is 45.71411389935214
At time: 527.827693939209 and batch: 550, loss is 3.8957349920272826 and perplexity is 49.19219595062807
At time: 528.1714873313904 and batch: 600, loss is 3.816954188346863 and perplexity is 45.4655178115167
At time: 528.5117795467377 and batch: 650, loss is 3.8830447816848754 and perplexity is 48.57188092556267
At time: 528.8644313812256 and batch: 700, loss is 3.9544251680374147 and perplexity is 52.165698813149135
At time: 529.2178926467896 and batch: 750, loss is 3.901945881843567 and perplexity is 49.49867402507167
At time: 529.5417158603668 and batch: 800, loss is 3.817609329223633 and perplexity is 45.495313889967285
At time: 529.8860585689545 and batch: 850, loss is 3.7834252595901487 and perplexity is 43.96638038018711
At time: 530.2312338352203 and batch: 900, loss is 3.693709235191345 and perplexity is 40.193658530797684
At time: 530.5557866096497 and batch: 950, loss is 3.8448443603515625 and perplexity is 46.751407412023205
At time: 530.9073462486267 and batch: 1000, loss is 3.866973886489868 and perplexity is 47.7975262702515
At time: 531.2553431987762 and batch: 1050, loss is 3.784964909553528 and perplexity is 44.034125354520434
At time: 531.5913174152374 and batch: 1100, loss is 3.9523751163482665 and perplexity is 52.05886597801434
At time: 531.9355237483978 and batch: 1150, loss is 3.8867533111572268 and perplexity is 48.752345599954126
At time: 532.2825427055359 and batch: 1200, loss is 3.812665843963623 and perplexity is 45.27096346974076
At time: 532.6483256816864 and batch: 1250, loss is 3.6981991291046143 and perplexity is 40.374529535548454
At time: 533.0024065971375 and batch: 1300, loss is 3.8209011793136596 and perplexity is 45.64532441370687
At time: 533.3491022586823 and batch: 1350, loss is 3.820694718360901 and perplexity is 45.635901409314144
At time: 533.6951072216034 and batch: 1400, loss is 3.6738074350357057 and perplexity is 39.40163981215683
At time: 534.0521454811096 and batch: 1450, loss is 3.7945461320877074 and perplexity is 44.45805374170711
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.371593247112046 and perplexity of 79.16966811441112
Finished 48 epochs...
Completing Train Step...
At time: 535.2672312259674 and batch: 50, loss is 3.851626353263855 and perplexity is 47.06955273596234
At time: 535.6001524925232 and batch: 100, loss is 3.897406129837036 and perplexity is 49.27447161706685
At time: 535.9430749416351 and batch: 150, loss is 3.733678116798401 and perplexity is 41.832691066690856
At time: 536.2869439125061 and batch: 200, loss is 3.885197868347168 and perplexity is 48.67657305972066
At time: 536.6380615234375 and batch: 250, loss is 3.9543880462646483 and perplexity is 52.16376236587399
At time: 536.989776134491 and batch: 300, loss is 3.932744426727295 and perplexity is 51.0468800273975
At time: 537.3249123096466 and batch: 350, loss is 3.9355246019363403 and perplexity is 51.18899676091901
At time: 537.6429603099823 and batch: 400, loss is 3.7354983997344973 and perplexity is 41.90890774732726
At time: 537.9986038208008 and batch: 450, loss is 3.8296806049346923 and perplexity is 46.047828436050445
At time: 538.3428726196289 and batch: 500, loss is 3.817719202041626 and perplexity is 45.50031286293045
At time: 538.6981456279755 and batch: 550, loss is 3.8908374881744385 and perplexity is 48.95186597030256
At time: 539.0193119049072 and batch: 600, loss is 3.8123545169830324 and perplexity is 45.256871591080134
At time: 539.3746638298035 and batch: 650, loss is 3.8784818124771117 and perplexity is 48.350753810313186
At time: 539.7275502681732 and batch: 700, loss is 3.950196475982666 and perplexity is 51.94557188955669
At time: 540.0861382484436 and batch: 750, loss is 3.8980314683914186 and perplexity is 49.30529448027376
At time: 540.431022644043 and batch: 800, loss is 3.813756012916565 and perplexity is 45.32034337991718
At time: 540.7838377952576 and batch: 850, loss is 3.7797870874404906 and perplexity is 43.8067137430391
At time: 541.1447229385376 and batch: 900, loss is 3.6901193952560423 and perplexity is 40.04962840747791
At time: 541.482358455658 and batch: 950, loss is 3.841681513786316 and perplexity is 46.60377347848198
At time: 541.838395357132 and batch: 1000, loss is 3.8640768909454346 and perplexity is 47.65925742842372
At time: 542.1812093257904 and batch: 1050, loss is 3.7821785259246825 and perplexity is 43.91160016888087
At time: 542.5346448421478 and batch: 1100, loss is 3.9498491621017457 and perplexity is 51.92753360404189
At time: 542.872659444809 and batch: 1150, loss is 3.8846375370025634 and perplexity is 48.649305690181706
At time: 543.2145884037018 and batch: 1200, loss is 3.810728030204773 and perplexity is 45.183321717974366
At time: 543.5512588024139 and batch: 1250, loss is 3.696005859375 and perplexity is 40.28607434058047
At time: 543.9023041725159 and batch: 1300, loss is 3.818921904563904 and perplexity is 45.555069125122074
At time: 544.2456295490265 and batch: 1350, loss is 3.818955273628235 and perplexity is 45.556589280517265
At time: 544.5860369205475 and batch: 1400, loss is 3.6725079822540283 and perplexity is 39.35047249365744
At time: 544.9296183586121 and batch: 1450, loss is 3.7934374809265137 and perplexity is 44.40879258056931
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.371067927433894 and perplexity of 79.12808965178633
Finished 49 epochs...
Completing Train Step...
At time: 546.1092247962952 and batch: 50, loss is 3.8469177055358887 and perplexity is 46.848439773471156
At time: 546.4793972969055 and batch: 100, loss is 3.8928705263137817 and perplexity is 49.05148821440952
At time: 546.850997209549 and batch: 150, loss is 3.7290548038482667 and perplexity is 41.639731843489855
At time: 547.1979126930237 and batch: 200, loss is 3.8808048391342163 and perplexity is 48.46320446266761
At time: 547.548261642456 and batch: 250, loss is 3.95008460521698 and perplexity is 51.93976102369446
At time: 547.8896956443787 and batch: 300, loss is 3.928824601173401 and perplexity is 50.8471768191927
At time: 548.2241020202637 and batch: 350, loss is 3.9313113689422607 and perplexity is 50.97377928987334
At time: 548.5582811832428 and batch: 400, loss is 3.7312487316131593 and perplexity is 41.731186693287626
At time: 548.8945889472961 and batch: 450, loss is 3.8255778837203978 and perplexity is 45.85929404992233
At time: 549.2363040447235 and batch: 500, loss is 3.81392617225647 and perplexity is 45.32805571577536
At time: 549.594889163971 and batch: 550, loss is 3.8867731380462645 and perplexity is 48.75331221688313
At time: 549.9528617858887 and batch: 600, loss is 3.808550534248352 and perplexity is 45.0850422580317
At time: 550.309713602066 and batch: 650, loss is 3.8746514654159547 and perplexity is 48.165907880581095
At time: 550.6671316623688 and batch: 700, loss is 3.946599826812744 and perplexity is 51.75907747007764
At time: 551.029730796814 and batch: 750, loss is 3.8947339963912966 and perplexity is 49.14297941403565
At time: 551.3662281036377 and batch: 800, loss is 3.8104234552383422 and perplexity is 45.16956210480211
At time: 551.7297649383545 and batch: 850, loss is 3.7765881490707396 and perplexity is 43.666802668357924
At time: 552.0705616474152 and batch: 900, loss is 3.686882643699646 and perplexity is 39.920207275412906
At time: 552.3979334831238 and batch: 950, loss is 3.8387745428085327 and perplexity is 46.46849438299152
At time: 552.7230908870697 and batch: 1000, loss is 3.8614272451400757 and perplexity is 47.533144428065825
At time: 553.0733518600464 and batch: 1050, loss is 3.779391198158264 and perplexity is 43.7893745670021
At time: 553.4094543457031 and batch: 1100, loss is 3.947300839424133 and perplexity is 51.795373956799104
At time: 553.7647707462311 and batch: 1150, loss is 3.8824636936187744 and perplexity is 48.54366458409236
At time: 554.0910422801971 and batch: 1200, loss is 3.8086648988723755 and perplexity is 45.09019868678951
At time: 554.4529211521149 and batch: 1250, loss is 3.693590087890625 and perplexity is 40.18886985016252
At time: 554.8201487064362 and batch: 1300, loss is 3.8166498231887815 and perplexity is 45.45168179770782
At time: 555.1655979156494 and batch: 1350, loss is 3.8168996381759643 and perplexity is 45.46303772739521
At time: 555.5182464122772 and batch: 1400, loss is 3.6707139348983766 and perplexity is 39.27993917151484
At time: 555.8670878410339 and batch: 1450, loss is 3.7917936134338377 and perplexity is 44.33585038013916
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.370698847322383 and perplexity of 79.09889043639028
Finished Training.
Improved accuracyfrom -90.35087601696883 to -79.09889043639028
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f3cb8201438>
SETTINGS FOR THIS RUN
{'lr': 4.899041561565707, 'batch_size': 20, 'dropout': 0.0, 'wordvec_source': 'glove', 'anneal': 7.307795951834938, 'num_layers': 1, 'seq_len': 35, 'wordvec_dim': 200, 'tune_wordvecs': True, 'data': 'ptb'}
Preparing Data Loaders

[93m    Warning: no model found for 'en'[0m

    Only loading the 'en' tokenizer.

Retrieving Train Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/train.txt...
Got Train Dataset with 1042946 words
Retrieving Valid Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/valid.txt...
Retrieving Test Data from file: /home-nfs/siddsach/Interpreting-Attention/interpreting_language/data/penn/test.txt...
Loading Vectors From Memory...
Using these vectors: ['GloVe']
Building Vocab...
Found 9600 tokens
Getting Batches...
Created Iterator with 1490 batches
Initializing Model parameters...
Constructing LSTM with 1 layers and 200 hidden size...
here
200
200
Using Cross Entropy Loss ...
Begin Training...
Finished 0 epochs...
Completing Train Step...
At time: 0.58479905128479 and batch: 50, loss is 6.712678022384644 and perplexity is 822.7710911055523
At time: 0.9518375396728516 and batch: 100, loss is 6.022946825027466 and perplexity is 412.79323461849424
At time: 1.2776663303375244 and batch: 150, loss is 5.667164001464844 and perplexity is 289.2131621328336
At time: 1.6287970542907715 and batch: 200, loss is 5.437705917358398 and perplexity is 229.91413597154627
At time: 1.9720075130462646 and batch: 250, loss is 5.3161743640899655 and perplexity is 203.6034773983044
At time: 2.3016791343688965 and batch: 300, loss is 5.2887125587463375 and perplexity is 198.0882342082048
At time: 2.6369941234588623 and batch: 350, loss is 5.261015501022339 and perplexity is 192.67705572957357
At time: 2.985173463821411 and batch: 400, loss is 5.081558046340942 and perplexity is 161.02474459973624
At time: 3.3195061683654785 and batch: 450, loss is 5.063023357391358 and perplexity is 158.0676897451224
At time: 3.642733335494995 and batch: 500, loss is 5.012395887374878 and perplexity is 150.26432160493766
At time: 3.996333122253418 and batch: 550, loss is 5.054514951705933 and perplexity is 156.72849101708655
At time: 4.339033603668213 and batch: 600, loss is 4.8709840488433835 and perplexity is 130.4492221629703
At time: 4.662848234176636 and batch: 650, loss is 4.984604988098145 and perplexity is 146.14583427882005
At time: 5.019848108291626 and batch: 700, loss is 4.977978458404541 and perplexity is 145.18059618984051
At time: 5.3683552742004395 and batch: 750, loss is 4.896018123626709 and perplexity is 133.75611757741814
At time: 5.717715263366699 and batch: 800, loss is 4.7927107334136965 and perplexity is 120.6279159943873
At time: 6.0354814529418945 and batch: 850, loss is 4.738970975875855 and perplexity is 114.31650669187914
At time: 6.44279408454895 and batch: 900, loss is 4.690731201171875 and perplexity is 108.9328024866041
At time: 6.796736478805542 and batch: 950, loss is 4.730646991729737 and perplexity is 113.36888735829491
At time: 7.157461166381836 and batch: 1000, loss is 4.744115285873413 and perplexity is 114.90610146904463
At time: 7.505486726760864 and batch: 1050, loss is 4.691919984817505 and perplexity is 109.06237702345835
At time: 7.84195351600647 and batch: 1100, loss is 4.780579471588135 and perplexity is 119.17338763241655
At time: 8.175366163253784 and batch: 1150, loss is 4.720229883193969 and perplexity is 112.19404122805916
At time: 8.534203290939331 and batch: 1200, loss is 4.641637620925903 and perplexity is 103.71405289219861
At time: 8.893193006515503 and batch: 1250, loss is 4.587500276565552 and perplexity is 98.2485287974549
At time: 9.237148523330688 and batch: 1300, loss is 4.6847888946533205 and perplexity is 108.28740984387836
At time: 9.568722248077393 and batch: 1350, loss is 4.636986589431762 and perplexity is 103.23279560476229
At time: 9.896605014801025 and batch: 1400, loss is 4.462831583023071 and perplexity is 86.73275270875823
At time: 10.225612878799438 and batch: 1450, loss is 4.575351572036743 and perplexity is 97.06215747945004
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.7024922167134084 and perplexity of 110.22152636560067
Finished 1 epochs...
Completing Train Step...
At time: 11.391557216644287 and batch: 50, loss is 4.645004911422729 and perplexity is 104.06387688585045
At time: 11.74936032295227 and batch: 100, loss is 4.624025430679321 and perplexity is 101.9034127340671
At time: 12.101041078567505 and batch: 150, loss is 4.456957492828369 and perplexity is 86.22477012492762
At time: 12.4536612033844 and batch: 200, loss is 4.548666477203369 and perplexity is 94.50629794535074
At time: 12.809162855148315 and batch: 250, loss is 4.587899913787842 and perplexity is 98.28780041327462
At time: 13.175715208053589 and batch: 300, loss is 4.576762704849243 and perplexity is 97.19922175992856
At time: 13.520735502243042 and batch: 350, loss is 4.589202136993408 and perplexity is 98.41587644148572
At time: 13.856893539428711 and batch: 400, loss is 4.4058156585693355 and perplexity is 81.9259391923101
At time: 14.178877353668213 and batch: 450, loss is 4.467521810531617 and perplexity is 87.14050452832038
At time: 14.524008989334106 and batch: 500, loss is 4.438780927658081 and perplexity is 84.67165785516019
At time: 14.8610098361969 and batch: 550, loss is 4.508816614151001 and perplexity is 90.8142865555848
At time: 15.189577341079712 and batch: 600, loss is 4.390783815383911 and perplexity is 80.70365095930055
At time: 15.573137998580933 and batch: 650, loss is 4.489985466003418 and perplexity is 89.1201505972817
At time: 15.92660665512085 and batch: 700, loss is 4.517492218017578 and perplexity is 91.60558285463995
At time: 16.28179359436035 and batch: 750, loss is 4.451427283287049 and perplexity is 85.74924516673802
At time: 16.626652002334595 and batch: 800, loss is 4.363751478195191 and perplexity is 78.55126572511678
At time: 16.95809555053711 and batch: 850, loss is 4.328000435829162 and perplexity is 75.79258281602434
At time: 17.30061411857605 and batch: 900, loss is 4.25268102645874 and perplexity is 70.293618992855
At time: 17.65741229057312 and batch: 950, loss is 4.362496647834778 and perplexity is 78.45275902955791
At time: 18.00079870223999 and batch: 1000, loss is 4.378831911087036 and perplexity is 79.7448299290022
At time: 18.32661247253418 and batch: 1050, loss is 4.327915172576905 and perplexity is 75.7861207694079
At time: 18.661110401153564 and batch: 1100, loss is 4.454208669662475 and perplexity is 85.98807893947829
At time: 19.005382776260376 and batch: 1150, loss is 4.378542323112487 and perplexity is 79.72174012864795
At time: 19.352042198181152 and batch: 1200, loss is 4.322390480041504 and perplexity is 75.3685802073412
At time: 19.701815128326416 and batch: 1250, loss is 4.224860877990722 and perplexity is 68.36499181190239
At time: 20.047179698944092 and batch: 1300, loss is 4.347155332565308 and perplexity is 77.2583756508531
At time: 20.411186933517456 and batch: 1350, loss is 4.330775327682495 and perplexity is 76.0031911091012
At time: 20.758769750595093 and batch: 1400, loss is 4.156846957206726 and perplexity is 63.86982050212652
At time: 21.122427940368652 and batch: 1450, loss is 4.283611950874328 and perplexity is 72.50184072686021
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.516421587039263 and perplexity of 91.50755956259894
Finished 2 epochs...
Completing Train Step...
At time: 22.337002992630005 and batch: 50, loss is 4.3345336961746215 and perplexity is 76.28937656619709
At time: 22.685105562210083 and batch: 100, loss is 4.346080274581909 and perplexity is 77.17536304700164
At time: 23.018301486968994 and batch: 150, loss is 4.1736879587173465 and perplexity is 64.95456066338092
At time: 23.351974725723267 and batch: 200, loss is 4.302615423202514 and perplexity is 73.89280213941227
At time: 23.685333013534546 and batch: 250, loss is 4.366026239395142 and perplexity is 78.73015448406039
At time: 24.043115615844727 and batch: 300, loss is 4.338292007446289 and perplexity is 76.57663525571465
At time: 24.40688180923462 and batch: 350, loss is 4.3472936153411865 and perplexity is 77.26905989220425
At time: 24.746264696121216 and batch: 400, loss is 4.148459711074829 and perplexity is 63.33636881962985
At time: 25.071648359298706 and batch: 450, loss is 4.232957615852356 and perplexity is 68.92077219728175
At time: 25.40808129310608 and batch: 500, loss is 4.211571321487427 and perplexity is 67.46246178538293
At time: 25.740848302841187 and batch: 550, loss is 4.282860713005066 and perplexity is 72.44739505190196
At time: 26.09798312187195 and batch: 600, loss is 4.182155289649963 and perplexity is 65.5068874911668
At time: 26.44225788116455 and batch: 650, loss is 4.270154738426209 and perplexity is 71.53270362085532
At time: 26.798327684402466 and batch: 700, loss is 4.303285126686096 and perplexity is 73.9423049806791
At time: 27.14533495903015 and batch: 750, loss is 4.249304447174072 and perplexity is 70.05666728336578
At time: 27.466901540756226 and batch: 800, loss is 4.162076635360718 and perplexity is 64.20471403654146
At time: 27.79960608482361 and batch: 850, loss is 4.129109992980957 and perplexity is 62.12260876557
At time: 28.135813236236572 and batch: 900, loss is 4.04768536567688 and perplexity is 57.26475655710711
At time: 28.48834466934204 and batch: 950, loss is 4.179045515060425 and perplexity is 65.30349225758599
At time: 28.812700986862183 and batch: 1000, loss is 4.195379128456116 and perplexity is 66.37889293449715
At time: 29.15518879890442 and batch: 1050, loss is 4.143577876091004 and perplexity is 63.02792461800273
At time: 29.508716583251953 and batch: 1100, loss is 4.284310808181763 and perplexity is 72.55252687718497
At time: 29.87458825111389 and batch: 1150, loss is 4.19884774684906 and perplexity is 66.60953575815854
At time: 30.23039746284485 and batch: 1200, loss is 4.150295977592468 and perplexity is 63.4527781195823
At time: 30.584787607192993 and batch: 1250, loss is 4.037184357643127 and perplexity is 56.66656519154613
At time: 30.934242010116577 and batch: 1300, loss is 4.160937113761902 and perplexity is 64.13159304753653
At time: 31.276925086975098 and batch: 1350, loss is 4.156088671684265 and perplexity is 63.821407299752586
At time: 31.615246295928955 and batch: 1400, loss is 3.993040018081665 and perplexity is 54.21946723750178
At time: 31.957377195358276 and batch: 1450, loss is 4.113832612037658 and perplexity is 61.180750886013556
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.449474367321047 and perplexity of 85.58194750908375
Finished 3 epochs...
Completing Train Step...
At time: 33.131762742996216 and batch: 50, loss is 4.1570341730117795 and perplexity is 63.881779061371155
At time: 33.49262523651123 and batch: 100, loss is 4.184394998550415 and perplexity is 65.65376827381996
At time: 33.846601486206055 and batch: 150, loss is 4.01018259525299 and perplexity is 55.15694103962857
At time: 34.19155168533325 and batch: 200, loss is 4.147079410552979 and perplexity is 63.249005904105495
At time: 34.542903900146484 and batch: 250, loss is 4.222994260787964 and perplexity is 68.23749956874498
At time: 34.88821315765381 and batch: 300, loss is 4.18883590221405 and perplexity is 65.94597869280018
At time: 35.22699546813965 and batch: 350, loss is 4.197694158554077 and perplexity is 66.53274008118713
At time: 35.58174443244934 and batch: 400, loss is 3.993338694572449 and perplexity is 54.23566373634476
At time: 35.92544722557068 and batch: 450, loss is 4.087678236961365 and perplexity is 59.6013507235532
At time: 36.276262044906616 and batch: 500, loss is 4.065604619979858 and perplexity is 58.30014730233098
At time: 36.62636065483093 and batch: 550, loss is 4.135493960380554 and perplexity is 62.52046607753869
At time: 36.95639204978943 and batch: 600, loss is 4.047818398475647 and perplexity is 57.272375154693016
At time: 37.310646057128906 and batch: 650, loss is 4.122129578590393 and perplexity is 61.69047719674971
At time: 37.641364097595215 and batch: 700, loss is 4.161599063873291 and perplexity is 64.17405901632368
At time: 37.972434759140015 and batch: 750, loss is 4.114584321975708 and perplexity is 61.2267583544411
At time: 38.29762125015259 and batch: 800, loss is 4.029378204345703 and perplexity is 56.22593933082716
At time: 38.644978046417236 and batch: 850, loss is 3.999096894264221 and perplexity is 54.54886438911008
At time: 38.987414836883545 and batch: 900, loss is 3.912271013259888 and perplexity is 50.01240192941133
At time: 39.323222160339355 and batch: 950, loss is 4.055707178115845 and perplexity is 57.72597110864426
At time: 39.63954567909241 and batch: 1000, loss is 4.0720186519622805 and perplexity is 58.675288108170555
At time: 39.98350739479065 and batch: 1050, loss is 4.015549421310425 and perplexity is 55.453754508756795
At time: 40.32435321807861 and batch: 1100, loss is 4.159729547500611 and perplexity is 64.05419663954005
At time: 40.667224645614624 and batch: 1150, loss is 4.073378834724426 and perplexity is 58.75515152572825
At time: 41.01955246925354 and batch: 1200, loss is 4.0292095279693605 and perplexity is 56.21645614294173
At time: 41.373793601989746 and batch: 1250, loss is 3.9112436056137083 and perplexity is 49.96104519193517
At time: 41.72334432601929 and batch: 1300, loss is 4.033962998390198 and perplexity is 56.48431553085274
At time: 42.07407093048096 and batch: 1350, loss is 4.039252395629883 and perplexity is 56.783875059764
At time: 42.412818908691406 and batch: 1400, loss is 3.8780882692337038 and perplexity is 48.33172944153889
At time: 42.75522446632385 and batch: 1450, loss is 3.995150046348572 and perplexity is 54.33399262940562
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.421654856103098 and perplexity of 83.23391159771687
Finished 4 epochs...
Completing Train Step...
At time: 43.89250993728638 and batch: 50, loss is 4.037758665084839 and perplexity is 56.69911856856044
At time: 44.25621557235718 and batch: 100, loss is 4.069587860107422 and perplexity is 58.53283390415898
At time: 44.59974217414856 and batch: 150, loss is 3.8954591274261476 and perplexity is 49.17862743673559
At time: 44.93584680557251 and batch: 200, loss is 4.039930014610291 and perplexity is 56.82236593088521
At time: 45.26306939125061 and batch: 250, loss is 4.119942536354065 and perplexity is 61.55570494756155
At time: 45.606196641922 and batch: 300, loss is 4.08198395729065 and perplexity is 59.262928413859754
At time: 45.96108150482178 and batch: 350, loss is 4.0894552516937255 and perplexity is 59.70735736164089
At time: 46.309459924697876 and batch: 400, loss is 3.8850947856903075 and perplexity is 48.67155560785337
At time: 46.65406084060669 and batch: 450, loss is 3.976434755325317 and perplexity is 53.326572629052485
At time: 46.986889123916626 and batch: 500, loss is 3.9651297521591187 and perplexity is 52.72711040223842
At time: 47.32962608337402 and batch: 550, loss is 4.027650456428528 and perplexity is 56.128878953334315
At time: 47.68433928489685 and batch: 600, loss is 3.944861307144165 and perplexity is 51.669171470187685
At time: 48.040162324905396 and batch: 650, loss is 4.016536264419556 and perplexity is 55.50850567523156
At time: 48.388067960739136 and batch: 700, loss is 4.057261300086975 and perplexity is 57.81575405740468
At time: 48.732850790023804 and batch: 750, loss is 4.019112372398377 and perplexity is 55.651685924302335
At time: 49.086721420288086 and batch: 800, loss is 3.9334398984909056 and perplexity is 51.08239403914171
At time: 49.43166399002075 and batch: 850, loss is 3.903416647911072 and perplexity is 49.57152855806877
At time: 49.75978994369507 and batch: 900, loss is 3.8150779247283935 and perplexity is 45.38029249213716
At time: 50.100873947143555 and batch: 950, loss is 3.96234938621521 and perplexity is 52.580713353149505
At time: 50.456300258636475 and batch: 1000, loss is 3.979840540885925 and perplexity is 53.50850112898358
At time: 50.823622703552246 and batch: 1050, loss is 3.9206668949127197 and perplexity is 50.43406778854796
At time: 51.14540886878967 and batch: 1100, loss is 4.0695067977905275 and perplexity is 58.52808928933564
At time: 51.49240565299988 and batch: 1150, loss is 3.9843262004852296 and perplexity is 53.749061182612294
At time: 51.82629585266113 and batch: 1200, loss is 3.9388493394851682 and perplexity is 51.35946997284875
At time: 52.18702268600464 and batch: 1250, loss is 3.816920590400696 and perplexity is 45.46399028915776
At time: 52.54129648208618 and batch: 1300, loss is 3.941118688583374 and perplexity is 51.476154889043904
At time: 52.88971138000488 and batch: 1350, loss is 3.95032292842865 and perplexity is 51.952140949508234
At time: 53.23017454147339 and batch: 1400, loss is 3.793549699783325 and perplexity is 44.41377636413709
At time: 53.55369997024536 and batch: 1450, loss is 3.9059935283660887 and perplexity is 49.69943318782841
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.411134377504006 and perplexity of 82.36284108556808
Finished 5 epochs...
Completing Train Step...
At time: 54.75741004943848 and batch: 50, loss is 3.9443902158737183 and perplexity is 51.64483630704837
At time: 55.11689043045044 and batch: 100, loss is 3.9876777505874634 and perplexity is 53.92950607024491
At time: 55.455007791519165 and batch: 150, loss is 3.8118024253845215 and perplexity is 45.231892548494066
At time: 55.808377742767334 and batch: 200, loss is 3.9535065650939942 and perplexity is 52.11780125146248
At time: 56.14987587928772 and batch: 250, loss is 4.037153601646423 and perplexity is 56.66482238165493
At time: 56.50051236152649 and batch: 300, loss is 4.002340989112854 and perplexity is 54.72611342997415
At time: 56.86118674278259 and batch: 350, loss is 4.002800221443176 and perplexity is 54.75125120217115
At time: 57.21577715873718 and batch: 400, loss is 3.803353452682495 and perplexity is 44.851339428369755
At time: 57.5616340637207 and batch: 450, loss is 3.895521330833435 and perplexity is 49.181686610072376
At time: 57.89483571052551 and batch: 500, loss is 3.887780342102051 and perplexity is 48.80244148812832
At time: 58.21909046173096 and batch: 550, loss is 3.946866765022278 and perplexity is 51.772895789781344
At time: 58.568902254104614 and batch: 600, loss is 3.866074604988098 and perplexity is 47.75456216035639
At time: 58.91638135910034 and batch: 650, loss is 3.9312110424041746 and perplexity is 50.96866552359155
At time: 59.26989269256592 and batch: 700, loss is 3.979656558036804 and perplexity is 53.49865738806119
At time: 59.62952184677124 and batch: 750, loss is 3.94102454662323 and perplexity is 51.47130905102388
At time: 59.9825713634491 and batch: 800, loss is 3.8576671981811526 and perplexity is 47.35475316285205
At time: 60.33555006980896 and batch: 850, loss is 3.8295314168930052 and perplexity is 46.040959163121556
At time: 60.69829726219177 and batch: 900, loss is 3.737552833557129 and perplexity is 41.99509532789892
At time: 61.02420783042908 and batch: 950, loss is 3.8928364896774292 and perplexity is 49.04981869515518
At time: 61.35990834236145 and batch: 1000, loss is 3.909556965827942 and perplexity is 49.87684992887577
At time: 61.70851492881775 and batch: 1050, loss is 3.8458377075195314 and perplexity is 46.79787086352287
At time: 62.03761076927185 and batch: 1100, loss is 3.998679938316345 and perplexity is 54.52612465671594
At time: 62.38388156890869 and batch: 1150, loss is 3.9108264207839967 and perplexity is 49.94020654888967
At time: 62.727078437805176 and batch: 1200, loss is 3.8680395793914797 and perplexity is 47.848490906214316
At time: 63.057334899902344 and batch: 1250, loss is 3.74520037651062 and perplexity is 42.31748579949795
At time: 63.37705039978027 and batch: 1300, loss is 3.869267477989197 and perplexity is 47.90728008729091
At time: 63.73383545875549 and batch: 1350, loss is 3.8812659549713135 and perplexity is 48.4855567668665
At time: 64.10144805908203 and batch: 1400, loss is 3.7280727863311767 and perplexity is 41.59886096865464
At time: 64.42115545272827 and batch: 1450, loss is 3.836595826148987 and perplexity is 46.367362908553666
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.415217472956731 and perplexity of 82.69982392585739
Annealing...
Finished 6 epochs...
Completing Train Step...
At time: 65.5800449848175 and batch: 50, loss is 3.9081094217300416 and perplexity is 49.80470321950895
At time: 65.94656252861023 and batch: 100, loss is 3.9403344440460204 and perplexity is 51.43580082156496
At time: 66.29342222213745 and batch: 150, loss is 3.75311448097229 and perplexity is 42.653719542208535
At time: 66.62453556060791 and batch: 200, loss is 3.8921989488601683 and perplexity is 49.01855739989251
At time: 66.97493839263916 and batch: 250, loss is 3.9684771728515624 and perplexity is 52.90390596212324
At time: 67.32923650741577 and batch: 300, loss is 3.933068370819092 and perplexity is 51.06341904130033
At time: 67.65650367736816 and batch: 350, loss is 3.909827299118042 and perplexity is 49.890335124483386
At time: 68.01285481452942 and batch: 400, loss is 3.701635708808899 and perplexity is 40.51351851087702
At time: 68.38068151473999 and batch: 450, loss is 3.7981550550460814 and perplexity is 44.61878929920606
At time: 68.7341742515564 and batch: 500, loss is 3.7792256021499635 and perplexity is 43.78212382173164
At time: 69.06946563720703 and batch: 550, loss is 3.8331478357315065 and perplexity is 46.20776399144732
At time: 69.43802523612976 and batch: 600, loss is 3.7609273338317872 and perplexity is 42.98827197961201
At time: 69.79376339912415 and batch: 650, loss is 3.8024559307098387 and perplexity is 44.81110242522801
At time: 70.14113736152649 and batch: 700, loss is 3.8606841373443603 and perplexity is 47.49783529875592
At time: 70.48540139198303 and batch: 750, loss is 3.8119836807250977 and perplexity is 45.2400918136407
At time: 70.8362364768982 and batch: 800, loss is 3.719030041694641 and perplexity is 41.22438877172041
At time: 71.19346165657043 and batch: 850, loss is 3.674306526184082 and perplexity is 39.42130972995122
At time: 71.55343723297119 and batch: 900, loss is 3.5716528272628785 and perplexity is 35.57534448460156
At time: 71.90259051322937 and batch: 950, loss is 3.7194301652908326 and perplexity is 41.24088692283622
At time: 72.26819634437561 and batch: 1000, loss is 3.7320403623580933 and perplexity is 41.76423546318186
At time: 72.61013555526733 and batch: 1050, loss is 3.658015079498291 and perplexity is 38.78428269960141
At time: 72.9526002407074 and batch: 1100, loss is 3.798014454841614 and perplexity is 44.61251632930826
At time: 73.29054760932922 and batch: 1150, loss is 3.7002686214447023 and perplexity is 40.458170832817366
At time: 73.63129019737244 and batch: 1200, loss is 3.646803297996521 and perplexity is 38.35187038213693
At time: 73.98292875289917 and batch: 1250, loss is 3.5040459060668945 and perplexity is 33.249705371892645
At time: 74.33025646209717 and batch: 1300, loss is 3.622474026679993 and perplexity is 37.430056323345994
At time: 74.67647695541382 and batch: 1350, loss is 3.6115547800064087 and perplexity is 37.02357159759469
At time: 75.03471541404724 and batch: 1400, loss is 3.4464856338500978 and perplexity is 31.38988269567102
At time: 75.40553855895996 and batch: 1450, loss is 3.545766067504883 and perplexity is 34.6662318464898
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.31434826973157 and perplexity of 74.7648810262334
Finished 7 epochs...
Completing Train Step...
At time: 76.5576901435852 and batch: 50, loss is 3.800569438934326 and perplexity is 44.726646336956335
At time: 76.89179301261902 and batch: 100, loss is 3.8450917196273804 and perplexity is 46.762973236702145
At time: 77.23472952842712 and batch: 150, loss is 3.666146535873413 and perplexity is 39.10094110461546
At time: 77.56324124336243 and batch: 200, loss is 3.811373496055603 and perplexity is 45.212495423472824
At time: 77.90990710258484 and batch: 250, loss is 3.8919597673416138 and perplexity is 49.006834468906355
At time: 78.25612783432007 and batch: 300, loss is 3.8587477684020994 and perplexity is 47.405950955363416
At time: 78.61303877830505 and batch: 350, loss is 3.8391070985794067 and perplexity is 46.48395031880029
At time: 78.95726251602173 and batch: 400, loss is 3.6315588998794555 and perplexity is 37.77165297053709
At time: 79.30331921577454 and batch: 450, loss is 3.7316318130493165 and perplexity is 41.747176198664434
At time: 79.65012741088867 and batch: 500, loss is 3.714957342147827 and perplexity is 41.05683565061093
At time: 79.98742294311523 and batch: 550, loss is 3.7698644399642944 and perplexity is 43.37418463128294
At time: 80.31965827941895 and batch: 600, loss is 3.701630597114563 and perplexity is 40.5133114186832
At time: 80.64352130889893 and batch: 650, loss is 3.746162843704224 and perplexity is 42.35823459784094
At time: 81.0074474811554 and batch: 700, loss is 3.807108483314514 and perplexity is 45.0200741856346
At time: 81.32936763763428 and batch: 750, loss is 3.762230019569397 and perplexity is 43.04430867958478
At time: 81.67407011985779 and batch: 800, loss is 3.6710467767715453 and perplexity is 39.2930153560768
At time: 82.01744771003723 and batch: 850, loss is 3.6292392444610595 and perplexity is 37.68413729341157
At time: 82.37832427024841 and batch: 900, loss is 3.529239020347595 and perplexity is 34.09800984765916
At time: 82.72309803962708 and batch: 950, loss is 3.6808746099472045 and perplexity is 39.68108437122805
At time: 83.07456183433533 and batch: 1000, loss is 3.696353416442871 and perplexity is 40.30007848393284
At time: 83.42279624938965 and batch: 1050, loss is 3.625564570426941 and perplexity is 37.54591449001241
At time: 83.7618978023529 and batch: 1100, loss is 3.770631151199341 and perplexity is 43.407452857882554
At time: 84.09576797485352 and batch: 1150, loss is 3.675814929008484 and perplexity is 39.48081781468791
At time: 84.41858673095703 and batch: 1200, loss is 3.625394592285156 and perplexity is 37.539533047604
At time: 84.7414116859436 and batch: 1250, loss is 3.485996437072754 and perplexity is 32.654949506204694
At time: 85.08537650108337 and batch: 1300, loss is 3.6077910661697388 and perplexity is 36.88448736968998
At time: 85.43099927902222 and batch: 1350, loss is 3.6036232852935792 and perplexity is 36.73108081312102
At time: 85.79140663146973 and batch: 1400, loss is 3.44474081993103 and perplexity is 31.33516094494468
At time: 86.13537073135376 and batch: 1450, loss is 3.550300064086914 and perplexity is 34.82376528135184
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.309117765508146 and perplexity of 74.37484393481371
Finished 8 epochs...
Completing Train Step...
At time: 87.3459243774414 and batch: 50, loss is 3.7655270099639893 and perplexity is 43.18645955811708
At time: 87.70103812217712 and batch: 100, loss is 3.8097580957412718 and perplexity is 45.13951810381624
At time: 88.02706480026245 and batch: 150, loss is 3.6310200309753418 and perplexity is 37.75130448436991
At time: 88.36633825302124 and batch: 200, loss is 3.7777576208114625 and perplexity is 43.717899632490465
At time: 88.69332385063171 and batch: 250, loss is 3.8581433582305906 and perplexity is 47.3773069736449
At time: 89.02660250663757 and batch: 300, loss is 3.8246302032470703 and perplexity is 45.8158546790035
At time: 89.35309505462646 and batch: 350, loss is 3.8062450742721556 and perplexity is 44.98122022234041
At time: 89.70264339447021 and batch: 400, loss is 3.5980591201782226 and perplexity is 36.527270557397884
At time: 90.05404424667358 and batch: 450, loss is 3.69849449634552 and perplexity is 40.3864566102871
At time: 90.392733335495 and batch: 500, loss is 3.682131567001343 and perplexity is 39.73099315016913
At time: 90.73632144927979 and batch: 550, loss is 3.7380562591552735 and perplexity is 42.016242056339095
At time: 91.10064482688904 and batch: 600, loss is 3.671465826034546 and perplexity is 39.30948451565643
At time: 91.45069193840027 and batch: 650, loss is 3.716665368080139 and perplexity is 41.12702171334534
At time: 91.77049398422241 and batch: 700, loss is 3.777923197746277 and perplexity is 43.7251389076201
At time: 92.11105561256409 and batch: 750, loss is 3.7349578523635865 and perplexity is 41.886260119036116
At time: 92.4590003490448 and batch: 800, loss is 3.644967861175537 and perplexity is 38.28154250801234
At time: 92.81496548652649 and batch: 850, loss is 3.604310460090637 and perplexity is 36.75633016048848
At time: 93.16601085662842 and batch: 900, loss is 3.506048946380615 and perplexity is 33.3163726184731
At time: 93.50691270828247 and batch: 950, loss is 3.6593826532363893 and perplexity is 38.837359350917346
At time: 93.859304189682 and batch: 1000, loss is 3.676360750198364 and perplexity is 39.502373163792974
At time: 94.20116376876831 and batch: 1050, loss is 3.606753559112549 and perplexity is 36.84623929849591
At time: 94.54439759254456 and batch: 1100, loss is 3.754151587486267 and perplexity is 42.69797893947863
At time: 94.8971118927002 and batch: 1150, loss is 3.660266857147217 and perplexity is 38.87171468226251
At time: 95.22922015190125 and batch: 1200, loss is 3.611410779953003 and perplexity is 37.01824058514961
At time: 95.58469247817993 and batch: 1250, loss is 3.474059638977051 and perplexity is 32.26747119319724
At time: 95.93180990219116 and batch: 1300, loss is 3.596802988052368 and perplexity is 36.48141628492267
At time: 96.28497457504272 and batch: 1350, loss is 3.595483684539795 and perplexity is 36.433317959395744
At time: 96.61792826652527 and batch: 1400, loss is 3.439854130744934 and perplexity is 31.18240928173309
At time: 96.97186517715454 and batch: 1450, loss is 3.547324652671814 and perplexity is 34.720304248515
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.308069212823852 and perplexity of 74.2968988644597
Finished 9 epochs...
Completing Train Step...
At time: 98.17974591255188 and batch: 50, loss is 3.739687042236328 and perplexity is 42.08481733351724
At time: 98.53419089317322 and batch: 100, loss is 3.7837247753143313 and perplexity is 43.979550974747994
At time: 98.87078952789307 and batch: 150, loss is 3.605803599357605 and perplexity is 36.81125347423483
At time: 99.21584224700928 and batch: 200, loss is 3.752955093383789 and perplexity is 42.64692161047748
At time: 99.55458950996399 and batch: 250, loss is 3.833531880378723 and perplexity is 46.225513243902626
At time: 99.88989424705505 and batch: 300, loss is 3.799901828765869 and perplexity is 44.69679633825082
At time: 100.23197841644287 and batch: 350, loss is 3.7822706937789916 and perplexity is 43.91564759336606
At time: 100.58943700790405 and batch: 400, loss is 3.573817286491394 and perplexity is 35.652429260611854
At time: 100.95412635803223 and batch: 450, loss is 3.674553575515747 and perplexity is 39.431049941280165
At time: 101.29679775238037 and batch: 500, loss is 3.658438467979431 and perplexity is 38.80070699482907
At time: 101.65205383300781 and batch: 550, loss is 3.714896574020386 and perplexity is 41.05434077939488
At time: 102.00364923477173 and batch: 600, loss is 3.6495786333084106 and perplexity is 38.45845752139569
At time: 102.3499231338501 and batch: 650, loss is 3.6952032375335695 and perplexity is 40.253752830119474
At time: 102.70045471191406 and batch: 700, loss is 3.756358938217163 and perplexity is 42.792332451835065
At time: 103.04351282119751 and batch: 750, loss is 3.7146263027191164 and perplexity is 41.04324646859411
At time: 103.38691353797913 and batch: 800, loss is 3.6253791856765747 and perplexity is 37.53895469516725
At time: 103.73795199394226 and batch: 850, loss is 3.585827374458313 and perplexity is 36.08319968971212
At time: 104.07752180099487 and batch: 900, loss is 3.4885486555099487 and perplexity is 32.73839851515205
At time: 104.41403245925903 and batch: 950, loss is 3.6430636930465696 and perplexity is 38.20871737249635
At time: 104.76041460037231 and batch: 1000, loss is 3.6609270334243775 and perplexity is 38.89738533879519
At time: 105.12165212631226 and batch: 1050, loss is 3.5918717527389528 and perplexity is 36.3019606692426
At time: 105.47908473014832 and batch: 1100, loss is 3.7407422924041747 and perplexity is 42.12925078415209
At time: 105.83495497703552 and batch: 1150, loss is 3.647148208618164 and perplexity is 38.365100631087145
At time: 106.1817672252655 and batch: 1200, loss is 3.5992793035507202 and perplexity is 36.571867728404804
At time: 106.52394104003906 and batch: 1250, loss is 3.463468885421753 and perplexity is 31.92753761168586
At time: 106.85484004020691 and batch: 1300, loss is 3.586302227973938 and perplexity is 36.100337992709456
At time: 107.19874501228333 and batch: 1350, loss is 3.5867510223388672 and perplexity is 36.1165432571163
At time: 107.55567479133606 and batch: 1400, loss is 3.433305125236511 and perplexity is 30.97886275275065
At time: 107.8987934589386 and batch: 1450, loss is 3.541531891822815 and perplexity is 34.5197592448135
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.308405167017227 and perplexity of 74.32186341242551
Annealing...
Finished 10 epochs...
Completing Train Step...
At time: 109.07556748390198 and batch: 50, loss is 3.7348507118225096 and perplexity is 41.881772642862884
At time: 109.42905116081238 and batch: 100, loss is 3.785464653968811 and perplexity is 44.05613666230418
At time: 109.75022220611572 and batch: 150, loss is 3.6086292600631715 and perplexity is 36.91541668233531
At time: 110.09673523902893 and batch: 200, loss is 3.751295566558838 and perplexity is 42.576206593026754
At time: 110.44937086105347 and batch: 250, loss is 3.838364043235779 and perplexity is 46.449423000565766
At time: 110.77812004089355 and batch: 300, loss is 3.796391973495483 and perplexity is 44.540192042029304
At time: 111.1163170337677 and batch: 350, loss is 3.777467074394226 and perplexity is 43.70519939847623
At time: 111.45943427085876 and batch: 400, loss is 3.564093189239502 and perplexity is 35.30742173318957
At time: 111.78811717033386 and batch: 450, loss is 3.6687827253341676 and perplexity is 39.20415457882404
At time: 112.13717818260193 and batch: 500, loss is 3.645865216255188 and perplexity is 38.3159100622823
At time: 112.52082514762878 and batch: 550, loss is 3.703497200012207 and perplexity is 40.58900430547391
At time: 112.86056065559387 and batch: 600, loss is 3.637892556190491 and perplexity is 38.01164484951525
At time: 113.19656276702881 and batch: 650, loss is 3.681747040748596 and perplexity is 39.71571847719978
At time: 113.52524948120117 and batch: 700, loss is 3.7438629388809206 and perplexity is 42.26092663220555
At time: 113.85977935791016 and batch: 750, loss is 3.696644492149353 and perplexity is 40.31181056512791
At time: 114.19596982002258 and batch: 800, loss is 3.6094493007659914 and perplexity is 36.94570124216513
At time: 114.54336714744568 and batch: 850, loss is 3.5662085103988646 and perplexity is 35.382187318197566
At time: 114.89360356330872 and batch: 900, loss is 3.458416213989258 and perplexity is 31.766625115805255
At time: 115.24284815788269 and batch: 950, loss is 3.613569164276123 and perplexity is 37.098226464379984
At time: 115.59113955497742 and batch: 1000, loss is 3.6334058666229248 and perplexity is 37.84148042205979
At time: 115.94528770446777 and batch: 1050, loss is 3.563772888183594 and perplexity is 35.296114539676715
At time: 116.29455327987671 and batch: 1100, loss is 3.7111351919174194 and perplexity is 40.900209771266276
At time: 116.63074493408203 and batch: 1150, loss is 3.6103640604019165 and perplexity is 36.97951314090473
At time: 116.95863723754883 and batch: 1200, loss is 3.5593787574768068 and perplexity is 35.14135905586583
At time: 117.28938174247742 and batch: 1250, loss is 3.421520447731018 and perplexity is 30.61592957126781
At time: 117.63231253623962 and batch: 1300, loss is 3.5415151166915892 and perplexity is 34.51918017617927
At time: 117.9922251701355 and batch: 1350, loss is 3.5403941249847413 and perplexity is 34.48050614216017
At time: 118.34720873832703 and batch: 1400, loss is 3.3840593194961546 and perplexity is 29.490238771734543
At time: 118.69368243217468 and batch: 1450, loss is 3.491010103225708 and perplexity is 32.819081629291894
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.292945274939904 and perplexity of 73.18169160077926
Finished 11 epochs...
Completing Train Step...
At time: 119.88009858131409 and batch: 50, loss is 3.7197627639770507 and perplexity is 41.254605868970486
At time: 120.23341989517212 and batch: 100, loss is 3.7647302389144897 and perplexity is 43.15206354210535
At time: 120.60004997253418 and batch: 150, loss is 3.588244242668152 and perplexity is 36.17051349843392
At time: 120.94965934753418 and batch: 200, loss is 3.735067377090454 and perplexity is 41.890847951471116
At time: 121.31924939155579 and batch: 250, loss is 3.821276612281799 and perplexity is 45.66246439058807
At time: 121.65825271606445 and batch: 300, loss is 3.781150121688843 and perplexity is 43.8664645060961
At time: 122.01835918426514 and batch: 350, loss is 3.7639807748794554 and perplexity is 43.11973473859404
At time: 122.36491847038269 and batch: 400, loss is 3.5498260831832886 and perplexity is 34.80726339271513
At time: 122.71222758293152 and batch: 450, loss is 3.6551158905029295 and perplexity is 38.67200257330467
At time: 123.0382649898529 and batch: 500, loss is 3.6348490428924563 and perplexity is 37.89613177489114
At time: 123.38797545433044 and batch: 550, loss is 3.691981539726257 and perplexity is 40.12427608235798
At time: 123.7205023765564 and batch: 600, loss is 3.6274014043807985 and perplexity is 37.614943478562864
At time: 124.04748702049255 and batch: 650, loss is 3.6715796041488646 and perplexity is 39.313957329128776
At time: 124.39270567893982 and batch: 700, loss is 3.7340331172943113 and perplexity is 41.84754432906656
At time: 124.73164701461792 and batch: 750, loss is 3.687492361068726 and perplexity is 39.944554740948035
At time: 125.07137513160706 and batch: 800, loss is 3.6010018491744997 and perplexity is 36.634918727635
At time: 125.42160296440125 and batch: 850, loss is 3.5587460517883303 and perplexity is 35.1191319504399
At time: 125.7852554321289 and batch: 900, loss is 3.4522832250595092 and perplexity is 31.57239696398754
At time: 126.11351275444031 and batch: 950, loss is 3.6079646444320677 and perplexity is 36.89089027060063
At time: 126.43791937828064 and batch: 1000, loss is 3.6284502363204956 and perplexity is 37.654415929058025
At time: 126.76221370697021 and batch: 1050, loss is 3.5595983028411866 and perplexity is 35.14907502531622
At time: 127.1069974899292 and batch: 1100, loss is 3.7082217931747437 and perplexity is 40.78122456138505
At time: 127.4502682685852 and batch: 1150, loss is 3.608343677520752 and perplexity is 36.904875789003896
At time: 127.7781994342804 and batch: 1200, loss is 3.5579908990859987 and perplexity is 35.0926216539648
At time: 128.10166239738464 and batch: 1250, loss is 3.421318769454956 and perplexity is 30.609755625968088
At time: 128.43272590637207 and batch: 1300, loss is 3.5424205112457274 and perplexity is 34.55044780655929
At time: 128.77948927879333 and batch: 1350, loss is 3.5423565244674684 and perplexity is 34.54823710544532
At time: 129.1317331790924 and batch: 1400, loss is 3.38783748626709 and perplexity is 29.601868557113082
At time: 129.4767291545868 and batch: 1450, loss is 3.4957720184326173 and perplexity is 32.97573600458288
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.292093912760417 and perplexity of 73.11941399048213
Finished 12 epochs...
Completing Train Step...
At time: 130.69745874404907 and batch: 50, loss is 3.714544515609741 and perplexity is 41.03988979737416
At time: 131.04777789115906 and batch: 100, loss is 3.758551769256592 and perplexity is 42.88627176556417
At time: 131.39874410629272 and batch: 150, loss is 3.5818323993682863 and perplexity is 35.939335763520894
At time: 131.73863863945007 and batch: 200, loss is 3.728885703086853 and perplexity is 41.63269112844198
At time: 132.09761834144592 and batch: 250, loss is 3.8147169733047486 and perplexity is 45.36391536680786
At time: 132.42139148712158 and batch: 300, loss is 3.774784708023071 and perplexity is 43.58812313228263
At time: 132.7689471244812 and batch: 350, loss is 3.757766580581665 and perplexity is 42.852611167353636
At time: 133.09949040412903 and batch: 400, loss is 3.5435173177719115 and perplexity is 34.58836375262362
At time: 133.42082118988037 and batch: 450, loss is 3.6488711786270143 and perplexity is 38.431259527391354
At time: 133.76393032073975 and batch: 500, loss is 3.6291305780410767 and perplexity is 37.6800425156082
At time: 134.12164616584778 and batch: 550, loss is 3.686058669090271 and perplexity is 39.88732758609182
At time: 134.4599609375 and batch: 600, loss is 3.6217935991287233 and perplexity is 37.404596544527784
At time: 134.80469250679016 and batch: 650, loss is 3.6663306045532225 and perplexity is 39.108139025659476
At time: 135.14204216003418 and batch: 700, loss is 3.7288019466400146 and perplexity is 41.629204268186285
At time: 135.4696090221405 and batch: 750, loss is 3.682451853752136 and perplexity is 39.74372049896277
At time: 135.81769967079163 and batch: 800, loss is 3.5963369178771973 and perplexity is 36.464417346501094
At time: 136.16540145874023 and batch: 850, loss is 3.554673976898193 and perplexity is 34.97641498934648
At time: 136.50517678260803 and batch: 900, loss is 3.4487749910354615 and perplexity is 31.461827671618995
At time: 136.83168578147888 and batch: 950, loss is 3.6049606800079346 and perplexity is 36.78023763015976
At time: 137.1542866230011 and batch: 1000, loss is 3.6257196855545044 and perplexity is 37.55173888104191
At time: 137.50443291664124 and batch: 1050, loss is 3.5572512769699096 and perplexity is 35.06667597106121
At time: 137.86486411094666 and batch: 1100, loss is 3.706460542678833 and perplexity is 40.70946182403152
At time: 138.21425652503967 and batch: 1150, loss is 3.6071265935897827 and perplexity is 36.859986780093536
At time: 138.5507082939148 and batch: 1200, loss is 3.5570979070663453 and perplexity is 35.06129821075304
At time: 138.90775418281555 and batch: 1250, loss is 3.4211075115203857 and perplexity is 30.60328975522414
At time: 139.2363395690918 and batch: 1300, loss is 3.5426207971572876 and perplexity is 34.55736846752535
At time: 139.59206986427307 and batch: 1350, loss is 3.543036074638367 and perplexity is 34.57172234466996
At time: 139.9344608783722 and batch: 1400, loss is 3.3893061208724977 and perplexity is 29.645374825246414
At time: 140.29531383514404 and batch: 1450, loss is 3.4976125955581665 and perplexity is 33.036486280604834
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.291851337139423 and perplexity of 73.10167915433311
Finished 13 epochs...
Completing Train Step...
At time: 141.56140398979187 and batch: 50, loss is 3.709910764694214 and perplexity is 40.850161087725674
At time: 141.92417788505554 and batch: 100, loss is 3.753630747795105 and perplexity is 42.67574592773465
At time: 142.2674388885498 and batch: 150, loss is 3.576793293952942 and perplexity is 35.75868919286405
At time: 142.60508751869202 and batch: 200, loss is 3.723993740081787 and perplexity is 41.42952289455549
At time: 142.95829892158508 and batch: 250, loss is 3.8097458982467653 and perplexity is 45.13896751815004
At time: 143.3159019947052 and batch: 300, loss is 3.7698466968536377 and perplexity is 43.373415045152825
At time: 143.65441703796387 and batch: 350, loss is 3.752946710586548 and perplexity is 42.64656411147907
At time: 143.99471020698547 and batch: 400, loss is 3.5386615228652953 and perplexity is 34.42081686795202
At time: 144.3122251033783 and batch: 450, loss is 3.644073348045349 and perplexity is 38.24731447658915
At time: 144.6674280166626 and batch: 500, loss is 3.6246142530441285 and perplexity is 37.510250903366114
At time: 145.001558303833 and batch: 550, loss is 3.6814577436447142 and perplexity is 39.7042304966656
At time: 145.34695386886597 and batch: 600, loss is 3.617490611076355 and perplexity is 37.243990802598
At time: 145.69474601745605 and batch: 650, loss is 3.6622257137298586 and perplexity is 38.94793342286561
At time: 146.04243206977844 and batch: 700, loss is 3.724742765426636 and perplexity is 41.460566281919085
At time: 146.3966941833496 and batch: 750, loss is 3.678573975563049 and perplexity is 39.58989763801027
At time: 146.74043679237366 and batch: 800, loss is 3.5927538156509398 and perplexity is 36.33399540863209
At time: 147.08566236495972 and batch: 850, loss is 3.5514887285232546 and perplexity is 34.86518366408379
At time: 147.42699646949768 and batch: 900, loss is 3.445950818061829 and perplexity is 31.373099379204817
At time: 147.80161046981812 and batch: 950, loss is 3.602526292800903 and perplexity is 36.69080918609595
At time: 148.12009501457214 and batch: 1000, loss is 3.6235275411605836 and perplexity is 37.469510208662584
At time: 148.46411156654358 and batch: 1050, loss is 3.555267744064331 and perplexity is 34.997189003009645
At time: 148.79510259628296 and batch: 1100, loss is 3.7048623752593994 and perplexity is 40.644453249611246
At time: 149.14141535758972 and batch: 1150, loss is 3.60590793132782 and perplexity is 36.815094265191036
At time: 149.46738171577454 and batch: 1200, loss is 3.556092801094055 and perplexity is 35.02607559472129
At time: 149.79577207565308 and batch: 1250, loss is 3.420559649467468 and perplexity is 30.58652796606618
At time: 150.14833331108093 and batch: 1300, loss is 3.542265625 and perplexity is 34.545096831817226
At time: 150.4758381843567 and batch: 1350, loss is 3.5430127954483033 and perplexity is 34.570917552342166
At time: 150.81786823272705 and batch: 1400, loss is 3.389808168411255 and perplexity is 29.6602619494223
At time: 151.16761875152588 and batch: 1450, loss is 3.498343572616577 and perplexity is 33.06064402246832
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.291805430355235 and perplexity of 73.09832336835164
Finished 14 epochs...
Completing Train Step...
At time: 152.348552942276 and batch: 50, loss is 3.7056982851028444 and perplexity is 40.678442552181174
At time: 152.6863992214203 and batch: 100, loss is 3.7493116283416748 and perplexity is 42.4918217644465
At time: 153.0244128704071 and batch: 150, loss is 3.572434787750244 and perplexity is 35.60317387763775
At time: 153.38267731666565 and batch: 200, loss is 3.7197370815277098 and perplexity is 41.253546363250585
At time: 153.73708248138428 and batch: 250, loss is 3.8055008697509765 and perplexity is 44.94775744800119
At time: 154.09312176704407 and batch: 300, loss is 3.7655708360672 and perplexity is 43.188352293826284
At time: 154.43759202957153 and batch: 350, loss is 3.7487915897369386 and perplexity is 42.469730121494884
At time: 154.7653844356537 and batch: 400, loss is 3.53448082447052 and perplexity is 34.277214203000824
At time: 155.11996722221375 and batch: 450, loss is 3.6399572706222534 and perplexity is 38.09020911969205
At time: 155.46739172935486 and batch: 500, loss is 3.6206878852844238 and perplexity is 37.36326062135077
At time: 155.81496739387512 and batch: 550, loss is 3.6775057315826416 and perplexity is 39.54762854904304
At time: 156.17231583595276 and batch: 600, loss is 3.6138061571121214 and perplexity is 37.10701952018475
At time: 156.52781891822815 and batch: 650, loss is 3.6586531257629393 and perplexity is 38.80903676258389
At time: 156.86593961715698 and batch: 700, loss is 3.7212230825424193 and perplexity is 41.31489474559683
At time: 157.2226288318634 and batch: 750, loss is 3.675237731933594 and perplexity is 39.458036177510664
At time: 157.56612920761108 and batch: 800, loss is 3.5896611261367797 and perplexity is 36.221799225431084
At time: 157.95564723014832 and batch: 850, loss is 3.54868613243103 and perplexity is 34.76760743384099
At time: 158.30686807632446 and batch: 900, loss is 3.4434203052520753 and perplexity is 31.293809713412465
At time: 158.67135000228882 and batch: 950, loss is 3.600313925743103 and perplexity is 36.60972537517721
At time: 159.01233625411987 and batch: 1000, loss is 3.6215355300903322 and perplexity is 37.394944821725105
At time: 159.37523102760315 and batch: 1050, loss is 3.553393478393555 and perplexity is 34.93165640502096
At time: 159.7175316810608 and batch: 1100, loss is 3.70328800201416 and perplexity is 40.58051405513314
At time: 160.05656123161316 and batch: 1150, loss is 3.6046133470535278 and perplexity is 36.76746485989032
At time: 160.40374398231506 and batch: 1200, loss is 3.5549627685546876 and perplexity is 34.98651734483727
At time: 160.76920413970947 and batch: 1250, loss is 3.4197729778289796 and perplexity is 30.56247587378525
At time: 161.12709259986877 and batch: 1300, loss is 3.5415740633010864 and perplexity is 34.5212150247864
At time: 161.45513200759888 and batch: 1350, loss is 3.5425978660583497 and perplexity is 34.556576038175656
At time: 161.7997326850891 and batch: 1400, loss is 3.3897988033294677 and perplexity is 29.659984179943976
At time: 162.13356375694275 and batch: 1450, loss is 3.498501725196838 and perplexity is 33.06587306210772
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.291860727163462 and perplexity of 73.1023655840804
Annealing...
Finished 15 epochs...
Completing Train Step...
At time: 163.29480695724487 and batch: 50, loss is 3.704894127845764 and perplexity is 40.64574383661292
At time: 163.6197543144226 and batch: 100, loss is 3.750203046798706 and perplexity is 42.52971664622938
At time: 163.9657392501831 and batch: 150, loss is 3.5736516094207764 and perplexity is 35.64652295985436
At time: 164.32721877098083 and batch: 200, loss is 3.7212129640579223 and perplexity is 41.31447670358983
At time: 164.64823365211487 and batch: 250, loss is 3.808521475791931 and perplexity is 45.08373217533058
At time: 164.9888379573822 and batch: 300, loss is 3.76665461063385 and perplexity is 43.235184104596655
At time: 165.35625076293945 and batch: 350, loss is 3.7497739696502688 and perplexity is 42.51147203114059
At time: 165.72130966186523 and batch: 400, loss is 3.5338676166534424 and perplexity is 34.25620159051145
At time: 166.04803204536438 and batch: 450, loss is 3.6417184686660766 and perplexity is 38.15735263063696
At time: 166.3881800174713 and batch: 500, loss is 3.6194882202148437 and perplexity is 37.31846409848217
At time: 166.73231863975525 and batch: 550, loss is 3.6798186349868773 and perplexity is 39.63920425580167
At time: 167.09142017364502 and batch: 600, loss is 3.6133779525756835 and perplexity is 37.091133527562306
At time: 167.42531538009644 and batch: 650, loss is 3.658781580924988 and perplexity is 38.81402230389258
At time: 167.75661945343018 and batch: 700, loss is 3.7197645616531374 and perplexity is 41.254680031455585
At time: 168.089013338089 and batch: 750, loss is 3.674536037445068 and perplexity is 39.4303584028035
At time: 168.4332456588745 and batch: 800, loss is 3.5867435836791994 and perplexity is 36.11627459944186
At time: 168.77990055084229 and batch: 850, loss is 3.5480138731002806 and perplexity is 34.7442424398833
At time: 169.10885739326477 and batch: 900, loss is 3.4406580829620363 and perplexity is 31.207488528717032
At time: 169.43576741218567 and batch: 950, loss is 3.5974279260635376 and perplexity is 36.504222034007924
At time: 169.7827649116516 and batch: 1000, loss is 3.6152870225906373 and perplexity is 37.162010731646674
At time: 170.12797498703003 and batch: 1050, loss is 3.5458253765106202 and perplexity is 34.66828792720472
At time: 170.47113013267517 and batch: 1100, loss is 3.697439079284668 and perplexity is 40.3438545403835
At time: 170.8210096359253 and batch: 1150, loss is 3.5964902877807616 and perplexity is 36.47001031955896
At time: 171.16920137405396 and batch: 1200, loss is 3.5467229795455935 and perplexity is 34.69942025781247
At time: 171.52651524543762 and batch: 1250, loss is 3.410523085594177 and perplexity is 30.28107971396443
At time: 171.89262318611145 and batch: 1300, loss is 3.5318572235107424 and perplexity is 34.18740233768404
At time: 172.22475004196167 and batch: 1350, loss is 3.532698588371277 and perplexity is 34.21617852062095
At time: 172.56442284584045 and batch: 1400, loss is 3.377222418785095 and perplexity is 29.289304603477426
At time: 172.90207028388977 and batch: 1450, loss is 3.4856325292587282 and perplexity is 32.64306827687998
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.28900146484375 and perplexity of 72.89364527993187
Finished 16 epochs...
Completing Train Step...
At time: 174.1141529083252 and batch: 50, loss is 3.7030297756195067 and perplexity is 40.570036448151065
At time: 174.47161149978638 and batch: 100, loss is 3.7473874378204344 and perplexity is 42.41013801652676
At time: 174.8047788143158 and batch: 150, loss is 3.5705756330490113 and perplexity is 35.537043561836136
At time: 175.13003134727478 and batch: 200, loss is 3.718676652908325 and perplexity is 41.2098231088283
At time: 175.4904646873474 and batch: 250, loss is 3.8048990392684936 and perplexity is 44.9207146558543
At time: 175.8384599685669 and batch: 300, loss is 3.764290814399719 and perplexity is 43.13310563311205
At time: 176.1957449913025 and batch: 350, loss is 3.747271499633789 and perplexity is 42.40522134705012
At time: 176.51916766166687 and batch: 400, loss is 3.531399087905884 and perplexity is 34.17174345865441
At time: 176.86024689674377 and batch: 450, loss is 3.6389236354827883 and perplexity is 38.05085808188765
At time: 177.19952297210693 and batch: 500, loss is 3.617159628868103 and perplexity is 37.2316657440781
At time: 177.54885816574097 and batch: 550, loss is 3.6769367837905884 and perplexity is 39.5251344127005
At time: 177.89090061187744 and batch: 600, loss is 3.6108792209625244 and perplexity is 36.9985684354721
At time: 178.2275311946869 and batch: 650, loss is 3.6560530996322633 and perplexity is 38.70826331646158
At time: 178.5704321861267 and batch: 700, loss is 3.7177366828918457 and perplexity is 41.17110531035716
At time: 178.9184606075287 and batch: 750, loss is 3.672162675857544 and perplexity is 39.336886869537146
At time: 179.2681884765625 and batch: 800, loss is 3.5850909519195557 and perplexity is 36.056636990075944
At time: 179.61508536338806 and batch: 850, loss is 3.545919680595398 and perplexity is 34.67155744253041
At time: 179.94214487075806 and batch: 900, loss is 3.4391975927352907 and perplexity is 31.16194356380337
At time: 180.2700595855713 and batch: 950, loss is 3.59586630821228 and perplexity is 36.447260876589176
At time: 180.59882044792175 and batch: 1000, loss is 3.6143303537368774 and perplexity is 37.12647599363532
At time: 180.9415168762207 and batch: 1050, loss is 3.5455446290969848 and perplexity is 34.658556261167945
At time: 181.28371667861938 and batch: 1100, loss is 3.697266459465027 and perplexity is 40.33689099252959
At time: 181.6343128681183 and batch: 1150, loss is 3.596320643424988 and perplexity is 36.46382391291256
At time: 181.97708010673523 and batch: 1200, loss is 3.546948847770691 and perplexity is 34.707258639465365
At time: 182.3194489479065 and batch: 1250, loss is 3.4110694122314453 and perplexity is 30.297627594279724
At time: 182.6485333442688 and batch: 1300, loss is 3.5323774576187135 and perplexity is 34.205192417544964
At time: 182.98286771774292 and batch: 1350, loss is 3.5334264993667603 and perplexity is 34.24109392018606
At time: 183.332861661911 and batch: 1400, loss is 3.378672471046448 and perplexity is 29.33180643334119
At time: 183.66449809074402 and batch: 1450, loss is 3.487737135887146 and perplexity is 32.7118414395893
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.288462320963542 and perplexity of 72.85435570949059
Finished 17 epochs...
Completing Train Step...
At time: 184.8744764328003 and batch: 50, loss is 3.7022708368301394 and perplexity is 40.5392579547781
At time: 185.24219632148743 and batch: 100, loss is 3.7462163829803465 and perplexity is 42.360502487769196
At time: 185.5978307723999 and batch: 150, loss is 3.5691554307937623 and perplexity is 35.48660959411909
At time: 185.94032645225525 and batch: 200, loss is 3.7175035858154297 and perplexity is 41.1615095644901
At time: 186.27346229553223 and batch: 250, loss is 3.803246750831604 and perplexity is 44.84655396275137
At time: 186.61497020721436 and batch: 300, loss is 3.763091607093811 and perplexity is 43.08141110013627
At time: 186.95208859443665 and batch: 350, loss is 3.745978345870972 and perplexity is 42.35042031621844
At time: 187.29935574531555 and batch: 400, loss is 3.5300731897354125 and perplexity is 34.12646523031411
At time: 187.64237928390503 and batch: 450, loss is 3.637461667060852 and perplexity is 37.99526957316755
At time: 187.98322820663452 and batch: 500, loss is 3.6159698963165283 and perplexity is 37.18739635897908
At time: 188.30792665481567 and batch: 550, loss is 3.675550060272217 and perplexity is 39.47036196514151
At time: 188.64594388008118 and batch: 600, loss is 3.6096859073638914 and perplexity is 36.954443873084365
At time: 188.9875066280365 and batch: 650, loss is 3.654672498703003 and perplexity is 38.654859525301234
At time: 189.31922101974487 and batch: 700, loss is 3.716682586669922 and perplexity is 41.12772986875792
At time: 189.67631030082703 and batch: 750, loss is 3.6710485887527464 and perplexity is 39.293086554346466
At time: 190.00821018218994 and batch: 800, loss is 3.5842435503005983 and perplexity is 36.02609547980664
At time: 190.37133193016052 and batch: 850, loss is 3.5450032806396483 and perplexity is 34.6397989827724
At time: 190.70842838287354 and batch: 900, loss is 3.438539967536926 and perplexity is 31.141457421325857
At time: 191.05104160308838 and batch: 950, loss is 3.5951535081863404 and perplexity is 36.42129052502414
At time: 191.4201214313507 and batch: 1000, loss is 3.6139006996154786 and perplexity is 37.1105278765441
At time: 191.79459977149963 and batch: 1050, loss is 3.545421280860901 and perplexity is 34.65428145303836
At time: 192.13695621490479 and batch: 1100, loss is 3.697211389541626 and perplexity is 40.33466970419605
At time: 192.48386907577515 and batch: 1150, loss is 3.596322622299194 and perplexity is 36.46389607030456
At time: 192.8218274116516 and batch: 1200, loss is 3.547135286331177 and perplexity is 34.71373001404266
At time: 193.1818745136261 and batch: 1250, loss is 3.411399278640747 and perplexity is 30.3076234124563
At time: 193.5245304107666 and batch: 1300, loss is 3.532786350250244 and perplexity is 34.219181528511875
At time: 193.86939477920532 and batch: 1350, loss is 3.533939824104309 and perplexity is 34.2586752328113
At time: 194.23051595687866 and batch: 1400, loss is 3.3794838571548462 and perplexity is 29.35561551148684
At time: 194.5687072277069 and batch: 1450, loss is 3.488827652931213 and perplexity is 32.7475337182039
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.288262261284722 and perplexity of 72.83978194834633
Finished 18 epochs...
Completing Train Step...
At time: 195.7180507183075 and batch: 50, loss is 3.701593108177185 and perplexity is 40.51179264615721
At time: 196.08110809326172 and batch: 100, loss is 3.7453067827224733 and perplexity is 42.32198888243078
At time: 196.42505168914795 and batch: 150, loss is 3.5681307125091553 and perplexity is 35.450264441360915
At time: 196.783358335495 and batch: 200, loss is 3.7165914726257325 and perplexity is 41.12398272567252
At time: 197.13984489440918 and batch: 250, loss is 3.802094507217407 and perplexity is 44.794909566505815
At time: 197.49137949943542 and batch: 300, loss is 3.7621692609786987 and perplexity is 43.041693447501544
At time: 197.8486566543579 and batch: 350, loss is 3.744999508857727 and perplexity is 42.30898643910094
At time: 198.2065703868866 and batch: 400, loss is 3.5290896224975588 and perplexity is 34.092916058807425
At time: 198.56617975234985 and batch: 450, loss is 3.6364229488372803 and perplexity is 37.955823684380775
At time: 198.92184162139893 and batch: 500, loss is 3.6151081943511962 and perplexity is 37.155365708870015
At time: 199.26962280273438 and batch: 550, loss is 3.6746154117584227 and perplexity is 39.43348828464151
At time: 199.6197898387909 and batch: 600, loss is 3.6088630151748657 and perplexity is 36.924046858319706
At time: 199.96243333816528 and batch: 650, loss is 3.6537439012527466 and perplexity is 38.61898138206031
At time: 200.30528950691223 and batch: 700, loss is 3.7159235286712646 and perplexity is 41.096523381699576
At time: 200.64742875099182 and batch: 750, loss is 3.6702833127975465 and perplexity is 39.2630280030111
At time: 200.99337697029114 and batch: 800, loss is 3.5836310243606566 and perplexity is 36.00403531871063
At time: 201.34058666229248 and batch: 850, loss is 3.5444031381607055 and perplexity is 34.619016404818495
At time: 201.66024732589722 and batch: 900, loss is 3.4381004095077516 and perplexity is 31.127771951675502
At time: 202.0100610256195 and batch: 950, loss is 3.594688391685486 and perplexity is 36.404354320777884
At time: 202.362078666687 and batch: 1000, loss is 3.6135789060592653 and perplexity is 37.09858786901753
At time: 202.70948338508606 and batch: 1050, loss is 3.5452839708328248 and perplexity is 34.6495233993508
At time: 203.05234956741333 and batch: 1100, loss is 3.697140498161316 and perplexity is 40.33181042513669
At time: 203.39811611175537 and batch: 1150, loss is 3.5963031339645384 and perplexity is 36.46318545661945
At time: 203.72890853881836 and batch: 1200, loss is 3.5472288608551024 and perplexity is 34.71697848678718
At time: 204.0692856311798 and batch: 1250, loss is 3.411591968536377 and perplexity is 30.313463947936448
At time: 204.395663022995 and batch: 1300, loss is 3.5330481576919555 and perplexity is 34.22814153773268
At time: 204.74975061416626 and batch: 1350, loss is 3.534265170097351 and perplexity is 34.26982296886251
At time: 205.10480499267578 and batch: 1400, loss is 3.3799707746505736 and perplexity is 29.3699127547837
At time: 205.44707131385803 and batch: 1450, loss is 3.489444580078125 and perplexity is 32.7677427938718
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.288161318526309 and perplexity of 72.83242967092006
Finished 19 epochs...
Completing Train Step...
At time: 206.57255172729492 and batch: 50, loss is 3.7009388828277587 and perplexity is 40.485297472309604
At time: 206.93956637382507 and batch: 100, loss is 3.744503073692322 and perplexity is 42.287987983037176
At time: 207.28196907043457 and batch: 150, loss is 3.567273588180542 and perplexity is 35.41989217551589
At time: 207.62730765342712 and batch: 200, loss is 3.7157951259613036 and perplexity is 41.091246815497335
At time: 207.97329354286194 and batch: 250, loss is 3.8011590909957884 and perplexity is 44.753027273193574
At time: 208.32931637763977 and batch: 300, loss is 3.7613677167892456 and perplexity is 43.007207451085854
At time: 208.67523956298828 and batch: 350, loss is 3.7441664648056032 and perplexity is 42.27375586594356
At time: 209.029940366745 and batch: 400, loss is 3.528264536857605 and perplexity is 34.0647980848066
At time: 209.39126420021057 and batch: 450, loss is 3.635575089454651 and perplexity is 37.92365612185642
At time: 209.75771045684814 and batch: 500, loss is 3.6143858528137205 and perplexity is 37.12853653595797
At time: 210.1034128665924 and batch: 550, loss is 3.67386700630188 and perplexity is 39.40398708764417
At time: 210.4544575214386 and batch: 600, loss is 3.6081847763061523 and perplexity is 36.899012025308295
At time: 210.78710103034973 and batch: 650, loss is 3.6530131196975706 and perplexity is 38.590769652347994
At time: 211.1309130191803 and batch: 700, loss is 3.7152899265289308 and perplexity is 41.07049278383458
At time: 211.48797035217285 and batch: 750, loss is 3.669657139778137 and perplexity is 39.23845024998128
At time: 211.84453916549683 and batch: 800, loss is 3.5831135749816894 and perplexity is 35.98540987227308
At time: 212.19064497947693 and batch: 850, loss is 3.543917655944824 and perplexity is 34.60221356709212
At time: 212.53099155426025 and batch: 900, loss is 3.437730917930603 and perplexity is 31.116272626706635
At time: 212.88109254837036 and batch: 950, loss is 3.5943175888061525 and perplexity is 36.39085798377042
At time: 213.23658108711243 and batch: 1000, loss is 3.6132903623580934 and perplexity is 37.08788484938426
At time: 213.58070874214172 and batch: 1050, loss is 3.545121750831604 and perplexity is 34.643903009504804
At time: 213.92883229255676 and batch: 1100, loss is 3.697045297622681 and perplexity is 40.32797099782076
At time: 214.26148319244385 and batch: 1150, loss is 3.596249384880066 and perplexity is 36.46122564645368
At time: 214.6056191921234 and batch: 1200, loss is 3.547256202697754 and perplexity is 34.71792772592722
At time: 214.95165133476257 and batch: 1250, loss is 3.4116994380950927 and perplexity is 30.31672189759215
At time: 215.28795647621155 and batch: 1300, loss is 3.5332048749923706 and perplexity is 34.23350610002158
At time: 215.61640524864197 and batch: 1350, loss is 3.5344685316085815 and perplexity is 34.27679284052887
At time: 215.94340872764587 and batch: 1400, loss is 3.3802815198898317 and perplexity is 29.37904073351419
At time: 216.26658487319946 and batch: 1450, loss is 3.489822940826416 and perplexity is 32.78014316731445
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.288104978382078 and perplexity of 72.82832639691833
Finished 20 epochs...
Completing Train Step...
At time: 217.52636861801147 and batch: 50, loss is 3.700302233695984 and perplexity is 40.45953074587654
At time: 217.88385677337646 and batch: 100, loss is 3.7437635183334352 and perplexity is 42.25672523659853
At time: 218.214985370636 and batch: 150, loss is 3.5665089321136474 and perplexity is 35.3928184924223
At time: 218.56251096725464 and batch: 200, loss is 3.715069260597229 and perplexity is 41.06143092513749
At time: 218.89821577072144 and batch: 250, loss is 3.8003452825546264 and perplexity is 44.71662169742277
At time: 219.22750639915466 and batch: 300, loss is 3.7606377840042113 and perplexity is 42.97582653474768
At time: 219.5828332901001 and batch: 350, loss is 3.743420991897583 and perplexity is 42.24225366970106
At time: 219.9291708469391 and batch: 400, loss is 3.5275292444229125 and perplexity is 34.039759702880005
At time: 220.26949524879456 and batch: 450, loss is 3.634830508232117 and perplexity is 37.89542938946977
At time: 220.5909411907196 and batch: 500, loss is 3.6137362575531005 and perplexity is 37.10442584653309
At time: 220.9442412853241 and batch: 550, loss is 3.673210597038269 and perplexity is 39.37813043269897
At time: 221.29863357543945 and batch: 600, loss is 3.607576599121094 and perplexity is 36.87657771075394
At time: 221.6295804977417 and batch: 650, loss is 3.6523837566375734 and perplexity is 38.56648968872948
At time: 221.9589183330536 and batch: 700, loss is 3.714721746444702 and perplexity is 41.047163975894975
At time: 222.29149198532104 and batch: 750, loss is 3.6691015005111693 and perplexity is 39.21665388226709
At time: 222.6266312599182 and batch: 800, loss is 3.582643232345581 and perplexity is 35.968488379494026
At time: 222.95523023605347 and batch: 850, loss is 3.5434837913513184 and perplexity is 34.58720414803163
At time: 223.31422758102417 and batch: 900, loss is 3.4373872232437135 and perplexity is 31.1055799667395
At time: 223.64411854743958 and batch: 950, loss is 3.593988356590271 and perplexity is 36.3788789130148
At time: 224.00217962265015 and batch: 1000, loss is 3.6130155611038206 and perplexity is 37.077694452340396
At time: 224.35333466529846 and batch: 1050, loss is 3.5449392890930174 and perplexity is 34.63758239938256
At time: 224.69711709022522 and batch: 1100, loss is 3.6969287633895873 and perplexity is 40.32327168246919
At time: 225.02649569511414 and batch: 1150, loss is 3.5961682558059693 and perplexity is 36.45826770096586
At time: 225.3439393043518 and batch: 1200, loss is 3.54723774433136 and perplexity is 34.717286895611174
At time: 225.6887664794922 and batch: 1250, loss is 3.411750068664551 and perplexity is 30.318256889344358
At time: 226.03194165229797 and batch: 1300, loss is 3.5332903242111207 and perplexity is 34.236431451355614
At time: 226.37658095359802 and batch: 1350, loss is 3.5345928955078123 and perplexity is 34.281055901219574
At time: 226.69919276237488 and batch: 1400, loss is 3.3804885387420653 and perplexity is 29.385123378395928
At time: 227.04958868026733 and batch: 1450, loss is 3.4900694847106934 and perplexity is 32.788225907472224
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2880736783019495 and perplexity of 72.82604690014088
Finished 21 epochs...
Completing Train Step...
At time: 228.3013813495636 and batch: 50, loss is 3.6996806287765502 and perplexity is 40.43438871754073
At time: 228.67014408111572 and batch: 100, loss is 3.7430691623687746 and perplexity is 42.22739421164798
At time: 229.03187561035156 and batch: 150, loss is 3.565803017616272 and perplexity is 35.367843005061964
At time: 229.3864483833313 and batch: 200, loss is 3.714391493797302 and perplexity is 41.033610279518925
At time: 229.72288584709167 and batch: 250, loss is 3.7996086645126343 and perplexity is 44.68369475588198
At time: 230.0504970550537 and batch: 300, loss is 3.7599567317962648 and perplexity is 42.946567717719766
At time: 230.3860833644867 and batch: 350, loss is 3.7427342081069948 and perplexity is 42.21325233456615
At time: 230.7223060131073 and batch: 400, loss is 3.526851315498352 and perplexity is 34.01669098555121
At time: 231.06969451904297 and batch: 450, loss is 3.6341494369506835 and perplexity is 37.86962868787079
At time: 231.40084290504456 and batch: 500, loss is 3.6131306505203247 and perplexity is 37.08196194812732
At time: 231.74204182624817 and batch: 550, loss is 3.6726067304611205 and perplexity is 39.35435847412807
At time: 232.0807580947876 and batch: 600, loss is 3.6070095109939575 and perplexity is 36.85567136979389
At time: 232.4083023071289 and batch: 650, loss is 3.651812696456909 and perplexity is 38.54447218941716
At time: 232.7433466911316 and batch: 700, loss is 3.7141927337646483 and perplexity is 41.02545524827385
At time: 233.07696843147278 and batch: 750, loss is 3.66858766078949 and perplexity is 39.196507984075645
At time: 233.41971707344055 and batch: 800, loss is 3.582199926376343 and perplexity is 35.952546867635675
At time: 233.76991748809814 and batch: 850, loss is 3.54307767868042 and perplexity is 34.57316069798069
At time: 234.10883903503418 and batch: 900, loss is 3.4370545530319214 and perplexity is 31.095233787892223
At time: 234.44011735916138 and batch: 950, loss is 3.5936799955368044 and perplexity is 36.36766281298234
At time: 234.75952863693237 and batch: 1000, loss is 3.612747483253479 and perplexity is 37.06775607590481
At time: 235.119726896286 and batch: 1050, loss is 3.5447416257858277 and perplexity is 34.63073649690659
At time: 235.46087956428528 and batch: 1100, loss is 3.696795024871826 and perplexity is 40.31787926847786
At time: 235.82389521598816 and batch: 1150, loss is 3.5960665941238403 and perplexity is 36.45456148053737
At time: 236.14158248901367 and batch: 1200, loss is 3.54718665599823 and perplexity is 34.715513292598466
At time: 236.48674774169922 and batch: 1250, loss is 3.411760425567627 and perplexity is 30.318570894218453
At time: 236.8363959789276 and batch: 1300, loss is 3.53332573890686 and perplexity is 34.237643945628605
At time: 237.17803382873535 and batch: 1350, loss is 3.5346642446517946 and perplexity is 34.283501912472296
At time: 237.53290224075317 and batch: 1400, loss is 3.380629620552063 and perplexity is 29.389269377244787
At time: 237.8822009563446 and batch: 1450, loss is 3.4902369022369384 and perplexity is 32.79371569067376
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.288060114933894 and perplexity of 72.82505914036145
Finished 22 epochs...
Completing Train Step...
At time: 239.18290376663208 and batch: 50, loss is 3.6990722370147706 and perplexity is 40.409796250238195
At time: 239.5095009803772 and batch: 100, loss is 3.7424081707000734 and perplexity is 42.19949147863606
At time: 239.86343002319336 and batch: 150, loss is 3.565138177871704 and perplexity is 35.34433687212411
At time: 240.2123830318451 and batch: 200, loss is 3.71374888420105 and perplexity is 41.007250158324965
At time: 240.53841257095337 and batch: 250, loss is 3.7989252042770385 and perplexity is 44.65316566123633
At time: 240.8900008201599 and batch: 300, loss is 3.7593120241165163 and perplexity is 42.918888659102876
At time: 241.2466905117035 and batch: 350, loss is 3.7420895099639893 and perplexity is 42.18604629995814
At time: 241.5858039855957 and batch: 400, loss is 3.526213274002075 and perplexity is 33.99499384770961
At time: 241.93294835090637 and batch: 450, loss is 3.6335112285614013 and perplexity is 37.845467683841
At time: 242.27683877944946 and batch: 500, loss is 3.612554440498352 and perplexity is 37.060601104775415
At time: 242.60604619979858 and batch: 550, loss is 3.672036399841309 and perplexity is 39.331919877784735
At time: 242.94239830970764 and batch: 600, loss is 3.6064697885513306 and perplexity is 36.83578490388626
At time: 243.295658826828 and batch: 650, loss is 3.6512783765792847 and perplexity is 38.523882612953656
At time: 243.64879655838013 and batch: 700, loss is 3.7136897087097167 and perplexity is 41.00482360594554
At time: 243.99425172805786 and batch: 750, loss is 3.668101658821106 and perplexity is 39.177463032358496
At time: 244.33624935150146 and batch: 800, loss is 3.5817738008499145 and perplexity is 35.93722983339668
At time: 244.71119952201843 and batch: 850, loss is 3.5426886606216432 and perplexity is 34.55971372984648
At time: 245.0571804046631 and batch: 900, loss is 3.4367277956008913 and perplexity is 31.08507484902718
At time: 245.4106569290161 and batch: 950, loss is 3.5933825254440306 and perplexity is 36.35684612985102
At time: 245.76100945472717 and batch: 1000, loss is 3.61248348236084 and perplexity is 37.05797144684487
At time: 246.10407638549805 and batch: 1050, loss is 3.5445329999923705 and perplexity is 34.6235123856211
At time: 246.45422506332397 and batch: 1100, loss is 3.696647353172302 and perplexity is 40.31192589830804
At time: 246.8002679347992 and batch: 1150, loss is 3.5959492683410645 and perplexity is 36.45028467147081
At time: 247.12774872779846 and batch: 1200, loss is 3.5471114206314085 and perplexity is 34.7129015564702
At time: 247.48404240608215 and batch: 1250, loss is 3.4117411756515503 and perplexity is 30.31798726989055
At time: 247.83717966079712 and batch: 1300, loss is 3.533325185775757 and perplexity is 34.23762500772808
At time: 248.1970727443695 and batch: 1350, loss is 3.534698238372803 and perplexity is 34.28466735608027
At time: 248.53799986839294 and batch: 1400, loss is 3.380725870132446 and perplexity is 29.39209821822531
At time: 248.87344408035278 and batch: 1450, loss is 3.490353193283081 and perplexity is 32.79752952793159
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.288058810763889 and perplexity of 72.82496416416564
Finished 23 epochs...
Completing Train Step...
At time: 250.12560033798218 and batch: 50, loss is 3.6984754848480224 and perplexity is 40.385688810566855
At time: 250.48317980766296 and batch: 100, loss is 3.7417732858657837 and perplexity is 42.172708164541156
At time: 250.826340675354 and batch: 150, loss is 3.5645036935806274 and perplexity is 35.321918558386244
At time: 251.17246866226196 and batch: 200, loss is 3.7131330728530885 and perplexity is 40.98200520219179
At time: 251.52164316177368 and batch: 250, loss is 3.7982800340652467 and perplexity is 44.62436606021082
At time: 251.85257840156555 and batch: 300, loss is 3.7586948347091673 and perplexity is 42.89240774835669
At time: 252.20297956466675 and batch: 350, loss is 3.7414760875701902 and perplexity is 42.16017636986034
At time: 252.54124402999878 and batch: 400, loss is 3.5256048488616942 and perplexity is 33.97431672968265
At time: 252.87375593185425 and batch: 450, loss is 3.632904028892517 and perplexity is 37.8224949036327
At time: 253.20176243782043 and batch: 500, loss is 3.6119997787475584 and perplexity is 37.04005070666794
At time: 253.540922164917 and batch: 550, loss is 3.6714896154403687 and perplexity is 39.31041967605967
At time: 253.89126539230347 and batch: 600, loss is 3.6059505558013916 and perplexity is 36.81666352264773
At time: 254.21439218521118 and batch: 650, loss is 3.6507693910598755 and perplexity is 38.50427950382479
At time: 254.55440664291382 and batch: 700, loss is 3.7132056045532225 and perplexity is 40.984977804506656
At time: 254.8908393383026 and batch: 750, loss is 3.6676354885101317 and perplexity is 39.15920391849257
At time: 255.25091433525085 and batch: 800, loss is 3.581359820365906 and perplexity is 35.922355600629785
At time: 255.57363438606262 and batch: 850, loss is 3.5423112106323242 and perplexity is 34.54667162779376
At time: 255.90414762496948 and batch: 900, loss is 3.436404676437378 and perplexity is 31.075032288203523
At time: 256.22177362442017 and batch: 950, loss is 3.5930915212631227 and perplexity is 36.34626767488457
At time: 256.54911065101624 and batch: 1000, loss is 3.612221837043762 and perplexity is 37.04827667050712
At time: 256.8750903606415 and batch: 1050, loss is 3.5443160104751588 and perplexity is 34.61600026143994
At time: 257.21226382255554 and batch: 1100, loss is 3.696488356590271 and perplexity is 40.30551694938911
At time: 257.54500222206116 and batch: 1150, loss is 3.5958198499679566 and perplexity is 36.44556764017115
At time: 257.87469720840454 and batch: 1200, loss is 3.5470176839828493 and perplexity is 34.709647837915256
At time: 258.20751428604126 and batch: 1250, loss is 3.4116994380950927 and perplexity is 30.31672189759215
At time: 258.5664806365967 and batch: 1300, loss is 3.5332980394363402 and perplexity is 34.236695594153936
At time: 258.898508310318 and batch: 1350, loss is 3.534704942703247 and perplexity is 34.28489721258991
At time: 259.2333846092224 and batch: 1400, loss is 3.3807899713516236 and perplexity is 29.393982347942146
At time: 259.5597758293152 and batch: 1450, loss is 3.4904338550567626 and perplexity is 32.8001751415342
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.288065853281918 and perplexity of 72.82547703709463
Annealing...
Finished 24 epochs...
Completing Train Step...
At time: 260.76311349868774 and batch: 50, loss is 3.6983254671096804 and perplexity is 40.37963069529384
At time: 261.12026357650757 and batch: 100, loss is 3.741883592605591 and perplexity is 42.17736035506689
At time: 261.44006061553955 and batch: 150, loss is 3.5646742963790894 and perplexity is 35.32794509059637
At time: 261.7910430431366 and batch: 200, loss is 3.713489055633545 and perplexity is 40.99659668735699
At time: 262.1596326828003 and batch: 250, loss is 3.7986055707931516 and perplexity is 44.63889529509437
At time: 262.5202991962433 and batch: 300, loss is 3.75889030456543 and perplexity is 42.90079274061393
At time: 262.8827223777771 and batch: 350, loss is 3.741650342941284 and perplexity is 42.167523647171734
At time: 263.2282416820526 and batch: 400, loss is 3.525234203338623 and perplexity is 33.961726634662696
At time: 263.5671947002411 and batch: 450, loss is 3.6326623344421387 and perplexity is 37.81335452114938
At time: 263.8920702934265 and batch: 500, loss is 3.611229043006897 and perplexity is 37.01151361444352
At time: 264.21537685394287 and batch: 550, loss is 3.6713434839248658 and perplexity is 39.304675604562505
At time: 264.56344079971313 and batch: 600, loss is 3.605251097679138 and perplexity is 36.79092081233598
At time: 264.9234707355499 and batch: 650, loss is 3.650452208518982 and perplexity is 38.492068555268716
At time: 265.2816638946533 and batch: 700, loss is 3.7124106740951537 and perplexity is 40.95241054339545
At time: 265.6236367225647 and batch: 750, loss is 3.6673115205764772 and perplexity is 39.14651964687511
At time: 265.9758610725403 and batch: 800, loss is 3.5805002212524415 and perplexity is 35.89149004350528
At time: 266.3242471218109 and batch: 850, loss is 3.5419849824905394 and perplexity is 34.53540336941521
At time: 266.6408417224884 and batch: 900, loss is 3.435574326515198 and perplexity is 31.049239847418814
At time: 266.9785544872284 and batch: 950, loss is 3.592541537284851 and perplexity is 36.3262833060385
At time: 267.3211703300476 and batch: 1000, loss is 3.6108068466186523 and perplexity is 36.99589078525513
At time: 267.65605211257935 and batch: 1050, loss is 3.542505292892456 and perplexity is 34.5533771745961
At time: 267.98185110092163 and batch: 1100, loss is 3.6947356462478638 and perplexity is 40.23493492596602
At time: 268.34051728248596 and batch: 1150, loss is 3.594209351539612 and perplexity is 36.38691934993251
At time: 268.6902799606323 and batch: 1200, loss is 3.5451868200302123 and perplexity is 34.64615733385305
At time: 269.041695356369 and batch: 1250, loss is 3.409489183425903 and perplexity is 30.24978821895019
At time: 269.3861494064331 and batch: 1300, loss is 3.5312227630615234 and perplexity is 34.165718662483776
At time: 269.7452800273895 and batch: 1350, loss is 3.532672653198242 and perplexity is 34.215291129617796
At time: 270.0863847732544 and batch: 1400, loss is 3.378330960273743 and perplexity is 29.32179101574514
At time: 270.4458086490631 and batch: 1450, loss is 3.4878911781311035 and perplexity is 32.71688083317842
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287914830395299 and perplexity of 72.81447955378985
Finished 25 epochs...
Completing Train Step...
At time: 271.6186544895172 and batch: 50, loss is 3.6981605005264284 and perplexity is 40.37296995499995
At time: 271.9573698043823 and batch: 100, loss is 3.7417190885543823 and perplexity is 42.17042257908097
At time: 272.3041298389435 and batch: 150, loss is 3.5645107889175414 and perplexity is 35.32216918018799
At time: 272.6482446193695 and batch: 200, loss is 3.713290228843689 and perplexity is 40.98844627592955
At time: 273.0038697719574 and batch: 250, loss is 3.7983891677856447 and perplexity is 44.629236349050906
At time: 273.3740088939667 and batch: 300, loss is 3.7587528800964356 and perplexity is 42.89489752703469
At time: 273.72164392471313 and batch: 350, loss is 3.7414767503738404 and perplexity is 42.16020431378839
At time: 274.0620834827423 and batch: 400, loss is 3.5250750255584715 and perplexity is 33.956321112637795
At time: 274.39943981170654 and batch: 450, loss is 3.6325279378890993 and perplexity is 37.808272878128186
At time: 274.7519769668579 and batch: 500, loss is 3.6111079549789427 and perplexity is 37.007032234574545
At time: 275.06984996795654 and batch: 550, loss is 3.6711714935302733 and perplexity is 39.29791615919245
At time: 275.41884183883667 and batch: 600, loss is 3.6051115655899046 and perplexity is 36.78578765641853
At time: 275.74934124946594 and batch: 650, loss is 3.6503158807754517 and perplexity is 38.48682137609493
At time: 276.0838499069214 and batch: 700, loss is 3.712320590019226 and perplexity is 40.94872154949694
At time: 276.4167478084564 and batch: 750, loss is 3.667164912223816 and perplexity is 39.14078086080454
At time: 276.7494888305664 and batch: 800, loss is 3.580399351119995 and perplexity is 35.88786984673883
At time: 277.0995647907257 and batch: 850, loss is 3.541866102218628 and perplexity is 34.53129803529853
At time: 277.4525828361511 and batch: 900, loss is 3.435530228614807 and perplexity is 31.047870671321927
At time: 277.7916474342346 and batch: 950, loss is 3.5924711179733277 and perplexity is 36.3237253242446
At time: 278.1483271121979 and batch: 1000, loss is 3.6107610940933226 and perplexity is 36.99419816854592
At time: 278.4939787387848 and batch: 1050, loss is 3.5425169706344604 and perplexity is 34.55378068237616
At time: 278.83034491539 and batch: 1100, loss is 3.6947770738601684 and perplexity is 40.23660179777826
At time: 279.1696226596832 and batch: 1150, loss is 3.5942026710510255 and perplexity is 36.386676268345056
At time: 279.5030310153961 and batch: 1200, loss is 3.5452010869979858 and perplexity is 34.64665163298927
At time: 279.8608343601227 and batch: 1250, loss is 3.409578866958618 and perplexity is 30.252501248476758
At time: 280.1926670074463 and batch: 1300, loss is 3.5312923288345335 and perplexity is 34.16809550978563
At time: 280.5476062297821 and batch: 1350, loss is 3.532734456062317 and perplexity is 34.21740579795036
At time: 280.8993790149689 and batch: 1400, loss is 3.3784574270248413 and perplexity is 29.32549948188518
At time: 281.2342164516449 and batch: 1450, loss is 3.48800244808197 and perplexity is 32.72052144144263
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287802671774839 and perplexity of 72.80631324018341
Finished 26 epochs...
Completing Train Step...
At time: 282.40681743621826 and batch: 50, loss is 3.698015422821045 and perplexity is 40.36711316201469
At time: 282.7558264732361 and batch: 100, loss is 3.7415692520141604 and perplexity is 42.16410438222223
At time: 283.1126947402954 and batch: 150, loss is 3.5643638372421265 and perplexity is 35.316978909616495
At time: 283.46373772621155 and batch: 200, loss is 3.7131314039230348 and perplexity is 40.981936806148724
At time: 283.81932640075684 and batch: 250, loss is 3.7981940126419067 and perplexity is 44.620527573825065
At time: 284.1677806377411 and batch: 300, loss is 3.7586210203170776 and perplexity is 42.88924178820162
At time: 284.49151945114136 and batch: 350, loss is 3.741324372291565 and perplexity is 42.153780512142426
At time: 284.8410429954529 and batch: 400, loss is 3.524935455322266 and perplexity is 33.95158215159607
At time: 285.1858274936676 and batch: 450, loss is 3.632407464981079 and perplexity is 37.80371827990569
At time: 285.510910987854 and batch: 500, loss is 3.610999035835266 and perplexity is 37.00300167981981
At time: 285.83549451828003 and batch: 550, loss is 3.6710288429260256 and perplexity is 39.29231068752813
At time: 286.17183327674866 and batch: 600, loss is 3.60499165058136 and perplexity is 36.78137675284944
At time: 286.52318716049194 and batch: 650, loss is 3.650193042755127 and perplexity is 38.48209402150388
At time: 286.84681820869446 and batch: 700, loss is 3.71223566532135 and perplexity is 40.94524413935204
At time: 287.20250725746155 and batch: 750, loss is 3.6670369863510133 and perplexity is 39.13577406250708
At time: 287.56234765052795 and batch: 800, loss is 3.5803120851516725 and perplexity is 35.88473819367097
At time: 287.9382905960083 and batch: 850, loss is 3.54176212310791 and perplexity is 34.527707688300666
At time: 288.2796895503998 and batch: 900, loss is 3.4354839611053465 and perplexity is 31.046434196903217
At time: 288.65374755859375 and batch: 950, loss is 3.5924098110198974 and perplexity is 36.32149849556847
At time: 289.00644183158875 and batch: 1000, loss is 3.610724401473999 and perplexity is 36.992840779418586
At time: 289.3466773033142 and batch: 1050, loss is 3.5425260353088377 and perplexity is 34.554093902566166
At time: 289.67507147789 and batch: 1100, loss is 3.6948097801208495 and perplexity is 40.23791780808635
At time: 290.02974915504456 and batch: 1150, loss is 3.5942034912109375 and perplexity is 36.3867061112505
At time: 290.3774936199188 and batch: 1200, loss is 3.545214819908142 and perplexity is 34.64712743561042
At time: 290.72049498558044 and batch: 1250, loss is 3.4096536159515383 and perplexity is 30.2547626769971
At time: 291.0641498565674 and batch: 1300, loss is 3.531345400810242 and perplexity is 34.16990892624089
At time: 291.4185104370117 and batch: 1350, loss is 3.5327898120880126 and perplexity is 34.219299989971944
At time: 291.75422263145447 and batch: 1400, loss is 3.3785657358169554 and perplexity is 29.328675863324122
At time: 292.08674907684326 and batch: 1450, loss is 3.4880977964401243 and perplexity is 32.72364143818094
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287720509064504 and perplexity of 72.8003315218985
Finished 27 epochs...
Completing Train Step...
At time: 293.2781901359558 and batch: 50, loss is 3.697884397506714 and perplexity is 40.36182439481276
At time: 293.6056308746338 and batch: 100, loss is 3.741430697441101 and perplexity is 42.15826275744238
At time: 293.93388080596924 and batch: 150, loss is 3.5642270183563234 and perplexity is 35.31214721045353
At time: 294.26364254951477 and batch: 200, loss is 3.712993884086609 and perplexity is 40.976301364404115
At time: 294.58954191207886 and batch: 250, loss is 3.7980163955688475 and perplexity is 44.612602910117666
At time: 294.9373743534088 and batch: 300, loss is 3.7584955501556396 and perplexity is 42.88386080569394
At time: 295.3077745437622 and batch: 350, loss is 3.7411856126785277 and perplexity is 42.14793167567104
At time: 295.6568627357483 and batch: 400, loss is 3.524806733131409 and perplexity is 33.947212110825106
At time: 296.0012581348419 and batch: 450, loss is 3.632293658256531 and perplexity is 37.79941620735954
At time: 296.3449716567993 and batch: 500, loss is 3.610896887779236 and perplexity is 36.99922208817319
At time: 296.67404198646545 and batch: 550, loss is 3.670902271270752 and perplexity is 39.287337709450554
At time: 297.00558161735535 and batch: 600, loss is 3.6048834848403932 and perplexity is 36.777398483139315
At time: 297.32587933540344 and batch: 650, loss is 3.6500797700881957 and perplexity is 38.4777352989517
At time: 297.6988260746002 and batch: 700, loss is 3.712154598236084 and perplexity is 40.94192496229398
At time: 298.04718494415283 and batch: 750, loss is 3.666923232078552 and perplexity is 39.13132245420093
At time: 298.3984537124634 and batch: 800, loss is 3.5802330446243285 and perplexity is 35.88190195713083
At time: 298.74164605140686 and batch: 850, loss is 3.541669039726257 and perplexity is 34.52449388208661
At time: 299.07484436035156 and batch: 900, loss is 3.435436935424805 and perplexity is 31.04497425153445
At time: 299.4074468612671 and batch: 950, loss is 3.5923549461364748 and perplexity is 36.31950577545346
At time: 299.76141834259033 and batch: 1000, loss is 3.6106916666030884 and perplexity is 36.99162984337107
At time: 300.10427141189575 and batch: 1050, loss is 3.542531714439392 and perplexity is 34.55429014033385
At time: 300.4361686706543 and batch: 1100, loss is 3.6948344612121584 and perplexity is 40.238910936065544
At time: 300.77334904670715 and batch: 1150, loss is 3.5942055797576904 and perplexity is 36.38678210666676
At time: 301.12586283683777 and batch: 1200, loss is 3.545227470397949 and perplexity is 34.64756574151529
At time: 301.48314595222473 and batch: 1250, loss is 3.40971586227417 and perplexity is 30.256645983329683
At time: 301.8249409198761 and batch: 1300, loss is 3.5313884353637697 and perplexity is 34.17137944465695
At time: 302.1732087135315 and batch: 1350, loss is 3.5328384399414063 and perplexity is 34.220964041534394
At time: 302.49207973480225 and batch: 1400, loss is 3.378657898902893 and perplexity is 29.331379009161367
At time: 302.82848262786865 and batch: 1450, loss is 3.4881810045242307 and perplexity is 32.7263644229756
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.28765869140625 and perplexity of 72.79583131498129
Finished 28 epochs...
Completing Train Step...
At time: 304.0619418621063 and batch: 50, loss is 3.697763967514038 and perplexity is 40.356963913276246
At time: 304.4169156551361 and batch: 100, loss is 3.7413014459609983 and perplexity is 42.152814091714056
At time: 304.7649984359741 and batch: 150, loss is 3.564097776412964 and perplexity is 35.30758369482903
At time: 305.12664270401 and batch: 200, loss is 3.712868824005127 and perplexity is 40.971177185238474
At time: 305.4781086444855 and batch: 250, loss is 3.7978536796569826 and perplexity is 44.60534432031453
At time: 305.80021357536316 and batch: 300, loss is 3.7583764934539796 and perplexity is 42.87875549858851
At time: 306.12458777427673 and batch: 350, loss is 3.74105703830719 and perplexity is 42.14251288021923
At time: 306.47986006736755 and batch: 400, loss is 3.524685378074646 and perplexity is 33.94309269493349
At time: 306.82444286346436 and batch: 450, loss is 3.632183837890625 and perplexity is 37.79526528957245
At time: 307.16447710990906 and batch: 500, loss is 3.6107988739013672 and perplexity is 36.995595828652995
At time: 307.50635957717896 and batch: 550, loss is 3.6707860708236693 and perplexity is 39.28277276847325
At time: 307.8493893146515 and batch: 600, loss is 3.604783115386963 and perplexity is 36.773707340997035
At time: 308.1846203804016 and batch: 650, loss is 3.649974002838135 and perplexity is 38.473665829912626
At time: 308.5181345939636 and batch: 700, loss is 3.7120764589309694 and perplexity is 40.938725913714705
At time: 308.8522493839264 and batch: 750, loss is 3.666820273399353 and perplexity is 39.1272937523242
At time: 309.19311261177063 and batch: 800, loss is 3.5801592683792114 and perplexity is 35.87925482278579
At time: 309.5357127189636 and batch: 850, loss is 3.5415839099884034 and perplexity is 34.5215549460701
At time: 309.87968158721924 and batch: 900, loss is 3.4353898859024046 and perplexity is 31.043513634683915
At time: 310.2271497249603 and batch: 950, loss is 3.5923044061660767 and perplexity is 36.31767023509116
At time: 310.5691542625427 and batch: 1000, loss is 3.6106604099273683 and perplexity is 36.990473626062546
At time: 310.924996137619 and batch: 1050, loss is 3.542533864974976 and perplexity is 34.55436445064428
At time: 311.27048206329346 and batch: 1100, loss is 3.6948523807525633 and perplexity is 40.23963200531651
At time: 311.61370730400085 and batch: 1150, loss is 3.594206519126892 and perplexity is 36.386816287305265
At time: 311.95561480522156 and batch: 1200, loss is 3.5452385759353637 and perplexity is 34.647950523489556
At time: 312.30949091911316 and batch: 1250, loss is 3.4097678804397584 and perplexity is 30.25821991948687
At time: 312.6535019874573 and batch: 1300, loss is 3.531424169540405 and perplexity is 34.17260055258341
At time: 312.97329545021057 and batch: 1350, loss is 3.53288094997406 and perplexity is 34.22241880675408
At time: 313.3300325870514 and batch: 1400, loss is 3.3787362003326415 and perplexity is 29.33367578799364
At time: 313.6960587501526 and batch: 1450, loss is 3.4882545280456543 and perplexity is 32.728770668988126
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287610958784055 and perplexity of 72.79235666199556
Finished 29 epochs...
Completing Train Step...
At time: 314.9234850406647 and batch: 50, loss is 3.697651424407959 and perplexity is 40.352422270775605
At time: 315.2675952911377 and batch: 100, loss is 3.741179642677307 and perplexity is 42.147680053218586
At time: 315.6042203903198 and batch: 150, loss is 3.563974905014038 and perplexity is 35.30324566914285
At time: 315.9337079524994 and batch: 200, loss is 3.7127521800994874 and perplexity is 40.966398425824934
At time: 316.25953435897827 and batch: 250, loss is 3.7977029848098756 and perplexity is 44.598623031216555
At time: 316.619948387146 and batch: 300, loss is 3.758262710571289 and perplexity is 42.87387690773703
At time: 316.98266339302063 and batch: 350, loss is 3.740936074256897 and perplexity is 42.13741545948026
At time: 317.3162863254547 and batch: 400, loss is 3.524569244384766 and perplexity is 33.93915098721984
At time: 317.6622533798218 and batch: 450, loss is 3.6320769786834717 and perplexity is 37.79122673327176
At time: 318.00711393356323 and batch: 500, loss is 3.6107041120529173 and perplexity is 36.99209022370919
At time: 318.34118461608887 and batch: 550, loss is 3.6706771850585938 and perplexity is 39.278495666568055
At time: 318.6672611236572 and batch: 600, loss is 3.604688639640808 and perplexity is 36.770233281666876
At time: 319.0050935745239 and batch: 650, loss is 3.6498740577697752 and perplexity is 38.469820768901855
At time: 319.3467469215393 and batch: 700, loss is 3.7120004653930665 and perplexity is 40.93561495330323
At time: 319.67642855644226 and batch: 750, loss is 3.6667257499694825 and perplexity is 39.12359548110658
At time: 320.0171232223511 and batch: 800, loss is 3.5800894927978515 and perplexity is 35.87675141426118
At time: 320.3758955001831 and batch: 850, loss is 3.5415051317214967 and perplexity is 34.51883550491836
At time: 320.72001242637634 and batch: 900, loss is 3.4353431987762453 and perplexity is 31.042064336078482
At time: 321.05201053619385 and batch: 950, loss is 3.592256965637207 and perplexity is 36.31594734647559
At time: 321.37804985046387 and batch: 1000, loss is 3.610629687309265 and perplexity is 36.989337199324964
At time: 321.70988059043884 and batch: 1050, loss is 3.5425325059890747 and perplexity is 34.55431749178207
At time: 322.04028606414795 and batch: 1100, loss is 3.6948645734786987 and perplexity is 40.24012263912041
At time: 322.3615367412567 and batch: 1150, loss is 3.594205904006958 and perplexity is 36.38679390505611
At time: 322.7026982307434 and batch: 1200, loss is 3.545247964859009 and perplexity is 34.64827583197863
At time: 323.0424795150757 and batch: 1250, loss is 3.40981107711792 and perplexity is 30.259527002305088
At time: 323.4191474914551 and batch: 1300, loss is 3.5314546251296997 and perplexity is 34.173641315119404
At time: 323.7730882167816 and batch: 1350, loss is 3.5329179668426516 and perplexity is 34.22368563698083
At time: 324.10748505592346 and batch: 1400, loss is 3.3788031244277956 and perplexity is 29.3356389833951
At time: 324.4404447078705 and batch: 1450, loss is 3.4883198881149293 and perplexity is 32.73090989361551
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287575485359909 and perplexity of 72.7897745136522
Finished 30 epochs...
Completing Train Step...
At time: 325.7011651992798 and batch: 50, loss is 3.6975450038909914 and perplexity is 40.34812817363073
At time: 326.04906272888184 and batch: 100, loss is 3.741063885688782 and perplexity is 42.14280144707412
At time: 326.3929364681244 and batch: 150, loss is 3.5638565540313722 and perplexity is 35.29906774256235
At time: 326.74009132385254 and batch: 200, loss is 3.7126412057876585 and perplexity is 40.96185246019889
At time: 327.0875334739685 and batch: 250, loss is 3.7975621700286863 and perplexity is 44.59234332802097
At time: 327.4217450618744 and batch: 300, loss is 3.758153533935547 and perplexity is 42.869196337604116
At time: 327.75846338272095 and batch: 350, loss is 3.740821180343628 and perplexity is 42.132574405032244
At time: 328.1014368534088 and batch: 400, loss is 3.5244577026367185 and perplexity is 33.93536556611165
At time: 328.449125289917 and batch: 450, loss is 3.6319722938537597 and perplexity is 37.78727077220476
At time: 328.80179595947266 and batch: 500, loss is 3.6106116008758544 and perplexity is 36.98866820019073
At time: 329.14860677719116 and batch: 550, loss is 3.6705735397338866 and perplexity is 39.27442484509513
At time: 329.4912705421448 and batch: 600, loss is 3.6045984840393066 and perplexity is 36.76691838859834
At time: 329.8375451564789 and batch: 650, loss is 3.6497789144515993 and perplexity is 38.466160796617984
At time: 330.1785886287689 and batch: 700, loss is 3.7119264125823976 and perplexity is 40.932583668198454
At time: 330.5410497188568 and batch: 750, loss is 3.666637353897095 and perplexity is 39.12013726177712
At time: 330.8628330230713 and batch: 800, loss is 3.5800226640701296 and perplexity is 35.874353896721786
At time: 331.20562291145325 and batch: 850, loss is 3.5414313745498656 and perplexity is 34.516289587134516
At time: 331.53247332572937 and batch: 900, loss is 3.435296821594238 and perplexity is 31.040624725993677
At time: 331.8589141368866 and batch: 950, loss is 3.5922117614746094 and perplexity is 36.314305751590595
At time: 332.20058965682983 and batch: 1000, loss is 3.6105990743637086 and perplexity is 36.988204864091266
At time: 332.55348658561707 and batch: 1050, loss is 3.5425280284881593 and perplexity is 34.55416277514024
At time: 332.93031072616577 and batch: 1100, loss is 3.6948720741271974 and perplexity is 40.24042446726783
At time: 333.2528212070465 and batch: 1150, loss is 3.594203233718872 and perplexity is 36.3866967419636
At time: 333.6067101955414 and batch: 1200, loss is 3.5452552795410157 and perplexity is 34.64852927402534
At time: 333.95155215263367 and batch: 1250, loss is 3.409847083091736 and perplexity is 30.26061654565693
At time: 334.2953586578369 and batch: 1300, loss is 3.531480474472046 and perplexity is 34.17452469269029
At time: 334.64998483657837 and batch: 1350, loss is 3.5329500436782837 and perplexity is 34.2247834421267
At time: 334.9986023902893 and batch: 1400, loss is 3.3788604497909547 and perplexity is 29.337320707755595
At time: 335.3321988582611 and batch: 1450, loss is 3.4883782720565795 and perplexity is 32.732820908934656
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287547315287794 and perplexity of 72.78772404933592
Finished 31 epochs...
Completing Train Step...
At time: 336.4918568134308 and batch: 50, loss is 3.6974430894851684 and perplexity is 40.34401632765357
At time: 336.8329131603241 and batch: 100, loss is 3.740952672958374 and perplexity is 42.138114891665296
At time: 337.17584466934204 and batch: 150, loss is 3.563742814064026 and perplexity is 35.295053056069435
At time: 337.5384945869446 and batch: 200, loss is 3.712534761428833 and perplexity is 40.957492534126345
At time: 337.90350794792175 and batch: 250, loss is 3.797429447174072 and perplexity is 44.58642529765817
At time: 338.24855875968933 and batch: 300, loss is 3.758048186302185 and perplexity is 42.86468040710129
At time: 338.59622836112976 and batch: 350, loss is 3.740711088180542 and perplexity is 42.12793619409964
At time: 338.92282009124756 and batch: 400, loss is 3.5243496179580687 and perplexity is 33.931697871243955
At time: 339.2463788986206 and batch: 450, loss is 3.6318698358535766 and perplexity is 37.783399362340894
At time: 339.57171750068665 and batch: 500, loss is 3.6105211400985717 and perplexity is 36.985322327852074
At time: 339.89747190475464 and batch: 550, loss is 3.670474395751953 and perplexity is 39.27053121524602
At time: 340.2578613758087 and batch: 600, loss is 3.6045117568969727 and perplexity is 36.76372983710306
At time: 340.62189865112305 and batch: 650, loss is 3.6496878242492676 and perplexity is 38.46265706582829
At time: 340.9594461917877 and batch: 700, loss is 3.7118536233901978 and perplexity is 40.92960432693183
At time: 341.29793643951416 and batch: 750, loss is 3.66655396938324 and perplexity is 39.11687538414653
At time: 341.66661834716797 and batch: 800, loss is 3.579957814216614 and perplexity is 35.872027525559844
At time: 342.0229573249817 and batch: 850, loss is 3.5413617372512816 and perplexity is 34.513886049659426
At time: 342.37233567237854 and batch: 900, loss is 3.4352509212493896 and perplexity is 31.03919998331278
At time: 342.7187557220459 and batch: 950, loss is 3.5921680402755736 and perplexity is 36.31271808130865
At time: 343.0622293949127 and batch: 1000, loss is 3.610568208694458 and perplexity is 36.98706321601271
At time: 343.4055540561676 and batch: 1050, loss is 3.54252067565918 and perplexity is 34.5539087052249
At time: 343.72834849357605 and batch: 1100, loss is 3.6948754453659056 and perplexity is 40.2405601275731
At time: 344.07649755477905 and batch: 1150, loss is 3.5941989326477053 and perplexity is 36.38654024052794
At time: 344.4168300628662 and batch: 1200, loss is 3.5452608108520507 and perplexity is 34.64872092634771
At time: 344.7434296607971 and batch: 1250, loss is 3.4098769521713255 and perplexity is 30.261520415919783
At time: 345.10384583473206 and batch: 1300, loss is 3.5315024995803834 and perplexity is 34.175277398588214
At time: 345.4754288196564 and batch: 1350, loss is 3.5329778718948366 and perplexity is 34.22573587006393
At time: 345.82414841651917 and batch: 1400, loss is 3.378909873962402 and perplexity is 29.338770716356507
At time: 346.16806149482727 and batch: 1450, loss is 3.488430781364441 and perplexity is 32.73453973183164
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287525405231704 and perplexity of 72.78612928369009
Finished 32 epochs...
Completing Train Step...
At time: 347.37013506889343 and batch: 50, loss is 3.6973447704315188 and perplexity is 40.34004993713688
At time: 347.7364535331726 and batch: 100, loss is 3.7408452367782594 and perplexity is 42.13358797674569
At time: 348.0750958919525 and batch: 150, loss is 3.563632378578186 and perplexity is 35.29115544495869
At time: 348.415890455246 and batch: 200, loss is 3.712431745529175 and perplexity is 40.95327347850384
At time: 348.74113965034485 and batch: 250, loss is 3.7973037481307985 and perplexity is 44.58082117887882
At time: 349.0643482208252 and batch: 300, loss is 3.7579458284378053 and perplexity is 42.86029309449931
At time: 349.4062900543213 and batch: 350, loss is 3.740604968070984 and perplexity is 42.12346581009828
At time: 349.7606475353241 and batch: 400, loss is 3.524244775772095 and perplexity is 33.928140584345456
At time: 350.09620451927185 and batch: 450, loss is 3.6317693567276 and perplexity is 37.7796031101218
At time: 350.46100544929504 and batch: 500, loss is 3.6104324007034303 and perplexity is 36.98204041833908
At time: 350.81096959114075 and batch: 550, loss is 3.6703786420822144 and perplexity is 39.266771097794965
At time: 351.16366362571716 and batch: 600, loss is 3.6044280195236205 and perplexity is 36.76065146782094
At time: 351.5032377243042 and batch: 650, loss is 3.6495997095108033 and perplexity is 38.459268088171925
At time: 351.85007071495056 and batch: 700, loss is 3.7117821550369263 and perplexity is 40.926679260036636
At time: 352.19307231903076 and batch: 750, loss is 3.666474380493164 and perplexity is 39.11376223933899
At time: 352.54519391059875 and batch: 800, loss is 3.579894814491272 and perplexity is 35.869767668864206
At time: 352.8763608932495 and batch: 850, loss is 3.5412953996658327 and perplexity is 34.51159655773496
At time: 353.2009553909302 and batch: 900, loss is 3.4352055311203005 and perplexity is 31.037791141992702
At time: 353.5412197113037 and batch: 950, loss is 3.592125587463379 and perplexity is 36.311176537029354
At time: 353.87261724472046 and batch: 1000, loss is 3.6105370569229125 and perplexity is 36.98591102141581
At time: 354.20681738853455 and batch: 1050, loss is 3.5425107669830322 and perplexity is 34.55356632343018
At time: 354.55216360092163 and batch: 1100, loss is 3.6948754024505615 and perplexity is 40.24055840063564
At time: 354.9080367088318 and batch: 1150, loss is 3.5941927576065065 and perplexity is 36.38631555283661
At time: 355.25166511535645 and batch: 1200, loss is 3.545264368057251 and perplexity is 34.64884417917718
At time: 355.57589769363403 and batch: 1250, loss is 3.4099016523361207 and perplexity is 30.26226788969234
At time: 355.91394209861755 and batch: 1300, loss is 3.53152117729187 and perplexity is 34.17591572052063
At time: 356.25911569595337 and batch: 1350, loss is 3.5330021476745603 and perplexity is 34.226566736573716
At time: 356.6131339073181 and batch: 1400, loss is 3.3789527893066404 and perplexity is 29.340029826818714
At time: 356.9721255302429 and batch: 1450, loss is 3.4884780073165893 and perplexity is 32.73608568814296
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.28750975519164 and perplexity of 72.78499018676418
Finished 33 epochs...
Completing Train Step...
At time: 358.1239242553711 and batch: 50, loss is 3.6972490549087524 and perplexity is 40.33618895294974
At time: 358.4678919315338 and batch: 100, loss is 3.740740933418274 and perplexity is 42.129193531133176
At time: 358.80704641342163 and batch: 150, loss is 3.5635252094268797 and perplexity is 35.287373524437264
At time: 359.15451097488403 and batch: 200, loss is 3.712331590652466 and perplexity is 40.94917201384204
At time: 359.48837780952454 and batch: 250, loss is 3.7971833610534667 and perplexity is 44.575454547155076
At time: 359.8245027065277 and batch: 300, loss is 3.75784619808197 and perplexity is 42.85602312096013
At time: 360.1715729236603 and batch: 350, loss is 3.7405022954940796 and perplexity is 42.119141107333405
At time: 360.5148141384125 and batch: 400, loss is 3.524142541885376 and perplexity is 33.92467215596285
At time: 360.85875725746155 and batch: 450, loss is 3.631670665740967 and perplexity is 37.77587478779518
At time: 361.17920994758606 and batch: 500, loss is 3.6103452920913695 and perplexity is 36.97881910443119
At time: 361.5290296077728 and batch: 550, loss is 3.6702859020233154 and perplexity is 39.26312966398658
At time: 361.88305282592773 and batch: 600, loss is 3.604346399307251 and perplexity is 36.75765117793807
At time: 362.24014616012573 and batch: 650, loss is 3.649514608383179 and perplexity is 38.455995300350956
At time: 362.58644580841064 and batch: 700, loss is 3.7117115545272825 and perplexity is 40.92378991761857
At time: 362.94283986091614 and batch: 750, loss is 3.666397838592529 and perplexity is 39.11076851221045
At time: 363.2847294807434 and batch: 800, loss is 3.5798331928253173 and perplexity is 35.86755738212451
At time: 363.64214062690735 and batch: 850, loss is 3.5412316656112672 and perplexity is 34.50939706384888
At time: 363.9613690376282 and batch: 900, loss is 3.4351606035232543 and perplexity is 31.03639671994332
At time: 364.30963706970215 and batch: 950, loss is 3.592083954811096 and perplexity is 36.309664837910844
At time: 364.6568601131439 and batch: 1000, loss is 3.6105055713653567 and perplexity is 36.98474651771821
At time: 365.00250220298767 and batch: 1050, loss is 3.542498574256897 and perplexity is 34.5531450238274
At time: 365.3327434062958 and batch: 1100, loss is 3.694872498512268 and perplexity is 40.240441544706826
At time: 365.67308950424194 and batch: 1150, loss is 3.5941853141784668 and perplexity is 36.38604471492314
At time: 366.02061462402344 and batch: 1200, loss is 3.545266056060791 and perplexity is 34.64890266659818
At time: 366.34259557724 and batch: 1250, loss is 3.409922037124634 and perplexity is 30.262884785910828
At time: 366.6834285259247 and batch: 1300, loss is 3.5315369367599487 and perplexity is 34.17645431901748
At time: 367.03405022621155 and batch: 1350, loss is 3.533023157119751 and perplexity is 34.22728582530544
At time: 367.3665072917938 and batch: 1400, loss is 3.3789903354644775 and perplexity is 29.341131452890316
At time: 367.7231779098511 and batch: 1450, loss is 3.4885206270217894 and perplexity is 32.737480920196376
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287494626819578 and perplexity of 72.78388907668115
Finished 34 epochs...
Completing Train Step...
At time: 368.90808296203613 and batch: 50, loss is 3.697155728340149 and perplexity is 40.332424690499806
At time: 369.23022270202637 and batch: 100, loss is 3.7406392765045164 and perplexity is 42.12491102501657
At time: 369.57142782211304 and batch: 150, loss is 3.5634208345413207 and perplexity is 35.28369060106967
At time: 369.90719532966614 and batch: 200, loss is 3.7122334575653078 and perplexity is 40.94515374234167
At time: 370.2569501399994 and batch: 250, loss is 3.797067723274231 and perplexity is 44.570300238604965
At time: 370.6026465892792 and batch: 300, loss is 3.7577487325668333 and perplexity is 42.85184634013928
At time: 370.94078493118286 and batch: 350, loss is 3.740402283668518 and perplexity is 42.11492890577867
At time: 371.2633285522461 and batch: 400, loss is 3.524042749404907 and perplexity is 33.92128689769378
At time: 371.606116771698 and batch: 450, loss is 3.631573786735535 and perplexity is 37.77221527588421
At time: 371.9623293876648 and batch: 500, loss is 3.610259370803833 and perplexity is 36.97564197317572
At time: 372.3117878437042 and batch: 550, loss is 3.6701956176757813 and perplexity is 39.25958497795997
At time: 372.6484282016754 and batch: 600, loss is 3.6042667388916017 and perplexity is 36.75472316479187
At time: 372.9950096607208 and batch: 650, loss is 3.6494317770004274 and perplexity is 38.45281006900552
At time: 373.3487992286682 and batch: 700, loss is 3.7116418218612672 and perplexity is 40.92093629214078
At time: 373.69596576690674 and batch: 750, loss is 3.666323771476746 and perplexity is 39.107871797667656
At time: 374.03902196884155 and batch: 800, loss is 3.5797725677490235 and perplexity is 35.86538297463422
At time: 374.36190915107727 and batch: 850, loss is 3.5411702299118044 and perplexity is 34.50727702002608
At time: 374.6921737194061 and batch: 900, loss is 3.4351159858703615 and perplexity is 31.035011979659586
At time: 375.02604389190674 and batch: 950, loss is 3.59204306602478 and perplexity is 36.308180210136605
At time: 375.36661863327026 and batch: 1000, loss is 3.610473713874817 and perplexity is 36.983568295273614
At time: 375.7133481502533 and batch: 1050, loss is 3.5424843311309813 and perplexity is 34.55265288253687
At time: 376.0925362110138 and batch: 1100, loss is 3.694867043495178 and perplexity is 40.24022203300921
At time: 376.43410897254944 and batch: 1150, loss is 3.5941763496398926 and perplexity is 36.385718532283775
At time: 376.7919616699219 and batch: 1200, loss is 3.5452662086486817 and perplexity is 34.64890795360156
At time: 377.12735986709595 and batch: 1250, loss is 3.4099387645721437 and perplexity is 30.26339101096149
At time: 377.4748287200928 and batch: 1300, loss is 3.5315501928329467 and perplexity is 34.17690736759356
At time: 377.8285412788391 and batch: 1350, loss is 3.5330413675308225 and perplexity is 34.22790912392542
At time: 378.17371129989624 and batch: 1400, loss is 3.379023275375366 and perplexity is 29.34209796306404
At time: 378.5287148952484 and batch: 1450, loss is 3.4885592079162597 and perplexity is 32.73874398585792
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.28748523679554 and perplexity of 72.78320563742187
Finished 35 epochs...
Completing Train Step...
At time: 379.69346380233765 and batch: 50, loss is 3.69706413269043 and perplexity is 40.328730585040105
At time: 380.02889037132263 and batch: 100, loss is 3.740539584159851 and perplexity is 42.12071170319127
At time: 380.39007019996643 and batch: 150, loss is 3.5633188104629516 and perplexity is 35.28009099868082
At time: 380.73113441467285 and batch: 200, loss is 3.7121373510360716 and perplexity is 40.941218834814634
At time: 381.0654458999634 and batch: 250, loss is 3.796956014633179 and perplexity is 44.56532162901606
At time: 381.4055140018463 and batch: 300, loss is 3.757653250694275 and perplexity is 42.84775496093753
At time: 381.75398421287537 and batch: 350, loss is 3.7403048372268675 and perplexity is 42.1108251557676
At time: 382.1048860549927 and batch: 400, loss is 3.5239452171325683 and perplexity is 33.91797863883562
At time: 382.44985699653625 and batch: 450, loss is 3.6314784717559814 and perplexity is 37.7686151895313
At time: 382.81239461898804 and batch: 500, loss is 3.610174899101257 and perplexity is 36.97251870965996
At time: 383.15878200531006 and batch: 550, loss is 3.6701077222824097 and perplexity is 39.25613439294221
At time: 383.50111651420593 and batch: 600, loss is 3.604188532829285 and perplexity is 36.75184883501808
At time: 383.8577253818512 and batch: 650, loss is 3.6493509006500244 and perplexity is 38.44970027182062
At time: 384.20237970352173 and batch: 700, loss is 3.7115729236602784 and perplexity is 40.91811701037031
At time: 384.55286502838135 and batch: 750, loss is 3.66625159740448 and perplexity is 39.10504932515826
At time: 384.90029430389404 and batch: 800, loss is 3.5797128915786742 and perplexity is 35.86324272979163
At time: 385.2461507320404 and batch: 850, loss is 3.5411105394363402 and perplexity is 34.505217325726456
At time: 385.6094250679016 and batch: 900, loss is 3.4350718212127687 and perplexity is 31.03364135924883
At time: 385.96094012260437 and batch: 950, loss is 3.592002339363098 and perplexity is 36.30670152927596
At time: 386.30846524238586 and batch: 1000, loss is 3.6104413890838623 and perplexity is 36.982372828481424
At time: 386.66408586502075 and batch: 1050, loss is 3.5424680948257445 and perplexity is 34.55209187967225
At time: 387.0038161277771 and batch: 1100, loss is 3.69485942363739 and perplexity is 40.239915409408184
At time: 387.33347392082214 and batch: 1150, loss is 3.5941663694381716 and perplexity is 36.38535539728514
At time: 387.66788053512573 and batch: 1200, loss is 3.545264678001404 and perplexity is 34.64885491838551
At time: 388.00237917900085 and batch: 1250, loss is 3.409952244758606 and perplexity is 30.263798969864972
At time: 388.3515453338623 and batch: 1300, loss is 3.5315612316131593 and perplexity is 34.17728464104465
At time: 388.6807084083557 and batch: 1350, loss is 3.533056993484497 and perplexity is 34.228443971826515
At time: 389.0409324169159 and batch: 1400, loss is 3.3790523624420166 and perplexity is 29.342951451035827
At time: 389.3914279937744 and batch: 1450, loss is 3.4885940456390383 and perplexity is 32.73988454901222
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.28747793344351 and perplexity of 72.78267407799034
Finished 36 epochs...
Completing Train Step...
At time: 390.64420437812805 and batch: 50, loss is 3.696973958015442 and perplexity is 40.32509411882797
At time: 391.0125617980957 and batch: 100, loss is 3.7404418754577637 and perplexity is 42.116596344176216
At time: 391.3563241958618 and batch: 150, loss is 3.5632188653945924 and perplexity is 35.27656510377507
At time: 391.6862823963165 and batch: 200, loss is 3.7120429706573486 and perplexity is 40.937354969415026
At time: 392.0160527229309 and batch: 250, loss is 3.7968478059768676 and perplexity is 44.56049953634529
At time: 392.34933042526245 and batch: 300, loss is 3.757559313774109 and perplexity is 42.843730163841954
At time: 392.69261837005615 and batch: 350, loss is 3.7402092170715333 and perplexity is 42.106798704632965
At time: 393.03465008735657 and batch: 400, loss is 3.523849534988403 and perplexity is 33.91473344916954
At time: 393.37505173683167 and batch: 450, loss is 3.6313847160339354 and perplexity is 37.76507433173396
At time: 393.71153116226196 and batch: 500, loss is 3.6100915908813476 and perplexity is 36.96943872323656
At time: 394.05902647972107 and batch: 550, loss is 3.6700214385986327 and perplexity is 39.25274737518023
At time: 394.4249429702759 and batch: 600, loss is 3.6041116523742676 and perplexity is 36.749023444766955
At time: 394.7902913093567 and batch: 650, loss is 3.6492718076705932 and perplexity is 38.4466592907296
At time: 395.13860988616943 and batch: 700, loss is 3.711504588127136 and perplexity is 40.915320944565636
At time: 395.4910044670105 and batch: 750, loss is 3.66618097782135 and perplexity is 39.10228784038523
At time: 395.90805172920227 and batch: 800, loss is 3.579654002189636 and perplexity is 35.861130827523276
At time: 396.25136709213257 and batch: 850, loss is 3.5410523509979246 and perplexity is 34.503209579427455
At time: 396.5940339565277 and batch: 900, loss is 3.43502769947052 and perplexity is 31.032272131130327
At time: 396.95169591903687 and batch: 950, loss is 3.5919622135162355 and perplexity is 36.305244721358335
At time: 397.3032658100128 and batch: 1000, loss is 3.6104088020324707 and perplexity is 36.98116770163335
At time: 397.64045667648315 and batch: 1050, loss is 3.542450361251831 and perplexity is 34.55147915302997
At time: 397.9784965515137 and batch: 1100, loss is 3.6948499393463137 and perplexity is 40.23953376414737
At time: 398.34031891822815 and batch: 1150, loss is 3.594155216217041 and perplexity is 36.384949585633535
At time: 398.6839635372162 and batch: 1200, loss is 3.5452617692947386 and perplexity is 34.64875413517684
At time: 399.0266082286835 and batch: 1250, loss is 3.4099629974365233 and perplexity is 30.26412438849741
At time: 399.3723998069763 and batch: 1300, loss is 3.5315701866149904 and perplexity is 34.17759070006157
At time: 399.7337670326233 and batch: 1350, loss is 3.533070511817932 and perplexity is 34.22890668647264
At time: 400.07171726226807 and batch: 1400, loss is 3.379078059196472 and perplexity is 29.34370547934226
At time: 400.42489194869995 and batch: 1450, loss is 3.4886257600784303 and perplexity is 32.7409228925616
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287471412593483 and perplexity of 72.78219947463552
Finished 37 epochs...
Completing Train Step...
At time: 401.59160590171814 and batch: 50, loss is 3.696884956359863 and perplexity is 40.32150527839876
At time: 401.93836069107056 and batch: 100, loss is 3.740345916748047 and perplexity is 42.11255508383353
At time: 402.3011403083801 and batch: 150, loss is 3.563120880126953 and perplexity is 35.273108689443596
At time: 402.6479184627533 and batch: 200, loss is 3.711950173377991 and perplexity is 40.933556270506955
At time: 402.9969844818115 and batch: 250, loss is 3.796742434501648 and perplexity is 44.55580437814484
At time: 403.3462610244751 and batch: 300, loss is 3.7574669218063352 and perplexity is 42.83977193016266
At time: 403.68955636024475 and batch: 350, loss is 3.740115623474121 and perplexity is 42.102857962283686
At time: 404.02180218696594 and batch: 400, loss is 3.523755612373352 and perplexity is 33.91154823829924
At time: 404.3730192184448 and batch: 450, loss is 3.631292290687561 and perplexity is 37.76158404295605
At time: 404.720032453537 and batch: 500, loss is 3.610009160041809 and perplexity is 36.96639142696265
At time: 405.0812714099884 and batch: 550, loss is 3.6699369764328003 and perplexity is 39.24943214312985
At time: 405.4321186542511 and batch: 600, loss is 3.60403594493866 and perplexity is 36.74624137575385
At time: 405.7540547847748 and batch: 650, loss is 3.6491943359375 and perplexity is 38.44368087677564
At time: 406.0947504043579 and batch: 700, loss is 3.7114367628097535 and perplexity is 40.912545944045476
At time: 406.43381571769714 and batch: 750, loss is 3.6661117935180663 and perplexity is 39.099582669422965
At time: 406.77581214904785 and batch: 800, loss is 3.5795958185195924 and perplexity is 35.85904435601969
At time: 407.11426281929016 and batch: 850, loss is 3.5409955167770386 and perplexity is 34.501248672116795
At time: 407.4488699436188 and batch: 900, loss is 3.434983868598938 and perplexity is 31.030911989403965
At time: 407.7931115627289 and batch: 950, loss is 3.591922388076782 and perplexity is 36.303798877823716
At time: 408.1414577960968 and batch: 1000, loss is 3.6103758811950684 and perplexity is 36.97995027066403
At time: 408.4876365661621 and batch: 1050, loss is 3.5424312496185304 and perplexity is 34.5508188241404
At time: 408.8337302207947 and batch: 1100, loss is 3.694838743209839 and perplexity is 40.23908323935773
At time: 409.1881685256958 and batch: 1150, loss is 3.594143090248108 and perplexity is 36.38450838554023
At time: 409.5354058742523 and batch: 1200, loss is 3.545257453918457 and perplexity is 34.64860461308768
At time: 409.8820593357086 and batch: 1250, loss is 3.4099714374542236 and perplexity is 30.26437981932085
At time: 410.20906043052673 and batch: 1300, loss is 3.5315772342681884 and perplexity is 34.17783157271676
At time: 410.5619866847992 and batch: 1350, loss is 3.5330820226669313 and perplexity is 34.22930069251659
At time: 410.9048500061035 and batch: 1400, loss is 3.3791008377075196 and perplexity is 29.3443738928744
At time: 411.2623875141144 and batch: 1450, loss is 3.4886544609069823 and perplexity is 32.74186259766127
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.28746593507946 and perplexity of 72.78180081020912
Finished 38 epochs...
Completing Train Step...
At time: 412.5231840610504 and batch: 50, loss is 3.696797099113464 and perplexity is 40.31796289758853
At time: 412.8735673427582 and batch: 100, loss is 3.740251302719116 and perplexity is 42.10857083381443
At time: 413.218612909317 and batch: 150, loss is 3.5630246114730837 and perplexity is 35.2697131581965
At time: 413.55081367492676 and batch: 200, loss is 3.7118585872650147 and perplexity is 40.92980749686827
At time: 413.8760504722595 and batch: 250, loss is 3.7966396141052248 and perplexity is 44.55122336819039
At time: 414.20687675476074 and batch: 300, loss is 3.7573756647109984 and perplexity is 42.83586267538775
At time: 414.5549931526184 and batch: 350, loss is 3.7400235080718995 and perplexity is 42.098979819208914
At time: 414.90578269958496 and batch: 400, loss is 3.5236632347106935 and perplexity is 33.90841571342575
At time: 415.2584881782532 and batch: 450, loss is 3.6312013339996336 and perplexity is 37.75814953053892
At time: 415.6026027202606 and batch: 500, loss is 3.60992769241333 and perplexity is 36.96337998538884
At time: 415.96688318252563 and batch: 550, loss is 3.6698540878295898 and perplexity is 39.246178947351
At time: 416.31139850616455 and batch: 600, loss is 3.6039613628387452 and perplexity is 36.743500866105826
At time: 416.64326882362366 and batch: 650, loss is 3.6491180801391603 and perplexity is 38.4407494349704
At time: 416.9743723869324 and batch: 700, loss is 3.7113696765899657 and perplexity is 40.90980136805884
At time: 417.3026957511902 and batch: 750, loss is 3.6660438108444215 and perplexity is 39.09692466560483
At time: 417.6455726623535 and batch: 800, loss is 3.5795380592346193 and perplexity is 35.85697322307202
At time: 418.0018353462219 and batch: 850, loss is 3.5409396505355835 and perplexity is 34.49932127086681
At time: 418.34837889671326 and batch: 900, loss is 3.4349402475357054 and perplexity is 31.029558417552245
At time: 418.6906273365021 and batch: 950, loss is 3.59188259601593 and perplexity is 36.30235430359109
At time: 419.05193543434143 and batch: 1000, loss is 3.6103427410125732 and perplexity is 36.97872476867019
At time: 419.4010965824127 and batch: 1050, loss is 3.5424108505249023 and perplexity is 34.55011402594093
At time: 419.73890566825867 and batch: 1100, loss is 3.694826407432556 and perplexity is 40.23858686205044
At time: 420.06743144989014 and batch: 1150, loss is 3.594130177497864 and perplexity is 36.38403856450403
At time: 420.42815494537354 and batch: 1200, loss is 3.545252060890198 and perplexity is 34.648417752687735
At time: 420.7741205692291 and batch: 1250, loss is 3.4099777793884276 and perplexity is 30.26457175463501
At time: 421.11176586151123 and batch: 1300, loss is 3.5315827989578246 and perplexity is 34.17802176227107
At time: 421.45896005630493 and batch: 1350, loss is 3.5330918502807616 and perplexity is 34.229637086518444
At time: 421.80686020851135 and batch: 1400, loss is 3.3791213703155516 and perplexity is 29.344976415587148
At time: 422.1455891132355 and batch: 1450, loss is 3.4886808252334593 and perplexity is 32.74272582619543
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287463587573451 and perplexity of 72.7816299546949
Finished 39 epochs...
Completing Train Step...
At time: 423.40839862823486 and batch: 50, loss is 3.696709976196289 and perplexity is 40.314450432056674
At time: 423.76539754867554 and batch: 100, loss is 3.7401579666137694 and perplexity is 42.10464076722249
At time: 424.12285470962524 and batch: 150, loss is 3.5629299116134643 and perplexity is 35.26637327945713
At time: 424.482604265213 and batch: 200, loss is 3.7117681169509886 and perplexity is 40.92610473182869
At time: 424.82327008247375 and batch: 250, loss is 3.7965391302108764 and perplexity is 44.54674691267798
At time: 425.1577732563019 and batch: 300, loss is 3.7572856760025024 and perplexity is 42.8320081048648
At time: 425.4997866153717 and batch: 350, loss is 3.739932737350464 and perplexity is 42.09515863786733
At time: 425.84322357177734 and batch: 400, loss is 3.5235722398757936 and perplexity is 33.905330363113784
At time: 426.1892018318176 and batch: 450, loss is 3.6311114597320557 and perplexity is 37.75475619699374
At time: 426.54285645484924 and batch: 500, loss is 3.609847149848938 and perplexity is 36.960402979865655
At time: 426.8879346847534 and batch: 550, loss is 3.669772448539734 and perplexity is 39.24297504795599
At time: 427.2311854362488 and batch: 600, loss is 3.6038876390457153 and perplexity is 36.740792095704414
At time: 427.5916428565979 and batch: 650, loss is 3.6490431022644043 and perplexity is 38.43786733732186
At time: 427.9386177062988 and batch: 700, loss is 3.711303024291992 and perplexity is 40.90707472665747
At time: 428.29464411735535 and batch: 750, loss is 3.665976815223694 and perplexity is 39.09430543060794
At time: 428.64874482154846 and batch: 800, loss is 3.5794807052612305 and perplexity is 35.85491674215822
At time: 429.00232100486755 and batch: 850, loss is 3.540884575843811 and perplexity is 34.497421283702536
At time: 429.358078956604 and batch: 900, loss is 3.434896788597107 and perplexity is 31.028209935180257
At time: 429.7047429084778 and batch: 950, loss is 3.5918430709838867 and perplexity is 36.300919480229894
At time: 430.06659722328186 and batch: 1000, loss is 3.610309262275696 and perplexity is 36.977486788396725
At time: 430.39950799942017 and batch: 1050, loss is 3.542389278411865 and perplexity is 34.54936871501471
At time: 430.73330330848694 and batch: 1100, loss is 3.6948126554489136 and perplexity is 40.238033505466994
At time: 431.0898311138153 and batch: 1150, loss is 3.594116439819336 and perplexity is 36.38353873571195
At time: 431.43375849723816 and batch: 1200, loss is 3.5452455425262452 and perplexity is 34.648191902426525
At time: 431.7829942703247 and batch: 1250, loss is 3.409982204437256 and perplexity is 30.264705677139098
At time: 432.12810134887695 and batch: 1300, loss is 3.531586890220642 and perplexity is 34.17816159382673
At time: 432.47266602516174 and batch: 1350, loss is 3.533100118637085 and perplexity is 34.22992011052477
At time: 432.84263801574707 and batch: 1400, loss is 3.3791395616531372 and perplexity is 29.345510244815088
At time: 433.18726658821106 and batch: 1450, loss is 3.4887047290802 and perplexity is 32.743508512650024
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287459414229434 and perplexity of 72.7813262125488
Finished 40 epochs...
Completing Train Step...
At time: 434.4212074279785 and batch: 50, loss is 3.6966237449645996 and perplexity is 40.31097421722233
At time: 434.7789878845215 and batch: 100, loss is 3.7400657176971435 and perplexity is 42.100756838873636
At time: 435.1207993030548 and batch: 150, loss is 3.562836561203003 and perplexity is 35.26308130269209
At time: 435.47956824302673 and batch: 200, loss is 3.7116788387298585 and perplexity is 40.92245108509841
At time: 435.82860350608826 and batch: 250, loss is 3.7964404344558718 and perplexity is 44.54235055481293
At time: 436.16128301620483 and batch: 300, loss is 3.75719678401947 and perplexity is 42.82820085194674
At time: 436.50776720046997 and batch: 350, loss is 3.7398432874679566 and perplexity is 42.09139339927564
At time: 436.8669102191925 and batch: 400, loss is 3.523482584953308 and perplexity is 33.902290719609766
At time: 437.20770931243896 and batch: 450, loss is 3.631022906303406 and perplexity is 37.751413031911206
At time: 437.55581307411194 and batch: 500, loss is 3.6097675132751466 and perplexity is 36.95745969720442
At time: 437.92091703414917 and batch: 550, loss is 3.6696919918060305 and perplexity is 39.23981781337492
At time: 438.2701745033264 and batch: 600, loss is 3.6038146448135375 and perplexity is 36.73811032767378
At time: 438.6318485736847 and batch: 650, loss is 3.6489691972732543 and perplexity is 38.4350266920467
At time: 438.9971330165863 and batch: 700, loss is 3.7112367248535154 and perplexity is 40.90436270047727
At time: 439.34006810188293 and batch: 750, loss is 3.6659104776382447 and perplexity is 39.091712094799625
At time: 439.67643690109253 and batch: 800, loss is 3.579423828125 and perplexity is 35.85287747516852
At time: 440.0070996284485 and batch: 850, loss is 3.54083044052124 and perplexity is 34.49555380522221
At time: 440.3612105846405 and batch: 900, loss is 3.4348534297943116 and perplexity is 31.026864618310462
At time: 440.72129583358765 and batch: 950, loss is 3.591803617477417 and perplexity is 36.29948730992058
At time: 441.06984972953796 and batch: 1000, loss is 3.6102755165100096 and perplexity is 36.97623897584621
At time: 441.4165506362915 and batch: 1050, loss is 3.5423666620254517 and perplexity is 34.54858734197746
At time: 441.7502820491791 and batch: 1100, loss is 3.694797782897949 and perplexity is 40.237435067713136
At time: 442.0706629753113 and batch: 1150, loss is 3.594102153778076 and perplexity is 36.383018962689135
At time: 442.42827558517456 and batch: 1200, loss is 3.5452380990982055 and perplexity is 34.647934002063224
At time: 442.78295040130615 and batch: 1250, loss is 3.4099849796295167 and perplexity is 30.264789667632616
At time: 443.14272356033325 and batch: 1300, loss is 3.531589641571045 and perplexity is 34.17825563005477
At time: 443.5000557899475 and batch: 1350, loss is 3.533107056617737 and perplexity is 34.23015759787206
At time: 443.8488562107086 and batch: 1400, loss is 3.379155888557434 and perplexity is 29.345989370063705
At time: 444.1838376522064 and batch: 1450, loss is 3.488726649284363 and perplexity is 32.74422626490824
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2874573275574255 and perplexity of 72.7811743419511
Finished 41 epochs...
Completing Train Step...
At time: 445.41970920562744 and batch: 50, loss is 3.696538190841675 and perplexity is 40.30752559470297
At time: 445.7653753757477 and batch: 100, loss is 3.7399744844436644 and perplexity is 42.09691602506093
At time: 446.11149549484253 and batch: 150, loss is 3.5627443647384642 and perplexity is 35.25983032113404
At time: 446.4549481868744 and batch: 200, loss is 3.7115904092788696 and perplexity is 40.91883249521315
At time: 446.7844223976135 and batch: 250, loss is 3.7963437271118163 and perplexity is 44.538043190673015
At time: 447.13935232162476 and batch: 300, loss is 3.7571087884902954 and perplexity is 42.82443232755825
At time: 447.49429059028625 and batch: 350, loss is 3.7397549390792846 and perplexity is 42.087674856757886
At time: 447.8478183746338 and batch: 400, loss is 3.5233940267562867 and perplexity is 33.899288526805094
At time: 448.22644305229187 and batch: 450, loss is 3.6309353160858153 and perplexity is 37.748106522240455
At time: 448.5611231327057 and batch: 500, loss is 3.609688630104065 and perplexity is 36.95454449057027
At time: 448.90150213241577 and batch: 550, loss is 3.669612684249878 and perplexity is 39.23670592272013
At time: 449.2359142303467 and batch: 600, loss is 3.6037423181533814 and perplexity is 36.73545327894222
At time: 449.57757902145386 and batch: 650, loss is 3.6488961505889894 and perplexity is 38.432219243325875
At time: 449.93005752563477 and batch: 700, loss is 3.711170907020569 and perplexity is 40.90167055256292
At time: 450.2834885120392 and batch: 750, loss is 3.6658450031280516 and perplexity is 39.089152667887134
At time: 450.64173674583435 and batch: 800, loss is 3.579367241859436 and perplexity is 35.850848752121955
At time: 451.00843381881714 and batch: 850, loss is 3.540776739120483 and perplexity is 34.49370139540193
At time: 451.3656539916992 and batch: 900, loss is 3.4348101568222047 and perplexity is 31.02552202271253
At time: 451.71511483192444 and batch: 950, loss is 3.591764349937439 and perplexity is 36.29806194633691
At time: 452.0569770336151 and batch: 1000, loss is 3.6102415466308595 and perplexity is 36.974982918810944
At time: 452.4052906036377 and batch: 1050, loss is 3.5423432207107544 and perplexity is 34.5477774871613
At time: 452.76927399635315 and batch: 1100, loss is 3.6947821378707886 and perplexity is 40.236805556873
At time: 453.11525082588196 and batch: 1150, loss is 3.5940871477127074 and perplexity is 36.38247300082466
At time: 453.4687566757202 and batch: 1200, loss is 3.5452296543121338 and perplexity is 34.64764140890819
At time: 453.81576108932495 and batch: 1250, loss is 3.4099864673614504 and perplexity is 30.264834693560164
At time: 454.16233253479004 and batch: 1300, loss is 3.531591114997864 and perplexity is 34.17830598925033
At time: 454.5153968334198 and batch: 1350, loss is 3.533112668991089 and perplexity is 34.23034971083549
At time: 454.8711965084076 and batch: 1400, loss is 3.379170560836792 and perplexity is 29.34641994577653
At time: 455.22572660446167 and batch: 1450, loss is 3.4887464427948 and perplexity is 32.74487439450692
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.28745602338742 and perplexity of 72.78107942298844
Finished 42 epochs...
Completing Train Step...
At time: 456.4294764995575 and batch: 50, loss is 3.696453356742859 and perplexity is 40.30410628713263
At time: 456.75523686408997 and batch: 100, loss is 3.739884338378906 and perplexity is 42.09312132478403
At time: 457.12076210975647 and batch: 150, loss is 3.562653408050537 and perplexity is 35.25662334960112
At time: 457.46650767326355 and batch: 200, loss is 3.7115027952194213 and perplexity is 40.91524758723682
At time: 457.8009819984436 and batch: 250, loss is 3.796248598098755 and perplexity is 44.53380653209837
At time: 458.14910435676575 and batch: 300, loss is 3.757021622657776 and perplexity is 42.82069966294502
At time: 458.5418176651001 and batch: 350, loss is 3.7396675539016724 and perplexity is 42.08399717850487
At time: 458.8916416168213 and batch: 400, loss is 3.5233066082000732 and perplexity is 33.8963252294709
At time: 459.2396183013916 and batch: 450, loss is 3.6308487367630007 and perplexity is 37.74483845821565
At time: 459.5673043727875 and batch: 500, loss is 3.609610290527344 and perplexity is 36.95164960059066
At time: 459.9367334842682 and batch: 550, loss is 3.6695343351364134 and perplexity is 39.23363188202156
At time: 460.29426407814026 and batch: 600, loss is 3.603670482635498 and perplexity is 36.732814463412716
At time: 460.6544885635376 and batch: 650, loss is 3.648823971748352 and perplexity is 38.429445350407164
At time: 461.01144647598267 and batch: 700, loss is 3.7111053323745726 and perplexity is 40.89898852793314
At time: 461.37162709236145 and batch: 750, loss is 3.665779986381531 and perplexity is 39.08661130097301
At time: 461.7347228527069 and batch: 800, loss is 3.579310960769653 and perplexity is 35.848831084063356
At time: 462.1019151210785 and batch: 850, loss is 3.540723805427551 and perplexity is 34.49187556472859
At time: 462.44773411750793 and batch: 900, loss is 3.434766969680786 and perplexity is 31.024182148038236
At time: 462.78596663475037 and batch: 950, loss is 3.5917250680923463 and perplexity is 36.2966361194951
At time: 463.13957953453064 and batch: 1000, loss is 3.6102074146270753 and perplexity is 36.97372091009161
At time: 463.4852502346039 and batch: 1050, loss is 3.542319111824036 and perplexity is 34.54694458874765
At time: 463.8367202281952 and batch: 1100, loss is 3.694765553474426 and perplexity is 40.23613825927467
At time: 464.1790018081665 and batch: 1150, loss is 3.594071617126465 and perplexity is 36.3819079640777
At time: 464.53509521484375 and batch: 1200, loss is 3.545220441818237 and perplexity is 34.647322219193455
At time: 464.8889584541321 and batch: 1250, loss is 3.409986667633057 and perplexity is 30.26484075474783
At time: 465.24810791015625 and batch: 1300, loss is 3.5315915536880493 and perplexity is 34.17832098294102
At time: 465.60228395462036 and batch: 1350, loss is 3.533117260932922 and perplexity is 34.23050689497119
At time: 465.9492037296295 and batch: 1400, loss is 3.3791839122772216 and perplexity is 29.346811765369928
At time: 466.2949059009552 and batch: 1450, loss is 3.4887647151947023 and perplexity is 32.74547272741309
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2874549800514155 and perplexity of 72.78100348790745
Finished 43 epochs...
Completing Train Step...
At time: 467.5458633899689 and batch: 50, loss is 3.6963689279556275 and perplexity is 40.3007036039626
At time: 467.88643288612366 and batch: 100, loss is 3.739794945716858 and perplexity is 42.08935867679396
At time: 468.2188341617584 and batch: 150, loss is 3.5625634717941286 and perplexity is 35.25345264346631
At time: 468.57920122146606 and batch: 200, loss is 3.7114161252975464 and perplexity is 40.91170161959153
At time: 468.9282383918762 and batch: 250, loss is 3.7961547994613647 and perplexity is 44.529629517630056
At time: 469.29765224456787 and batch: 300, loss is 3.7569354581832886 and perplexity is 42.81701019881403
At time: 469.6467900276184 and batch: 350, loss is 3.739581151008606 and perplexity is 42.08036115648052
At time: 469.98952198028564 and batch: 400, loss is 3.523220100402832 and perplexity is 33.89339305987032
At time: 470.339191198349 and batch: 450, loss is 3.630762972831726 and perplexity is 37.74160145129535
At time: 470.69210934638977 and batch: 500, loss is 3.609532585144043 and perplexity is 36.948778370051336
At time: 471.06182956695557 and batch: 550, loss is 3.669456810951233 and perplexity is 39.23059044457225
At time: 471.40936756134033 and batch: 600, loss is 3.603599467277527 and perplexity is 36.73020596206724
At time: 471.7613718509674 and batch: 650, loss is 3.6487525033950807 and perplexity is 38.426698959372025
At time: 472.11087679862976 and batch: 700, loss is 3.7110401821136474 and perplexity is 40.896324034956116
At time: 472.46861243247986 and batch: 750, loss is 3.665715608596802 and perplexity is 39.08409507252037
At time: 472.80683183670044 and batch: 800, loss is 3.5792549324035643 and perplexity is 35.8468225888984
At time: 473.16225576400757 and batch: 850, loss is 3.5406712436676027 and perplexity is 34.490062658690164
At time: 473.5179452896118 and batch: 900, loss is 3.4347237300872804 and perplexity is 31.022840704015263
At time: 473.89921140670776 and batch: 950, loss is 3.5916858243942262 and perplexity is 36.29521173321373
At time: 474.27412700653076 and batch: 1000, loss is 3.610172986984253 and perplexity is 36.97244801394584
At time: 474.62763571739197 and batch: 1050, loss is 3.5422940158843996 and perplexity is 34.54607761159048
At time: 474.98289823532104 and batch: 1100, loss is 3.694748167991638 and perplexity is 40.235438740666254
At time: 475.3318667411804 and batch: 1150, loss is 3.5940556287765504 and perplexity is 36.38132628205268
At time: 475.70774602890015 and batch: 1200, loss is 3.54521032333374 and perplexity is 34.64697164257437
At time: 476.06893014907837 and batch: 1250, loss is 3.4099857568740846 and perplexity is 30.264813190785123
At time: 476.41725993156433 and batch: 1300, loss is 3.5315909671783445 and perplexity is 34.178300937029945
At time: 476.7683825492859 and batch: 1350, loss is 3.5331207656860353 and perplexity is 34.230626864657026
At time: 477.127813577652 and batch: 1400, loss is 3.3791958618164064 and perplexity is 29.347162448342313
At time: 477.49500012397766 and batch: 1450, loss is 3.4887814283370973 and perplexity is 32.74602001173498
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287455762553419 and perplexity of 72.78106043921079
Annealing...
Finished 44 epochs...
Completing Train Step...
At time: 478.7483820915222 and batch: 50, loss is 3.6963438892364504 and perplexity is 40.299694538595325
At time: 479.11081099510193 and batch: 100, loss is 3.7398053884506224 and perplexity is 42.08979820705588
At time: 479.47022771835327 and batch: 150, loss is 3.562583065032959 and perplexity is 35.25414337955041
At time: 479.8230571746826 and batch: 200, loss is 3.711461238861084 and perplexity is 40.91354733387505
At time: 480.18584871292114 and batch: 250, loss is 3.796191244125366 and perplexity is 44.53125241458872
At time: 480.5391321182251 and batch: 300, loss is 3.756961989402771 and perplexity is 42.81814620137889
At time: 480.89619278907776 and batch: 350, loss is 3.7396138381958006 and perplexity is 42.081736667603536
At time: 481.24577474594116 and batch: 400, loss is 3.52314444065094 and perplexity is 33.89082879116782
At time: 481.6218934059143 and batch: 450, loss is 3.6307020139694215 and perplexity is 37.73930083633148
At time: 481.9682836532593 and batch: 500, loss is 3.6094011878967285 and perplexity is 36.9439237212326
At time: 482.316846370697 and batch: 550, loss is 3.6693915033340456 and perplexity is 39.22802847184854
At time: 482.6503665447235 and batch: 600, loss is 3.6034583759307863 and perplexity is 36.72502401341465
At time: 482.9839677810669 and batch: 650, loss is 3.648698539733887 and perplexity is 38.42462536995833
At time: 483.3360517024994 and batch: 700, loss is 3.710896544456482 and perplexity is 40.890450204646775
At time: 483.7026901245117 and batch: 750, loss is 3.665638027191162 and perplexity is 39.081062991104574
At time: 484.06631302833557 and batch: 800, loss is 3.579101700782776 and perplexity is 35.84133014299193
At time: 484.43364453315735 and batch: 850, loss is 3.5405893421173094 and perplexity is 34.487237984762864
At time: 484.7882311344147 and batch: 900, loss is 3.434531683921814 and perplexity is 31.01688345846758
At time: 485.16237592697144 and batch: 950, loss is 3.591579866409302 and perplexity is 36.29136616945377
At time: 485.50917291641235 and batch: 1000, loss is 3.609969902038574 and perplexity is 36.964940228734186
At time: 485.8622932434082 and batch: 1050, loss is 3.542004952430725 and perplexity is 34.536093046241156
At time: 486.2209515571594 and batch: 1100, loss is 3.6944741010665894 and perplexity is 40.22441304865038
At time: 486.58516573905945 and batch: 1150, loss is 3.5938233947753906 and perplexity is 36.37287828207709
At time: 486.9388756752014 and batch: 1200, loss is 3.544946761131287 and perplexity is 34.63784121369074
At time: 487.30013513565063 and batch: 1250, loss is 3.4096573066711424 and perplexity is 30.25487433904889
At time: 487.6479504108429 and batch: 1300, loss is 3.5312774562835694 and perplexity is 34.16758734682266
At time: 488.0184762477875 and batch: 1350, loss is 3.5328206539154055 and perplexity is 34.22035539199092
At time: 488.3809745311737 and batch: 1400, loss is 3.3788335704803467 and perplexity is 29.336532151397858
At time: 488.7278208732605 and batch: 1450, loss is 3.488414888381958 and perplexity is 32.73401948649923
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287454197549413 and perplexity of 72.78094653664876
Finished 45 epochs...
Completing Train Step...
At time: 489.98318886756897 and batch: 50, loss is 3.696329655647278 and perplexity is 40.29912093338172
At time: 490.3452184200287 and batch: 100, loss is 3.73978994846344 and perplexity is 42.08914834612798
At time: 490.68096446990967 and batch: 150, loss is 3.5625675392150877 and perplexity is 35.25359603439009
At time: 491.0297327041626 and batch: 200, loss is 3.7114454746246337 and perplexity is 40.91290236812456
At time: 491.3828372955322 and batch: 250, loss is 3.7961759901046754 and perplexity is 44.53057313912386
At time: 491.748416185379 and batch: 300, loss is 3.756948447227478 and perplexity is 42.81756635446352
At time: 492.11864972114563 and batch: 350, loss is 3.739598708152771 and perplexity is 42.08109997393361
At time: 492.4761266708374 and batch: 400, loss is 3.523131561279297 and perplexity is 33.890392301399395
At time: 492.8361699581146 and batch: 450, loss is 3.6306892442703247 and perplexity is 37.738818919892644
At time: 493.2149758338928 and batch: 500, loss is 3.609389214515686 and perplexity is 36.94348138020484
At time: 493.5927803516388 and batch: 550, loss is 3.669378333091736 and perplexity is 39.227511832610375
At time: 493.9530222415924 and batch: 600, loss is 3.603447813987732 and perplexity is 36.72463612785076
At time: 494.31004190444946 and batch: 650, loss is 3.6486861419677736 and perplexity is 38.42414899339301
At time: 494.65088295936584 and batch: 700, loss is 3.7108867025375365 and perplexity is 40.8900477661306
At time: 495.02564907073975 and batch: 750, loss is 3.665627498626709 and perplexity is 39.08065152578005
At time: 495.39827513694763 and batch: 800, loss is 3.5790929222106933 and perplexity is 35.841015508672754
At time: 495.74407410621643 and batch: 850, loss is 3.540580496788025 and perplexity is 34.48693293513591
At time: 496.08847975730896 and batch: 900, loss is 3.434527974128723 and perplexity is 31.016768392461056
At time: 496.43687987327576 and batch: 950, loss is 3.5915739870071413 and perplexity is 36.291152798544346
At time: 496.7876555919647 and batch: 1000, loss is 3.6099647808074953 and perplexity is 36.964750923218205
At time: 497.15373396873474 and batch: 1050, loss is 3.54200355052948 and perplexity is 34.53604463008326
At time: 497.49926376342773 and batch: 1100, loss is 3.6944734048843384 and perplexity is 40.22438504513771
At time: 497.8866431713104 and batch: 1150, loss is 3.593821110725403 and perplexity is 36.37279520469977
At time: 498.2231822013855 and batch: 1200, loss is 3.54494478225708 and perplexity is 34.63777266982801
At time: 498.56604647636414 and batch: 1250, loss is 3.409658522605896 and perplexity is 30.254911127024435
At time: 498.9317035675049 and batch: 1300, loss is 3.53127836227417 and perplexity is 34.167618302349666
At time: 499.2804071903229 and batch: 1350, loss is 3.532820420265198 and perplexity is 34.220347396398715
At time: 499.6174840927124 and batch: 1400, loss is 3.3788366222381594 and perplexity is 29.336621679525656
At time: 499.9772412776947 and batch: 1450, loss is 3.4884184122085573 and perplexity is 32.73413483571104
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287453936715411 and perplexity of 72.78092755290571
Finished 46 epochs...
Completing Train Step...
At time: 501.1623091697693 and batch: 50, loss is 3.6963154029846192 and perplexity is 40.29854656769875
At time: 501.495805978775 and batch: 100, loss is 3.73977472782135 and perplexity is 42.08850772714047
At time: 501.8556659221649 and batch: 150, loss is 3.5625522804260252 and perplexity is 35.25305811130855
At time: 502.20794916152954 and batch: 200, loss is 3.711430149078369 and perplexity is 40.91227536035113
At time: 502.5929114818573 and batch: 250, loss is 3.796160788536072 and perplexity is 44.52989620970654
At time: 502.9348213672638 and batch: 300, loss is 3.7569349431991577 and perplexity is 42.81698814873892
At time: 503.295969247818 and batch: 350, loss is 3.7395838499069214 and perplexity is 42.080474727249616
At time: 503.65176463127136 and batch: 400, loss is 3.5231187534332276 and perplexity is 33.88995824125126
At time: 503.9938271045685 and batch: 450, loss is 3.6306764602661135 and perplexity is 37.738336469756476
At time: 504.3163595199585 and batch: 500, loss is 3.6093774318695067 and perplexity is 36.94304609079955
At time: 504.66716599464417 and batch: 550, loss is 3.669365396499634 and perplexity is 39.22700436557307
At time: 505.02087020874023 and batch: 600, loss is 3.6034371709823607 and perplexity is 36.72424526943115
At time: 505.3545708656311 and batch: 650, loss is 3.6486738681793214 and perplexity is 38.423677386411015
At time: 505.7013692855835 and batch: 700, loss is 3.71087700843811 and perplexity is 40.88965137586334
At time: 506.0365664958954 and batch: 750, loss is 3.665616931915283 and perplexity is 39.08023857399482
At time: 506.37212562561035 and batch: 800, loss is 3.579084014892578 and perplexity is 35.840696262767864
At time: 506.7226779460907 and batch: 850, loss is 3.5405718374252317 and perplexity is 34.486634301565
At time: 507.05797052383423 and batch: 900, loss is 3.4345239543914796 and perplexity is 31.016643713452563
At time: 507.38696908950806 and batch: 950, loss is 3.5915679931640625 and perplexity is 36.290935275721225
At time: 507.7095227241516 and batch: 1000, loss is 3.609959592819214 and perplexity is 36.96455915102105
At time: 508.0726397037506 and batch: 1050, loss is 3.542002019882202 and perplexity is 34.53599176762102
At time: 508.4238667488098 and batch: 1100, loss is 3.694472522735596 and perplexity is 40.22434956126268
At time: 508.75180649757385 and batch: 1150, loss is 3.5938187551498415 and perplexity is 36.3727095259332
At time: 509.0957691669464 and batch: 1200, loss is 3.544942979812622 and perplexity is 34.63771023722288
At time: 509.44563269615173 and batch: 1250, loss is 3.409659676551819 and perplexity is 30.254946039575916
At time: 509.7977352142334 and batch: 1300, loss is 3.5312790727615355 and perplexity is 34.167642578019404
At time: 510.14747071266174 and batch: 1350, loss is 3.5328204298019408 and perplexity is 34.22034772274937
At time: 510.49410939216614 and batch: 1400, loss is 3.378839602470398 and perplexity is 29.336709109601646
At time: 510.8404574394226 and batch: 1450, loss is 3.4884218311309816 and perplexity is 32.73424675136998
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287450285039396 and perplexity of 72.78066178102347
Finished 47 epochs...
Completing Train Step...
At time: 512.0756957530975 and batch: 50, loss is 3.6963013410568237 and perplexity is 40.29797989643091
At time: 512.4159233570099 and batch: 100, loss is 3.7397595834732056 and perplexity is 42.087870328953066
At time: 512.7521710395813 and batch: 150, loss is 3.5625370359420776 and perplexity is 35.25252070072635
At time: 513.0966331958771 and batch: 200, loss is 3.7114150381088256 and perplexity is 40.911657140875164
At time: 513.4615755081177 and batch: 250, loss is 3.7961454963684083 and perplexity is 44.5292152562743
At time: 513.8087973594666 and batch: 300, loss is 3.756921424865723 and perplexity is 42.81640933832873
At time: 514.1466045379639 and batch: 350, loss is 3.7395689582824705 and perplexity is 42.079848085289136
At time: 514.507246017456 and batch: 400, loss is 3.523105835914612 and perplexity is 33.889520469912256
At time: 514.8566343784332 and batch: 450, loss is 3.6306635904312134 and perplexity is 37.73785078672204
At time: 515.2058582305908 and batch: 500, loss is 3.6093656063079833 and perplexity is 36.94260922111826
At time: 515.5548107624054 and batch: 550, loss is 3.669352250099182 and perplexity is 39.2264886750549
At time: 515.8848748207092 and batch: 600, loss is 3.6034266328811646 and perplexity is 36.72385826765729
At time: 516.2197349071503 and batch: 650, loss is 3.6486617136001587 and perplexity is 38.423210365620726
At time: 516.5700311660767 and batch: 700, loss is 3.7108671045303345 and perplexity is 40.8892464105325
At time: 516.926566362381 and batch: 750, loss is 3.665606369972229 and perplexity is 39.07982581292025
At time: 517.2772364616394 and batch: 800, loss is 3.579075336456299 and perplexity is 35.84038522291881
At time: 517.641051530838 and batch: 850, loss is 3.5405631828308106 and perplexity is 34.48633583502372
At time: 518.0027313232422 and batch: 900, loss is 3.43451967716217 and perplexity is 31.016511048438712
At time: 518.3660087585449 and batch: 950, loss is 3.5915619802474974 and perplexity is 36.290717062011396
At time: 518.7157156467438 and batch: 1000, loss is 3.6099542379379272 and perplexity is 36.96436121072495
At time: 519.0796029567719 and batch: 1050, loss is 3.5420003843307497 and perplexity is 34.53593528227571
At time: 519.4386541843414 and batch: 1100, loss is 3.6944715547561646 and perplexity is 40.22431062493851
At time: 519.7926931381226 and batch: 1150, loss is 3.5938163471221922 and perplexity is 36.37262193954844
At time: 520.1616473197937 and batch: 1200, loss is 3.544941158294678 and perplexity is 34.63764714406961
At time: 520.5076570510864 and batch: 1250, loss is 3.409660634994507 and perplexity is 30.25497503722162
At time: 520.8498587608337 and batch: 1300, loss is 3.5312797355651857 and perplexity is 34.167665224465125
At time: 521.2164888381958 and batch: 1350, loss is 3.5328203344345095 and perplexity is 34.22034445924287
At time: 521.5794885158539 and batch: 1400, loss is 3.378842601776123 and perplexity is 29.336797099493175
At time: 521.9232687950134 and batch: 1450, loss is 3.4884253311157227 and perplexity is 32.734361320934624
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.2874513283754005 and perplexity of 72.78073771574793
Annealing...
Finished 48 epochs...
Completing Train Step...
At time: 523.1363878250122 and batch: 50, loss is 3.696295461654663 and perplexity is 40.29774296909733
At time: 523.5030896663666 and batch: 100, loss is 3.739758515357971 and perplexity is 42.08782537428159
At time: 523.8511683940887 and batch: 150, loss is 3.56253755569458 and perplexity is 35.252539023316956
At time: 524.2140138149261 and batch: 200, loss is 3.7114184999465945 and perplexity is 40.91179877064019
At time: 524.5597920417786 and batch: 250, loss is 3.7961488342285157 and perplexity is 44.52936388881357
At time: 524.8985583782196 and batch: 300, loss is 3.7569242238998415 and perplexity is 42.816529183087034
At time: 525.2612133026123 and batch: 350, loss is 3.7395720529556273 and perplexity is 42.07997830886695
At time: 525.6508409976959 and batch: 400, loss is 3.523094801902771 and perplexity is 33.88914653460511
At time: 525.9888031482697 and batch: 450, loss is 3.6306544446945193 and perplexity is 37.737505647853624
At time: 526.3572340011597 and batch: 500, loss is 3.6093466758728026 and perplexity is 36.94190988806835
At time: 526.7087459564209 and batch: 550, loss is 3.669341163635254 and perplexity is 39.22605379441382
At time: 527.0632772445679 and batch: 600, loss is 3.6034061908721924 and perplexity is 36.72310756589004
At time: 527.4143290519714 and batch: 650, loss is 3.64865327835083 and perplexity is 38.42288625762824
At time: 527.7654724121094 and batch: 700, loss is 3.7108469152450563 and perplexity is 40.888420894205225
At time: 528.1038227081299 and batch: 750, loss is 3.665594806671143 and perplexity is 39.07937392374064
At time: 528.4757690429688 and batch: 800, loss is 3.579053530693054 and perplexity is 35.839603704484865
At time: 528.8292210102081 and batch: 850, loss is 3.5405510091781616 and perplexity is 34.48591601290552
At time: 529.2083404064178 and batch: 900, loss is 3.434492588043213 and perplexity is 31.01567084986145
At time: 529.5609040260315 and batch: 950, loss is 3.5915471744537353 and perplexity is 36.290179753116746
At time: 529.9169733524323 and batch: 1000, loss is 3.6099259281158447 and perplexity is 36.96331477104801
At time: 530.2683537006378 and batch: 1050, loss is 3.5419603204727172 and perplexity is 34.53455166718421
At time: 530.5968704223633 and batch: 1100, loss is 3.6944336128234863 and perplexity is 40.22278446580564
At time: 530.9378244876862 and batch: 1150, loss is 3.593784017562866 and perplexity is 36.37144604771773
At time: 531.2821967601776 and batch: 1200, loss is 3.5449050951004026 and perplexity is 34.636398022395205
At time: 531.6413288116455 and batch: 1250, loss is 3.4096155881881716 and perplexity is 30.253612177916896
At time: 532.0063529014587 and batch: 1300, loss is 3.53123637676239 and perplexity is 34.166183787523565
At time: 532.3505012989044 and batch: 1350, loss is 3.5327788639068602 and perplexity is 34.21892535292755
At time: 532.7062728404999 and batch: 1400, loss is 3.3787921857833862 and perplexity is 29.335318093026796
At time: 533.0629842281342 and batch: 1450, loss is 3.488374433517456 and perplexity is 32.732695262962125
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287450806707398 and perplexity of 72.78069974837581
Annealing...
Finished 49 epochs...
Completing Train Step...
At time: 534.2425093650818 and batch: 50, loss is 3.696295042037964 and perplexity is 40.29772605949499
At time: 534.6172015666962 and batch: 100, loss is 3.7397587394714353 and perplexity is 42.087834806730996
At time: 534.9798562526703 and batch: 150, loss is 3.562537794113159 and perplexity is 35.252547428178225
At time: 535.3319947719574 and batch: 200, loss is 3.711419463157654 and perplexity is 40.9118381773562
At time: 535.6740791797638 and batch: 250, loss is 3.796149868965149 and perplexity is 44.529409965001484
At time: 536.0354146957397 and batch: 300, loss is 3.756924858093262 and perplexity is 42.816556337056745
At time: 536.3871078491211 and batch: 350, loss is 3.7395727968215944 and perplexity is 42.080009610742344
At time: 536.75523853302 and batch: 400, loss is 3.523093595504761 and perplexity is 33.889105650830835
At time: 537.1030352115631 and batch: 450, loss is 3.630653591156006 and perplexity is 37.737473437452906
At time: 537.4696774482727 and batch: 500, loss is 3.609344334602356 and perplexity is 36.941823397167745
At time: 537.8176329135895 and batch: 550, loss is 3.669340090751648 and perplexity is 39.22601170944636
At time: 538.1718819141388 and batch: 600, loss is 3.6034038639068604 and perplexity is 36.72302211259127
At time: 538.5343992710114 and batch: 650, loss is 3.648652653694153 and perplexity is 38.42286225652329
At time: 538.8708248138428 and batch: 700, loss is 3.7108445835113524 and perplexity is 40.888325553407284
At time: 539.2098574638367 and batch: 750, loss is 3.665593466758728 and perplexity is 39.079321560837435
At time: 539.5544698238373 and batch: 800, loss is 3.5790508604049682 and perplexity is 35.83950800254587
At time: 539.90940284729 and batch: 850, loss is 3.540549774169922 and perplexity is 34.48587342254139
At time: 540.2661147117615 and batch: 900, loss is 3.434489312171936 and perplexity is 31.0155692466826
At time: 540.594854593277 and batch: 950, loss is 3.59154541015625 and perplexity is 36.29011572650034
At time: 540.9407916069031 and batch: 1000, loss is 3.6099222898483276 and perplexity is 36.963180288865196
At time: 541.3050518035889 and batch: 1050, loss is 3.541955280303955 and perplexity is 34.53437760765432
At time: 541.6639695167542 and batch: 1100, loss is 3.6944286584854127 and perplexity is 40.22258518902678
At time: 542.0121397972107 and batch: 1150, loss is 3.5937799835205078 and perplexity is 36.371299324059684
At time: 542.3540778160095 and batch: 1200, loss is 3.5449003744125367 and perplexity is 34.63623451515728
At time: 542.6891932487488 and batch: 1250, loss is 3.409609718322754 and perplexity is 30.253434593806208
At time: 543.0324082374573 and batch: 1300, loss is 3.5312306594848635 and perplexity is 34.16598845052723
At time: 543.3754487037659 and batch: 1350, loss is 3.532773494720459 and perplexity is 34.21874162563211
At time: 543.7311940193176 and batch: 1400, loss is 3.378785700798035 and perplexity is 29.335127854535532
At time: 544.1110465526581 and batch: 1450, loss is 3.488367838859558 and perplexity is 32.73247940274655
Finished Train Step
Begin Evaluating...
Getting Batches...
Created Iterator with 118 batches
Done Evaluating: Achieved loss of 4.287450806707398 and perplexity of 72.78069974837581
Annealing...
Finished Training.
Improved accuracyfrom -79.09889043639028 to -72.78066178102347
<pretraining.langmodel.trainer.TrainLangModel object at 0x7f3cbddbdac8>
Saving Model Parameters and Results...
/home-nfs/siddsach/Interpreting-Attention/interpreting_language/trained_models/langmodel/



RESULTS:
[{'best_accuracy': -228.39466900152988, 'params': {'lr': 25.145396342418447, 'batch_size': 20, 'dropout': 0.500916955390465, 'wordvec_source': 'glove', 'anneal': 6.743474951113646, 'num_layers': 1, 'seq_len': 35, 'wordvec_dim': 200, 'tune_wordvecs': True, 'data': 'ptb'}}, {'best_accuracy': -90.35087601696883, 'params': {'lr': 10.67664684982944, 'batch_size': 20, 'dropout': 0.046121755424648025, 'wordvec_source': 'glove', 'anneal': 5.355902851142083, 'num_layers': 1, 'seq_len': 35, 'wordvec_dim': 200, 'tune_wordvecs': True, 'data': 'ptb'}}, {'best_accuracy': -242.22754526897492, 'params': {'lr': 22.75285281568356, 'batch_size': 20, 'dropout': 0.7521985588596631, 'wordvec_source': 'glove', 'anneal': 2.5011846208586856, 'num_layers': 1, 'seq_len': 35, 'wordvec_dim': 200, 'tune_wordvecs': True, 'data': 'ptb'}}, {'best_accuracy': -219.64134004945976, 'params': {'lr': 28.981646950798023, 'batch_size': 20, 'dropout': 0.8673038668667764, 'wordvec_source': 'glove', 'anneal': 3.365168688768163, 'num_layers': 1, 'seq_len': 35, 'wordvec_dim': 200, 'tune_wordvecs': True, 'data': 'ptb'}}, {'best_accuracy': -79.09889043639028, 'params': {'lr': 0.6456549527031341, 'batch_size': 20, 'dropout': 0.7685258544297481, 'wordvec_source': 'glove', 'anneal': 3.209469390982112, 'num_layers': 1, 'seq_len': 35, 'wordvec_dim': 200, 'tune_wordvecs': True, 'data': 'ptb'}}, {'best_accuracy': -72.78066178102347, 'params': {'lr': 4.899041561565707, 'batch_size': 20, 'dropout': 0.0, 'wordvec_source': 'glove', 'anneal': 7.307795951834938, 'num_layers': 1, 'seq_len': 35, 'wordvec_dim': 200, 'tune_wordvecs': True, 'data': 'ptb'}}]
